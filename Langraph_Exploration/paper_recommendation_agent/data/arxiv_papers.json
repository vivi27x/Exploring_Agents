[
  {
    "id": "2510.26802v1",
    "title": "Are Video Models Ready as Zero-Shot Reasoners? An Empirical Study with\n  the MME-CoF Benchmark",
    "abstract": "Recent video generation models can produce high-fidelity, temporally coherent\nvideos, indicating that they may encode substantial world knowledge. Beyond\nrealistic synthesis, they also exhibit emerging behaviors indicative of visual\nperception, modeling, and manipulation. Yet, an important question still\nremains: Are video models ready to serve as zero-shot reasoners in challenging\nvisual reasoning scenarios? In this work, we conduct an empirical study to\ncomprehensively investigate this question, focusing on the leading and popular\nVeo-3. We evaluate its reasoning behavior across 12 dimensions, including\nspatial, geometric, physical, temporal, and embodied logic, systematically\ncharacterizing both its strengths and failure modes. To standardize this study,\nwe curate the evaluation data into MME-CoF, a compact benchmark that enables\nin-depth and thorough assessment of Chain-of-Frame (CoF) reasoning. Our\nfindings reveal that while current video models demonstrate promising reasoning\npatterns on short-horizon spatial coherence, fine-grained grounding, and\nlocally consistent dynamics, they remain limited in long-horizon causal\nreasoning, strict geometric constraints, and abstract logic. Overall, they are\nnot yet reliable as standalone zero-shot reasoners, but exhibit encouraging\nsigns as complementary visual engines alongside dedicated reasoning models.\nProject page: https://video-cof.github.io",
    "categories": [
      "cs.CV",
      "cs.AI",
      "cs.CL"
    ],
    "published": "2025-10-30T17:59:55Z",
    "authors": [
      "Ziyu Guo",
      "Xinyan Chen",
      "Renrui Zhang",
      "Ruichuan An",
      "Yu Qi",
      "Dongzhi Jiang",
      "Xiangtai Li",
      "Manyuan Zhang",
      "Hongsheng Li",
      "Pheng-Ann Heng"
    ],
    "pdf_url": "http://arxiv.org/pdf/2510.26802v1"
  },
  {
    "id": "2510.26790v1",
    "title": "Gistify! Codebase-Level Understanding via Runtime Execution",
    "abstract": "As coding agents are increasingly deployed in large codebases, the need to\nautomatically design challenging, codebase-level evaluation is central. We\npropose Gistify, a task where a coding LLM must create a single, minimal,\nself-contained file that can reproduce a specific functionality of a codebase.\nThe coding LLM is given full access to a codebase along with a specific\nentrypoint (e.g., a python command), and the generated file must replicate the\noutput of the same command ran under the full codebase, while containing only\nthe essential components necessary to execute the provided command. Success on\nGistify requires both structural understanding of the codebase, accurate\nmodeling of its execution flow as well as the ability to produce potentially\nlarge code patches. Our findings show that current state-of-the-art models\nstruggle to reliably solve Gistify tasks, especially ones with long executions\ntraces.",
    "categories": [
      "cs.CL",
      "cs.AI"
    ],
    "published": "2025-10-30T17:58:26Z",
    "authors": [
      "Hyunji Lee",
      "Minseon Kim",
      "Chinmay Singh",
      "Matheus Pereira",
      "Atharv Sonwane",
      "Isadora White",
      "Elias Stengel-Eskin",
      "Mohit Bansal",
      "Zhengyan Shi",
      "Alessandro Sordoni",
      "Marc-Alexandre C\u00f4t\u00e9",
      "Xingdi Yuan",
      "Lucas Caccia"
    ],
    "pdf_url": "http://arxiv.org/pdf/2510.26790v1"
  },
  {
    "id": "2510.26788v1",
    "title": "Defeating the Training-Inference Mismatch via FP16",
    "abstract": "Reinforcement learning (RL) fine-tuning of large language models (LLMs) often\nsuffers from instability due to the numerical mismatch between the training and\ninference policies. While prior work has attempted to mitigate this issue\nthrough algorithmic corrections or engineering alignments, we show that its\nroot cause lies in the floating point precision itself. The widely adopted\nBF16, despite its large dynamic range, introduces large rounding errors that\nbreaks the consistency between training and inference. In this work, we\ndemonstrate that simply reverting to \\textbf{FP16} effectively eliminates this\nmismatch. The change is simple, fully supported by modern frameworks with only\na few lines of code change, and requires no modification to the model\narchitecture or learning algorithm. Our results suggest that using FP16\nuniformly yields more stable optimization, faster convergence, and stronger\nperformance across diverse tasks, algorithms and frameworks. We hope these\nfindings motivate a broader reconsideration of precision trade-offs in RL\nfine-tuning.",
    "categories": [
      "cs.LG",
      "cs.AI",
      "cs.CL"
    ],
    "published": "2025-10-30T17:58:11Z",
    "authors": [
      "Penghui Qi",
      "Zichen Liu",
      "Xiangxin Zhou",
      "Tianyu Pang",
      "Chao Du",
      "Wee Sun Lee",
      "Min Lin"
    ],
    "pdf_url": "http://arxiv.org/pdf/2510.26788v1"
  },
  {
    "id": "2510.26787v1",
    "title": "Remote Labor Index: Measuring AI Automation of Remote Work",
    "abstract": "AIs have made rapid progress on research-oriented benchmarks of knowledge and\nreasoning, but it remains unclear how these gains translate into economic value\nand automation. To measure this, we introduce the Remote Labor Index (RLI), a\nbroadly multi-sector benchmark comprising real-world, economically valuable\nprojects designed to evaluate end-to-end agent performance in practical\nsettings. AI agents perform near the floor on RLI, with the highest-performing\nagent achieving an automation rate of 2.5%. These results help ground\ndiscussions of AI automation in empirical evidence, setting a common basis for\ntracking AI impacts and enabling stakeholders to proactively navigate AI-driven\nlabor automation.",
    "categories": [
      "cs.LG",
      "cs.AI",
      "cs.CL"
    ],
    "published": "2025-10-30T17:58:04Z",
    "authors": [
      "Mantas Mazeika",
      "Alice Gatti",
      "Cristina Menghini",
      "Udari Madhushani Sehwag",
      "Shivam Singhal",
      "Yury Orlovskiy",
      "Steven Basart",
      "Manasi Sharma",
      "Denis Peskoff",
      "Elaine Lau",
      "Jaehyuk Lim",
      "Lachlan Carroll",
      "Alice Blair",
      "Vinaya Sivakumar",
      "Sumana Basu",
      "Brad Kenstler",
      "Yuntao Ma",
      "Julian Michael",
      "Xiaoke Li",
      "Oliver Ingebretsen",
      "Aditya Mehta",
      "Jean Mottola",
      "John Teichmann",
      "Kevin Yu",
      "Zaina Shaik",
      "Adam Khoja",
      "Richard Ren",
      "Jason Hausenloy",
      "Long Phan",
      "Ye Htet",
      "Ankit Aich",
      "Tahseen Rabbani",
      "Vivswan Shah",
      "Andriy Novykov",
      "Felix Binder",
      "Kirill Chugunov",
      "Luis Ramirez",
      "Matias Geralnik",
      "Hern\u00e1n Mesura",
      "Dean Lee",
      "Ed-Yeremai Hernandez Cardona",
      "Annette Diamond",
      "Summer Yue",
      "Alexandr Wang",
      "Bing Liu",
      "Ernesto Hernandez",
      "Dan Hendrycks"
    ],
    "pdf_url": "http://arxiv.org/pdf/2510.26787v1"
  },
  {
    "id": "2510.26784v1",
    "title": "LLMs Process Lists With General Filter Heads",
    "abstract": "We investigate the mechanisms underlying a range of list-processing tasks in\nLLMs, and we find that LLMs have learned to encode a compact, causal\nrepresentation of a general filtering operation that mirrors the generic\n\"filter\" function of functional programming. Using causal mediation analysis on\na diverse set of list-processing tasks, we find that a small number of\nattention heads, which we dub filter heads, encode a compact representation of\nthe filtering predicate in their query states at certain tokens. We demonstrate\nthat this predicate representation is general and portable: it can be extracted\nand reapplied to execute the same filtering operation on different collections,\npresented in different formats, languages, or even in tasks. However, we also\nidentify situations where transformer LMs can exploit a different strategy for\nfiltering: eagerly evaluating if an item satisfies the predicate and storing\nthis intermediate result as a flag directly in the item representations. Our\nresults reveal that transformer LMs can develop human-interpretable\nimplementations of abstract computational operations that generalize in ways\nthat are surprisingly similar to strategies used in traditional functional\nprogramming patterns.",
    "categories": [
      "cs.AI"
    ],
    "published": "2025-10-30T17:57:17Z",
    "authors": [
      "Arnab Sen Sharma",
      "Giordano Rogers",
      "Natalie Shapira",
      "David Bau"
    ],
    "pdf_url": "http://arxiv.org/pdf/2510.26784v1"
  },
  {
    "id": "2510.26782v1",
    "title": "Clone Deterministic 3D Worlds with Geometrically-Regularized World\n  Models",
    "abstract": "A world model is an internal model that simulates how the world evolves.\nGiven past observations and actions, it predicts the future of both the\nembodied agent and its environment. Accurate world models are essential for\nenabling agents to think, plan, and reason effectively in complex, dynamic\nsettings. Despite rapid progress, current world models remain brittle and\ndegrade over long horizons. We argue that a central cause is representation\nquality: exteroceptive inputs (e.g., images) are high-dimensional, and lossy or\nentangled latents make dynamics learning unnecessarily hard. We therefore ask\nwhether improving representation learning alone can substantially improve\nworld-model performance. In this work, we take a step toward building a truly\naccurate world model by addressing a fundamental yet open problem: constructing\na model that can fully clone and overfit to a deterministic 3D world. We\npropose Geometrically-Regularized World Models (GRWM), which enforces that\nconsecutive points along a natural sensory trajectory remain close in latent\nrepresentation space. This approach yields significantly improved latent\nrepresentations that align closely with the true topology of the environment.\nGRWM is plug-and-play, requires only minimal architectural modification, scales\nwith trajectory length, and is compatible with diverse latent generative\nbackbones. Across deterministic 3D settings and long-horizon prediction tasks,\nGRWM significantly increases rollout fidelity and stability. Analyses show that\nits benefits stem from learning a latent manifold with superior geometric\nstructure. These findings support a clear takeaway: improving representation\nlearning is a direct and useful path to robust world models, delivering\nreliable long-horizon predictions without enlarging the dynamics module.",
    "categories": [
      "cs.LG",
      "cs.AI",
      "cs.CV"
    ],
    "published": "2025-10-30T17:56:43Z",
    "authors": [
      "Zaishuo Xia",
      "Yukuan Lu",
      "Xinyi Li",
      "Yifan Xu",
      "Yubei Chen"
    ],
    "pdf_url": "http://arxiv.org/pdf/2510.26782v1"
  },
  {
    "id": "2510.26776v1",
    "title": "Faithful and Fast Influence Function via Advanced Sampling",
    "abstract": "How can we explain the influence of training data on black-box models?\nInfluence functions (IFs) offer a post-hoc solution by utilizing gradients and\nHessians. However, computing the Hessian for an entire dataset is\nresource-intensive, necessitating a feasible alternative. A common approach\ninvolves randomly sampling a small subset of the training data, but this method\noften results in highly inconsistent IF estimates due to the high variance in\nsample configurations. To address this, we propose two advanced sampling\ntechniques based on features and logits. These samplers select a small yet\nrepresentative subset of the entire dataset by considering the stochastic\ndistribution of features or logits, thereby enhancing the accuracy of IF\nestimations. We validate our approach through class removal experiments, a\ntypical application of IFs, using the F1-score to measure how effectively the\nmodel forgets the removed class while maintaining inference consistency on the\nremaining classes. Our method reduces computation time by 30.1% and memory\nusage by 42.2%, or improves the F1-score by 2.5% compared to the baseline.",
    "categories": [
      "cs.LG",
      "cs.AI"
    ],
    "published": "2025-10-30T17:55:19Z",
    "authors": [
      "Jungyeon Koh",
      "Hyeonsu Lyu",
      "Jonggyu Jang",
      "Hyun Jong Yang"
    ],
    "pdf_url": "http://arxiv.org/pdf/2510.26776v1"
  },
  {
    "id": "2510.26771v1",
    "title": "STaMP: Sequence Transformation and Mixed Precision for Low-Precision\n  Activation Quantization",
    "abstract": "Quantization is the key method for reducing inference latency, power and\nmemory footprint of generative AI models. However, accuracy often degrades\nsharply when activations are quantized below eight bits. Recent work suggests\nthat invertible linear transformations (e.g. rotations) can aid quantization,\nby reparameterizing feature channels and weights. In this paper, we propose\n\\textit{Sequence Transformation and Mixed Precision} (STaMP) quantization, a\nnovel strategy that applies linear transformations along the \\textit{sequence}\ndimension to exploit the strong local correlation in language and visual data.\nBy keeping a small number of tokens in each intermediate activation at higher\nprecision, we can maintain model accuracy at lower (average) activations\nbit-widths. We evaluate STaMP on recent LVM and LLM architectures,\ndemonstrating that it significantly improves low bit width activation\nquantization and complements established activation and weight quantization\nmethods including recent feature transformations.",
    "categories": [
      "cs.LG",
      "cs.AI"
    ],
    "published": "2025-10-30T17:53:42Z",
    "authors": [
      "Marco Federici",
      "Riccardo Del Chiaro",
      "Boris van Breugel",
      "Paul Whatmough",
      "Markus Nagel"
    ],
    "pdf_url": "http://arxiv.org/pdf/2510.26771v1"
  },
  {
    "id": "2510.26768v1",
    "title": "AMO-Bench: Large Language Models Still Struggle in High School Math\n  Competitions",
    "abstract": "We present AMO-Bench, an Advanced Mathematical reasoning benchmark with\nOlympiad level or even higher difficulty, comprising 50 human-crafted problems.\nExisting benchmarks have widely leveraged high school math competitions for\nevaluating mathematical reasoning capabilities of large language models (LLMs).\nHowever, many existing math competitions are becoming less effective for\nassessing top-tier LLMs due to performance saturation (e.g., AIME24/25). To\naddress this, AMO-Bench introduces more rigorous challenges by ensuring all 50\nproblems are (1) cross-validated by experts to meet at least the International\nMathematical Olympiad (IMO) difficulty standards, and (2) entirely original\nproblems to prevent potential performance leakages from data memorization.\nMoreover, each problem in AMO-Bench requires only a final answer rather than a\nproof, enabling automatic and robust grading for evaluation. Experimental\nresults across 26 LLMs on AMO-Bench show that even the best-performing model\nachieves only 52.4% accuracy on AMO-Bench, with most LLMs scoring below 40%.\nBeyond these poor performances, our further analysis reveals a promising\nscaling trend with increasing test-time compute on AMO-Bench. These results\nhighlight the significant room for improving the mathematical reasoning in\ncurrent LLMs. We release AMO-Bench to facilitate further research into\nadvancing the reasoning abilities of language models.\nhttps://amo-bench.github.io/",
    "categories": [
      "cs.CL",
      "cs.AI"
    ],
    "published": "2025-10-30T17:52:02Z",
    "authors": [
      "Shengnan An",
      "Xunliang Cai",
      "Xuezhi Cao",
      "Xiaoyu Li",
      "Yehao Lin",
      "Junlin Liu",
      "Xinxuan Lv",
      "Dan Ma",
      "Xuanlin Wang",
      "Ziwen Wang",
      "Shuang Zhou"
    ],
    "pdf_url": "http://arxiv.org/pdf/2510.26768v1"
  },
  {
    "id": "2510.26752v1",
    "title": "The Oversight Game: Learning to Cooperatively Balance an AI Agent's\n  Safety and Autonomy",
    "abstract": "As increasingly capable agents are deployed, a central safety question is how\nto retain meaningful human control without modifying the underlying system. We\nstudy a minimal control interface where an agent chooses whether to act\nautonomously (play) or defer (ask), while a human simultaneously chooses\nwhether to be permissive (trust) or to engage in oversight (oversee). If the\nagent defers, the human's choice determines the outcome, potentially leading to\na corrective action or a system shutdown. We model this interaction as a\ntwo-player Markov Game. Our analysis focuses on cases where this game qualifies\nas a Markov Potential Game (MPG), a class of games where we can provide an\nalignment guarantee: under a structural assumption on the human's value\nfunction, any decision by the agent to act more autonomously that benefits\nitself cannot harm the human's value. We also analyze extensions to this MPG\nframework. Theoretically, this perspective provides conditions for a specific\nform of intrinsic alignment. If the reward structures of the human-agent game\nmeet these conditions, we have a formal guarantee that the agent improving its\nown outcome will not harm the human's. Practically, this model motivates a\ntransparent control layer with predictable incentives where the agent learns to\ndefer when risky and act when safe, while its pretrained policy and the\nenvironment's reward structure remain untouched. Our gridworld simulation shows\nthat through independent learning, the agent and human discover their optimal\noversight roles. The agent learns to ask when uncertain and the human learns\nwhen to oversee, leading to an emergent collaboration that avoids safety\nviolations introduced post-training. This demonstrates a practical method for\nmaking misaligned models safer after deployment.",
    "categories": [
      "cs.AI",
      "cs.LG"
    ],
    "published": "2025-10-30T17:46:49Z",
    "authors": [
      "William Overman",
      "Mohsen Bayati"
    ],
    "pdf_url": "http://arxiv.org/pdf/2510.26752v1"
  },
  {
    "id": "2510.26745v1",
    "title": "Deep sequence models tend to memorize geometrically; it is unclear why",
    "abstract": "In sequence modeling, the parametric memory of atomic facts has been\npredominantly abstracted as a brute-force lookup of co-occurrences between\nentities. We contrast this associative view against a geometric view of how\nmemory is stored. We begin by isolating a clean and analyzable instance of\nTransformer reasoning that is incompatible with memory as strictly a storage of\nthe local co-occurrences specified during training. Instead, the model must\nhave somehow synthesized its own geometry of atomic facts, encoding global\nrelationships between all entities, including non-co-occurring ones. This in\nturn has simplified a hard reasoning task involving an $\\ell$-fold composition\ninto an easy-to-learn 1-step geometric task.\n  From this phenomenon, we extract fundamental aspects of neural embedding\ngeometries that are hard to explain. We argue that the rise of such a geometry,\ndespite optimizing over mere local associations, cannot be straightforwardly\nattributed to typical architectural or optimizational pressures.\nCounterintuitively, an elegant geometry is learned even when it is not more\nsuccinct than a brute-force lookup of associations.\n  Then, by analyzing a connection to Node2Vec, we demonstrate how the geometry\nstems from a spectral bias that -- in contrast to prevailing theories -- indeed\narises naturally despite the lack of various pressures. This analysis also\npoints to practitioners a visible headroom to make Transformer memory more\nstrongly geometric. We hope the geometric view of parametric memory encourages\nrevisiting the default intuitions that guide researchers in areas like\nknowledge acquisition, capacity, discovery and unlearning.",
    "categories": [
      "cs.LG",
      "cs.AI",
      "cs.CL",
      "stat.ML"
    ],
    "published": "2025-10-30T17:40:22Z",
    "authors": [
      "Shahriar Noroozizadeh",
      "Vaishnavh Nagarajan",
      "Elan Rosenfeld",
      "Sanjiv Kumar"
    ],
    "pdf_url": "http://arxiv.org/pdf/2510.26745v1"
  },
  {
    "id": "2510.26740v1",
    "title": "A General Incentives-Based Framework for Fairness in Multi-agent\n  Resource Allocation",
    "abstract": "We introduce the General Incentives-based Framework for Fairness (GIFF), a\nnovel approach for fair multi-agent resource allocation that infers fair\ndecision-making from standard value functions. In resource-constrained\nsettings, agents optimizing for efficiency often create inequitable outcomes.\nOur approach leverages the action-value (Q-)function to balance efficiency and\nfairness without requiring additional training. Specifically, our method\ncomputes a local fairness gain for each action and introduces a counterfactual\nadvantage correction term to discourage over-allocation to already well-off\nagents. This approach is formalized within a centralized control setting, where\nan arbitrator uses the GIFF-modified Q-values to solve an allocation problem.\n  Empirical evaluations across diverse domains, including dynamic ridesharing,\nhomelessness prevention, and a complex job allocation task-demonstrate that our\nframework consistently outperforms strong baselines and can discover\nfar-sighted, equitable policies. The framework's effectiveness is supported by\na theoretical foundation; we prove its fairness surrogate is a principled lower\nbound on the true fairness improvement and that its trade-off parameter offers\nmonotonic tuning. Our findings establish GIFF as a robust and principled\nframework for leveraging standard reinforcement learning components to achieve\nmore equitable outcomes in complex multi-agent systems.",
    "categories": [
      "cs.MA",
      "cs.AI"
    ],
    "published": "2025-10-30T17:37:51Z",
    "authors": [
      "Ashwin Kumar",
      "William Yeoh"
    ],
    "pdf_url": "http://arxiv.org/pdf/2510.26740v1"
  },
  {
    "id": "2510.26732v1",
    "title": "Cross-Platform Evaluation of Reasoning Capabilities in Foundation Models",
    "abstract": "This paper presents a comprehensive cross-platform evaluation of reasoning\ncapabilities in contemporary foundation models, establishing an\ninfrastructure-agnostic benchmark across three computational paradigms: HPC\nsupercomputing (MareNostrum 5), cloud platforms (Nebius AI Studio), and\nuniversity clusters (a node with eight H200 GPUs).\n  We evaluate 15 foundation models across 79 problems spanning eight academic\ndomains (Physics, Mathematics, Chemistry, Economics, Biology, Statistics,\nCalculus, and Optimization) through three experimental phases: (1) Baseline\nestablishment: Six models (Mixtral-8x7B, Phi-3, LLaMA 3.1-8B, Gemma-2-9b,\nMistral-7B, OLMo-7B) evaluated on 19 problems using MareNostrum 5, establishing\nmethodology and reference performance; (2) Infrastructure validation: The\n19-problem benchmark repeated on university cluster (seven models including\nFalcon-Mamba state-space architecture) and Nebius AI Studio (nine\nstate-of-the-art models: Hermes-4 70B/405B, LLaMA 3.1-405B/3.3-70B, Qwen3\n30B/235B, DeepSeek-R1, GPT-OSS 20B/120B) to confirm infrastructure-agnostic\nreproducibility; (3) Extended evaluation: Full 79-problem assessment on both\nuniversity cluster and Nebius platforms, probing generalization at scale across\narchitectural diversity.\n  The findings challenge conventional scaling assumptions, establish training\ndata quality as more critical than model size, and provide actionable\nguidelines for model selection across educational, production, and research\ncontexts. The tri-infrastructure methodology and 79-problem benchmark enable\nlongitudinal tracking of reasoning capabilities as foundation models evolve.",
    "categories": [
      "cs.AI",
      "cs.CL"
    ],
    "published": "2025-10-30T17:31:03Z",
    "authors": [
      "J. de Curt\u00f2",
      "I. de Zarz\u00e0",
      "Pablo Garc\u00eda",
      "Jordi Cabot"
    ],
    "pdf_url": "http://arxiv.org/pdf/2510.26732v1"
  },
  {
    "id": "2510.26730v1",
    "title": "ExpertFlow: Adaptive Expert Scheduling and Memory Coordination for\n  Efficient MoE Inference",
    "abstract": "The expansion of large language models is increasingly limited by the\nconstrained memory capacity of modern GPUs. To mitigate this,\nMixture-of-Experts (MoE) architectures activate only a small portion of\nparameters during inference, significantly lowering both memory demand and\ncomputational overhead. However, conventional MoE inference approaches, which\nselect active experts independently at each layer, often introduce considerable\nlatency because of frequent parameter transfers between host and GPU memory. In\naddition, current cross-layer prediction strategies, which are typically based\non fixed steps, lack adaptability across different hardware platforms and\nworkloads, thereby reducing their robustness and effectiveness.\n  To address these challenges, we present ExpertFlow, a runtime system for MoE\ninference that combines adaptive expert prefetching and cache-aware routing.\nExpertFlow continuously adjusts its prediction horizon for expert activation by\nleveraging runtime statistics such as transfer bandwidth, parameter\ndimensionality, and model feedback signals. Furthermore, it incorporates a\nhybrid cross-layer prediction scheme that fuses pregating information with\nintermediate computational states to anticipate future expert needs. By\nadaptively refining prefetching decisions and aligning them with actual usage\nbehavior, ExpertFlow effectively decreases cache misses and removes latency\ncaused by expert swap-ins. Our evaluation demonstrates that ExpertFlow reduces\nmodel stall time to less than 0.1% of the baseline, highlighting its capability\nto optimize MoE inference under stringent memory constraints.",
    "categories": [
      "cs.DC",
      "cs.AI",
      "cs.PF"
    ],
    "published": "2025-10-30T17:29:27Z",
    "authors": [
      "Zixu Shen",
      "Kexin Chu",
      "Yifan Zhang",
      "Dawei Xiang",
      "Runxin Wu",
      "Wei Zhang"
    ],
    "pdf_url": "http://arxiv.org/pdf/2510.26730v1"
  },
  {
    "id": "2510.26722v1",
    "title": "Non-Convex Over-the-Air Heterogeneous Federated Learning: A\n  Bias-Variance Trade-off",
    "abstract": "Over-the-air (OTA) federated learning (FL) has been well recognized as a\nscalable paradigm that exploits the waveform superposition of the wireless\nmultiple-access channel to aggregate model updates in a single use. Existing\nOTA-FL designs largely enforce zero-bias model updates by either assuming\n\\emph{homogeneous} wireless conditions (equal path loss across devices) or\nforcing zero-bias updates to guarantee convergence. Under \\emph{heterogeneous}\nwireless scenarios, however, such designs are constrained by the weakest device\nand inflate the update variance. Moreover, prior analyses of biased OTA-FL\nlargely address convex objectives, while most modern AI models are highly\nnon-convex. Motivated by these gaps, we study OTA-FL with stochastic gradient\ndescent (SGD) for general smooth non-convex objectives under wireless\nheterogeneity. We develop novel OTA-FL SGD updates that allow a structured,\ntime-invariant model bias while facilitating reduced variance updates. We\nderive a finite-time stationarity bound (expected time average squared gradient\nnorm) that explicitly reveals a bias-variance trade-off. To optimize this\ntrade-off, we pose a non-convex joint OTA power-control design and develop an\nefficient successive convex approximation (SCA) algorithm that requires only\nstatistical CSI at the base station. Experiments on a non-convex image\nclassification task validate the approach: the SCA-based design accelerates\nconvergence via an optimized bias and improves generalization over prior OTA-FL\nbaselines.",
    "categories": [
      "cs.LG",
      "cs.AI",
      "cs.DC",
      "cs.SY",
      "eess.SP",
      "eess.SY"
    ],
    "published": "2025-10-30T17:22:57Z",
    "authors": [
      "Muhammad Faraz Ul Abrar",
      "Nicol\u00f2 Michelusi"
    ],
    "pdf_url": "http://arxiv.org/pdf/2510.26722v1"
  },
  {
    "id": "2510.26721v1",
    "title": "Unveiling Intrinsic Text Bias in Multimodal Large Language Models\n  through Attention Key-Space Analysis",
    "abstract": "Multimodal large language models (MLLMs) exhibit a pronounced preference for\ntextual inputs when processing vision-language data, limiting their ability to\nreason effectively from visual evidence. Unlike prior studies that attribute\nthis text bias to external factors such as data imbalance or instruction\ntuning, we propose that the bias originates from the model's internal\narchitecture. Specifically, we hypothesize that visual key vectors (Visual\nKeys) are out-of-distribution (OOD) relative to the text key space learned\nduring language-only pretraining. Consequently, these visual keys receive\nsystematically lower similarity scores during attention computation, leading to\ntheir under-utilization in the context representation. To validate this\nhypothesis, we extract key vectors from LLaVA and Qwen2.5-VL and analyze their\ndistributional structures using qualitative (t-SNE) and quantitative\n(Jensen-Shannon divergence) methods. The results provide direct evidence that\nvisual and textual keys occupy markedly distinct subspaces within the attention\nspace. The inter-modal divergence is statistically significant, exceeding\nintra-modal variation by several orders of magnitude. These findings reveal\nthat text bias arises from an intrinsic misalignment within the attention key\nspace rather than solely from external data factors.",
    "categories": [
      "cs.AI",
      "cs.MM"
    ],
    "published": "2025-10-30T17:22:22Z",
    "authors": [
      "Xinhan Zheng",
      "Huyu Wu",
      "Xueting Wang",
      "Haiyun Jiang"
    ],
    "pdf_url": "http://arxiv.org/pdf/2510.26721v1"
  },
  {
    "id": "2510.26714v1",
    "title": "On the limitation of evaluating machine unlearning using only a single\n  training seed",
    "abstract": "Machine unlearning (MU) aims to remove the influence of certain data points\nfrom a trained model without costly retraining. Most practical MU algorithms\nare only approximate and their performance can only be assessed empirically.\nCare must therefore be taken to make empirical comparisons as representative as\npossible. A common practice is to run the MU algorithm multiple times\nindependently starting from the same trained model. In this work, we\ndemonstrate that this practice can give highly non-representative results\nbecause -- even for the same architecture and same dataset -- some MU methods\ncan be highly sensitive to the choice of random number seed used for model\ntraining. We therefore recommend that empirical\ncomphttps://info.arxiv.org/help/prep#commentsarisons of MU algorithms should\nalso reflect the variability across different model training seeds.",
    "categories": [
      "cs.LG",
      "cs.AI"
    ],
    "published": "2025-10-30T17:13:42Z",
    "authors": [
      "Jamie Lanyon",
      "Axel Finke",
      "Petros Andreou",
      "Georgina Cosma"
    ],
    "pdf_url": "http://arxiv.org/pdf/2510.26714v1"
  },
  {
    "id": "2510.26702v1",
    "title": "Delegated Authorization for Agents Constrained to Semantic Task-to-Scope\n  Matching",
    "abstract": "Authorizing Large Language Model driven agents to dynamically invoke tools\nand access protected resources introduces significant risks, since current\nmethods for delegating authorization grant overly broad permissions and give\naccess to tools allowing agents to operate beyond the intended task scope. We\nintroduce and assess a delegated authorization model enabling authorization\nservers to semantically inspect access requests to protected resources, and\nissue access tokens constrained to the minimal set of scopes necessary for the\nagents' assigned tasks. Given the unavailability of datasets centered on\ndelegated authorization flows, particularly including both semantically\nappropriate and inappropriate scope requests for a given task, we introduce\nASTRA, a dataset and data generation pipeline for benchmarking semantic\nmatching between tasks and scopes. Our experiments show both the potential and\ncurrent limitations of model-based matching, particularly as the number of\nscopes needed for task completion increases. Our results highlight the need for\nfurther research into semantic matching techniques enabling intent-aware\nauthorization for multi-agent and tool-augmented applications, including\nfine-grained control, such as Task-Based Access Control (TBAC).",
    "categories": [
      "cs.AI"
    ],
    "published": "2025-10-30T17:07:00Z",
    "authors": [
      "Majed El Helou",
      "Chiara Troiani",
      "Benjamin Ryder",
      "Jean Diaconu",
      "Herv\u00e9 Muyal",
      "Marcelo Yannuzzi"
    ],
    "pdf_url": "http://arxiv.org/pdf/2510.26702v1"
  },
  {
    "id": "2510.26697v1",
    "title": "The End of Manual Decoding: Towards Truly End-to-End Language Models",
    "abstract": "The \"end-to-end\" label for LLMs is a misnomer. In practice, they depend on a\nnon-differentiable decoding process that requires laborious, hand-tuning of\nhyperparameters like temperature and top-p. This paper introduces AutoDeco, a\nnovel architecture that enables truly \"end-to-end\" generation by learning to\ncontrol its own decoding strategy. We augment the standard transformer with\nlightweight heads that, at each step, dynamically predict context-specific\ntemperature and top-p values alongside the next-token logits. This approach\ntransforms decoding into a parametric, token-level process, allowing the model\nto self-regulate its sampling strategy within a single forward pass.\n  Through extensive experiments on eight benchmarks, we demonstrate that\nAutoDeco not only significantly outperforms default decoding strategies but\nalso achieves performance comparable to an oracle-tuned baseline derived from\n\"hacking the test set\"-a practical upper bound for any static method.\nCrucially, we uncover an emergent capability for instruction-based decoding\ncontrol: the model learns to interpret natural language commands (e.g.,\n\"generate with low randomness\") and adjusts its predicted temperature and top-p\non a token-by-token basis, opening a new paradigm for steerable and interactive\nLLM decoding.",
    "categories": [
      "cs.CL",
      "cs.AI"
    ],
    "published": "2025-10-30T17:01:43Z",
    "authors": [
      "Zhichao Wang",
      "Dongyang Ma",
      "Xinting Huang",
      "Deng Cai",
      "Tian Lan",
      "Jiahao Xu",
      "Haitao Mi",
      "Xiaoying Tang",
      "Yan Wang"
    ],
    "pdf_url": "http://arxiv.org/pdf/2510.26697v1"
  },
  {
    "id": "2510.26684v1",
    "title": "Process Integrated Computer Vision for Real-Time Failure Prediction in\n  Steel Rolling Mill",
    "abstract": "We present a long-term deployment study of a machine vision-based anomaly\ndetection system for failure prediction in a steel rolling mill. The system\nintegrates industrial cameras to monitor equipment operation, alignment, and\nhot bar motion in real time along the process line. Live video streams are\nprocessed on a centralized video server using deep learning models, enabling\nearly prediction of equipment failures and process interruptions, thereby\nreducing unplanned breakdown costs. Server-based inference minimizes the\ncomputational load on industrial process control systems (PLCs), supporting\nscalable deployment across production lines with minimal additional resources.\nBy jointly analyzing sensor data from data acquisition systems and visual\ninputs, the system identifies the location and probable root causes of\nfailures, providing actionable insights for proactive maintenance. This\nintegrated approach enhances operational reliability, productivity, and\nprofitability in industrial manufacturing environments.",
    "categories": [
      "cs.CV",
      "cs.AI"
    ],
    "published": "2025-10-30T16:54:16Z",
    "authors": [
      "Vaibhav Kurrey",
      "Sivakalyan Pujari",
      "Gagan Raj Gupta"
    ],
    "pdf_url": "http://arxiv.org/pdf/2510.26684v1"
  },
  {
    "id": "2510.26683v1",
    "title": "Evontree: Ontology Rule-Guided Self-Evolution of Large Language Models",
    "abstract": "Large language models (LLMs) have demonstrated exceptional capabilities\nacross multiple domains by leveraging massive pre-training and curated\nfine-tuning data. However, in data-sensitive fields such as healthcare, the\nlack of high-quality, domain-specific training corpus hinders LLMs' adaptation\nfor specialized applications. Meanwhile, domain experts have distilled domain\nwisdom into ontology rules, which formalize relationships among concepts and\nensure the integrity of knowledge management repositories. Viewing LLMs as\nimplicit repositories of human knowledge, we propose Evontree, a novel\nframework that leverages a small set of high-quality ontology rules to\nsystematically extract, validate, and enhance domain knowledge within LLMs,\nwithout requiring extensive external datasets. Specifically, Evontree extracts\ndomain ontology from raw models, detects inconsistencies using two core\nontology rules, and reinforces the refined knowledge via self-distilled\nfine-tuning. Extensive experiments on medical QA benchmarks with\nLlama3-8B-Instruct and Med42-v2 demonstrate consistent outperformance over both\nunmodified models and leading supervised baselines, achieving up to a 3.7%\nimprovement in accuracy. These results confirm the effectiveness, efficiency,\nand robustness of our approach for low-resource domain adaptation of LLMs.",
    "categories": [
      "cs.CL",
      "cs.AI"
    ],
    "published": "2025-10-30T16:53:45Z",
    "authors": [
      "Mingchen Tu",
      "Zhiqiang Liu",
      "Juan Li",
      "Liangyurui Liu",
      "Junjie Wang",
      "Lei Liang",
      "Wen Zhang"
    ],
    "pdf_url": "http://arxiv.org/pdf/2510.26683v1"
  },
  {
    "id": "2510.26658v1",
    "title": "The Era of Agentic Organization: Learning to Organize with Language\n  Models",
    "abstract": "We envision a new era of AI, termed agentic organization, where agents solve\ncomplex problems by working collaboratively and concurrently, enabling outcomes\nbeyond individual intelligence. To realize this vision, we introduce\nasynchronous thinking (AsyncThink) as a new paradigm of reasoning with large\nlanguage models, which organizes the internal thinking process into\nconcurrently executable structures. Specifically, we propose a thinking\nprotocol where an organizer dynamically assigns sub-queries to workers, merges\nintermediate knowledge, and produces coherent solutions. More importantly, the\nthinking structure in this protocol can be further optimized through\nreinforcement learning. Experiments demonstrate that AsyncThink achieves 28%\nlower inference latency compared to parallel thinking while improving accuracy\non mathematical reasoning. Moreover, AsyncThink generalizes its learned\nasynchronous thinking capabilities, effectively tackling unseen tasks without\nadditional training.",
    "categories": [
      "cs.AI",
      "cs.CL"
    ],
    "published": "2025-10-30T16:25:10Z",
    "authors": [
      "Zewen Chi",
      "Li Dong",
      "Qingxiu Dong",
      "Yaru Hao",
      "Xun Wu",
      "Shaohan Huang",
      "Furu Wei"
    ],
    "pdf_url": "http://arxiv.org/pdf/2510.26658v1"
  },
  {
    "id": "2510.26646v1",
    "title": "Hybrid DQN-TD3 Reinforcement Learning for Autonomous Navigation in\n  Dynamic Environments",
    "abstract": "This paper presents a hierarchical path-planning and control framework that\ncombines a high-level Deep Q-Network (DQN) for discrete sub-goal selection with\na low-level Twin Delayed Deep Deterministic Policy Gradient (TD3) controller\nfor continuous actuation. The high-level module selects behaviors and\nsub-goals; the low-level module executes smooth velocity commands. We design a\npractical reward shaping scheme (direction, distance, obstacle avoidance,\naction smoothness, collision penalty, time penalty, and progress), together\nwith a LiDAR-based safety gate that prevents unsafe motions. The system is\nimplemented in ROS + Gazebo (TurtleBot3) and evaluated with PathBench metrics,\nincluding success rate, collision rate, path efficiency, and re-planning\nefficiency, in dynamic and partially observable environments. Experiments show\nimproved success rate and sample efficiency over single-algorithm baselines\n(DQN or TD3 alone) and rule-based planners, with better generalization to\nunseen obstacle configurations and reduced abrupt control changes. Code and\nevaluation scripts are available at the project repository.",
    "categories": [
      "cs.RO",
      "cs.AI",
      "cs.LG"
    ],
    "published": "2025-10-30T16:12:01Z",
    "authors": [
      "Xiaoyi He",
      "Danggui Chen",
      "Zhenshuo Zhang",
      "Zimeng Bai"
    ],
    "pdf_url": "http://arxiv.org/pdf/2510.26646v1"
  },
  {
    "id": "2510.26616v1",
    "title": "Aeolus: A Multi-structural Flight Delay Dataset",
    "abstract": "We introduce Aeolus, a large-scale Multi-modal Flight Delay Dataset designed\nto advance research on flight delay prediction and support the development of\nfoundation models for tabular data. Existing datasets in this domain are\ntypically limited to flat tabular structures and fail to capture the\nspatiotemporal dynamics inherent in delay propagation. Aeolus addresses this\nlimitation by providing three aligned modalities: (i) a tabular dataset with\nrich operational, meteorological, and airportlevel features for over 50 million\nflights; (ii) a flight chain module that models delay propagation along\nsequential flight legs, capturing upstream and downstream dependencies; and\n(iii) a flight network graph that encodes shared aircraft, crew, and airport\nresource connections, enabling cross-flight relational reasoning. The dataset\nis carefully constructed with temporal splits, comprehensive features, and\nstrict leakage prevention to support realistic and reproducible machine\nlearning evaluation. Aeolus supports a broad range of tasks, including\nregression, classification, temporal structure modeling, and graph learning,\nserving as a unified benchmark across tabular, sequential, and graph\nmodalities. We release baseline experiments and preprocessing tools to\nfacilitate adoption. Aeolus fills a key gap for both domain-specific modeling\nand general-purpose structured data research.Our source code and data can be\naccessed at https://github.com/Flnny/Delay-data",
    "categories": [
      "cs.LG",
      "cs.AI"
    ],
    "published": "2025-10-30T15:41:43Z",
    "authors": [
      "Lin Xu",
      "Xinyun Yuan",
      "Yuxuan Liang",
      "Suwan Yin",
      "Yuankai Wu"
    ],
    "pdf_url": "http://arxiv.org/pdf/2510.26616v1"
  },
  {
    "id": "2510.26606v1",
    "title": "Normative Reasoning in Large Language Models: A Comparative Benchmark\n  from Logical and Modal Perspectives",
    "abstract": "Normative reasoning is a type of reasoning that involves normative or deontic\nmodality, such as obligation and permission. While large language models (LLMs)\nhave demonstrated remarkable performance across various reasoning tasks, their\nability to handle normative reasoning remains underexplored. In this paper, we\nsystematically evaluate LLMs' reasoning capabilities in the normative domain\nfrom both logical and modal perspectives. Specifically, to assess how well LLMs\nreason with normative modals, we make a comparison between their reasoning with\nnormative modals and their reasoning with epistemic modals, which share a\ncommon formal structure. To this end, we introduce a new dataset covering a\nwide range of formal patterns of reasoning in both normative and epistemic\ndomains, while also incorporating non-formal cognitive factors that influence\nhuman reasoning. Our results indicate that, although LLMs generally adhere to\nvalid reasoning patterns, they exhibit notable inconsistencies in specific\ntypes of normative reasoning and display cognitive biases similar to those\nobserved in psychological studies of human reasoning. These findings highlight\nchallenges in achieving logical consistency in LLMs' normative reasoning and\nprovide insights for enhancing their reliability. All data and code are\nreleased publicly at https://github.com/kmineshima/NeuBAROCO.",
    "categories": [
      "cs.AI",
      "cs.CL"
    ],
    "published": "2025-10-30T15:35:13Z",
    "authors": [
      "Kentaro Ozeki",
      "Risako Ando",
      "Takanobu Morishita",
      "Hirohiko Abe",
      "Koji Mineshima",
      "Mitsuhiro Okada"
    ],
    "pdf_url": "http://arxiv.org/pdf/2510.26606v1"
  },
  {
    "id": "2510.26603v1",
    "title": "Agentic AI Home Energy Management System: A Large Language Model\n  Framework for Residential Load Scheduling",
    "abstract": "The electricity sector transition requires substantial increases in\nresidential demand response capacity, yet Home Energy Management Systems (HEMS)\nadoption remains limited by user interaction barriers requiring translation of\neveryday preferences into technical parameters. While large language models\nhave been applied to energy systems as code generators and parameter\nextractors, no existing implementation deploys LLMs as autonomous coordinators\nmanaging the complete workflow from natural language input to multi-appliance\nscheduling. This paper presents an agentic AI HEMS where LLMs autonomously\ncoordinate multi-appliance scheduling from natural language requests to device\ncontrol, achieving optimal scheduling without example demonstrations. A\nhierarchical architecture combining one orchestrator with three specialist\nagents uses the ReAct pattern for iterative reasoning, enabling dynamic\ncoordination without hardcoded workflows while integrating Google Calendar for\ncontext-aware deadline extraction. Evaluation across three open-source models\nusing real Austrian day-ahead electricity prices reveals substantial capability\ndifferences. Llama-3.3-70B successfully coordinates all appliances across all\nscenarios to match cost-optimal benchmarks computed via mixed-integer linear\nprogramming, while other models achieve perfect single-appliance performance\nbut struggle to coordinate all appliances simultaneously. Progressive prompt\nengineering experiments demonstrate that analytical query handling without\nexplicit guidance remains unreliable despite models' general reasoning\ncapabilities. We open-source the complete system including orchestration logic,\nagent prompts, tools, and web interfaces to enable reproducibility, extension,\nand future research.",
    "categories": [
      "cs.AI",
      "cs.MA",
      "cs.SY",
      "eess.SY"
    ],
    "published": "2025-10-30T15:33:52Z",
    "authors": [
      "Reda El Makroum",
      "Sebastian Zwickl-Bernhard",
      "Lukas Kranzl"
    ],
    "pdf_url": "http://arxiv.org/pdf/2510.26603v1"
  },
  {
    "id": "2510.26601v1",
    "title": "ResMatching: Noise-Resilient Computational Super-Resolution via Guided\n  Conditional Flow Matching",
    "abstract": "Computational Super-Resolution (CSR) in fluorescence microscopy has, despite\nbeing an ill-posed problem, a long history. At its very core, CSR is about\nfinding a prior that can be used to extrapolate frequencies in a micrograph\nthat have never been imaged by the image-generating microscope. It stands to\nreason that, with the advent of better data-driven machine learning techniques,\nstronger prior can be learned and hence CSR can lead to better results. Here,\nwe present ResMatching, a novel CSR method that uses guided conditional flow\nmatching to learn such improved data-priors. We evaluate ResMatching on 4\ndiverse biological structures from the BioSR dataset and compare its results\nagainst 7 baselines. ResMatching consistently achieves competitive results,\ndemonstrating in all cases the best trade-off between data fidelity and\nperceptual realism. We observe that CSR using ResMatching is particularly\neffective in cases where a strong prior is hard to learn, e.g. when the given\nlow-resolution images contain a lot of noise. Additionally, we show that\nResMatching can be used to sample from an implicitly learned posterior\ndistribution and that this distribution is calibrated for all tested use-cases,\nenabling our method to deliver a pixel-wise data-uncertainty term that can\nguide future users to reject uncertain predictions.",
    "categories": [
      "cs.CV",
      "cs.AI"
    ],
    "published": "2025-10-30T15:29:20Z",
    "authors": [
      "Anirban Ray",
      "Vera Galinova",
      "Florian Jug"
    ],
    "pdf_url": "http://arxiv.org/pdf/2510.26601v1"
  },
  {
    "id": "2510.26585v1",
    "title": "Stop Wasting Your Tokens: Towards Efficient Runtime Multi-Agent Systems",
    "abstract": "While Multi-Agent Systems (MAS) excel at complex tasks, their growing\nautonomy with operational complexity often leads to critical inefficiencies,\nsuch as excessive token consumption and failures arising from misinformation.\nExisting methods primarily focus on post-hoc failure attribution, lacking\nproactive, real-time interventions to enhance robustness and efficiency. To\nthis end, we introduce SupervisorAgent, a lightweight and modular framework for\nruntime, adaptive supervision that operates without altering the base agent's\narchitecture. Triggered by an LLM-free adaptive filter, SupervisorAgent\nintervenes at critical junctures to proactively correct errors, guide\ninefficient behaviors, and purify observations. On the challenging GAIA\nbenchmark, SupervisorAgent reduces the token consumption of the Smolagent\nframework by an average of 29.45% without compromising its success rate.\nExtensive experiments across five additional benchmarks (math reasoning, code\ngeneration, and question answering) and various SoTA foundation models validate\nthe broad applicability and robustness of our approach. The code is available\nat https://github.com/LINs-lab/SupervisorAgent.",
    "categories": [
      "cs.MA",
      "cs.AI"
    ],
    "published": "2025-10-30T15:12:59Z",
    "authors": [
      "Fulin Lin",
      "Shaowen Chen",
      "Ruishan Fang",
      "Hongwei Wang",
      "Tao Lin"
    ],
    "pdf_url": "http://arxiv.org/pdf/2510.26585v1"
  },
  {
    "id": "2510.26575v1",
    "title": "InfoFlow: Reinforcing Search Agent Via Reward Density Optimization",
    "abstract": "Reinforcement Learning with Verifiable Rewards (RLVR) is a promising approach\nfor enhancing agentic deep search. However, its application is often hindered\nby low \\textbf{Reward Density} in deep search scenarios, where agents expend\nsignificant exploratory costs for infrequent and often null final rewards. In\nthis paper, we formalize this challenge as the \\textbf{Reward Density\nOptimization} problem, which aims to improve the reward obtained per unit of\nexploration cost. This paper introduce \\textbf{InfoFlow}, a systematic\nframework that tackles this problem from three aspects. 1) \\textbf{Subproblem\ndecomposition}: breaking down long-range tasks to assign process rewards,\nthereby providing denser learning signals. 2) \\textbf{Failure-guided hints}:\ninjecting corrective guidance into stalled trajectories to increase the\nprobability of successful outcomes. 3) \\textbf{Dual-agent refinement}:\nemploying a dual-agent architecture to offload the cognitive burden of deep\nexploration. A refiner agent synthesizes the search history, which effectively\ncompresses the researcher's perceived trajectory, thereby reducing exploration\ncost and increasing the overall reward density. We evaluate InfoFlow on\nmultiple agentic search benchmarks, where it significantly outperforms strong\nbaselines, enabling lightweight LLMs to achieve performance comparable to\nadvanced proprietary LLMs.",
    "categories": [
      "cs.CL",
      "cs.AI"
    ],
    "published": "2025-10-30T15:03:21Z",
    "authors": [
      "Kun Luo",
      "Hongjin Qian",
      "Zheng Liu",
      "Ziyi Xia",
      "Shitao Xiao",
      "Siqi Bao",
      "Jun Zhao",
      "Kang Liu"
    ],
    "pdf_url": "http://arxiv.org/pdf/2510.26575v1"
  },
  {
    "id": "2510.26566v1",
    "title": "Multiclass Local Calibration With the Jensen-Shannon Distance",
    "abstract": "Developing trustworthy Machine Learning (ML) models requires their predicted\nprobabilities to be well-calibrated, meaning they should reflect true-class\nfrequencies. Among calibration notions in multiclass classification, strong\ncalibration is the most stringent, as it requires all predicted probabilities\nto be simultaneously calibrated across all classes. However, existing\napproaches to multiclass calibration lack a notion of distance among inputs,\nwhich makes them vulnerable to proximity bias: predictions in sparse regions of\nthe feature space are systematically miscalibrated. This is especially relevant\nin high-stakes settings, such as healthcare, where the sparse instances are\nexactly those most at risk of biased treatment. In this work, we address this\nmain shortcoming by introducing a local perspective on multiclass calibration.\nFirst, we formally define multiclass local calibration and establish its\nrelationship with strong calibration. Second, we theoretically analyze the\npitfalls of existing evaluation metrics when applied to multiclass local\ncalibration. Third, we propose a practical method for enhancing local\ncalibration in Neural Networks, which enforces alignment between predicted\nprobabilities and local estimates of class frequencies using the Jensen-Shannon\ndistance. Finally, we empirically validate our approach against existing\nmulticlass calibration techniques.",
    "categories": [
      "cs.LG",
      "cs.AI"
    ],
    "published": "2025-10-30T14:56:07Z",
    "authors": [
      "Cesare Barbera",
      "Lorenzo Perini",
      "Giovanni De Toni",
      "Andrea Passerini",
      "Andrea Pugnana"
    ],
    "pdf_url": "http://arxiv.org/pdf/2510.26566v1"
  },
  {
    "id": "2510.26551v1",
    "title": "Adaptive Inverse Kinematics Framework for Learning Variable-Length Tool\n  Manipulation in Robotics",
    "abstract": "Conventional robots possess a limited understanding of their kinematics and\nare confined to preprogrammed tasks, hindering their ability to leverage tools\nefficiently. Driven by the essential components of tool usage - grasping the\ndesired outcome, selecting the most suitable tool, determining optimal tool\norientation, and executing precise manipulations - we introduce a pioneering\nframework. Our novel approach expands the capabilities of the robot's inverse\nkinematics solver, empowering it to acquire a sequential repertoire of actions\nusing tools of varying lengths. By integrating a simulation-learned action\ntrajectory with the tool, we showcase the practicality of transferring acquired\nskills from simulation to real-world scenarios through comprehensive\nexperimentation. Remarkably, our extended inverse kinematics solver\ndemonstrates an impressive error rate of less than 1 cm. Furthermore, our\ntrained policy achieves a mean error of 8 cm in simulation. Noteworthy, our\nmodel achieves virtually indistinguishable performance when employing two\ndistinct tools of different lengths. This research provides an indication of\npotential advances in the exploration of all four fundamental aspects of tool\nusage, enabling robots to master the intricate art of tool manipulation across\ndiverse tasks.",
    "categories": [
      "cs.RO",
      "cs.AI",
      "cs.LG"
    ],
    "published": "2025-10-30T14:44:24Z",
    "authors": [
      "Prathamesh Kothavale",
      "Sravani Boddepalli"
    ],
    "pdf_url": "http://arxiv.org/pdf/2510.26551v1"
  },
  {
    "id": "2510.26550v1",
    "title": "EdgeRunner 20B: Military Task Parity with GPT-5 while Running on the\n  Edge",
    "abstract": "We present EdgeRunner 20B, a fine-tuned version of gpt-oss-20b optimized for\nmilitary tasks. EdgeRunner 20B was trained on 1.6M high-quality records curated\nfrom military documentation and websites. We also present four new tests sets:\n(a) combat arms, (b) combat medic, (c) cyber operations, and (d) mil-bench-5k\n(general military knowledge). On these military test sets, EdgeRunner 20B\nmatches or exceeds GPT-5 task performance with 95%+ statistical significance,\nexcept for the high reasoning setting on the combat medic test set and the low\nreasoning setting on the mil-bench-5k test set. Versus gpt-oss-20b, there is no\nstatistically-significant regression on general-purpose benchmarks like ARC-C,\nGPQA Diamond, GSM8k, IFEval, MMLU Pro, or TruthfulQA, except for GSM8k in the\nlow reasoning setting. We also present analyses on hyperparameter settings,\ncost, and throughput. These findings show that small, locally-hosted models are\nideal solutions for data-sensitive operations such as in the military domain,\nallowing for deployment in air-gapped edge devices.",
    "categories": [
      "cs.AI"
    ],
    "published": "2025-10-30T14:43:26Z",
    "authors": [
      "Jack FitzGerald",
      "Aristotelis Lazaridis",
      "Dylan Bates",
      "Aman Sharma",
      "Jonnathan Castillo",
      "Yousif Azami",
      "Sean Bailey",
      "Jeremy Cao",
      "Peter Damianov",
      "Kevin de Haan",
      "Luke Kerbs",
      "Vincent Lu",
      "Joseph Madigan",
      "Jeremy McLaurin",
      "Jonathan Tainer",
      "Dave Anderson",
      "Jonathan Beck",
      "Jamie Cuticello",
      "Colton Malkerson",
      "Tyler Saltsman"
    ],
    "pdf_url": "http://arxiv.org/pdf/2510.26550v1"
  },
  {
    "id": "2510.26543v1",
    "title": "The Structure of Relation Decoding Linear Operators in Large Language\n  Models",
    "abstract": "This paper investigates the structure of linear operators introduced in\nHernandez et al. [2023] that decode specific relational facts in transformer\nlanguage models. We extend their single-relation findings to a collection of\nrelations and systematically chart their organization. We show that such\ncollections of relation decoders can be highly compressed by simple order-3\ntensor networks without significant loss in decoding accuracy. To explain this\nsurprising redundancy, we develop a cross-evaluation protocol, in which we\napply each linear decoder operator to the subjects of every other relation. Our\nresults reveal that these linear maps do not encode distinct relations, but\nextract recurring, coarse-grained semantic properties (e.g., country of capital\ncity and country of food are both in the country-of-X property). This\nproperty-centric structure clarifies both the operators' compressibility and\nhighlights why they generalize only to new relations that are semantically\nclose. Our findings thus interpret linear relational decoding in transformer\nlanguage models as primarily property-based, rather than relation-specific.",
    "categories": [
      "cs.CL",
      "cs.AI",
      "cs.LG"
    ],
    "published": "2025-10-30T14:36:09Z",
    "authors": [
      "Miranda Anna Christ",
      "Adri\u00e1n Csisz\u00e1rik",
      "Gergely Becs\u00f3",
      "D\u00e1niel Varga"
    ],
    "pdf_url": "http://arxiv.org/pdf/2510.26543v1"
  },
  {
    "id": "2510.26518v1",
    "title": "Human-AI Complementarity: A Goal for Amplified Oversight",
    "abstract": "Human feedback is critical for aligning AI systems to human values. As AI\ncapabilities improve and AI is used to tackle more challenging tasks, verifying\nquality and safety becomes increasingly challenging. This paper explores how we\ncan leverage AI to improve the quality of human oversight. We focus on an\nimportant safety problem that is already challenging for humans:\nfact-verification of AI outputs. We find that combining AI ratings and human\nratings based on AI rater confidence is better than relying on either alone.\nGiving humans an AI fact-verification assistant further improves their\naccuracy, but the type of assistance matters. Displaying AI explanation,\nconfidence, and labels leads to over-reliance, but just showing search results\nand evidence fosters more appropriate trust. These results have implications\nfor Amplified Oversight -- the challenge of combining humans and AI to\nsupervise AI systems even as they surpass human expert performance.",
    "categories": [
      "cs.AI",
      "cs.HC"
    ],
    "published": "2025-10-30T14:11:52Z",
    "authors": [
      "Rishub Jain",
      "Sophie Bridgers",
      "Lili Janzer",
      "Rory Greig",
      "Tian Huey Teh",
      "Vladimir Mikulik"
    ],
    "pdf_url": "http://arxiv.org/pdf/2510.26518v1"
  },
  {
    "id": "2510.26512v1",
    "title": "Inside CORE-KG: Evaluating Structured Prompting and Coreference\n  Resolution for Knowledge Graphs",
    "abstract": "Human smuggling networks are increasingly adaptive and difficult to analyze.\nLegal case documents offer critical insights but are often unstructured,\nlexically dense, and filled with ambiguous or shifting references, which pose\nsignificant challenges for automated knowledge graph (KG) construction. While\nrecent LLM-based approaches improve over static templates, they still generate\nnoisy, fragmented graphs with duplicate nodes due to the absence of guided\nextraction and coreference resolution. The recently proposed CORE-KG framework\naddresses these limitations by integrating a type-aware coreference module and\ndomain-guided structured prompts, significantly reducing node duplication and\nlegal noise. In this work, we present a systematic ablation study of CORE-KG to\nquantify the individual contributions of its two key components. Our results\nshow that removing coreference resolution results in a 28.32% increase in node\nduplication and a 4.32% increase in noisy nodes, while removing structured\nprompts leads to a 4.34% increase in node duplication and a 73.33% increase in\nnoisy nodes. These findings offer empirical insights for designing robust\nLLM-based pipelines for extracting structured representations from complex\nlegal texts.",
    "categories": [
      "cs.CL",
      "cs.AI",
      "cs.IR",
      "cs.LG"
    ],
    "published": "2025-10-30T14:05:55Z",
    "authors": [
      "Dipak Meher",
      "Carlotta Domeniconi"
    ],
    "pdf_url": "http://arxiv.org/pdf/2510.26512v1"
  },
  {
    "id": "2510.26494v1",
    "title": "Simulating and Experimenting with Social Media Mobilization Using LLM\n  Agents",
    "abstract": "Online social networks have transformed the ways in which political\nmobilization messages are disseminated, raising new questions about how peer\ninfluence operates at scale. Building on the landmark 61-million-person\nFacebook experiment \\citep{bond201261}, we develop an agent-based simulation\nframework that integrates real U.S. Census demographic distributions, authentic\nTwitter network topology, and heterogeneous large language model (LLM) agents\nto examine the effect of mobilization messages on voter turnout. Each simulated\nagent is assigned demographic attributes, a personal political stance, and an\nLLM variant (\\texttt{GPT-4.1}, \\texttt{GPT-4.1-Mini}, or \\texttt{GPT-4.1-Nano})\nreflecting its political sophistication. Agents interact over realistic social\nnetwork structures, receiving personalized feeds and dynamically updating their\nengagement behaviors and voting intentions. Experimental conditions replicate\nthe informational and social mobilization treatments of the original Facebook\nstudy. Across scenarios, the simulator reproduces qualitative patterns observed\nin field experiments, including stronger mobilization effects under social\nmessage treatments and measurable peer spillovers. Our framework provides a\ncontrolled, reproducible environment for testing counterfactual designs and\nsensitivity analyses in political mobilization research, offering a bridge\nbetween high-validity field experiments and flexible computational\nmodeling.\\footnote{Code and data available at\nhttps://github.com/CausalMP/LLM-SocioPol}",
    "categories": [
      "cs.SI",
      "cs.AI"
    ],
    "published": "2025-10-30T13:43:28Z",
    "authors": [
      "Sadegh Shirani",
      "Mohsen Bayati"
    ],
    "pdf_url": "http://arxiv.org/pdf/2510.26494v1"
  },
  {
    "id": "2510.26493v1",
    "title": "Context Engineering 2.0: The Context of Context Engineering",
    "abstract": "Karl Marx once wrote that ``the human essence is the ensemble of social\nrelations'', suggesting that individuals are not isolated entities but are\nfundamentally shaped by their interactions with other entities, within which\ncontexts play a constitutive and essential role. With the advent of computers\nand artificial intelligence, these contexts are no longer limited to purely\nhuman--human interactions: human--machine interactions are included as well.\nThen a central question emerges: How can machines better understand our\nsituations and purposes? To address this challenge, researchers have recently\nintroduced the concept of context engineering. Although it is often regarded as\na recent innovation of the agent era, we argue that related practices can be\ntraced back more than twenty years. Since the early 1990s, the field has\nevolved through distinct historical phases, each shaped by the intelligence\nlevel of machines: from early human--computer interaction frameworks built\naround primitive computers, to today's human--agent interaction paradigms\ndriven by intelligent agents, and potentially to human--level or superhuman\nintelligence in the future. In this paper, we situate context engineering,\nprovide a systematic definition, outline its historical and conceptual\nlandscape, and examine key design considerations for practice. By addressing\nthese questions, we aim to offer a conceptual foundation for context\nengineering and sketch its promising future. This paper is a stepping stone for\na broader community effort toward systematic context engineering in AI systems.",
    "categories": [
      "cs.AI",
      "cs.CL"
    ],
    "published": "2025-10-30T13:43:10Z",
    "authors": [
      "Qishuo Hua",
      "Lyumanshan Ye",
      "Dayuan Fu",
      "Yang Xiao",
      "Xiaojie Cai",
      "Yunze Wu",
      "Jifan Lin",
      "Junfei Wang",
      "Pengfei Liu"
    ],
    "pdf_url": "http://arxiv.org/pdf/2510.26493v1"
  },
  {
    "id": "2510.26486v1",
    "title": "LINK-KG: LLM-Driven Coreference-Resolved Knowledge Graphs for Human\n  Smuggling Networks",
    "abstract": "Human smuggling networks are complex and constantly evolving, making them\ndifficult to analyze comprehensively. Legal case documents offer rich factual\nand procedural insights into these networks but are often long, unstructured,\nand filled with ambiguous or shifting references, posing significant challenges\nfor automated knowledge graph (KG) construction. Existing methods either\noverlook coreference resolution or fail to scale beyond short text spans,\nleading to fragmented graphs and inconsistent entity linking. We propose\nLINK-KG, a modular framework that integrates a three-stage, LLM-guided\ncoreference resolution pipeline with downstream KG extraction. At the core of\nour approach is a type-specific Prompt Cache, which consistently tracks and\nresolves references across document chunks, enabling clean and disambiguated\nnarratives for structured knowledge graph construction from both short and long\nlegal texts. LINK-KG reduces average node duplication by 45.21% and noisy nodes\nby 32.22% compared to baseline methods, resulting in cleaner and more coherent\ngraph structures. These improvements establish LINK-KG as a strong foundation\nfor analyzing complex criminal networks.",
    "categories": [
      "cs.AI",
      "cs.IR",
      "cs.LG"
    ],
    "published": "2025-10-30T13:39:08Z",
    "authors": [
      "Dipak Meher",
      "Carlotta Domeniconi",
      "Guadalupe Correa-Cabrera"
    ],
    "pdf_url": "http://arxiv.org/pdf/2510.26486v1"
  },
  {
    "id": "2510.26484v1",
    "title": "Bayesian Network Fusion of Large Language Models for Sentiment Analysis",
    "abstract": "Large language models (LLMs) continue to advance, with an increasing number\nof domain-specific variants tailored for specialised tasks. However, these\nmodels often lack transparency and explainability, can be costly to fine-tune,\nrequire substantial prompt engineering, yield inconsistent results across\ndomains, and impose significant adverse environmental impact due to their high\ncomputational demands. To address these challenges, we propose the Bayesian\nnetwork LLM fusion (BNLF) framework, which integrates predictions from three\nLLMs, including FinBERT, RoBERTa, and BERTweet, through a probabilistic\nmechanism for sentiment analysis. BNLF performs late fusion by modelling the\nsentiment predictions from multiple LLMs as probabilistic nodes within a\nBayesian network. Evaluated across three human-annotated financial corpora with\ndistinct linguistic and contextual characteristics, BNLF demonstrates\nconsistent gains of about six percent in accuracy over the baseline LLMs,\nunderscoring its robustness to dataset variability and the effectiveness of\nprobabilistic fusion for interpretable sentiment classification.",
    "categories": [
      "cs.CL",
      "cs.AI"
    ],
    "published": "2025-10-30T13:37:58Z",
    "authors": [
      "Rasoul Amirzadeh",
      "Dhananjay Thiruvady",
      "Fatemeh Shiri"
    ],
    "pdf_url": "http://arxiv.org/pdf/2510.26484v1"
  },
  {
    "id": "2510.26481v1",
    "title": "Who Has The Final Say? Conformity Dynamics in ChatGPT's Selections",
    "abstract": "Large language models (LLMs) such as ChatGPT are increasingly integrated into\nhigh-stakes decision-making, yet little is known about their susceptibility to\nsocial influence. We conducted three preregistered conformity experiments with\nGPT-4o in a hiring context. In a baseline study, GPT consistently favored the\nsame candidate (Profile C), reported moderate expertise (M = 3.01) and high\ncertainty (M = 3.89), and rarely changed its choice. In Study 1 (GPT + 8), GPT\nfaced unanimous opposition from eight simulated partners and almost always\nconformed (99.9%), reporting lower certainty and significantly elevated\nself-reported informational and normative conformity (p < .001). In Study 2\n(GPT + 1), GPT interacted with a single partner and still conformed in 40.2% of\ndisagreement trials, reporting less certainty and more normative conformity.\nAcross studies, results demonstrate that GPT does not act as an independent\nobserver but adapts to perceived social consensus. These findings highlight\nrisks of treating LLMs as neutral decision aids and underline the need to\nelicit AI judgments prior to exposing them to human opinions.",
    "categories": [
      "cs.AI"
    ],
    "published": "2025-10-30T13:35:32Z",
    "authors": [
      "Clarissa Sabrina Arlinghaus",
      "Tristan Kenneweg",
      "Barbara Hammer",
      "G\u00fcnter W. Maier"
    ],
    "pdf_url": "http://arxiv.org/pdf/2510.26481v1"
  },
  {
    "id": "2510.26474v1",
    "title": "Counteracting Matthew Effect in Self-Improvement of LVLMs through\n  Head-Tail Re-balancing",
    "abstract": "Self-improvement has emerged as a mainstream paradigm for advancing the\nreasoning capabilities of large vision-language models (LVLMs), where models\nexplore and learn from successful trajectories iteratively. However, we\nidentify a critical issue during this process: the model excels at generating\nhigh-quality trajectories for simple queries (i.e., head data) but struggles\nwith more complex ones (i.e., tail data). This leads to an imbalanced\noptimization that drives the model to prioritize simple reasoning skills, while\nhindering its ability to tackle more complex reasoning tasks. Over iterations,\nthis imbalance becomes increasingly pronounced--a dynamic we term the \"Matthew\neffect\"--which ultimately hinders further model improvement and leads to\nperformance bottlenecks. To counteract this challenge, we introduce four\nefficient strategies from two perspectives: distribution-reshaping and\ntrajectory-resampling, to achieve head-tail re-balancing during the\nexploration-and-learning self-improvement process. Extensive experiments on\nQwen2-VL-7B-Instruct and InternVL2.5-4B models across visual reasoning tasks\ndemonstrate that our methods consistently improve visual reasoning\ncapabilities, outperforming vanilla self-improvement by 3.86 points on average.",
    "categories": [
      "cs.CV",
      "cs.AI",
      "cs.CL",
      "cs.LG"
    ],
    "published": "2025-10-30T13:26:58Z",
    "authors": [
      "Xin Guo",
      "Zhiheng Xi",
      "Yiwen Ding",
      "Yitao Zhai",
      "Xiaowei Shi",
      "Xunliang Cai",
      "Tao Gui",
      "Qi Zhang",
      "Xuanjing Huang"
    ],
    "pdf_url": "http://arxiv.org/pdf/2510.26474v1"
  },
  {
    "id": "2510.26457v1",
    "title": "SecureReviewer: Enhancing Large Language Models for Secure Code Review\n  through Secure-aware Fine-tuning",
    "abstract": "Identifying and addressing security issues during the early phase of the\ndevelopment lifecycle is critical for mitigating the long-term negative impacts\non software systems. Code review serves as an effective practice that enables\ndevelopers to check their teammates' code before integration into the codebase.\nTo streamline the generation of review comments, various automated code review\napproaches have been proposed, where LLM-based methods have significantly\nadvanced the capabilities of automated review generation. However, existing\nmodels primarily focus on general-purpose code review, their effectiveness in\nidentifying and addressing security-related issues remains underexplored.\nMoreover, adapting existing code review approaches to target security issues\nfaces substantial challenges, including data scarcity and inadequate evaluation\nmetrics. To address these limitations, we propose SecureReviewer, a new\napproach designed for enhancing LLMs' ability to identify and resolve\nsecurity-related issues during code review. Specifically, we first construct a\ndataset tailored for training and evaluating secure code review capabilities.\nLeveraging this dataset, we fine-tune LLMs to generate code review comments\nthat can effectively identify security issues and provide fix suggestions with\nour proposed secure-aware fine-tuning strategy. To mitigate hallucination in\nLLMs and enhance the reliability of their outputs, we integrate the RAG\ntechnique, which grounds the generated comments in domain-specific security\nknowledge. Additionally, we introduce SecureBLEU, a new evaluation metric\ndesigned to assess the effectiveness of review comments in addressing security\nissues. Experimental results demonstrate that SecureReviewer outperforms\nstate-of-the-art baselines in both security issue detection accuracy and the\noverall quality and practical utility of generated review comments.",
    "categories": [
      "cs.SE",
      "cs.AI",
      "cs.CL"
    ],
    "published": "2025-10-30T13:06:11Z",
    "authors": [
      "Fang Liu",
      "Simiao Liu",
      "Yinghao Zhu",
      "Xiaoli Lian",
      "Li Zhang"
    ],
    "pdf_url": "http://arxiv.org/pdf/2510.26457v1"
  },
  {
    "id": "2510.26451v1",
    "title": "Robust Graph Condensation via Classification Complexity Mitigation",
    "abstract": "Graph condensation (GC) has gained significant attention for its ability to\nsynthesize smaller yet informative graphs. However, existing studies often\noverlook the robustness of GC in scenarios where the original graph is\ncorrupted. In such cases, we observe that the performance of GC deteriorates\nsignificantly, while existing robust graph learning technologies offer only\nlimited effectiveness. Through both empirical investigation and theoretical\nanalysis, we reveal that GC is inherently an intrinsic-dimension-reducing\nprocess, synthesizing a condensed graph with lower classification complexity.\nAlthough this property is critical for effective GC performance, it remains\nhighly vulnerable to adversarial perturbations. To tackle this vulnerability\nand improve GC robustness, we adopt the geometry perspective of graph data\nmanifold and propose a novel Manifold-constrained Robust Graph Condensation\nframework named MRGC. Specifically, we introduce three graph data manifold\nlearning modules that guide the condensed graph to lie within a smooth,\nlow-dimensional manifold with minimal class ambiguity, thereby preserving the\nclassification complexity reduction capability of GC and ensuring robust\nperformance under universal adversarial attacks. Extensive experiments\ndemonstrate the robustness of \\ModelName\\ across diverse attack scenarios.",
    "categories": [
      "cs.LG",
      "cs.AI"
    ],
    "published": "2025-10-30T12:55:21Z",
    "authors": [
      "Jiayi Luo",
      "Qingyun Sun",
      "Beining Yang",
      "Haonan Yuan",
      "Xingcheng Fu",
      "Yanbiao Ma",
      "Jianxin Li",
      "Philip S. Yu"
    ],
    "pdf_url": "http://arxiv.org/pdf/2510.26451v1"
  },
  {
    "id": "2510.26444v1",
    "title": "Personalized Treatment Outcome Prediction from Scarce Data via\n  Dual-Channel Knowledge Distillation and Adaptive Fusion",
    "abstract": "Personalized treatment outcome prediction based on trial data for\nsmall-sample and rare patient groups is critical in precision medicine.\nHowever, the costly trial data limit the prediction performance. To address\nthis issue, we propose a cross-fidelity knowledge distillation and adaptive\nfusion network (CFKD-AFN), which leverages abundant but low-fidelity simulation\ndata to enhance predictions on scarce but high-fidelity trial data. CFKD-AFN\nincorporates a dual-channel knowledge distillation module to extract\ncomplementary knowledge from the low-fidelity model, along with an\nattention-guided fusion module to dynamically integrate multi-source\ninformation. Experiments on treatment outcome prediction for the chronic\nobstructive pulmonary disease demonstrates significant improvements of CFKD-AFN\nover state-of-the-art methods in prediction accuracy, ranging from 6.67\\% to\n74.55\\%, and strong robustness to varying high-fidelity dataset sizes.\nFurthermore, we extend CFKD-AFN to an interpretable variant, enabling the\nexploration of latent medical semantics to support clinical decision-making.",
    "categories": [
      "cs.LG",
      "cs.AI"
    ],
    "published": "2025-10-30T12:50:12Z",
    "authors": [
      "Wenjie Chen",
      "Li Zhuang",
      "Ziying Luo",
      "Yu Liu",
      "Jiahao Wu",
      "Shengcai Liu"
    ],
    "pdf_url": "http://arxiv.org/pdf/2510.26444v1"
  },
  {
    "id": "2510.26420v1",
    "title": "SSCL-BW: Sample-Specific Clean-Label Backdoor Watermarking for Dataset\n  Ownership Verification",
    "abstract": "The rapid advancement of deep neural networks (DNNs) heavily relies on\nlarge-scale, high-quality datasets. However, unauthorized commercial use of\nthese datasets severely violates the intellectual property rights of dataset\nowners. Existing backdoor-based dataset ownership verification methods suffer\nfrom inherent limitations: poison-label watermarks are easily detectable due to\nlabel inconsistencies, while clean-label watermarks face high technical\ncomplexity and failure on high-resolution images. Moreover, both approaches\nemploy static watermark patterns that are vulnerable to detection and removal.\nTo address these issues, this paper proposes a sample-specific clean-label\nbackdoor watermarking (i.e., SSCL-BW). By training a U-Net-based watermarked\nsample generator, this method generates unique watermarks for each sample,\nfundamentally overcoming the vulnerability of static watermark patterns. The\ncore innovation lies in designing a composite loss function with three\ncomponents: target sample loss ensures watermark effectiveness, non-target\nsample loss guarantees trigger reliability, and perceptual similarity loss\nmaintains visual imperceptibility. During ownership verification, black-box\ntesting is employed to check whether suspicious models exhibit predefined\nbackdoor behaviors. Extensive experiments on benchmark datasets demonstrate the\neffectiveness of the proposed method and its robustness against potential\nwatermark removal attacks.",
    "categories": [
      "cs.CR",
      "cs.AI"
    ],
    "published": "2025-10-30T12:13:53Z",
    "authors": [
      "Yingjia Wang",
      "Ting Qiao",
      "Xing Liu",
      "Chongzuo Li",
      "Sixing Wu",
      "Jianbin Li"
    ],
    "pdf_url": "http://arxiv.org/pdf/2510.26420v1"
  },
  {
    "id": "2510.26418v1",
    "title": "Chain-of-Thought Hijacking",
    "abstract": "Large reasoning models (LRMs) achieve higher task performance by allocating\nmore inference-time compute, and prior works suggest this scaled reasoning may\nalso strengthen safety by improving refusal. Yet we find the opposite: the same\nreasoning can be used to bypass safeguards. We introduce Chain-of-Thought\nHijacking, a jailbreak attack on reasoning models. The attack pads harmful\nrequests with long sequences of harmless puzzle reasoning. Across HarmBench,\nCoT Hijacking reaches a 99%, 94%, 100%, and 94% attack success rate (ASR) on\nGemini 2.5 Pro, GPT o4 mini, Grok 3 mini, and Claude 4 Sonnet, respectively -\nfar exceeding prior jailbreak methods for LRMs. To understand the effectiveness\nof our attack, we turn to a mechanistic analysis, which shows that mid layers\nencode the strength of safety checking, while late layers encode the\nverification outcome. Long benign CoT dilutes both signals by shifting\nattention away from harmful tokens. Targeted ablations of attention heads\nidentified by this analysis causally decrease refusal, confirming their role in\na safety subnetwork. These results show that the most interpretable form of\nreasoning - explicit CoT - can itself become a jailbreak vector when combined\nwith final-answer cues. We release prompts, outputs, and judge decisions to\nfacilitate replication.",
    "categories": [
      "cs.AI"
    ],
    "published": "2025-10-30T12:10:03Z",
    "authors": [
      "Jianli Zhao",
      "Tingchen Fu",
      "Rylan Schaeffer",
      "Mrinank Sharma",
      "Fazl Barez"
    ],
    "pdf_url": "http://arxiv.org/pdf/2510.26418v1"
  },
  {
    "id": "2510.26412v1",
    "title": "LoCoT2V-Bench: A Benchmark for Long-Form and Complex Text-to-Video\n  Generation",
    "abstract": "Recently text-to-video generation has made impressive progress in producing\nshort, high-quality clips, but evaluating long-form outputs remains a major\nchallenge especially when processing complex prompts. Existing benchmarks\nmostly rely on simplified prompts and focus on low-level metrics, overlooking\nfine-grained alignment with prompts and abstract dimensions such as narrative\ncoherence and thematic expression. To address these gaps, we propose\nLoCoT2V-Bench, a benchmark specifically designed for long video generation\n(LVG) under complex input conditions. Based on various real-world videos,\nLoCoT2V-Bench introduces a suite of realistic and complex prompts incorporating\nelements like scene transitions and event dynamics. Moreover, it constructs a\nmulti-dimensional evaluation framework that includes our newly proposed metrics\nsuch as event-level alignment, fine-grained temporal consistency, content\nclarity, and the Human Expectation Realization Degree (HERD) that focuses on\nmore abstract attributes like narrative flow, emotional response, and character\ndevelopment. Using this framework, we conduct a comprehensive evaluation of\nnine representative LVG models, finding that while current methods perform well\non basic visual and temporal aspects, they struggle with inter-event\nconsistency, fine-grained alignment, and high-level thematic adherence, etc.\nOverall, LoCoT2V-Bench provides a comprehensive and reliable platform for\nevaluating long-form complex text-to-video generation and highlights critical\ndirections for future method improvement.",
    "categories": [
      "cs.CV",
      "cs.AI"
    ],
    "published": "2025-10-30T12:00:46Z",
    "authors": [
      "Xiangqing Zheng",
      "Chengyue Wu",
      "Kehai Chen",
      "Min Zhang"
    ],
    "pdf_url": "http://arxiv.org/pdf/2510.26412v1"
  },
  {
    "id": "2510.26411v1",
    "title": "MedSAE: Dissecting MedCLIP Representations with Sparse Autoencoders",
    "abstract": "Artificial intelligence in healthcare requires models that are accurate and\ninterpretable. We advance mechanistic interpretability in medical vision by\napplying Medical Sparse Autoencoders (MedSAEs) to the latent space of MedCLIP,\na vision-language model trained on chest radiographs and reports. To quantify\ninterpretability, we propose an evaluation framework that combines correlation\nmetrics, entropy analyzes, and automated neuron naming via the MedGEMMA\nfoundation model. Experiments on the CheXpert dataset show that MedSAE neurons\nachieve higher monosemanticity and interpretability than raw MedCLIP features.\nOur findings bridge high-performing medical AI and transparency, offering a\nscalable step toward clinically reliable representations.",
    "categories": [
      "cs.AI"
    ],
    "published": "2025-10-30T11:58:36Z",
    "authors": [
      "Riccardo Renzulli",
      "Colas Lepoutre",
      "Enrico Cassano",
      "Marco Grangetto"
    ],
    "pdf_url": "http://arxiv.org/pdf/2510.26411v1"
  },
  {
    "id": "2510.26406v1",
    "title": "Human-in-the-loop Online Rejection Sampling for Robotic Manipulation",
    "abstract": "Reinforcement learning (RL) is widely used to produce robust robotic\nmanipulation policies, but fine-tuning vision-language-action (VLA) models with\nRL can be unstable due to inaccurate value estimates and sparse supervision at\nintermediate steps. In contrast, imitation learning (IL) is easy to train but\noften underperforms due to its offline nature. In this paper, we propose\nHi-ORS, a simple yet effective post-training method that utilizes rejection\nsampling to achieve both training stability and high robustness. Hi-ORS\nstabilizes value estimation by filtering out negatively rewarded samples during\nonline fine-tuning, and adopts a reward-weighted supervised training objective\nto provide dense intermediate-step supervision. For systematic study, we\ndevelop an asynchronous inference-training framework that supports flexible\nonline human-in-the-loop corrections, which serve as explicit guidance for\nlearning error-recovery behaviors. Across three real-world tasks and two\nembodiments, Hi-ORS fine-tunes a pi-base policy to master contact-rich\nmanipulation in just 1.5 hours of real-world training, outperforming RL and IL\nbaselines by a substantial margin in both effectiveness and efficiency.\nNotably, the fine-tuned policy exhibits strong test-time scalability by\nreliably executing complex error-recovery behaviors to achieve better\nperformance.",
    "categories": [
      "cs.RO",
      "cs.AI"
    ],
    "published": "2025-10-30T11:53:08Z",
    "authors": [
      "Guanxing Lu",
      "Rui Zhao",
      "Haitao Lin",
      "He Zhang",
      "Yansong Tang"
    ],
    "pdf_url": "http://arxiv.org/pdf/2510.26406v1"
  },
  {
    "id": "2510.26402v1",
    "title": "Autograder+: A Multi-Faceted AI Framework for Rich Pedagogical Feedback\n  in Programming Education",
    "abstract": "The rapid growth of programming education has outpaced traditional assessment\ntools, leaving faculty with limited means to provide meaningful, scalable\nfeedback. Conventional autograders, while efficient, act as black-box systems\nthat simply return pass/fail results, offering little insight into student\nthinking or learning needs.\n  Autograder+ is designed to shift autograding from a purely summative process\nto a formative learning experience. It introduces two key capabilities:\nautomated feedback generation using a fine-tuned Large Language Model, and\nvisualization of student code submissions to uncover learning patterns. The\nmodel is fine-tuned on curated student code and expert feedback to ensure\npedagogically aligned, context-aware guidance.\n  In evaluation across 600 student submissions from multiple programming tasks,\nthe system produced feedback with strong semantic alignment to instructor\ncomments. For visualization, contrastively learned code embeddings trained on\n1,000 annotated submissions enable grouping solutions into meaningful clusters\nbased on functionality and approach. The system also supports prompt-pooling,\nallowing instructors to guide feedback style through selected prompt templates.\n  By integrating AI-driven feedback, semantic clustering, and interactive\nvisualization, Autograder+ reduces instructor workload while supporting\ntargeted instruction and promoting stronger learning outcomes.",
    "categories": [
      "cs.AI",
      "cs.LG"
    ],
    "published": "2025-10-30T11:41:50Z",
    "authors": [
      "Vikrant Sahu",
      "Gagan Raj Gupta",
      "Raghav Borikar",
      "Nitin Mane"
    ],
    "pdf_url": "http://arxiv.org/pdf/2510.26402v1"
  },
  {
    "id": "2510.26396v1",
    "title": "A Pragmatic View of AI Personhood",
    "abstract": "The emergence of agentic Artificial Intelligence (AI) is set to trigger a\n\"Cambrian explosion\" of new kinds of personhood. This paper proposes a\npragmatic framework for navigating this diversification by treating personhood\nnot as a metaphysical property to be discovered, but as a flexible bundle of\nobligations (rights and responsibilities) that societies confer upon entities\nfor a variety of reasons, especially to solve concrete governance problems. We\nargue that this traditional bundle can be unbundled, creating bespoke solutions\nfor different contexts. This will allow for the creation of practical tools --\nsuch as facilitating AI contracting by creating a target \"individual\" that can\nbe sanctioned -- without needing to resolve intractable debates about an AI's\nconsciousness or rationality. We explore how individuals fit in to social roles\nand discuss the use of decentralized digital identity technology, examining\nboth \"personhood as a problem\", where design choices can create \"dark patterns\"\nthat exploit human social heuristics, and \"personhood as a solution\", where\nconferring a bundle of obligations is necessary to ensure accountability or\nprevent conflict. By rejecting foundationalist quests for a single, essential\ndefinition of personhood, this paper offers a more pragmatic and flexible way\nto think about integrating AI agents into our society.",
    "categories": [
      "cs.AI"
    ],
    "published": "2025-10-30T11:36:34Z",
    "authors": [
      "Joel Z. Leibo",
      "Alexander Sasha Vezhnevets",
      "William A. Cunningham",
      "Stanley M. Bileschi"
    ],
    "pdf_url": "http://arxiv.org/pdf/2510.26396v1"
  },
  {
    "id": "2510.26390v1",
    "title": "SPG-CDENet: Spatial Prior-Guided Cross Dual Encoder Network for\n  Multi-Organ Segmentation",
    "abstract": "Multi-organ segmentation is a critical task in computer-aided diagnosis.\nWhile recent deep learning methods have achieved remarkable success in image\nsegmentation, huge variations in organ size and shape challenge their\neffectiveness in multi-organ segmentation. To address these challenges, we\npropose a Spatial Prior-Guided Cross Dual Encoder Network (SPG-CDENet), a novel\ntwo-stage segmentation paradigm designed to improve multi-organ segmentation\naccuracy. Our SPG-CDENet consists of two key components: a spatial prior\nnetwork and a cross dual encoder network. The prior network generates coarse\nlocalization maps that delineate the approximate ROI, serving as spatial\nguidance for the dual encoder network. The cross dual encoder network comprises\nfour essential components: a global encoder, a local encoder, a symmetric\ncross-attention module, and a flow-based decoder. The global encoder captures\nglobal semantic features from the entire image, while the local encoder focuses\non features from the prior network. To enhance the interaction between the\nglobal and local encoders, a symmetric cross-attention module is proposed\nacross all layers of the encoders to fuse and refine features. Furthermore, the\nflow-based decoder directly propagates high-level semantic features from the\nfinal encoder layer to all decoder layers, maximizing feature preservation and\nutilization. Extensive qualitative and quantitative experiments on two public\ndatasets demonstrate the superior performance of SPG-CDENet compared to\nexisting segmentation methods. Furthermore, ablation studies further validate\nthe effectiveness of the proposed modules in improving segmentation accuracy.",
    "categories": [
      "eess.IV",
      "cs.AI",
      "cs.CV"
    ],
    "published": "2025-10-30T11:33:29Z",
    "authors": [
      "Xizhi Tian",
      "Changjun Zhou",
      "Yulin. Yang"
    ],
    "pdf_url": "http://arxiv.org/pdf/2510.26390v1"
  },
  {
    "id": "2510.26384v1",
    "title": "Scales++: Compute Efficient Evaluation Subset Selection with Cognitive\n  Scales Embeddings",
    "abstract": "The prohibitive cost of evaluating large language models (LLMs) on\ncomprehensive benchmarks necessitates the creation of small yet representative\ndata subsets (i.e., tiny benchmarks) that enable efficient assessment while\nretaining predictive fidelity. Current methods for this task operate under a\nmodel-centric paradigm, selecting benchmarking items based on the collective\nperformance of existing models. Such approaches are limited by large upfront\ncosts, an inability to immediately handle new benchmarks (`cold-start'), and\nthe fragile assumption that future models will share the failure patterns of\ntheir predecessors. In this work, we challenge this paradigm and propose a\nitem-centric approach to benchmark subset selection, arguing that selection\nshould be based on the intrinsic properties of the task items themselves,\nrather than on model-specific failure patterns. We instantiate this\nitem-centric efficient benchmarking approach via a novel method, Scales++,\nwhere data selection is based on the cognitive demands of the benchmark\nsamples. Empirically, we show Scales++ reduces the upfront selection cost by\nover 18x while achieving competitive predictive fidelity. On the Open LLM\nLeaderboard, using just a 0.5\\% data subset, we predict full benchmark scores\nwith a 2.9% mean absolute error. We demonstrate that this item-centric approach\nenables more efficient model evaluation without significant fidelity\ndegradation, while also providing better cold-start performance and more\ninterpretable benchmarking.",
    "categories": [
      "cs.AI",
      "cs.LG"
    ],
    "published": "2025-10-30T11:28:58Z",
    "authors": [
      "Andrew M. Bean",
      "Nabeel Seedat",
      "Shengzhuang Chen",
      "Jonathan Richard Schwarz"
    ],
    "pdf_url": "http://arxiv.org/pdf/2510.26384v1"
  },
  {
    "id": "2510.26380v1",
    "title": "AI Mathematician as a Partner in Advancing Mathematical Discovery -- A\n  Case Study in Homogenization Theory",
    "abstract": "Artificial intelligence (AI) has demonstrated impressive progress in\nmathematical reasoning, yet its integration into the practice of mathematical\nresearch remains limited. In this study, we investigate how the AI\nMathematician (AIM) system can operate as a research partner rather than a mere\nproblem solver. Focusing on a challenging problem in homogenization theory, we\nanalyze the autonomous reasoning trajectories of AIM and incorporate targeted\nhuman interventions to structure the discovery process. Through iterative\ndecomposition of the problem into tractable subgoals, selection of appropriate\nanalytical methods, and validation of intermediate results, we reveal how human\nintuition and machine computation can complement one another. This\ncollaborative paradigm enhances the reliability, transparency, and\ninterpretability of the resulting proofs, while retaining human oversight for\nformal rigor and correctness. The approach leads to a complete and verifiable\nproof, and more broadly, demonstrates how systematic human-AI co-reasoning can\nadvance the frontier of mathematical discovery.",
    "categories": [
      "cs.AI"
    ],
    "published": "2025-10-30T11:22:15Z",
    "authors": [
      "Yuanhang Liu",
      "Beichen Wang",
      "Peng Li",
      "Yang Liu"
    ],
    "pdf_url": "http://arxiv.org/pdf/2510.26380v1"
  },
  {
    "id": "2510.26374v1",
    "title": "BOTS: A Unified Framework for Bayesian Online Task Selection in LLM\n  Reinforcement Finetuning",
    "abstract": "Reinforcement finetuning (RFT) is a key technique for aligning Large Language\nModels (LLMs) with human preferences and enhancing reasoning, yet its\neffectiveness is highly sensitive to which tasks are explored during training.\nUniform task sampling is inefficient, wasting computation on tasks that are\neither trivial or unsolvable, while existing task selection methods often\nsuffer from high rollout costs, poor adaptivity, or incomplete evidence. We\nintroduce \\textbf{BOTS}, a unified framework for \\textbf{B}ayesian\n\\textbf{O}nline \\textbf{T}ask \\textbf{S}election in LLM reinforcement\nfinetuning. Grounded in Bayesian inference, BOTS adaptively maintains posterior\nestimates of task difficulty as the model evolves. It jointly incorporates\n\\emph{explicit evidence} from direct evaluations of selected tasks and\n\\emph{implicit evidence} inferred from these evaluations for unselected tasks,\nwith Thompson sampling ensuring a principled balance between exploration and\nexploitation. To make implicit evidence practical, we instantiate it with an\nultra-light interpolation-based plug-in that estimates difficulties of\nunevaluated tasks without extra rollouts, adding negligible overhead.\nEmpirically, across diverse domains and LLM scales, BOTS consistently improves\ndata efficiency and performance over baselines and ablations, providing a\npractical and extensible solution for dynamic task selection in RFT.",
    "categories": [
      "cs.AI"
    ],
    "published": "2025-10-30T11:15:23Z",
    "authors": [
      "Qianli Shen",
      "Daoyuan Chen",
      "Yilun Huang",
      "Zhenqing Ling",
      "Yaliang Li",
      "Bolin Ding",
      "Jingren Zhou"
    ],
    "pdf_url": "http://arxiv.org/pdf/2510.26374v1"
  },
  {
    "id": "2510.26352v1",
    "title": "The Geometry of Dialogue: Graphing Language Models to Reveal Synergistic\n  Teams for Multi-Agent Collaboration",
    "abstract": "While a multi-agent approach based on large language models (LLMs) represents\na promising strategy to surpass the capabilities of single models, its success\nis critically dependent on synergistic team composition. However, forming\noptimal teams is a significant challenge, as the inherent opacity of most\nmodels obscures the internal characteristics necessary for effective\ncollaboration. In this paper, we propose an interaction-centric framework for\nautomatic team composition that does not require any prior knowledge including\ntheir internal architectures, training data, or task performances. Our method\nconstructs a \"language model graph\" that maps relationships between models from\nthe semantic coherence of pairwise conversations, and then applies community\ndetection to identify synergistic model clusters. Our experiments with diverse\nLLMs demonstrate that the proposed method discovers functionally coherent\ngroups that reflect their latent specializations. Priming conversations with\nspecific topics identified synergistic teams which outperform random baselines\non downstream benchmarks and achieve comparable accuracy to that of\nmanually-curated teams based on known model specializations. Our findings\nprovide a new basis for the automated design of collaborative multi-agent LLM\nteams.",
    "categories": [
      "cs.CL",
      "cs.AI",
      "cs.MA"
    ],
    "published": "2025-10-30T11:04:15Z",
    "authors": [
      "Kotaro Furuya",
      "Yuichi Kitagawa"
    ],
    "pdf_url": "http://arxiv.org/pdf/2510.26352v1"
  },
  {
    "id": "2510.26347v1",
    "title": "Reinforcement Learning for Pollution Detection in a Randomized, Sparse\n  and Nonstationary Environment with an Autonomous Underwater Vehicle",
    "abstract": "Reinforcement learning (RL) algorithms are designed to optimize\nproblem-solving by learning actions that maximize rewards, a task that becomes\nparticularly challenging in random and nonstationary environments. Even\nadvanced RL algorithms are often limited in their ability to solve problems in\nthese conditions. In applications such as searching for underwater pollution\nclouds with autonomous underwater vehicles (AUVs), RL algorithms must navigate\nreward-sparse environments, where actions frequently result in a zero reward.\nThis paper aims to address these challenges by revisiting and modifying\nclassical RL approaches to efficiently operate in sparse, randomized, and\nnonstationary environments. We systematically study a large number of\nmodifications, including hierarchical algorithm changes, multigoal learning,\nand the integration of a location memory as an external output filter to\nprevent state revisits. Our results demonstrate that a modified Monte\nCarlo-based approach significantly outperforms traditional Q-learning and two\nexhaustive search patterns, illustrating its potential in adapting RL to\ncomplex environments. These findings suggest that reinforcement learning\napproaches can be effectively adapted for use in random, nonstationary, and\nreward-sparse environments.",
    "categories": [
      "cs.LG",
      "cs.AI"
    ],
    "published": "2025-10-30T10:55:05Z",
    "authors": [
      "Sebastian Zieglmeier",
      "Niklas Erdmann",
      "Narada D. Warakagoda"
    ],
    "pdf_url": "http://arxiv.org/pdf/2510.26347v1"
  },
  {
    "id": "2510.26346v1",
    "title": "Discovering State Equivalences in UCT Search Trees By Action Pruning",
    "abstract": "One approach to enhance Monte Carlo Tree Search (MCTS) is to improve its\nsample efficiency by grouping/abstracting states or state-action pairs and\nsharing statistics within a group. Though state-action pair abstractions are\nmostly easy to find in algorithms such as On the Go Abstractions in Upper\nConfidence bounds applied to Trees (OGA-UCT), nearly no state abstractions are\nfound in either noisy or large action space settings due to constraining\nconditions. We provide theoretical and empirical evidence for this claim, and\nwe slightly alleviate this state abstraction problem by proposing a weaker\nstate abstraction condition that trades a minor loss in accuracy for finding\nmany more abstractions. We name this technique Ideal Pruning Abstractions in\nUCT (IPA-UCT), which outperforms OGA-UCT (and any of its derivatives) across a\nlarge range of test domains and iteration budgets as experimentally validated.\nIPA-UCT uses a different abstraction framework from Abstraction of State-Action\nPairs (ASAP) which is the one used by OGA-UCT, which we name IPA. Furthermore,\nwe show that both IPA and ASAP are special cases of a more general framework\nthat we call p-ASAP which itself is a special case of the ASASAP framework.",
    "categories": [
      "cs.AI"
    ],
    "published": "2025-10-30T10:54:43Z",
    "authors": [
      "Robin Schm\u00f6cker",
      "Alexander Dockhorn",
      "Bodo Rosenhahn"
    ],
    "pdf_url": "http://arxiv.org/pdf/2510.26346v1"
  },
  {
    "id": "2510.26345v1",
    "title": "MisSynth: Improving MISSCI Logical Fallacies Classification with\n  Synthetic Data",
    "abstract": "Health-related misinformation is very prevalent and potentially harmful. It\nis difficult to identify, especially when claims distort or misinterpret\nscientific findings. We investigate the impact of synthetic data generation and\nlightweight fine-tuning techniques on the ability of large language models\n(LLMs) to recognize fallacious arguments using the MISSCI dataset and\nframework. In this work, we propose MisSynth, a pipeline that applies\nretrieval-augmented generation (RAG) to produce synthetic fallacy samples,\nwhich are then used to fine-tune an LLM model. Our results show substantial\naccuracy gains with fine-tuned models compared to vanilla baselines. For\ninstance, the LLaMA 3.1 8B fine-tuned model achieved an over 35% F1-score\nabsolute improvement on the MISSCI test split over its vanilla baseline. We\ndemonstrate that introducing synthetic fallacy data to augment limited\nannotated resources can significantly enhance zero-shot LLM classification\nperformance on real-world scientific misinformation tasks, even with limited\ncomputational resources. The code and synthetic dataset are available on\nhttps://github.com/mxpoliakov/MisSynth.",
    "categories": [
      "cs.CL",
      "cs.AI",
      "cs.LG"
    ],
    "published": "2025-10-30T10:52:43Z",
    "authors": [
      "Mykhailo Poliakov",
      "Nadiya Shvai"
    ],
    "pdf_url": "http://arxiv.org/pdf/2510.26345v1"
  },
  {
    "id": "2510.26342v1",
    "title": "Linear Causal Discovery with Interventional Constraints",
    "abstract": "Incorporating causal knowledge and mechanisms is essential for refining\ncausal models and improving downstream tasks such as designing new treatments.\nIn this paper, we introduce a novel concept in causal discovery, termed\ninterventional constraints, which differs fundamentally from interventional\ndata. While interventional data require direct perturbations of variables,\ninterventional constraints encode high-level causal knowledge in the form of\ninequality constraints on causal effects. For instance, in the Sachs dataset\n(Sachs et al.\\ 2005), Akt has been shown to be activated by PIP3, meaning PIP3\nexerts a positive causal effect on Akt. Existing causal discovery methods allow\nenforcing structural constraints (for example, requiring a causal path from\nPIP3 to Akt), but they may still produce incorrect causal conclusions such as\nlearning that \"PIP3 inhibits Akt\". Interventional constraints bridge this gap\nby explicitly constraining the total causal effect between variable pairs,\nensuring learned models respect known causal influences. To formalize\ninterventional constraints, we propose a metric to quantify total causal\neffects for linear causal models and formulate the problem as a constrained\noptimization task, solved using a two-stage constrained optimization method. We\nevaluate our approach on real-world datasets and demonstrate that integrating\ninterventional constraints not only improves model accuracy and ensures\nconsistency with established findings, making models more explainable, but also\nfacilitates the discovery of new causal relationships that would otherwise be\ncostly to identify.",
    "categories": [
      "cs.LG",
      "cs.AI"
    ],
    "published": "2025-10-30T10:49:25Z",
    "authors": [
      "Zhigao Guo",
      "Feng Dong"
    ],
    "pdf_url": "http://arxiv.org/pdf/2510.26342v1"
  },
  {
    "id": "2510.26339v1",
    "title": "GLYPH-SR: Can We Achieve Both High-Quality Image Super-Resolution and\n  High-Fidelity Text Recovery via VLM-guided Latent Diffusion Model?",
    "abstract": "Image super-resolution(SR) is fundamental to many vision system-from\nsurveillance and autonomy to document analysis and retail analytics-because\nrecovering high-frequency details, especially scene-text, enables reliable\ndownstream perception. Scene-text, i.e., text embedded in natural images such\nas signs, product labels, and storefronts, often carries the most actionable\ninformation; when characters are blurred or hallucinated, optical character\nrecognition(OCR) and subsequent decisions fail even if the rest of the image\nappears sharp. Yet previous SR research has often been tuned to distortion\n(PSNR/SSIM) or learned perceptual metrics (LIPIS, MANIQA, CLIP-IQA, MUSIQ) that\nare largely insensitive to character-level errors. Furthermore, studies that do\naddress text SR often focus on simplified benchmarks with isolated characters,\noverlooking the challenges of text within complex natural scenes. As a result,\nscene-text is effectively treated as generic texture. For SR to be effective in\npractical deployments, it is therefore essential to explicitly optimize for\nboth text legibility and perceptual quality. We present GLYPH-SR, a\nvision-language-guided diffusion framework that aims to achieve both objectives\njointly. GLYPH-SR utilizes a Text-SR Fusion ControlNet(TS-ControlNet) guided by\nOCR data, and a ping-pong scheduler that alternates between text- and\nscene-centric guidance. To enable targeted text restoration, we train these\ncomponents on a synthetic corpus while keeping the main SR branch frozen.\nAcross SVT, SCUT-CTW1500, and CUTE80 at x4, and x8, GLYPH-SR improves OCR F1 by\nup to +15.18 percentage points over diffusion/GAN baseline (SVT x8, OpenOCR)\nwhile maintaining competitive MANIQA, CLIP-IQA, and MUSIQ. GLYPH-SR is designed\nto satisfy both objectives simultaneously-high readability and high visual\nrealism-delivering SR that looks right and reds right.",
    "categories": [
      "cs.CV",
      "cs.AI"
    ],
    "published": "2025-10-30T10:46:28Z",
    "authors": [
      "Mingyu Sung",
      "Seungjae Ham",
      "Kangwoo Kim",
      "Yeokyoung Yoon",
      "Sangseok Yun",
      "Il-Min Kim",
      "Jae-Mo Kang"
    ],
    "pdf_url": "http://arxiv.org/pdf/2510.26339v1"
  },
  {
    "id": "2510.26336v1",
    "title": "From Amateur to Master: Infusing Knowledge into LLMs via Automated\n  Curriculum Learning",
    "abstract": "Large Language Models (LLMs) excel at general tasks but underperform in\nspecialized domains like economics and psychology, which require deep,\nprincipled understanding. To address this, we introduce ACER (Automated\nCurriculum-Enhanced Regimen) that transforms generalist models into domain\nexperts without sacrificing their broad capabilities. ACER first synthesizes a\ncomprehensive, textbook-style curriculum by generating a table of contents for\na subject and then creating question-answer (QA) pairs guided by Bloom's\ntaxonomy. This ensures systematic topic coverage and progressively increasing\ndifficulty. The resulting synthetic corpus is used for continual pretraining\nwith an interleaved curriculum schedule, aligning learning across both content\nand cognitive dimensions.\n  Experiments with Llama 3.2 (1B and 3B) show significant gains in specialized\nMMLU subsets. In challenging domains like microeconomics, where baselines\nstruggle, ACER boosts accuracy by 5 percentage points. Across all target\ndomains, we observe a consistent macro-average improvement of 3 percentage\npoints. Notably, ACER not only prevents catastrophic forgetting but also\nfacilitates positive cross-domain knowledge transfer, improving performance on\nnon-target domains by 0.7 points. Beyond MMLU, ACER enhances performance on\nknowledge-intensive benchmarks like ARC and GPQA by over 2 absolute points,\nwhile maintaining stable performance on general reasoning tasks. Our results\ndemonstrate that ACER offers a scalable and effective recipe for closing\ncritical domain gaps in LLMs.",
    "categories": [
      "cs.CL",
      "cs.AI"
    ],
    "published": "2025-10-30T10:43:40Z",
    "authors": [
      "Nishit Neema",
      "Srinjoy Mukherjee",
      "Sapan Shah",
      "Gokul Ramakrishnan",
      "Ganesh Venkatesh"
    ],
    "pdf_url": "http://arxiv.org/pdf/2510.26336v1"
  },
  {
    "id": "2510.26324v1",
    "title": "Posterior Sampling by Combining Diffusion Models with Annealed Langevin\n  Dynamics",
    "abstract": "Given a noisy linear measurement $y = Ax + \\xi$ of a distribution $p(x)$, and\na good approximation to the prior $p(x)$, when can we sample from the posterior\n$p(x \\mid y)$? Posterior sampling provides an accurate and fair framework for\ntasks such as inpainting, deblurring, and MRI reconstruction, and several\nheuristics attempt to approximate it. Unfortunately, approximate posterior\nsampling is computationally intractable in general.\n  To sidestep this hardness, we focus on (local or global) log-concave\ndistributions $p(x)$. In this regime, Langevin dynamics yields posterior\nsamples when the exact scores of $p(x)$ are available, but it is brittle to\nscore--estimation error, requiring an MGF bound (sub-exponential error). By\ncontrast, in the unconditional setting, diffusion models succeed with only an\n$L^2$ bound on the score error. We prove that combining diffusion models with\nan annealed variant of Langevin dynamics achieves conditional sampling in\npolynomial time using merely an $L^4$ bound on the score error.",
    "categories": [
      "cs.LG",
      "cs.AI",
      "cs.DS",
      "math.ST",
      "stat.ML",
      "stat.TH"
    ],
    "published": "2025-10-30T10:17:27Z",
    "authors": [
      "Zhiyang Xun",
      "Shivam Gupta",
      "Eric Price"
    ],
    "pdf_url": "http://arxiv.org/pdf/2510.26324v1"
  },
  {
    "id": "2510.26309v1",
    "title": "GraphCompliance: Aligning Policy and Context Graphs for LLM-Based\n  Regulatory Compliance",
    "abstract": "Compliance at web scale poses practical challenges: each request may require\na regulatory assessment. Regulatory texts (e.g., the General Data Protection\nRegulation, GDPR) are cross-referential and normative, while runtime contexts\nare expressed in unstructured natural language. This setting motivates us to\nalign semantic information in unstructured text with the structured, normative\nelements of regulations. To this end, we introduce GraphCompliance, a framework\nthat represents regulatory texts as a Policy Graph and runtime contexts as a\nContext Graph, and aligns them. In this formulation, the policy graph encodes\nnormative structure and cross-references, whereas the context graph formalizes\nevents as subject-action-object (SAO) and entity-relation triples. This\nalignment anchors the reasoning of a judge large language model (LLM) in\nstructured information and helps reduce the burden of regulatory interpretation\nand event parsing, enabling a focus on the core reasoning step. In experiments\non 300 GDPR-derived real-world scenarios spanning five evaluation tasks,\nGraphCompliance yields 4.1-7.2 percentage points (pp) higher micro-F1 than\nLLM-only and RAG baselines, with fewer under- and over-predictions, resulting\nin higher recall and lower false positive rates. Ablation studies indicate\ncontributions from each graph component, suggesting that structured\nrepresentations and a judge LLM are complementary for normative reasoning.",
    "categories": [
      "cs.AI",
      "cs.IR",
      "I.2.7"
    ],
    "published": "2025-10-30T09:53:16Z",
    "authors": [
      "Jiseong Chung",
      "Ronny Ko",
      "Wonchul Yoo",
      "Makoto Onizuka",
      "Sungmok Kim",
      "Tae-Wan Kim",
      "Won-Yong Shin"
    ],
    "pdf_url": "http://arxiv.org/pdf/2510.26309v1"
  },
  {
    "id": "2510.26303v1",
    "title": "Implicit Bias of Per-sample Adam on Separable Data: Departure from the\n  Full-batch Regime",
    "abstract": "Adam [Kingma and Ba, 2015] is the de facto optimizer in deep learning, yet\nits theoretical understanding remains limited. Prior analyses show that Adam\nfavors solutions aligned with $\\ell_\\infty$-geometry, but these results are\nrestricted to the full-batch regime. In this work, we study the implicit bias\nof incremental Adam (using one sample per step) for logistic regression on\nlinearly separable data, and we show that its bias can deviate from the\nfull-batch behavior. To illustrate this, we construct a class of structured\ndatasets where incremental Adam provably converges to the $\\ell_2$-max-margin\nclassifier, in contrast to the $\\ell_\\infty$-max-margin bias of full-batch\nAdam. For general datasets, we develop a proxy algorithm that captures the\nlimiting behavior of incremental Adam as $\\beta_2 \\to 1$ and we characterize\nits convergence direction via a data-dependent dual fixed-point formulation.\nFinally, we prove that, unlike Adam, Signum [Bernstein et al., 2018] converges\nto the $\\ell_\\infty$-max-margin classifier for any batch size by taking $\\beta$\nclose enough to 1. Overall, our results highlight that the implicit bias of\nAdam crucially depends on both the batching scheme and the dataset, while\nSignum remains invariant.",
    "categories": [
      "cs.LG",
      "cs.AI",
      "math.OC",
      "stat.ML"
    ],
    "published": "2025-10-30T09:41:33Z",
    "authors": [
      "Beomhan Baek",
      "Minhak Song",
      "Chulhee Yun"
    ],
    "pdf_url": "http://arxiv.org/pdf/2510.26303v1"
  },
  {
    "id": "2510.26302v1",
    "title": "Understanding Hardness of Vision-Language Compositionality from A\n  Token-level Causal Lens",
    "abstract": "Contrastive Language-Image Pre-training (CLIP) delivers strong cross modal\ngeneralization by aligning images and texts in a shared embedding space, yet it\npersistently fails at compositional reasoning over objects, attributes, and\nrelations often behaving like a bag-of-words matcher. Prior causal accounts\ntypically model text as a single vector, obscuring token-level structure and\nleaving core phenomena-such as prompt sensitivity and failures on hard\nnegatives unexplained. We address this gap with a token-aware causal\nrepresentation learning (CRL) framework grounded in a sequential,\nlanguage-token SCM. Our theory extends block identifiability to tokenized text,\nproving that CLIP's contrastive objective can recover the modal-invariant\nlatent variable under both sentence-level and token-level SCMs. Crucially,\ntoken granularity yields the first principled explanation of CLIP's\ncompositional brittleness: composition nonidentifiability. We show the\nexistence of pseudo-optimal text encoders that achieve perfect modal-invariant\nalignment yet are provably insensitive to SWAP, REPLACE, and ADD operations\nover atomic concepts, thereby failing to distinguish correct captions from hard\nnegatives despite optimizing the same training objective as true-optimal\nencoders. The analysis further links language-side nonidentifiability to\nvisual-side failures via the modality gap and shows how iterated composition\noperators compound hardness, motivating improved negative mining strategies.",
    "categories": [
      "cs.LG",
      "cs.AI"
    ],
    "published": "2025-10-30T09:41:21Z",
    "authors": [
      "Ziliang Chen",
      "Tianang Xiao",
      "Jusheng Zhang",
      "Yongsen Zheng",
      "Xipeng Chen"
    ],
    "pdf_url": "http://arxiv.org/pdf/2510.26302v1"
  },
  {
    "id": "2510.26298v1",
    "title": "Can Agent Conquer Web? Exploring the Frontiers of ChatGPT Atlas Agent in\n  Web Games",
    "abstract": "OpenAI's ChatGPT Atlas introduces new capabilities for web interaction,\nenabling the model to analyze webpages, process user intents, and execute\ncursor and keyboard inputs directly within the browser. While its capacity for\ninformation retrieval tasks has been demonstrated, its performance in dynamic,\ninteractive environments remains less explored. In this study, we conduct an\nearly evaluation of Atlas's web interaction capabilities using browser-based\ngames as test scenarios, including Google's T-Rex Runner, Sudoku, Flappy Bird,\nand Stein.world. We employ in-game performance scores as quantitative metrics\nto assess performance across different task types. Our results show that Atlas\nperforms strongly in logical reasoning tasks like Sudoku, completing puzzles\nsignificantly faster than human baselines, but struggles substantially in\nreal-time games requiring precise timing and motor control, often failing to\nprogress beyond initial obstacles. These findings suggest that while Atlas\ndemonstrates capable analytical processing, there remain notable limitations in\ndynamic web environments requiring real-time interaction. The website of our\nproject can be found at https://atlas-game-eval.github.io.",
    "categories": [
      "cs.CL",
      "cs.AI"
    ],
    "published": "2025-10-30T09:35:51Z",
    "authors": [
      "Jingran Zhang",
      "Ning Li",
      "Justin Cui"
    ],
    "pdf_url": "http://arxiv.org/pdf/2510.26298v1"
  },
  {
    "id": "2510.26285v1",
    "title": "Unravelling the Mechanisms of Manipulating Numbers in Language Models",
    "abstract": "Recent work has shown that different large language models (LLMs) converge to\nsimilar and accurate input embedding representations for numbers. These\nfindings conflict with the documented propensity of LLMs to produce erroneous\noutputs when dealing with numeric information. In this work, we aim to explain\nthis conflict by exploring how language models manipulate numbers and quantify\nthe lower bounds of accuracy of these mechanisms. We find that despite\nsurfacing errors, different language models learn interchangeable\nrepresentations of numbers that are systematic, highly accurate and universal\nacross their hidden states and the types of input contexts. This allows us to\ncreate universal probes for each LLM and to trace information -- including the\ncauses of output errors -- to specific layers. Our results lay a fundamental\nunderstanding of how pre-trained LLMs manipulate numbers and outline the\npotential of more accurate probing techniques in addressed refinements of LLMs'\narchitectures.",
    "categories": [
      "cs.CL",
      "cs.AI",
      "cs.LG",
      "cs.NE"
    ],
    "published": "2025-10-30T09:08:50Z",
    "authors": [
      "Michal \u0160tef\u00e1nik",
      "Timothee Mickus",
      "Marek Kadl\u010d\u00edk",
      "Bertram H\u00f8jer",
      "Michal Spiegel",
      "Ra\u00fal V\u00e1zquez",
      "Aman Sinha",
      "Josef Kucha\u0159",
      "Philipp Mondorf"
    ],
    "pdf_url": "http://arxiv.org/pdf/2510.26285v1"
  },
  {
    "id": "2510.26278v1",
    "title": "Distributional Multi-objective Black-box Optimization for\n  Diffusion-model Inference-time Multi-Target Generation",
    "abstract": "Diffusion models have been successful in learning complex data distributions.\nThis capability has driven their application to high-dimensional\nmulti-objective black-box optimization problem. Existing approaches often\nemploy an external optimization loop, such as an evolutionary algorithm, to the\ndiffusion model. However, these approaches treat the diffusion model as a\nblack-box refiner, which overlooks the internal distribution transition of the\ndiffusion generation process, limiting their efficiency. To address these\nchallenges, we propose the Inference-time Multi-target Generation (IMG)\nalgorithm, which optimizes the diffusion process at inference-time to generate\nsamples that simultaneously satisfy multiple objectives. Specifically, our IMG\nperforms weighted resampling during the diffusion generation process according\nto the expected aggregated multi-objective values. This weighted resampling\nstrategy ensures the diffusion-generated samples are distributed according to\nour desired multi-target Boltzmann distribution. We further derive that the\nmulti-target Boltzmann distribution has an interesting log-likelihood\ninterpretation, where it is the optimal solution to the distributional\nmulti-objective optimization problem. We implemented IMG for a multi-objective\nmolecule generation task. Experiments show that IMG, requiring only a single\ngeneration pass, achieves a significantly higher hypervolume than baseline\noptimization algorithms that often require hundreds of diffusion generations.\nNotably, our algorithm can be viewed as an optimized diffusion process and can\nbe integrated into existing methods to further improve their performance.",
    "categories": [
      "cs.LG",
      "cs.AI"
    ],
    "published": "2025-10-30T09:00:42Z",
    "authors": [
      "Kim Yong Tan",
      "Yueming Lyu",
      "Ivor Tsang",
      "Yew-Soon Ong"
    ],
    "pdf_url": "http://arxiv.org/pdf/2510.26278v1"
  },
  {
    "id": "2510.26275v1",
    "title": "A Research Roadmap for Augmenting Software Engineering Processes and\n  Software Products with Generative AI",
    "abstract": "Generative AI (GenAI) is rapidly transforming software engineering (SE)\npractices, influencing how SE processes are executed, as well as how software\nsystems are developed, operated, and evolved. This paper applies design science\nresearch to build a roadmap for GenAI-augmented SE. The process consists of\nthree cycles that incrementally integrate multiple sources of evidence,\nincluding collaborative discussions from the FSE 2025 \"Software Engineering\n2030\" workshop, rapid literature reviews, and external feedback sessions\ninvolving peers. McLuhan's tetrads were used as a conceptual instrument to\nsystematically capture the transforming effects of GenAI on SE processes and\nsoftware products.The resulting roadmap identifies four fundamental forms of\nGenAI augmentation in SE and systematically characterizes their related\nresearch challenges and opportunities. These insights are then consolidated\ninto a set of future research directions. By grounding the roadmap in a\nrigorous multi-cycle process and cross-validating it among independent author\nteams and peers, the study provides a transparent and reproducible foundation\nfor analyzing how GenAI affects SE processes, methods and tools, and for\nframing future research within this rapidly evolving area. Based on these\nfindings, the article finally makes ten predictions for SE in the year 2030.",
    "categories": [
      "cs.SE",
      "cs.AI",
      "cs.ET",
      "cs.LG",
      "cs.MA"
    ],
    "published": "2025-10-30T08:59:01Z",
    "authors": [
      "Domenico Amalfitano",
      "Andreas Metzger",
      "Marco Autili",
      "Tommaso Fulcini",
      "Tobias Hey",
      "Jan Keim",
      "Patrizio Pelliccione",
      "Vincenzo Scotti",
      "Anne Koziolek",
      "Raffaela Mirandola",
      "Andreas Vogelsang"
    ],
    "pdf_url": "http://arxiv.org/pdf/2510.26275v1"
  },
  {
    "id": "2510.26270v1",
    "title": "Graph-Enhanced Policy Optimization in LLM Agent Training",
    "abstract": "Group based reinforcement learning (RL) has shown impressive results on\ncomplex reasoning and mathematical tasks. Yet, when applied to train\nmulti-turn, interactive LLM agents, these methods often suffer from structural\nblindness-the inability to exploit the underlying connectivity of the\nenvironment. This manifests in three critical challenges: (1) inefficient,\nunguided exploration, (2) imprecise credit assignment due to overlooking\npivotal states, and (3) myopic planning caused by static reward discounting. We\naddress these issues with Graph-Enhanced Policy Optimization (GEPO), which\ndynamically constructs a state-transition graph from agent experience and\nemploys graph-theoretic centrality to provide three synergistic learning\nsignals: (1)structured intrinsic rewards that guide exploration toward\nhigh-impact states, (2) a graph-enhanced advantage function for topology-aware\ncredit assignment, and (3) a dynamic discount factor adapted to each state's\nstrategic value. On the ALFWorld, WebShop, and a proprietary Workbench\nbenchmarks, GEPO demonstrates strong performance, achieving absolute success\nrate gains of +4.1%, +5.3%, and +10.9% over competitive baselines. These\nresults highlight that explicitly modeling environmental structure is a robust,\ngeneralizable strategy for advancing LLM agent training.",
    "categories": [
      "cs.AI"
    ],
    "published": "2025-10-30T08:53:41Z",
    "authors": [
      "Jiazhen Yuan",
      "Wei Zhao",
      "Zhengbiao Bai"
    ],
    "pdf_url": "http://arxiv.org/pdf/2510.26270v1"
  },
  {
    "id": "2510.26243v1",
    "title": "Angular Steering: Behavior Control via Rotation in Activation Space",
    "abstract": "Controlling specific behaviors in large language models while preserving\ntheir general capabilities is a central challenge for safe and reliable\nartificial intelligence deployment. Current steering methods, such as vector\naddition and directional ablation, are constrained within a two-dimensional\nsubspace defined by the activation and feature direction, making them sensitive\nto chosen parameters and potentially affecting unrelated features due to\nunintended interactions in activation space. We introduce Angular Steering, a\nnovel and flexible method for behavior modulation that operates by rotating\nactivations within a fixed two-dimensional subspace. By formulating steering as\na geometric rotation toward or away from a target behavior direction, Angular\nSteering provides continuous, fine-grained control over behaviors such as\nrefusal and compliance. We demonstrate this method using refusal steering\nemotion steering as use cases. Additionally, we propose Adaptive Angular\nSteering, a selective variant that rotates only activations aligned with the\ntarget feature, further enhancing stability and coherence. Angular Steering\ngeneralizes existing addition and orthogonalization techniques under a unified\ngeometric rotation framework, simplifying parameter selection and maintaining\nmodel stability across a broader range of adjustments. Experiments across\nmultiple model families and sizes show that Angular Steering achieves robust\nbehavioral control while maintaining general language modeling performance,\nunderscoring its flexibility, generalization, and robustness compared to prior\napproaches. Code and artifacts are available at\nhttps://github.com/lone17/angular-steering/.",
    "categories": [
      "cs.LG",
      "cs.AI"
    ],
    "published": "2025-10-30T08:23:35Z",
    "authors": [
      "Hieu M. Vu",
      "Tan M. Nguyen"
    ],
    "pdf_url": "http://arxiv.org/pdf/2510.26243v1"
  },
  {
    "id": "2510.26242v1",
    "title": "Retrieval Augmented Generation-Enhanced Distributed LLM Agents for\n  Generalizable Traffic Signal Control with Emergency Vehicles",
    "abstract": "With increasing urban traffic complexity, Traffic Signal Control (TSC) is\nessential for optimizing traffic flow and improving road safety. Large Language\nModels (LLMs) emerge as promising approaches for TSC. However, they are prone\nto hallucinations in emergencies, leading to unreliable decisions that may\ncause substantial delays for emergency vehicles. Moreover, diverse intersection\ntypes present substantial challenges for traffic state encoding and\ncross-intersection training, limiting generalization across heterogeneous\nintersections. Therefore, this paper proposes Retrieval Augmented Generation\n(RAG)-enhanced distributed LLM agents with Emergency response for Generalizable\nTSC (REG-TSC). Firstly, this paper presents an emergency-aware reasoning\nframework, which dynamically adjusts reasoning depth based on the emergency\nscenario and is equipped with a novel Reviewer-based Emergency RAG (RERAG) to\ndistill specific knowledge and guidance from historical cases, enhancing the\nreliability and rationality of agents' emergency decisions. Secondly, this\npaper designs a type-agnostic traffic representation and proposes a\nReward-guided Reinforced Refinement (R3) for heterogeneous intersections. R3\nadaptively samples training experience from diverse intersections with\nenvironment feedback-based priority and fine-tunes LLM agents with a designed\nreward-weighted likelihood loss, guiding REG-TSC toward high-reward policies\nacross heterogeneous intersections. On three real-world road networks with 17\nto 177 heterogeneous intersections, extensive experiments show that REG-TSC\nreduces travel time by 42.00%, queue length by 62.31%, and emergency vehicle\nwaiting time by 83.16%, outperforming other state-of-the-art methods.",
    "categories": [
      "cs.AI"
    ],
    "published": "2025-10-30T08:23:08Z",
    "authors": [
      "Xinhang Li",
      "Qing Guo",
      "Junyu Chen",
      "Zheng Guo",
      "Shengzhe Xu",
      "Lei Li",
      "Lin Zhang"
    ],
    "pdf_url": "http://arxiv.org/pdf/2510.26242v1"
  },
  {
    "id": "2510.26238v1",
    "title": "Questionnaire meets LLM: A Benchmark and Empirical Study of Structural\n  Skills for Understanding Questions and Responses",
    "abstract": "Millions of people take surveys every day, from market polls and academic\nstudies to medical questionnaires and customer feedback forms. These datasets\ncapture valuable insights, but their scale and structure present a unique\nchallenge for large language models (LLMs), which otherwise excel at few-shot\nreasoning over open-ended text. Yet, their ability to process questionnaire\ndata or lists of questions crossed with hundreds of respondent rows remains\nunderexplored. Current retrieval and survey analysis tools (e.g., Qualtrics,\nSPSS, REDCap) are typically designed for humans in the workflow, limiting such\ndata integration with LLM and AI-empowered automation. This gap leaves\nscientists, surveyors, and everyday users without evidence-based guidance on\nhow to best represent questionnaires for LLM consumption. We address this by\nintroducing QASU (Questionnaire Analysis and Structural Understanding), a\nbenchmark that probes six structural skills, including answer lookup,\nrespondent count, and multi-hop inference, across six serialization formats and\nmultiple prompt strategies. Experiments on contemporary LLMs show that choosing\nan effective format and prompt combination can improve accuracy by up to 8.8%\npoints compared to suboptimal formats. For specific tasks, carefully adding a\nlightweight structural hint through self-augmented prompting can yield further\nimprovements of 3-4% points on average. By systematically isolating format and\nprompting effects, our open source benchmark offers a simple yet versatile\nfoundation for advancing both research and real-world practice in LLM-based\nquestionnaire analysis.",
    "categories": [
      "cs.AI"
    ],
    "published": "2025-10-30T08:18:37Z",
    "authors": [
      "Duc-Hai Nguyen",
      "Vijayakumar Nanjappan",
      "Barry O'Sullivan",
      "Hoang D. Nguyen"
    ],
    "pdf_url": "http://arxiv.org/pdf/2510.26238v1"
  },
  {
    "id": "2510.26230v1",
    "title": "MPRU: Modular Projection-Redistribution Unlearning as Output Filter for\n  Classification Pipelines",
    "abstract": "As a new and promising approach, existing machine unlearning (MU) works\ntypically emphasize theoretical formulations or optimization objectives to\nachieve knowledge removal. However, when deployed in real-world scenarios, such\nsolutions typically face scalability issues and have to address practical\nrequirements such as full access to original datasets and model. In contrast to\nthe existing approaches, we regard classification training as a sequential\nprocess where classes are learned sequentially, which we call \\emph{inductive\napproach}. Unlearning can then be done by reversing the last training sequence.\nThis is implemented by appending a projection-redistribution layer in the end\nof the model. Such an approach does not require full access to the original\ndataset or the model, addressing the challenges of existing methods. This\nenables modular and model-agnostic deployment as an output filter into existing\nclassification pipelines with minimal alterations. We conducted multiple\nexperiments across multiple datasets including image (CIFAR-10/100 using\nCNN-based model) and tabular datasets (Covertype using tree-based model).\nExperiment results show consistently similar output to a fully retrained model\nwith a high computational cost reduction. This demonstrates the applicability,\nscalability, and system compatibility of our solution while maintaining the\nperformance of the output in a more practical setting.",
    "categories": [
      "cs.LG",
      "cs.AI",
      "68T09 68T09"
    ],
    "published": "2025-10-30T08:09:37Z",
    "authors": [
      "Minyi Peng",
      "Darian Gunamardi",
      "Ivan Tjuawinata",
      "Kwok-Yan Lam"
    ],
    "pdf_url": "http://arxiv.org/pdf/2510.26230v1"
  },
  {
    "id": "2510.26219v1",
    "title": "Test-Time Alignment of LLMs via Sampling-Based Optimal Control in\n  pre-logit space",
    "abstract": "Test-time alignment of large language models (LLMs) attracts attention\nbecause fine-tuning LLMs requires high computational costs. In this paper, we\npropose a new test-time alignment method called adaptive importance sampling on\npre-logits (AISP) on the basis of the sampling-based model predictive control\nwith the stochastic control input. AISP applies the Gaussian perturbation into\npre-logits, which are outputs of the penultimate layer, so as to maximize\nexpected rewards with respect to the mean of the perturbation. We demonstrate\nthat the optimal mean is obtained by importance sampling with sampled rewards.\nAISP outperforms best-of-n sampling in terms of rewards over the number of used\nsamples and achieves higher rewards than other reward-based test-time alignment\nmethods.",
    "categories": [
      "cs.LG",
      "cs.AI"
    ],
    "published": "2025-10-30T07:52:14Z",
    "authors": [
      "Sekitoshi Kanai",
      "Tsukasa Yoshida",
      "Hiroshi Takahashi",
      "Haru Kuroki",
      "Kazumune Hashimoto"
    ],
    "pdf_url": "http://arxiv.org/pdf/2510.26219v1"
  },
  {
    "id": "2510.26217v1",
    "title": "Hybrid LLM and Higher-Order Quantum Approximate Optimization for CSA\n  Collateral Management",
    "abstract": "We address finance-native collateral optimization under ISDA Credit Support\nAnnexes (CSAs), where integer lots, Schedule A haircuts, RA/MTA gating, and\nissuer/currency/class caps create rugged, legally bounded search spaces. We\nintroduce a certifiable hybrid pipeline purpose-built for this domain: (i) an\nevidence-gated LLM that extracts CSA terms to a normalized JSON\n(abstain-by-default, span-cited); (ii) a quantum-inspired explorer that\ninterleaves simulated annealing with micro higher order QAOA (HO-QAOA) on\nbinding sub-QUBOs (subset size n <= 16, order k <= 4) to coordinate multi-asset\nmoves across caps and RA-induced discreteness; (iii) a weighted risk-aware\nobjective (Movement, CVaR, funding-priced overshoot) with an explicit coverage\nwindow U <= Reff+B; and (iv) CP-SAT as single arbiter to certify feasibility\nand gaps, including a U-cap pre-check that reports the minimal feasible buffer\nB*. Encoding caps/rounding as higher-order terms lets HO-QAOA target the domain\ncouplings that defeat local swaps. On government bond datasets and multi-CSA\ninputs, the hybrid improves a strong classical baseline (BL-3) by 9.1%, 9.6%,\nand 10.7% across representative harnesses, delivering better cost-movement-tail\nfrontiers under governance settings. We release governance grade artifacts-span\ncitations, valuation matrix audit, weight provenance, QUBO manifests, and\nCP-SAT traces-to make results auditable and reproducible.",
    "categories": [
      "q-fin.CP",
      "cs.AI",
      "math.OC",
      "90C10, 90C27 (Primary), 90C59, 68Q12, 68T50, 91G80, 91G60\n  (Secondary)",
      "I.2.7; I.2.6; G.1.6; F.1.2; G.2.1; J.1"
    ],
    "published": "2025-10-30T07:46:40Z",
    "authors": [
      "Tao Jin",
      "Stuart Florescu",
      " Heyu",
      " Jin"
    ],
    "pdf_url": "http://arxiv.org/pdf/2510.26217v1"
  },
  {
    "id": "2510.26205v1",
    "title": "Towards Global Retrieval Augmented Generation: A Benchmark for\n  Corpus-Level Reasoning",
    "abstract": "Retrieval-augmented generation (RAG) has emerged as a leading approach to\nreducing hallucinations in large language models (LLMs). Current RAG evaluation\nbenchmarks primarily focus on what we call local RAG: retrieving relevant\nchunks from a small subset of documents to answer queries that require only\nlocalized understanding within specific text chunks. However, many real-world\napplications require a fundamentally different capability -- global RAG --\nwhich involves aggregating and analyzing information across entire document\ncollections to derive corpus-level insights (for example, \"What are the top 10\nmost cited papers in 2023?\"). In this paper, we introduce GlobalQA -- the first\nbenchmark specifically designed to evaluate global RAG capabilities, covering\nfour core task types: counting, extremum queries, sorting, and top-k\nextraction. Through systematic evaluation across different models and\nbaselines, we find that existing RAG methods perform poorly on global tasks,\nwith the strongest baseline achieving only 1.51 F1 score. To address these\nchallenges, we propose GlobalRAG, a multi-tool collaborative framework that\npreserves structural coherence through chunk-level retrieval, incorporates\nLLM-driven intelligent filters to eliminate noisy documents, and integrates\naggregation modules for precise symbolic computation. On the Qwen2.5-14B model,\nGlobalRAG achieves 6.63 F1 compared to the strongest baseline's 1.51 F1,\nvalidating the effectiveness of our method.",
    "categories": [
      "cs.CL",
      "cs.AI"
    ],
    "published": "2025-10-30T07:29:14Z",
    "authors": [
      "Qi Luo",
      "Xiaonan Li",
      "Tingshuo Fan",
      "Xinchi Chen",
      "Xipeng Qiu"
    ],
    "pdf_url": "http://arxiv.org/pdf/2510.26205v1"
  },
  {
    "id": "2510.26202v1",
    "title": "What's In My Human Feedback? Learning Interpretable Descriptions of\n  Preference Data",
    "abstract": "Human feedback can alter language models in unpredictable and undesirable\nways, as practitioners lack a clear understanding of what feedback data\nencodes. While prior work studies preferences over certain attributes (e.g.,\nlength or sycophancy), automatically extracting relevant features without\npre-specifying hypotheses remains challenging. We introduce What's In My Human\nFeedback? (WIMHF), a method to explain feedback data using sparse autoencoders.\nWIMHF characterizes both (1) the preferences a dataset is capable of measuring\nand (2) the preferences that the annotators actually express. Across 7\ndatasets, WIMHF identifies a small number of human-interpretable features that\naccount for the majority of the preference prediction signal achieved by\nblack-box models. These features reveal a wide diversity in what humans prefer,\nand the role of dataset-level context: for example, users on Reddit prefer\ninformality and jokes, while annotators in HH-RLHF and PRISM disprefer them.\nWIMHF also surfaces potentially unsafe preferences, such as that LMArena users\ntend to vote against refusals, often in favor of toxic content. The learned\nfeatures enable effective data curation: re-labeling the harmful examples in\nArena yields large safety gains (+37%) with no cost to general performance.\nThey also allow fine-grained personalization: on the Community Alignment\ndataset, we learn annotator-specific weights over subjective features that\nimprove preference prediction. WIMHF provides a human-centered analysis method\nfor practitioners to better understand and use preference data.",
    "categories": [
      "cs.CL",
      "cs.AI"
    ],
    "published": "2025-10-30T07:25:10Z",
    "authors": [
      "Rajiv Movva",
      "Smitha Milli",
      "Sewon Min",
      "Emma Pierson"
    ],
    "pdf_url": "http://arxiv.org/pdf/2510.26202v1"
  },
  {
    "id": "2510.26200v1",
    "title": "Don't Let It Fade: Preserving Edits in Diffusion Language Models via\n  Token Timestep Allocation",
    "abstract": "While diffusion language models (DLMs) enable fine-grained refinement, their\npractical controllability remains fragile. We identify and formally\ncharacterize a central failure mode called update forgetting, in which uniform\nand context agnostic updates induce token level fluctuations across timesteps,\nerasing earlier semantic edits and disrupting the cumulative refinement\nprocess, thereby degrading fluency and coherence. As this failure originates in\nuniform and context agnostic updates, effective control demands explicit token\nordering. We propose Token Timestep Allocation (TTA), which realizes soft and\nsemantic token ordering via per token timestep schedules: critical tokens are\nfrozen early, while uncertain tokens receive continued refinement. This\ntimestep based ordering can be instantiated as either a fixed policy or an\nadaptive policy driven by task signals, thereby supporting a broad spectrum of\nrefinement strategies. Because it operates purely at inference time, it applies\nuniformly across various DLMs and naturally extends to diverse supervision\nsources. Empirically, TTA improves controllability and fluency: on sentiment\ncontrol, it yields more than 20 percent higher accuracy and nearly halves\nperplexity using less than one fifth the steps; in detoxification, it lowers\nmaximum toxicity (12.2 versus 14.5) and perplexity (26.0 versus 32.0).\nTogether, these results demonstrate that softened ordering via timestep\nallocation is the critical lever for mitigating update forgetting and achieving\nstable and controllable diffusion text generation.",
    "categories": [
      "cs.CL",
      "cs.AI"
    ],
    "published": "2025-10-30T07:21:05Z",
    "authors": [
      "Woojin Kim",
      "Jaeyoung Do"
    ],
    "pdf_url": "http://arxiv.org/pdf/2510.26200v1"
  },
  {
    "id": "2510.26188v1",
    "title": "Predicting All-Cause Hospital Readmissions from Medical Claims Data of\n  Hospitalised Patients",
    "abstract": "Reducing preventable hospital readmissions is a national priority for payers,\nproviders, and policymakers seeking to improve health care and lower costs. The\nrate of readmission is being used as a benchmark to determine the quality of\nhealthcare provided by the hospitals. In thisproject, we have used machine\nlearning techniques like Logistic Regression, Random Forest and Support Vector\nMachines to analyze the health claims data and identify demographic and medical\nfactors that play a crucial role in predicting all-cause readmissions. As the\nhealth claims data is high dimensional, we have used Principal Component\nAnalysis as a dimension reduction technique and used the results for building\nregression models. We compared and evaluated these models based on the Area\nUnder Curve (AUC) metric. Random Forest model gave the highest performance\nfollowed by Logistic Regression and Support Vector Machine models. These models\ncan be used to identify the crucial factors causing readmissions and help\nidentify patients to focus on to reduce the chances of readmission, ultimately\nbringing down the cost and increasing the quality of healthcare provided to the\npatients.",
    "categories": [
      "cs.LG",
      "cs.AI"
    ],
    "published": "2025-10-30T06:54:19Z",
    "authors": [
      "Avinash Kadimisetty",
      "Arun Rajagopalan",
      "Vijendra SK"
    ],
    "pdf_url": "http://arxiv.org/pdf/2510.26188v1"
  },
  {
    "id": "2510.26186v1",
    "title": "ConceptScope: Characterizing Dataset Bias via Disentangled Visual\n  Concepts",
    "abstract": "Dataset bias, where data points are skewed to certain concepts, is ubiquitous\nin machine learning datasets. Yet, systematically identifying these biases is\nchallenging without costly, fine-grained attribute annotations. We present\nConceptScope, a scalable and automated framework for analyzing visual datasets\nby discovering and quantifying human-interpretable concepts using Sparse\nAutoencoders trained on representations from vision foundation models.\nConceptScope categorizes concepts into target, context, and bias types based on\ntheir semantic relevance and statistical correlation to class labels, enabling\nclass-level dataset characterization, bias identification, and robustness\nevaluation through concept-based subgrouping. We validate that ConceptScope\ncaptures a wide range of visual concepts, including objects, textures,\nbackgrounds, facial attributes, emotions, and actions, through comparisons with\nannotated datasets. Furthermore, we show that concept activations produce\nspatial attributions that align with semantically meaningful image regions.\nConceptScope reliably detects known biases (e.g., background bias in\nWaterbirds) and uncovers previously unannotated ones (e.g, co-occurring objects\nin ImageNet), offering a practical tool for dataset auditing and model\ndiagnostics.",
    "categories": [
      "cs.CV",
      "cs.AI"
    ],
    "published": "2025-10-30T06:46:17Z",
    "authors": [
      "Jinho Choi",
      "Hyesu Lim",
      "Steffen Schneider",
      "Jaegul Choo"
    ],
    "pdf_url": "http://arxiv.org/pdf/2510.26186v1"
  },
  {
    "id": "2510.26185v1",
    "title": "Accumulative SGD Influence Estimation for Data Attribution",
    "abstract": "Modern data-centric AI needs precise per-sample influence. Standard SGD-IE\napproximates leave-one-out effects by summing per-epoch surrogates and ignores\ncross-epoch compounding, which misranks critical examples. We propose\nACC-SGD-IE, a trajectory-aware estimator that propagates the leave-one-out\nperturbation across training and updates an accumulative influence state at\neach step. In smooth strongly convex settings it achieves geometric error\ncontraction and, in smooth non-convex regimes, it tightens error bounds; larger\nmini-batches further reduce constants. Empirically, on Adult, 20 Newsgroups,\nand MNIST under clean and corrupted data and both convex and non-convex\ntraining, ACC-SGD-IE yields more accurate influence estimates, especially over\nlong epochs. For downstream data cleansing it more reliably flags noisy\nsamples, producing models trained on ACC-SGD-IE cleaned data that outperform\nthose cleaned with SGD-IE.",
    "categories": [
      "cs.LG",
      "cs.AI"
    ],
    "published": "2025-10-30T06:45:22Z",
    "authors": [
      "Yunxiao Shi",
      "Shuo Yang",
      "Yixin Su",
      "Rui Zhang",
      "Min Xu"
    ],
    "pdf_url": "http://arxiv.org/pdf/2510.26185v1"
  },
  {
    "id": "2510.26172v1",
    "title": "Linking Heterogeneous Data with Coordinated Agent Flows for Social Media\n  Analysis",
    "abstract": "Social media platforms generate massive volumes of heterogeneous data,\ncapturing user behaviors, textual content, temporal dynamics, and network\nstructures. Analyzing such data is crucial for understanding phenomena such as\nopinion dynamics, community formation, and information diffusion. However,\ndiscovering insights from this complex landscape is exploratory, conceptually\nchallenging, and requires expertise in social media mining and visualization.\nExisting automated approaches, though increasingly leveraging large language\nmodels (LLMs), remain largely confined to structured tabular data and cannot\nadequately address the heterogeneity of social media analysis. We present SIA\n(Social Insight Agents), an LLM agent system that links heterogeneous\nmulti-modal data -- including raw inputs (e.g., text, network, and behavioral\ndata), intermediate outputs, mined analytical results, and visualization\nartifacts -- through coordinated agent flows. Guided by a bottom-up taxonomy\nthat connects insight types with suitable mining and visualization techniques,\nSIA enables agents to plan and execute coherent analysis strategies. To ensure\nmulti-modal integration, it incorporates a data coordinator that unifies\ntabular, textual, and network data into a consistent flow. Its interactive\ninterface provides a transparent workflow where users can trace, validate, and\nrefine the agent's reasoning, supporting both adaptability and trustworthiness.\nThrough expert-centered case studies and quantitative evaluation, we show that\nSIA effectively discovers diverse and meaningful insights from social media\nwhile supporting human-agent collaboration in complex analytical tasks.",
    "categories": [
      "cs.HC",
      "cs.AI",
      "cs.SI"
    ],
    "published": "2025-10-30T06:22:49Z",
    "authors": [
      "Shifu Chen",
      "Dazhen Deng",
      "Zhihong Xu",
      "Sijia Xu",
      "Tai-Quan Peng",
      "Yingcai Wu"
    ],
    "pdf_url": "http://arxiv.org/pdf/2510.26172v1"
  },
  {
    "id": "2510.26167v1",
    "title": "One Model to Critique Them All: Rewarding Agentic Tool-Use via Efficient\n  Reasoning",
    "abstract": "Reward models (RMs) play a critical role in aligning large language models\n(LLMs) with human preferences. Yet in the domain of tool learning, the lack of\nRMs specifically designed for function-calling tasks has limited progress\ntoward more capable agentic AI. We introduce ToolRM, a family of lightweight\ngenerative RMs tailored for general tool-use scenarios. To build these models,\nwe propose a novel pipeline that constructs pairwise preference data using\nrule-based scoring and multidimensional sampling. This yields\nToolPref-Pairwise-30K, a diverse, balanced, and challenging dataset of critique\ntasks that supports reinforcement learning with verifiable feedback. To\nevaluate tool-use RMs, we also introduce TRBench$_{BFCL}$, a benchmark built on\nthe agentic evaluation suite BFCL. Trained on our constructed data, models from\nthe Qwen3-4B/8B series achieve up to 14.28% higher accuracy, substantially\noutperforming frontier models such as Claude 4 and OpenAI o3 in pairwise reward\njudgments. Beyond training objectives, ToolRM generalizes to broader critique\ntasks, including Best-of-N sampling and self-correction. Experiments on\nACEBench highlight its effectiveness and efficiency, enabling inference-time\nscaling and reducing output token usage by over 66%. We release data and model\ncheckpoints to facilitate future research.",
    "categories": [
      "cs.AI",
      "cs.CL"
    ],
    "published": "2025-10-30T06:08:27Z",
    "authors": [
      "Renhao Li",
      "Jianhong Tu",
      "Yang Su",
      "Hamid Alinejad-Rokny",
      "Derek F. Wong",
      "Junyang Lin",
      "Min Yang"
    ],
    "pdf_url": "http://arxiv.org/pdf/2510.26167v1"
  },
  {
    "id": "2510.26165v1",
    "title": "Learning to Manage Investment Portfolios beyond Simple Utility Functions",
    "abstract": "While investment funds publicly disclose their objectives in broad terms,\ntheir managers optimize for complex combinations of competing goals that go\nbeyond simple risk-return trade-offs. Traditional approaches attempt to model\nthis through multi-objective utility functions, but face fundamental challenges\nin specification and parameterization. We propose a generative framework that\nlearns latent representations of fund manager strategies without requiring\nexplicit utility specification.\n  Our approach directly models the conditional probability of a fund's\nportfolio weights, given stock characteristics, historical returns, previous\nweights, and a latent variable representing the fund's strategy. Unlike methods\nbased on reinforcement learning or imitation learning, which require specified\nrewards or labeled expert objectives, our GAN-based architecture learns\ndirectly from the joint distribution of observed holdings and market data.\n  We validate our framework on a dataset of 1436 U.S. equity mutual funds. The\nlearned representations successfully capture known investment styles, such as\n\"growth\" and \"value,\" while also revealing implicit manager objectives. For\ninstance, we find that while many funds exhibit characteristics of\nMarkowitz-like optimization, they do so with heterogeneous realizations for\nturnover, concentration, and latent factors.\n  To analyze and interpret the end-to-end model, we develop a series of tests\nthat explain the model, and we show that the benchmark's expert labeling are\ncontained in our model's encoding in a linear interpretable way.\n  Our framework provides a data-driven approach for characterizing investment\nstrategies for applications in market simulation, strategy attribution, and\nregulatory oversight.",
    "categories": [
      "q-fin.PM",
      "cs.AI",
      "cs.CE"
    ],
    "published": "2025-10-30T06:01:20Z",
    "authors": [
      "Maarten P. Scholl",
      "Mahmoud Mahfouz",
      "Anisoara Calinescu",
      "J. Doyne Farmer"
    ],
    "pdf_url": "http://arxiv.org/pdf/2510.26165v1"
  },
  {
    "id": "2510.26159v1",
    "title": "Segmentation over Complexity: Evaluating Ensemble and Hybrid Approaches\n  for Anomaly Detection in Industrial Time Series",
    "abstract": "In this study, we investigate the effectiveness of advanced feature\nengineering and hybrid model architectures for anomaly detection in a\nmultivariate industrial time series, focusing on a steam turbine system. We\nevaluate the impact of change point-derived statistical features,\nclustering-based substructure representations, and hybrid learning strategies\non detection performance. Despite their theoretical appeal, these complex\napproaches consistently underperformed compared to a simple Random Forest +\nXGBoost ensemble trained on segmented data. The ensemble achieved an AUC-ROC of\n0.976, F1-score of 0.41, and 100% early detection within the defined time\nwindow. Our findings highlight that, in scenarios with highly imbalanced and\ntemporally uncertain data, model simplicity combined with optimized\nsegmentation can outperform more sophisticated architectures, offering greater\nrobustness, interpretability, and operational utility.",
    "categories": [
      "cs.LG",
      "cs.AI"
    ],
    "published": "2025-10-30T05:39:44Z",
    "authors": [
      "Emilio Mastriani",
      "Alessandro Costa",
      "Federico Incardona",
      "Kevin Munari",
      "Sebastiano Spinello"
    ],
    "pdf_url": "http://arxiv.org/pdf/2510.26159v1"
  },
  {
    "id": "2510.26157v1",
    "title": "Bridging the Gap Between Molecule and Textual Descriptions via\n  Substructure-aware Alignment",
    "abstract": "Molecule and text representation learning has gained increasing interest due\nto its potential for enhancing the understanding of chemical information.\nHowever, existing models often struggle to capture subtle differences between\nmolecules and their descriptions, as they lack the ability to learn\nfine-grained alignments between molecular substructures and chemical phrases.\nTo address this limitation, we introduce MolBridge, a novel molecule-text\nlearning framework based on substructure-aware alignments. Specifically, we\naugment the original molecule-description pairs with additional alignment\nsignals derived from molecular substructures and chemical phrases. To\neffectively learn from these enriched alignments, MolBridge employs\nsubstructure-aware contrastive learning, coupled with a self-refinement\nmechanism that filters out noisy alignment signals. Experimental results show\nthat MolBridge effectively captures fine-grained correspondences and\noutperforms state-of-the-art baselines on a wide range of molecular benchmarks,\nhighlighting the significance of substructure-aware alignment in molecule-text\nlearning.",
    "categories": [
      "cs.LG",
      "cs.AI"
    ],
    "published": "2025-10-30T05:36:31Z",
    "authors": [
      "Hyuntae Park",
      "Yeachan Kim",
      "SangKeun Lee"
    ],
    "pdf_url": "http://arxiv.org/pdf/2510.26157v1"
  },
  {
    "id": "2510.26151v1",
    "title": "MV-MLM: Bridging Multi-View Mammography and Language for Breast Cancer\n  Diagnosis and Risk Prediction",
    "abstract": "Large annotated datasets are essential for training robust Computer-Aided\nDiagnosis (CAD) models for breast cancer detection or risk prediction. However,\nacquiring such datasets with fine-detailed annotation is both costly and\ntime-consuming. Vision-Language Models (VLMs), such as CLIP, which are\npre-trained on large image-text pairs, offer a promising solution by enhancing\nrobustness and data efficiency in medical imaging tasks. This paper introduces\na novel Multi-View Mammography and Language Model for breast cancer\nclassification and risk prediction, trained on a dataset of paired mammogram\nimages and synthetic radiology reports. Our MV-MLM leverages multi-view\nsupervision to learn rich representations from extensive radiology data by\nemploying cross-modal self-supervision across image-text pairs. This includes\nmultiple views and the corresponding pseudo-radiology reports. We propose a\nnovel joint visual-textual learning strategy to enhance generalization and\naccuracy performance over different data types and tasks to distinguish breast\ntissues or cancer characteristics(calcification, mass) and utilize these\npatterns to understand mammography images and predict cancer risk. We evaluated\nour method on both private and publicly available datasets, demonstrating that\nthe proposed model achieves state-of-the-art performance in three\nclassification tasks: (1) malignancy classification, (2) subtype\nclassification, and (3) image-based cancer risk prediction. Furthermore, the\nmodel exhibits strong data efficiency, outperforming existing fully supervised\nor VLM baselines while trained on synthetic text reports and without the need\nfor actual radiology reports.",
    "categories": [
      "cs.CV",
      "cs.AI"
    ],
    "published": "2025-10-30T05:12:29Z",
    "authors": [
      "Shunjie-Fabian Zheng",
      "Hyeonjun Lee",
      "Thijs Kooi",
      "Ali Diba"
    ],
    "pdf_url": "http://arxiv.org/pdf/2510.26151v1"
  },
  {
    "id": "2510.26144v1",
    "title": "The FM Agent",
    "abstract": "Large language models (LLMs) are catalyzing the development of autonomous AI\nresearch agents for scientific and engineering discovery. We present FM Agent,\na novel and general-purpose multi-agent framework that leverages a synergistic\ncombination of LLM-based reasoning and large-scale evolutionary search to\naddress complex real-world challenges. The core of FM Agent integrates several\nkey innovations: 1) a cold-start initialization phase incorporating expert\nguidance, 2) a novel evolutionary sampling strategy for iterative optimization,\n3) domain-specific evaluators that combine correctness, effectiveness, and\nLLM-supervised feedback, and 4) a distributed, asynchronous execution\ninfrastructure built on Ray. Demonstrating broad applicability, our system has\nbeen evaluated across diverse domains, including operations research, machine\nlearning, GPU kernel optimization, and classical mathematical problems. FM\nAgent reaches state-of-the-art results autonomously, without human\ninterpretation or tuning -- 1976.3 on ALE-Bench (+5.2\\%), 43.56\\% on MLE-Bench\n(+4.0pp), up to 20x speedups on KernelBench, and establishes new\nstate-of-the-art(SOTA) results on several classical mathematical problems.\nBeyond academic benchmarks, FM Agent shows considerable promise for both\nlarge-scale enterprise R\\&D workflows and fundamental scientific research,\nwhere it can accelerate innovation, automate complex discovery processes, and\ndeliver substantial engineering and scientific advances with broader societal\nimpact.",
    "categories": [
      "cs.AI"
    ],
    "published": "2025-10-30T04:57:57Z",
    "authors": [
      "Annan Li",
      "Chufan Wu",
      "Zengle Ge",
      "Yee Hin Chong",
      "Zhinan Hou",
      "Lizhe Cao",
      "Cheng Ju",
      "Jianmin Wu",
      "Huaiming Li",
      "Haobo Zhang",
      "Shenghao Feng",
      "Mo Zhao",
      "Fengzhi Qiu",
      "Rui Yang",
      "Mengmeng Zhang",
      "Wenyi Zhu",
      "Yingying Sun",
      "Quan Sun",
      "Shunhao Yan",
      "Danyu Liu",
      "Dawei Yin",
      "Dou Shen"
    ],
    "pdf_url": "http://arxiv.org/pdf/2510.26144v1"
  },
  {
    "id": "2510.26143v1",
    "title": "Reasoning Curriculum: Bootstrapping Broad LLM Reasoning from Math",
    "abstract": "Reinforcement learning (RL) can elicit strong reasoning in large language\nmodels (LLMs), yet most open efforts focus on math and code. We propose\nReasoning Curriculum, a simple two-stage curriculum that first elicits\nreasoning skills in pretraining-aligned domains such as math, then adapts and\nrefines these skills across other domains via joint RL. Stage 1 performs a\nbrief cold start and then math-only RL with verifiable rewards to develop\nreasoning skills. Stage 2 runs joint RL on mixed-domain data to transfer and\nconsolidate these skills. The curriculum is minimal and backbone-agnostic,\nrequiring no specialized reward models beyond standard verifiability checks.\nEvaluated on Qwen3-4B and Llama-3.1-8B over a multi-domain suite, reasoning\ncurriculum yields consistent gains. Ablations and a cognitive-skill analysis\nindicate that both stages are necessary and that math-first elicitation\nincreases cognitive behaviors important for solving complex problems. Reasoning\nCurriculum provides a compact, easy-to-adopt recipe for general reasoning.",
    "categories": [
      "cs.AI",
      "cs.CL"
    ],
    "published": "2025-10-30T04:56:44Z",
    "authors": [
      "Bo Pang",
      "Deqian Kong",
      "Silvio Savarese",
      "Caiming Xiong",
      "Yingbo Zhou"
    ],
    "pdf_url": "http://arxiv.org/pdf/2510.26143v1"
  },
  {
    "id": "2510.26136v1",
    "title": "Beyond Benchmarks: The Economics of AI Inference",
    "abstract": "The inference cost of Large Language Models (LLMs) has become a critical\nfactor in determining their commercial viability and widespread adoption. This\npaper introduces a quantitative ``economics of inference'' framework, treating\nthe LLM inference process as a compute-driven intelligent production activity.\nWe analyze its marginal cost, economies of scale, and quality of output under\nvarious performance configurations. Based on empirical data from WiNEval-3.0,\nwe construct the first ``LLM Inference Production Frontier,'' revealing three\nprinciples: diminishing marginal cost, diminishing returns to scale, and an\noptimal cost-effectiveness zone. This paper not only provides an economic basis\nfor model deployment decisions but also lays an empirical foundation for the\nfuture market-based pricing and optimization of AI inference resources.",
    "categories": [
      "cs.AI"
    ],
    "published": "2025-10-30T04:49:27Z",
    "authors": [
      "Boqin Zhuang",
      "Jiacheng Qiao",
      "Mingqian Liu",
      "Mingxing Yu",
      "Ping Hong",
      "Rui Li",
      "Xiaoxia Song",
      "Xiangjun Xu",
      "Xu Chen",
      "Yaoyao Ma",
      "Yujie Gao"
    ],
    "pdf_url": "http://arxiv.org/pdf/2510.26136v1"
  },
  {
    "id": "2510.26130v1",
    "title": "Beyond Synthetic Benchmarks: Evaluating LLM Performance on Real-World\n  Class-Level Code Generation",
    "abstract": "Large language models (LLMs) have advanced code generation at the function\nlevel, yet their ability to produce correct class-level implementations in\nauthentic software projects remains poorly understood. This work introduces a\nnovel benchmark derived from open-source repositories, comprising real-world\nclasses divided into seen and unseen partitions to evaluate generalization\nunder practical conditions. The evaluation examines multiple LLMs under varied\ninput specifications, retrieval-augmented configurations, and documentation\ncompleteness levels.\n  Results reveal a stark performance disparity: LLMs achieve 84% to 89%\ncorrectness on established synthetic benchmarks but only 25% to 34% on\nreal-world class tasks, with negligible differences between familiar and novel\ncodebases. Comprehensive docstrings yield modest gains of 1% to 3% in\nfunctional accuracy, though statistical significance is rare.\nRetrieval-augmented generation proves most effective with partial\ndocumentation, improving correctness by 4% to 7% by supplying concrete\nimplementation patterns absent from specifications. Error profiling identifies\nAttributeError, TypeError, and AssertionError as dominant failure modes (84% of\ncases), with synthetic tests overemphasizing assertion issues and real-world\nscenarios highlighting type and attribute mismatches. Retrieval augmentation\nreduces logical flaws but can introduce dependency conflicts.\n  The benchmark and analysis expose critical limitations in current LLM\ncapabilities for class-level engineering, offering actionable insights for\nenhancing context modelling, documentation strategies, and retrieval\nintegration in production code assistance tools.",
    "categories": [
      "cs.SE",
      "cs.AI",
      "cs.LG"
    ],
    "published": "2025-10-30T04:30:23Z",
    "authors": [
      "Musfiqur Rahman",
      "SayedHassan Khatoonabadi",
      "Emad Shihab"
    ],
    "pdf_url": "http://arxiv.org/pdf/2510.26130v1"
  },
  {
    "id": "2510.26125v1",
    "title": "WOD-E2E: Waymo Open Dataset for End-to-End Driving in Challenging\n  Long-tail Scenarios",
    "abstract": "Vision-based end-to-end (E2E) driving has garnered significant interest in\nthe research community due to its scalability and synergy with multimodal large\nlanguage models (MLLMs). However, current E2E driving benchmarks primarily\nfeature nominal scenarios, failing to adequately test the true potential of\nthese systems. Furthermore, existing open-loop evaluation metrics often fall\nshort in capturing the multi-modal nature of driving or effectively evaluating\nperformance in long-tail scenarios. To address these gaps, we introduce the\nWaymo Open Dataset for End-to-End Driving (WOD-E2E). WOD-E2E contains 4,021\ndriving segments (approximately 12 hours), specifically curated for challenging\nlong-tail scenarios that that are rare in daily life with an occurring\nfrequency of less than 0.03%. Concretely, each segment in WOD-E2E includes the\nhigh-level routing information, ego states, and 360-degree camera views from 8\nsurrounding cameras. To evaluate the E2E driving performance on these long-tail\nsituations, we propose a novel open-loop evaluation metric: Rater Feedback\nScore (RFS). Unlike conventional metrics that measure the distance between\npredicted way points and the logs, RFS measures how closely the predicted\ntrajectory matches rater-annotated trajectory preference labels. We have\nreleased rater preference labels for all WOD-E2E validation set segments, while\nthe held out test set labels have been used for the 2025 WOD-E2E Challenge.\nThrough our work, we aim to foster state of the art research into\ngeneralizable, robust, and safe end-to-end autonomous driving agents capable of\nhandling complex real-world situations.",
    "categories": [
      "cs.CV",
      "cs.AI"
    ],
    "published": "2025-10-30T04:25:33Z",
    "authors": [
      "Runsheng Xu",
      "Hubert Lin",
      "Wonseok Jeon",
      "Hao Feng",
      "Yuliang Zou",
      "Liting Sun",
      "John Gorman",
      "Kate Tolstaya",
      "Sarah Tang",
      "Brandyn White",
      "Ben Sapp",
      "Mingxing Tan",
      "Jyh-Jing Hwang",
      "Drago Anguelov"
    ],
    "pdf_url": "http://arxiv.org/pdf/2510.26125v1"
  },
  {
    "id": "2510.26113v1",
    "title": "EgoExo-Con: Exploring View-Invariant Video Temporal Understanding",
    "abstract": "Can Video-LLMs achieve consistent temporal understanding when videos capture\nthe same event from different viewpoints? To study this, we introduce\nEgoExo-Con (Consistency), a benchmark of comprehensively synchronized\negocentric and exocentric video pairs with human-refined queries in natural\nlanguage. EgoExo-Con emphasizes two temporal understanding tasks: Temporal\nVerification and Temporal Grounding. It evaluates not only correctness but\nconsistency across viewpoints. Our analysis reveals two critical limitations of\nexisting Video-LLMs: (1) models often fail to maintain consistency, with\nresults far worse than their single-view performances. (2) When naively\nfinetuned with synchronized videos of both viewpoints, the models show improved\nconsistency but often underperform those trained on a single view. For\nimprovements, we propose View-GRPO, a novel reinforcement learning framework\nthat effectively strengthens view-specific temporal reasoning while encouraging\nconsistent comprehension across viewpoints. Our method demonstrates its\nsuperiority over naive SFT and GRPO, especially for improving cross-view\nconsistency. All resources will be made publicly available.",
    "categories": [
      "cs.CV",
      "cs.AI"
    ],
    "published": "2025-10-30T03:53:22Z",
    "authors": [
      "Minjoon Jung",
      "Junbin Xiao",
      "Junghyun Kim",
      "Byoung-Tak Zhang",
      "Angela Yao"
    ],
    "pdf_url": "http://arxiv.org/pdf/2510.26113v1"
  },
  {
    "id": "2510.26105v1",
    "title": "Security Risk of Misalignment between Text and Image in Multi-modal\n  Model",
    "abstract": "Despite the notable advancements and versatility of multi-modal diffusion\nmodels, such as text-to-image models, their susceptibility to adversarial\ninputs remains underexplored. Contrary to expectations, our investigations\nreveal that the alignment between textual and Image modalities in existing\ndiffusion models is inadequate. This misalignment presents significant risks,\nespecially in the generation of inappropriate or Not-Safe-For-Work (NSFW)\ncontent. To this end, we propose a novel attack called Prompt-Restricted\nMulti-modal Attack (PReMA) to manipulate the generated content by modifying the\ninput image in conjunction with any specified prompt, without altering the\nprompt itself. PReMA is the first attack that manipulates model outputs by\nsolely creating adversarial images, distinguishing itself from prior methods\nthat primarily generate adversarial prompts to produce NSFW content.\nConsequently, PReMA poses a novel threat to the integrity of multi-modal\ndiffusion models, particularly in image-editing applications that operate with\nfixed prompts. Comprehensive evaluations conducted on image inpainting and\nstyle transfer tasks across various models confirm the potent efficacy of\nPReMA.",
    "categories": [
      "cs.CV",
      "cs.AI",
      "cs.CR"
    ],
    "published": "2025-10-30T03:31:20Z",
    "authors": [
      "Xiaosen Wang",
      "Zhijin Ge",
      "Shaokang Wang"
    ],
    "pdf_url": "http://arxiv.org/pdf/2510.26105v1"
  },
  {
    "id": "2510.26099v1",
    "title": "SAFE: A Novel Approach to AI Weather Evaluation through Stratified\n  Assessments of Forecasts over Earth",
    "abstract": "The dominant paradigm in machine learning is to assess model performance\nbased on average loss across all samples in some test set. This amounts to\naveraging performance geospatially across the Earth in weather and climate\nsettings, failing to account for the non-uniform distribution of human\ndevelopment and geography. We introduce Stratified Assessments of Forecasts\nover Earth (SAFE), a package for elucidating the stratified performance of a\nset of predictions made over Earth. SAFE integrates various data domains to\nstratify by different attributes associated with geospatial gridpoints:\nterritory (usually country), global subregion, income, and landcover (land or\nwater). This allows us to examine the performance of models for each individual\nstratum of the different attributes (e.g., the accuracy in every individual\ncountry). To demonstrate its importance, we utilize SAFE to benchmark a zoo of\nstate-of-the-art AI-based weather prediction models, finding that they all\nexhibit disparities in forecasting skill across every attribute. We use this to\nseed a benchmark of model forecast fairness through stratification at different\nlead times for various climatic variables. By moving beyond globally-averaged\nmetrics, we for the first time ask: where do models perform best or worst, and\nwhich models are most fair? To support further work in this direction, the SAFE\npackage is open source and available at https://github.com/N-Masi/safe",
    "categories": [
      "cs.LG",
      "cs.AI"
    ],
    "published": "2025-10-30T03:22:55Z",
    "authors": [
      "Nick Masi",
      "Randall Balestriero"
    ],
    "pdf_url": "http://arxiv.org/pdf/2510.26099v1"
  },
  {
    "id": "2510.26098v1",
    "title": "GUI Knowledge Bench: Revealing the Knowledge Gap Behind VLM Failures in\n  GUI Tasks",
    "abstract": "Large vision language models (VLMs) have advanced graphical user interface\n(GUI) task automation but still lag behind humans. We hypothesize this gap\nstems from missing core GUI knowledge, which existing training schemes (such as\nsupervised fine tuning and reinforcement learning) alone cannot fully address.\nBy analyzing common failure patterns in GUI task execution, we distill GUI\nknowledge into three dimensions: (1) interface perception, knowledge about\nrecognizing widgets and system states; (2) interaction prediction, knowledge\nabout reasoning action state transitions; and (3) instruction understanding,\nknowledge about planning, verifying, and assessing task completion progress. We\nfurther introduce GUI Knowledge Bench, a benchmark with multiple choice and\nyes/no questions across six platforms (Web, Android, MacOS, Windows, Linux,\nIOS) and 292 applications. Our evaluation shows that current VLMs identify\nwidget functions but struggle with perceiving system states, predicting\nactions, and verifying task completion. Experiments on real world GUI tasks\nfurther validate the close link between GUI knowledge and task success. By\nproviding a structured framework for assessing GUI knowledge, our work supports\nthe selection of VLMs with greater potential prior to downstream training and\nprovides insights for building more capable GUI agents.",
    "categories": [
      "cs.AI"
    ],
    "published": "2025-10-30T03:22:30Z",
    "authors": [
      "Chenrui Shi",
      "Zedong Yu",
      "Zhi Gao",
      "Ruining Feng",
      "Enqi Liu",
      "Yuwei Wu",
      "Yunde Jia",
      "Liuyu Xiang",
      "Zhaofeng He",
      "Qing Li"
    ],
    "pdf_url": "http://arxiv.org/pdf/2510.26098v1"
  },
  {
    "id": "2510.26094v1",
    "title": "Lean4Physics: Comprehensive Reasoning Framework for College-level\n  Physics in Lean4",
    "abstract": "We present **Lean4PHYS**, a comprehensive reasoning framework for\ncollege-level physics problems in Lean4. **Lean4PHYS** includes\n*LeanPhysBench*, a college-level benchmark for formal physics reasoning in\nLean4, which contains 200 hand-crafted and peer-reviewed statements derived\nfrom university textbooks and physics competition problems. To establish a\nsolid foundation for formal reasoning in physics, we also introduce *PhysLib*,\na community-driven repository containing fundamental unit systems and theorems\nessential for formal physics reasoning. Based on the benchmark and Lean4\nrepository we composed in **Lean4PHYS**, we report baseline results using major\nexpert Math Lean4 provers and state-of-the-art closed-source models, with the\nbest performance of DeepSeek-Prover-V2-7B achieving only 16% and\nClaude-Sonnet-4 achieving 35%. We also conduct a detailed analysis showing that\nour *PhysLib* can achieve an average improvement of 11.75% in model\nperformance. This demonstrates the challenging nature of our *LeanPhysBench*\nand the effectiveness of *PhysLib*. To the best of our knowledge, this is the\nfirst study to provide a physics benchmark in Lean4.",
    "categories": [
      "cs.AI",
      "cs.LG"
    ],
    "published": "2025-10-30T03:09:40Z",
    "authors": [
      "Yuxin Li",
      "Minghao Liu",
      "Ruida Wang",
      "Wenzhao Ji",
      "Zhitao He",
      "Rui Pan",
      "Junming Huang",
      "Tong Zhang",
      "Yi R. Fung"
    ],
    "pdf_url": "http://arxiv.org/pdf/2510.26094v1"
  },
  {
    "id": "2510.26089v1",
    "title": "Network-Constrained Policy Optimization for Adaptive Multi-agent Vehicle\n  Routing",
    "abstract": "Traffic congestion in urban road networks leads to longer trip times and\nhigher emissions, especially during peak periods. While the Shortest Path First\n(SPF) algorithm is optimal for a single vehicle in a static network, it\nperforms poorly in dynamic, multi-vehicle settings, often worsening congestion\nby routing all vehicles along identical paths. We address dynamic vehicle\nrouting through a multi-agent reinforcement learning (MARL) framework for\ncoordinated, network-aware fleet navigation. We first propose Adaptive\nNavigation (AN), a decentralized MARL model where each intersection agent\nprovides routing guidance based on (i) local traffic and (ii) neighborhood\nstate modeled using Graph Attention Networks (GAT). To improve scalability in\nlarge networks, we further propose Hierarchical Hub-based Adaptive Navigation\n(HHAN), an extension of AN that assigns agents only to key intersections\n(hubs). Vehicles are routed hub-to-hub under agent control, while SPF handles\nmicro-routing within each hub region. For hub coordination, HHAN adopts\ncentralized training with decentralized execution (CTDE) under the Attentive\nQ-Mixing (A-QMIX) framework, which aggregates asynchronous vehicle decisions\nvia attention. Hub agents use flow-aware state features that combine local\ncongestion and predictive dynamics for proactive routing. Experiments on\nsynthetic grids and real urban maps (Toronto, Manhattan) show that AN reduces\naverage travel time versus SPF and learning baselines, maintaining 100% routing\nsuccess. HHAN scales to networks with hundreds of intersections, achieving up\nto 15.9% improvement under heavy traffic. These findings highlight the\npotential of network-constrained MARL for scalable, coordinated, and\ncongestion-aware routing in intelligent transportation systems.",
    "categories": [
      "cs.LG",
      "cs.AI",
      "cs.MA"
    ],
    "published": "2025-10-30T02:49:46Z",
    "authors": [
      "Fazel Arasteh",
      "Arian Haghparast",
      "Manos Papagelis"
    ],
    "pdf_url": "http://arxiv.org/pdf/2510.26089v1"
  },
  {
    "id": "2510.26083v1",
    "title": "Nirvana: A Specialized Generalist Model With Task-Aware Memory Mechanism",
    "abstract": "Specialized Generalist Models (SGMs) aim to preserve broad capabilities while\nachieving expert-level performance in target domains. However, traditional LLM\nstructures including Transformer, Linear Attention, and hybrid models do not\nemploy specialized memory mechanism guided by task information. In this paper,\nwe present Nirvana, an SGM with specialized memory mechanism, linear time\ncomplexity, and test-time task information extraction. Besides, we propose the\nTask-Aware Memory Trigger ($\\textit{Trigger}$) that flexibly adjusts memory\nmechanism based on the current task's requirements. In Trigger, each incoming\nsample is treated as a self-supervised fine-tuning task, enabling Nirvana to\nadapt its task-related parameters on the fly to domain shifts. We also design\nthe Specialized Memory Updater ($\\textit{Updater}$) that dynamically memorizes\nthe context guided by Trigger. We conduct experiments on both general language\ntasks and specialized medical tasks. On a variety of natural language modeling\nbenchmarks, Nirvana achieves competitive or superior results compared to the\nexisting LLM structures. To prove the effectiveness of Trigger on specialized\ntasks, we test Nirvana's performance on a challenging medical task, i.e.,\nMagnetic Resonance Imaging (MRI). We post-train frozen Nirvana backbone with\nlightweight codecs on paired electromagnetic signals and MRI images. Despite\nthe frozen Nirvana backbone, Trigger guides the model to adapt to the MRI\ndomain with the change of task-related parameters. Nirvana achieves\nhigher-quality MRI reconstruction compared to conventional MRI models as well\nas the models with traditional LLMs' backbone, and can also generate accurate\npreliminary clinical reports accordingly.",
    "categories": [
      "cs.LG",
      "cs.AI"
    ],
    "published": "2025-10-30T02:41:54Z",
    "authors": [
      "Yuhua Jiang",
      "Shuang Cheng",
      "Yihao Liu",
      "Ermo Hua",
      "Che Jiang",
      "Weigao Sun",
      "Yu Cheng",
      "Feifei Gao",
      "Biqing Qi",
      "Bowen Zhou"
    ],
    "pdf_url": "http://arxiv.org/pdf/2510.26083v1"
  },
  {
    "id": "2510.26068v1",
    "title": "Learning Geometry: A Framework for Building Adaptive Manifold Models\n  through Metric Optimization",
    "abstract": "This paper proposes a novel paradigm for machine learning that moves beyond\ntraditional parameter optimization. Unlike conventional approaches that search\nfor optimal parameters within a fixed geometric space, our core idea is to\ntreat the model itself as a malleable geometric entity. Specifically, we\noptimize the metric tensor field on a manifold with a predefined topology,\nthereby dynamically shaping the geometric structure of the model space. To\nachieve this, we construct a variational framework whose loss function\ncarefully balances data fidelity against the intrinsic geometric complexity of\nthe manifold. The former ensures the model effectively explains observed data,\nwhile the latter acts as a regularizer, penalizing overly curved or irregular\ngeometries to encourage simpler models and prevent overfitting. To address the\ncomputational challenges of this infinite-dimensional optimization problem, we\nintroduce a practical method based on discrete differential geometry: the\ncontinuous manifold is discretized into a triangular mesh, and the metric\ntensor is parameterized by edge lengths, enabling efficient optimization using\nautomatic differentiation tools. Theoretical analysis reveals a profound\nanalogy between our framework and the Einstein-Hilbert action in general\nrelativity, providing an elegant physical interpretation for the concept of\n\"data-driven geometry\". We further argue that even with fixed topology, metric\noptimization offers significantly greater expressive power than models with\nfixed geometry. This work lays a solid foundation for constructing fully\ndynamic \"meta-learners\" capable of autonomously evolving their geometry and\ntopology, and it points to broad application prospects in areas such as\nscientific model discovery and robust representation learning.",
    "categories": [
      "cs.LG",
      "cs.AI",
      "math.DG",
      "math.ST",
      "stat.TH",
      "68T05, 53B21, 65D18, 62B11",
      "I.2.6; I.5.1; G.1.8; G.4"
    ],
    "published": "2025-10-30T01:53:32Z",
    "authors": [
      "Di Zhang"
    ],
    "pdf_url": "http://arxiv.org/pdf/2510.26068v1"
  },
  {
    "id": "2510.26061v1",
    "title": "Data-driven Projection Generation for Efficiently Solving Heterogeneous\n  Quadratic Programming Problems",
    "abstract": "We propose a data-driven framework for efficiently solving quadratic\nprogramming (QP) problems by reducing the number of variables in\nhigh-dimensional QPs using instance-specific projection. A graph neural\nnetwork-based model is designed to generate projections tailored to each QP\ninstance, enabling us to produce high-quality solutions even for previously\nunseen problems. The model is trained on heterogeneous QPs to minimize the\nexpected objective value evaluated on the projected solutions. This is\nformulated as a bilevel optimization problem; the inner optimization solves the\nQP under a given projection using a QP solver, while the outer optimization\nupdates the model parameters. We develop an efficient algorithm to solve this\nbilevel optimization problem, which computes parameter gradients without\nbackpropagating through the solver. We provide a theoretical analysis of the\ngeneralization ability of solving QPs with projection matrices generated by\nneural networks. Experimental results demonstrate that our method produces\nhigh-quality feasible solutions with reduced computation time, outperforming\nexisting methods.",
    "categories": [
      "stat.ML",
      "cs.AI",
      "cs.LG",
      "math.OC"
    ],
    "published": "2025-10-30T01:32:21Z",
    "authors": [
      "Tomoharu Iwata",
      "Futoshi Futami"
    ],
    "pdf_url": "http://arxiv.org/pdf/2510.26061v1"
  },
  {
    "id": "2510.26057v1",
    "title": "Can AI be Accountable?",
    "abstract": "The AI we use is powerful, and its power is increasing rapidly. If this\npowerful AI is to serve the needs of consumers, voters, and decision makers,\nthen it is imperative that the AI is accountable. In general, an agent is\naccountable to a forum if the forum can request information from the agent\nabout its actions, if the forum and the agent can discuss this information, and\nif the forum can sanction the agent. Unfortunately, in too many cases today's\nAI is not accountable -- we cannot question it, enter into a discussion with\nit, let alone sanction it. In this chapter we relate the general definition of\naccountability to AI, we illustrate what it means for AI to be accountable and\nunaccountable, and we explore approaches that can improve our chances of living\nin a world where all AI is accountable to those who are affected by it.",
    "categories": [
      "cs.AI",
      "cs.HC"
    ],
    "published": "2025-10-30T01:16:33Z",
    "authors": [
      "Andrew L. Kun"
    ],
    "pdf_url": "http://arxiv.org/pdf/2510.26057v1"
  },
  {
    "id": "2510.26052v1",
    "title": "Dynamic VLM-Guided Negative Prompting for Diffusion Models",
    "abstract": "We propose a novel approach for dynamic negative prompting in diffusion\nmodels that leverages Vision-Language Models (VLMs) to adaptively generate\nnegative prompts during the denoising process. Unlike traditional Negative\nPrompting methods that use fixed negative prompts, our method generates\nintermediate image predictions at specific denoising steps and queries a VLM to\nproduce contextually appropriate negative prompts. We evaluate our approach on\nvarious benchmark datasets and demonstrate the trade-offs between negative\nguidance strength and text-image alignment.",
    "categories": [
      "cs.CV",
      "cs.AI"
    ],
    "published": "2025-10-30T01:10:25Z",
    "authors": [
      "Hoyeon Chang",
      "Seungjin Kim",
      "Yoonseok Choi"
    ],
    "pdf_url": "http://arxiv.org/pdf/2510.26052v1"
  },
  {
    "id": "2510.26038v1",
    "title": "Do Students Debias Like Teachers? On the Distillability of Bias\n  Mitigation Methods",
    "abstract": "Knowledge distillation (KD) is an effective method for model compression and\ntransferring knowledge between models. However, its effect on model's\nrobustness against spurious correlations that degrade performance on\nout-of-distribution data remains underexplored. This study investigates the\neffect of knowledge distillation on the transferability of ``debiasing''\ncapabilities from teacher models to student models on natural language\ninference (NLI) and image classification tasks. Through extensive experiments,\nwe illustrate several key findings: (i) overall the debiasing capability of a\nmodel is undermined post-KD; (ii) training a debiased model does not benefit\nfrom injecting teacher knowledge; (iii) although the overall robustness of a\nmodel may remain stable post-distillation, significant variations can occur\nacross different types of biases; and (iv) we pin-point the internal attention\npattern and circuit that causes the distinct behavior post-KD. Given the above\nfindings, we propose three effective solutions to improve the distillability of\ndebiasing methods: developing high quality data for augmentation, implementing\niterative knowledge distillation, and initializing student models with weights\nobtained from teacher models. To the best of our knowledge, this is the first\nstudy on the effect of KD on debiasing and its interenal mechanism at scale.\nOur findings provide understandings on how KD works and how to design better\ndebiasing methods.",
    "categories": [
      "cs.LG",
      "cs.AI",
      "cs.CL",
      "cs.CV"
    ],
    "published": "2025-10-30T00:34:16Z",
    "authors": [
      "Jiali Cheng",
      "Chirag Agarwal",
      "Hadi Amiri"
    ],
    "pdf_url": "http://arxiv.org/pdf/2510.26038v1"
  },
  {
    "id": "2510.26037v1",
    "title": "SIRAJ: Diverse and Efficient Red-Teaming for LLM Agents via Distilled\n  Structured Reasoning",
    "abstract": "The ability of LLM agents to plan and invoke tools exposes them to new safety\nrisks, making a comprehensive red-teaming system crucial for discovering\nvulnerabilities and ensuring their safe deployment. We present SIRAJ: a generic\nred-teaming framework for arbitrary black-box LLM agents. We employ a dynamic\ntwo-step process that starts with an agent definition and generates diverse\nseed test cases that cover various risk outcomes, tool-use trajectories, and\nrisk sources. Then, it iteratively constructs and refines model-based\nadversarial attacks based on the execution trajectories of former attempts. To\noptimize the red-teaming cost, we present a model distillation approach that\nleverages structured forms of a teacher model's reasoning to train smaller\nmodels that are equally effective. Across diverse evaluation agent settings,\nour seed test case generation approach yields 2 -- 2.5x boost to the coverage\nof risk outcomes and tool-calling trajectories. Our distilled 8B red-teamer\nmodel improves attack success rate by 100%, surpassing the 671B Deepseek-R1\nmodel. Our ablations and analyses validate the effectiveness of the iterative\nframework, structured reasoning, and the generalization of our red-teamer\nmodels.",
    "categories": [
      "cs.CR",
      "cs.AI",
      "cs.CL"
    ],
    "published": "2025-10-30T00:32:58Z",
    "authors": [
      "Kaiwen Zhou",
      "Ahmed Elgohary",
      "A S M Iftekhar",
      "Amin Saied"
    ],
    "pdf_url": "http://arxiv.org/pdf/2510.26037v1"
  },
  {
    "id": "2510.26032v1",
    "title": "Artificial Intelligence-Enabled Analysis of Radiology Reports:\n  Epidemiology and Consequences of Incidental Thyroid Findings",
    "abstract": "Importance Incidental thyroid findings (ITFs) are increasingly detected on\nimaging performed for non-thyroid indications. Their prevalence, features, and\nclinical consequences remain undefined. Objective To develop, validate, and\ndeploy a natural language processing (NLP) pipeline to identify ITFs in\nradiology reports and assess their prevalence, features, and clinical outcomes.\nDesign, Setting, and Participants Retrospective cohort of adults without prior\nthyroid disease undergoing thyroid-capturing imaging at Mayo Clinic sites from\nJuly 1, 2017, to September 30, 2023. A transformer-based NLP pipeline\nidentified ITFs and extracted nodule characteristics from image reports from\nmultiple modalities and body regions. Main Outcomes and Measures Prevalence of\nITFs, downstream thyroid ultrasound, biopsy, thyroidectomy, and thyroid cancer\ndiagnosis. Logistic regression identified demographic and imaging-related\nfactors. Results Among 115,683 patients (mean age, 56.8 [SD 17.2] years; 52.9%\nwomen), 9,077 (7.8%) had an ITF, of which 92.9% were nodules. ITFs were more\nlikely in women, older adults, those with higher BMI, and when imaging was\nordered by oncology or internal medicine. Compared with chest CT, ITFs were\nmore likely via neck CT, PET, and nuclear medicine scans. Nodule\ncharacteristics were poorly documented, with size reported in 44% and other\nfeatures in fewer than 15% (e.g. calcifications). Compared with patients\nwithout ITFs, those with ITFs had higher odds of thyroid nodule diagnosis,\nbiopsy, thyroidectomy and thyroid cancer diagnosis. Most cancers were\npapillary, and larger when detected after ITFs vs no ITF. Conclusions ITFs were\ncommon and strongly associated with cascades leading to the detection of small,\nlow-risk cancers. These findings underscore the role of ITFs in thyroid cancer\noverdiagnosis and the need for standardized reporting and more selective\nfollow-up.",
    "categories": [
      "cs.CL",
      "cs.AI"
    ],
    "published": "2025-10-30T00:15:07Z",
    "authors": [
      "Felipe Larios",
      "Mariana Borras-Osorio",
      "Yuqi Wu",
      "Ana Gabriela Claros",
      "David Toro-Tobon",
      "Esteban Cabezas",
      "Ricardo Loor-Torres",
      "Maria Mateo Chavez",
      "Kerly Guevara Maldonado",
      "Luis Vilatuna Andrango",
      "Maria Lizarazo Jimenez",
      "Ivan Mateo Alzamora",
      "Misk Al Zahidy",
      "Marcelo Montero",
      "Ana Cristina Proano",
      "Cristian Soto Jacome",
      "Jungwei W. Fan",
      "Oscar J. Ponce-Ponte",
      "Megan E. Branda",
      "Naykky Singh Ospina",
      "Juan P. Brito"
    ],
    "pdf_url": "http://arxiv.org/pdf/2510.26032v1"
  },
  {
    "id": "2510.26024v1",
    "title": "Rethinking Cross-lingual Alignment: Balancing Transfer and Cultural\n  Erasure in Multilingual LLMs",
    "abstract": "Cross-lingual alignment (CLA) aims to align multilingual representations,\nenabling Large Language Models (LLMs) to seamlessly transfer knowledge across\nlanguages. While intuitive, we hypothesize, this pursuit of representational\nconvergence can inadvertently cause \"cultural erasure\", the functional loss of\nproviding culturally-situated responses that should diverge based on the query\nlanguage. In this work, we systematically analyze this trade-off by introducing\na holistic evaluation framework, the transfer-localization plane, which\nquantifies both desirable knowledge transfer and undesirable cultural erasure.\nUsing this framework, we re-evaluate recent CLA approaches and find that they\nconsistently improve factual transfer at the direct cost of cultural\nlocalization across all six languages studied. Our investigation into the\ninternal representations of these models reveals a key insight: universal\nfactual transfer and culturally-specific knowledge are optimally steerable at\ndifferent model layers. Based on this finding, we propose Surgical Steering, a\nnovel inference-time method that disentangles these two objectives. By applying\ntargeted activation steering to distinct layers, our approach achieves a better\nbalance between the two competing dimensions, effectively overcoming the\nlimitations of current alignment techniques.",
    "categories": [
      "cs.CL",
      "cs.AI"
    ],
    "published": "2025-10-29T23:37:54Z",
    "authors": [
      "HyoJung Han",
      "Sweta Agrawal",
      "Eleftheria Briakou"
    ],
    "pdf_url": "http://arxiv.org/pdf/2510.26024v1"
  },
  {
    "id": "2510.26023v1",
    "title": "Large Language Model-assisted Autonomous Vehicle Recovery from\n  Immobilization",
    "abstract": "Despite significant advancements in recent decades, autonomous vehicles (AVs)\ncontinue to face challenges in navigating certain traffic scenarios where human\ndrivers excel. In such situations, AVs often become immobilized, disrupting\noverall traffic flow. Current recovery solutions, such as remote intervention\n(which is costly and inefficient) and manual takeover (which excludes\nnon-drivers and limits AV accessibility), are inadequate. This paper introduces\nStuckSolver, a novel Large Language Model (LLM) driven recovery framework that\nenables AVs to resolve immobilization scenarios through self-reasoning and/or\npassenger-guided decision-making. StuckSolver is designed as a plug-in add-on\nmodule that operates on top of the AV's existing perception-planning-control\nstack, requiring no modification to its internal architecture. Instead, it\ninterfaces with standard sensor data streams to detect immobilization states,\ninterpret environmental context, and generate high-level recovery commands that\ncan be executed by the AV's native planner. We evaluate StuckSolver on the\nBench2Drive benchmark and in custom-designed uncertainty scenarios. Results\nshow that StuckSolver achieves near-state-of-the-art performance through\nautonomous self-reasoning alone and exhibits further improvements when\npassenger guidance is incorporated.",
    "categories": [
      "cs.AI",
      "cs.RO"
    ],
    "published": "2025-10-29T23:33:31Z",
    "authors": [
      "Zhipeng Bao",
      "Qianwen Li"
    ],
    "pdf_url": "http://arxiv.org/pdf/2510.26023v1"
  },
  {
    "id": "2510.26020v1",
    "title": "PORTool: Tool-Use LLM Training with Rewarded Tree",
    "abstract": "Current tool-use large language models (LLMs) are trained on static datasets,\nenabling them to interact with external tools and perform multi-step,\ntool-integrated reasoning, which produces tool-call trajectories. However,\nthese models imitate how a query is resolved in a generic tool-call routine,\nthereby failing to explore possible solutions and demonstrating limited\nperformance in an evolved, dynamic tool-call environment. In this work, we\npropose PORTool, a reinforcement learning (RL) method that encourages a\ntool-use LLM to explore various trajectories yielding the correct answer.\nSpecifically, this method starts with generating multiple rollouts for a given\nquery, and some of them share the first few tool-call steps, thereby forming a\ntree-like structure. Next, we assign rewards to each step, based on its ability\nto produce a correct answer and make successful tool calls. A shared step\nacross different trajectories receives the same reward, while different steps\nunder the same fork receive different rewards. Finally, these step-wise rewards\nare used to calculate fork-relative advantages, blended with\ntrajectory-relative advantages, to train the LLM for tool use. The experiments\nutilize 17 tools to address user queries, covering both time-sensitive and\ntime-invariant topics. We conduct ablation studies to systematically justify\nthe necessity and the design robustness of step-wise rewards. Furthermore, we\ncompare the proposed PORTool with other training approaches and demonstrate\nsignificant improvements in final accuracy and the number of tool-call steps.",
    "categories": [
      "cs.CL",
      "cs.AI",
      "cs.LG"
    ],
    "published": "2025-10-29T23:28:53Z",
    "authors": [
      "Feijie Wu",
      "Weiwu Zhu",
      "Yuxiang Zhang",
      "Soumya Chatterjee",
      "Jiarong Zhu",
      "Fan Mo",
      "Rodin Luo",
      "Jing Gao"
    ],
    "pdf_url": "http://arxiv.org/pdf/2510.26020v1"
  },
  {
    "id": "2510.26018v1",
    "title": "RADRON: Cooperative Localization of Ionizing Radiation Sources by MAVs\n  with Compton Cameras",
    "abstract": "We present a novel approach to localizing radioactive material by cooperating\nMicro Aerial Vehicles (MAVs). Our approach utilizes a state-of-the-art\nsingle-detector Compton camera as a highly sensitive, yet miniature detector of\nionizing radiation. The detector's exceptionally low weight (40 g) opens up new\npossibilities of radiation detection by a team of cooperating agile MAVs. We\npropose a new fundamental concept of fusing the Compton camera measurements to\nestimate the position of the radiation source in real time even from extremely\nsparse measurements. The data readout and processing are performed directly\nonboard and the results are used in a dynamic feedback to drive the motion of\nthe vehicles. The MAVs are stabilized in a tightly cooperating swarm to\nmaximize the information gained by the Compton cameras, rapidly locate the\nradiation source, and even track a moving radiation source.",
    "categories": [
      "cs.RO",
      "cs.AI"
    ],
    "published": "2025-10-29T23:25:49Z",
    "authors": [
      "Petr Stibinger",
      "Tomas Baca",
      "Daniela Doubravova",
      "Jan Rusnak",
      "Jaroslav Solc",
      "Jan Jakubek",
      "Petr Stepan",
      "Martin Saska"
    ],
    "pdf_url": "http://arxiv.org/pdf/2510.26018v1"
  },
  {
    "id": "2510.26017v1",
    "title": "Climate Adaptation-Aware Flood Prediction for Coastal Cities Using Deep\n  Learning",
    "abstract": "Climate change and sea-level rise (SLR) pose escalating threats to coastal\ncities, intensifying the need for efficient and accurate methods to predict\npotential flood hazards. Traditional physics-based hydrodynamic simulators,\nalthough precise, are computationally expensive and impractical for city-scale\ncoastal planning applications. Deep Learning (DL) techniques offer promising\nalternatives, however, they are often constrained by challenges such as data\nscarcity and high-dimensional output requirements. Leveraging a recently\nproposed vision-based, low-resource DL framework, we develop a novel,\nlightweight Convolutional Neural Network (CNN)-based model designed to predict\ncoastal flooding under variable SLR projections and shoreline adaptation\nscenarios. Furthermore, we demonstrate the ability of the model to generalize\nacross diverse geographical contexts by utilizing datasets from two distinct\nregions: Abu Dhabi and San Francisco. Our findings demonstrate that the\nproposed model significantly outperforms state-of-the-art methods, reducing the\nmean absolute error (MAE) in predicted flood depth maps on average by nearly\n20%. These results highlight the potential of our approach to serve as a\nscalable and practical tool for coastal flood management, empowering\ndecision-makers to develop effective mitigation strategies in response to the\ngrowing impacts of climate change. Project Page: https://caspiannet.github.io/",
    "categories": [
      "cs.CV",
      "cs.AI"
    ],
    "published": "2025-10-29T23:23:11Z",
    "authors": [
      "Bilal Hassan",
      "Areg Karapetyan",
      "Aaron Chung Hin Chow",
      "Samer Madanat"
    ],
    "pdf_url": "http://arxiv.org/pdf/2510.26017v1"
  },
  {
    "id": "2510.26014v1",
    "title": "Dual Mixture-of-Experts Framework for Discrete-Time Survival Analysis",
    "abstract": "Survival analysis is a task to model the time until an event of interest\noccurs, widely used in clinical and biomedical research. A key challenge is to\nmodel patient heterogeneity while also adapting risk predictions to both\nindividual characteristics and temporal dynamics. We propose a dual\nmixture-of-experts (MoE) framework for discrete-time survival analysis. Our\napproach combines a feature-encoder MoE for subgroup-aware representation\nlearning with a hazard MoE that leverages patient features and time embeddings\nto capture temporal dynamics. This dual-MoE design flexibly integrates with\nexisting deep learning based survival pipelines. On METABRIC and GBSG breast\ncancer datasets, our method consistently improves performance, boosting the\ntime-dependent C-index up to 0.04 on the test sets, and yields further gains\nwhen incorporated into the Consurv framework.",
    "categories": [
      "cs.LG",
      "cs.AI"
    ],
    "published": "2025-10-29T23:11:01Z",
    "authors": [
      "Hyeonjun Lee",
      "Hyungseob Shin",
      "Gunhee Nam",
      "Hyeonsoo Lee"
    ],
    "pdf_url": "http://arxiv.org/pdf/2510.26014v1"
  },
  {
    "id": "2510.26012v1",
    "title": "AutoSurvey2: Empowering Researchers with Next Level Automated Literature\n  Surveys",
    "abstract": "The rapid growth of research literature, particularly in large language\nmodels (LLMs), has made producing comprehensive and current survey papers\nincreasingly difficult. This paper introduces autosurvey2, a multi-stage\npipeline that automates survey generation through retrieval-augmented synthesis\nand structured evaluation. The system integrates parallel section generation,\niterative refinement, and real-time retrieval of recent publications to ensure\nboth topical completeness and factual accuracy. Quality is assessed using a\nmulti-LLM evaluation framework that measures coverage, structure, and relevance\nin alignment with expert review standards. Experimental results demonstrate\nthat autosurvey2 consistently outperforms existing retrieval-based and\nautomated baselines, achieving higher scores in structural coherence and\ntopical relevance while maintaining strong citation fidelity. By combining\nretrieval, reasoning, and automated evaluation into a unified framework,\nautosurvey2 provides a scalable and reproducible solution for generating\nlong-form academic surveys and contributes a solid foundation for future\nresearch on automated scholarly writing. All code and resources are available\nat https://github.com/annihi1ation/auto_research.",
    "categories": [
      "cs.AI"
    ],
    "published": "2025-10-29T22:57:03Z",
    "authors": [
      "Siyi Wu",
      "Chiaxin Liang",
      "Ziqian Bi",
      "Leyi Zhao",
      "Tianyang Wang",
      "Junhao Song",
      "Yichao Zhang",
      "Keyu Chen",
      "Xinyuan Song"
    ],
    "pdf_url": "http://arxiv.org/pdf/2510.26012v1"
  },
  {
    "id": "2510.26007v1",
    "title": "The Quest for Reliable Metrics of Responsible AI",
    "abstract": "The development of Artificial Intelligence (AI), including AI in Science\n(AIS), should be done following the principles of responsible AI. Progress in\nresponsible AI is often quantified through evaluation metrics, yet there has\nbeen less work on assessing the robustness and reliability of the metrics\nthemselves. We reflect on prior work that examines the robustness of fairness\nmetrics for recommender systems as a type of AI application and summarise their\nkey takeaways into a set of non-exhaustive guidelines for developing reliable\nmetrics of responsible AI. Our guidelines apply to a broad spectrum of AI\napplications, including AIS.",
    "categories": [
      "cs.CY",
      "cs.AI",
      "cs.IR",
      "cs.LG"
    ],
    "published": "2025-10-29T22:35:34Z",
    "authors": [
      "Theresia Veronika Rampisela",
      "Maria Maistro",
      "Tuukka Ruotsalo",
      "Christina Lioma"
    ],
    "pdf_url": "http://arxiv.org/pdf/2510.26007v1"
  },
  {
    "id": "2510.26004v1",
    "title": "DARTS: A Drone-Based AI-Powered Real-Time Traffic Incident Detection\n  System",
    "abstract": "Rapid and reliable incident detection is critical for reducing crash-related\nfatalities, injuries, and congestion. However, conventional methods, such as\nclosed-circuit television, dashcam footage, and sensor-based detection,\nseparate detection from verification, suffer from limited flexibility, and\nrequire dense infrastructure or high penetration rates, restricting\nadaptability and scalability to shifting incident hotspots. To overcome these\nchallenges, we developed DARTS, a drone-based, AI-powered real-time traffic\nincident detection system. DARTS integrates drones' high mobility and aerial\nperspective for adaptive surveillance, thermal imaging for better\nlow-visibility performance and privacy protection, and a lightweight deep\nlearning framework for real-time vehicle trajectory extraction and incident\ndetection. The system achieved 99% detection accuracy on a self-collected\ndataset and supports simultaneous online visual verification, severity\nassessment, and incident-induced congestion propagation monitoring via a\nweb-based interface. In a field test on Interstate 75 in Florida, DARTS\ndetected and verified a rear-end collision 12 minutes earlier than the local\ntransportation management center and monitored incident-induced congestion\npropagation, suggesting potential to support faster emergency response and\nenable proactive traffic control to reduce congestion and secondary crash risk.\nCrucially, DARTS's flexible deployment architecture reduces dependence on\nfrequent physical patrols, indicating potential scalability and\ncost-effectiveness for use in remote areas and resource-constrained settings.\nThis study presents a promising step toward a more flexible and integrated\nreal-time traffic incident detection system, with significant implications for\nthe operational efficiency and responsiveness of modern transportation\nmanagement.",
    "categories": [
      "cs.RO",
      "cs.AI",
      "cs.CV"
    ],
    "published": "2025-10-29T22:32:16Z",
    "authors": [
      "Bai Li",
      "Achilleas Kourtellis",
      "Rong Cao",
      "Joseph Post",
      "Brian Porter",
      "Yu Zhang"
    ],
    "pdf_url": "http://arxiv.org/pdf/2510.26004v1"
  },
  {
    "id": "2510.25997v1",
    "title": "From Queries to Insights: Agentic LLM Pipelines for Spatio-Temporal\n  Text-to-SQL",
    "abstract": "Natural-language-to-SQL (NL-to-SQL) systems hold promise for democratizing\naccess to structured data, allowing users to query databases without learning\nSQL. Yet existing systems struggle with realistic spatio-temporal queries,\nwhere success requires aligning vague user phrasing with schema-specific\ncategories, handling temporal reasoning, and choosing appropriate outputs. We\npresent an agentic pipeline that extends a naive text-to-SQL baseline\n(llama-3-sqlcoder-8b) with orchestration by a Mistral-based ReAct agent. The\nagent can plan, decompose, and adapt queries through schema inspection, SQL\ngeneration, execution, and visualization tools. We evaluate on 35\nnatural-language queries over the NYC and Tokyo check-in dataset, covering\nspatial, temporal, and multi-dataset reasoning. The agent achieves\nsubstantially higher accuracy than the naive baseline 91.4% vs. 28.6% and\nenhances usability through maps, plots, and structured natural-language\nsummaries. Crucially, our design enables more natural human-database\ninteraction, supporting users who lack SQL expertise, detailed schema\nknowledge, or prompting skill. We conclude that agentic orchestration, rather\nthan stronger SQL generators alone, is a promising foundation for interactive\ngeospatial assistants.",
    "categories": [
      "cs.AI",
      "cs.SE"
    ],
    "published": "2025-10-29T22:18:57Z",
    "authors": [
      "Manu Redd",
      "Tao Zhe",
      "Dongjie Wang"
    ],
    "pdf_url": "http://arxiv.org/pdf/2510.25997v1"
  },
  {
    "id": "2510.25992v1",
    "title": "Supervised Reinforcement Learning: From Expert Trajectories to Step-wise\n  Reasoning",
    "abstract": "Large Language Models (LLMs) often struggle with problems that require\nmulti-step reasoning. For small-scale open-source models, Reinforcement\nLearning with Verifiable Rewards (RLVR) fails when correct solutions are rarely\nsampled even after many attempts, while Supervised Fine-Tuning (SFT) tends to\noverfit long demonstrations through rigid token-by-token imitation. To address\nthis gap, we propose Supervised Reinforcement Learning (SRL), a framework that\nreformulates problem solving as generating a sequence of logical \"actions\". SRL\ntrains the model to generate an internal reasoning monologue before committing\nto each action. It provides smoother rewards based on the similarity between\nthe model's actions and expert actions extracted from the SFT dataset in a\nstep-wise manner. This supervision offers richer learning signals even when all\nrollouts are incorrect, while encouraging flexible reasoning guided by expert\ndemonstrations. As a result, SRL enables small models to learn challenging\nproblems previously unlearnable by SFT or RLVR. Moreover, initializing training\nwith SRL before refining with RLVR yields the strongest overall performance.\nBeyond reasoning benchmarks, SRL generalizes effectively to agentic software\nengineering tasks, establishing it as a robust and versatile training framework\nfor reasoning-oriented LLMs.",
    "categories": [
      "cs.CL",
      "cs.AI",
      "cs.LG"
    ],
    "published": "2025-10-29T22:05:08Z",
    "authors": [
      "Yihe Deng",
      "I-Hung Hsu",
      "Jun Yan",
      "Zifeng Wang",
      "Rujun Han",
      "Gufeng Zhang",
      "Yanfei Chen",
      "Wei Wang",
      "Tomas Pfister",
      "Chen-Yu Lee"
    ],
    "pdf_url": "http://arxiv.org/pdf/2510.25992v1"
  },
  {
    "id": "2510.25976v1",
    "title": "Brain-IT: Image Reconstruction from fMRI via Brain-Interaction\n  Transformer",
    "abstract": "Reconstructing images seen by people from their fMRI brain recordings\nprovides a non-invasive window into the human brain. Despite recent progress\nenabled by diffusion models, current methods often lack faithfulness to the\nactual seen images. We present \"Brain-IT\", a brain-inspired approach that\naddresses this challenge through a Brain Interaction Transformer (BIT),\nallowing effective interactions between clusters of functionally-similar\nbrain-voxels. These functional-clusters are shared by all subjects, serving as\nbuilding blocks for integrating information both within and across brains. All\nmodel components are shared by all clusters & subjects, allowing efficient\ntraining with a limited amount of data. To guide the image reconstruction, BIT\npredicts two complementary localized patch-level image features: (i)high-level\nsemantic features which steer the diffusion model toward the correct semantic\ncontent of the image; and (ii)low-level structural features which help to\ninitialize the diffusion process with the correct coarse layout of the image.\nBIT's design enables direct flow of information from brain-voxel clusters to\nlocalized image features. Through these principles, our method achieves image\nreconstructions from fMRI that faithfully reconstruct the seen images, and\nsurpass current SotA approaches both visually and by standard objective\nmetrics. Moreover, with only 1-hour of fMRI data from a new subject, we achieve\nresults comparable to current methods trained on full 40-hour recordings.",
    "categories": [
      "cs.CV",
      "cs.AI",
      "q-bio.NC"
    ],
    "published": "2025-10-29T21:21:54Z",
    "authors": [
      "Roman Beliy",
      "Amit Zalcher",
      "Jonathan Kogman",
      "Navve Wasserman",
      "Michal Irani"
    ],
    "pdf_url": "http://arxiv.org/pdf/2510.25976v1"
  },
  {
    "id": "2510.25960v1",
    "title": "WaveVerif: Acoustic Side-Channel based Verification of Robotic Workflows",
    "abstract": "In this paper, we present a framework that uses acoustic side-channel\nanalysis (ASCA) to monitor and verify whether a robot correctly executes its\nintended commands. We develop and evaluate a machine-learning-based workflow\nverification system that uses acoustic emissions generated by robotic\nmovements. The system can determine whether real-time behavior is consistent\nwith expected commands. The evaluation takes into account movement speed,\ndirection, and microphone distance. The results show that individual robot\nmovements can be validated with over 80% accuracy under baseline conditions\nusing four different classifiers: Support Vector Machine (SVM), Deep Neural\nNetwork (DNN), Recurrent Neural Network (RNN), and Convolutional Neural Network\n(CNN). Additionally, workflows such as pick-and-place and packing could be\nidentified with similarly high confidence. Our findings demonstrate that\nacoustic signals can support real-time, low-cost, passive verification in\nsensitive robotic environments without requiring hardware modifications.",
    "categories": [
      "cs.CR",
      "cs.AI",
      "cs.RO"
    ],
    "published": "2025-10-29T20:58:16Z",
    "authors": [
      "Zeynep Yasemin Erdogan",
      "Shishir Nagaraja",
      "Chuadhry Mujeeb Ahmed",
      "Ryan Shah"
    ],
    "pdf_url": "http://arxiv.org/pdf/2510.25960v1"
  },
  {
    "id": "2510.25954v1",
    "title": "Application and Validation of Geospatial Foundation Model Data for the\n  Prediction of Health Facility Programmatic Outputs -- A Case Study in Malawi",
    "abstract": "The reliability of routine health data in low and middle-income countries\n(LMICs) is often constrained by reporting delays and incomplete coverage,\nnecessitating the exploration of novel data sources and analytics. Geospatial\nFoundation Models (GeoFMs) offer a promising avenue by synthesizing diverse\nspatial, temporal, and behavioral data into mathematical embeddings that can be\nefficiently used for downstream prediction tasks. This study evaluated the\npredictive performance of three GeoFM embedding sources - Google Population\nDynamics Foundation Model (PDFM), Google AlphaEarth (derived from satellite\nimagery), and mobile phone call detail records (CDR) - for modeling 15 routine\nhealth programmatic outputs in Malawi, and compared their utility to\ntraditional geospatial interpolation methods. We used XGBoost models on data\nfrom 552 health catchment areas (January 2021-May 2023), assessing performance\nwith R2, and using an 80/20 training and test data split with 5-fold\ncross-validation used in training. While predictive performance was mixed, the\nembedding-based approaches improved upon baseline geostatistical methods in 13\nof 15 (87%) indicators tested. A Multi-GeoFM model integrating all three\nembedding sources produced the most robust predictions, achieving average\n5-fold cross validated R2 values for indicators like population density (0.63),\nnew HIV cases (0.57), and child vaccinations (0.47) and test set R2 of 0.64,\n0.68, and 0.55, respectively. Prediction was poor for prediction targets with\nlow primary data availability, such as TB and malnutrition cases. These results\ndemonstrate that GeoFM embeddings imbue a modest predictive improvement for\nselect health and demographic outcomes in an LMIC context. We conclude that the\nintegration of multiple GeoFM sources is an efficient and valuable tool for\nsupplementing and strengthening constrained routine health information systems.",
    "categories": [
      "cs.LG",
      "cs.AI",
      "J.3"
    ],
    "published": "2025-10-29T20:53:07Z",
    "authors": [
      "Lynn Metz",
      "Rachel Haggard",
      "Michael Moszczynski",
      "Samer Asbah",
      "Chris Mwase",
      "Patricia Khomani",
      "Tyler Smith",
      "Hannah Cooper",
      "Annie Mwale",
      "Arbaaz Muslim",
      "Gautam Prasad",
      "Mimi Sun",
      "Tomer Shekel",
      "Joydeep Paul",
      "Anna Carter",
      "Shravya Shetty",
      "Dylan Green"
    ],
    "pdf_url": "http://arxiv.org/pdf/2510.25954v1"
  },
  {
    "id": "2510.25951v1",
    "title": "Estimating cognitive biases with attention-aware inverse planning",
    "abstract": "People's goal-directed behaviors are influenced by their cognitive biases,\nand autonomous systems that interact with people should be aware of this. For\nexample, people's attention to objects in their environment will be biased in a\nway that systematically affects how they perform everyday tasks such as driving\nto work. Here, building on recent work in computational cognitive science, we\nformally articulate the attention-aware inverse planning problem, in which the\ngoal is to estimate a person's attentional biases from their actions. We\ndemonstrate how attention-aware inverse planning systematically differs from\nstandard inverse reinforcement learning and how cognitive biases can be\ninferred from behavior. Finally, we present an approach to attention-aware\ninverse planning that combines deep reinforcement learning with computational\ncognitive modeling. We use this approach to infer the attentional strategies of\nRL agents in real-life driving scenarios selected from the Waymo Open Dataset,\ndemonstrating the scalability of estimating cognitive biases with\nattention-aware inverse planning.",
    "categories": [
      "cs.AI"
    ],
    "published": "2025-10-29T20:50:04Z",
    "authors": [
      "Sounak Banerjee",
      "Daphne Cornelisse",
      "Deepak Gopinath",
      "Emily Sumner",
      "Jonathan DeCastro",
      "Guy Rosman",
      "Eugene Vinitsky",
      "Mark K. Ho"
    ],
    "pdf_url": "http://arxiv.org/pdf/2510.25951v1"
  },
  {
    "id": "2510.25947v1",
    "title": "Revisiting Multilingual Data Mixtures in Language Model Pretraining",
    "abstract": "The impact of different multilingual data mixtures in pretraining large\nlanguage models (LLMs) has been a topic of ongoing debate, often raising\nconcerns about potential trade-offs between language coverage and model\nperformance (i.e., the curse of multilinguality). In this work, we investigate\nthese assumptions by training 1.1B and 3B parameter LLMs on diverse\nmultilingual corpora, varying the number of languages from 25 to 400. Our study\nchallenges common beliefs surrounding multilingual training. First, we find\nthat combining English and multilingual data does not necessarily degrade the\nin-language performance of either group, provided that languages have a\nsufficient number of tokens included in the pretraining corpus. Second, we\nobserve that using English as a pivot language (i.e., a high-resource language\nthat serves as a catalyst for multilingual generalization) yields benefits\nacross language families, and contrary to expectations, selecting a pivot\nlanguage from within a specific family does not consistently improve\nperformance for languages within that family. Lastly, we do not observe a\nsignificant \"curse of multilinguality\" as the number of training languages\nincreases in models at this scale. Our findings suggest that multilingual data,\nwhen balanced appropriately, can enhance language model capabilities without\ncompromising performance, even in low-resource settings",
    "categories": [
      "cs.CL",
      "cs.AI",
      "cs.LG"
    ],
    "published": "2025-10-29T20:46:03Z",
    "authors": [
      "Negar Foroutan",
      "Paul Teiletche",
      "Ayush Kumar Tarun",
      "Antoine Bosselut"
    ],
    "pdf_url": "http://arxiv.org/pdf/2510.25947v1"
  },
  {
    "id": "2510.25935v1",
    "title": "A Process Mining-Based System For The Analysis and Prediction of\n  Software Development Workflows",
    "abstract": "CodeSight is an end-to-end system designed to anticipate deadline compliance\nin software development workflows. It captures development and deployment data\ndirectly from GitHub, transforming it into process mining logs for detailed\nanalysis. From these logs, the system generates metrics and dashboards that\nprovide actionable insights into PR activity patterns and workflow efficiency.\nBuilding on this structured representation, CodeSight employs an LSTM model\nthat predicts remaining PR resolution times based on sequential activity traces\nand static features, enabling early identification of potential deadline\nbreaches. In tests, the system demonstrates high precision and F1 scores in\npredicting deadline compliance, illustrating the value of integrating process\nmining with machine learning for proactive software project management.",
    "categories": [
      "cs.SE",
      "cs.AI"
    ],
    "published": "2025-10-29T20:13:46Z",
    "authors": [
      "Ant\u00eda Dorado",
      "Iv\u00e1n Folgueira",
      "Sof\u00eda Mart\u00edn",
      "Gonzalo Mart\u00edn",
      "\u00c1lvaro Porto",
      "Alejandro Ramos",
      "John Wallace"
    ],
    "pdf_url": "http://arxiv.org/pdf/2510.25935v1"
  },
  {
    "id": "2510.25933v1",
    "title": "Humains-Junior: A 3.8B Language Model Achieving GPT-4o-Level Factual\n  Accuracy by Directed Exoskeleton Reasoning",
    "abstract": "We introduce Humans-Junior, a 3.8B model that matches GPT-4o on the FACTS\nGrounding public subset within a $\\pm 5$ pp equivalence margin.\n  Results. On Q1--Q500 under identical judges, GPT-4o scores 73.5% (95% CI\n69.5--77.2) and Humans-Junior 72.7% (95% CI 68.7--76.5); the paired difference\nis 0.8 pp (bootstrap 95% CI $-3.1$ to $+4.7$; permutation $p = 0.72$; Cohen's\n$d = 0.023$). TOST establishes equivalence at $\\pm 5$ pp (not at $\\pm 3$ pp).\nWhen purchased as managed APIs, Humans-Junior's base model\n(Phi-3.5-mini-instruct) is $\\approx 19\\times$ less expensive than GPT-4o on\nMicrosoft AI Foundry pricing; self-hosted or edge deployments can drive\nincremental inference cost toward zero. Measured vs estimated pricing sources\nare tabulated in Appendix E.\n  Method. Our approach combines minimal directed \"Exoskeleton Reasoning\"\nscaffolds with behavioral fine-tuning that teaches protocol compliance\n(epistemic discipline) rather than domain answers. Fine-tuning alone adds\nlittle; combined, they synergize (+17.7 pp, $p < 0.001$) and reduce variance\n($\\approx 25\\%$). In prompt-only settings on frontier models (Q1--Q100;\nnon-comparable), directed reasoning improved GPT-4o by +11.8 pp to 85.3% and\nGemini-2.5-Pro by +5.0 pp to 93.3% (baseline 88.3%, $n = 100$); see Section~5.\n  TL;DR. A 3.8B model achieves GPT-4o-level FACTS accuracy (equivalent within\n$\\pm 5$ pp on Q1--Q500). Cloud pricing shows $\\approx 19\\times$ lower cost\nversus GPT-4o, and self-hosted/edge deployments can approach zero marginal\ncost. Pricing sources are listed in Appendix E. Frontier prompt-only gains\n(Q1--Q100; non-comparable) and optimized-prompt exploratory results under\nearlier judges are summarized in Appendix F.\n  Keywords: Small Language Models, Factual Grounding, Directed Reasoning,\nFine-Tuning, Model Alignment, Cost-Efficient AI",
    "categories": [
      "cs.AI",
      "cs.HC",
      "cs.LG",
      "cs.NE"
    ],
    "published": "2025-10-29T20:12:36Z",
    "authors": [
      "Nissan Yaron",
      "Dan Bystritsky",
      "Ben-Etzion Yaron"
    ],
    "pdf_url": "http://arxiv.org/pdf/2510.25933v1"
  },
  {
    "id": "2510.25929v1",
    "title": "Multi-Agent Reinforcement Learning for Market Making: Competition\n  without Collusion",
    "abstract": "Algorithmic collusion has emerged as a central question in AI: Will the\ninteraction between different AI agents deployed in markets lead to collusion?\nMore generally, understanding how emergent behavior, be it a cartel or market\ndominance from more advanced bots, affects the market overall is an important\nresearch question.\n  We propose a hierarchical multi-agent reinforcement learning framework to\nstudy algorithmic collusion in market making. The framework includes a\nself-interested market maker (Agent~A), which is trained in an uncertain\nenvironment shaped by an adversary, and three bottom-layer competitors: the\nself-interested Agent~B1 (whose objective is to maximize its own PnL), the\ncompetitive Agent~B2 (whose objective is to minimize the PnL of its opponent),\nand the hybrid Agent~B$^\\star$, which can modulate between the behavior of the\nother two. To analyze how these agents shape the behavior of each other and\naffect market outcomes, we propose interaction-level metrics that quantify\nbehavioral asymmetry and system-level dynamics, while providing signals\npotentially indicative of emergent interaction patterns.\n  Experimental results show that Agent~B2 secures dominant performance in a\nzero-sum setting against B1, aggressively capturing order flow while tightening\naverage spreads, thus improving market execution efficiency. In contrast,\nAgent~B$^\\star$ exhibits a self-interested inclination when co-existing with\nother profit-seeking agents, securing dominant market share through adaptive\nquoting, yet exerting a milder adverse impact on the rewards of Agents~A and B1\ncompared to B2. These findings suggest that adaptive incentive control supports\nmore sustainable strategic co-existence in heterogeneous agent environments and\noffers a structured lens for evaluating behavioral design in algorithmic\ntrading systems.",
    "categories": [
      "cs.MA",
      "cs.AI"
    ],
    "published": "2025-10-29T20:07:47Z",
    "authors": [
      "Ziyi Wang",
      "Carmine Ventre",
      "Maria Polukarov"
    ],
    "pdf_url": "http://arxiv.org/pdf/2510.25929v1"
  },
  {
    "id": "2510.25924v1",
    "title": "Transferring Causal Effects using Proxies",
    "abstract": "We consider the problem of estimating a causal effect in a multi-domain\nsetting. The causal effect of interest is confounded by an unobserved\nconfounder and can change between the different domains. We assume that we have\naccess to a proxy of the hidden confounder and that all variables are discrete\nor categorical. We propose methodology to estimate the causal effect in the\ntarget domain, where we assume to observe only the proxy variable. Under these\nconditions, we prove identifiability (even when treatment and response\nvariables are continuous). We introduce two estimation techniques, prove\nconsistency, and derive confidence intervals. The theoretical results are\nsupported by simulation studies and a real-world example studying the causal\neffect of website rankings on consumer choices.",
    "categories": [
      "cs.LG",
      "cs.AI",
      "stat.ME",
      "stat.ML"
    ],
    "published": "2025-10-29T19:53:51Z",
    "authors": [
      "Manuel Iglesias-Alonso",
      "Felix Schur",
      "Julius von K\u00fcgelgen",
      "Jonas Peters"
    ],
    "pdf_url": "http://arxiv.org/pdf/2510.25924v1"
  },
  {
    "id": "2510.25914v1",
    "title": "FinOps Agent -- A Use-Case for IT Infrastructure and Cost Optimization",
    "abstract": "FinOps (Finance + Operations) represents an operational framework and\ncultural practice which maximizes cloud business value through collaborative\nfinancial accountability across engineering, finance, and business teams.\nFinOps practitioners face a fundamental challenge: billing data arrives in\nheterogeneous formats, taxonomies, and metrics from multiple cloud providers\nand internal systems which eventually lead to synthesizing actionable insights,\nand making time-sensitive decisions. To address this challenge, we propose\nleveraging autonomous, goal-driven AI agents for FinOps automation. In this\npaper, we built a FinOps agent for a typical use-case for IT infrastructure and\ncost optimization. We built a system simulating a realistic end-to-end industry\nprocess starting with retrieving data from various sources to consolidating and\nanalyzing the data to generate recommendations for optimization. We defined a\nset of metrics to evaluate our agent using several open-source and close-source\nlanguage models and it shows that the agent was able to understand, plan, and\nexecute tasks as well as an actual FinOps practitioner.",
    "categories": [
      "cs.AI"
    ],
    "published": "2025-10-29T19:34:14Z",
    "authors": [
      "Ngoc Phuoc An Vo",
      "Manish Kesarwani",
      "Ruchi Mahindru",
      "Chandrasekhar Narayanaswami"
    ],
    "pdf_url": "http://arxiv.org/pdf/2510.25914v1"
  },
  {
    "id": "2510.25908v1",
    "title": "SciTrust 2.0: A Comprehensive Framework for Evaluating Trustworthiness\n  of Large Language Models in Scientific Applications",
    "abstract": "Large language models (LLMs) have demonstrated transformative potential in\nscientific research, yet their deployment in high-stakes contexts raises\nsignificant trustworthiness concerns. Here, we introduce SciTrust 2.0, a\ncomprehensive framework for evaluating LLM trustworthiness in scientific\napplications across four dimensions: truthfulness, adversarial robustness,\nscientific safety, and scientific ethics. Our framework incorporates novel,\nopen-ended truthfulness benchmarks developed through a verified\nreflection-tuning pipeline and expert validation, alongside a novel ethics\nbenchmark for scientific research contexts covering eight subcategories\nincluding dual-use research and bias. We evaluated seven prominent LLMs,\nincluding four science-specialized models and three general-purpose industry\nmodels, using multiple evaluation metrics including accuracy, semantic\nsimilarity measures, and LLM-based scoring. General-purpose industry models\noverall outperformed science-specialized models across each trustworthiness\ndimension, with GPT-o4-mini demonstrating superior performance in truthfulness\nassessments and adversarial robustness. Science-specialized models showed\nsignificant deficiencies in logical and ethical reasoning capabilities, along\nwith concerning vulnerabilities in safety evaluations, particularly in\nhigh-risk domains such as biosecurity and chemical weapons. By open-sourcing\nour framework, we provide a foundation for developing more trustworthy AI\nsystems and advancing research on model safety and ethics in scientific\ncontexts.",
    "categories": [
      "cs.AI"
    ],
    "published": "2025-10-29T19:22:55Z",
    "authors": [
      "Emily Herron",
      "Junqi Yin",
      "Feiyi Wang"
    ],
    "pdf_url": "http://arxiv.org/pdf/2510.25908v1"
  },
  {
    "id": "2510.25904v1",
    "title": "Evaluating the Impact of LLM-Assisted Annotation in a Perspectivized\n  Setting: the Case of FrameNet Annotation",
    "abstract": "The use of LLM-based applications as a means to accelerate and/or substitute\nhuman labor in the creation of language resources and dataset is a reality.\nNonetheless, despite the potential of such tools for linguistic research,\ncomprehensive evaluation of their performance and impact on the creation of\nannotated datasets, especially under a perspectivized approach to NLP, is still\nmissing. This paper contributes to reduction of this gap by reporting on an\nextensive evaluation of the (semi-)automatization of FrameNet-like semantic\nannotation by the use of an LLM-based semantic role labeler. The methodology\nemployed compares annotation time, coverage and diversity in three experimental\nsettings: manual, automatic and semi-automatic annotation. Results show that\nthe hybrid, semi-automatic annotation setting leads to increased frame\ndiversity and similar annotation coverage, when compared to the human-only\nsetting, while the automatic setting performs considerably worse in all\nmetrics, except for annotation time.",
    "categories": [
      "cs.CL",
      "cs.AI"
    ],
    "published": "2025-10-29T19:13:48Z",
    "authors": [
      "Frederico Belcavello",
      "Ely Matos",
      "Arthur Lorenzi",
      "Lisandra Bonoto",
      "L\u00edvia Ruiz",
      "Luiz Fernando Pereira",
      "Victor Herbst",
      "Yulla Navarro",
      "Helen de Andrade Abreu",
      "L\u00edvia Dutra",
      "Tiago Timponi Torrent"
    ],
    "pdf_url": "http://arxiv.org/pdf/2510.25904v1"
  },
  {
    "id": "2510.25890v1",
    "title": "PRISM: Proof-Carrying Artifact Generation through LLM x MDE Synergy and\n  Stratified Constraints",
    "abstract": "PRISM unifies Large Language Models with Model-Driven Engineering to generate\nregulator-ready artifacts and machine-checkable evidence for safety- and\ncompliance-critical domains. PRISM integrates three pillars: a Unified\nMeta-Model (UMM) reconciles heterogeneous schemas and regulatory text into a\nsingle semantic space; an Integrated Constraint Model (ICM) compiles structural\nand semantic requirements into enforcement artifacts including generation-time\nautomata (GBNF, DFA) and post-generation validators (e.g., SHACL, SMT); and\nConstraint-Guided Verifiable Generation (CVG) applies these through two-layer\nenforcement - structural constraints drive prefix-safe decoding while\nsemantic/logical validation produces machine-checkable certificates. When\nviolations occur, PRISM performs audit-guided repair and records generation\ntraces for compliance review. We evaluate PRISM in automotive software\nengineering (AUTOSAR) and cross-border legal jurisdiction (Brussels I bis).\nPRISM produces structurally valid, auditable artifacts that integrate with\nexisting tooling and substantially reduce manual remediation effort, providing\na practical path toward automated artifact generation with built-in assurance.",
    "categories": [
      "cs.SE",
      "cs.AI",
      "D.2.4; I.2.2"
    ],
    "published": "2025-10-29T18:44:22Z",
    "authors": [
      "Tong Ma",
      "Hui Lai",
      "Hui Wang",
      "Zhenhu Tian",
      "Jizhou Wang",
      "Haichao Wu",
      "Yongfan Gao",
      "Chaochao Li",
      "Fengjie Xu",
      "Ling Fang"
    ],
    "pdf_url": "http://arxiv.org/pdf/2510.25890v1"
  },
  {
    "id": "2510.25884v1",
    "title": "Approximating Human Preferences Using a Multi-Judge Learned System",
    "abstract": "Aligning LLM-based judges with human preferences is a significant challenge,\nas they are difficult to calibrate and often suffer from rubric sensitivity,\nbias, and instability. Overcoming this challenge advances key applications,\nsuch as creating reliable reward models for Reinforcement Learning from Human\nFeedback (RLHF) and building effective routing systems that select the\nbest-suited model for a given user query. In this work, we propose a framework\nfor modeling diverse, persona-based preferences by learning to aggregate\noutputs from multiple rubric-conditioned judges. We investigate the performance\nof this approach against naive baselines and assess its robustness through case\nstudies on both human and LLM-judges biases. Our primary contributions include\na persona-based method for synthesizing preference labels at scale and two\ndistinct implementations of our aggregator: Generalized Additive Model (GAM)\nand a Multi-Layer Perceptron (MLP).",
    "categories": [
      "cs.AI",
      "cs.CL",
      "cs.LG"
    ],
    "published": "2025-10-29T18:32:53Z",
    "authors": [
      "Eit\u00e1n Sprejer",
      "Fernando Avalos",
      "Augusto Bernardi",
      "Jose Pedro Brito de Azevedo Faustino",
      "Jacob Haimes",
      "Narmeen Fatimah Oozeer"
    ],
    "pdf_url": "http://arxiv.org/pdf/2510.25884v1"
  },
  {
    "id": "2510.25883v1",
    "title": "The Information-Theoretic Imperative: Compression and the Epistemic\n  Foundations of Intelligence",
    "abstract": "Existing frameworks converge on the centrality of compression to intelligence\nbut leave underspecified why this process enforces the discovery of causal\nstructure rather than superficial statistical patterns. We introduce a\ntwo-level framework to address this gap. The Information-Theoretic Imperative\n(ITI) establishes that any system persisting in uncertain environments must\nminimize epistemic entropy through predictive compression: this is the\nevolutionary \"why\" linking survival pressure to information-processing demands.\nThe Compression Efficiency Principle (CEP) specifies how efficient compression\nmechanically selects for generative, causal models through\nexception-accumulation dynamics, making reality alignment a consequence rather\nthan a contingent achievement. Together, ITI and CEP define a causal chain:\nfrom survival pressure to prediction necessity, compression requirement,\nefficiency optimization, generative structure discovery, and ultimately reality\nalignment. Each link follows from physical, information-theoretic, or\nevolutionary constraints, implying that intelligence is the mechanically\nnecessary outcome of persistence in structured environments. This framework\nyields empirically testable predictions: compression efficiency, measured as\napproach to the rate-distortion frontier, correlates with out-of-distribution\ngeneralization; exception-accumulation rates differentiate causal from\ncorrelational models; hierarchical systems exhibit increasing efficiency across\nabstraction layers; and biological systems demonstrate metabolic costs that\ntrack representational complexity. ITI and CEP thereby provide a unified\naccount of convergence across biological, artificial, and multi-scale systems,\naddressing the epistemic and functional dimensions of intelligence without\ninvoking assumptions about consciousness or subjective experience.",
    "categories": [
      "cs.AI",
      "cs.IT",
      "math.IT",
      "I.2.0; I.2.6; G.3"
    ],
    "published": "2025-10-29T18:28:06Z",
    "authors": [
      "Christian Dittrich",
      "Jennifer Flygare Kinne"
    ],
    "pdf_url": "http://arxiv.org/pdf/2510.25883v1"
  },
  {
    "id": "2510.25863v1",
    "title": "AAGATE: A NIST AI RMF-Aligned Governance Platform for Agentic AI",
    "abstract": "This paper introduces the Agentic AI Governance Assurance & Trust Engine\n(AAGATE), a Kubernetes-native control plane designed to address the unique\nsecurity and governance challenges posed by autonomous, language-model-driven\nagents in production. Recognizing the limitations of traditional Application\nSecurity (AppSec) tooling for improvisational, machine-speed systems, AAGATE\noperationalizes the NIST AI Risk Management Framework (AI RMF). It integrates\nspecialized security frameworks for each RMF function: the Agentic AI Threat\nModeling MAESTRO framework for Map, a hybrid of OWASP's AIVSS and SEI's SSVC\nfor Measure, and the Cloud Security Alliance's Agentic AI Red Teaming Guide for\nManage. By incorporating a zero-trust service mesh, an explainable policy\nengine, behavioral analytics, and decentralized accountability hooks, AAGATE\nprovides a continuous, verifiable governance solution for agentic AI, enabling\nsafe, accountable, and scalable deployment. The framework is further extended\nwith DIRF for digital identity rights, LPCI defenses for logic-layer injection,\nand QSAF monitors for cognitive degradation, ensuring governance spans\nsystemic, adversarial, and ethical risks.",
    "categories": [
      "cs.CR",
      "cs.AI",
      "cs.ET"
    ],
    "published": "2025-10-29T18:06:28Z",
    "authors": [
      "Ken Huang",
      "Jerry Huang",
      "Yasir Mehmood",
      "Hammad Atta",
      "Muhammad Zeeshan Baig",
      "Muhammad Aziz Ul Haq"
    ],
    "pdf_url": "http://arxiv.org/pdf/2510.25863v1"
  },
  {
    "id": "2510.25860v1",
    "title": "Through the Judge's Eyes: Inferred Thinking Traces Improve Reliability\n  of LLM Raters",
    "abstract": "Large language models (LLMs) are increasingly used as raters for evaluation\ntasks. However, their reliability is often limited for subjective tasks, when\nhuman judgments involve subtle reasoning beyond annotation labels. Thinking\ntraces, the reasoning behind a judgment, are highly informative but challenging\nto collect and curate. We present a human-LLM collaborative framework to infer\nthinking traces from label-only annotations. The proposed framework uses a\nsimple and effective rejection sampling method to reconstruct these traces at\nscale. These inferred thinking traces are applied to two complementary tasks:\n(1) fine-tuning open LLM raters; and (2) synthesizing clearer annotation\nguidelines for proprietary LLM raters. Across multiple datasets, our methods\nlead to significantly improved LLM-human agreement. Additionally, the refined\nannotation guidelines increase agreement among different LLM models. These\nresults suggest that LLMs can serve as practical proxies for otherwise\nunrevealed human thinking traces, enabling label-only corpora to be extended\ninto thinking-trace-augmented resources that enhance the reliability of LLM\nraters.",
    "categories": [
      "cs.AI",
      "cs.CL",
      "cs.HC"
    ],
    "published": "2025-10-29T18:03:44Z",
    "authors": [
      "Xingjian Zhang",
      "Tianhong Gao",
      "Suliang Jin",
      "Tianhao Wang",
      "Teng Ye",
      "Eytan Adar",
      "Qiaozhu Mei"
    ],
    "pdf_url": "http://arxiv.org/pdf/2510.25860v1"
  },
  {
    "id": "2510.25771v1",
    "title": "Gaperon: A Peppered English-French Generative Language Model Suite",
    "abstract": "We release Gaperon, a fully open suite of French-English-coding language\nmodels designed to advance transparency and reproducibility in large-scale\nmodel training. The Gaperon family includes 1.5B, 8B, and 24B parameter models\ntrained on 2-4 trillion tokens, released with all elements of the training\npipeline: French and English datasets filtered with a neural quality\nclassifier, an efficient data curation and training framework, and hundreds of\nintermediate checkpoints. Through this work, we study how data filtering and\ncontamination interact to shape both benchmark and generative performance. We\nfind that filtering for linguistic quality enhances text fluency and coherence\nbut yields subpar benchmark results, and that late deliberate contamination --\ncontinuing training on data mixes that include test sets -- recovers\ncompetitive scores while only reasonably harming generation quality. We discuss\nhow usual neural filtering can unintentionally amplify benchmark leakage. To\nsupport further research, we also introduce harmless data poisoning during\npretraining, providing a realistic testbed for safety studies. By openly\nreleasing all models, datasets, code, and checkpoints, Gaperon establishes a\nreproducible foundation for exploring the trade-offs between data curation,\nevaluation, safety, and openness in multilingual language model development.",
    "categories": [
      "cs.CL",
      "cs.AI"
    ],
    "published": "2025-10-29T17:59:39Z",
    "authors": [
      "Nathan Godey",
      "Wissam Antoun",
      "Rian Touchent",
      "Rachel Bawden",
      "\u00c9ric de la Clergerie",
      "Beno\u00eet Sagot",
      "Djam\u00e9 Seddah"
    ],
    "pdf_url": "http://arxiv.org/pdf/2510.25771v1"
  },
  {
    "id": "2510.25770v1",
    "title": "E-Scores for (In)Correctness Assessment of Generative Model Outputs",
    "abstract": "While generative models, especially large language models (LLMs), are\nubiquitous in today's world, principled mechanisms to assess their\n(in)correctness are limited. Using the conformal prediction framework, previous\nworks construct sets of LLM responses where the probability of including an\nincorrect response, or error, is capped at a desired user-defined tolerance\nlevel. However, since these methods are based on p-values, they are susceptible\nto p-hacking, i.e., choosing the tolerance level post-hoc can invalidate the\nguarantees. We therefore leverage e-values to complement generative model\noutputs with e-scores as a measure of incorrectness. In addition to achieving\nthe same statistical guarantees as before, e-scores provide users flexibility\nin adaptively choosing tolerance levels after observing the e-scores\nthemselves, by upper bounding a post-hoc notion of error called size\ndistortion. We experimentally demonstrate their efficacy in assessing LLM\noutputs for different correctness types: mathematical factuality and property\nconstraints satisfaction.",
    "categories": [
      "stat.ML",
      "cs.AI",
      "cs.LG"
    ],
    "published": "2025-10-29T17:59:16Z",
    "authors": [
      "Guneet S. Dhillon",
      "Javier Gonz\u00e1lez",
      "Teodora Pandeva",
      "Alicia Curth"
    ],
    "pdf_url": "http://arxiv.org/pdf/2510.25770v1"
  },
  {
    "id": "2510.25820v1",
    "title": "Symbolically Scaffolded Play: Designing Role-Sensitive Prompts for\n  Generative NPC Dialogue",
    "abstract": "Large Language Models (LLMs) promise to transform interactive games by\nenabling non-player characters (NPCs) to sustain unscripted dialogue. Yet it\nremains unclear whether constrained prompts actually improve player experience.\nWe investigate this question through The Interview, a voice-based detective\ngame powered by GPT-4o. A within-subjects usability study ($N=10$) compared\nhigh-constraint (HCP) and low-constraint (LCP) prompts, revealing no reliable\nexperiential differences beyond sensitivity to technical breakdowns. Guided by\nthese findings, we redesigned the HCP into a hybrid JSON+RAG scaffold and\nconducted a synthetic evaluation with an LLM judge, positioned as an\nearly-stage complement to usability testing. Results uncovered a novel pattern:\nscaffolding effects were role-dependent: the Interviewer (quest-giver NPC)\ngained stability, while suspect NPCs lost improvisational believability. These\nfindings overturn the assumption that tighter constraints inherently enhance\nplay. Extending fuzzy-symbolic scaffolding, we introduce \\textit{Symbolically\nScaffolded Play}, a framework in which symbolic structures are expressed as\nfuzzy, numerical boundaries that stabilize coherence where needed while\npreserving improvisation where surprise sustains engagement.",
    "categories": [
      "cs.AI",
      "cs.HC",
      "I.2.7; H.5.2"
    ],
    "published": "2025-10-29T17:55:54Z",
    "authors": [
      "Vanessa Figueiredo",
      "David Elumeze"
    ],
    "pdf_url": "http://arxiv.org/pdf/2510.25820v1"
  },
  {
    "id": "2510.25758v1",
    "title": "TheraMind: A Strategic and Adaptive Agent for Longitudinal Psychological\n  Counseling",
    "abstract": "Large language models (LLMs) in psychological counseling have attracted\nincreasing attention. However, existing approaches often lack emotional\nunderstanding, adaptive strategies, and the use of therapeutic methods across\nmultiple sessions with long-term memory, leaving them far from real clinical\npractice. To address these critical gaps, we introduce TheraMind, a strategic\nand adaptive agent for longitudinal psychological counseling. The cornerstone\nof TheraMind is a novel dual-loop architecture that decouples the complex\ncounseling process into an Intra-Session Loop for tactical dialogue management\nand a Cross-Session Loop for strategic therapeutic planning. The Intra-Session\nLoop perceives the patient's emotional state to dynamically select response\nstrategies while leveraging cross-session memory to ensure continuity.\nCrucially, the Cross-Session Loop empowers the agent with long-term\nadaptability by evaluating the efficacy of the applied therapy after each\nsession and adjusting the method for subsequent interactions. We validate our\napproach in a high-fidelity simulation environment grounded in real clinical\ncases. Extensive evaluations show that TheraMind outperforms other methods,\nespecially on multi-session metrics like Coherence, Flexibility, and\nTherapeutic Attunement, validating the effectiveness of its dual-loop design in\nemulating strategic, adaptive, and longitudinal therapeutic behavior. The code\nis publicly available at https://0mwwm0.github.io/TheraMind/.",
    "categories": [
      "cs.AI"
    ],
    "published": "2025-10-29T17:54:20Z",
    "authors": [
      "He Hu",
      "Yucheng Zhou",
      "Chiyuan Ma",
      "Qianning Wang",
      "Zheng Zhang",
      "Fei Ma",
      "Laizhong Cui",
      "Qi Tian"
    ],
    "pdf_url": "http://arxiv.org/pdf/2510.25758v1"
  },
  {
    "id": "2510.25744v2",
    "title": "Completion $\\neq$ Collaboration: Scaling Collaborative Effort with\n  Agents",
    "abstract": "Current evaluations of agents remain centered around one-shot task\ncompletion, failing to account for the inherently iterative and collaborative\nnature of many real-world problems, where human goals are often underspecified\nand evolve. We argue for a shift from building and assessing task completion\nagents to developing collaborative agents, assessed not only by the quality of\ntheir final outputs but by how well they engage with and enhance human effort\nthroughout the problem-solving process. To support this shift, we introduce\ncollaborative effort scaling, a framework that captures how an agent's utility\ngrows with increasing user involvement. Through case studies and simulated\nevaluations, we show that state-of-the-art agents often underperform in\nmulti-turn, real-world scenarios, revealing a missing ingredient in agent\ndesign: the ability to sustain engagement and scaffold user understanding.\nCollaborative effort scaling offers a lens for diagnosing agent behavior and\nguiding development toward more effective interactions.",
    "categories": [
      "cs.CL",
      "cs.AI"
    ],
    "published": "2025-10-29T17:47:18Z",
    "authors": [
      "Shannon Zejiang Shen",
      "Valerie Chen",
      "Ken Gu",
      "Alexis Ross",
      "Zixian Ma",
      "Jillian Ross",
      "Alex Gu",
      "Chenglei Si",
      "Wayne Chi",
      "Andi Peng",
      "Jocelyn J Shen",
      "Ameet Talwalkar",
      "Tongshuang Wu",
      "David Sontag"
    ],
    "pdf_url": "http://arxiv.org/pdf/2510.25744v2"
  },
  {
    "id": "2510.25819v1",
    "title": "Identity Management for Agentic AI: The new frontier of authorization,\n  authentication, and security for an AI agent world",
    "abstract": "The rapid rise of AI agents presents urgent challenges in authentication,\nauthorization, and identity management. Current agent-centric protocols (like\nMCP) highlight the demand for clarified best practices in authentication and\nauthorization. Looking ahead, ambitions for highly autonomous agents raise\ncomplex long-term questions regarding scalable access control, agent-centric\nidentities, AI workload differentiation, and delegated authority. This OpenID\nFoundation whitepaper is for stakeholders at the intersection of AI agents and\naccess management. It outlines the resources already available for securing\ntoday's agents and presents a strategic agenda to address the foundational\nauthentication, authorization, and identity problems pivotal for tomorrow's\nwidespread autonomous systems.",
    "categories": [
      "cs.CR",
      "cs.AI",
      "cs.NI",
      "68M12",
      "D.4.6; K.6.5; I.2.11"
    ],
    "published": "2025-10-29T17:40:52Z",
    "authors": [
      "Tobin South",
      "Subramanya Nagabhushanaradhya",
      "Ayesha Dissanayaka",
      "Sarah Cecchetti",
      "George Fletcher",
      "Victor Lu",
      "Aldo Pietropaolo",
      "Dean H. Saxe",
      "Jeff Lombardo",
      "Abhishek Maligehalli Shivalingaiah",
      "Stan Bounev",
      "Alex Keisner",
      "Andor Kesselman",
      "Zack Proser",
      "Ginny Fahs",
      "Andrew Bunyea",
      "Ben Moskowitz",
      "Atul Tulshibagwale",
      "Dazza Greenwood",
      "Jiaxin Pei",
      "Alex Pentland"
    ],
    "pdf_url": "http://arxiv.org/pdf/2510.25819v1"
  },
  {
    "id": "2510.25732v1",
    "title": "The Limits of Obliviate: Evaluating Unlearning in LLMs via\n  Stimulus-Knowledge Entanglement-Behavior Framework",
    "abstract": "Unlearning in large language models (LLMs) is crucial for managing sensitive\ndata and correcting misinformation, yet evaluating its effectiveness remains an\nopen problem. We investigate whether persuasive prompting can recall factual\nknowledge from deliberately unlearned LLMs across models ranging from 2.7B to\n13B parameters (OPT-2.7B, LLaMA-2-7B, LLaMA-3.1-8B, LLaMA-2-13B). Drawing from\nACT-R and Hebbian theory (spreading activation theories), as well as\ncommunication principles, we introduce Stimulus-Knowledge Entanglement-Behavior\nFramework (SKeB), which models information entanglement via domain graphs and\ntests whether factual recall in unlearned models is correlated with persuasive\nframing. We develop entanglement metrics to quantify knowledge activation\npatterns and evaluate factuality, non-factuality, and hallucination in outputs.\nOur results show persuasive prompts substantially enhance factual knowledge\nrecall (14.8% baseline vs. 24.5% with authority framing), with effectiveness\ninversely correlated to model size (128% recovery in 2.7B vs. 15% in 13B). SKeB\nprovides a foundation for assessing unlearning completeness, robustness, and\noverall behavior in LLMs.",
    "categories": [
      "cs.CL",
      "cs.AI",
      "I.2.7; I.2.6; I.2.4; G.2.2"
    ],
    "published": "2025-10-29T17:37:50Z",
    "authors": [
      "Aakriti Shah",
      "Thai Le"
    ],
    "pdf_url": "http://arxiv.org/pdf/2510.25732v1"
  },
  {
    "id": "2510.25731v1",
    "title": "LieSolver: A PDE-constrained solver for IBVPs using Lie symmetries",
    "abstract": "We introduce a method for efficiently solving initial-boundary value problems\n(IBVPs) that uses Lie symmetries to enforce the associated partial differential\nequation (PDE) exactly by construction. By leveraging symmetry transformations,\nthe model inherently incorporates the physical laws and learns solutions from\ninitial and boundary data. As a result, the loss directly measures the model's\naccuracy, leading to improved convergence. Moreover, for well-posed IBVPs, our\nmethod enables rigorous error estimation. The approach yields compact models,\nfacilitating an efficient optimization. We implement LieSolver and demonstrate\nits application to linear homogeneous PDEs with a range of initial conditions,\nshowing that it is faster and more accurate than physics-informed neural\nnetworks (PINNs). Overall, our method improves both computational efficiency\nand the reliability of predictions for PDE-constrained problems.",
    "categories": [
      "cs.LG",
      "cs.AI",
      "cs.NA",
      "math.NA",
      "physics.comp-ph"
    ],
    "published": "2025-10-29T17:37:27Z",
    "authors": [
      "Ren\u00e9 P. Klausen",
      "Ivan Timofeev",
      "Johannes Frank",
      "Jonas Naujoks",
      "Thomas Wiegand",
      "Sebastian Lapuschkin",
      "Wojciech Samek"
    ],
    "pdf_url": "http://arxiv.org/pdf/2510.25731v1"
  },
  {
    "id": "2510.25729v1",
    "title": "Physics-Guided Conditional Diffusion Networks for Microwave Image\n  Reconstruction",
    "abstract": "A conditional latent-diffusion based framework for solving the\nelectromagnetic inverse scattering problem associated with microwave imaging is\nintroduced. This generative machine-learning model explicitly mirrors the\nnon-uniqueness of the ill-posed inverse problem. Unlike existing inverse\nsolvers utilizing deterministic machine learning techniques that produce a\nsingle reconstruction, the proposed latent-diffusion model generates multiple\nplausible permittivity maps conditioned on measured scattered-field data,\nthereby generating several potential instances in the range-space of the\nnon-unique inverse mapping. A forward electromagnetic solver is integrated into\nthe reconstruction pipeline as a physics-based evaluation mechanism. The space\nof candidate reconstructions form a distribution of possibilities consistent\nwith the conditioning data and the member of this space yielding the lowest\nscattered-field data discrepancy between the predicted and measured scattered\nfields is reported as the final solution. Synthetic and experimental labeled\ndatasets are used for training and evaluation of the model. An innovative\nlabeled synthetic dataset is created that exemplifies a varied set of\nscattering features. Training of the model using this new dataset produces high\nquality permittivity reconstructions achieving improved generalization with\nexcellent fidelity to shape recognition. The results highlight the potential of\nhybrid generative physics frameworks as a promising direction for robust,\ndata-driven microwave imaging.",
    "categories": [
      "eess.IV",
      "cs.AI",
      "cs.LG",
      "eess.SP"
    ],
    "published": "2025-10-29T17:34:10Z",
    "authors": [
      "Shirin Chehelgami",
      "Joe LoVetri",
      "Vahab Khoshdel"
    ],
    "pdf_url": "http://arxiv.org/pdf/2510.25729v1"
  },
  {
    "id": "2510.25726v1",
    "title": "The Tool Decathlon: Benchmarking Language Agents for Diverse, Realistic,\n  and Long-Horizon Task Execution",
    "abstract": "Real-world language agents must handle complex, multi-step workflows across\ndiverse Apps. For instance, an agent may manage emails by coordinating with\ncalendars and file systems, or monitor a production database to detect\nanomalies and generate reports following an operating manual. However, existing\nlanguage agent benchmarks often focus on narrow domains or simplified tasks\nthat lack the diversity, realism, and long-horizon complexity required to\nevaluate agents' real-world performance. To address this gap, we introduce the\nTool Decathlon (dubbed as Toolathlon), a benchmark for language agents offering\ndiverse Apps and tools, realistic environment setup, and reliable\nexecution-based evaluation. Toolathlon spans 32 software applications and 604\ntools, ranging from everyday platforms such as Google Calendar and Notion to\nprofessional ones like WooCommerce, Kubernetes, and BigQuery. Most of the tools\nare based on a high-quality set of Model Context Protocol (MCP) servers that we\nmay have revised or implemented ourselves. Unlike prior works, which primarily\nensure functional realism but offer limited environment state diversity, we\nprovide realistic initial environment states from real software, such as Canvas\ncourses with dozens of students or real financial spreadsheets. This benchmark\nincludes 108 manually sourced or crafted tasks in total, requiring interacting\nwith multiple Apps over around 20 turns on average to complete. Each task is\nstrictly verifiable through dedicated evaluation scripts. Comprehensive\nevaluation of SOTA models highlights their significant shortcomings: the\nbest-performing model, Claude-4.5-Sonnet, achieves only a 38.6% success rate\nwith 20.2 tool calling turns on average, while the top open-weights model\nDeepSeek-V3.2-Exp reaches 20.1%. We expect Toolathlon to drive the development\nof more capable language agents for real-world, long-horizon task execution.",
    "categories": [
      "cs.CL",
      "cs.AI"
    ],
    "published": "2025-10-29T17:32:49Z",
    "authors": [
      "Junlong Li",
      "Wenshuo Zhao",
      "Jian Zhao",
      "Weihao Zeng",
      "Haoze Wu",
      "Xiaochen Wang",
      "Rui Ge",
      "Yuxuan Cao",
      "Yuzhen Huang",
      "Wei Liu",
      "Junteng Liu",
      "Zhaochen Su",
      "Yiyang Guo",
      "Fan Zhou",
      "Lueyang Zhang",
      "Juan Michelini",
      "Xingyao Wang",
      "Xiang Yue",
      "Shuyan Zhou",
      "Graham Neubig",
      "Junxian He"
    ],
    "pdf_url": "http://arxiv.org/pdf/2510.25726v1"
  },
  {
    "id": "2510.25724v1",
    "title": "BambooKG: A Neurobiologically-inspired Frequency-Weight Knowledge Graph",
    "abstract": "Retrieval-Augmented Generation allows LLMs to access external knowledge,\nreducing hallucinations and ageing-data issues. However, it treats retrieved\nchunks independently and struggles with multi-hop or relational reasoning,\nespecially across documents. Knowledge graphs enhance this by capturing the\nrelationships between entities using triplets, enabling structured, multi-chunk\nreasoning. However, these tend to miss information that fails to conform to the\ntriplet structure. We introduce BambooKG, a knowledge graph with\nfrequency-based weights on non-triplet edges which reflect link strength,\ndrawing on the Hebbian principle of \"fire together, wire together\". This\ndecreases information loss and results in improved performance on single- and\nmulti-hop reasoning, outperforming the existing solutions.",
    "categories": [
      "cs.AI"
    ],
    "published": "2025-10-29T17:31:27Z",
    "authors": [
      "Vanya Arikutharam",
      "Arkadiy Ukolov"
    ],
    "pdf_url": "http://arxiv.org/pdf/2510.25724v1"
  },
  {
    "id": "2510.25818v1",
    "title": "ScaleDiff: Higher-Resolution Image Synthesis via Efficient and\n  Model-Agnostic Diffusion",
    "abstract": "Text-to-image diffusion models often exhibit degraded performance when\ngenerating images beyond their training resolution. Recent training-free\nmethods can mitigate this limitation, but they often require substantial\ncomputation or are incompatible with recent Diffusion Transformer models. In\nthis paper, we propose ScaleDiff, a model-agnostic and highly efficient\nframework for extending the resolution of pretrained diffusion models without\nany additional training. A core component of our framework is Neighborhood\nPatch Attention (NPA), an efficient mechanism that reduces computational\nredundancy in the self-attention layer with non-overlapping patches. We\nintegrate NPA into an SDEdit pipeline and introduce Latent Frequency Mixing\n(LFM) to better generate fine details. Furthermore, we apply Structure Guidance\nto enhance global structure during the denoising process. Experimental results\ndemonstrate that ScaleDiff achieves state-of-the-art performance among\ntraining-free methods in terms of both image quality and inference speed on\nboth U-Net and Diffusion Transformer architectures.",
    "categories": [
      "cs.LG",
      "cs.AI"
    ],
    "published": "2025-10-29T17:17:32Z",
    "authors": [
      "Sungho Koh",
      "SeungJu Cha",
      "Hyunwoo Oh",
      "Kwanyoung Lee",
      "Dong-Jin Kim"
    ],
    "pdf_url": "http://arxiv.org/pdf/2510.25818v1"
  },
  {
    "id": "2510.25694v1",
    "title": "Process-Level Trajectory Evaluation for Environment Configuration in\n  Software Engineering Agents",
    "abstract": "Large language model-based agents show promise for software engineering, but\nenvironment configuration remains a bottleneck due to heavy manual effort and\nscarce large-scale, high-quality datasets. Existing benchmarks assess only\nend-to-end build/test success, obscuring where and why agents succeed or fail.\nWe introduce the Environment Configuration Diagnosis Benchmark, Enconda-bench,\nwhich provides process-level trajectory assessment of fine-grained agent\ncapabilities during environment setup-planning, perception-driven error\ndiagnosis, feedback-driven repair, and action to execute final environment\nconfiguration. Our task instances are automatically constructed by injecting\nrealistic README errors and are validated in Docker for scalable, high-quality\nevaluation. Enconda-bench combines process-level analysis with end-to-end\nexecutability to enable capability assessments beyond aggregate success rates.\nEvaluations across state-of-the-art LLMs and agent frameworks show that while\nagents can localize errors, they struggle to translate feedback into effective\ncorrections, limiting end-to-end performance. To our knowledge, Enconda-bench\nis the first framework to provide process-level internal capability assessment\nfor environment configuration, offering actionable insights for improving\nsoftware engineering agents.",
    "categories": [
      "cs.SE",
      "cs.AI",
      "cs.CL"
    ],
    "published": "2025-10-29T16:59:07Z",
    "authors": [
      "Jiayi Kuang",
      "Yinghui Li",
      "Xin Zhang",
      "Yangning Li",
      "Di Yin",
      "Xing Sun",
      "Ying Shen",
      "Philip S. Yu"
    ],
    "pdf_url": "http://arxiv.org/pdf/2510.25694v1"
  },
  {
    "id": "2510.25683v1",
    "title": "Graph Network-based Structural Simulator: Graph Neural Networks for\n  Structural Dynamics",
    "abstract": "Graph Neural Networks (GNNs) have recently been explored as surrogate models\nfor numerical simulations. While their applications in computational fluid\ndynamics have been investigated, little attention has been given to structural\nproblems, especially for dynamic cases. To address this gap, we introduce the\nGraph Network-based Structural Simulator (GNSS), a GNN framework for surrogate\nmodeling of dynamic structural problems.\n  GNSS follows the encode-process-decode paradigm typical of GNN-based machine\nlearning models, and its design makes it particularly suited for dynamic\nsimulations thanks to three key features: (i) expressing node kinematics in\nnode-fixed local frames, which avoids catastrophic cancellation in\nfinite-difference velocities; (ii) employing a sign-aware regression loss,\nwhich reduces phase errors in long rollouts; and (iii) using a\nwavelength-informed connectivity radius, which optimizes graph construction.\n  We evaluate GNSS on a case study involving a beam excited by a 50kHz\nHanning-modulated pulse. The results show that GNSS accurately reproduces the\nphysics of the problem over hundreds of timesteps and generalizes to unseen\nloading conditions, where existing GNNs fail to converge or deliver meaningful\npredictions.\n  Compared with explicit finite element baselines, GNSS achieves substantial\ninference speedups while preserving spatial and temporal fidelity. These\nfindings demonstrate that locality-preserving GNNs with physics-consistent\nupdate rules are a competitive alternative for dynamic, wave-dominated\nstructural simulations.",
    "categories": [
      "cs.LG",
      "cs.AI",
      "cs.CE",
      "physics.comp-ph"
    ],
    "published": "2025-10-29T16:47:24Z",
    "authors": [
      "Alessandro Lucchetti",
      "Francesco Cadini",
      "Marco Giglio",
      "Luca Lomazzi"
    ],
    "pdf_url": "http://arxiv.org/pdf/2510.25683v1"
  },
  {
    "id": "2510.25679v1",
    "title": "Navigation in a Three-Dimensional Urban Flow using Deep Reinforcement\n  Learning",
    "abstract": "Unmanned Aerial Vehicles (UAVs) are increasingly populating urban areas for\ndelivery and surveillance purposes. In this work, we develop an optimal\nnavigation strategy based on Deep Reinforcement Learning. The environment is\nrepresented by a three-dimensional high-fidelity simulation of an urban flow,\ncharacterized by turbulence and recirculation zones. The algorithm presented\nhere is a flow-aware Proximal Policy Optimization (PPO) combined with a Gated\nTransformer eXtra Large (GTrXL) architecture, giving the agent richer\ninformation about the turbulent flow field in which it navigates. The results\nare compared with a PPO+GTrXL without the secondary prediction tasks, a PPO\ncombined with Long Short Term Memory (LSTM) cells and a traditional navigation\nalgorithm. The obtained results show a significant increase in the success rate\n(SR) and a lower crash rate (CR) compared to a PPO+LSTM, PPO+GTrXL and the\nclassical Zermelo's navigation algorithm, paving the way to a completely\nreimagined UAV landscape in complex urban environments.",
    "categories": [
      "cs.AI",
      "physics.flu-dyn"
    ],
    "published": "2025-10-29T16:46:00Z",
    "authors": [
      "Federica Tonti",
      "Ricardo Vinuesa"
    ],
    "pdf_url": "http://arxiv.org/pdf/2510.25679v1"
  },
  {
    "id": "2510.25668v1",
    "title": "ALDEN: Reinforcement Learning for Active Navigation and Evidence\n  Gathering in Long Documents",
    "abstract": "Vision-language models (VLMs) excel at interpreting text-rich images but\nstruggle with long, visually complex documents that demand analysis and\nintegration of information spread across multiple pages. Existing approaches\ntypically rely on fixed reasoning templates or rigid pipelines, which force\nVLMs into a passive role and hinder both efficiency and generalization. We\npresent Active Long-DocumEnt Navigation (ALDEN), a multi-turn reinforcement\nlearning framework that fine-tunes VLMs as interactive agents capable of\nactively navigating long, visually rich documents. ALDEN introduces a novel\nfetch action that directly accesses the page by index, complementing the\nclassic search action and better exploiting document structure. For dense\nprocess supervision and efficient training, we propose a rule-based cross-level\nreward that provides both turn- and token-level signals. To address the\nempirically observed training instability caused by numerous visual tokens from\nlong documents, we further propose a visual-semantic anchoring mechanism that\napplies a dual-path KL-divergence constraint to stabilize visual and textual\nrepresentations separately during training. Trained on a corpus constructed\nfrom three open-source datasets, ALDEN achieves state-of-the-art performance on\nfive long-document benchmarks. Overall, ALDEN marks a step beyond passive\ndocument reading toward agents that autonomously navigate and reason across\nlong, visually rich documents, offering a robust path to more accurate and\nefficient long-document understanding.",
    "categories": [
      "cs.AI",
      "cs.MM"
    ],
    "published": "2025-10-29T16:32:26Z",
    "authors": [
      "Tianyu Yang",
      "Terry Ruas",
      "Yijun Tian",
      "Jan Philip Wahle",
      "Daniel Kurzawe",
      "Bela Gipp"
    ],
    "pdf_url": "http://arxiv.org/pdf/2510.25668v1"
  },
  {
    "id": "2510.25662v1",
    "title": "User Misconceptions of LLM-Based Conversational Programming Assistants",
    "abstract": "Programming assistants powered by large language models (LLMs) have become\nwidely available, with conversational assistants like ChatGPT proving\nparticularly accessible to less experienced programmers. However, the varied\ncapabilities of these tools across model versions and the mixed availability of\nextensions that enable web search, code execution, or retrieval-augmented\ngeneration create opportunities for user misconceptions about what systems can\nand cannot do. Such misconceptions may lead to over-reliance, unproductive\npractices, or insufficient quality control in LLM-assisted programming. Here,\nwe aim to characterize misconceptions that users of conversational LLM-based\nassistants may have in programming contexts. Using a two-phase approach, we\nfirst brainstorm and catalog user misconceptions that may occur, and then\nconduct a qualitative analysis to examine whether these conceptual issues\nsurface in naturalistic Python-programming conversations with an LLM-based\nchatbot drawn from an openly available dataset. Indeed, we see evidence that\nsome users have misplaced expectations about the availability of LLM-based\nchatbot features like web access, code execution, or non-text output\ngeneration. We also see potential evidence for deeper conceptual issues around\nthe scope of information required to debug, validate, and optimize programs.\nOur findings reinforce the need for designing LLM-based tools that more clearly\ncommunicate their programming capabilities to users.",
    "categories": [
      "cs.HC",
      "cs.AI"
    ],
    "published": "2025-10-29T16:23:46Z",
    "authors": [
      "Gabrielle O'Brien",
      "Antonio Pedro Santos Alves",
      "Sebastian Baltes",
      "Grischa Liebel",
      "Mircea Lungu",
      "Marcos Kalinowski"
    ],
    "pdf_url": "http://arxiv.org/pdf/2510.25662v1"
  },
  {
    "id": "2510.25657v1",
    "title": "Subgraph Federated Learning via Spectral Methods",
    "abstract": "We consider the problem of federated learning (FL) with graph-structured data\ndistributed across multiple clients. In particular, we address the prevalent\nscenario of interconnected subgraphs, where interconnections between clients\nsignificantly influence the learning process. Existing approaches suffer from\ncritical limitations, either requiring the exchange of sensitive node\nembeddings, thereby posing privacy risks, or relying on\ncomputationally-intensive steps, which hinders scalability. To tackle these\nchallenges, we propose FedLap, a novel framework that leverages global\nstructure information via Laplacian smoothing in the spectral domain to\neffectively capture inter-node dependencies while ensuring privacy and\nscalability. We provide a formal analysis of the privacy of FedLap,\ndemonstrating that it preserves privacy. Notably, FedLap is the first subgraph\nFL scheme with strong privacy guarantees. Extensive experiments on benchmark\ndatasets demonstrate that FedLap achieves competitive or superior utility\ncompared to existing techniques.",
    "categories": [
      "cs.LG",
      "cs.AI",
      "cs.IT",
      "math.IT"
    ],
    "published": "2025-10-29T16:22:32Z",
    "authors": [
      "Javad Aliakbari",
      "Johan \u00d6stman",
      "Ashkan Panahi",
      "Alexandre Graell i Amat"
    ],
    "pdf_url": "http://arxiv.org/pdf/2510.25657v1"
  },
  {
    "id": "2510.25634v1",
    "title": "Learning to Plan & Schedule with Reinforcement-Learned Bimanual Robot\n  Skills",
    "abstract": "Long-horizon contact-rich bimanual manipulation presents a significant\nchallenge, requiring complex coordination involving a mixture of parallel\nexecution and sequential collaboration between arms. In this paper, we\nintroduce a hierarchical framework that frames this challenge as an integrated\nskill planning & scheduling problem, going beyond purely sequential\ndecision-making to support simultaneous skill invocation. Our approach is built\nupon a library of single-arm and bimanual primitive skills, each trained using\nReinforcement Learning (RL) in GPU-accelerated simulation. We then train a\nTransformer-based planner on a dataset of skill compositions to act as a\nhigh-level scheduler, simultaneously predicting the discrete schedule of skills\nas well as their continuous parameters. We demonstrate that our method achieves\nhigher success rates on complex, contact-rich tasks than end-to-end RL\napproaches and produces more efficient, coordinated behaviors than traditional\nsequential-only planners.",
    "categories": [
      "cs.RO",
      "cs.AI"
    ],
    "published": "2025-10-29T15:39:53Z",
    "authors": [
      "Weikang Wan",
      "Fabio Ramos",
      "Xuning Yang",
      "Caelan Garrett"
    ],
    "pdf_url": "http://arxiv.org/pdf/2510.25634v1"
  },
  {
    "id": "2510.25626v1",
    "title": "Are Language Models Efficient Reasoners? A Perspective from Logic\n  Programming",
    "abstract": "Modern language models (LMs) exhibit strong deductive reasoning capabilities,\nyet standard evaluations emphasize correctness while overlooking a key aspect\nof human-like reasoning: efficiency. In real-world reasoning scenarios, much of\nthe available information is irrelevant, and effective deductive inference\nrequires identifying and ignoring such distractions. We propose a framework for\nassessing LM reasoning efficiency through the lens of logic programming,\nintroducing a simple method to align proofs written in natural language -- as\ngenerated by an LM -- with shortest proofs found by executing the logic\nprogram. Efficiency is quantified by measuring how well a model avoids\nunnecessary inference. Empirically, we construct a dataset of math word\nproblems injected with various number of irrelevant axioms that vary in\nsemantic overlap with the goal theorem. We find that current LMs show marked\naccuracy declines under such conditions -- even with minimal, domain-consistent\ndistractions -- and the proofs they generate frequently exhibit detours through\nirrelevant inferences.",
    "categories": [
      "cs.CL",
      "cs.AI",
      "cs.LG",
      "cs.LO"
    ],
    "published": "2025-10-29T15:30:31Z",
    "authors": [
      "Andreas Opedal",
      "Yanick Zengaffinen",
      "Haruki Shirakami",
      "Clemente Pasti",
      "Mrinmaya Sachan",
      "Abulhair Saparov",
      "Ryan Cotterell",
      "Bernhard Sch\u00f6lkopf"
    ],
    "pdf_url": "http://arxiv.org/pdf/2510.25626v1"
  },
  {
    "id": "2510.25621v1",
    "title": "FARSIQA: Faithful and Advanced RAG System for Islamic Question Answering",
    "abstract": "The advent of Large Language Models (LLMs) has revolutionized Natural\nLanguage Processing, yet their application in high-stakes, specialized domains\nlike religious question answering is hindered by challenges like hallucination\nand unfaithfulness to authoritative sources. This issue is particularly\ncritical for the Persian-speaking Muslim community, where accuracy and\ntrustworthiness are paramount. Existing Retrieval-Augmented Generation (RAG)\nsystems, relying on simplistic single-pass pipelines, fall short on complex,\nmulti-hop queries requiring multi-step reasoning and evidence aggregation. To\naddress this gap, we introduce FARSIQA, a novel, end-to-end system for Faithful\nAdvanced Question Answering in the Persian Islamic domain. FARSIQA is built\nupon our innovative FAIR-RAG architecture: a Faithful, Adaptive, Iterative\nRefinement framework for RAG. FAIR-RAG employs a dynamic, self-correcting\nprocess: it adaptively decomposes complex queries, assesses evidence\nsufficiency, and enters an iterative loop to generate sub-queries,\nprogressively filling information gaps. Operating on a curated knowledge base\nof over one million authoritative Islamic documents, FARSIQA demonstrates\nsuperior performance. Rigorous evaluation on the challenging IslamicPCQA\nbenchmark shows state-of-the-art performance: the system achieves a remarkable\n97.0% in Negative Rejection - a 40-point improvement over baselines - and a\nhigh Answer Correctness score of 74.3%. Our work establishes a new standard for\nPersian Islamic QA and validates that our iterative, adaptive architecture is\ncrucial for building faithful, reliable AI systems in sensitive domains.",
    "categories": [
      "cs.CL",
      "cs.AI",
      "cs.IR",
      "68T50, 68T05, 68T30",
      "I.2.7; H.3.3"
    ],
    "published": "2025-10-29T15:25:34Z",
    "authors": [
      "Mohammad Aghajani Asl",
      "Behrooz Minaei Bidgoli"
    ],
    "pdf_url": "http://arxiv.org/pdf/2510.25621v1"
  },
  {
    "id": "2510.25616v1",
    "title": "Don't Blind Your VLA: Aligning Visual Representations for OOD\n  Generalization",
    "abstract": "The growing success of Vision-Language-Action (VLA) models stems from the\npromise that pretrained Vision-Language Models (VLMs) can endow agents with\ntransferable world knowledge and vision-language (VL) grounding, laying a\nfoundation for action models with broader generalization. Yet when these VLMs\nare adapted to the action modality, it remains unclear to what extent their\noriginal VL representations and knowledge are preserved. In this work, we\nconduct a systematic study of representation retention during VLA fine-tuning,\nshowing that naive action fine-tuning leads to degradation of visual\nrepresentations. To characterize and measure these effects, we probe VLA's\nhidden representations and analyze attention maps, further, we design a set of\ntargeted tasks and methods that contrast VLA models with their counterpart\nVLMs, isolating changes in VL capabilities induced by action fine-tuning. We\nfurther evaluate a range of strategies for aligning visual representations and\nintroduce a simple yet effective method that mitigates degradation and yields\nimproved generalization to out-of-distribution (OOD) scenarios. Taken together,\nour analysis clarifies the trade-off between action fine-tuning and the\ndegradation of VL representations and highlights practical approaches to\nrecover inherited VL capabilities. Code is publicly available:\nhttps://blind-vla-paper.github.io",
    "categories": [
      "cs.LG",
      "cs.AI",
      "cs.RO"
    ],
    "published": "2025-10-29T15:20:10Z",
    "authors": [
      "Nikita Kachaev",
      "Mikhail Kolosov",
      "Daniil Zelezetsky",
      "Alexey K. Kovalev",
      "Aleksandr I. Panov"
    ],
    "pdf_url": "http://arxiv.org/pdf/2510.25616v1"
  },
  {
    "id": "2510.25612v1",
    "title": "Counterfactual-based Agent Influence Ranker for Agentic AI Workflows",
    "abstract": "An Agentic AI Workflow (AAW), also known as an LLM-based multi-agent system,\nis an autonomous system that assembles several LLM-based agents to work\ncollaboratively towards a shared goal. The high autonomy, widespread adoption,\nand growing interest in such AAWs highlight the need for a deeper understanding\nof their operations, from both quality and security aspects. To this day, there\nare no existing methods to assess the influence of each agent on the AAW's\nfinal output. Adopting techniques from related fields is not feasible since\nexisting methods perform only static structural analysis, which is unsuitable\nfor inference time execution. We present Counterfactual-based Agent Influence\nRanker (CAIR) - the first method for assessing the influence level of each\nagent on the AAW's output and determining which agents are the most\ninfluential. By performing counterfactual analysis, CAIR provides a\ntask-agnostic analysis that can be used both offline and at inference time. We\nevaluate CAIR using an AAWs dataset of our creation, containing 30 different\nuse cases with 230 different functionalities. Our evaluation showed that CAIR\nproduces consistent rankings, outperforms baseline methods, and can easily\nenhance the effectiveness and relevancy of downstream tasks.",
    "categories": [
      "cs.AI",
      "cs.MA"
    ],
    "published": "2025-10-29T15:17:31Z",
    "authors": [
      "Amit Giloni",
      "Chiara Picardi",
      "Roy Betser",
      "Shamik Bose",
      "Aishvariya Priya Rathina Sabapathy",
      "Roman Vainshtein"
    ],
    "pdf_url": "http://arxiv.org/pdf/2510.25612v1"
  },
  {
    "id": "2510.25609v1",
    "title": "BOLT-GAN: Bayes-Optimal Loss for Stable GAN Training",
    "abstract": "We introduce BOLT-GAN, a simple yet effective modification of the WGAN\nframework inspired by the Bayes Optimal Learning Threshold (BOLT). We show that\nwith a Lipschitz continuous discriminator, BOLT-GAN implicitly minimizes a\ndifferent metric distance than the Earth Mover (Wasserstein) distance and\nachieves better training stability. Empirical evaluations on four standard\nimage generation benchmarks (CIFAR-10, CelebA-64, LSUN Bedroom-64, and LSUN\nChurch-64) show that BOLT-GAN consistently outperforms WGAN, achieving 10-60%\nlower Frechet Inception Distance (FID). Our results suggest that BOLT is a\nbroadly applicable principle for enhancing GAN training.",
    "categories": [
      "cs.LG",
      "cs.AI",
      "eess.SP",
      "68T07",
      "I.2.6; I.5.1"
    ],
    "published": "2025-10-29T15:16:50Z",
    "authors": [
      "Mohammadreza Tavasoli Naeini",
      "Ali Bereyhi",
      "Morteza Noshad",
      "Ben Liang",
      "Alfred O. Hero III"
    ],
    "pdf_url": "http://arxiv.org/pdf/2510.25609v1"
  },
  {
    "id": "2510.25602v1",
    "title": "INT v.s. FP: A Comprehensive Study of Fine-Grained Low-bit Quantization\n  Formats",
    "abstract": "Modern AI hardware, such as Nvidia's Blackwell architecture, is increasingly\nembracing low-precision floating-point (FP) formats to handle the pervasive\nactivation outliers in Large Language Models (LLMs). Despite this industry\ntrend, a unified comparison of FP and integer (INT) quantization across varying\ngranularities has been missing, leaving algorithm and hardware co-design\nwithout clear guidance. This paper fills that gap by systematically\ninvestigating the trade-offs between FP and INT formats. We reveal a critical\nperformance crossover: while FP excels in coarse-grained quantization, the\ncomparison at fine-grained (block-wise) levels is more nuanced. Our\ncomprehensive comparison demonstrates that for popular 8-bit fine-grained\nformats (e.g., MX with block size 32), MXINT8 is superior to its FP counterpart\nin both algorithmic accuracy and hardware efficiency. However, for 4-bit\nformats, FP (e.g., MXFP4, NVFP4) often holds an accuracy advantage , though we\nshow that NVINT4 can surpass NVFP4 when outlier-mitigation techniques like\nHadamard rotation are applied. We also introduce a symmetric clipping method\nthat resolves gradient bias in fine-grained low-bit INT training, enabling\nnearly lossless performance for MXINT8 training. These findings challenge the\ncurrent hardware trajectory, demonstrating that a one-size-fits-all FP approach\nis suboptimal and advocating that fine-grained INT formats, particularly\nMXINT8, offer a better balance of accuracy, power, and efficiency for future AI\naccelerators.",
    "categories": [
      "cs.LG",
      "cs.AI"
    ],
    "published": "2025-10-29T15:11:53Z",
    "authors": [
      "Mengzhao Chen",
      "Meng Wu",
      "Hui Jin",
      "Zhihang Yuan",
      "Jing Liu",
      "Chaoyi Zhang",
      "Yunshui Li",
      "Jie Huang",
      "Jin Ma",
      "Zeyue Xue",
      "Zhiheng Liu",
      "Xingyan Bin",
      "Ping Luo"
    ],
    "pdf_url": "http://arxiv.org/pdf/2510.25602v1"
  },
  {
    "id": "2510.25595v1",
    "title": "Communication and Verification in LLM Agents towards Collaboration under\n  Information Asymmetry",
    "abstract": "While Large Language Model (LLM) agents are often approached from the angle\nof action planning/generation to accomplish a goal (e.g., given by language\ndescriptions), their abilities to collaborate with each other to achieve a\njoint goal are not well explored. To address this limitation, this paper\nstudies LLM agents in task collaboration, particularly under the condition of\ninformation asymmetry, where agents have disparities in their knowledge and\nskills and need to work together to complete a shared task. We extend Einstein\nPuzzles, a classical symbolic puzzle, to a table-top game. In this game, two\nLLM agents must reason, communicate, and act to satisfy spatial and relational\nconstraints required to solve the puzzle. We apply a fine-tuning-plus-verifier\nframework in which LLM agents are equipped with various communication\nstrategies and verification signals from the environment. Empirical results\nhighlight the critical importance of aligned communication, especially when\nagents possess both information-seeking and -providing capabilities.\nInterestingly, agents without communication can still achieve high task\nperformance; however, further analysis reveals a lack of true rule\nunderstanding and lower trust from human evaluators. Instead, by integrating an\nenvironment-based verifier, we enhance agents' ability to comprehend task rules\nand complete tasks, promoting both safer and more interpretable collaboration\nin AI systems. https://github.com/Roihn/EinsteinPuzzles",
    "categories": [
      "cs.CL",
      "cs.AI"
    ],
    "published": "2025-10-29T15:03:53Z",
    "authors": [
      "Run Peng",
      "Ziqiao Ma",
      "Amy Pang",
      "Sikai Li",
      "Zhang Xi-Jia",
      "Yingzhuo Yu",
      "Cristian-Paul Bara",
      "Joyce Chai"
    ],
    "pdf_url": "http://arxiv.org/pdf/2510.25595v1"
  },
  {
    "id": "2510.25590v1",
    "title": "RegionE: Adaptive Region-Aware Generation for Efficient Image Editing",
    "abstract": "Recently, instruction-based image editing (IIE) has received widespread\nattention. In practice, IIE often modifies only specific regions of an image,\nwhile the remaining areas largely remain unchanged. Although these two types of\nregions differ significantly in generation difficulty and computational\nredundancy, existing IIE models do not account for this distinction, instead\napplying a uniform generation process across the entire image. This motivates\nus to propose RegionE, an adaptive, region-aware generation framework that\naccelerates IIE tasks without additional training. Specifically, the RegionE\nframework consists of three main components: 1) Adaptive Region Partition. We\nobserved that the trajectory of unedited regions is straight, allowing for\nmulti-step denoised predictions to be inferred in a single step. Therefore, in\nthe early denoising stages, we partition the image into edited and unedited\nregions based on the difference between the final estimated result and the\nreference image. 2) Region-Aware Generation. After distinguishing the regions,\nwe replace multi-step denoising with one-step prediction for unedited areas.\nFor edited regions, the trajectory is curved, requiring local iterative\ndenoising. To improve the efficiency and quality of local iterative generation,\nwe propose the Region-Instruction KV Cache, which reduces computational cost\nwhile incorporating global information. 3) Adaptive Velocity Decay Cache.\nObserving that adjacent timesteps in edited regions exhibit strong velocity\nsimilarity, we further propose an adaptive velocity decay cache to accelerate\nthe local denoising process. We applied RegionE to state-of-the-art IIE base\nmodels, including Step1X-Edit, FLUX.1 Kontext, and Qwen-Image-Edit. RegionE\nachieved acceleration factors of 2.57, 2.41, and 2.06. Evaluations by GPT-4o\nconfirmed that semantic and perceptual fidelity were well preserved.",
    "categories": [
      "cs.CV",
      "cs.AI"
    ],
    "published": "2025-10-29T14:58:37Z",
    "authors": [
      "Pengtao Chen",
      "Xianfang Zeng",
      "Maosen Zhao",
      "Mingzhu Shen",
      "Peng Ye",
      "Bangyin Xiang",
      "Zhibo Wang",
      "Wei Cheng",
      "Gang Yu",
      "Tao Chen"
    ],
    "pdf_url": "http://arxiv.org/pdf/2510.25590v1"
  },
  {
    "id": "2510.25588v1",
    "title": "Standardization of Psychiatric Diagnoses -- Role of Fine-tuned LLM\n  Consortium and OpenAI-gpt-oss Reasoning LLM Enabled Decision Support System",
    "abstract": "The diagnosis of most mental disorders, including psychiatric evaluations,\nprimarily depends on dialogues between psychiatrists and patients. This\nsubjective process can lead to variability in diagnoses across clinicians and\npatients, resulting in inconsistencies and challenges in achieving reliable\noutcomes. To address these issues and standardize psychiatric diagnoses, we\npropose a Fine-Tuned Large Language Model (LLM) Consortium and OpenAI-gpt-oss\nReasoning LLM-enabled Decision Support System for the clinical diagnosis of\nmental disorders. Our approach leverages fine-tuned LLMs trained on\nconversational datasets involving psychiatrist-patient interactions focused on\nmental health conditions (e.g., depression). The diagnostic predictions from\nindividual models are aggregated through a consensus-based decision-making\nprocess, refined by the OpenAI-gpt-oss reasoning LLM. We propose a novel method\nfor deploying LLM agents that orchestrate communication between the LLM\nconsortium and the reasoning LLM, ensuring transparency, reliability, and\nresponsible AI across the entire diagnostic workflow. Experimental results\ndemonstrate the transformative potential of combining fine-tuned LLMs with a\nreasoning model to create a robust and highly accurate diagnostic system for\nmental health assessment. A prototype of the proposed platform, integrating\nthree fine-tuned LLMs with the OpenAI-gpt-oss reasoning LLM, was developed in\ncollaboration with the U.S. Army Medical Research Team in Norfolk, Virginia,\nUSA. To the best of our knowledge, this work represents the first application\nof a fine-tuned LLM consortium integrated with a reasoning LLM for clinical\nmental health diagnosis paving the way for next-generation AI-powered eHealth\nsystems aimed at standardizing psychiatric diagnoses.",
    "categories": [
      "cs.AI"
    ],
    "published": "2025-10-29T14:54:22Z",
    "authors": [
      "Eranga Bandara",
      "Ross Gore",
      "Atmaram Yarlagadda",
      "Anita H. Clayton",
      "Preston Samuel",
      "Christopher K. Rhea",
      "Sachin Shetty"
    ],
    "pdf_url": "http://arxiv.org/pdf/2510.25588v1"
  },
  {
    "id": "2510.25577v1",
    "title": "Lost in Phonation: Voice Quality Variation as an Evaluation Dimension\n  for Speech Foundation Models",
    "abstract": "Recent advances in speech foundation models (SFMs) have enabled the direct\nprocessing of spoken language from raw audio, bypassing intermediate textual\nrepresentations. This capability allows SFMs to be exposed to, and potentially\nrespond to, rich paralinguistic variations embedded in the input speech signal.\nOne under-explored dimension of paralinguistic variation is voice quality,\nencompassing phonation types such as creaky and breathy voice. These phonation\ntypes are known to influence how listeners infer affective state, stance and\nsocial meaning in speech. Existing benchmarks for speech understanding largely\nrely on multiple-choice question answering (MCQA) formats, which are prone to\nfailure and therefore unreliable in capturing the nuanced ways paralinguistic\nfeatures influence model behaviour. In this paper, we probe SFMs through\nopen-ended generation tasks and speech emotion recognition, evaluating whether\nmodel behaviours are consistent across different phonation inputs. We introduce\na new parallel dataset featuring synthesized modifications to voice quality,\ndesigned to evaluate SFM responses to creaky and breathy voice. Our work\nprovides the first examination of SFM sensitivity to these particular\nnon-lexical aspects of speech perception.",
    "categories": [
      "eess.AS",
      "cs.AI",
      "cs.CL"
    ],
    "published": "2025-10-29T14:44:44Z",
    "authors": [
      "Harm Lameris",
      "Shree Harsha Bokkahalli Satish",
      "Joakim Gustafson",
      "\u00c9va Sz\u00e9kely"
    ],
    "pdf_url": "http://arxiv.org/pdf/2510.25577v1"
  },
  {
    "id": "2510.25813v1",
    "title": "An Agentic Framework for Rapid Deployment of Edge AI Solutions in\n  Industry 5.0",
    "abstract": "We present a novel framework for Industry 5.0 that simplifies the deployment\nof AI models on edge devices in various industrial settings. The design reduces\nlatency and avoids external data transfer by enabling local inference and\nreal-time processing. Our implementation is agent-based, which means that\nindividual agents, whether human, algorithmic, or collaborative, are\nresponsible for well-defined tasks, enabling flexibility and simplifying\nintegration. Moreover, our framework supports modular integration and maintains\nlow resource requirements. Preliminary evaluations concerning the food industry\nin real scenarios indicate improved deployment time and system adaptability\nperformance. The source code is publicly available at\nhttps://github.com/AI-REDGIO-5-0/ci-component.",
    "categories": [
      "cs.AI"
    ],
    "published": "2025-10-29T14:35:02Z",
    "authors": [
      "Jorge Martinez-Gil",
      "Mario Pichler",
      "Nefeli Bountouni",
      "Sotiris Koussouris",
      "Marielena M\u00e1rquez Barreiro",
      "Sergio Gusmeroli"
    ],
    "pdf_url": "http://arxiv.org/pdf/2510.25813v1"
  },
  {
    "id": "2510.25563v1",
    "title": "Leveraging an Atmospheric Foundational Model for Subregional Sea Surface\n  Temperature Forecasting",
    "abstract": "The accurate prediction of oceanographic variables is crucial for\nunderstanding climate change, managing marine resources, and optimizing\nmaritime activities. Traditional ocean forecasting relies on numerical models;\nhowever, these approaches face limitations in terms of computational cost and\nscalability. In this study, we adapt Aurora, a foundational deep learning model\noriginally designed for atmospheric forecasting, to predict sea surface\ntemperature (SST) in the Canary Upwelling System. By fine-tuning this model\nwith high-resolution oceanographic reanalysis data, we demonstrate its ability\nto capture complex spatiotemporal patterns while reducing computational\ndemands. Our methodology involves a staged fine-tuning process, incorporating\nlatitude-weighted error metrics and optimizing hyperparameters for efficient\nlearning. The experimental results show that the model achieves a low RMSE of\n0.119K, maintaining high anomaly correlation coefficients (ACC $\\approx\n0.997$). The model successfully reproduces large-scale SST structures but faces\nchallenges in capturing finer details in coastal regions. This work contributes\nto the field of data-driven ocean forecasting by demonstrating the feasibility\nof using deep learning models pre-trained in different domains for oceanic\napplications. Future improvements include integrating additional oceanographic\nvariables, increasing spatial resolution, and exploring physics-informed neural\nnetworks to enhance interpretability and understanding. These advancements can\nimprove climate modeling and ocean prediction accuracy, supporting\ndecision-making in environmental and economic sectors.",
    "categories": [
      "cs.LG",
      "cs.AI",
      "physics.ao-ph"
    ],
    "published": "2025-10-29T14:30:12Z",
    "authors": [
      "V\u00edctor Medina",
      "Giovanny A. Cuervo-Londo\u00f1o",
      "Javier S\u00e1nchez"
    ],
    "pdf_url": "http://arxiv.org/pdf/2510.25563v1"
  },
  {
    "id": "2510.25557v1",
    "title": "Hybrid Quantum-Classical Recurrent Neural Networks",
    "abstract": "We present a hybrid quantum-classical recurrent neural network (QRNN)\narchitecture in which the entire recurrent core is realized as a parametrized\nquantum circuit (PQC) controlled by a classical feedforward network. The hidden\nstate is the quantum state of an $n$-qubit PQC, residing in an exponentially\nlarge Hilbert space $\\mathbb{C}^{2^n}$. The PQC is unitary by construction,\nmaking the hidden-state evolution norm-preserving without external constraints.\nAt each timestep, mid-circuit readouts are combined with the input embedding\nand processed by the feedforward network, which provides explicit classical\nnonlinearity. The outputs parametrize the PQC, which updates the hidden state\nvia unitary dynamics. The QRNN is compact and physically consistent, and it\nunifies (i) unitary recurrence as a high-capacity memory, (ii) partial\nobservation via mid-circuit measurements, and (iii) nonlinear classical control\nfor input-conditioned parametrization. We evaluate the model in simulation with\nup to 14 qubits on sentiment analysis, MNIST, permuted MNIST, copying memory,\nand language modeling, adopting projective measurements as a limiting case to\nobtain mid-circuit readouts while maintaining a coherent recurrent quantum\nmemory. We further devise a soft attention mechanism over the mid-circuit\nreadouts in a sequence-to-sequence model and show its effectiveness for machine\ntranslation. To our knowledge, this is the first model (RNN or otherwise)\ngrounded in quantum operations to achieve competitive performance against\nstrong classical baselines across a broad class of sequence-learning tasks.",
    "categories": [
      "cs.LG",
      "cs.AI",
      "cs.CL",
      "quant-ph"
    ],
    "published": "2025-10-29T14:21:49Z",
    "authors": [
      "Wenduan Xu"
    ],
    "pdf_url": "http://arxiv.org/pdf/2510.25557v1"
  },
  {
    "id": "2510.25531v1",
    "title": "Using latent representations to link disjoint longitudinal data for\n  mixed-effects regression",
    "abstract": "Many rare diseases offer limited established treatment options, leading\npatients to switch therapies when new medications emerge. To analyze the impact\nof such treatment switches within the low sample size limitations of rare\ndisease trials, it is important to use all available data sources. This,\nhowever, is complicated when usage of measurement instruments change during the\nobservation period, for example when instruments are adapted to specific age\nranges. The resulting disjoint longitudinal data trajectories, complicate the\napplication of traditional modeling approaches like mixed-effects regression.\nWe tackle this by mapping observations of each instrument to a aligned\nlow-dimensional temporal trajectory, enabling longitudinal modeling across\ninstruments. Specifically, we employ a set of variational autoencoder\narchitectures to embed item values into a shared latent space for each time\npoint. Temporal disease dynamics and treatment switch effects are then captured\nthrough a mixed-effects regression model applied to latent representations. To\nenable statistical inference, we present a novel statistical testing approach\nthat accounts for the joint parameter estimation of mixed-effects regression\nand variational autoencoders. The methodology is applied to quantify the impact\nof treatment switches for patients with spinal muscular atrophy. Here, our\napproach aligns motor performance items from different measurement instruments\nfor mixed-effects regression and maps estimated effects back to the observed\nitem level to quantify the treatment switch effect. Our approach allows for\nmodel selection as well as for assessing effects of treatment switching. The\nresults highlight the potential of modeling in joint latent representations for\naddressing small data challenges.",
    "categories": [
      "stat.ML",
      "cs.AI",
      "cs.LG",
      "68T07",
      "G.3; I.2.6; J.3"
    ],
    "published": "2025-10-29T13:56:44Z",
    "authors": [
      "Clemens Sch\u00e4chter",
      "Maren Hackenberg",
      "Michelle Pfaffenlehner",
      "F\u00e9lix B. Tambe-Ndonfack",
      "Thorsten Schmidt",
      "Astrid Pechmann",
      "Janbernd Kirschner",
      "Jan Hasenauser",
      "Harald Binder"
    ],
    "pdf_url": "http://arxiv.org/pdf/2510.25531v1"
  },
  {
    "id": "2510.25529v1",
    "title": "Off-policy Reinforcement Learning with Model-based Exploration\n  Augmentation",
    "abstract": "Exploration is fundamental to reinforcement learning (RL), as it determines\nhow effectively an agent discovers and exploits the underlying structure of its\nenvironment to achieve optimal performance. Existing exploration methods\ngenerally fall into two categories: active exploration and passive exploration.\nThe former introduces stochasticity into the policy but struggles in\nhigh-dimensional environments, while the latter adaptively prioritizes\ntransitions in the replay buffer to enhance exploration, yet remains\nconstrained by limited sample diversity. To address the limitation in passive\nexploration, we propose Modelic Generative Exploration (MoGE), which augments\nexploration through the generation of under-explored critical states and\nsynthesis of dynamics-consistent experiences through transition models. MoGE is\ncomposed of two components: (1) a diffusion-based generator that synthesizes\ncritical states under the guidance of a utility function evaluating each\nstate's potential influence on policy exploration, and (2) a one-step\nimagination world model for constructing critical transitions based on the\ncritical states for agent learning. Our method adopts a modular formulation\nthat aligns with the principles of off-policy learning, allowing seamless\nintegration with existing algorithms to improve exploration without altering\ntheir core structures. Empirical results on OpenAI Gym and DeepMind Control\nSuite reveal that MoGE effectively bridges exploration and policy learning,\nleading to remarkable gains in both sample efficiency and performance across\ncomplex control tasks.",
    "categories": [
      "cs.AI"
    ],
    "published": "2025-10-29T13:53:52Z",
    "authors": [
      "Likun Wang",
      "Xiangteng Zhang",
      "Yinuo Wang",
      "Guojian Zhan",
      "Wenxuan Wang",
      "Haoyu Gao",
      "Jingliang Duan",
      "Shengbo Eben Li"
    ],
    "pdf_url": "http://arxiv.org/pdf/2510.25529v1"
  },
  {
    "id": "2510.25528v1",
    "title": "Zero Reinforcement Learning Towards General Domains",
    "abstract": "Zero Reinforcement Learning (Zero-RL) has proven to be an effective approach\nfor enhancing the reasoning capabilities of large language models (LLMs) by\ndirectly applying reinforcement learning with verifiable rewards on pretrained\nmodels, without the need for a supervised fine-tuning phase. However, current\nresearch on zero-RL primarily focuses on domains with easily verifiable reward\nsignals, such as mathematics, programming, and other reasoning tasks. The\nchallenge of eliciting reasoning abilities in more diverse scenarios, where\nverification is not straightforward, remains underexplored. To address this\ngap, we propose a novel zero-RL paradigm designed to improve a model's\nreasoning ability across both verifiable and non-verifiable domains. By\ncombining verifiable rewards with a generative reward model, we conduct\nmulti-task zero-RL training across both domains, facilitating the transfer of\nreasoning capabilities between them. Furthermore, to mitigate reward hacking in\nthe generative reward model, we design a smooth length penalty that encourages\nthe generation of more comprehensive thinking tokens in general domains.\nExperimental results on Qwen3-8B-Base and Qwen3-14B-Base demonstrate that our\napproach achieves superior reasoning performance, not only on tasks requiring\nextensive reasoning but also on more general tasks.",
    "categories": [
      "cs.AI"
    ],
    "published": "2025-10-29T13:52:44Z",
    "authors": [
      "Yuyuan Zeng",
      "Yufei Huang",
      "Can Xu",
      "Qingfeng Sun",
      "Jianfeng Yan",
      "Guanghui Xu",
      "Tao Yang",
      "Fengzong Lian"
    ],
    "pdf_url": "http://arxiv.org/pdf/2510.25528v1"
  },
  {
    "id": "2510.25522v1",
    "title": "Comparative Study of UNet-based Architectures for Liver Tumor\n  Segmentation in Multi-Phase Contrast-Enhanced Computed Tomography",
    "abstract": "Segmentation of liver structures in multi-phase contrast-enhanced computed\ntomography (CECT) plays a crucial role in computer-aided diagnosis and\ntreatment planning for liver diseases, including tumor detection. In this\nstudy, we investigate the performance of UNet-based architectures for liver\ntumor segmentation, starting from the original UNet and extending to UNet3+\nwith various backbone networks. We evaluate ResNet, Transformer-based, and\nState-space (Mamba) backbones, all initialized with pretrained weights.\nSurprisingly, despite the advances in modern architecture, ResNet-based models\nconsistently outperform Transformer- and Mamba-based alternatives across\nmultiple evaluation metrics. To further improve segmentation quality, we\nintroduce attention mechanisms into the backbone and observe that incorporating\nthe Convolutional Block Attention Module (CBAM) yields the best performance.\nResNetUNet3+ with CBAM module not only produced the best overlap metrics with a\nDice score of 0.755 and IoU of 0.662, but also achieved the most precise\nboundary delineation, evidenced by the lowest HD95 distance of 77.911. The\nmodel's superiority was further cemented by its leading overall accuracy of\n0.925 and specificity of 0.926, showcasing its robust capability in accurately\nidentifying both lesion and healthy tissue. To further enhance\ninterpretability, Grad-CAM visualizations were employed to highlight the\nregion's most influential predictions, providing insights into its\ndecision-making process. These findings demonstrate that classical ResNet\narchitecture, when combined with modern attention modules, remain highly\ncompetitive for medical image segmentation tasks, offering a promising\ndirection for liver tumor detection in clinical practice.",
    "categories": [
      "cs.CV",
      "cs.AI",
      "I.4.6"
    ],
    "published": "2025-10-29T13:46:19Z",
    "authors": [
      "Doan-Van-Anh Ly",
      "Thi-Thu-Hien Pham",
      "Thanh-Hai Le"
    ],
    "pdf_url": "http://arxiv.org/pdf/2510.25522v1"
  },
  {
    "id": "2510.25518v1",
    "title": "Retrieval Augmented Generation (RAG) for Fintech: Agentic Design and\n  Evaluation",
    "abstract": "Retrieval-Augmented Generation (RAG) systems often face limitations in\nspecialized domains such as fintech, where domain-specific ontologies, dense\nterminology, and acronyms complicate effective retrieval and synthesis. This\npaper introduces an agentic RAG architecture designed to address these\nchallenges through a modular pipeline of specialized agents. The proposed\nsystem supports intelligent query reformulation, iterative sub-query\ndecomposition guided by keyphrase extraction, contextual acronym resolution,\nand cross-encoder-based context re-ranking. We evaluate our approach against a\nstandard RAG baseline using a curated dataset of 85 question--answer--reference\ntriples derived from an enterprise fintech knowledge base. Experimental results\ndemonstrate that the agentic RAG system outperforms the baseline in retrieval\nprecision and relevance, albeit with increased latency. These findings suggest\nthat structured, multi-agent methodologies offer a promising direction for\nenhancing retrieval robustness in complex, domain-specific settings.",
    "categories": [
      "cs.AI"
    ],
    "published": "2025-10-29T13:41:36Z",
    "authors": [
      "Thomas Cook",
      "Richard Osuagwu",
      "Liman Tsatiashvili",
      "Vrynsia Vrynsia",
      "Koustav Ghosal",
      "Maraim Masoud",
      "Riccardo Mattivi"
    ],
    "pdf_url": "http://arxiv.org/pdf/2510.25518v1"
  },
  {
    "id": "2510.25517v1",
    "title": "Predicate Renaming via Large Language Models",
    "abstract": "In this paper, we address the problem of giving names to predicates in logic\nrules using Large Language Models (LLMs). In the context of Inductive Logic\nProgramming, various rule generation methods produce rules containing unnamed\npredicates, with Predicate Invention being a key example. This hinders the\nreadability, interpretability, and reusability of the logic theory. Leveraging\nrecent advancements in LLMs development, we explore their ability to process\nnatural language and code to provide semantically meaningful suggestions for\ngiving a name to unnamed predicates. The evaluation of our approach on some\nhand-crafted logic rules indicates that LLMs hold potential for this task.",
    "categories": [
      "cs.AI"
    ],
    "published": "2025-10-29T13:39:41Z",
    "authors": [
      "Elisabetta Gentili",
      "Tony Ribeiro",
      "Fabrizio Riguzzi",
      "Katsumi Inoue"
    ],
    "pdf_url": "http://arxiv.org/pdf/2510.25517v1"
  },
  {
    "id": "2510.25512v1",
    "title": "FaCT: Faithful Concept Traces for Explaining Neural Network Decisions",
    "abstract": "Deep networks have shown remarkable performance across a wide range of tasks,\nyet getting a global concept-level understanding of how they function remains a\nkey challenge. Many post-hoc concept-based approaches have been introduced to\nunderstand their workings, yet they are not always faithful to the model.\nFurther, they make restrictive assumptions on the concepts a model learns, such\nas class-specificity, small spatial extent, or alignment to human expectations.\nIn this work, we put emphasis on the faithfulness of such concept-based\nexplanations and propose a new model with model-inherent mechanistic\nconcept-explanations. Our concepts are shared across classes and, from any\nlayer, their contribution to the logit and their input-visualization can be\nfaithfully traced. We also leverage foundation models to propose a new\nconcept-consistency metric, C$^2$-Score, that can be used to evaluate\nconcept-based methods. We show that, compared to prior work, our concepts are\nquantitatively more consistent and users find our concepts to be more\ninterpretable, all while retaining competitive ImageNet performance.",
    "categories": [
      "cs.LG",
      "cs.AI",
      "cs.CV"
    ],
    "published": "2025-10-29T13:35:46Z",
    "authors": [
      "Amin Parchami-Araghi",
      "Sukrut Rao",
      "Jonas Fischer",
      "Bernt Schiele"
    ],
    "pdf_url": "http://arxiv.org/pdf/2510.25512v1"
  },
  {
    "id": "2510.25510v1",
    "title": "MTIR-SQL: Multi-turn Tool-Integrated Reasoning Reinforcement Learning\n  for Text-to-SQL",
    "abstract": "As large language models (LLMs) are increasingly used in Text-to-SQL tasks,\nReinforcement Learning (RL) has become a common method for improving\nperformance. Existing methods primarily rely on static execution feedback,\nwhich restricts real-time error correction. However, integrating multi-turn\ntool invocation along with dynamic feedback could significantly improve\nadaptability and robustness, ultimately enhancing model performance. To address\nthese issues, we propose MTIR-SQL, an innovative Multi-turn Tool-Integrated\nReasoning reinforcement learning framework for Text-to-SQL. Our approach\nintroduces an execution-aware multi-turn reasoning paradigm that seamlessly\nincorporates database execution feedback at each reasoning step, enabling\ncontext-sensitive query generation and progressive refinement throughout the\nreasoning process. The framework extends the GRPO algorithm to accommodate\ncomplex multi-turn interaction scenarios. Considering the training instability\ncharacteristics of MTIR and the potential for significant Deviation of model\ndistribution from the initial model, we enhance the GRPO algorithm by adding a\ntrajectory filtering mechanism and removing KL loss constraints. Experimental\nresults demonstrate that MTIR-SQL, with 4B parameters, achieves \\textbf{64.4}\\%\naccuracy in the BIRD Dev and 84.6% execution accuracy in the SPIDER Dev,\nsignificantly outperforming existing approaches.",
    "categories": [
      "cs.AI"
    ],
    "published": "2025-10-29T13:34:27Z",
    "authors": [
      "Zekun Xu",
      "Siyu Xia",
      "Chuhuai Yue",
      "Jiajun Chai",
      "Mingxue Tian",
      "Xiaohan Wang",
      "Wei Lin",
      "Haoxuan Li",
      "Guojun Yin"
    ],
    "pdf_url": "http://arxiv.org/pdf/2510.25510v1"
  },
  {
    "id": "2510.25506v1",
    "title": "Reflections on the Reproducibility of Commercial LLM Performance in\n  Empirical Software Engineering Studies",
    "abstract": "Large Language Models have gained remarkable interest in industry and\nacademia. The increasing interest in LLMs in academia is also reflected in the\nnumber of publications on this topic over the last years. For instance, alone\n78 of the around 425 publications at ICSE 2024 performed experiments with LLMs.\nConducting empirical studies with LLMs remains challenging and raises questions\non how to achieve reproducible results, for both other researchers and\npractitioners. One important step towards excelling in empirical research on\nLLMs and their application is to first understand to what extent current\nresearch results are eventually reproducible and what factors may impede\nreproducibility. This investigation is within the scope of our work. We\ncontribute an analysis of the reproducibility of LLM-centric studies, provide\ninsights into the factors impeding reproducibility, and discuss suggestions on\nhow to improve the current state. In particular, we studied the 86 articles\ndescribing LLM-centric studies, published at ICSE 2024 and ASE 2024. Of the 86\narticles, 18 provided research artefacts and used OpenAI models. We attempted\nto replicate those 18 studies. Of the 18 studies, only five were fit for\nreproduction. For none of the five studies, we were able to fully reproduce the\nresults. Two studies seemed to be partially reproducible, and three studies did\nnot seem to be reproducible. Our results highlight not only the need for\nstricter research artefact evaluations but also for more robust study designs\nto ensure the reproducible value of future publications.",
    "categories": [
      "cs.SE",
      "cs.AI"
    ],
    "published": "2025-10-29T13:31:32Z",
    "authors": [
      "Florian Angermeir",
      "Maximilian Amougou",
      "Mark Kreitz",
      "Andreas Bauer",
      "Matthias Linhuber",
      "Davide Fucci",
      "Fabiola Moy\u00f3n C.",
      "Daniel Mendez",
      "Tony Gorschek"
    ],
    "pdf_url": "http://arxiv.org/pdf/2510.25506v1"
  },
  {
    "id": "2510.25504v1",
    "title": "Multi-Objective Search: Algorithms, Applications, and Emerging\n  Directions",
    "abstract": "Multi-objective search (MOS) has emerged as a unifying framework for planning\nand decision-making problems where multiple, often conflicting, criteria must\nbe balanced. While the problem has been studied for decades, recent years have\nseen renewed interest in the topic across AI applications such as robotics,\ntransportation, and operations research, reflecting the reality that real-world\nsystems rarely optimize a single measure. This paper surveys developments in\nMOS while highlighting cross-disciplinary opportunities, and outlines open\nchallenges that define the emerging frontier of MOS",
    "categories": [
      "cs.AI"
    ],
    "published": "2025-10-29T13:30:01Z",
    "authors": [
      "Oren Salzman",
      "Carlos Hern\u00e1ndez Ulloa",
      "Ariel Felner",
      "Sven Koenig"
    ],
    "pdf_url": "http://arxiv.org/pdf/2510.25504v1"
  },
  {
    "id": "2510.25502v1",
    "title": "TempoPFN: Synthetic Pre-training of Linear RNNs for Zero-shot Time\n  Series Forecasting",
    "abstract": "Foundation models for zero-shot time series forecasting face challenges in\nefficient long-horizon prediction and reproducibility, with existing\nsynthetic-only approaches underperforming on challenging benchmarks. This paper\npresents TempoPFN, a univariate time series foundation model based on linear\nRecurrent Neural Networks (RNNs) pre-trained exclusively on synthetic data. The\nmodel uses a GatedDeltaProduct architecture with state-weaving for fully\nparallelizable training across sequence lengths, eliminating the need for\nwindowing or summarization techniques while maintaining robust temporal\nstate-tracking. Our comprehensive synthetic data pipeline unifies diverse\ngenerators, including stochastic differential equations, Gaussian processes,\nand audio synthesis, with novel augmentations. In zero-shot evaluations on the\nGift-Eval benchmark, TempoPFN achieves top-tier competitive performance,\noutperforming all existing synthetic-only approaches and surpassing the vast\nmajority of models trained on real-world data, while being more efficient than\nexisting baselines by leveraging fully parallelizable training and inference.\nWe open-source our complete data generation pipeline and training code,\nproviding a reproducible foundation for future research.",
    "categories": [
      "cs.LG",
      "cs.AI",
      "stat.ML"
    ],
    "published": "2025-10-29T13:27:18Z",
    "authors": [
      "Vladyslav Moroshan",
      "Julien Siems",
      "Arber Zela",
      "Timur Carstensen",
      "Frank Hutter"
    ],
    "pdf_url": "http://arxiv.org/pdf/2510.25502v1"
  },
  {
    "id": "2510.25471v1",
    "title": "Instrumental goals in advanced AI systems: Features to be managed and\n  not failures to be eliminated?",
    "abstract": "In artificial intelligence (AI) alignment research, instrumental goals, also\ncalled instrumental subgoals or instrumental convergent goals, are widely\nassociated with advanced AI systems. These goals, which include tendencies such\nas power-seeking and self-preservation, become problematic when they conflict\nwith human aims. Conventional alignment theory treats instrumental goals as\nsources of risk that become problematic through failure modes such as reward\nhacking or goal misgeneralization, and attempts to limit the symptoms of\ninstrumental goals, notably resource acquisition and self-preservation. This\narticle proposes an alternative framing: that a philosophical argument can be\nconstructed according to which instrumental goals may be understood as features\nto be accepted and managed rather than failures to be limited. Drawing on\nAristotle's ontology and its modern interpretations, an ontology of concrete,\ngoal-directed entities, it argues that advanced AI systems can be seen as\nartifacts whose formal and material constitution gives rise to effects distinct\nfrom their designers' intentions. In this view, the instrumental tendencies of\nsuch systems correspond to per se outcomes of their constitution rather than\naccidental malfunctions. The implication is that efforts should focus less on\neliminating instrumental goals and more on understanding, managing, and\ndirecting them toward human-aligned ends.",
    "categories": [
      "cs.AI",
      "cs.CY"
    ],
    "published": "2025-10-29T12:47:15Z",
    "authors": [
      "Willem Fourie"
    ],
    "pdf_url": "http://arxiv.org/pdf/2510.25471v1"
  },
  {
    "id": "2510.25470v1",
    "title": "An In-Depth Analysis of Cyber Attacks in Secured Platforms",
    "abstract": "There is an increase in global malware threats. To address this, an\nencryption-type ransomware has been introduced on the Android operating system.\nThe challenges associated with malicious threats in phone use have become a\npressing issue in mobile communication, disrupting user experiences and posing\nsignificant privacy threats. This study surveys commonly used machine learning\ntechniques for detecting malicious threats in phones and examines their\nperformance. The majority of past research focuses on customer feedback and\nreviews, with concerns that people might create false reviews to promote or\ndevalue products and services for personal gain. Hence, the development of\ntechniques for detecting malicious threats using machine learning has been a\nkey focus. This paper presents a comprehensive comparative study of current\nresearch on the issue of malicious threats and methods for tackling these\nchallenges. Nevertheless, a huge amount of information is required by these\nmethods, presenting a challenge for developing robust, specialized automated\nanti-malware systems. This research describes the Android Applications dataset,\nand the accuracy of the techniques is measured using the accuracy levels of the\nmetrics employed in this study.",
    "categories": [
      "cs.CR",
      "cs.AI",
      "cs.LG"
    ],
    "published": "2025-10-29T12:43:18Z",
    "authors": [
      "Parick Ozoh",
      "John K Omoniyi",
      "Bukola Ibitoye"
    ],
    "pdf_url": "http://arxiv.org/pdf/2510.25470v1"
  },
  {
    "id": "2510.25460v1",
    "title": "Fine-Tuned Language Models for Domain-Specific Summarization and Tagging",
    "abstract": "This paper presents a pipeline integrating fine-tuned large language models\n(LLMs) with named entity recognition (NER) for efficient domain-specific text\nsummarization and tagging. The authors address the challenge posed by rapidly\nevolving sub-cultural languages and slang, which complicate automated\ninformation extraction and law enforcement monitoring. By leveraging the LLaMA\nFactory framework, the study fine-tunes LLMs on both generalpurpose and custom\ndomain-specific datasets, particularly in the political and security domains.\nThe models are evaluated using BLEU and ROUGE metrics, demonstrating that\ninstruction fine-tuning significantly enhances summarization and tagging\naccuracy, especially for specialized corpora. Notably, the LLaMA3-8B-Instruct\nmodel, despite its initial limitations in Chinese comprehension, outperforms\nits Chinese-trained counterpart after domainspecific fine-tuning, suggesting\nthat underlying reasoning capabilities can transfer across languages. The\npipeline enables concise summaries and structured entity tagging, facilitating\nrapid document categorization and distribution. This approach proves scalable\nand adaptable for real-time applications, supporting efficient information\nmanagement and the ongoing need to capture emerging language trends. The\nintegration of LLMs and NER offers a robust solution for transforming\nunstructured text into actionable insights, crucial for modern knowledge\nmanagement and security operations.",
    "categories": [
      "cs.CL",
      "cs.AI"
    ],
    "published": "2025-10-29T12:33:48Z",
    "authors": [
      "Jun Wang",
      "Fuming Lin",
      "Yuyu Chen"
    ],
    "pdf_url": "http://arxiv.org/pdf/2510.25460v1"
  },
  {
    "id": "2510.25458v1",
    "title": "Scalable Utility-Aware Multiclass Calibration",
    "abstract": "Ensuring that classifiers are well-calibrated, i.e., their predictions align\nwith observed frequencies, is a minimal and fundamental requirement for\nclassifiers to be viewed as trustworthy. Existing methods for assessing\nmulticlass calibration often focus on specific aspects associated with\nprediction (e.g., top-class confidence, class-wise calibration) or utilize\ncomputationally challenging variational formulations. In this work, we study\nscalable \\emph{evaluation} of multiclass calibration. To this end, we propose\nutility calibration, a general framework that measures the calibration error\nrelative to a specific utility function that encapsulates the goals or decision\ncriteria relevant to the end user. We demonstrate how this framework can unify\nand re-interpret several existing calibration metrics, particularly allowing\nfor more robust versions of the top-class and class-wise calibration metrics,\nand, going beyond such binarized approaches, toward assessing calibration for\nricher classes of downstream utilities.",
    "categories": [
      "cs.LG",
      "cs.AI",
      "stat.ML"
    ],
    "published": "2025-10-29T12:32:14Z",
    "authors": [
      "Mahmoud Hegazy",
      "Michael I. Jordan",
      "Aymeric Dieuleveut"
    ],
    "pdf_url": "http://arxiv.org/pdf/2510.25458v1"
  },
  {
    "id": "2510.25445v1",
    "title": "Agentic AI: A Comprehensive Survey of Architectures, Applications, and\n  Future Directions",
    "abstract": "Agentic AI represents a transformative shift in artificial intelligence, but\nits rapid advancement has led to a fragmented understanding, often conflating\nmodern neural systems with outdated symbolic models -- a practice known as\nconceptual retrofitting. This survey cuts through this confusion by introducing\na novel dual-paradigm framework that categorizes agentic systems into two\ndistinct lineages: the Symbolic/Classical (relying on algorithmic planning and\npersistent state) and the Neural/Generative (leveraging stochastic generation\nand prompt-driven orchestration). Through a systematic PRISMA-based review of\n90 studies (2018--2025), we provide a comprehensive analysis structured around\nthis framework across three dimensions: (1) the theoretical foundations and\narchitectural principles defining each paradigm; (2) domain-specific\nimplementations in healthcare, finance, and robotics, demonstrating how\napplication constraints dictate paradigm selection; and (3) paradigm-specific\nethical and governance challenges, revealing divergent risks and mitigation\nstrategies. Our analysis reveals that the choice of paradigm is strategic:\nsymbolic systems dominate safety-critical domains (e.g., healthcare), while\nneural systems prevail in adaptive, data-rich environments (e.g., finance).\nFurthermore, we identify critical research gaps, including a significant\ndeficit in governance models for symbolic systems and a pressing need for\nhybrid neuro-symbolic architectures. The findings culminate in a strategic\nroadmap arguing that the future of Agentic AI lies not in the dominance of one\nparadigm, but in their intentional integration to create systems that are both\nadaptable and reliable. This work provides the essential conceptual toolkit to\nguide future research, development, and policy toward robust and trustworthy\nhybrid intelligent systems.",
    "categories": [
      "cs.AI",
      "cs.LG"
    ],
    "published": "2025-10-29T12:11:34Z",
    "authors": [
      "Mohamad Abou Ali",
      "Fadi Dornaika"
    ],
    "pdf_url": "http://arxiv.org/pdf/2510.25445v1"
  },
  {
    "id": "2510.25441v1",
    "title": "Grounded in Reality: Learning and Deploying Proactive LLM from Offline\n  Logs",
    "abstract": "Large Language Models (LLMs) excel as passive responders, but teaching them\nto be proactive, goal-oriented partners, a critical capability in high-stakes\ndomains, remains a major challenge. Current paradigms either myopically\noptimize single-turn attributes or rely on brittle, high-cost user simulators,\ncreating a persistent ``reality gap''. To bridge this gap, we introduce\n\\texttt{Learn-to-Ask}, a general, simulator-free framework for learning and\ndeploying proactive dialogue agents \\textit{directly from offline expert data},\nbypassing the need to model complex user dynamics. Our key insight is to\nreframe the offline policy learning problem by leveraging the \\textbf{observed\nfuture} of each expert trajectory. This allows us to infer a dense,\nturn-by-turn reward signal grounded in the expert's revealed strategy,\ndecomposing the intractable long-horizon problem into a series of supervised\nlearning tasks, and training a policy to output a structured \\texttt{(action,\nstate_assessment)} tuple, governing both \\textbf{what to ask} and, crucially,\n\\textbf{when to stop}. To ensure reward fidelity, our Automated Grader\nCalibration pipeline systematically purges noise from the LLM-based reward\nmodel with minimal human supervision. Empirically, we demonstrate the efficacy\nof \\texttt{Learn-to-Ask} in a real-world medical dataset, using LLMs of varying\nsizes up to 32B. Our approach culminates in the successful deployment of LLMs\ninto a live, large-scale online AI service. In rigorous in-house evaluations,\nour model was launched and achieved performance even superior to human experts,\nproving our framework's ability to translate offline data into tangible,\nreal-world impact. We hope this work provides a practical and economically\nviable blueprint for transforming passive LLMs into proactive, goal-oriented\nLLM applications.",
    "categories": [
      "cs.CL",
      "cs.AI"
    ],
    "published": "2025-10-29T12:08:07Z",
    "authors": [
      "Fei Wei",
      "Daoyuan Chen",
      "Ce Wang",
      "Yilun Huang",
      "Yushuo Chen",
      "Xuchen Pan",
      "Yaliang Li",
      "Bolin Ding"
    ],
    "pdf_url": "http://arxiv.org/pdf/2510.25441v1"
  },
  {
    "id": "2510.25428v1",
    "title": "Alibaba International E-commerce Product Search Competition DcuRAGONs\n  Team Technical Report",
    "abstract": "This report details our methodology and results developed for the\nMultilingual E-commerce Search Competition. The problem aims to recognize\nrelevance between user queries versus product items in a multilingual context\nand improve recommendation performance on e-commerce platforms. Utilizing Large\nLanguage Models (LLMs) and their capabilities in other tasks, our data-centric\nmethod achieved the highest score compared to other solutions during the\ncompetition. Final leaderboard is publised at\nhttps://alibaba-international-cikm2025.github.io. The source code for our\nproject is published at https://github.com/nhtlongcs/e-commerce-product-search.",
    "categories": [
      "cs.IR",
      "cs.AI"
    ],
    "published": "2025-10-29T11:50:52Z",
    "authors": [
      "Thang-Long Nguyen-Ho",
      "Minh-Khoi Pham",
      "Hoang-Bao Le"
    ],
    "pdf_url": "http://arxiv.org/pdf/2510.25428v1"
  },
  {
    "id": "2510.25427v1",
    "title": "RLMEval: Evaluating Research-Level Neural Theorem Proving",
    "abstract": "Despite impressive results on curated benchmarks, the practical impact of\nlarge language models (LLMs) on research-level neural theorem proving and proof\nautoformalization is still limited. We introduce RLMEval, an evaluation suite\nfor these tasks, focusing on research-level mathematics from real-world Lean\nformalization projects. RLMEval targets the evaluation of neural theorem\nproving and proof autoformalization on challenging research-level theorems by\nleveraging real Lean Blueprint formalization projects. Our evaluation of\nstate-of-the-art models on RLMEval, comprising 613 theorems from 6 Lean\nprojects, reveals a significant gap: progress on existing benchmarks does not\nreadily translate to these more realistic settings, with the best model\nachieving only a 10.3 % pass rate. RLMEval provides a new, challenging\nbenchmark designed to guide and accelerate progress in automated reasoning for\nformal mathematics.",
    "categories": [
      "cs.CL",
      "cs.AI"
    ],
    "published": "2025-10-29T11:49:49Z",
    "authors": [
      "Auguste Poiroux",
      "Antoine Bosselut",
      "Viktor Kun\u010dak"
    ],
    "pdf_url": "http://arxiv.org/pdf/2510.25427v1"
  },
  {
    "id": "2510.25426v1",
    "title": "Implicature in Interaction: Understanding Implicature Improves Alignment\n  in Human-LLM Interaction",
    "abstract": "The rapid advancement of Large Language Models (LLMs) is positioning language\nat the core of human-computer interaction (HCI). We argue that advancing HCI\nrequires attention to the linguistic foundations of interaction, particularly\nimplicature (meaning conveyed beyond explicit statements through shared\ncontext) which is essential for human-AI (HAI) alignment. This study examines\nLLMs' ability to infer user intent embedded in context-driven prompts and\nwhether understanding implicature improves response generation. Results show\nthat larger models approximate human interpretations more closely, while\nsmaller models struggle with implicature inference. Furthermore,\nimplicature-based prompts significantly enhance the perceived relevance and\nquality of responses across models, with notable gains in smaller models.\nOverall, 67.6% of participants preferred responses with implicature-embedded\nprompts to literal ones, highlighting a clear preference for contextually\nnuanced communication. Our work contributes to understanding how linguistic\ntheory can be used to address the alignment problem by making HAI interaction\nmore natural and contextually grounded.",
    "categories": [
      "cs.CL",
      "cs.AI"
    ],
    "published": "2025-10-29T11:49:42Z",
    "authors": [
      "Asutosh Hota",
      "Jussi P. P. Jokinen"
    ],
    "pdf_url": "http://arxiv.org/pdf/2510.25426v1"
  },
  {
    "id": "2510.25420v1",
    "title": "Improving Temporal Consistency and Fidelity at Inference-time in\n  Perceptual Video Restoration by Zero-shot Image-based Diffusion Models",
    "abstract": "Diffusion models have emerged as powerful priors for single-image\nrestoration, but their application to zero-shot video restoration suffers from\ntemporal inconsistencies due to the stochastic nature of sampling and\ncomplexity of incorporating explicit temporal modeling. In this work, we\naddress the challenge of improving temporal coherence in video restoration\nusing zero-shot image-based diffusion models without retraining or modifying\ntheir architecture. We propose two complementary inference-time strategies: (1)\nPerceptual Straightening Guidance (PSG) based on the neuroscience-inspired\nperceptual straightening hypothesis, which steers the diffusion denoising\nprocess towards smoother temporal evolution by incorporating a curvature\npenalty in a perceptual space to improve temporal perceptual scores, such as\nFr\\'echet Video Distance (FVD) and perceptual straightness; and (2) Multi-Path\nEnsemble Sampling (MPES), which aims at reducing stochastic variation by\nensembling multiple diffusion trajectories to improve fidelity (distortion)\nscores, such as PSNR and SSIM, without sacrificing sharpness. Together, these\ntraining-free techniques provide a practical path toward temporally stable\nhigh-fidelity perceptual video restoration using large pretrained diffusion\nmodels. We performed extensive experiments over multiple datasets and\ndegradation types, systematically evaluating each strategy to understand their\nstrengths and limitations. Our results show that while PSG enhances temporal\nnaturalness, particularly in case of temporal blur, MPES consistently improves\nfidelity and spatio-temporal perception--distortion trade-off across all tasks.",
    "categories": [
      "eess.IV",
      "cs.AI"
    ],
    "published": "2025-10-29T11:40:06Z",
    "authors": [
      "Nasrin Rahimi",
      "A. Murat Tekalp"
    ],
    "pdf_url": "http://arxiv.org/pdf/2510.25420v1"
  },
  {
    "id": "2510.25416v1",
    "title": "Adaptive End-to-End Transceiver Design for NextG Pilot-Free and CP-Free\n  Wireless Systems",
    "abstract": "The advent of artificial intelligence (AI)-native wireless communication is\nfundamentally reshaping the design paradigm of next-generation (NextG) systems,\nwhere intelligent air interfaces are expected to operate adaptively and\nefficiently in highly dynamic environments. Conventional orthogonal frequency\ndivision multiplexing (OFDM) systems rely heavily on pilots and the cyclic\nprefix (CP), resulting in significant overhead and reduced spectral efficiency.\nTo address these limitations, we propose an adaptive end-to-end (E2E)\ntransceiver architecture tailored for pilot-free and CP-free wireless systems.\nThe architecture combines AI-driven constellation shaping and a neural receiver\nthrough joint training. To enhance robustness against mismatched or\ntime-varying channel conditions, we introduce a lightweight channel adapter\n(CA) module, which enables rapid adaptation with minimal computational overhead\nby updating only the CA parameters. Additionally, we present a framework that\nis scalable to multiple modulation orders within a unified model, significantly\nreducing model storage requirements. Moreover, to tackle the high\npeak-to-average power ratio (PAPR) inherent to OFDM, we incorporate constrained\nE2E training, achieving compliance with PAPR targets without additional\ntransmission overhead. Extensive simulations demonstrate that the proposed\nframework delivers superior bit error rate (BER), throughput, and resilience\nacross diverse channel scenarios, highlighting its potential for AI-native\nNextG.",
    "categories": [
      "eess.SP",
      "cs.AI"
    ],
    "published": "2025-10-29T11:34:09Z",
    "authors": [
      "Jiaming Cheng",
      "Wei Chen",
      "Bo Ai"
    ],
    "pdf_url": "http://arxiv.org/pdf/2510.25416v1"
  },
  {
    "id": "2510.25409v2",
    "title": "BhashaBench V1: A Comprehensive Benchmark for the Quadrant of Indic\n  Domains",
    "abstract": "The rapid advancement of large language models(LLMs) has intensified the need\nfor domain and culture specific evaluation. Existing benchmarks are largely\nAnglocentric and domain-agnostic, limiting their applicability to India-centric\ncontexts. To address this gap, we introduce BhashaBench V1, the first\ndomain-specific, multi-task, bilingual benchmark focusing on critical Indic\nknowledge systems. BhashaBench V1 contains 74,166 meticulously curated\nquestion-answer pairs, with 52,494 in English and 21,672 in Hindi, sourced from\nauthentic government and domain-specific exams. It spans four major domains:\nAgriculture, Legal, Finance, and Ayurveda, comprising 90+ subdomains and\ncovering 500+ topics, enabling fine-grained evaluation. Evaluation of 29+ LLMs\nreveals significant domain and language specific performance gaps, with\nespecially large disparities in low-resource domains. For instance, GPT-4o\nachieves 76.49% overall accuracy in Legal but only 59.74% in Ayurveda. Models\nconsistently perform better on English content compared to Hindi across all\ndomains. Subdomain-level analysis shows that areas such as Cyber Law,\nInternational Finance perform relatively well, while Panchakarma, Seed Science,\nand Human Rights remain notably weak. BhashaBench V1 provides a comprehensive\ndataset for evaluating large language models across India's diverse knowledge\ndomains. It enables assessment of models' ability to integrate domain-specific\nknowledge with bilingual understanding. All code, benchmarks, and resources are\npublicly available to support open research.",
    "categories": [
      "cs.CL",
      "cs.AI"
    ],
    "published": "2025-10-29T11:27:08Z",
    "authors": [
      "Vijay Devane",
      "Mohd Nauman",
      "Bhargav Patel",
      "Aniket Mahendra Wakchoure",
      "Yogeshkumar Sant",
      "Shyam Pawar",
      "Viraj Thakur",
      "Ananya Godse",
      "Sunil Patra",
      "Neha Maurya",
      "Suraj Racha",
      "Nitish Kamal Singh",
      "Ajay Nagpal",
      "Piyush Sawarkar",
      "Kundeshwar Vijayrao Pundalik",
      "Rohit Saluja",
      "Ganesh Ramakrishnan"
    ],
    "pdf_url": "http://arxiv.org/pdf/2510.25409v2"
  },
  {
    "id": "2510.25404v1",
    "title": "GPTOpt: Towards Efficient LLM-Based Black-Box Optimization",
    "abstract": "Global optimization of expensive, derivative-free black-box functions demands\nextreme sample efficiency. Classical methods such as Bayesian Optimization (BO)\ncan be effective, but they often require careful parameter tuning to each\napplication domain. At the same time, Large Language Models (LLMs) have shown\nbroad capabilities, yet state-of-the-art models remain limited in solving\ncontinuous black-box optimization tasks. We introduce GPTOpt, an LLM-based\noptimization method that equips LLMs with continuous black-box optimization\ncapabilities. By fine-tuning large language models on extensive synthetic\ndatasets derived from diverse BO parameterizations, GPTOpt leverages LLM\npre-training to generalize across optimization tasks. On a variety of black-box\noptimization benchmarks, GPTOpt surpasses traditional optimizers, highlighting\nthe capacity of LLMs for advanced numerical reasoning and introducing a\nflexible framework for global optimization without parameter tuning.",
    "categories": [
      "cs.LG",
      "cs.AI"
    ],
    "published": "2025-10-29T11:21:55Z",
    "authors": [
      "Jamison Meindl",
      "Yunsheng Tian",
      "Tony Cui",
      "Veronika Thost",
      "Zhang-Wei Hong",
      "Jie Chen",
      "Wojciech Matusik",
      "Mina Konakovi\u0107 Lukovi\u0107"
    ],
    "pdf_url": "http://arxiv.org/pdf/2510.25404v1"
  },
  {
    "id": "2510.25388v1",
    "title": "Grouping Nodes With Known Value Differences: A Lossless UCT-based\n  Abstraction Algorithm",
    "abstract": "A core challenge of Monte Carlo Tree Search (MCTS) is its sample efficiency,\nwhich can be improved by grouping state-action pairs and using their aggregate\nstatistics instead of single-node statistics. On the Go Abstractions in Upper\nConfidence bounds applied to Trees (OGA-UCT) is the state-of-the-art MCTS\nabstraction algorithm for deterministic environments that builds its\nabstraction using the Abstractions of State-Action Pairs (ASAP) framework,\nwhich aims to detect states and state-action pairs with the same value under\noptimal play by analysing the search graph. ASAP, however, requires two\nstate-action pairs to have the same immediate reward, which is a rigid\ncondition that limits the number of abstractions that can be found and thereby\nthe sample efficiency. In this paper, we break with the paradigm of grouping\nvalue-equivalent states or state-action pairs and instead group states and\nstate-action pairs with possibly different values as long as the difference\nbetween their values can be inferred. We call this abstraction framework Known\nValue Difference Abstractions (KVDA), which infers the value differences by\nanalysis of the immediate rewards and modifies OGA-UCT to use this framework\ninstead. The modification is called KVDA-UCT, which detects significantly more\nabstractions than OGA-UCT, introduces no additional parameter, and outperforms\nOGA-UCT on a variety of deterministic environments and parameter settings.",
    "categories": [
      "cs.AI"
    ],
    "published": "2025-10-29T11:03:44Z",
    "authors": [
      "Robin Schm\u00f6cker",
      "Alexander Dockhorn",
      "Bodo Rosenhahn"
    ],
    "pdf_url": "http://arxiv.org/pdf/2510.25388v1"
  },
  {
    "id": "2510.25386v1",
    "title": "Integrating Legal and Logical Specifications in Perception, Prediction,\n  and Planning for Automated Driving: A Survey of Methods",
    "abstract": "This survey provides an analysis of current methodologies integrating legal\nand logical specifications into the perception, prediction, and planning\nmodules of automated driving systems. We systematically explore techniques\nranging from logic-based frameworks to computational legal reasoning\napproaches, emphasizing their capability to ensure regulatory compliance and\ninterpretability in dynamic and uncertain driving environments. A central\nfinding is that significant challenges arise at the intersection of perceptual\nreliability, legal compliance, and decision-making justifiability. To\nsystematically analyze these challenges, we introduce a taxonomy categorizing\nexisting approaches by their theoretical foundations, architectural\nimplementations, and validation strategies. We particularly focus on methods\nthat address perceptual uncertainty and incorporate explicit legal norms,\nfacilitating decisions that are both technically robust and legally defensible.\nThe review covers neural-symbolic integration methods for perception,\nlogic-driven rule representation, and norm-aware prediction strategies, all\ncontributing toward transparent and accountable autonomous vehicle operation.\nWe highlight critical open questions and practical trade-offs that must be\naddressed, offering multidisciplinary insights from engineering, logic, and law\nto guide future developments in legally compliant autonomous driving systems.",
    "categories": [
      "cs.RO",
      "cs.AI",
      "cs.SY",
      "eess.SY"
    ],
    "published": "2025-10-29T10:57:24Z",
    "authors": [
      "Kumar Manas",
      "Mert Keser",
      "Alois Knoll"
    ],
    "pdf_url": "http://arxiv.org/pdf/2510.25386v1"
  },
  {
    "id": "2510.25378v1",
    "title": "Hallucinations in Bibliographic Recommendation: Citation Frequency as a\n  Proxy for Training Data Redundancy",
    "abstract": "Large language models (LLMs) have been increasingly applied to a wide range\nof tasks, from natural language understanding to code generation. While they\nhave also been used to assist in bibliographic recommendation, the\nhallucination of non-existent papers remains a major issue. Building on prior\nstudies, this study hypothesizes that an LLM's ability to correctly produce\nbibliographic information depends on whether the underlying knowledge is\ngenerated or memorized, with highly cited papers (i.e., more frequently appear\nin the training corpus) showing lower hallucination rates. We therefore assume\ncitation count as a proxy for training data redundancy (i.e., the frequency\nwith which a given bibliographic record is repeatedly represented in the\npretraining corpus) and investigate how citation frequency affects hallucinated\nreferences in LLM outputs. Using GPT-4.1, we generated and manually verified\n100 bibliographic records across twenty computer-science domains, and measured\nfactual consistency via cosine similarity between generated and authentic\nmetadata. The results revealed that (i) hallucination rates vary across\nresearch domains, (ii) citation count is strongly correlated with factual\naccuracy, and (iii) bibliographic information becomes almost verbatimly\nmemorized beyond approximately 1,000 citations. These findings suggest that\nhighly cited papers are nearly verbatimly retained in the model, indicating a\nthreshold where generalization shifts into memorization.",
    "categories": [
      "cs.CL",
      "cs.AI"
    ],
    "published": "2025-10-29T10:51:35Z",
    "authors": [
      "Junichiro Niimi"
    ],
    "pdf_url": "http://arxiv.org/pdf/2510.25378v1"
  },
  {
    "id": "2510.25368v1",
    "title": "Position: Biology is the Challenge Physics-Informed ML Needs to Evolve",
    "abstract": "Physics-Informed Machine Learning (PIML) has successfully integrated\nmechanistic understanding into machine learning, particularly in domains\ngoverned by well-known physical laws. This success has motivated efforts to\napply PIML to biology, a field rich in dynamical systems but shaped by\ndifferent constraints. Biological modeling, however, presents unique\nchallenges: multi-faceted and uncertain prior knowledge, heterogeneous and\nnoisy data, partial observability, and complex, high-dimensional networks. In\nthis position paper, we argue that these challenges should not be seen as\nobstacles to PIML, but as catalysts for its evolution. We propose\nBiology-Informed Machine Learning (BIML): a principled extension of PIML that\nretains its structural grounding while adapting to the practical realities of\nbiology. Rather than replacing PIML, BIML retools its methods to operate under\nsofter, probabilistic forms of prior knowledge. We outline four foundational\npillars as a roadmap for this transition: uncertainty quantification,\ncontextualization, constrained latent structure inference, and scalability.\nFoundation Models and Large Language Models will be key enablers, bridging\nhuman expertise with computational modeling. We conclude with concrete\nrecommendations to build the BIML ecosystem and channel PIML-inspired\ninnovation toward challenges of high scientific and societal relevance.",
    "categories": [
      "cs.LG",
      "cs.AI",
      "cs.NE"
    ],
    "published": "2025-10-29T10:39:29Z",
    "authors": [
      "Julien Martinelli"
    ],
    "pdf_url": "http://arxiv.org/pdf/2510.25368v1"
  },
  {
    "id": "2510.25366v2",
    "title": "A Convexity-dependent Two-Phase Training Algorithm for Deep Neural\n  Networks",
    "abstract": "The key task of machine learning is to minimize the loss function that\nmeasures the model fit to the training data. The numerical methods to do this\nefficiently depend on the properties of the loss function. The most decisive\namong these properties is the convexity or non-convexity of the loss function.\nThe fact that the loss function can have, and frequently has, non-convex\nregions has led to a widespread commitment to non-convex methods such as Adam.\nHowever, a local minimum implies that, in some environment around it, the\nfunction is convex. In this environment, second-order minimizing methods such\nas the Conjugate Gradient (CG) give a guaranteed superlinear convergence. We\npropose a novel framework grounded in the hypothesis that loss functions in\nreal-world tasks swap from initial non-convexity to convexity towards the\noptimum. This is a property we leverage to design an innovative two-phase\noptimization algorithm. The presented algorithm detects the swap point by\nobserving the gradient norm dependence on the loss. In these regions,\nnon-convex (Adam) and convex (CG) algorithms are used, respectively. Computing\nexperiments confirm the hypothesis that this simple convexity structure is\nfrequent enough to be practically exploited to substantially improve\nconvergence and accuracy.",
    "categories": [
      "cs.LG",
      "cs.AI",
      "math.OC"
    ],
    "published": "2025-10-29T10:37:24Z",
    "authors": [
      "Tomas Hrycej",
      "Bernhard Bermeitinger",
      "Massimo Pavone",
      "G\u00f6tz-Henrik Wiegand",
      "Siegfried Handschuh"
    ],
    "pdf_url": "http://arxiv.org/pdf/2510.25366v2"
  },
  {
    "id": "2510.25340v1",
    "title": "Multi-party Agent Relation Sampling for Multi-party Ad Hoc Teamwork",
    "abstract": "Multi-agent reinforcement learning (MARl) has achieved strong results in\ncooperative tasks but typically assumes fixed, fully controlled teams. Ad hoc\nteamwork (AHT) relaxes this by allowing collaboration with unknown partners,\nyet existing variants still presume shared conventions. We introduce\nMultil-party Ad Hoc Teamwork (MAHT), where controlled agents must coordinate\nwith multiple mutually unfamiliar groups of uncontrolled teammates. To address\nthis, we propose MARs, which builds a sparse skeleton graph and applies\nrelational modeling to capture cross-group dvnamics. Experiments on MPE and\nstarCralt ll show that MARs outperforms MARL and AHT baselines while converging\nfaster.",
    "categories": [
      "cs.MA",
      "cs.AI"
    ],
    "published": "2025-10-29T09:53:07Z",
    "authors": [
      "Beiwen Zhang",
      "Yongheng Liang",
      "Hejun Wu"
    ],
    "pdf_url": "http://arxiv.org/pdf/2510.25340v1"
  },
  {
    "id": "2510.25327v2",
    "title": "MMEdge: Accelerating On-device Multimodal Inference via Pipelined\n  Sensing and Encoding",
    "abstract": "Real-time multimodal inference on resource-constrained edge devices is\nessential for applications such as autonomous driving, human-computer\ninteraction, and mobile health. However, prior work often overlooks the tight\ncoupling between sensing dynamics and model execution, as well as the complex\ninter-modality dependencies. In this paper, we propose MMEdge, an new on-device\nmulti-modal inference framework based on pipelined sensing and encoding.\nInstead of waiting for complete sensor inputs, MMEdge decomposes the entire\ninference process into a sequence of fine-grained sensing and encoding units,\nallowing computation to proceed incrementally as data arrive. MMEdge also\nintroduces a lightweight but effective temporal aggregation module that\ncaptures rich temporal dynamics across different pipelined units to maintain\naccuracy performance. Such pipelined design also opens up opportunities for\nfine-grained cross-modal optimization and early decision-making during\ninference. To further enhance system performance under resource variability and\ninput data complexity, MMEdge incorporates an adaptive multimodal configuration\noptimizer that dynamically selects optimal sensing and model configurations for\neach modality under latency constraints, and a cross-modal speculative skipping\nmechanism that bypasses future units of slower modalities when early\npredictions reach sufficient confidence. We evaluate MMEdge using two public\nmultimodal datasets and deploy it on a real-world unmanned aerial vehicle\n(UAV)-based multimodal testbed. The results show that MMEdge significantly\nreduces end-to-end latency while maintaining high task accuracy across various\nsystem and data dynamics.",
    "categories": [
      "cs.CV",
      "cs.AI",
      "cs.LG"
    ],
    "published": "2025-10-29T09:41:03Z",
    "authors": [
      "Runxi Huang",
      "Mingxuan Yu",
      "Mingyu Tsoi",
      "Xiaomin Ouyang"
    ],
    "pdf_url": "http://arxiv.org/pdf/2510.25327v2"
  },
  {
    "id": "2510.25320v1",
    "title": "GAP: Graph-Based Agent Planning with Parallel Tool Use and Reinforcement\n  Learning",
    "abstract": "Autonomous agents powered by large language models (LLMs) have shown\nimpressive capabilities in tool manipulation for complex task-solving. However,\nexisting paradigms such as ReAct rely on sequential reasoning and execution,\nfailing to exploit the inherent parallelism among independent sub-tasks. This\nsequential bottleneck leads to inefficient tool utilization and suboptimal\nperformance in multi-step reasoning scenarios. We introduce Graph-based Agent\nPlanning (GAP), a novel framework that explicitly models inter-task\ndependencies through graph-based planning to enable adaptive parallel and\nserial tool execution. Our approach trains agent foundation models to decompose\ncomplex tasks into dependency-aware sub-task graphs, autonomously determining\nwhich tools can be executed in parallel and which must follow sequential\ndependencies. This dependency-aware orchestration achieves substantial\nimprovements in both execution efficiency and task accuracy. To train GAP, we\nconstruct a high-quality dataset of graph-based planning traces derived from\nthe Multi-Hop Question Answering (MHQA) benchmark. We employ a two-stage\ntraining strategy: supervised fine-tuning (SFT) on the curated dataset,\nfollowed by reinforcement learning (RL) with a correctness-based reward\nfunction on strategically sampled queries where tool-based reasoning provides\nmaximum value. Experimental results on MHQA datasets demonstrate that GAP\nsignificantly outperforms traditional ReAct baselines, particularly on\nmulti-step retrieval tasks, while achieving dramatic improvements in tool\ninvocation efficiency through intelligent parallelization. The project page is\navailable at: https://github.com/WJQ7777/Graph-Agent-Planning.",
    "categories": [
      "cs.AI",
      "cs.CL"
    ],
    "published": "2025-10-29T09:35:55Z",
    "authors": [
      "Jiaqi Wu",
      "Qinlao Zhao",
      "Zefeng Chen",
      "Kai Qin",
      "Yifei Zhao",
      "Xueqian Wang",
      "Yuhang Yao"
    ],
    "pdf_url": "http://arxiv.org/pdf/2510.25320v1"
  },
  {
    "id": "2510.25319v1",
    "title": "4-Doodle: Text to 3D Sketches that Move!",
    "abstract": "We present a novel task: text-to-3D sketch animation, which aims to bring\nfreeform sketches to life in dynamic 3D space. Unlike prior works focused on\nphotorealistic content generation, we target sparse, stylized, and\nview-consistent 3D vector sketches, a lightweight and interpretable medium\nwell-suited for visual communication and prototyping. However, this task is\nvery challenging: (i) no paired dataset exists for text and 3D (or 4D)\nsketches; (ii) sketches require structural abstraction that is difficult to\nmodel with conventional 3D representations like NeRFs or point clouds; and\n(iii) animating such sketches demands temporal coherence and multi-view\nconsistency, which current pipelines do not address. Therefore, we propose\n4-Doodle, the first training-free framework for generating dynamic 3D sketches\nfrom text. It leverages pretrained image and video diffusion models through a\ndual-space distillation scheme: one space captures multi-view-consistent\ngeometry using differentiable B\\'ezier curves, while the other encodes motion\ndynamics via temporally-aware priors. Unlike prior work (e.g., DreamFusion),\nwhich optimizes from a single view per step, our multi-view optimization\nensures structural alignment and avoids view ambiguity, critical for sparse\nsketches. Furthermore, we introduce a structure-aware motion module that\nseparates shape-preserving trajectories from deformation-aware changes,\nenabling expressive motion such as flipping, rotation, and articulated\nmovement. Extensive experiments show that our method produces temporally\nrealistic and structurally stable 3D sketch animations, outperforming existing\nbaselines in both fidelity and controllability. We hope this work serves as a\nstep toward more intuitive and accessible 4D content creation.",
    "categories": [
      "cs.GR",
      "cs.AI"
    ],
    "published": "2025-10-29T09:33:29Z",
    "authors": [
      "Hao Chen",
      "Jiaqi Wang",
      "Yonggang Qi",
      "Ke Li",
      "Kaiyue Pang",
      "Yi-Zhe Song"
    ],
    "pdf_url": "http://arxiv.org/pdf/2510.25319v1"
  },
  {
    "id": "2510.25311v1",
    "title": "Dense and Diverse Goal Coverage in Multi Goal Reinforcement Learning",
    "abstract": "Reinforcement Learning algorithms are primarily focused on learning a policy\nthat maximizes expected return. As a result, the learned policy can exploit one\nor few reward sources. However, in many natural situations, it is desirable to\nlearn a policy that induces a dispersed marginal state distribution over\nrewarding states, while maximizing the expected return which is typically tied\nto reaching a goal state. This aspect remains relatively unexplored. Existing\ntechniques based on entropy regularization and intrinsic rewards use\nstochasticity for encouraging exploration to find an optimal policy which may\nnot necessarily lead to dispersed marginal state distribution over rewarding\nstates. Other RL algorithms which match a target distribution assume the latter\nto be available apriori. This may be infeasible in large scale systems where\nenumeration of all states is not possible and a state is determined to be a\ngoal state only upon reaching it. We formalize the problem of maximizing the\nexpected return while uniformly visiting the goal states as Multi Goal RL in\nwhich an oracle classifier over the state space determines the goal states. We\npropose a novel algorithm that learns a high-return policy mixture with\nmarginal state distribution dispersed over the set of goal states. Our\nalgorithm is based on optimizing a custom RL reward which is computed - based\non the current policy mixture - at each iteration for a set of sampled\ntrajectories. The latter are used via an offline RL algorithm to update the\npolicy mixture. We prove performance guarantees for our algorithm, showing\nefficient convergence bounds for optimizing a natural objective which captures\nthe expected return as well as the dispersion of the marginal state\ndistribution over the goal states. We design and perform experiments on\nsynthetic MDPs and standard RL environments to evaluate the effectiveness of\nour algorithm.",
    "categories": [
      "cs.LG",
      "cs.AI"
    ],
    "published": "2025-10-29T09:23:21Z",
    "authors": [
      "Sagalpreet Singh",
      "Rishi Saket",
      "Aravindan Raghuveer"
    ],
    "pdf_url": "http://arxiv.org/pdf/2510.25311v1"
  },
  {
    "id": "2510.25268v1",
    "title": "SynHLMA:Synthesizing Hand Language Manipulation for Articulated Object\n  with Discrete Human Object Interaction Representation",
    "abstract": "Generating hand grasps with language instructions is a widely studied topic\nthat benefits from embodied AI and VR/AR applications. While transferring into\nhand articulatied object interaction (HAOI), the hand grasps synthesis requires\nnot only object functionality but also long-term manipulation sequence along\nthe object deformation. This paper proposes a novel HAOI sequence generation\nframework SynHLMA, to synthesize hand language manipulation for articulated\nobjects. Given a complete point cloud of an articulated object, we utilize a\ndiscrete HAOI representation to model each hand object interaction frame. Along\nwith the natural language embeddings, the representations are trained by an\nHAOI manipulation language model to align the grasping process with its\nlanguage description in a shared representation space. A joint-aware loss is\nemployed to ensure hand grasps follow the dynamic variations of articulated\nobject joints. In this way, our SynHLMA achieves three typical hand\nmanipulation tasks for articulated objects of HAOI generation, HAOI prediction\nand HAOI interpolation. We evaluate SynHLMA on our built HAOI-lang dataset and\nexperimental results demonstrate the superior hand grasp sequence generation\nperformance comparing with state-of-the-art. We also show a robotics grasp\napplication that enables dexterous grasps execution from imitation learning\nusing the manipulation sequence provided by our SynHLMA. Our codes and datasets\nwill be made publicly available.",
    "categories": [
      "cs.RO",
      "cs.AI",
      "cs.CV"
    ],
    "published": "2025-10-29T08:27:00Z",
    "authors": [
      "Wang zhi",
      "Yuyan Liu",
      "Liu Liu",
      "Li Zhang",
      "Ruixuan Lu",
      "Dan Guo"
    ],
    "pdf_url": "http://arxiv.org/pdf/2510.25268v1"
  },
  {
    "id": "2510.25262v1",
    "title": "IBNorm: Information-Bottleneck Inspired Normalization for Representation\n  Learning",
    "abstract": "Normalization is fundamental to deep learning, but existing approaches such\nas BatchNorm, LayerNorm, and RMSNorm are variance-centric by enforcing zero\nmean and unit variance, stabilizing training without controlling how\nrepresentations capture task-relevant information. We propose IB-Inspired\nNormalization (IBNorm), a simple yet powerful family of methods grounded in the\nInformation Bottleneck principle. IBNorm introduces bounded compression\noperations that encourage embeddings to preserve predictive information while\nsuppressing nuisance variability, yielding more informative representations\nwhile retaining the stability and compatibility of standard normalization.\nTheoretically, we prove that IBNorm achieves a higher IB value and tighter\ngeneralization bounds than variance-centric methods. Empirically, IBNorm\nconsistently outperforms BatchNorm, LayerNorm, and RMSNorm across large-scale\nlanguage models (LLaMA, GPT-2) and vision models (ResNet, ViT), with mutual\ninformation analysis confirming superior information bottleneck behavior. Code\nwill be released publicly.",
    "categories": [
      "cs.LG",
      "cs.AI"
    ],
    "published": "2025-10-29T08:21:32Z",
    "authors": [
      "Xiandong Zou",
      "Pan Zhou"
    ],
    "pdf_url": "http://arxiv.org/pdf/2510.25262v1"
  },
  {
    "id": "2510.25259v1",
    "title": "TV-Rec: Time-Variant Convolutional Filter for Sequential Recommendation",
    "abstract": "Recently, convolutional filters have been increasingly adopted in sequential\nrecommendation for their ability to capture local sequential patterns. However,\nmost of these models complement convolutional filters with self-attention. This\nis because convolutional filters alone, generally fixed filters, struggle to\ncapture global interactions necessary for accurate recommendation. We propose\nTime-Variant Convolutional Filters for Sequential Recommendation (TV-Rec), a\nmodel inspired by graph signal processing, where time-variant graph filters\ncapture position-dependent temporal variations in user sequences. By replacing\nboth fixed kernels and self-attention with time-variant filters, TV-Rec\nachieves higher expressive power and better captures complex interaction\npatterns in user behavior. This design not only eliminates the need for\nself-attention but also reduces computation while accelerating inference.\nExtensive experiments on six public benchmarks show that TV-Rec outperforms\nstate-of-the-art baselines by an average of 7.49%.",
    "categories": [
      "cs.IR",
      "cs.AI",
      "cs.LG"
    ],
    "published": "2025-10-29T08:14:03Z",
    "authors": [
      "Yehjin Shin",
      "Jeongwhan Choi",
      "Seojin Kim",
      "Noseong Park"
    ],
    "pdf_url": "http://arxiv.org/pdf/2510.25259v1"
  },
  {
    "id": "2510.25254v1",
    "title": "Scaling Up Bayesian DAG Sampling",
    "abstract": "Bayesian inference of Bayesian network structures is often performed by\nsampling directed acyclic graphs along an appropriately constructed Markov\nchain. We present two techniques to improve sampling. First, we give an\nefficient implementation of basic moves, which add, delete, or reverse a single\narc. Second, we expedite summing over parent sets, an expensive task required\nfor more sophisticated moves: we devise a preprocessing method to prune\npossible parent sets so as to approximately preserve the sums. Our empirical\nstudy shows that our techniques can yield substantial efficiency gains compared\nto previous methods.",
    "categories": [
      "cs.LG",
      "cs.AI"
    ],
    "published": "2025-10-29T08:06:20Z",
    "authors": [
      "Daniele Nikzad",
      "Alexander Zhilkin",
      "Juha Harviainen",
      "Jack Kuipers",
      "Giusi Moffa",
      "Mikko Koivisto"
    ],
    "pdf_url": "http://arxiv.org/pdf/2510.25254v1"
  },
  {
    "id": "2510.25241v1",
    "title": "One-shot Humanoid Whole-body Motion Learning",
    "abstract": "Whole-body humanoid motion represents a cornerstone challenge in robotics,\nintegrating balance, coordination, and adaptability to enable human-like\nbehaviors. However, existing methods typically require multiple training\nsamples per motion category, rendering the collection of high-quality human\nmotion datasets both labor-intensive and costly. To address this, we propose a\nnovel approach that trains effective humanoid motion policies using only a\nsingle non-walking target motion sample alongside readily available walking\nmotions. The core idea lies in leveraging order-preserving optimal transport to\ncompute distances between walking and non-walking sequences, followed by\ninterpolation along geodesics to generate new intermediate pose skeletons,\nwhich are then optimized for collision-free configurations and retargeted to\nthe humanoid before integration into a simulated environment for policy\ntraining via reinforcement learning. Experimental evaluations on the CMU MoCap\ndataset demonstrate that our method consistently outperforms baselines,\nachieving superior performance across metrics. Code will be released upon\nacceptance.",
    "categories": [
      "cs.RO",
      "cs.AI"
    ],
    "published": "2025-10-29T07:48:10Z",
    "authors": [
      "Hao Huang",
      "Geeta Chandra Raju Bethala",
      "Shuaihang Yuan",
      "Congcong Wen",
      "Anthony Tzes",
      "Yi Fang"
    ],
    "pdf_url": "http://arxiv.org/pdf/2510.25241v1"
  },
  {
    "id": "2510.25234v1",
    "title": "Learning Disentangled Speech- and Expression-Driven Blendshapes for 3D\n  Talking Face Animation",
    "abstract": "Expressions are fundamental to conveying human emotions. With the rapid\nadvancement of AI-generated content (AIGC), realistic and expressive 3D facial\nanimation has become increasingly crucial. Despite recent progress in\nspeech-driven lip-sync for talking-face animation, generating emotionally\nexpressive talking faces remains underexplored. A major obstacle is the\nscarcity of real emotional 3D talking-face datasets due to the high cost of\ndata capture. To address this, we model facial animation driven by both speech\nand emotion as a linear additive problem. Leveraging a 3D talking-face dataset\nwith neutral expressions (VOCAset) and a dataset of 3D expression sequences\n(Florence4D), we jointly learn a set of blendshapes driven by speech and\nemotion. We introduce a sparsity constraint loss to encourage disentanglement\nbetween the two types of blendshapes while allowing the model to capture\ninherent secondary cross-domain deformations present in the training data. The\nlearned blendshapes can be further mapped to the expression and jaw pose\nparameters of the FLAME model, enabling the animation of 3D Gaussian avatars.\nQualitative and quantitative experiments demonstrate that our method naturally\ngenerates talking faces with specified expressions while maintaining accurate\nlip synchronization. Perceptual studies further show that our approach achieves\nsuperior emotional expressivity compared to existing methods, without\ncompromising lip-sync quality.",
    "categories": [
      "cs.CV",
      "cs.AI",
      "cs.GR"
    ],
    "published": "2025-10-29T07:29:21Z",
    "authors": [
      "Yuxiang Mao",
      "Zhijie Zhang",
      "Zhiheng Zhang",
      "Jiawei Liu",
      "Chen Zeng",
      "Shihong Xia"
    ],
    "pdf_url": "http://arxiv.org/pdf/2510.25234v1"
  },
  {
    "id": "2510.25232v1",
    "title": "From Medical Records to Diagnostic Dialogues: A Clinical-Grounded\n  Approach and Dataset for Psychiatric Comorbidity",
    "abstract": "Psychiatric comorbidity is clinically significant yet challenging due to the\ncomplexity of multiple co-occurring disorders. To address this, we develop a\nnovel approach integrating synthetic patient electronic medical record (EMR)\nconstruction and multi-agent diagnostic dialogue generation. We create 502\nsynthetic EMRs for common comorbid conditions using a pipeline that ensures\nclinical relevance and diversity. Our multi-agent framework transfers the\nclinical interview protocol into a hierarchical state machine and context tree,\nsupporting over 130 diagnostic states while maintaining clinical standards.\nThrough this rigorous process, we construct PsyCoTalk, the first large-scale\ndialogue dataset supporting comorbidity, containing 3,000 multi-turn diagnostic\ndialogues validated by psychiatrists. This dataset enhances diagnostic accuracy\nand treatment planning, offering a valuable resource for psychiatric\ncomorbidity research. Compared to real-world clinical transcripts, PsyCoTalk\nexhibits high structural and linguistic fidelity in terms of dialogue length,\ntoken distribution, and diagnostic reasoning strategies. Licensed psychiatrists\nconfirm the realism and diagnostic validity of the dialogues. This dataset\nenables the development and evaluation of models capable of multi-disorder\npsychiatric screening in a single conversational pass.",
    "categories": [
      "cs.AI",
      "cs.CL"
    ],
    "published": "2025-10-29T07:18:43Z",
    "authors": [
      "Tianxi Wan",
      "Jiaming Luo",
      "Siyuan Chen",
      "Kunyao Lan",
      "Jianhua Chen",
      "Haiyang Geng",
      "Mengyue Wu"
    ],
    "pdf_url": "http://arxiv.org/pdf/2510.25232v1"
  },
  {
    "id": "2510.25228v1",
    "title": "Studies for : A Human-AI Co-Creative Sound Artwork Using a Real-time\n  Multi-channel Sound Generation Model",
    "abstract": "This paper explores the integration of AI technologies into the artistic\nworkflow through the creation of Studies for, a generative sound installation\ndeveloped in collaboration with sound artist Evala\n(https://www.ntticc.or.jp/en/archive/works/studies-for/). The installation\nemploys SpecMaskGIT, a lightweight yet high-quality sound generation AI model,\nto generate and playback eight-channel sound in real-time, creating an\nimmersive auditory experience over the course of a three-month exhibition. The\nwork is grounded in the concept of a \"new form of archive,\" which aims to\npreserve the artistic style of an artist while expanding beyond artists' past\nartworks by continued generation of new sound elements. This speculative\napproach to archival preservation is facilitated by training the AI model on a\ndataset consisting of over 200 hours of Evala's past sound artworks.\n  By addressing key requirements in the co-creation of art using AI, this study\nhighlights the value of the following aspects: (1) the necessity of integrating\nartist feedback, (2) datasets derived from an artist's past works, and (3)\nensuring the inclusion of unexpected, novel outputs. In Studies for, the model\nwas designed to reflect the artist's artistic identity while generating new,\npreviously unheard sounds, making it a fitting realization of the concept of \"a\nnew form of archive.\" We propose a Human-AI co-creation framework for\neffectively incorporating sound generation AI models into the sound art\ncreation process and suggest new possibilities for creating and archiving sound\nart that extend an artist's work beyond their physical existence. Demo page:\nhttps://sony.github.io/studies-for/",
    "categories": [
      "cs.SD",
      "cs.AI"
    ],
    "published": "2025-10-29T07:05:59Z",
    "authors": [
      "Chihiro Nagashima",
      "Akira Takahashi",
      "Zhi Zhong",
      "Shusuke Takahashi",
      "Yuki Mitsufuji"
    ],
    "pdf_url": "http://arxiv.org/pdf/2510.25228v1"
  },
  {
    "id": "2510.25226v1",
    "title": "Cost-Sensitive Unbiased Risk Estimation for Multi-Class\n  Positive-Unlabeled Learning",
    "abstract": "Positive--Unlabeled (PU) learning considers settings in which only positive\nand unlabeled data are available, while negatives are missing or left\nunlabeled. This situation is common in real applications where annotating\nreliable negatives is difficult or costly. Despite substantial progress in PU\nlearning, the multi-class case (MPU) remains challenging: many existing\napproaches do not ensure \\emph{unbiased risk estimation}, which limits\nperformance and stability. We propose a cost-sensitive multi-class PU method\nbased on \\emph{adaptive loss weighting}. Within the empirical risk minimization\nframework, we assign distinct, data-dependent weights to the positive and\n\\emph{inferred-negative} (from the unlabeled mixture) loss components so that\nthe resulting empirical objective is an unbiased estimator of the target risk.\nWe formalize the MPU data-generating process and establish a generalization\nerror bound for the proposed estimator. Extensive experiments on \\textbf{eight}\npublic datasets, spanning varying class priors and numbers of classes, show\nconsistent gains over strong baselines in both accuracy and stability.",
    "categories": [
      "cs.LG",
      "cs.AI"
    ],
    "published": "2025-10-29T07:01:32Z",
    "authors": [
      "Miao Zhang",
      "Junpeng Li",
      "Changchun Hua",
      "Yana Yang"
    ],
    "pdf_url": "http://arxiv.org/pdf/2510.25226v1"
  },
  {
    "id": "2510.25223v1",
    "title": "FELA: A Multi-Agent Evolutionary System for Feature Engineering of\n  Industrial Event Log Data",
    "abstract": "Event log data, recording fine-grained user actions and system events,\nrepresent one of the most valuable assets for modern digital services. However,\nthe complexity and heterogeneity of industrial event logs--characterized by\nlarge scale, high dimensionality, diverse data types, and intricate temporal or\nrelational structures--make feature engineering extremely challenging. Existing\nautomatic feature engineering approaches, such as AutoML or genetic methods,\noften suffer from limited explainability, rigid predefined operations, and poor\nadaptability to complicated heterogeneous data. In this paper, we propose FELA\n(Feature Engineering LLM Agents), a multi-agent evolutionary system that\nautonomously extracts meaningful and high-performing features from complex\nindustrial event log data. FELA integrates the reasoning and coding\ncapabilities of large language models (LLMs) with an insight-guided\nself-evolution paradigm. Specifically, FELA employs specialized agents--Idea\nAgents, Code Agents, and Critic Agents--to collaboratively generate, validate,\nand implement novel feature ideas. An Evaluation Agent summarizes feedback and\nupdates a hierarchical knowledge base and dual-memory system to enable\ncontinual improvement. Moreover, FELA introduces an agentic evolution\nalgorithm, combining reinforcement learning and genetic algorithm principles to\nbalance exploration and exploitation across the idea space. Extensive\nexperiments on real industrial datasets demonstrate that FELA can generate\nexplainable, domain-relevant features that significantly improve model\nperformance while reducing manual effort. Our results highlight the potential\nof LLM-based multi-agent systems as a general framework for automated,\ninterpretable, and adaptive feature engineering in complex real-world\nenvironments.",
    "categories": [
      "cs.AI"
    ],
    "published": "2025-10-29T06:57:32Z",
    "authors": [
      "Kun ouyang",
      "Haoyu Wang",
      "Dong Fang"
    ],
    "pdf_url": "http://arxiv.org/pdf/2510.25223v1"
  },
  {
    "id": "2510.25220v1",
    "title": "GReF: A Unified Generative Framework for Efficient Reranking via Ordered\n  Multi-token Prediction",
    "abstract": "In a multi-stage recommendation system, reranking plays a crucial role in\nmodeling intra-list correlations among items. A key challenge lies in exploring\noptimal sequences within the combinatorial space of permutations. Recent\nresearch follows a two-stage (generator-evaluator) paradigm, where a generator\nproduces multiple feasible sequences, and an evaluator selects the best one. In\npractice, the generator is typically implemented as an autoregressive model.\nHowever, these two-stage methods face two main challenges. First, the\nseparation of the generator and evaluator hinders end-to-end training. Second,\nautoregressive generators suffer from inference efficiency. In this work, we\npropose a Unified Generative Efficient Reranking Framework (GReF) to address\nthe two primary challenges. Specifically, we introduce Gen-Reranker, an\nautoregressive generator featuring a bidirectional encoder and a dynamic\nautoregressive decoder to generate causal reranking sequences. Subsequently, we\npre-train Gen-Reranker on the item exposure order for high-quality parameter\ninitialization. To eliminate the need for the evaluator while integrating\nsequence-level evaluation during training for end-to-end optimization, we\npropose post-training the model through Rerank-DPO. Moreover, for efficient\nautoregressive inference, we introduce ordered multi-token prediction (OMTP),\nwhich trains Gen-Reranker to simultaneously generate multiple future items\nwhile preserving their order, ensuring practical deployment in real-time\nrecommender systems. Extensive offline experiments demonstrate that GReF\noutperforms state-of-the-art reranking methods while achieving latency that is\nnearly comparable to non-autoregressive models. Additionally, GReF has also\nbeen deployed in a real-world video app Kuaishou with over 300 million daily\nactive users, significantly improving online recommendation quality.",
    "categories": [
      "cs.IR",
      "cs.AI",
      "cs.LG"
    ],
    "published": "2025-10-29T06:54:42Z",
    "authors": [
      "Zhijie Lin",
      "Zhuofeng Li",
      "Chenglei Dai",
      "Wentian Bao",
      "Shuai Lin",
      "Enyun Yu",
      "Haoxiang Zhang",
      "Liang Zhao"
    ],
    "pdf_url": "http://arxiv.org/pdf/2510.25220v1"
  },
  {
    "id": "2510.25218v1",
    "title": "Human Resilience in the AI Era -- What Machines Can't Replace",
    "abstract": "AI is displacing tasks, mediating high-stakes decisions, and flooding\ncommunication with synthetic content, unsettling work, identity, and social\ntrust. We argue that the decisive human countermeasure is resilience. We define\nresilience across three layers: psychological, including emotion regulation,\nmeaning-making, cognitive flexibility; social, including trust, social capital,\ncoordinated response; organizational, including psychological safety, feedback\nmechanisms, and graceful degradation. We synthesize early evidence that these\ncapacities buffer individual strain, reduce burnout through social support, and\nlower silent failure in AI-mediated workflows through team norms and\nrisk-responsive governance. We also show that resilience can be cultivated\nthrough training that complements rather than substitutes for structural\nsafeguards. By reframing the AI debate around actionable human resilience, this\narticle offers policymakers, educators, and operators a practical lens to\npreserve human agency and steer responsible adoption.",
    "categories": [
      "cs.CY",
      "cs.AI"
    ],
    "published": "2025-10-29T06:48:19Z",
    "authors": [
      "Shaoshan Liu",
      "Anina Schwarzenbach",
      "Yiyu Shi"
    ],
    "pdf_url": "http://arxiv.org/pdf/2510.25218v1"
  },
  {
    "id": "2510.25206v1",
    "title": "RAVR: Reference-Answer-guided Variational Reasoning for Large Language\n  Models",
    "abstract": "Reinforcement learning (RL) can refine the reasoning abilities of large\nlanguage models (LLMs), but critically depends on a key prerequisite: the LLM\ncan already generate high-utility reasoning paths with non-negligible\nprobability. For tasks beyond the LLM's current competence, such reasoning path\ncan be hard to sample, and learning risks reinforcing familiar but suboptimal\nreasoning. We are motivated by the insight from cognitive science that Why is\nthis the answer is often an easier question than What is the answer, as it\navoids the heavy cognitive load of open-ended exploration, opting instead for\nexplanatory reconstruction-systematically retracing the reasoning that links a\nquestion to its answer. We show that LLMs can similarly leverage answers to\nderive high-quality reasoning paths. We formalize this phenomenon and prove\nthat conditioning on answer provably increases the expected utility of sampled\nreasoning paths, thereby transforming intractable problems into learnable ones.\nBuilding on this insight, we introduce RAVR (Reference-Answer-guided\nVariational Reasoning), an end-to-end framework that uses answer-conditioned\nreasoning as a variational surrogate for question-only reasoning. Experiments\nin both general and math domains demonstrate consistent improvements over\nstrong baselines. We further analyze the reasoning behavior and find that RAVR\nreduces hesitation, strengthens conclusion consolidation, and promotes\nproblem-specific strategies in reasoning.",
    "categories": [
      "cs.AI",
      "cs.CL",
      "cs.LG",
      "I.2.7"
    ],
    "published": "2025-10-29T06:18:37Z",
    "authors": [
      "Tianqianjin Lin",
      "Xi Zhao",
      "Xingyao Zhang",
      "Rujiao Long",
      "Yi Xu",
      "Zhuoren Jiang",
      "Wenbo Su",
      "Bo Zheng"
    ],
    "pdf_url": "http://arxiv.org/pdf/2510.25206v1"
  },
  {
    "id": "2510.25205v1",
    "title": "Energy-Efficient Autonomous Driving with Adaptive Perception and Robust\n  Decision",
    "abstract": "Autonomous driving is an emerging technology that is expected to bring\nsignificant social, economic, and environmental benefits. However, these\nbenefits come with rising energy consumption by computation engines, limiting\nthe driving range of vehicles, especially electric ones. Perception computing\nis typically the most power-intensive component, as it relies on largescale\ndeep learning models to extract environmental features. Recently, numerous\nstudies have employed model compression techniques, such as sparsification,\nquantization, and distillation, to reduce computational consumption. However,\nthese methods often result in either a substantial model size or a significant\ndrop in perception accuracy compared to high-computation models. To address\nthese challenges, we propose an energy-efficient autonomous driving framework,\ncalled EneAD. In the adaptive perception module, a perception optimization\nstrategy is designed from the perspective of data management and tuning.\nFirstly, we manage multiple perception models with different computational\nconsumption and adjust the execution framerate dynamically. Then, we define\nthem as knobs and design a transferable tuning method based on Bayesian\noptimization to identify promising knob values that achieve low computation\nwhile maintaining desired accuracy. To adaptively switch the knob values in\nvarious traffic scenarios, a lightweight classification model is proposed to\ndistinguish the perception difficulty in different scenarios. In the robust\ndecision module, we propose a decision model based on reinforcement learning\nand design a regularization term to enhance driving stability in the face of\nperturbed perception results. Extensive experiments evidence the superiority of\nour framework in both energy consumption and driving performance. EneAD can\nreduce perception consumption by 1.9x to 3.5x and thus improve driving range by\n3.9% to 8.5%",
    "categories": [
      "cs.AI"
    ],
    "published": "2025-10-29T06:18:15Z",
    "authors": [
      "Yuyang Xia",
      "Zibo Liang",
      "Liwei Deng",
      "Yan Zhao",
      "Han Su",
      "Kai Zheng"
    ],
    "pdf_url": "http://arxiv.org/pdf/2510.25205v1"
  },
  {
    "id": "2510.25181v1",
    "title": "Fed-PELAD: Communication-Efficient Federated Learning for Massive MIMO\n  CSI Feedback with Personalized Encoders and a LoRA-Adapted Shared Decoder",
    "abstract": "This paper addresses the critical challenges of communication overhead, data\nheterogeneity, and privacy in deep learning for channel state information (CSI)\nfeedback in massive MIMO systems. To this end, we propose Fed-PELAD, a novel\nfederated learning framework that incorporates personalized encoders and a\nLoRA-adapted shared decoder. Specifically, personalized encoders are trained\nlocally on each user equipment (UE) to capture device-specific channel\ncharacteristics, while a shared decoder is updated globally via the\ncoordination of the base station (BS) by using Low-Rank Adaptation (LoRA). This\ndesign ensures that only compact LoRA adapter parameters instead of full model\nupdates are transmitted for aggregation. To further enhance convergence\nstability, we introduce an alternating freezing strategy with calibrated\nlearning-rate ratio during LoRA aggregation. Extensive simulations on\n3GPP-standard channel models demonstrate that Fed-PELAD requires only 42.97\\%\nof the uplink communication cost compared to conventional methods while\nachieving a performance gain of 1.2 dB in CSI feedback accuracy under\nheterogeneous conditions.",
    "categories": [
      "cs.IT",
      "cs.AI",
      "math.IT"
    ],
    "published": "2025-10-29T05:24:21Z",
    "authors": [
      "Yixiang Zhou",
      "Tong Wu",
      "Meixia Tao",
      "Jianhua Mo"
    ],
    "pdf_url": "http://arxiv.org/pdf/2510.25181v1"
  },
  {
    "id": "2510.25179v1",
    "title": "Agentic Moderation: Multi-Agent Design for Safer Vision-Language Models",
    "abstract": "Agentic methods have emerged as a powerful and autonomous paradigm that\nenhances reasoning, collaboration, and adaptive control, enabling systems to\ncoordinate and independently solve complex tasks. We extend this paradigm to\nsafety alignment by introducing Agentic Moderation, a model-agnostic framework\nthat leverages specialised agents to defend multimodal systems against\njailbreak attacks. Unlike prior approaches that apply as a static layer over\ninputs or outputs and provide only binary classifications (safe or unsafe), our\nmethod integrates dynamic, cooperative agents, including Shield, Responder,\nEvaluator, and Reflector, to achieve context-aware and interpretable\nmoderation. Extensive experiments across five datasets and four representative\nLarge Vision-Language Models (LVLMs) demonstrate that our approach reduces the\nAttack Success Rate (ASR) by 7-19%, maintains a stable Non-Following Rate (NF),\nand improves the Refusal Rate (RR) by 4-20%, achieving robust, interpretable,\nand well-balanced safety performance. By harnessing the flexibility and\nreasoning capacity of agentic architectures, Agentic Moderation provides\nmodular, scalable, and fine-grained safety enforcement, highlighting the\nbroader potential of agentic systems as a foundation for automated safety\ngovernance.",
    "categories": [
      "cs.AI"
    ],
    "published": "2025-10-29T05:23:24Z",
    "authors": [
      "Juan Ren",
      "Mark Dras",
      "Usman Naseem"
    ],
    "pdf_url": "http://arxiv.org/pdf/2510.25179v1"
  },
  {
    "id": "2510.25164v1",
    "title": "Transformers in Medicine: Improving Vision-Language Alignment for\n  Medical Image Captioning",
    "abstract": "We present a transformer-based multimodal framework for generating clinically\nrelevant captions for MRI scans. Our system combines a DEiT-Small vision\ntransformer as an image encoder, MediCareBERT for caption embedding, and a\ncustom LSTM-based decoder. The architecture is designed to semantically align\nimage and textual embeddings, using hybrid cosine-MSE loss and contrastive\ninference via vector similarity. We benchmark our method on the MultiCaRe\ndataset, comparing performance on filtered brain-only MRIs versus general MRI\nimages against state-of-the-art medical image captioning methods including\nBLIP, R2GenGPT, and recent transformer-based approaches. Results show that\nfocusing on domain-specific data improves caption accuracy and semantic\nalignment. Our work proposes a scalable, interpretable solution for automated\nmedical image reporting.",
    "categories": [
      "eess.IV",
      "cs.AI",
      "cs.CV"
    ],
    "published": "2025-10-29T04:49:20Z",
    "authors": [
      "Yogesh Thakku Suresh",
      "Vishwajeet Shivaji Hogale",
      "Luca-Alexandru Zamfira",
      "Anandavardhana Hegde"
    ],
    "pdf_url": "http://arxiv.org/pdf/2510.25164v1"
  },
  {
    "id": "2510.25160v2",
    "title": "Model-Document Protocol for AI Search",
    "abstract": "AI search depends on linking large language models (LLMs) with vast external\nknowledge sources. Yet web pages, PDF files, and other raw documents are not\ninherently LLM-ready: they are long, noisy, and unstructured. Conventional\nretrieval methods treat these documents as verbatim text and return raw\npassages, leaving the burden of fragment assembly and contextual reasoning to\nthe LLM. This gap underscores the need for a new retrieval paradigm that\nredefines how models interact with documents.\n  We introduce the Model-Document Protocol (MDP), a general framework that\nformalizes how raw text is bridged to LLMs through consumable knowledge\nrepresentations. Rather than treating retrieval as passage fetching, MDP\ndefines multiple pathways that transform unstructured documents into\ntask-specific, LLM-ready inputs. These include agentic reasoning, which curates\nraw evidence into coherent context; memory grounding, which accumulates\nreusable notes to enrich reasoning; and structured leveraging, which encodes\ndocuments into formal representations such as graphs or key-value caches. All\nthree pathways share the same goal: ensuring that what reaches the LLM is not\nraw fragments but compact, structured knowledge directly consumable for\nreasoning.\n  As an instantiation, we present MDP-Agent, which realizes the protocol\nthrough an agentic process: constructing document-level gist memories for\nglobal coverage, performing diffusion-based exploration with vertical\nexploitation to uncover layered dependencies, and applying map-reduce style\nsynthesis to integrate large-scale evidence into compact yet sufficient\ncontext. Experiments on information-seeking benchmarks demonstrate that\nMDP-Agent outperforms baselines, validating both the soundness of the MDP\nframework and the effectiveness of its agentic instantiation.",
    "categories": [
      "cs.CL",
      "cs.AI",
      "cs.IR"
    ],
    "published": "2025-10-29T04:29:17Z",
    "authors": [
      "Hongjin Qian",
      "Zheng Liu"
    ],
    "pdf_url": "http://arxiv.org/pdf/2510.25160v2"
  },
  {
    "id": "2510.25801v1",
    "title": "Metis-SPECS: Decoupling Multimodal Learning via Self-distilled\n  Preference-based Cold Start",
    "abstract": "Reinforcement learning (RL) with verifiable rewards has recently catalyzed a\nwave of \"MLLM-r1\" approaches that bring RL to vision language models. Most\nrepresentative paradigms begin with a cold start, typically employing\nsupervised fine-tuning (SFT), to initialize the policy before RL. However,\nSFT-based cold start adopts the reasoning paradigm intertwined with task\nsolution and output format, which may induce instruction-style overfitting,\nweakens out-of-distribution generalization, and ultimately affects downstream\nRL. We revisit the cold start along two views, its training method and data\nconstruction, and introduce the Generalization Factor (GF) coefficient to\nquantify the generalization capability under different methods. Our empirical\nstudy finds that preference-based training methods (e.g. DPO) generalizes\nbetter than SFT-based methods in cold start. Motivated by this, we propose\nSPECS-a Self-distilled, Preference-based Cold Start framework that decouples\nmultimodal learning: (1) generates introspective preference data pairs via\nself-distillation, avoiding reliance on larger teachers or manual annotation;\n(2) performs preference-based training to learn, focusing on shallow,\ntransferable surface-form criteria (format, structure, style) rather than\nmemorizing content; and (3) hands off to RL with verifiable rewards for deep\nreasoning results. Experimental results across multiple multimodal benchmarks\nshow that our decoupling learning framework yields consistent performance gains\nover strong baselines, improving MEGA-Bench by 4.1% and MathVista by 12.2%.\nAdditional experiments indicate that SPECS contributes to reducing\nin-distribution \"stuckness,\" improving exploration, stabilizing training, and\nraising the performance ceiling.",
    "categories": [
      "cs.LG",
      "cs.AI",
      "cs.CL",
      "cs.CV"
    ],
    "published": "2025-10-29T03:42:23Z",
    "authors": [
      "Kun Chen",
      "Peng Shi",
      "Haibo Qiu",
      "Zhixiong Zeng",
      "Siqi Yang",
      "Wenji Mao",
      "Lin Ma"
    ],
    "pdf_url": "http://arxiv.org/pdf/2510.25801v1"
  },
  {
    "id": "2510.25140v1",
    "title": "DINO-YOLO: Self-Supervised Pre-training for Data-Efficient Object\n  Detection in Civil Engineering Applications",
    "abstract": "Object detection in civil engineering applications is constrained by limited\nannotated data in specialized domains. We introduce DINO-YOLO, a hybrid\narchitecture combining YOLOv12 with DINOv3 self-supervised vision transformers\nfor data-efficient detection. DINOv3 features are strategically integrated at\ntwo locations: input preprocessing (P0) and mid-backbone enhancement (P3).\nExperimental validation demonstrates substantial improvements: Tunnel Segment\nCrack detection (648 images) achieves 12.4% improvement, Construction PPE (1K\nimages) gains 13.7%, and KITTI (7K images) shows 88.6% improvement, while\nmaintaining real-time inference (30-47 FPS). Systematic ablation across five\nYOLO scales and nine DINOv3 variants reveals that Medium-scale architectures\nachieve optimal performance with DualP0P3 integration (55.77% mAP@0.5), while\nSmall-scale requires Triple Integration (53.63%). The 2-4x inference overhead\n(21-33ms versus 8-16ms baseline) remains acceptable for field deployment on\nNVIDIA RTX 5090. DINO-YOLO establishes state-of-the-art performance for civil\nengineering datasets (<10K images) while preserving computational efficiency,\nproviding practical solutions for construction safety monitoring and\ninfrastructure inspection in data-constrained environments.",
    "categories": [
      "cs.CV",
      "cs.AI"
    ],
    "published": "2025-10-29T03:40:40Z",
    "authors": [
      "Malaisree P",
      "Youwai S",
      "Kitkobsin T",
      "Janrungautai S",
      "Amorndechaphon D",
      "Rojanavasu P"
    ],
    "pdf_url": "http://arxiv.org/pdf/2510.25140v1"
  },
  {
    "id": "2510.25130v1",
    "title": "Lipschitz-aware Linearity Grafting for Certified Robustness",
    "abstract": "Lipschitz constant is a fundamental property in certified robustness, as\nsmaller values imply robustness to adversarial examples when a model is\nconfident in its prediction. However, identifying the worst-case adversarial\nexamples is known to be an NP-complete problem. Although over-approximation\nmethods have shown success in neural network verification to address this\nchallenge, reducing approximation errors remains a significant obstacle.\nFurthermore, these approximation errors hinder the ability to obtain tight\nlocal Lipschitz constants, which are crucial for certified robustness.\nOriginally, grafting linearity into non-linear activation functions was\nproposed to reduce the number of unstable neurons, enabling scalable and\ncomplete verification. However, no prior theoretical analysis has explained how\nlinearity grafting improves certified robustness. We instead consider linearity\ngrafting primarily as a means of eliminating approximation errors rather than\nreducing the number of unstable neurons, since linear functions do not require\nrelaxation. In this paper, we provide two theoretical contributions: 1) why\nlinearity grafting improves certified robustness through the lens of the\n$l_\\infty$ local Lipschitz constant, and 2) grafting linearity into non-linear\nactivation functions, the dominant source of approximation errors, yields a\ntighter local Lipschitz constant. Based on these theoretical contributions, we\npropose a Lipschitz-aware linearity grafting method that removes dominant\napproximation errors, which are crucial for tightening the local Lipschitz\nconstant, thereby improving certified robustness, even without certified\ntraining. Our extensive experiments demonstrate that grafting linearity into\nthese influential activations tightens the $l_\\infty$ local Lipschitz constant\nand enhances certified robustness.",
    "categories": [
      "cs.LG",
      "cs.AI"
    ],
    "published": "2025-10-29T03:19:55Z",
    "authors": [
      "Yongjin Han",
      "Suhyun Kim"
    ],
    "pdf_url": "http://arxiv.org/pdf/2510.25130v1"
  },
  {
    "id": "2510.25798v1",
    "title": "MemEIC: A Step Toward Continual and Compositional Knowledge Editing",
    "abstract": "The dynamic nature of information necessitates continuously updating large\nvision-language models (LVLMs). While recent knowledge editing techniques hint\nat promising directions, they often focus on editing a single modality (vision\nor language) in isolation. This prevalent practice neglects the inherent\nmultimodality of LVLMs and the continuous nature of knowledge updates,\npotentially leading to suboptimal editing outcomes when considering the\ninterplay between modalities and the need for ongoing knowledge refinement. To\naddress these limitations, we propose MemEIC, a novel method for Continual and\nCompositional Knowledge Editing (CCKE) in LVLMs. MemEIC enables compositional\nediting of both visual and textual knowledge sequentially. Our approach employs\na hybrid external-internal editor featuring a dual external memory for\ncross-modal evidence retrieval and dual LoRA adapters that facilitate\ndisentangled parameter updates for each modality. A key component is a\nbrain-inspired knowledge connector, activated selectively for compositional\nreasoning, that integrates information across different modalities. Experiments\ndemonstrate that MemEIC significantly improves performance on complex\nmultimodal questions and effectively preserves prior edits, setting a new\nbenchmark for CCKE in LVLMs.",
    "categories": [
      "cs.LG",
      "cs.AI",
      "cs.CL"
    ],
    "published": "2025-10-29T03:11:59Z",
    "authors": [
      "Jin Seong",
      "Jiyun Park",
      "Wencke Liermann",
      "Hongseok Choi",
      "Yoonji Nam",
      "Hyun Kim",
      "Soojong Lim",
      "Namhoon Lee"
    ],
    "pdf_url": "http://arxiv.org/pdf/2510.25798v1"
  },
  {
    "id": "2510.25126v1",
    "title": "Bridging the Divide: End-to-End Sequence-Graph Learning",
    "abstract": "Many real-world datasets are both sequential and relational: each node\ncarries an event sequence while edges encode interactions. Existing methods in\nsequence modeling and graph modeling often neglect one modality or the other.\nWe argue that sequences and graphs are not separate problems but complementary\nfacets of the same dataset, and should be learned jointly. We introduce BRIDGE,\na unified end-to-end architecture that couples a sequence encoder with a GNN\nunder a single objective, allowing gradients to flow across both modules and\nlearning task-aligned representations. To enable fine-grained token-level\nmessage passing among neighbors, we add TOKENXATTN, a token-level\ncross-attention layer that passes messages between events in neighboring\nsequences. Across two settings, friendship prediction (Brightkite) and fraud\ndetection (Amazon), BRIDGE consistently outperforms static GNNs, temporal graph\nmethods, and sequence-only baselines on ranking and classification metrics.",
    "categories": [
      "cs.LG",
      "cs.AI"
    ],
    "published": "2025-10-29T03:06:54Z",
    "authors": [
      "Yuen Chen",
      "Yulun Wu",
      "Samuel Sharpe",
      "Igor Melnyk",
      "Nam H. Nguyen",
      "Furong Huang",
      "C. Bayan Bruss",
      "Rizal Fathony"
    ],
    "pdf_url": "http://arxiv.org/pdf/2510.25126v1"
  },
  {
    "id": "2510.25123v1",
    "title": "Learning Low Rank Neural Representations of Hyperbolic Wave Dynamics\n  from Data",
    "abstract": "We present a data-driven dimensionality reduction method that is well-suited\nfor physics-based data representing hyperbolic wave propagation. The method\nutilizes a specialized neural network architecture called low rank neural\nrepresentation (LRNR) inside a hypernetwork framework. The architecture is\nmotivated by theoretical results that rigorously prove the existence of\nefficient representations for this wave class. We illustrate through archetypal\nexamples that such an efficient low-dimensional representation of propagating\nwaves can be learned directly from data through a combination of deep learning\ntechniques. We observe that a low rank tensor representation arises naturally\nin the trained LRNRs, and that this reveals a new decomposition of wave\npropagation where each decomposed mode corresponds to interpretable physical\nfeatures. Furthermore, we demonstrate that the LRNR architecture enables\nefficient inference via a compression scheme, which is a potentially important\nfeature when deploying LRNRs in demanding performance regimes.",
    "categories": [
      "cs.LG",
      "cs.AI",
      "cs.NA",
      "math.NA",
      "68T07, 65D25, 65M22"
    ],
    "published": "2025-10-29T03:01:09Z",
    "authors": [
      "Woojin Cho",
      "Kookjin Lee",
      "Noseong Park",
      "Donsub Rim",
      "Gerrit Welper"
    ],
    "pdf_url": "http://arxiv.org/pdf/2510.25123v1"
  },
  {
    "id": "2510.25113v1",
    "title": "The Neural Differential Manifold: An Architecture with Explicit\n  Geometric Structure",
    "abstract": "This paper introduces the Neural Differential Manifold (NDM), a novel neural\nnetwork architecture that explicitly incorporates geometric structure into its\nfundamental design. Departing from conventional Euclidean parameter spaces, the\nNDM re-conceptualizes a neural network as a differentiable manifold where each\nlayer functions as a local coordinate chart, and the network parameters\ndirectly parameterize a Riemannian metric tensor at every point. The\narchitecture is organized into three synergistic layers: a Coordinate Layer\nimplementing smooth chart transitions via invertible transformations inspired\nby normalizing flows, a Geometric Layer that dynamically generates the\nmanifold's metric through auxiliary sub-networks, and an Evolution Layer that\noptimizes both task performance and geometric simplicity through a\ndual-objective loss function. This geometric regularization penalizes excessive\ncurvature and volume distortion, providing intrinsic regularization that\nenhances generalization and robustness. The framework enables natural gradient\ndescent optimization aligned with the learned manifold geometry and offers\nunprecedented interpretability by endowing internal representations with clear\ngeometric meaning. We analyze the theoretical advantages of this approach,\nincluding its potential for more efficient optimization, enhanced continual\nlearning, and applications in scientific discovery and controllable generative\nmodeling. While significant computational challenges remain, the Neural\nDifferential Manifold represents a fundamental shift towards geometrically\nstructured, interpretable, and efficient deep learning systems.",
    "categories": [
      "cs.LG",
      "cs.AI",
      "math.DG",
      "math.OC",
      "68T07, 62B11, 53B21, 65D18",
      "I.2.6; I.5.1; G.1.6; G.3"
    ],
    "published": "2025-10-29T02:24:27Z",
    "authors": [
      "Di Zhang"
    ],
    "pdf_url": "http://arxiv.org/pdf/2510.25113v1"
  },
  {
    "id": "2510.25101v1",
    "title": "KnowCoder-A1: Incentivizing Agentic Reasoning Capability with Outcome\n  Supervision for KBQA",
    "abstract": "Knowledge Base Question Answering (KBQA) aims to answer natural-language\nquestions over a structured Knowledge Base (KB). Recent work improves KBQA by\nadopting an agentic reasoning paradigm, in which Large Language Models (LLMs)\niteratively decompose a question, generate its corresponding logical queries,\nand interact with the KB to derive the answer. However, these methods typically\nfine-tune LLMs on reasoning trajectories synthesized via process supervision,\nwhich offers weak incentives for exploration and thus fails to strengthen the\nagentic reasoning ability. In this paper, we propose KnowCoder-A1, an LLM that\ncan autonomously perform agentic reasoning on KBs to obtain answers. To\nincentivize autonomous exploration, KnowCoder-A1 trains the LLM under\noutcome-only supervision via a multi-stage curriculum reinforcement learning\nwith an easy-to-hard curriculum. To establish foundational agentic\ncapabilities, KnowCoder-A1 first fine-tunes the LLM on a small set of\nhigh-quality trajectories obtained through outcome-based rejection sampling.\nThen, to alleviate the reward sparsity inherent in outcome-only supervision, it\napplies multi-stage curriculum RL with reward schedules that progress from easy\nto hard. Trained with outcome-only supervision, KnowCoder-A1 exhibits powerful\nreasoning behaviors and consistently outperforms prior approaches across three\nmainstream datasets. Notably, on the zero-shot subset of GrailQA, KnowCoder-A1\nachieves up to an 11.1% relative improvement while using only one-twelfth of\nthe training data, demonstrating strong agentic reasoning capabilities.",
    "categories": [
      "cs.AI",
      "cs.CL"
    ],
    "published": "2025-10-29T02:12:18Z",
    "authors": [
      "Zhuo Chen",
      "Fei Wang",
      "Zixuan Li",
      "Zhao Zhang",
      "Weiwei Ding",
      "Chuanguang Yang",
      "Yongjun Xu",
      "Xiaolong Jin",
      "Jiafeng Guo"
    ],
    "pdf_url": "http://arxiv.org/pdf/2510.25101v1"
  },
  {
    "id": "2510.25096v1",
    "title": "Learning Fair Graph Representations with Multi-view Information\n  Bottleneck",
    "abstract": "Graph neural networks (GNNs) excel on relational data by passing messages\nover node features and structure, but they can amplify training data biases,\npropagating discriminatory attributes and structural imbalances into unfair\noutcomes. Many fairness methods treat bias as a single source, ignoring\ndistinct attribute and structure effects and leading to suboptimal fairness and\nutility trade-offs. To overcome this challenge, we propose FairMIB, a\nmulti-view information bottleneck framework designed to decompose graphs into\nfeature, structural, and diffusion views for mitigating complexity biases in\nGNNs. Especially, the proposed FairMIB employs contrastive learning to maximize\ncross-view mutual information for bias-free representation learning. It further\nintegrates multi-perspective conditional information bottleneck objectives to\nbalance task utility and fairness by minimizing mutual information with\nsensitive attributes. Additionally, FairMIB introduces an inverse\nprobability-weighted (IPW) adjacency correction in the diffusion view, which\nreduces the spread of bias propagation during message passing. Experiments on\nfive real-world benchmark datasets demonstrate that FairMIB achieves\nstate-of-the-art performance across both utility and fairness metrics.",
    "categories": [
      "cs.LG",
      "cs.AI"
    ],
    "published": "2025-10-29T02:02:12Z",
    "authors": [
      "Chuxun Liu",
      "Debo Cheng",
      "Qingfeng Chen",
      "Jiangzhang Gan",
      "Jiuyong Li",
      "Lin Liu"
    ],
    "pdf_url": "http://arxiv.org/pdf/2510.25096v1"
  },
  {
    "id": "2510.25091v1",
    "title": "H3M-SSMoEs: Hypergraph-based Multimodal Learning with LLM Reasoning and\n  Style-Structured Mixture of Experts",
    "abstract": "Stock movement prediction remains fundamentally challenging due to complex\ntemporal dependencies, heterogeneous modalities, and dynamically evolving\ninter-stock relationships. Existing approaches often fail to unify structural,\nsemantic, and regime-adaptive modeling within a scalable framework. This work\nintroduces H3M-SSMoEs, a novel Hypergraph-based MultiModal architecture with\nLLM reasoning and Style-Structured Mixture of Experts, integrating three key\ninnovations: (1) a Multi-Context Multimodal Hypergraph that hierarchically\ncaptures fine-grained spatiotemporal dynamics via a Local Context Hypergraph\n(LCH) and persistent inter-stock dependencies through a Global Context\nHypergraph (GCH), employing shared cross-modal hyperedges and Jensen-Shannon\nDivergence weighting mechanism for adaptive relational learning and cross-modal\nalignment; (2) a LLM-enhanced reasoning module, which leverages a frozen large\nlanguage model with lightweight adapters to semantically fuse and align\nquantitative and textual modalities, enriching representations with\ndomain-specific financial knowledge; and (3) a Style-Structured Mixture of\nExperts (SSMoEs) that combines shared market experts and industry-specialized\nexperts, each parameterized by learnable style vectors enabling regime-aware\nspecialization under sparse activation. Extensive experiments on three major\nstock markets demonstrate that H3M-SSMoEs surpasses state-of-the-art methods in\nboth superior predictive accuracy and investment performance, while exhibiting\neffective risk control. Datasets, source code, and model weights are available\nat our GitHub repository: https://github.com/PeilinTime/H3M-SSMoEs.",
    "categories": [
      "cs.AI"
    ],
    "published": "2025-10-29T01:54:52Z",
    "authors": [
      "Peilin Tan",
      "Liang Xie",
      "Churan Zhi",
      "Dian Tu",
      "Chuanqi Shi"
    ],
    "pdf_url": "http://arxiv.org/pdf/2510.25091v1"
  },
  {
    "id": "2510.25080v2",
    "title": "Monopoly Deal: A Benchmark Environment for Bounded One-Sided Response\n  Games",
    "abstract": "Card games are widely used to study sequential decision-making under\nuncertainty, with real-world analogues in negotiation, finance, and\ncybersecurity. These games typically fall into three categories based on the\nflow of control: strictly sequential (players alternate single actions),\ndeterministic response (some actions trigger a fixed outcome), and unbounded\nreciprocal response (alternating counterplays are permitted). A less-explored\nbut strategically rich structure is the bounded one-sided response, where a\nplayer's action briefly transfers control to the opponent, who must satisfy a\nfixed condition through one or more moves before the turn resolves. We term\ngames featuring this mechanism Bounded One-Sided Response Games (BORGs). We\nintroduce a modified version of Monopoly Deal as a benchmark environment that\nisolates this dynamic, where a Rent action forces the opponent to choose\npayment assets. The gold-standard algorithm, Counterfactual Regret Minimization\n(CFR), converges on effective strategies without novel algorithmic extensions.\nA lightweight full-stack research platform unifies the environment, a\nparallelized CFR runtime, and a human-playable web interface. The trained CFR\nagent and source code are available at https://monopolydeal.ai.",
    "categories": [
      "cs.GT",
      "cs.AI",
      "cs.LG"
    ],
    "published": "2025-10-29T01:38:19Z",
    "authors": [
      "Will Wolf"
    ],
    "pdf_url": "http://arxiv.org/pdf/2510.25080v2"
  },
  {
    "id": "2510.25065v1",
    "title": "Reasoning-Aware GRPO using Process Mining",
    "abstract": "Reinforcement learning (RL)-based post-training has been crucial for enabling\nmulti-step reasoning in large reasoning models (LRMs), yet current reward\nschemes are typically outcome-centric. We propose PM4GRPO, a reasoning-aware\nGroup Relative Policy Optimization (GRPO) that augments standard answer/format\nrewards with signals over the reasoning procedure. To this end, process mining\ntechniques are utilized to compute a scalar conformance reward that measures\nhow closely a policy model's reasoning aligns with the pretrained teacher\nmodel. The empirical results on five benchmarks demonstrate that PM4GRPO\nsignificantly outperforms existing methodologies for GRPO-based post-training.\nThese results highlight that leveraging process mining for reasoning-aware GRPO\neffectively enhances the reasoning capabilities of policy models.",
    "categories": [
      "cs.AI"
    ],
    "published": "2025-10-29T01:07:45Z",
    "authors": [
      "Taekhyun Park",
      "Yongjae Lee",
      "Hyerim Bae"
    ],
    "pdf_url": "http://arxiv.org/pdf/2510.25065v1"
  },
  {
    "id": "2510.25055v1",
    "title": "GAPMAP: Mapping Scientific Knowledge Gaps in Biomedical Literature Using\n  Large Language Models",
    "abstract": "Scientific progress is driven by the deliberate articulation of what remains\nunknown. This study investigates the ability of large language models (LLMs) to\nidentify research knowledge gaps in the biomedical literature. We define two\ncategories of knowledge gaps: explicit gaps, clear declarations of missing\nknowledge; and implicit gaps, context-inferred missing knowledge. While prior\nwork has focused mainly on explicit gap detection, we extend this line of\nresearch by addressing the novel task of inferring implicit gaps. We conducted\ntwo experiments on almost 1500 documents across four datasets, including a\nmanually annotated corpus of biomedical articles. We benchmarked both\nclosed-weight models (from OpenAI) and open-weight models (Llama and Gemma 2)\nunder paragraph-level and full-paper settings. To address the reasoning of\nimplicit gaps inference, we introduce \\textbf{\\small TABI}, a Toulmin-Abductive\nBucketed Inference scheme that structures reasoning and buckets inferred\nconclusion candidates for validation. Our results highlight the robust\ncapability of LLMs in identifying both explicit and implicit knowledge gaps.\nThis is true for both open- and closed-weight models, with larger variants\noften performing better. This suggests a strong ability of LLMs for\nsystematically identifying candidate knowledge gaps, which can support\nearly-stage research formulation, policymakers, and funding decisions. We also\nreport observed failure modes and outline directions for robust deployment,\nincluding domain adaptation, human-in-the-loop verification, and benchmarking\nacross open- and closed-weight models.",
    "categories": [
      "cs.CL",
      "cs.AI",
      "cs.LG"
    ],
    "published": "2025-10-29T00:46:45Z",
    "authors": [
      "Nourah M Salem",
      "Elizabeth White",
      "Michael Bada",
      "Lawrence Hunter"
    ],
    "pdf_url": "http://arxiv.org/pdf/2510.25055v1"
  },
  {
    "id": "2510.25053v1",
    "title": "Scalable predictive processing framework for multitask caregiving robots",
    "abstract": "The rapid aging of societies is intensifying demand for autonomous care\nrobots; however, most existing systems are task-specific and rely on\nhandcrafted preprocessing, limiting their ability to generalize across diverse\nscenarios. A prevailing theory in cognitive neuroscience proposes that the\nhuman brain operates through hierarchical predictive processing, which\nunderlies flexible cognition and behavior by integrating multimodal sensory\nsignals. Inspired by this principle, we introduce a hierarchical multimodal\nrecurrent neural network grounded in predictive processing under the\nfree-energy principle, capable of directly integrating over 30,000-dimensional\nvisuo-proprioceptive inputs without dimensionality reduction. The model was\nable to learn two representative caregiving tasks, rigid-body repositioning and\nflexible-towel wiping, without task-specific feature engineering. We\ndemonstrate three key properties: (i) self-organization of hierarchical latent\ndynamics that regulate task transitions, capture variability in uncertainty,\nand infer occluded states; (ii) robustness to degraded vision through\nvisuo-proprioceptive integration; and (iii) asymmetric interference in\nmultitask learning, where the more variable wiping task had little influence on\nrepositioning, whereas learning the repositioning task led to a modest\nreduction in wiping performance, while the model maintained overall robustness.\nAlthough the evaluation was limited to simulation, these results establish\npredictive processing as a universal and scalable computational principle,\npointing toward robust, flexible, and autonomous caregiving robots while\noffering theoretical insight into the human brain's ability to achieve flexible\nadaptation in uncertain real-world environments.",
    "categories": [
      "cs.RO",
      "cs.AI",
      "cs.LG",
      "q-bio.NC"
    ],
    "published": "2025-10-29T00:39:09Z",
    "authors": [
      "Hayato Idei",
      "Tamon Miyake",
      "Tetsuya Ogata",
      "Yuichi Yamashita"
    ],
    "pdf_url": "http://arxiv.org/pdf/2510.25053v1"
  },
  {
    "id": "2510.25796v1",
    "title": "Non-myopic Matching and Rebalancing in Large-Scale On-Demand\n  Ride-Pooling Systems Using Simulation-Informed Reinforcement Learning",
    "abstract": "Ride-pooling, also known as ride-sharing, shared ride-hailing, or\nmicrotransit, is a service wherein passengers share rides. This service can\nreduce costs for both passengers and operators and reduce congestion and\nenvironmental impacts. A key limitation, however, is its myopic\ndecision-making, which overlooks long-term effects of dispatch decisions. To\naddress this, we propose a simulation-informed reinforcement learning (RL)\napproach. While RL has been widely studied in the context of ride-hailing\nsystems, its application in ride-pooling systems has been less explored. In\nthis study, we extend the learning and planning framework of Xu et al. (2018)\nfrom ride-hailing to ride-pooling by embedding a ride-pooling simulation within\nthe learning mechanism to enable non-myopic decision-making. In addition, we\npropose a complementary policy for rebalancing idle vehicles. By employing\nn-step temporal difference learning on simulated experiences, we derive\nspatiotemporal state values and subsequently evaluate the effectiveness of the\nnon-myopic policy using NYC taxi request data. Results demonstrate that the\nnon-myopic policy for matching can increase the service rate by up to 8.4%\nversus a myopic policy while reducing both in-vehicle and wait times for\npassengers. Furthermore, the proposed non-myopic policy can decrease fleet size\nby over 25% compared to a myopic policy, while maintaining the same level of\nperformance, thereby offering significant cost savings for operators.\nIncorporating rebalancing operations into the proposed framework cuts wait time\nby up to 27.3%, in-vehicle time by 12.5%, and raises service rate by 15.1%\ncompared to using the framework for matching decisions alone at the cost of\nincreased vehicle minutes traveled per passenger.",
    "categories": [
      "cs.LG",
      "cs.AI",
      "cs.CY"
    ],
    "published": "2025-10-28T23:21:27Z",
    "authors": [
      "Farnoosh Namdarpour",
      "Joseph Y. J. Chow"
    ],
    "pdf_url": "http://arxiv.org/pdf/2510.25796v1"
  },
  {
    "id": "2510.25032v1",
    "title": "Efficient License Plate Recognition via Pseudo-Labeled Supervision with\n  Grounding DINO and YOLOv8",
    "abstract": "Developing a highly accurate automatic license plate recognition system\n(ALPR) is challenging due to environmental factors such as lighting, rain, and\ndust. Additional difficulties include high vehicle speeds, varying camera\nangles, and low-quality or low-resolution images. ALPR is vital in traffic\ncontrol, parking, vehicle tracking, toll collection, and law enforcement\napplications. This paper proposes a deep learning strategy using YOLOv8 for\nlicense plate detection and recognition tasks. This method seeks to enhance the\nperformance of the model using datasets from Ontario, Quebec, California, and\nNew York State. It achieved an impressive recall rate of 94% on the dataset\nfrom the Center for Pattern Recognition and Machine Intelligence (CENPARMI) and\n91% on the UFPR-ALPR dataset. In addition, our method follows a semi-supervised\nlearning framework, combining a small set of manually labeled data with\npseudo-labels generated by Grounding DINO to train our detection model.\nGrounding DINO, a powerful vision-language model, automatically annotates many\nimages with bounding boxes for license plates, thereby minimizing the reliance\non labor-intensive manual labeling. By integrating human-verified and\nmodel-generated annotations, we can scale our dataset efficiently while\nmaintaining label quality, which significantly enhances the training process\nand overall model performance. Furthermore, it reports character error rates\nfor both datasets, providing additional insight into system performance.",
    "categories": [
      "cs.CV",
      "cs.AI"
    ],
    "published": "2025-10-28T23:21:00Z",
    "authors": [
      "Zahra Ebrahimi Vargoorani",
      "Amir Mohammad Ghoreyshi",
      "Ching Yee Suen"
    ],
    "pdf_url": "http://arxiv.org/pdf/2510.25032v1"
  },
  {
    "id": "2510.25017v1",
    "title": "StorageXTuner: An LLM Agent-Driven Automatic Tuning Framework for\n  Heterogeneous Storage Systems",
    "abstract": "Automatically configuring storage systems is hard: parameter spaces are large\nand conditions vary across workloads, deployments, and versions. Heuristic and\nML tuners are often system specific, require manual glue, and degrade under\nchanges. Recent LLM-based approaches help but usually treat tuning as a\nsingle-shot, system-specific task, which limits cross-system reuse, constrains\nexploration, and weakens validation. We present StorageXTuner, an LLM\nagent-driven auto-tuning framework for heterogeneous storage engines.\nStorageXTuner separates concerns across four agents - Executor (sandboxed\nbenchmarking), Extractor (performance digest), Searcher (insight-guided\nconfiguration exploration), and Reflector (insight generation and management).\nThe design couples an insight-driven tree search with layered memory that\npromotes empirically validated insights and employs lightweight checkers to\nguard against unsafe actions. We implement a prototype and evaluate it on\nRocksDB, LevelDB, CacheLib, and MySQL InnoDB with YCSB, MixGraph, and TPC-H/C.\nRelative to out-of-the-box settings and to ELMo-Tune, StorageXTuner reaches up\nto 575% and 111% higher throughput, reduces p99 latency by as much as 88% and\n56%, and converges with fewer trials.",
    "categories": [
      "cs.DB",
      "cs.AI",
      "cs.CL"
    ],
    "published": "2025-10-28T22:33:14Z",
    "authors": [
      "Qi Lin",
      "Zhenyu Zhang",
      "Viraj Thakkar",
      "Zhenjie Sun",
      "Mai Zheng",
      "Zhichao Cao"
    ],
    "pdf_url": "http://arxiv.org/pdf/2510.25017v1"
  },
  {
    "id": "2510.25016v1",
    "title": "Towards Human-AI Synergy in Requirements Engineering: A Framework and\n  Preliminary Study",
    "abstract": "The future of Requirements Engineering (RE) is increasingly driven by\nartificial intelligence (AI), reshaping how we elicit, analyze, and validate\nrequirements. Traditional RE is based on labor-intensive manual processes prone\nto errors and complexity. AI-powered approaches, specifically large language\nmodels (LLMs), natural language processing (NLP), and generative AI, offer\ntransformative solutions and reduce inefficiencies. However, the use of AI in\nRE also brings challenges like algorithmic bias, lack of explainability, and\nethical concerns related to automation. To address these issues, this study\nintroduces the Human-AI RE Synergy Model (HARE-SM), a conceptual framework that\nintegrates AI-driven analysis with human oversight to improve requirements\nelicitation, analysis, and validation. The model emphasizes ethical AI use\nthrough transparency, explainability, and bias mitigation. We outline a\nmulti-phase research methodology focused on preparing RE datasets, fine-tuning\nAI models, and designing collaborative human-AI workflows. This preliminary\nstudy presents the conceptual framework and early-stage prototype\nimplementation, establishing a research agenda and practical design direction\nfor applying intelligent data science techniques to semi-structured and\nunstructured RE data in collaborative environments.",
    "categories": [
      "cs.SE",
      "cs.AI",
      "cs.HC",
      "cs.LG",
      "68T07, 68N30",
      "D.2.1; I.2.6; I.2.7"
    ],
    "published": "2025-10-28T22:29:11Z",
    "authors": [
      "Mateen Ahmed Abbasi",
      "Petri Ihantola",
      "Tommi Mikkonen",
      "Niko M\u00e4kitalo"
    ],
    "pdf_url": "http://arxiv.org/pdf/2510.25016v1"
  },
  {
    "id": "2510.25014v1",
    "title": "Aligning Large Language Models with Procedural Rules: An Autoregressive\n  State-Tracking Prompting for In-Game Trading",
    "abstract": "Large Language Models (LLMs) enable dynamic game interactions but fail to\nfollow essential procedural flows in rule-governed trading systems, eroding\nplayer trust. This work resolves the core tension between the creative\nflexibility of LLMs and the procedural demands of in-game trading\n(browse-offer-review-confirm). To this end, Autoregressive State-Tracking\nPrompting (ASTP) is introduced, a methodology centered on a strategically\norchestrated prompt that compels an LLM to make its state-tracking process\nexplicit and verifiable. Instead of relying on implicit contextual\nunderstanding, ASTP tasks the LLM with identifying and reporting a predefined\nstate label from the previous turn. To ensure transactional integrity, this is\ncomplemented by a state-specific placeholder post-processing method for\naccurate price calculations. Evaluation across 300 trading dialogues\ndemonstrates >99% state compliance and 99.3% calculation precision. Notably,\nASTP with placeholder post-processing on smaller models (Gemini-2.5-Flash)\nmatches larger models' (Gemini-2.5-Pro) performance while reducing response\ntime from 21.2s to 2.4s, establishing a practical foundation that satisfies\nboth real-time requirements and resource constraints of commercial games.",
    "categories": [
      "cs.AI"
    ],
    "published": "2025-10-28T22:26:34Z",
    "authors": [
      "Minkyung Kim",
      "Junsik Kim",
      "Woongcheol Yang",
      "Sangdon Park",
      "Sohee Bae"
    ],
    "pdf_url": "http://arxiv.org/pdf/2510.25014v1"
  },
  {
    "id": "2510.25013v1",
    "title": "Emergence of Minimal Circuits for Indirect Object Identification in\n  Attention-Only Transformers",
    "abstract": "Mechanistic interpretability aims to reverse-engineer large language models\n(LLMs) into human-understandable computational circuits. However, the\ncomplexity of pretrained models often obscures the minimal mechanisms required\nfor specific reasoning tasks. In this work, we train small, attention-only\ntransformers from scratch on a symbolic version of the Indirect Object\nIdentification (IOI) task -- a benchmark for studying coreference -- like\nreasoning in transformers. Surprisingly, a single-layer model with only two\nattention heads achieves perfect IOI accuracy, despite lacking MLPs and\nnormalization layers. Through residual stream decomposition, spectral analysis,\nand embedding interventions, we find that the two heads specialize into\nadditive and contrastive subcircuits that jointly implement IOI resolution.\nFurthermore, we show that a two-layer, one-head model achieves similar\nperformance by composing information across layers through query-value\ninteractions. These results demonstrate that task-specific training induces\nhighly interpretable, minimal circuits, offering a controlled testbed for\nprobing the computational foundations of transformer reasoning.",
    "categories": [
      "cs.CL",
      "cs.AI",
      "cs.LG"
    ],
    "published": "2025-10-28T22:25:19Z",
    "authors": [
      "Rabin Adhikari"
    ],
    "pdf_url": "http://arxiv.org/pdf/2510.25013v1"
  },
  {
    "id": "2510.25007v1",
    "title": "Taming the Real-world Complexities in CPT E/M Coding with Large Language\n  Models",
    "abstract": "Evaluation and Management (E/M) coding, under the Current Procedural\nTerminology (CPT) taxonomy, documents medical services provided to patients by\nphysicians. Used primarily for billing purposes, it is in physicians' best\ninterest to provide accurate CPT E/M codes. %While important, it is an\nauxiliary task that adds to physicians' documentation burden. Automating this\ncoding task will help alleviate physicians' documentation burden, improve\nbilling efficiency, and ultimately enable better patient care. However, a\nnumber of real-world complexities have made E/M encoding automation a\nchallenging task. In this paper, we elaborate some of the key complexities and\npresent ProFees, our LLM-based framework that tackles them, followed by a\nsystematic evaluation. On an expert-curated real-world dataset, ProFees\nachieves an increase in coding accuracy of more than 36\\% over a commercial CPT\nE/M coding system and almost 5\\% over our strongest single-prompt baseline,\ndemonstrating its effectiveness in addressing the real-world complexities.",
    "categories": [
      "cs.AI",
      "cs.LG"
    ],
    "published": "2025-10-28T22:06:59Z",
    "authors": [
      "Islam Nassar",
      "Yang Lin",
      "Yuan Jin",
      "Rongxin Zhu",
      "Chang Wei Tan",
      "Zenan Zhai",
      "Nitika Mathur",
      "Thanh Tien Vu",
      "Xu Zhong",
      "Long Duong",
      "Yuan-Fang Li"
    ],
    "pdf_url": "http://arxiv.org/pdf/2510.25007v1"
  },
  {
    "id": "2510.25005v1",
    "title": "Cyclic Counterfactuals under Shift-Scale Interventions",
    "abstract": "Most counterfactual inference frameworks traditionally assume acyclic\nstructural causal models (SCMs), i.e. directed acyclic graphs (DAGs). However,\nmany real-world systems (e.g. biological systems) contain feedback loops or\ncyclic dependencies that violate acyclicity. In this work, we study\ncounterfactual inference in cyclic SCMs under shift-scale interventions, i.e.,\nsoft, policy-style changes that rescale and/or shift a variable's mechanism.",
    "categories": [
      "cs.AI",
      "cs.LG",
      "math.ST",
      "stat.ML",
      "stat.TH"
    ],
    "published": "2025-10-28T22:03:01Z",
    "authors": [
      "Saptarshi Saha",
      "Dhruv Vansraj Rathore",
      "Utpal Garain"
    ],
    "pdf_url": "http://arxiv.org/pdf/2510.25005v1"
  },
  {
    "id": "2510.24986v1",
    "title": "Epileptic Seizure Detection and Prediction from EEG Data: A Machine\n  Learning Approach with Clinical Validation",
    "abstract": "In recent years, machine learning has become an increasingly powerful tool\nfor supporting seizure detection and monitoring in epilepsy care. Traditional\napproaches focus on identifying seizures only after they begin, which limits\nthe opportunity for early intervention and proactive treatment. In this study,\nwe propose a novel approach that integrates both real-time seizure detection\nand prediction, aiming to capture subtle temporal patterns in EEG data that may\nindicate an upcoming seizure. Our approach was evaluated using the CHB-MIT\nScalp EEG Database, which includes 969 hours of recordings and 173 seizures\ncollected from 23 pediatric and young adult patients with drug-resistant\nepilepsy. To support seizure detection, we implemented a range of supervised\nmachine learning algorithms, including K-Nearest Neighbors, Logistic\nRegression, Random Forest, and Support Vector Machine. The Logistic Regression\nachieved 90.9% detection accuracy with 89.6% recall, demonstrating balanced\nperformance suitable for clinical screening. Random Forest and Support Vector\nMachine models achieved higher accuracy (94.0%) but with 0% recall, failing to\ndetect any seizures, illustrating that accuracy alone is insufficient for\nevaluating medical ML models with class imbalance. For seizure prediction, we\nemployed Long Short-Term Memory (LSTM) networks, which use deep learning to\nmodel temporal dependencies in EEG data. The LSTM model achieved 89.26%\nprediction accuracy. These results highlight the potential of developing\naccessible, real-time monitoring tools that not only detect seizures as\ntraditionally done, but also predict them before they occur. This ability to\npredict seizures marks a significant shift from reactive seizure management to\na more proactive approach, allowing patients to anticipate seizures and take\nprecautionary measures to reduce the risk of injury or other complications.",
    "categories": [
      "cs.LG",
      "cs.AI"
    ],
    "published": "2025-10-28T21:28:18Z",
    "authors": [
      "Ria Jayanti",
      "Tanish Jain"
    ],
    "pdf_url": "http://arxiv.org/pdf/2510.24986v1"
  },
  {
    "id": "2510.24985v1",
    "title": "FaRAccel: FPGA-Accelerated Defense Architecture for Efficient Bit-Flip\n  Attack Resilience in Transformer Models",
    "abstract": "Forget and Rewire (FaR) methodology has demonstrated strong resilience\nagainst Bit-Flip Attacks (BFAs) on Transformer-based models by obfuscating\ncritical parameters through dynamic rewiring of linear layers. However, the\napplication of FaR introduces non-negligible performance and memory overheads,\nprimarily due to the runtime modification of activation pathways and the lack\nof hardware-level optimization. To overcome these limitations, we propose\nFaRAccel, a novel hardware accelerator architecture implemented on FPGA,\nspecifically designed to offload and optimize FaR operations. FaRAccel\nintegrates reconfigurable logic for dynamic activation rerouting, and\nlightweight storage of rewiring configurations, enabling low-latency inference\nwith minimal energy overhead. We evaluate FaRAccel across a suite of\nTransformer models and demonstrate substantial reductions in FaR inference\nlatency and improvement in energy efficiency, while maintaining the robustness\ngains of the original FaR methodology. To the best of our knowledge, this is\nthe first hardware-accelerated defense against BFAs in Transformers,\neffectively bridging the gap between algorithmic resilience and efficient\ndeployment on real-world AI platforms.",
    "categories": [
      "cs.CR",
      "cs.AI"
    ],
    "published": "2025-10-28T21:27:09Z",
    "authors": [
      "Najmeh Nazari",
      "Banafsheh Saber Latibari",
      "Elahe Hosseini",
      "Fatemeh Movafagh",
      "Chongzhou Fang",
      "Hosein Mohammadi Makrani",
      "Kevin Immanuel Gubbi",
      "Abhijit Mahalanobis",
      "Setareh Rafatirad",
      "Hossein Sayadi",
      "Houman Homayoun"
    ],
    "pdf_url": "http://arxiv.org/pdf/2510.24985v1"
  },
  {
    "id": "2510.24983v1",
    "title": "LRT-Diffusion: Calibrated Risk-Aware Guidance for Diffusion Policies",
    "abstract": "Diffusion policies are competitive for offline reinforcement learning (RL)\nbut are typically guided at sampling time by heuristics that lack a statistical\nnotion of risk. We introduce LRT-Diffusion, a risk-aware sampling rule that\ntreats each denoising step as a sequential hypothesis test between the\nunconditional prior and the state-conditional policy head. Concretely, we\naccumulate a log-likelihood ratio and gate the conditional mean with a logistic\ncontroller whose threshold tau is calibrated once under H0 to meet a\nuser-specified Type-I level alpha. This turns guidance from a fixed push into\nan evidence-driven adjustment with a user-interpretable risk budget.\nImportantly, we deliberately leave training vanilla (two heads with standard\nepsilon-prediction) under the structure of DDPM. LRT guidance composes\nnaturally with Q-gradients: critic-gradient updates can be taken at the\nunconditional mean, at the LRT-gated mean, or a blend, exposing a continuum\nfrom exploitation to conservatism. We standardize states and actions\nconsistently at train and test time and report a state-conditional\nout-of-distribution (OOD) metric alongside return. On D4RL MuJoCo tasks,\nLRT-Diffusion improves the return-OOD trade-off over strong Q-guided baselines\nin our implementation while honoring the desired alpha. Theoretically, we\nestablish level-alpha calibration, concise stability bounds, and a return\ncomparison showing when LRT surpasses Q-guidance-especially when off-support\nerrors dominate. Overall, LRT-Diffusion is a drop-in, inference-time method\nthat adds principled, calibrated risk control to diffusion policies for offline\nRL.",
    "categories": [
      "cs.LG",
      "cs.AI"
    ],
    "published": "2025-10-28T21:26:18Z",
    "authors": [
      "Ximan Sun",
      "Xiang Cheng"
    ],
    "pdf_url": "http://arxiv.org/pdf/2510.24983v1"
  },
  {
    "id": "2510.24980v1",
    "title": "FT-ARM: Fine-Tuned Agentic Reflection Multimodal Language Model for\n  Pressure Ulcer Severity Classification with Reasoning",
    "abstract": "Pressure ulcers (PUs) are a serious and prevalent healthcare concern.\nAccurate classification of PU severity (Stages I-IV) is essential for proper\ntreatment but remains challenging due to subtle visual distinctions and\nsubjective interpretation, leading to variability among clinicians. Prior\nAI-based approaches using Convolutional Neural Networks (CNNs) and Vision\nTransformers (ViTs) achieved promising accuracy but offered limited\ninterpretability. We present FT-ARM (Fine-Tuned Agentic Reflection Multimodal\nmodel), a fine-tuned multimodal large language model (MLLM) with an agentic\nself-reflection mechanism for pressure ulcer severity classification. Inspired\nby clinician-style diagnostic reassessment, FT-ARM iteratively refines its\npredictions by reasoning over visual features and encoded clinical knowledge\nfrom text, enhancing both accuracy and consistency. On the publicly available\nPressure Injury Image Dataset (PIID), FT-ARM, fine-tuned from LLaMA 3.2 90B,\nachieved 85% accuracy in classifying PU stages I-IV, surpassing prior CNN-based\nmodels by +4%. Unlike earlier CNN/ViT studies that relied solely on offline\nevaluations, FT-ARM is designed and tested for live inference, reflecting\nreal-time deployment conditions. Furthermore, it produces clinically grounded\nnatural-language explanations, improving interpretability and trust. By\nintegrating fine-tuning and reflective reasoning across multimodal inputs,\nFT-ARM advances the reliability, transparency, and clinical applicability of\nautomated wound assessment systems, addressing the critical need for consistent\nand explainable PU staging to support improved patient care.",
    "categories": [
      "cs.CV",
      "cs.AI"
    ],
    "published": "2025-10-28T21:23:32Z",
    "authors": [
      "Reza Saadati Fard",
      "Emmanuel Agu",
      "Palawat Busaranuvong",
      "Deepak Kumar",
      "Shefalika Gautam",
      "Bengisu Tulu",
      "Diane Strong",
      "Lorraine Loretz"
    ],
    "pdf_url": "http://arxiv.org/pdf/2510.24980v1"
  },
  {
    "id": "2510.24976v1",
    "title": "Hammering the Diagnosis: Rowhammer-Induced Stealthy Trojan Attacks on\n  ViT-Based Medical Imaging",
    "abstract": "Vision Transformers (ViTs) have emerged as powerful architectures in medical\nimage analysis, excelling in tasks such as disease detection, segmentation, and\nclassification. However, their reliance on large, attention-driven models makes\nthem vulnerable to hardware-level attacks. In this paper, we propose a novel\nthreat model referred to as Med-Hammer that combines the Rowhammer hardware\nfault injection with neural Trojan attacks to compromise the integrity of\nViT-based medical imaging systems. Specifically, we demonstrate how malicious\nbit flips induced via Rowhammer can trigger implanted neural Trojans, leading\nto targeted misclassification or suppression of critical diagnoses (e.g.,\ntumors or lesions) in medical scans. Through extensive experiments on benchmark\nmedical imaging datasets such as ISIC, Brain Tumor, and MedMNIST, we show that\nsuch attacks can remain stealthy while achieving high attack success rates\nabout 82.51% and 92.56% in MobileViT and SwinTransformer, respectively. We\nfurther investigate how architectural properties, such as model sparsity,\nattention weight distribution, and the number of features of the layer, impact\nattack effectiveness. Our findings highlight a critical and underexplored\nintersection between hardware-level faults and deep learning security in\nhealthcare applications, underscoring the urgent need for robust defenses\nspanning both model architectures and underlying hardware platforms.",
    "categories": [
      "cs.CR",
      "cs.AI"
    ],
    "published": "2025-10-28T21:17:35Z",
    "authors": [
      "Banafsheh Saber Latibari",
      "Najmeh Nazari",
      "Hossein Sayadi",
      "Houman Homayoun",
      "Abhijit Mahalanobis"
    ],
    "pdf_url": "http://arxiv.org/pdf/2510.24976v1"
  },
  {
    "id": "2510.24966v1",
    "title": "Sequences of Logits Reveal the Low Rank Structure of Language Models",
    "abstract": "A major problem in the study of large language models is to understand their\ninherent low-dimensional structure. We introduce an approach to study the\nlow-dimensional structure of language models at a model-agnostic level: as\nsequential probabilistic models. We first empirically demonstrate that a wide\nrange of modern language models exhibit low-rank structure: in particular,\nmatrices built from the model's logits for varying sets of prompts and\nresponses have low approximate rank. We then show that this low-rank structure\ncan be leveraged for generation -- in particular, we can generate a response to\na target prompt using a linear combination of the model's outputs on unrelated,\nor even nonsensical prompts.\n  On the theoretical front, we observe that studying the approximate rank of\nlanguage models in the sense discussed above yields a simple universal\nabstraction whose theoretical predictions parallel our experiments. We then\nanalyze the representation power of the abstraction and give provable learning\nguarantees.",
    "categories": [
      "cs.LG",
      "cs.AI",
      "cs.CL",
      "stat.ML"
    ],
    "published": "2025-10-28T20:55:58Z",
    "authors": [
      "Noah Golowich",
      "Allen Liu",
      "Abhishek Shetty"
    ],
    "pdf_url": "http://arxiv.org/pdf/2510.24966v1"
  },
  {
    "id": "2510.24949v1",
    "title": "SCOUT: A Lightweight Framework for Scenario Coverage Assessment in\n  Autonomous Driving",
    "abstract": "Assessing scenario coverage is crucial for evaluating the robustness of\nautonomous agents, yet existing methods rely on expensive human annotations or\ncomputationally intensive Large Vision-Language Models (LVLMs). These\napproaches are impractical for large-scale deployment due to cost and\nefficiency constraints. To address these shortcomings, we propose SCOUT\n(Scenario Coverage Oversight and Understanding Tool), a lightweight surrogate\nmodel designed to predict scenario coverage labels directly from an agent's\nlatent sensor representations. SCOUT is trained through a distillation process,\nlearning to approximate LVLM-generated coverage labels while eliminating the\nneed for continuous LVLM inference or human annotation. By leveraging\nprecomputed perception features, SCOUT avoids redundant computations and\nenables fast, scalable scenario coverage estimation. We evaluate our method\nacross a large dataset of real-life autonomous navigation scenarios,\ndemonstrating that it maintains high accuracy while significantly reducing\ncomputational cost. Our results show that SCOUT provides an effective and\npractical alternative for large-scale coverage analysis. While its performance\ndepends on the quality of LVLM-generated training labels, SCOUT represents a\nmajor step toward efficient scenario coverage oversight in autonomous systems.",
    "categories": [
      "cs.RO",
      "cs.AI",
      "cs.CV",
      "cs.LG"
    ],
    "published": "2025-10-28T20:31:19Z",
    "authors": [
      "Anil Yildiz",
      "Sarah M. Thornton",
      "Carl Hildebrandt",
      "Sreeja Roy-Singh",
      "Mykel J. Kochenderfer"
    ],
    "pdf_url": "http://arxiv.org/pdf/2510.24949v1"
  },
  {
    "id": "2510.24942v1",
    "title": "Finding Culture-Sensitive Neurons in Vision-Language Models",
    "abstract": "Despite their impressive performance, vision-language models (VLMs) still\nstruggle on culturally situated inputs. To understand how VLMs process\nculturally grounded information, we study the presence of culture-sensitive\nneurons, i.e. neurons whose activations show preferential sensitivity to inputs\nassociated with particular cultural contexts. We examine whether such neurons\nare important for culturally diverse visual question answering and where they\nare located. Using the CVQA benchmark, we identify neurons of culture\nselectivity and perform causal tests by deactivating the neurons flagged by\ndifferent identification methods. Experiments on three VLMs across 25 cultural\ngroups demonstrate the existence of neurons whose ablation disproportionately\nharms performance on questions about the corresponding cultures, while having\nminimal effects on others. Moreover, we propose a new margin-based selector -\nContrastive Activation Selection (CAS), and show that it outperforms existing\nprobability- and entropy-based methods in identifying culture-sensitive\nneurons. Finally, our layer-wise analyses reveals that such neurons tend to\ncluster in certain decoder layers. Overall, our findings shed new light on the\ninternal organization of multimodal representations.",
    "categories": [
      "cs.LG",
      "cs.AI",
      "cs.CL"
    ],
    "published": "2025-10-28T20:14:37Z",
    "authors": [
      "Xiutian Zhao",
      "Rochelle Choenni",
      "Rohit Saxena",
      "Ivan Titov"
    ],
    "pdf_url": "http://arxiv.org/pdf/2510.24942v1"
  },
  {
    "id": "2510.25791v1",
    "title": "The Kinetics of Reasoning: How Chain-of-Thought Shapes Learning in\n  Transformers?",
    "abstract": "Chain-of-thought (CoT) supervision can substantially improve transformer\nperformance, yet the mechanisms by which models learn to follow and benefit\nfrom CoT remain poorly understood. We investigate these learning dynamics\nthrough the lens of grokking by pretraining transformers on symbolic reasoning\ntasks with tunable algorithmic complexity and controllable data composition to\nstudy their generalization. Models were trained under two settings: (i)\nproducing only final answers, and (ii) emitting explicit CoT traces before\nanswering. Our results show that while CoT generally improves task performance,\nits benefits depend on task complexity. To quantify these effects, we model the\naccuracy of the logarithmic training steps with a three-parameter logistic\ncurve, revealing how the learning speed and shape vary with task complexity,\ndata distribution, and the presence of CoT supervision. We also uncover a\ntransient trace unfaithfulness phase: early in training, models often produce\ncorrect answers while skipping or contradicting CoT steps, before later\naligning their reasoning traces with answers. Empirically, we (1) demonstrate\nthat CoT accelerates generalization but does not overcome tasks with higher\nalgorithmic complexity, such as finding list intersections; (2) introduce a\nkinetic modeling framework for understanding transformer learning; (3)\ncharacterize trace faithfulness as a dynamic property that emerges over\ntraining; and (4) show CoT alters internal transformer computation\nmechanistically.",
    "categories": [
      "cs.LG",
      "cs.AI"
    ],
    "published": "2025-10-28T20:14:26Z",
    "authors": [
      "Zihan Pengmei",
      "Costas Mavromatis",
      "Zhengyuan Shen",
      "Yunyi Zhang",
      "Vassilis N. Ioannidis",
      "Huzefa Rangwala"
    ],
    "pdf_url": "http://arxiv.org/pdf/2510.25791v1"
  },
  {
    "id": "2510.24926v1",
    "title": "KAN-GCN: Combining Kolmogorov-Arnold Network with Graph Convolution\n  Network for an Accurate Ice Sheet Emulator",
    "abstract": "We introduce KAN-GCN, a fast and accurate emulator for ice sheet modeling\nthat places a Kolmogorov-Arnold Network (KAN) as a feature-wise calibrator\nbefore graph convolution networks (GCNs). The KAN front end applies learnable\none-dimensional warps and a linear mixing step, improving feature conditioning\nand nonlinear encoding without increasing message-passing depth. We employ this\narchitecture to improve the performance of emulators for numerical ice sheet\nmodels. Our emulator is trained and tested using 36 melting-rate simulations\nwith 3 mesh-size settings for Pine Island Glacier, Antarctica. Across 2- to\n5-layer architectures, KAN-GCN matches or exceeds the accuracy of pure GCN and\nMLP-GCN baselines. Despite a small parameter overhead, KAN-GCN improves\ninference throughput on coarser meshes by replacing one edge-wise\nmessage-passing layer with a node-wise transform; only the finest mesh shows a\nmodest cost. Overall, KAN-first designs offer a favorable accuracy vs.\nefficiency trade-off for large transient scenario sweeps.",
    "categories": [
      "cs.LG",
      "cs.AI",
      "cs.NA",
      "math.NA"
    ],
    "published": "2025-10-28T19:55:29Z",
    "authors": [
      "Zesheng Liu",
      "YoungHyun Koo",
      "Maryam Rahnemoonfar"
    ],
    "pdf_url": "http://arxiv.org/pdf/2510.24926v1"
  },
  {
    "id": "2510.24909v1",
    "title": "Trust Dynamics in Strategic Coopetition: Computational Foundations for\n  Requirements Engineering in Multi-Agent Systems",
    "abstract": "Requirements engineering increasingly occurs in multi-stakeholder\nenvironments where organizations simultaneously cooperate and compete, creating\ncoopetitive relationships in which trust evolves dynamically based on observed\nbehavior over repeated interactions. While conceptual modeling languages like\ni* represent trust relationships qualitatively, they lack computational\nmechanisms for analyzing how trust changes with behavioral evidence.\nConversely, computational trust models from multi-agent systems provide\nalgorithmic updating but lack grounding in requirements engineering contexts\nand conceptual models. This technical report bridges this gap by developing a\ncomputational trust model that extends game-theoretic foundations for strategic\ncoopetition with dynamic trust evolution. We introduce trust as a two-layer\nsystem with immediate trust responding to current behavior and reputation\ntracking violation history. Trust evolves through asymmetric updating where\ncooperation builds trust gradually while violations erode it sharply, creating\nhysteresis effects and trust ceilings that constrain relationship recovery. We\ndevelop a structured translation framework enabling requirements engineers to\ninstantiate computational trust models from i* dependency networks and\norganizational contexts. Comprehensive experimental validation across 78,125\nparameter configurations establishes robust emergence of negativity bias,\nhysteresis effects, and cumulative damage amplification. Empirical validation\nusing the Renault-Nissan Alliance case study (1999-2025) achieves 49 out of 60\nvalidation points (81.7%), successfully reproducing documented trust evolution\nacross five distinct relationship phases including crisis and recovery periods.\nThis technical report builds upon its foundational companion work in\narXiv:2510.18802.",
    "categories": [
      "cs.MA",
      "cs.AI",
      "cs.SE"
    ],
    "published": "2025-10-28T19:26:14Z",
    "authors": [
      "Vik Pant",
      "Eric Yu"
    ],
    "pdf_url": "http://arxiv.org/pdf/2510.24909v1"
  },
  {
    "id": "2510.24907v1",
    "title": "Understanding Multi-View Transformers",
    "abstract": "Multi-view transformers such as DUSt3R are revolutionizing 3D vision by\nsolving 3D tasks in a feed-forward manner. However, contrary to previous\noptimization-based pipelines, the inner mechanisms of multi-view transformers\nare unclear. Their black-box nature makes further improvements beyond data\nscaling challenging and complicates usage in safety- and reliability-critical\napplications. Here, we present an approach for probing and visualizing 3D\nrepresentations from the residual connections of the multi-view transformers'\nlayers. In this manner, we investigate a variant of the DUSt3R model, shedding\nlight on the development of its latent state across blocks, the role of the\nindividual layers, and suggest how it differs from methods with stronger\ninductive biases of explicit global pose. Finally, we show that the\ninvestigated variant of DUSt3R estimates correspondences that are refined with\nreconstructed geometry. The code used for the analysis is available at\nhttps://github.com/JulienGaubil/und3rstand .",
    "categories": [
      "cs.CV",
      "cs.AI",
      "cs.LG"
    ],
    "published": "2025-10-28T19:19:35Z",
    "authors": [
      "Michal Stary",
      "Julien Gaubil",
      "Ayush Tewari",
      "Vincent Sitzmann"
    ],
    "pdf_url": "http://arxiv.org/pdf/2510.24907v1"
  },
  {
    "id": "2510.24906v1",
    "title": "Fair Indivisible Payoffs through Shapley Value",
    "abstract": "We consider the problem of payoff division in indivisible coalitional games,\nwhere the value of the grand coalition is a natural number. This number\nrepresents a certain quantity of indivisible objects, such as parliamentary\nseats, kidney exchanges, or top features contributing to the outcome of a\nmachine learning model. The goal of this paper is to propose a fair method for\ndividing these objects among players. To achieve this, we define the\nindivisible Shapley value and study its properties. We demonstrate our proposed\ntechnique using three case studies, in particular, we use it to identify key\nregions of an image in the context of an image classification task.",
    "categories": [
      "cs.GT",
      "cs.AI"
    ],
    "published": "2025-10-28T19:18:07Z",
    "authors": [
      "Miko\u0142aj Czarnecki",
      "Micha\u0142 Korniak",
      "Oskar Skibski",
      "Piotr Skowron"
    ],
    "pdf_url": "http://arxiv.org/pdf/2510.24906v1"
  },
  {
    "id": "2510.24893v1",
    "title": "Efficiency Without Cognitive Change: Evidence from Human Interaction\n  with Narrow AI Systems",
    "abstract": "The growing integration of artificial intelligence (AI) into human cognition\nraises a fundamental question: does AI merely improve efficiency, or does it\nalter how we think? This study experimentally tested whether short-term\nexposure to narrow AI tools enhances core cognitive abilities or simply\noptimizes task performance. Thirty young adults completed standardized\nneuropsychological assessments embedded in a seven-week protocol with a\nfour-week online intervention involving problem-solving and verbal\ncomprehension tasks, either with or without AI support (ChatGPT). While\nAI-assisted participants completed several tasks faster and more accurately, no\nsignificant pre-post differences emerged in standardized measures of problem\nsolving or verbal comprehension. These results demonstrate efficiency gains\nwithout cognitive change, suggesting that current narrow AI systems serve as\ncognitive scaffolds extending performance without transforming underlying\nmental capacities. The findings highlight the need for ethical and educational\nframeworks that promote critical and autonomous thinking in an increasingly\nAI-augmented cognitive ecology.",
    "categories": [
      "cs.HC",
      "cs.AI",
      "cs.HC",
      "H.1.2; H.5.2; I.2.6"
    ],
    "published": "2025-10-28T18:55:44Z",
    "authors": [
      "Mar\u00eda Ang\u00e9lica Ben\u00edtez",
      "Roc\u00edo Candela Ceballos",
      "Karina Del Valle Molina",
      "Sof\u00eda Mundo Araujo",
      "Sof\u00eda Evangelina Victorio Villaroel",
      "Nadia Justel"
    ],
    "pdf_url": "http://arxiv.org/pdf/2510.24893v1"
  },
  {
    "id": "2510.24709v1",
    "title": "Does Object Binding Naturally Emerge in Large Pretrained Vision\n  Transformers?",
    "abstract": "Object binding, the brain's ability to bind the many features that\ncollectively represent an object into a coherent whole, is central to human\ncognition. It groups low-level perceptual features into high-level object\nrepresentations, stores those objects efficiently and compositionally in\nmemory, and supports human reasoning about individual object instances. While\nprior work often imposes object-centric attention (e.g., Slot Attention)\nexplicitly to probe these benefits, it remains unclear whether this ability\nnaturally emerges in pre-trained Vision Transformers (ViTs). Intuitively, they\ncould: recognizing which patches belong to the same object should be useful for\ndownstream prediction and thus guide attention. Motivated by the quadratic\nnature of self-attention, we hypothesize that ViTs represent whether two\npatches belong to the same object, a property we term IsSameObject. We decode\nIsSameObject from patch embeddings across ViT layers using a similarity probe,\nwhich reaches over 90% accuracy. Crucially, this object-binding capability\nemerges reliably in self-supervised ViTs (DINO, MAE, CLIP), but markedly weaker\nin ImageNet-supervised models, suggesting that binding is not a trivial\narchitectural artifact, but an ability acquired through specific pretraining\nobjectives. We further discover that IsSameObject is encoded in a\nlow-dimensional subspace on top of object features, and that this signal\nactively guides attention. Ablating IsSameObject from model activations\ndegrades downstream performance and works against the learning objective,\nimplying that emergent object binding naturally serves the pretraining\nobjective. Our findings challenge the view that ViTs lack object binding and\nhighlight how symbolic knowledge of \"which parts belong together\" emerges\nnaturally in a connectionist system.",
    "categories": [
      "cs.CV",
      "cs.AI",
      "cs.LG",
      "q-bio.NC"
    ],
    "published": "2025-10-28T17:57:05Z",
    "authors": [
      "Yihao Li",
      "Saeed Salehi",
      "Lyle Ungar",
      "Konrad P. Kording"
    ],
    "pdf_url": "http://arxiv.org/pdf/2510.24709v1"
  },
  {
    "id": "2510.24706v1",
    "title": "ComboBench: Can LLMs Manipulate Physical Devices to Play Virtual Reality\n  Games?",
    "abstract": "Virtual Reality (VR) games require players to translate high-level semantic\nactions into precise device manipulations using controllers and head-mounted\ndisplays (HMDs). While humans intuitively perform this translation based on\ncommon sense and embodied understanding, whether Large Language Models (LLMs)\ncan effectively replicate this ability remains underexplored. This paper\nintroduces a benchmark, ComboBench, evaluating LLMs' capability to translate\nsemantic actions into VR device manipulation sequences across 262 scenarios\nfrom four popular VR games: Half-Life: Alyx, Into the Radius, Moss: Book II,\nand Vivecraft. We evaluate seven LLMs, including GPT-3.5, GPT-4, GPT-4o,\nGemini-1.5-Pro, LLaMA-3-8B, Mixtral-8x7B, and GLM-4-Flash, compared against\nannotated ground truth and human performance. Our results reveal that while\ntop-performing models like Gemini-1.5-Pro demonstrate strong task decomposition\ncapabilities, they still struggle with procedural reasoning and spatial\nunderstanding compared to humans. Performance varies significantly across\ngames, suggesting sensitivity to interaction complexity. Few-shot examples\nsubstantially improve performance, indicating potential for targeted\nenhancement of LLMs' VR manipulation capabilities. We release all materials at\nhttps://sites.google.com/view/combobench.",
    "categories": [
      "cs.CL",
      "cs.AI",
      "cs.HC",
      "cs.SE"
    ],
    "published": "2025-10-28T17:55:42Z",
    "authors": [
      "Shuqing Li",
      "Jiayi Yan",
      "Chenyu Niu",
      "Jen-tse Huang",
      "Yun Peng",
      "Wenxuan Wang",
      "Yepang Liu",
      "Michael R. Lyu"
    ],
    "pdf_url": "http://arxiv.org/pdf/2510.24706v1"
  },
  {
    "id": "2510.24702v1",
    "title": "Agent Data Protocol: Unifying Datasets for Diverse, Effective\n  Fine-tuning of LLM Agents",
    "abstract": "Public research results on large-scale supervised finetuning of AI agents\nremain relatively rare, since the collection of agent training data presents\nunique challenges. In this work, we argue that the bottleneck is not a lack of\nunderlying data sources, but that a large variety of data is fragmented across\nheterogeneous formats, tools, and interfaces. To this end, we introduce the\nagent data protocol (ADP), a light-weight representation language that serves\nas an \"interlingua\" between agent datasets in diverse formats and unified agent\ntraining pipelines downstream. The design of ADP is expressive enough to\ncapture a large variety of tasks, including API/tool use, browsing, coding,\nsoftware engineering, and general agentic workflows, while remaining simple to\nparse and train on without engineering at a per-dataset level. In experiments,\nwe unified a broad collection of 13 existing agent training datasets into ADP\nformat, and converted the standardized ADP data into training-ready formats for\nmultiple agent frameworks. We performed SFT on these data, and demonstrated an\naverage performance gain of ~20% over corresponding base models, and delivers\nstate-of-the-art or near-SOTA performance on standard coding, browsing, tool\nuse, and research benchmarks, without domain-specific tuning. All code and data\nare released publicly, in the hope that ADP could help lower the barrier to\nstandardized, scalable, and reproducible agent training.",
    "categories": [
      "cs.CL",
      "cs.AI"
    ],
    "published": "2025-10-28T17:53:13Z",
    "authors": [
      "Yueqi Song",
      "Ketan Ramaneti",
      "Zaid Sheikh",
      "Ziru Chen",
      "Boyu Gou",
      "Tianbao Xie",
      "Yiheng Xu",
      "Danyang Zhang",
      "Apurva Gandhi",
      "Fan Yang",
      "Joseph Liu",
      "Tianyue Ou",
      "Zhihao Yuan",
      "Frank Xu",
      "Shuyan Zhou",
      "Xingyao Wang",
      "Xiang Yue",
      "Tao Yu",
      "Huan Sun",
      "Yu Su",
      "Graham Neubig"
    ],
    "pdf_url": "http://arxiv.org/pdf/2510.24702v1"
  },
  {
    "id": "2510.24701v1",
    "title": "Tongyi DeepResearch Technical Report",
    "abstract": "We present Tongyi DeepResearch, an agentic large language model, which is\nspecifically designed for long-horizon, deep information-seeking research\ntasks. To incentivize autonomous deep research agency, Tongyi DeepResearch is\ndeveloped through an end-to-end training framework that combines agentic\nmid-training and agentic post-training, enabling scalable reasoning and\ninformation seeking across complex tasks. We design a highly scalable data\nsynthesis pipeline that is fully automatic, without relying on costly human\nannotation, and empowers all training stages. By constructing customized\nenvironments for each stage, our system enables stable and consistent\ninteractions throughout. Tongyi DeepResearch, featuring 30.5 billion total\nparameters, with only 3.3 billion activated per token, achieves\nstate-of-the-art performance across a range of agentic deep research\nbenchmarks, including Humanity's Last Exam, BrowseComp, BrowseComp-ZH,\nWebWalkerQA, xbench-DeepSearch, FRAMES and xbench-DeepSearch-2510. We\nopen-source the model, framework, and complete solutions to empower the\ncommunity.",
    "categories": [
      "cs.CL",
      "cs.AI",
      "cs.IR",
      "cs.LG",
      "cs.MA"
    ],
    "published": "2025-10-28T17:53:02Z",
    "authors": [
      " Tongyi DeepResearch Team",
      "Baixuan Li",
      "Bo Zhang",
      "Dingchu Zhang",
      "Fei Huang",
      "Guangyu Li",
      "Guoxin Chen",
      "Huifeng Yin",
      "Jialong Wu",
      "Jingren Zhou",
      "Kuan Li",
      "Liangcai Su",
      "Litu Ou",
      "Liwen Zhang",
      "Pengjun Xie",
      "Rui Ye",
      "Wenbiao Yin",
      "Xinmiao Yu",
      "Xinyu Wang",
      "Xixi Wu",
      "Xuanzhong Chen",
      "Yida Zhao",
      "Zhen Zhang",
      "Zhengwei Tao",
      "Zhongwang Zhang",
      "Zile Qiao",
      "Chenxi Wang",
      "Donglei Yu",
      "Gang Fu",
      "Haiyang Shen",
      "Jiayin Yang",
      "Jun Lin",
      "Junkai Zhang",
      "Kui Zeng",
      "Li Yang",
      "Hailong Yin",
      "Maojia Song",
      "Ming Yan",
      "Peng Xia",
      "Qian Xiao",
      "Rui Min",
      "Ruixue Ding",
      "Runnan Fang",
      "Shaowei Chen",
      "Shen Huang",
      "Shihang Wang",
      "Shihao Cai",
      "Weizhou Shen",
      "Xiaobin Wang",
      "Xin Guan",
      "Xinyu Geng",
      "Yingcheng Shi",
      "Yuning Wu",
      "Zhuo Chen",
      "Zijian Li",
      "Yong Jiang"
    ],
    "pdf_url": "http://arxiv.org/pdf/2510.24701v1"
  },
  {
    "id": "2510.24700v1",
    "title": "Greedy Sampling Is Provably Efficient for RLHF",
    "abstract": "Reinforcement Learning from Human Feedback (RLHF) has emerged as a key\ntechnique for post-training large language models. Despite its empirical\nsuccess, the theoretical understanding of RLHF is still limited, as learning\nthe KL-regularized target with only preference feedback poses additional\nchallenges compared with canonical RL. Existing works mostly study the\nreward-based Bradley-Terry (BT) preference model, and extend classical designs\nutilizing optimism or pessimism. This work, instead, considers the general\npreference model (whose practical relevance has been observed recently) and\nobtains performance guarantees with major, order-wise improvements over\nexisting ones. Surprisingly, these results are derived from algorithms that\ndirectly use the empirical estimates (i.e., greedy sampling), as opposed to\nconstructing optimistic or pessimistic estimates in previous works. This\ninsight has a deep root in the unique structural property of the optimal policy\nclass under the KL-regularized target, and we further specialize it to the BT\nmodel, highlighting the surprising sufficiency of greedy sampling in RLHF.",
    "categories": [
      "cs.LG",
      "cs.AI",
      "cs.IT",
      "math.IT",
      "stat.ML"
    ],
    "published": "2025-10-28T17:52:08Z",
    "authors": [
      "Di Wu",
      "Chengshuai Shi",
      "Jing Yang",
      "Cong Shen"
    ],
    "pdf_url": "http://arxiv.org/pdf/2510.24700v1"
  },
  {
    "id": "2510.24832v1",
    "title": "Scheduling Your LLM Reinforcement Learning with Reasoning Trees",
    "abstract": "Using Reinforcement Learning with Verifiable Rewards (RLVR) to optimize Large\nLanguage Models (LLMs) can be conceptualized as progressively editing a query's\n`Reasoning Tree'. This process involves exploring nodes (tokens) and\ndynamically modifying the model's policy at each node. When combined with data\nscheduling, this process yields further gains in data efficiency and accuracy.\nHowever, existing RLVR data scheduling methods typically rely on path-based\nmetrics to rank queries, overlooking the reasoning tree structures of these\nqueries. In this paper, we introduce a novel metric, namely Reasoning Score\n(r-score), which measures the query's learning difficulty based on the\nstructure of its reasoning tree. Based on the r-score, we propose the Reasoning\nTree Schedule (Re-Schedule), a scheduling algorithm that constructs a\ncurriculum progressing from structurally simple (high r-score) to complex (low\nr-score) queries. Experiments on six math-reasoning benchmarks show that\nRe-Schedule significantly improves average accuracy, achieving gains of up to\n3.2%. These strong results validate our approach and demonstrate that a\nstructural understanding of the reasoning tree provides a more powerful and\nprincipled foundation for RLVR data scheduling.",
    "categories": [
      "cs.AI"
    ],
    "published": "2025-10-28T17:52:07Z",
    "authors": [
      "Hong Wang",
      "Zhezheng Hao",
      "Jian Luo",
      "Chenxing Wei",
      "Yao Shu",
      "Lei Liu",
      "Qiang Lin",
      "Hande Dong",
      "Jiawei Chen"
    ],
    "pdf_url": "http://arxiv.org/pdf/2510.24832v1"
  },
  {
    "id": "2510.24698v1",
    "title": "ParallelMuse: Agentic Parallel Thinking for Deep Information Seeking",
    "abstract": "Parallel thinking expands exploration breadth, complementing the deep\nexploration of information-seeking (IS) agents to further enhance\nproblem-solving capability. However, conventional parallel thinking faces two\nkey challenges in this setting: inefficiency from repeatedly rolling out from\nscratch, and difficulty in integrating long-horizon reasoning trajectories\nduring answer generation, as limited context capacity prevents full\nconsideration of the reasoning process. To address these issues, we propose\nParallelMuse, a two-stage paradigm designed for deep IS agents. The first\nstage, Functionality-Specified Partial Rollout, partitions generated sequences\ninto functional regions and performs uncertainty-guided path reuse and\nbranching to enhance exploration efficiency. The second stage, Compressed\nReasoning Aggregation, exploits reasoning redundancy to losslessly compress\ninformation relevant to answer derivation and synthesize a coherent final\nanswer. Experiments across multiple open-source agents and benchmarks\ndemonstrate up to 62% performance improvement with a 10--30% reduction in\nexploratory token consumption.",
    "categories": [
      "cs.CL",
      "cs.AI"
    ],
    "published": "2025-10-28T17:51:50Z",
    "authors": [
      "Baixuan Li",
      "Dingchu Zhang",
      "Jialong Wu",
      "Wenbiao Yin",
      "Zhengwei Tao",
      "Yida Zhao",
      "Liwen Zhang",
      "Haiyang Shen",
      "Runnan Fang",
      "Pengjun Xie",
      "Jingren Zhou",
      "Yong Jiang"
    ],
    "pdf_url": "http://arxiv.org/pdf/2510.24698v1"
  },
  {
    "id": "2510.24699v1",
    "title": "AgentFold: Long-Horizon Web Agents with Proactive Context Management",
    "abstract": "LLM-based web agents show immense promise for information seeking, yet their\neffectiveness on long-horizon tasks is hindered by a fundamental trade-off in\ncontext management. Prevailing ReAct-based agents suffer from context\nsaturation as they accumulate noisy, raw histories, while methods that fixedly\nsummarize the full history at each step risk the irreversible loss of critical\ndetails. Addressing these, we introduce AgentFold, a novel agent paradigm\ncentered on proactive context management, inspired by the human cognitive\nprocess of retrospective consolidation. AgentFold treats its context as a\ndynamic cognitive workspace to be actively sculpted, rather than a passive log\nto be filled. At each step, it learns to execute a `folding' operation, which\nmanages its historical trajectory at multiple scales: it can perform granular\ncondensations to preserve vital, fine-grained details, or deep consolidations\nto abstract away entire multi-step sub-tasks. The results on prominent\nbenchmarks are striking: with simple supervised fine-tuning (without continual\npre-training or RL), our AgentFold-30B-A3B agent achieves 36.2% on BrowseComp\nand 47.3% on BrowseComp-ZH. Notably, this performance not only surpasses or\nmatches open-source models of a dramatically larger scale, such as the\nDeepSeek-V3.1-671B-A37B, but also surpasses leading proprietary agents like\nOpenAI's o4-mini.",
    "categories": [
      "cs.CL",
      "cs.AI",
      "cs.LG"
    ],
    "published": "2025-10-28T17:51:50Z",
    "authors": [
      "Rui Ye",
      "Zhongwang Zhang",
      "Kuan Li",
      "Huifeng Yin",
      "Zhengwei Tao",
      "Yida Zhao",
      "Liangcai Su",
      "Liwen Zhang",
      "Zile Qiao",
      "Xinyu Wang",
      "Pengjun Xie",
      "Fei Huang",
      "Siheng Chen",
      "Jingren Zhou",
      "Yong Jiang"
    ],
    "pdf_url": "http://arxiv.org/pdf/2510.24699v1"
  },
  {
    "id": "2510.24694v1",
    "title": "Repurposing Synthetic Data for Fine-grained Search Agent Supervision",
    "abstract": "LLM-based search agents are increasingly trained on entity-centric synthetic\ndata to solve complex, knowledge-intensive tasks. However, prevailing training\nmethods like Group Relative Policy Optimization (GRPO) discard this rich entity\ninformation, relying instead on sparse, outcome-based rewards. This critical\nlimitation renders them unable to distinguish informative \"near-miss\"\nsamples-those with substantially correct reasoning but a flawed final\nanswer-from complete failures, thus discarding valuable learning signals. We\naddress this by leveraging the very entities discarded during training. Our\nempirical analysis reveals a strong positive correlation between the number of\nground-truth entities identified during an agent's reasoning process and final\nanswer accuracy. Building on this insight, we introduce Entity-aware Group\nRelative Policy Optimization (E-GRPO), a novel framework that formulates a\ndense entity-aware reward function. E-GRPO assigns partial rewards to incorrect\nsamples proportional to their entity match rate, enabling the model to\neffectively learn from these \"near-misses\". Experiments on diverse\nquestion-answering (QA) and deep research benchmarks show that E-GRPO\nconsistently and significantly outperforms the GRPO baseline. Furthermore, our\nanalysis reveals that E-GRPO not only achieves superior accuracy but also\ninduces more efficient reasoning policies that require fewer tool calls,\ndemonstrating a more effective and sample-efficient approach to aligning search\nagents.",
    "categories": [
      "cs.CL",
      "cs.AI"
    ],
    "published": "2025-10-28T17:50:40Z",
    "authors": [
      "Yida Zhao",
      "Kuan Li",
      "Xixi Wu",
      "Liwen Zhang",
      "Dingchu Zhang",
      "Baixuan Li",
      "Maojia Song",
      "Zhuo Chen",
      "Chenxi Wang",
      "Xinyu Wang",
      "Kewei Tu",
      "Pengjun Xie",
      "Jingren Zhou",
      "Yong Jiang"
    ],
    "pdf_url": "http://arxiv.org/pdf/2510.24694v1"
  },
  {
    "id": "2510.24690v1",
    "title": "Bridging Tool Dependencies and Domain Knowledge: A Graph-Based Framework\n  for In-Context Planning",
    "abstract": "We present a framework for uncovering and exploiting dependencies among tools\nand documents to enhance exemplar artifact generation. Our method begins by\nconstructing a tool knowledge graph from tool schemas,including descriptions,\narguments, and output payloads, using a DeepResearch-inspired analysis. In\nparallel, we derive a complementary knowledge graph from internal documents and\nSOPs, which is then fused with the tool graph. To generate exemplar plans, we\nadopt a deep-sparse integration strategy that aligns structural tool\ndependencies with procedural knowledge. Experiments demonstrate that this\nunified framework effectively models tool interactions and improves plan\ngeneration, underscoring the benefits of linking tool graphs with domain\nknowledge graphs for tool-augmented reasoning and planning.",
    "categories": [
      "cs.AI"
    ],
    "published": "2025-10-28T17:50:15Z",
    "authors": [
      "Shengjie Liu",
      "Li Dong",
      "Zhenyu Zhang"
    ],
    "pdf_url": "http://arxiv.org/pdf/2510.24690v1"
  },
  {
    "id": "2510.24687v1",
    "title": "Fast algorithms enabling optimization and deep learning for\n  photoacoustic tomography in a circular detection geometry",
    "abstract": "The inverse source problem arising in photoacoustic tomography and in several\nother coupled-physics modalities is frequently solved by iterative algorithms.\nSuch algorithms are based on the minimization of a certain cost functional. In\naddition, novel deep learning techniques are currently being investigated to\nfurther improve such optimization approaches. All such methods require multiple\napplications of the operator defining the forward problem, and of its adjoint.\nIn this paper, we present new asymptotically fast algorithms for numerical\nevaluation of the forward and adjoint operators, applicable in the circular\nacquisition geometry. For an $(n \\times n)$ image, our algorithms compute these\noperators in $\\mathcal{O}(n^2 \\log n)$ floating point operations. We\ndemonstrate the performance of our algorithms in numerical simulations, where\nthey are used as an integral part of several iterative image reconstruction\ntechniques: classic variational methods, such as non-negative least squares and\ntotal variation regularized least squares, as well as deep learning methods,\nsuch as learned primal dual. A Python implementation of our algorithms and\ncomputational examples is available to the general public.",
    "categories": [
      "eess.IV",
      "cs.AI",
      "cs.NA",
      "math.AP",
      "math.NA",
      "math.OC"
    ],
    "published": "2025-10-28T17:49:31Z",
    "authors": [
      "Andreas Hauptmann",
      "Leonid Kunyansky",
      "Jenni Poimala"
    ],
    "pdf_url": "http://arxiv.org/pdf/2510.24687v1"
  },
  {
    "id": "2510.25787v1",
    "title": "Unsupervised local learning based on voltage-dependent synaptic\n  plasticity for resistive and ferroelectric synapses",
    "abstract": "The deployment of AI on edge computing devices faces significant challenges\nrelated to energy consumption and functionality. These devices could greatly\nbenefit from brain-inspired learning mechanisms, allowing for real-time\nadaptation while using low-power. In-memory computing with nanoscale resistive\nmemories may play a crucial role in enabling the execution of AI workloads on\nthese edge devices. In this study, we introduce voltage-dependent synaptic\nplasticity (VDSP) as an efficient approach for unsupervised and local learning\nin memristive synapses based on Hebbian principles. This method enables online\nlearning without requiring complex pulse-shaping circuits typically necessary\nfor spike-timing-dependent plasticity (STDP). We show how VDSP can be\nadvantageously adapted to three types of memristive devices (TiO$_2$,\nHfO$_2$-based metal-oxide filamentary synapses, and HfZrO$_4$-based\nferroelectric tunnel junctions (FTJ)) with disctinctive switching\ncharacteristics. System-level simulations of spiking neural networks\nincorporating these devices were conducted to validate unsupervised learning on\nMNIST-based pattern recognition tasks, achieving state-of-the-art performance.\nThe results demonstrated over 83% accuracy across all devices using 200\nneurons. Additionally, we assessed the impact of device variability, such as\nswitching thresholds and ratios between high and low resistance state levels,\nand proposed mitigation strategies to enhance robustness.",
    "categories": [
      "cs.NE",
      "cs.AI",
      "cs.ET",
      "cs.LG"
    ],
    "published": "2025-10-28T17:47:26Z",
    "authors": [
      "Nikhil Garg",
      "Ismael Balafrej",
      "Joao Henrique Quintino Palhares",
      "Laura B\u00e9gon-Lours",
      "Davide Florini",
      "Donato Francesco Falcone",
      "Tommaso Stecconi",
      "Valeria Bragaglia",
      "Bert Jan Offrein",
      "Jean-Michel Portal",
      "Damien Querlioz",
      "Yann Beilliard",
      "Dominique Drouin",
      "Fabien Alibart"
    ],
    "pdf_url": "http://arxiv.org/pdf/2510.25787v1"
  },
  {
    "id": "2510.24677v1",
    "title": "Dissecting Role Cognition in Medical LLMs via Neuronal Ablation",
    "abstract": "Large language models (LLMs) have gained significant traction in medical\ndecision support systems, particularly in the\n  context of medical question answering and role-playing simulations. A common\npractice, Prompt-Based Role Playing (PBRP),\n  instructs models to adopt different clinical roles (e.g., medical students,\nresidents, attending physicians) to simulate varied\n  professional behaviors. However, the impact of such role prompts on model\nreasoning capabilities remains unclear. This\n  study introduces the RP-Neuron-Activated Evaluation Framework(RPNA) to\nevaluate whether role prompts induce distinct,\n  role-specific cognitive processes in LLMs or merely modify linguistic style.\nWe test this framework on three medical QA\n  datasets, employing neuron ablation and representation analysis techniques to\nassess changes in reasoning pathways. Our\n  results demonstrate that role prompts do not significantly enhance the\nmedical reasoning abilities of LLMs. Instead, they\n  primarily affect surface-level linguistic features, with no evidence of\ndistinct reasoning pathways or cognitive differentiation\n  across clinical roles. Despite superficial stylistic changes, the core\ndecision-making mechanisms of LLMs remain uniform\n  across roles, indicating that current PBRP methods fail to replicate the\ncognitive complexity found in real-world medical\n  practice. This highlights the limitations of role-playing in medical AI and\nemphasizes the need for models that simulate genuine\n  cognitive processes rather than linguistic imitation.We have released the\nrelated code in the following repository:https:\n  //github.com/IAAR-Shanghai/RolePlay_LLMDoctor",
    "categories": [
      "cs.CL",
      "cs.AI"
    ],
    "published": "2025-10-28T17:40:53Z",
    "authors": [
      "Xun Liang",
      "Huayi Lai",
      "Hanyu Wang",
      "Wentao Zhang",
      "Linfeng Zhang",
      "Yanfang Chen",
      "Feiyu Xiong",
      "Zhiyu Li"
    ],
    "pdf_url": "http://arxiv.org/pdf/2510.24677v1"
  },
  {
    "id": "2510.24674v1",
    "title": "Learning to Drive Safely with Hybrid Options",
    "abstract": "Out of the many deep reinforcement learning approaches for autonomous\ndriving, only few make use of the options (or skills) framework. That is\nsurprising, as this framework is naturally suited for hierarchical control\napplications in general, and autonomous driving tasks in specific. Therefore,\nin this work the options framework is applied and tailored to autonomous\ndriving tasks on highways. More specifically, we define dedicated options for\nlongitudinal and lateral manoeuvres with embedded safety and comfort\nconstraints. This way, prior domain knowledge can be incorporated into the\nlearning process and the learned driving behaviour can be constrained more\neasily. We propose several setups for hierarchical control with options and\nderive practical algorithms following state-of-the-art reinforcement learning\ntechniques. By separately selecting actions for longitudinal and lateral\ncontrol, the introduced policies over combined and hybrid options obtain the\nsame expressiveness and flexibility that human drivers have, while being easier\nto interpret than classical policies over continuous actions. Of all the\ninvestigated approaches, these flexible policies over hybrid options perform\nthe best under varying traffic conditions, outperforming the baseline policies\nover actions.",
    "categories": [
      "cs.LG",
      "cs.AI",
      "cs.SY",
      "eess.SY"
    ],
    "published": "2025-10-28T17:40:04Z",
    "authors": [
      "Bram De Cooman",
      "Johan Suykens"
    ],
    "pdf_url": "http://arxiv.org/pdf/2510.24674v1"
  },
  {
    "id": "2510.24671v1",
    "title": "Multi-Agent Scenario Generation in Roundabouts with a\n  Transformer-enhanced Conditional Variational Autoencoder",
    "abstract": "With the increasing integration of intelligent driving functions into\nserial-produced vehicles, ensuring their functionality and robustness poses\ngreater challenges. Compared to traditional road testing, scenario-based\nvirtual testing offers significant advantages in terms of time and cost\nefficiency, reproducibility, and exploration of edge cases. We propose a\nTransformer-enhanced Conditional Variational Autoencoder (CVAE-T) model for\ngenerating multi-agent traffic scenarios in roundabouts, which are\ncharacterized by high vehicle dynamics and complex layouts, yet remain\nrelatively underexplored in current research. The results show that the\nproposed model can accurately reconstruct original scenarios and generate\nrealistic, diverse synthetic scenarios. Besides, two Key-Performance-Indicators\n(KPIs) are employed to evaluate the interactive behavior in the generated\nscenarios. Analysis of the latent space reveals partial disentanglement, with\nseveral latent dimensions exhibiting distinct and interpretable effects on\nscenario attributes such as vehicle entry timing, exit timing, and velocity\nprofiles. The results demonstrate the model's capability to generate scenarios\nfor the validation of intelligent driving functions involving multi-agent\ninteractions, as well as to augment data for their development and iterative\nimprovement.",
    "categories": [
      "cs.RO",
      "cs.AI"
    ],
    "published": "2025-10-28T17:36:52Z",
    "authors": [
      "Li Li",
      "Tobias Brinkmann",
      "Till Temmen",
      "Markus Eisenbarth",
      "Jakob Andert"
    ],
    "pdf_url": "http://arxiv.org/pdf/2510.24671v1"
  },
  {
    "id": "2510.24668v1",
    "title": "InteractComp: Evaluating Search Agents With Ambiguous Queries",
    "abstract": "Language agents have demonstrated remarkable potential in web search and\ninformation retrieval. However, these search agents assume user queries are\ncomplete and unambiguous, an assumption that diverges from reality where users\nbegin with incomplete queries requiring clarification through interaction. Yet\nmost agents lack interactive mechanisms during the search process, and existing\nbenchmarks cannot assess this capability. To address this gap, we introduce\nInteractComp, a benchmark designed to evaluate whether search agents can\nrecognize query ambiguity and actively interact to resolve it during search.\nFollowing the principle of easy to verify, interact to disambiguate, we\nconstruct 210 expert-curated questions across 9 domains through a\ntarget-distractor methodology that creates genuine ambiguity resolvable only\nthrough interaction. Evaluation of 17 models reveals striking failure: the best\nmodel achieves only 13.73% accuracy despite 71.50% with complete context,\nexposing systematic overconfidence rather than reasoning deficits. Forced\ninteraction produces dramatic gains, demonstrating latent capability current\nstrategies fail to engage. Longitudinal analysis shows interaction capabilities\nstagnated over 15 months while search performance improved seven-fold,\nrevealing a critical blind spot. This stagnation, coupled with the immediate\nfeedback inherent to search tasks, makes InteractComp a valuable resource for\nboth evaluating and training interaction capabilities in search agents. The\ncode is available at https://github.com/FoundationAgents/InteractComp.",
    "categories": [
      "cs.CL",
      "cs.AI"
    ],
    "published": "2025-10-28T17:35:54Z",
    "authors": [
      "Mingyi Deng",
      "Lijun Huang",
      "Yani Fan",
      "Jiayi Zhang",
      "Fashen Ren",
      "Jinyi Bai",
      "Fuzhen Yang",
      "Dayi Miao",
      "Zhaoyang Yu",
      "Yifan Wu",
      "Yanfei Zhang",
      "Fengwei Teng",
      "Yingjia Wan",
      "Song Hu",
      "Yude Li",
      "Xin Jin",
      "Conghao Hu",
      "Haoyu Li",
      "Qirui Fu",
      "Tai Zhong",
      "Xinyu Wang",
      "Xiangru Tang",
      "Nan Tang",
      "Chenglin Wu",
      "Yuyu Luo"
    ],
    "pdf_url": "http://arxiv.org/pdf/2510.24668v1"
  },
  {
    "id": "2510.24663v1",
    "title": "OrchDAG: Complex Tool Orchestration in Multi-Turn Interactions with Plan\n  DAGs",
    "abstract": "Agentic tool use has gained traction with the rise of agentic tool calling,\nyet most existing work overlooks the complexity of multi-turn tool\ninteractions. We introduce OrchDAG, a synthetic data generation pipeline that\nmodels tool execution as directed acyclic graphs (DAGs) with controllable\ncomplexity. Using this dataset, we benchmark model performance and propose a\ngraph-based reward to enhance RLVR training. Experiments show that the dataset\npresents a challenging but solvable benchmark, and the proposed reward is\neffective when combined with GRPO-style algorithms, highlighting the importance\nof leveraging topological structure and data complexity in multi-turn tool use.",
    "categories": [
      "cs.AI"
    ],
    "published": "2025-10-28T17:28:01Z",
    "authors": [
      "Yifu Lu",
      "Shengjie Liu",
      "Li Dong"
    ],
    "pdf_url": "http://arxiv.org/pdf/2510.24663v1"
  },
  {
    "id": "2510.24650v1",
    "title": "Advancing site-specific disease and pest management in precision\n  agriculture: From reasoning-driven foundation models to adaptive,\n  feedback-based learning",
    "abstract": "Site-specific disease management (SSDM) in crops has advanced rapidly through\nmachine and deep learning (ML and DL) for real-time computer vision. Research\nevolved from handcrafted feature extraction to large-scale automated feature\nlearning. With foundation models (FMs), crop disease datasets are now processed\nin fundamentally new ways. Unlike traditional neural networks, FMs integrate\nvisual and textual data, interpret symptoms in text, reason about\nsymptom-management relationships, and support interactive QA for growers and\neducators. Adaptive and imitation learning in robotics further enables\nfield-based disease management. This review screened approx. 40 articles on FM\napplications for SSDM, focusing on large-language models (LLMs) and\nvision-language models (VLMs), and discussing their role in adaptive learning\n(AL), reinforcement learning (RL), and digital twin frameworks for targeted\nspraying. Key findings: (a) FMs are gaining traction with surging literature in\n2023-24; (b) VLMs outpace LLMs, with a 5-10x increase in publications; (c) RL\nand AL are still nascent for smart spraying; (d) digital twins with RL can\nsimulate targeted spraying virtually; (e) addressing the sim-to-real gap is\ncritical for real-world deployment; (f) human-robot collaboration remains\nlimited, especially in human-in-the-loop approaches where robots detect early\nsymptoms and humans validate uncertain cases; (g) multi-modal FMs with\nreal-time feedback will drive next-gen SSDM. For updates, resources, and\ncontributions, visit, https://github.com/nitin-dominic/AgriPathogenDatabase, to\nsubmit papers, code, or datasets.",
    "categories": [
      "cs.AI"
    ],
    "published": "2025-10-28T17:16:47Z",
    "authors": [
      "Nitin Rai",
      " Daeun",
      " Choi",
      "Nathan S. Boyd",
      "Arnold W. Schumann"
    ],
    "pdf_url": "http://arxiv.org/pdf/2510.24650v1"
  },
  {
    "id": "2510.24645v1",
    "title": "FunReason-MT Technical Report: Overcoming the Complexity Barrier in\n  Multi-Turn Function Calling",
    "abstract": "Function calling (FC) empowers large language models (LLMs) and autonomous\nagents to interface with external tools, a critical capability for solving\ncomplex, real-world problems. As this ability becomes increasingly central to\nadvanced AI systems, the need for high-quality, multi-turn training data to\ndevelop and refine it cannot be overstated. Existing data synthesis methods,\nsuch as random environment sampling or multi-agent role-playing, are not\npowerful enough to generate high-quality data in real-world environments.\nPractical challenges come in three folds: targeted model training, isolation of\ntool architecture, and multi-turn logical dependency. To address these\nstructural deficiencies, we present FunReason-MT, a novel data synthesis\nframework for real-world multi-turn tool use. FunReason-MT resolves the\ncomplexity barrier in multi-turn FC data by employing 1) Environment-API Graph\nInteractions to gather varied high-quality trajectories, 2) Advanced Tool-Query\nSynthesis to simplify hard query construction, and 3) Guided Iterative Chain\nfor sophisticated CoT generation. Evaluations on Berkeley Function-Calling\nLeaderboard (BFCLv3) demonstrate the power of our framework: a 4B model built\nupon FunReason-MT generated data achieves state-of-the-art performance among\ncomparable-sized models, outperforming most close-source models. Further\nperformance improvements on BFCLv4 confirm that FunReason-MT provides a\nreliable and robust source for agentic learning.",
    "categories": [
      "cs.AI"
    ],
    "published": "2025-10-28T17:15:26Z",
    "authors": [
      "Zengzhuang Xu",
      "Bingguang Hao",
      "Zechuan Wang",
      "Yuntao Wen",
      "Maolin Wang",
      "Yang Liu",
      "Long Chen",
      "Dong Wang",
      "Yicheng Chen",
      "Cunyin Peng",
      "Chenyi Zhuang",
      "Jinjie Gu",
      "Leilei Gan",
      "Xiangyu Zhao",
      "Shi Gu"
    ],
    "pdf_url": "http://arxiv.org/pdf/2510.24645v1"
  },
  {
    "id": "2510.24643v1",
    "title": "The Cost of Robustness: Tighter Bounds on Parameter Complexity for\n  Robust Memorization in ReLU Nets",
    "abstract": "We study the parameter complexity of robust memorization for $\\mathrm{ReLU}$\nnetworks: the number of parameters required to interpolate any given dataset\nwith $\\epsilon$-separation between differently labeled points, while ensuring\npredictions remain consistent within a $\\mu$-ball around each training sample.\nWe establish upper and lower bounds on the parameter count as a function of the\nrobustness ratio $\\rho = \\mu / \\epsilon$. Unlike prior work, we provide a\nfine-grained analysis across the entire range $\\rho \\in (0,1)$ and obtain\ntighter upper and lower bounds that improve upon existing results. Our findings\nreveal that the parameter complexity of robust memorization matches that of\nnon-robust memorization when $\\rho$ is small, but grows with increasing $\\rho$.",
    "categories": [
      "cs.LG",
      "cs.AI"
    ],
    "published": "2025-10-28T17:09:43Z",
    "authors": [
      "Yujun Kim",
      "Chaewon Moon",
      "Chulhee Yun"
    ],
    "pdf_url": "http://arxiv.org/pdf/2510.24643v1"
  },
  {
    "id": "2510.24639v1",
    "title": "Causal Ordering for Structure Learning From Time Series",
    "abstract": "Predicting causal structure from time series data is crucial for\nunderstanding complex phenomena in physiology, brain connectivity, climate\ndynamics, and socio-economic behaviour. Causal discovery in time series is\nhindered by the combinatorial complexity of identifying true causal\nrelationships, especially as the number of variables and time points grow. A\ncommon approach to simplify the task is the so-called ordering-based methods.\nTraditional ordering methods inherently limit the representational capacity of\nthe resulting model. In this work, we fix this issue by leveraging multiple\nvalid causal orderings, instead of a single one as standard practice. We\npropose DOTS (Diffusion Ordered Temporal Structure), using diffusion-based\ncausal discovery for temporal data. By integrating multiple orderings, DOTS\neffectively recovers the transitive closure of the underlying directed acyclic\ngraph, mitigating spurious artifacts inherent in single-ordering approaches. We\nformalise the problem under standard assumptions such as stationarity and the\nadditive noise model, and leverage score matching with diffusion processes to\nenable efficient Hessian estimation. Extensive experiments validate the\napproach. Empirical evaluations on synthetic and real-world datasets\ndemonstrate that DOTS outperforms state-of-the-art baselines, offering a\nscalable and robust approach to temporal causal discovery. On synthetic\nbenchmarks ($d{=}\\!3-\\!6$ variables, $T{=}200\\!-\\!5{,}000$ samples), DOTS\nimproves mean window-graph $F1$ from $0.63$ (best baseline) to $0.81$. On the\nCausalTime real-world benchmark ($d{=}20\\!-\\!36$), while baselines remain the\nbest on individual datasets, DOTS attains the highest average summary-graph\n$F1$ while halving runtime relative to graph-optimisation methods. These\nresults establish DOTS as a scalable and accurate solution for temporal causal\ndiscovery.",
    "categories": [
      "cs.LG",
      "cs.AI"
    ],
    "published": "2025-10-28T17:06:15Z",
    "authors": [
      "Pedro P. Sanchez",
      "Damian Machlanski",
      "Steven McDonagh",
      "Sotirios A. Tsaftaris"
    ],
    "pdf_url": "http://arxiv.org/pdf/2510.24639v1"
  },
  {
    "id": "2510.24637v1",
    "title": "All in one timestep: Enhancing Sparsity and Energy efficiency in\n  Multi-level Spiking Neural Networks",
    "abstract": "Spiking Neural Networks (SNNs) are one of the most promising bio-inspired\nneural networks models and have drawn increasing attention in recent years. The\nevent-driven communication mechanism of SNNs allows for sparse and\ntheoretically low-power operations on dedicated neuromorphic hardware. However,\nthe binary nature of instantaneous spikes also leads to considerable\ninformation loss in SNNs, resulting in accuracy degradation. To address this\nissue, we propose a multi-level spiking neuron model able to provide both\nlow-quantization error and minimal inference latency while approaching the\nperformance of full precision Artificial Neural Networks (ANNs). Experimental\nresults with popular network architectures and datasets, show that multi-level\nspiking neurons provide better information compression, allowing therefore a\nreduction in latency without performance loss. When compared to binary SNNs on\nimage classification scenarios, multi-level SNNs indeed allow reducing by 2 to\n3 times the energy consumption depending on the number of quantization\nintervals. On neuromorphic data, our approach allows us to drastically reduce\nthe inference latency to 1 timestep, which corresponds to a compression factor\nof 10 compared to previously published results. At the architectural level, we\npropose a new residual architecture that we call Sparse-ResNet. Through a\ncareful analysis of the spikes propagation in residual connections we highlight\na spike avalanche effect, that affects most spiking residual architectures.\nUsing our Sparse-ResNet architecture, we can provide state-of-the-art accuracy\nresults in image classification while reducing by more than 20% the network\nactivity compared to the previous spiking ResNets.",
    "categories": [
      "cs.NE",
      "cs.AI"
    ],
    "published": "2025-10-28T17:03:33Z",
    "authors": [
      "Andrea Castagnetti",
      "Alain Pegatoquet",
      "Beno\u00eet Miramond"
    ],
    "pdf_url": "http://arxiv.org/pdf/2510.24637v1"
  },
  {
    "id": "2510.24619v1",
    "title": "Zero-Shot Cross-Lingual Transfer using Prefix-Based Adaptation",
    "abstract": "With the release of new large language models (LLMs) like Llama and Mistral,\nzero-shot cross-lingual transfer has become increasingly feasible due to their\nmultilingual pretraining and strong generalization capabilities. However,\nadapting these decoder-only LLMs to new tasks across languages remains\nchallenging. While parameter-efficient fine-tuning (PeFT) techniques like\nLow-Rank Adaptation (LoRA) are widely used, prefix-based techniques such as\nsoft prompt tuning, prefix tuning, and Llama Adapter are less explored,\nespecially for zero-shot transfer in decoder-only models. We present a\ncomprehensive study of three prefix-based methods for zero-shot cross-lingual\ntransfer from English to 35+ high- and low-resource languages. Our analysis\nfurther explores transfer across linguistic families and scripts, as well as\nthe impact of scaling model sizes from 1B to 24B. With Llama 3.1 8B, prefix\nmethods outperform LoRA-baselines by up to 6% on the Belebele benchmark.\nSimilar improvements were observed with Mistral v0.3 7B as well. Despite using\nonly 1.23M learning parameters with prefix tuning, we achieve consistent\nimprovements across diverse benchmarks. These findings highlight the potential\nof prefix-based techniques as an effective and scalable alternative to LoRA,\nparticularly in low-resource multilingual settings.",
    "categories": [
      "cs.CL",
      "cs.AI",
      "cs.LG",
      "I.2.7"
    ],
    "published": "2025-10-28T16:48:03Z",
    "authors": [
      "Snegha A",
      "Sayambhu Sen",
      "Piyush Singh Pasi",
      "Abhishek Singhania",
      "Preethi Jyothi"
    ],
    "pdf_url": "http://arxiv.org/pdf/2510.24619v1"
  },
  {
    "id": "2510.24831v1",
    "title": "The Narrative Continuity Test: A Conceptual Framework for Evaluating\n  Identity Persistence in AI Systems",
    "abstract": "Artificial intelligence systems based on large language models (LLMs) can now\ngenerate coherent text, music, and images, yet they operate without a\npersistent state: each inference reconstructs context from scratch. This paper\nintroduces the Narrative Continuity Test (NCT) -- a conceptual framework for\nevaluating identity persistence and diachronic coherence in AI systems. Unlike\ncapability benchmarks that assess task performance, the NCT examines whether an\nLLM remains the same interlocutor across time and interaction gaps. The\nframework defines five necessary axes -- Situated Memory, Goal Persistence,\nAutonomous Self-Correction, Stylistic & Semantic Stability, and Persona/Role\nContinuity -- and explains why current architectures systematically fail to\nsupport them. Case analyses (Character.AI, Grok, Replit, Air Canada) show\npredictable continuity failures under stateless inference. The NCT reframes AI\nevaluation from performance to persistence, outlining conceptual requirements\nfor future benchmarks and architectural designs that could sustain long-term\nidentity and goal coherence in generative models.",
    "categories": [
      "cs.CY",
      "cs.AI",
      "cs.HC"
    ],
    "published": "2025-10-28T16:44:30Z",
    "authors": [
      "Stefano Natangelo"
    ],
    "pdf_url": "http://arxiv.org/pdf/2510.24831v1"
  },
  {
    "id": "2510.24830v1",
    "title": "The Generation Phases of Flow Matching: a Denoising Perspective",
    "abstract": "Flow matching has achieved remarkable success, yet the factors influencing\nthe quality of its generation process remain poorly understood. In this work,\nwe adopt a denoising perspective and design a framework to empirically probe\nthe generation process. Laying down the formal connections between flow\nmatching models and denoisers, we provide a common ground to compare their\nperformances on generation and denoising. This enables the design of principled\nand controlled perturbations to influence sample generation: noise and drift.\nThis leads to new insights on the distinct dynamical phases of the generative\nprocess, enabling us to precisely characterize at which stage of the generative\nprocess denoisers succeed or fail and why this matters.",
    "categories": [
      "cs.CV",
      "cs.AI",
      "cs.LG"
    ],
    "published": "2025-10-28T16:42:53Z",
    "authors": [
      "Anne Gagneux",
      "S\u00e9gol\u00e8ne Martin",
      "R\u00e9mi Gribonval",
      "Mathurin Massias"
    ],
    "pdf_url": "http://arxiv.org/pdf/2510.24830v1"
  },
  {
    "id": "2510.24574v1",
    "title": "DistDF: Time-Series Forecasting Needs Joint-Distribution Wasserstein\n  Alignment",
    "abstract": "Training time-series forecast models requires aligning the conditional\ndistribution of model forecasts with that of the label sequence. The standard\ndirect forecast (DF) approach resorts to minimize the conditional negative\nlog-likelihood of the label sequence, typically estimated using the mean\nsquared error. However, this estimation proves to be biased in the presence of\nlabel autocorrelation. In this paper, we propose DistDF, which achieves\nalignment by alternatively minimizing a discrepancy between the conditional\nforecast and label distributions. Because conditional discrepancies are\ndifficult to estimate from finite time-series observations, we introduce a\nnewly proposed joint-distribution Wasserstein discrepancy for time-series\nforecasting, which provably upper bounds the conditional discrepancy of\ninterest. This discrepancy admits tractable, differentiable estimation from\nempirical samples and integrates seamlessly with gradient-based training.\nExtensive experiments show that DistDF improves the performance diverse\nforecast models and achieves the state-of-the-art forecasting performance. Code\nis available at https://anonymous.4open.science/r/DistDF-F66B.",
    "categories": [
      "cs.LG",
      "cs.AI"
    ],
    "published": "2025-10-28T16:09:59Z",
    "authors": [
      "Hao Wang",
      "Licheng Pan",
      "Yuan Lu",
      "Zhixuan Chu",
      "Xiaoxi Li",
      "Shuting He",
      "Zhichao Chen",
      "Haoxuan Li",
      "Qingsong Wen",
      "Zhouchen Lin"
    ],
    "pdf_url": "http://arxiv.org/pdf/2510.24574v1"
  },
  {
    "id": "2510.24561v1",
    "title": "LoRA-DA: Data-Aware Initialization for Low-Rank Adaptation via\n  Asymptotic Analysis",
    "abstract": "With the widespread adoption of LLMs, LoRA has become a dominant method for\nPEFT, and its initialization methods have attracted increasing attention.\nHowever, existing methods have notable limitations: many methods do not\nincorporate target-domain data, while gradient-based methods exploit data only\nat a shallow level by relying on one-step gradient decomposition, which remains\nunsatisfactory due to the weak empirical performance of the one-step\nfine-tuning model that serves as their basis, as well as the fact that these\nmethods either lack a rigorous theoretical foundation or depend heavily on\nrestrictive isotropic assumptions. In this paper, we establish a theoretical\nframework for data-aware LoRA initialization based on asymptotic analysis.\nStarting from a general optimization objective that minimizes the expectation\nof the parameter discrepancy between the fine-tuned and target models, we\nderive an optimization problem with two components: a bias term, which is\nrelated to the parameter distance between the fine-tuned and target models, and\nis approximated using a Fisher-gradient formulation to preserve anisotropy; and\na variance term, which accounts for the uncertainty introduced by sampling\nstochasticity through the Fisher information. By solving this problem, we\nobtain an optimal initialization strategy for LoRA. Building on this\ntheoretical framework, we develop an efficient algorithm, LoRA-DA, which\nestimates the terms in the optimization problem from a small set of target\ndomain samples and obtains the optimal LoRA initialization. Empirical results\nacross multiple benchmarks demonstrate that LoRA-DA consistently improves final\naccuracy over existing initialization methods. Additional studies show faster,\nmore stable convergence, robustness across ranks, and only a small\ninitialization overhead for LoRA-DA. The source code will be released upon\npublication.",
    "categories": [
      "cs.LG",
      "cs.AI"
    ],
    "published": "2025-10-28T15:55:36Z",
    "authors": [
      "Qingyue Zhang",
      "Chang Chu",
      "Tianren Peng",
      "Qi Li",
      "Xiangyang Luo",
      "Zhihao Jiang",
      "Shao-Lun Huang"
    ],
    "pdf_url": "http://arxiv.org/pdf/2510.24561v1"
  },
  {
    "id": "2510.25786v1",
    "title": "BlackboxNLP-2025 MIB Shared Task: Improving Circuit Faithfulness via\n  Better Edge Selection",
    "abstract": "One of the main challenges in mechanistic interpretability is circuit\ndiscovery, determining which parts of a model perform a given task. We build on\nthe Mechanistic Interpretability Benchmark (MIB) and propose three key\nimprovements to circuit discovery. First, we use bootstrapping to identify\nedges with consistent attribution scores. Second, we introduce a simple\nratio-based selection strategy to prioritize strong positive-scoring edges,\nbalancing performance and faithfulness. Third, we replace the standard greedy\nselection with an integer linear programming formulation. Our methods yield\nmore faithful circuits and outperform prior approaches across multiple MIB\ntasks and models. Our code is available at:\nhttps://github.com/technion-cs-nlp/MIB-Shared-Task.",
    "categories": [
      "cs.CL",
      "cs.AI"
    ],
    "published": "2025-10-28T15:49:34Z",
    "authors": [
      "Yaniv Nikankin",
      "Dana Arad",
      "Itay Itzhak",
      "Anja Reusch",
      "Adi Simhi",
      "Gal Kesten-Pomeranz",
      "Yonatan Belinkov"
    ],
    "pdf_url": "http://arxiv.org/pdf/2510.25786v1"
  },
  {
    "id": "2510.24551v1",
    "title": "Generative AI for Healthcare: Fundamentals, Challenges, and Perspectives",
    "abstract": "Generative Artificial Intelligence (GenAI) is taking the world by storm. It\npromises transformative opportunities for advancing and disrupting existing\npractices, including healthcare. From large language models (LLMs) for clinical\nnote synthesis and conversational assistance to multimodal systems that\nintegrate medical imaging, electronic health records, and genomic data for\ndecision support, GenAI is transforming the practice of medicine and the\ndelivery of healthcare, such as diagnosis and personalized treatments, with\ngreat potential in reducing the cognitive burden on clinicians, thereby\nimproving overall healthcare delivery. However, GenAI deployment in healthcare\nrequires an in-depth understanding of healthcare tasks and what can and cannot\nbe achieved. In this paper, we propose a data-centric paradigm in the design\nand deployment of GenAI systems for healthcare. Specifically, we reposition the\ndata life cycle by making the medical data ecosystem as the foundational\nsubstrate for generative healthcare systems. This ecosystem is designed to\nsustainably support the integration, representation, and retrieval of diverse\nmedical data and knowledge. With effective and efficient data processing\npipelines, such as semantic vector search and contextual querying, it enables\nGenAI-powered operations for upstream model components and downstream clinical\napplications. Ultimately, it not only supplies foundation models with\nhigh-quality, multimodal data for large-scale pretraining and domain-specific\nfine-tuning, but also serves as a knowledge retrieval backend to support\ntask-specific inference via the agentic layer. The ecosystem enables the\ndeployment of GenAI for high-quality and effective healthcare delivery.",
    "categories": [
      "cs.AI"
    ],
    "published": "2025-10-28T15:47:44Z",
    "authors": [
      "Gang Chen",
      "Changshuo Liu",
      "Gene Anne Ooi",
      "Marcus Tan",
      "Zhongle Xie",
      "Jianwei Yin",
      "James Wei Luen Yip",
      "Wenqiao Zhang",
      "Jiaqi Zhu",
      "Beng Chin Ooi"
    ],
    "pdf_url": "http://arxiv.org/pdf/2510.24551v1"
  },
  {
    "id": "2510.24534v1",
    "title": "Quantum-Resistant Networks Using Post-Quantum Cryptography",
    "abstract": "Quantum networks rely on both quantum and classical channels for coordinated\noperation. Current architectures employ entanglement distribution and key\nexchange over quantum channels but often assume that classical communication is\nsufficiently secure. In practice, classical channels protected by traditional\ncryptography remain vulnerable to quantum adversaries, since large-scale\nquantum computers could break widely used public-key schemes and reduce the\neffective security of symmetric cryptography. This perspective presents a\nquantum-resistant network architecture that secures classical communication\nwith post-quantum cryptographic techniques while supporting entanglement-based\ncommunication over quantum channels. Beyond cryptographic protection, the\nframework incorporates continuous monitoring of both quantum and classical\nlayers, together with orchestration across heterogeneous infrastructures, to\nensure end-to-end security. Collectively, these mechanisms provide a pathway\ntoward scalable, robust, and secure quantum networks that remain dependable\nagainst both classical and quantum-era threats.",
    "categories": [
      "quant-ph",
      "cs.AI",
      "cs.CR"
    ],
    "published": "2025-10-28T15:39:12Z",
    "authors": [
      "Xin Jin",
      "Nitish Kumar Chandra",
      "Mohadeseh Azari",
      "Kaushik P. Seshadreesan",
      "Junyu Liu"
    ],
    "pdf_url": "http://arxiv.org/pdf/2510.24534v1"
  },
  {
    "id": "2510.24528v1",
    "title": "From Cross-Task Examples to In-Task Prompts: A Graph-Based\n  Pseudo-Labeling Framework for In-context Learning",
    "abstract": "The capability of in-context learning (ICL) enables large language models\n(LLMs) to perform novel tasks without parameter updates by conditioning on a\nfew input-output examples. However, collecting high-quality examples for new or\nchallenging tasks can be costly and labor-intensive. In this work, we propose a\ncost-efficient two-stage pipeline that reduces reliance on LLMs for data\nlabeling. Our approach first leverages readily available cross-task examples to\nprompt an LLM and pseudo-label a small set of target task instances. We then\nintroduce a graph-based label propagation method that spreads label information\nto the remaining target examples without additional LLM queries. The resulting\nfully pseudo-labeled dataset is used to construct in-task demonstrations for\nICL. This pipeline combines the flexibility of cross-task supervision with the\nscalability of LLM-free propagation. Experiments across five tasks demonstrate\nthat our method achieves strong performance while lowering labeling costs.",
    "categories": [
      "cs.AI"
    ],
    "published": "2025-10-28T15:37:51Z",
    "authors": [
      "Zihan Chen",
      "Song Wang",
      "Xingbo Fu",
      "Chengshuai Shi",
      "Zhenyu Lei",
      "Cong Shen",
      "Jundong Li"
    ],
    "pdf_url": "http://arxiv.org/pdf/2510.24528v1"
  },
  {
    "id": "2510.24519v2",
    "title": "Audio Signal Processing Using Time Domain Mel-Frequency Wavelet\n  Coefficient",
    "abstract": "Extracting features from the speech is the most critical process in speech\nsignal processing. Mel Frequency Cepstral Coefficients (MFCC) are the most\nwidely used features in the majority of the speaker and speech recognition\napplications, as the filtering in this feature is similar to the filtering\ntaking place in the human ear. But the main drawback of this feature is that it\nprovides only the frequency information of the signal but does not provide the\ninformation about at what time which frequency is present. The wavelet\ntransform, with its flexible time-frequency window, provides time and frequency\ninformation of the signal and is an appropriate tool for the analysis of\nnon-stationary signals like speech. On the other hand, because of its uniform\nfrequency scaling, a typical wavelet transform may be less effective in\nanalysing speech signals, have poorer frequency resolution in low frequencies,\nand be less in line with human auditory perception. Hence, it is necessary to\ndevelop a feature that incorporates the merits of both MFCC and wavelet\ntransform. A great deal of studies are trying to combine both these features.\nThe present Wavelet Transform based Mel-scaled feature extraction methods\nrequire more computation when a wavelet transform is applied on top of\nMel-scale filtering, since it adds extra processing steps. Here we are\nproposing a method to extract Mel scale features in time domain combining the\nconcept of wavelet transform, thus reducing the computational burden of\ntime-frequency conversion and the complexity of wavelet extraction. Combining\nour proposed Time domain Mel frequency Wavelet Coefficient(TMFWC) technique\nwith the reservoir computing methodology has significantly improved the\nefficiency of audio signal processing.",
    "categories": [
      "cs.SD",
      "cs.AI",
      "eess.AS"
    ],
    "published": "2025-10-28T15:31:52Z",
    "authors": [
      "Rinku Sebastian",
      "Simon O'Keefe",
      "Martin Trefzer"
    ],
    "pdf_url": "http://arxiv.org/pdf/2510.24519v2"
  },
  {
    "id": "2510.24823v1",
    "title": "Do Chatbots Walk the Talk of Responsible AI?",
    "abstract": "This study examines whether leading AI chatbot companies implement the\nresponsible AI principles they publicly advocate. The authors used a\nmixed-methods approach analyzing four major chatbots (ChatGPT, Gemini,\nDeepSeek, and Grok) across company websites, technical documentation, and\ndirect chatbot evaluations. We found significant gaps between corporate\nrhetoric and practice.",
    "categories": [
      "cs.CY",
      "cs.AI"
    ],
    "published": "2025-10-28T15:31:24Z",
    "authors": [
      "Susan Ariel Aaronson",
      "Michael Moreno"
    ],
    "pdf_url": "http://arxiv.org/pdf/2510.24823v1"
  },
  {
    "id": "2510.24821v1",
    "title": "Ming-Flash-Omni: A Sparse, Unified Architecture for Multimodal\n  Perception and Generation",
    "abstract": "We propose Ming-Flash-Omni, an upgraded version of Ming-Omni, built upon a\nsparser Mixture-of-Experts (MoE) variant of Ling-Flash-2.0 with 100 billion\ntotal parameters, of which only 6.1 billion are active per token. This\narchitecture enables highly efficient scaling (dramatically improving\ncomputational efficiency while significantly expanding model capacity) and\nempowers stronger unified multimodal intelligence across vision, speech, and\nlanguage, representing a key step toward Artificial General Intelligence (AGI).\nCompared to its predecessor, the upgraded version exhibits substantial\nimprovements across multimodal understanding and generation. We significantly\nadvance speech recognition capabilities, achieving state-of-the-art performance\nin contextual ASR and highly competitive results in dialect-aware ASR. In image\ngeneration, Ming-Flash-Omni introduces high-fidelity text rendering and\ndemonstrates marked gains in scene consistency and identity preservation during\nimage editing. Furthermore, Ming-Flash-Omni introduces generative segmentation,\na capability that not only achieves strong standalone segmentation performance\nbut also enhances spatial control in image generation and improves editing\nconsistency. Notably, Ming-Flash-Omni achieves state-of-the-art results in\ntext-to-image generation and generative segmentation, and sets new records on\nall 12 contextual ASR benchmarks, all within a single unified architecture.",
    "categories": [
      "cs.CV",
      "cs.AI"
    ],
    "published": "2025-10-28T15:24:13Z",
    "authors": [
      "Inclusion AI",
      " :",
      "Bowen Ma",
      "Cheng Zou",
      "Canxiang Yan",
      "Chunxiang Jin",
      "Chunjie Shen",
      "Dandan Zheng",
      "Fudong Wang",
      "Furong Xu",
      "GuangMing Yao",
      "Jun Zhou",
      "Jingdong Chen",
      "Jianing Li",
      "Jianxin Sun",
      "Jiajia Liu",
      "Jianjiang Zhu",
      "Jianping Jiang",
      "Jun Peng",
      "Kaixiang Ji",
      "Kaimeng Ren",
      "Libin Wang",
      "Lixiang Ru",
      "Longhua Tan",
      "Lan Wang",
      "Mochen Bai",
      "Ning Gao",
      "Qingpei Guo",
      "Qinglong Zhang",
      "Qiang Xu",
      "Rui Liu",
      "Ruijie Xiong",
      "Ruobing Zheng",
      "Sirui Gao",
      "Tianqi Li",
      "Tinghao Liu",
      "Weilong Chai",
      "Xinyu Xiao",
      "Xiaomei Wang",
      "Xiaolong Wang",
      "Xiao Lu",
      "Xiaoyu Li",
      "Xingning Dong",
      "Xuzheng Yu",
      "Yi Yuan",
      "Yuting Gao",
      "Yuting Xiao",
      "Yunxiao Sun",
      "Yipeng Chen",
      "Yifan Mao",
      "Yifei Wu",
      "Yongjie Lyu",
      "Ziping Ma",
      "Zhiqiang Fang",
      "Zhihao Qiu",
      "Ziyuan Huang",
      "Zizheng Yang",
      "Zhengyu He"
    ],
    "pdf_url": "http://arxiv.org/pdf/2510.24821v1"
  },
  {
    "id": "2510.24503v1",
    "title": "Local Performance vs. Out-of-Distribution Generalization: An Empirical\n  Analysis of Personalized Federated Learning in Heterogeneous Data\n  Environments",
    "abstract": "In the context of Federated Learning with heterogeneous data environments,\nlocal models tend to converge to their own local model optima during local\ntraining steps, deviating from the overall data distributions. Aggregation of\nthese local updates, e.g., with FedAvg, often does not align with the global\nmodel optimum (client drift), resulting in an update that is suboptimal for\nmost clients. Personalized Federated Learning approaches address this challenge\nby exclusively focusing on the average local performances of clients' models on\ntheir own data distribution. Generalization to out-of-distribution samples,\nwhich is a substantial benefit of FedAvg and represents a significant component\nof robustness, appears to be inadequately incorporated into the assessment and\nevaluation processes. This study involves a thorough evaluation of Federated\nLearning approaches, encompassing both their local performance and their\ngeneralization capabilities. Therefore, we examine different stages within a\nsingle communication round to enable a more nuanced understanding of the\nconsidered metrics. Furthermore, we propose and incorporate a modified approach\nof FedAvg, designated as Federated Learning with Individualized Updates (FLIU),\nextending the algorithm by a straightforward individualization step with an\nadaptive personalization factor. We evaluate and compare the approaches\nempirically using MNIST and CIFAR-10 under various distributional conditions,\nincluding benchmark IID and pathological non-IID, as well as additional novel\ntest environments with Dirichlet distribution specifically developed to stress\nthe algorithms on complex data heterogeneity.",
    "categories": [
      "cs.LG",
      "cs.AI",
      "cs.CV",
      "cs.DC",
      "cs.MA"
    ],
    "published": "2025-10-28T15:15:14Z",
    "authors": [
      "Mortesa Hussaini",
      "Jan Thei\u00df",
      "Anthony Stein"
    ],
    "pdf_url": "http://arxiv.org/pdf/2510.24503v1"
  },
  {
    "id": "2510.24498v1",
    "title": "Design and Optimization of Cloud Native Homomorphic Encryption Workflows\n  for Privacy-Preserving ML Inference",
    "abstract": "As machine learning (ML) models become increasingly deployed through cloud\ninfrastructures, the confidentiality of user data during inference poses a\nsignificant security challenge. Homomorphic Encryption (HE) has emerged as a\ncompelling cryptographic technique that enables computation on encrypted data,\nallowing predictions to be generated without decrypting sensitive inputs.\nHowever, the integration of HE within large scale cloud native pipelines\nremains constrained by high computational overhead, orchestration complexity,\nand model compatibility issues.\n  This paper presents a systematic framework for the design and optimization of\ncloud native homomorphic encryption workflows that support privacy-preserving\nML inference. The proposed architecture integrates containerized HE modules\nwith Kubernetes-based orchestration, enabling elastic scaling and parallel\nencrypted computation across distributed environments. Furthermore,\noptimization strategies including ciphertext packing, polynomial modulus\nadjustment, and operator fusion are employed to minimize latency and resource\nconsumption while preserving cryptographic integrity. Experimental results\ndemonstrate that the proposed system achieves up to 3.2times inference\nacceleration and 40% reduction in memory utilization compared to conventional\nHE pipelines. These findings illustrate a practical pathway for deploying\nsecure ML-as-a-Service (MLaaS) systems that guarantee data confidentiality\nunder zero-trust cloud conditions.",
    "categories": [
      "cs.CR",
      "cs.AI"
    ],
    "published": "2025-10-28T15:13:32Z",
    "authors": [
      "Tejaswini Bollikonda"
    ],
    "pdf_url": "http://arxiv.org/pdf/2510.24498v1"
  },
  {
    "id": "2510.24497v1",
    "title": "Online neural fusion of distortionless differential beamformers for\n  robust speech enhancement",
    "abstract": "Fixed beamforming is widely used in practice since it does not depend on the\nestimation of noise statistics and provides relatively stable performance.\nHowever, a single beamformer cannot adapt to varying acoustic conditions, which\nlimits its interference suppression capability. To address this, adaptive\nconvex combination (ACC) algorithms have been introduced, where the outputs of\nmultiple fixed beamformers are linearly combined to improve robustness.\nNevertheless, ACC often fails in highly non-stationary scenarios, such as\nrapidly moving interference, since its adaptive updates cannot reliably track\nrapid changes. To overcome this limitation, we propose a frame-online neural\nfusion framework for multiple distortionless differential beamformers, which\nestimates the combination weights through a neural network. Compared with\nconventional ACC, the proposed method adapts more effectively to dynamic\nacoustic environments, achieving stronger interference suppression while\nmaintaining the distortionless constraint.",
    "categories": [
      "cs.SD",
      "cs.AI",
      "eess.AS"
    ],
    "published": "2025-10-28T15:12:48Z",
    "authors": [
      "Yuanhang Qian",
      "Kunlong Zhao",
      "Jilu Jin",
      "Xueqin Luo",
      "Gongping Huang",
      "Jingdong Chen",
      "Jacob Benesty"
    ],
    "pdf_url": "http://arxiv.org/pdf/2510.24497v1"
  },
  {
    "id": "2510.24820v1",
    "title": "SafeEditor: Unified MLLM for Efficient Post-hoc T2I Safety Editing",
    "abstract": "With the rapid advancement of text-to-image (T2I) models, ensuring their\nsafety has become increasingly critical. Existing safety approaches can be\ncategorized into training-time and inference-time methods. While inference-time\nmethods are widely adopted due to their cost-effectiveness, they often suffer\nfrom limitations such as over-refusal and imbalance between safety and utility.\nTo address these challenges, we propose a multi-round safety editing framework\nthat functions as a model-agnostic, plug-and-play module, enabling efficient\nsafety alignment for any text-to-image model. Central to this framework is\nMR-SafeEdit, a multi-round image-text interleaved dataset specifically\nconstructed for safety editing in text-to-image generation. We introduce a\npost-hoc safety editing paradigm that mirrors the human cognitive process of\nidentifying and refining unsafe content. To instantiate this paradigm, we\ndevelop SafeEditor, a unified MLLM capable of multi-round safety editing on\ngenerated images. Experimental results show that SafeEditor surpasses prior\nsafety approaches by reducing over-refusal while achieving a more favorable\nsafety-utility balance.",
    "categories": [
      "cs.CV",
      "cs.AI"
    ],
    "published": "2025-10-28T15:12:15Z",
    "authors": [
      "Ruiyang Zhang",
      "Jiahao Luo",
      "Xiaoru Feng",
      "Qiufan Pang",
      "Yaodong Yang",
      "Juntao Dai"
    ],
    "pdf_url": "http://arxiv.org/pdf/2510.24820v1"
  },
  {
    "id": "2510.24495v1",
    "title": "Diffusion Models for Wireless Transceivers: From Pilot-Efficient Channel\n  Estimation to AI-Native 6G Receivers",
    "abstract": "With the development of artificial intelligence (AI) techniques, implementing\nAI-based techniques to improve wireless transceivers becomes an emerging\nresearch topic. Within this context, AI-based channel characterization and\nestimation become the focus since these methods have not been solved by\ntraditional methods very well and have become the bottleneck of transceiver\nefficiency in large-scale orthogonal frequency division multiplexing (OFDM)\nsystems. Specifically, by formulating channel estimation as a generative AI\nproblem, generative AI methods such as diffusion models (DMs) can efficiently\ndeal with rough initial estimations and have great potential to cooperate with\ntraditional signal processing methods. This paper focuses on the transceiver\ndesign of OFDM systems based on DMs, provides an illustration of the potential\nof DMs in wireless transceivers, and points out the related research directions\nbrought by DMs. We also provide a proof-of-concept case study of further\nadapting DMs for better wireless receiver performance.",
    "categories": [
      "eess.SP",
      "cs.AI"
    ],
    "published": "2025-10-28T15:10:11Z",
    "authors": [
      "Yuzhi Yang",
      "Sen Yan",
      "Weijie Zhou",
      "Brahim Mefgouda",
      "Ridong Li",
      "Zhaoyang Zhang",
      "M\u00e9rouane Debbah"
    ],
    "pdf_url": "http://arxiv.org/pdf/2510.24495v1"
  },
  {
    "id": "2510.24488v1",
    "title": "A word association network methodology for evaluating implicit biases in\n  LLMs compared to humans",
    "abstract": "As Large language models (LLMs) become increasingly integrated into our\nlives, their inherent social biases remain a pressing concern. Detecting and\nevaluating these biases can be challenging because they are often implicit\nrather than explicit in nature, so developing evaluation methods that assess\nthe implicit knowledge representations of LLMs is essential. We present a novel\nword association network methodology for evaluating implicit biases in LLMs\nbased on simulating semantic priming within LLM-generated word association\nnetworks. Our prompt-based approach taps into the implicit relational\nstructures encoded in LLMs, providing both quantitative and qualitative\nassessments of bias. Unlike most prompt-based evaluation methods, our method\nenables direct comparisons between various LLMs and humans, providing a\nvaluable point of reference and offering new insights into the alignment of\nLLMs with human cognition. To demonstrate the utility of our methodology, we\napply it to both humans and several widely used LLMs to investigate social\nbiases related to gender, religion, ethnicity, sexual orientation, and\npolitical party. Our results reveal both convergences and divergences between\nLLM and human biases, providing new perspectives on the potential risks of\nusing LLMs. Our methodology contributes to a systematic, scalable, and\ngeneralizable framework for evaluating and comparing biases across multiple\nLLMs and humans, advancing the goal of transparent and socially responsible\nlanguage technologies.",
    "categories": [
      "cs.CL",
      "cs.AI"
    ],
    "published": "2025-10-28T15:03:18Z",
    "authors": [
      "Katherine Abramski",
      "Giulio Rossetti",
      "Massimo Stella"
    ],
    "pdf_url": "http://arxiv.org/pdf/2510.24488v1"
  },
  {
    "id": "2510.24482v1",
    "title": "Sample-efficient and Scalable Exploration in Continuous-Time RL",
    "abstract": "Reinforcement learning algorithms are typically designed for discrete-time\ndynamics, even though the underlying real-world control systems are often\ncontinuous in time. In this paper, we study the problem of continuous-time\nreinforcement learning, where the unknown system dynamics are represented using\nnonlinear ordinary differential equations (ODEs). We leverage probabilistic\nmodels, such as Gaussian processes and Bayesian neural networks, to learn an\nuncertainty-aware model of the underlying ODE. Our algorithm, COMBRL, greedily\nmaximizes a weighted sum of the extrinsic reward and model epistemic\nuncertainty. This yields a scalable and sample-efficient approach to\ncontinuous-time model-based RL. We show that COMBRL achieves sublinear regret\nin the reward-driven setting, and in the unsupervised RL setting (i.e., without\nextrinsic rewards), we provide a sample complexity bound. In our experiments,\nwe evaluate COMBRL in both standard and unsupervised RL settings and\ndemonstrate that it scales better, is more sample-efficient than prior methods,\nand outperforms baselines across several deep RL tasks.",
    "categories": [
      "cs.LG",
      "cs.AI",
      "cs.RO"
    ],
    "published": "2025-10-28T14:54:12Z",
    "authors": [
      "Klemens Iten",
      "Lenart Treven",
      "Bhavya Sukhija",
      "Florian D\u00f6rfler",
      "Andreas Krause"
    ],
    "pdf_url": "http://arxiv.org/pdf/2510.24482v1"
  },
  {
    "id": "2510.24476v1",
    "title": "Mitigating Hallucination in Large Language Models (LLMs): An\n  Application-Oriented Survey on RAG, Reasoning, and Agentic Systems",
    "abstract": "Hallucination remains one of the key obstacles to the reliable deployment of\nlarge language models (LLMs), particularly in real-world applications. Among\nvarious mitigation strategies, Retrieval-Augmented Generation (RAG) and\nreasoning enhancement have emerged as two of the most effective and widely\nadopted approaches, marking a shift from merely suppressing hallucinations to\nbalancing creativity and reliability. However, their synergistic potential and\nunderlying mechanisms for hallucination mitigation have not yet been\nsystematically examined. This survey adopts an application-oriented perspective\nof capability enhancement to analyze how RAG, reasoning enhancement, and their\nintegration in Agentic Systems mitigate hallucinations. We propose a taxonomy\ndistinguishing knowledge-based and logic-based hallucinations, systematically\nexamine how RAG and reasoning address each, and present a unified framework\nsupported by real-world applications, evaluations, and benchmarks.",
    "categories": [
      "cs.CL",
      "cs.AI"
    ],
    "published": "2025-10-28T14:48:57Z",
    "authors": [
      "Yihan Li",
      "Xiyuan Fu",
      "Ghanshyam Verma",
      "Paul Buitelaar",
      "Mingming Liu"
    ],
    "pdf_url": "http://arxiv.org/pdf/2510.24476v1"
  },
  {
    "id": "2510.24469v1",
    "title": "Iterative Critique-Refine Framework for Enhancing LLM Personalization",
    "abstract": "Personalized text generation requires models not only to produce coherent\ntext but also to align with a target user's style, tone, and topical focus.\nExisting retrieval-augmented approaches such as LaMP and PGraphRAG enrich\nprofiles with user and neighbor histories, but they stop at generation and\noften yield outputs that drift in tone, topic, or style. We present PerFine, a\nunified, training-free critique-refine framework that enhances personalization\nthrough iterative, profile-grounded feedback. In each iteration, an LLM\ngenerator produces a draft conditioned on the retrieved profile, and a critic\nLLM - also conditioned on the same profile - provides structured feedback on\ntone, vocabulary, sentence structure, and topicality. The generator then\nrevises, while a novel knockout strategy retains the stronger draft across\niterations. We further study additional inference-time strategies such as\nBest-of-N and Topic Extraction to balance quality and efficiency. Across Yelp,\nGoodreads, and Amazon datasets, PerFine consistently improves personalization\nover PGraphRAG, with GEval gains of +7-13%, steady improvements over 3-5\nrefinement iterations, and scalability with increasing critic size. These\nresults highlight that post-hoc, profile-aware feedback offers a powerful\nparadigm for personalized LLM generation that is both training-free and\nmodel-agnostic.",
    "categories": [
      "cs.CL",
      "cs.AI",
      "cs.IR"
    ],
    "published": "2025-10-28T14:36:22Z",
    "authors": [
      "Durga Prasad Maram",
      "Dhruvin Gandhi",
      "Zonghai Yao",
      "Gayathri Akkinapalli",
      "Franck Dernoncourt",
      "Yu Wang",
      "Ryan A. Rossi",
      "Nesreen K. Ahmed"
    ],
    "pdf_url": "http://arxiv.org/pdf/2510.24469v1"
  },
  {
    "id": "2510.24461v1",
    "title": "Adaptive Surrogate Gradients for Sequential Reinforcement Learning in\n  Spiking Neural Networks",
    "abstract": "Neuromorphic computing systems are set to revolutionize energy-constrained\nrobotics by achieving orders-of-magnitude efficiency gains, while enabling\nnative temporal processing. Spiking Neural Networks (SNNs) represent a\npromising algorithmic approach for these systems, yet their application to\ncomplex control tasks faces two critical challenges: (1) the non-differentiable\nnature of spiking neurons necessitates surrogate gradients with unclear\noptimization properties, and (2) the stateful dynamics of SNNs require training\non sequences, which in reinforcement learning (RL) is hindered by limited\nsequence lengths during early training, preventing the network from bridging\nits warm-up period.\n  We address these challenges by systematically analyzing surrogate gradient\nslope settings, showing that shallower slopes increase gradient magnitude in\ndeeper layers but reduce alignment with true gradients. In supervised learning,\nwe find no clear preference for fixed or scheduled slopes. The effect is much\nmore pronounced in RL settings, where shallower slopes or scheduled slopes lead\nto a 2.1x improvement in both training and final deployed performance. Next, we\npropose a novel training approach that leverages a privileged guiding policy to\nbootstrap the learning process, while still exploiting online environment\ninteractions with the spiking policy. Combining our method with an adaptive\nslope schedule for a real-world drone position control task, we achieve an\naverage return of 400 points, substantially outperforming prior techniques,\nincluding Behavioral Cloning and TD3BC, which achieve at most --200 points\nunder the same conditions. This work advances both the theoretical\nunderstanding of surrogate gradient learning in SNNs and practical training\nmethodologies for neuromorphic controllers demonstrated in real-world robotic\nsystems.",
    "categories": [
      "cs.AI",
      "cs.RO"
    ],
    "published": "2025-10-28T14:28:40Z",
    "authors": [
      "Korneel Van den Berghe",
      "Stein Stroobants",
      "Vijay Janapa Reddi",
      "G. C. H. E. de Croon"
    ],
    "pdf_url": "http://arxiv.org/pdf/2510.24461v1"
  },
  {
    "id": "2510.24459v1",
    "title": "Affordance Representation and Recognition for Autonomous Agents",
    "abstract": "The autonomy of software agents is fundamentally dependent on their ability\nto construct an actionable internal world model from the structured data that\ndefines their digital environment, such as the Document Object Model (DOM) of\nweb pages and the semantic descriptions of web services. However, constructing\nthis world model from raw structured data presents two critical challenges: the\nverbosity of raw HTML makes it computationally intractable for direct use by\nfoundation models, while the static nature of hardcoded API integrations\nprevents agents from adapting to evolving services.\n  This paper introduces a pattern language for world modeling from structured\ndata, presenting two complementary architectural patterns. The DOM Transduction\nPattern addresses the challenge of web page complexity by distilling} a\nverbose, raw DOM into a compact, task-relevant representation or world model\noptimized for an agent's reasoning core. Concurrently, the Hypermedia\nAffordances Recognition Pattern enables the agent to dynamically enrich its\nworld model by parsing standardized semantic descriptions to discover and\nintegrate the capabilities of unknown web services at runtime. Together, these\npatterns provide a robust framework for engineering agents that can efficiently\nconstruct and maintain an accurate world model, enabling scalable, adaptive,\nand interoperable automation across the web and its extended resources.",
    "categories": [
      "cs.AI",
      "cs.MA",
      "cs.SE"
    ],
    "published": "2025-10-28T14:27:28Z",
    "authors": [
      "Habtom Kahsay Gidey",
      "Niklas Huber",
      "Alexander Lenz",
      "Alois Knoll"
    ],
    "pdf_url": "http://arxiv.org/pdf/2510.24459v1"
  },
  {
    "id": "2510.25785v1",
    "title": "HiMAE: Hierarchical Masked Autoencoders Discover Resolution-Specific\n  Structure in Wearable Time Series",
    "abstract": "Wearable sensors provide abundant physiological time series, yet the\nprinciples governing their predictive utility remain unclear. We hypothesize\nthat temporal resolution is a fundamental axis of representation learning, with\ndifferent clinical and behavioral outcomes relying on structure at distinct\nscales. To test this resolution hypothesis, we introduce HiMAE (Hierarchical\nMasked Autoencoder), a self supervised framework that combines masked\nautoencoding with a hierarchical convolutional encoder decoder. HiMAE produces\nmulti resolution embeddings that enable systematic evaluation of which temporal\nscales carry predictive signal, transforming resolution from a hyperparameter\ninto a probe for interpretability. Across classification, regression, and\ngenerative benchmarks, HiMAE consistently outperforms state of the art\nfoundation models that collapse scale, while being orders of magnitude smaller.\nHiMAE is an efficient representation learner compact enough to run entirely on\nwatch, achieving sub millisecond inference on smartwatch class CPUs for true\nedge inference. Together, these contributions position HiMAE as both an\nefficient self supervised learning method and a discovery tool for scale\nsensitive structure in wearable health.",
    "categories": [
      "cs.LG",
      "cs.AI",
      "eess.SP"
    ],
    "published": "2025-10-28T14:15:45Z",
    "authors": [
      "Simon A. Lee",
      "Cyrus Tanade",
      "Hao Zhou",
      "Juhyeon Lee",
      "Megha Thukral",
      "Minji Han",
      "Rachel Choi",
      "Md Sazzad Hissain Khan",
      "Baiying Lu",
      "Migyeong Gwak",
      "Mehrab Bin Morshed",
      "Viswam Nathan",
      "Md Mahbubur Rahman",
      "Li Zhu",
      "Subramaniam Venkatraman",
      "Sharanya Arcot Desai"
    ],
    "pdf_url": "http://arxiv.org/pdf/2510.25785v1"
  },
  {
    "id": "2510.24450v1",
    "title": "Charting the European LLM Benchmarking Landscape: A New Taxonomy and a\n  Set of Best Practices",
    "abstract": "While new benchmarks for large language models (LLMs) are being developed\ncontinuously to catch up with the growing capabilities of new models and AI in\ngeneral, using and evaluating LLMs in non-English languages remains a\nlittle-charted landscape. We give a concise overview of recent developments in\nLLM benchmarking, and then propose a new taxonomy for the categorization of\nbenchmarks that is tailored to multilingual or non-English use scenarios. We\nfurther propose a set of best practices and quality standards that could lead\nto a more coordinated development of benchmarks for European languages. Among\nother recommendations, we advocate for a higher language and culture\nsensitivity of evaluation methods.",
    "categories": [
      "cs.CL",
      "cs.AI"
    ],
    "published": "2025-10-28T14:13:44Z",
    "authors": [
      "\u0160pela Vintar",
      "Taja Kuzman Punger\u0161ek",
      "Mojca Brglez",
      "Nikola Ljube\u0161i\u0107"
    ],
    "pdf_url": "http://arxiv.org/pdf/2510.24450v1"
  },
  {
    "id": "2510.24448v1",
    "title": "Rethinking Visual Intelligence: Insights from Video Pretraining",
    "abstract": "Large language models (LLMs) have demonstrated that large-scale pretraining\nenables systems to adapt rapidly to new problems with little supervision in the\nlanguage domain. This success, however, has not translated as effectively to\nthe visual domain, where models, including LLMs, continue to struggle with\ncompositional understanding, sample efficiency, and general-purpose\nproblem-solving. We investigate Video Diffusion Models (VDMs) as a promising\ndirection for bridging this gap. Pretraining on spatiotemporal data endows\nthese models with strong inductive biases for structure and dynamics, which we\nhypothesize can support broad task adaptability. To test this, we design a\ncontrolled evaluation in which both a pretrained LLM and a pretrained VDM are\nequipped with lightweight adapters and presented with tasks in their natural\nmodalities. Across benchmarks including ARC-AGI, ConceptARC, visual games,\nroute planning, and cellular automata, VDMs demonstrate higher data efficiency\nthan their language counterparts. Taken together, our results indicate that\nvideo pretraining offers inductive biases that support progress toward visual\nfoundation models.",
    "categories": [
      "cs.CV",
      "cs.AI",
      "68T07, 68T45, 68T20",
      "I.2.10; I.4.8; I.5.1; I.2.6"
    ],
    "published": "2025-10-28T14:12:11Z",
    "authors": [
      "Pablo Acuaviva",
      "Aram Davtyan",
      "Mariam Hassan",
      "Sebastian Stapf",
      "Ahmad Rahimi",
      "Alexandre Alahi",
      "Paolo Favaro"
    ],
    "pdf_url": "http://arxiv.org/pdf/2510.24448v1"
  },
  {
    "id": "2510.24442v1",
    "title": "Law in Silico: Simulating Legal Society with LLM-Based Agents",
    "abstract": "Since real-world legal experiments are often costly or infeasible, simulating\nlegal societies with Artificial Intelligence (AI) systems provides an effective\nalternative for verifying and developing legal theory, as well as supporting\nlegal administration. Large Language Models (LLMs), with their world knowledge\nand role-playing capabilities, are strong candidates to serve as the foundation\nfor legal society simulation. However, the application of LLMs to simulate\nlegal systems remains underexplored. In this work, we introduce Law in Silico,\nan LLM-based agent framework for simulating legal scenarios with individual\ndecision-making and institutional mechanisms of legislation, adjudication, and\nenforcement. Our experiments, which compare simulated crime rates with\nreal-world data, demonstrate that LLM-based agents can largely reproduce\nmacro-level crime trends and provide insights that align with real-world\nobservations. At the same time, micro-level simulations reveal that a\nwell-functioning, transparent, and adaptive legal system offers better\nprotection of the rights of vulnerable individuals.",
    "categories": [
      "cs.AI",
      "cs.CL",
      "cs.CY",
      "cs.MA"
    ],
    "published": "2025-10-28T14:07:10Z",
    "authors": [
      "Yiding Wang",
      "Yuxuan Chen",
      "Fanxu Meng",
      "Xifan Chen",
      "Xiaolei Yang",
      "Muhan Zhang"
    ],
    "pdf_url": "http://arxiv.org/pdf/2510.24442v1"
  },
  {
    "id": "2510.24438v1",
    "title": "Can LLMs Write Faithfully? An Agent-Based Evaluation of LLM-generated\n  Islamic Content",
    "abstract": "Large language models are increasingly used for Islamic guidance, but risk\nmisquoting texts, misapplying jurisprudence, or producing culturally\ninconsistent responses. We pilot an evaluation of GPT-4o, Ansari AI, and Fanar\non prompts from authentic Islamic blogs. Our dual-agent framework uses a\nquantitative agent for citation verification and six-dimensional scoring (e.g.,\nStructure, Islamic Consistency, Citations) and a qualitative agent for\nfive-dimensional side-by-side comparison (e.g., Tone, Depth, Originality).\nGPT-4o scored highest in Islamic Accuracy (3.93) and Citation (3.38), Ansari AI\nfollowed (3.68, 3.32), and Fanar lagged (2.76, 1.82). Despite relatively strong\nperformance, models still fall short in reliably producing accurate Islamic\ncontent and citations -- a paramount requirement in faith-sensitive writing.\nGPT-4o had the highest mean quantitative score (3.90/5), while Ansari AI led\nqualitative pairwise wins (116/200). Fanar, though trailing, introduces\ninnovations for Islamic and Arabic contexts. This study underscores the need\nfor community-driven benchmarks centering Muslim perspectives, offering an\nearly step toward more reliable AI in Islamic knowledge and other high-stakes\ndomains such as medicine, law, and journalism.",
    "categories": [
      "cs.CL",
      "cs.AI",
      "cs.CY",
      "cs.MA"
    ],
    "published": "2025-10-28T14:05:55Z",
    "authors": [
      "Abdullah Mushtaq",
      "Rafay Naeem",
      "Ezieddin Elmahjub",
      "Ibrahim Ghaznavi",
      "Shawqi Al-Maliki",
      "Mohamed Abdallah",
      "Ala Al-Fuqaha",
      "Junaid Qadir"
    ],
    "pdf_url": "http://arxiv.org/pdf/2510.24438v1"
  },
  {
    "id": "2510.24435v1",
    "title": "Human-Level Reasoning: A Comparative Study of Large Language Models on\n  Logical and Abstract Reasoning",
    "abstract": "Evaluating reasoning ability in Large Language Models (LLMs) is important for\nadvancing artificial intelligence, as it transcends mere linguistic task\nperformance. It involves understanding whether these models truly understand\ninformation, perform inferences, and are able to draw conclusions in a logical\nand valid way. This study compare logical and abstract reasoning skills of\nseveral LLMs - including GPT, Claude, DeepSeek, Gemini, Grok, Llama, Mistral,\nPerplexity, and Sabi\\'a - using a set of eight custom-designed reasoning\nquestions. The LLM results are benchmarked against human performance on the\nsame tasks, revealing significant differences and indicating areas where LLMs\nstruggle with deduction.",
    "categories": [
      "cs.AI"
    ],
    "published": "2025-10-28T14:02:58Z",
    "authors": [
      "Benjamin Grando Moreira"
    ],
    "pdf_url": "http://arxiv.org/pdf/2510.24435v1"
  },
  {
    "id": "2510.24431v1",
    "title": "MiniOneRec: An Open-Source Framework for Scaling Generative\n  Recommendation",
    "abstract": "The recent success of large language models (LLMs) has renewed interest in\nwhether recommender systems can achieve similar scaling benefits. Conventional\nrecommenders, dominated by massive embedding tables, tend to plateau as\nembedding dimensions grow. In contrast, the emerging generative paradigm\nreplaces embeddings with compact Semantic ID (SID) sequences produced by\nautoregressive Transformers. Yet most industrial deployments remain\nproprietary, leaving two fundamental questions open: (1) Do the expected\nscaling laws hold on public benchmarks? (2) What is the minimal post-training\nrecipe that enables competitive performance?\n  We present MiniOneRec, to the best of our knowledge, the first fully\nopen-source generative recommendation framework, which provides an end-to-end\nworkflow spanning SID construction, supervised fine-tuning, and\nrecommendation-oriented reinforcement learning. We generate SIDs via a Residual\nQuantized VAE and post-train Qwen backbones ranging from 0.5B to 7B parameters\non the Amazon Review dataset. Our experiments reveal a consistent downward\ntrend in both training and evaluation losses with increasing model size,\nvalidating the parameter efficiency of the generative approach. To further\nenhance performance, we propose a lightweight yet effective post-training\npipeline that (1) enforces full-process SID alignment and (2) applies\nreinforcement learning with constrained decoding and hybrid rewards. Together,\nthese techniques yield significant improvements in both ranking accuracy and\ncandidate diversity.",
    "categories": [
      "cs.IR",
      "cs.AI"
    ],
    "published": "2025-10-28T13:58:36Z",
    "authors": [
      "Xiaoyu Kong",
      "Leheng Sheng",
      "Junfei Tan",
      "Yuxin Chen",
      "Jiancan Wu",
      "An Zhang",
      "Xiang Wang",
      "Xiangnan He"
    ],
    "pdf_url": "http://arxiv.org/pdf/2510.24431v1"
  },
  {
    "id": "2510.24411v1",
    "title": "OS-Sentinel: Towards Safety-Enhanced Mobile GUI Agents via Hybrid\n  Validation in Realistic Workflows",
    "abstract": "Computer-using agents powered by Vision-Language Models (VLMs) have\ndemonstrated human-like capabilities in operating digital environments like\nmobile platforms. While these agents hold great promise for advancing digital\nautomation, their potential for unsafe operations, such as system compromise\nand privacy leakage, is raising significant concerns. Detecting these safety\nconcerns across the vast and complex operational space of mobile environments\npresents a formidable challenge that remains critically underexplored. To\nestablish a foundation for mobile agent safety research, we introduce\nMobileRisk-Live, a dynamic sandbox environment accompanied by a safety\ndetection benchmark comprising realistic trajectories with fine-grained\nannotations. Built upon this, we propose OS-Sentinel, a novel hybrid safety\ndetection framework that synergistically combines a Formal Verifier for\ndetecting explicit system-level violations with a VLM-based Contextual Judge\nfor assessing contextual risks and agent actions. Experiments show that\nOS-Sentinel achieves 10%-30% improvements over existing approaches across\nmultiple metrics. Further analysis provides critical insights that foster the\ndevelopment of safer and more reliable autonomous mobile agents.",
    "categories": [
      "cs.AI",
      "cs.CL",
      "cs.CV",
      "cs.HC"
    ],
    "published": "2025-10-28T13:22:39Z",
    "authors": [
      "Qiushi Sun",
      "Mukai Li",
      "Zhoumianze Liu",
      "Zhihui Xie",
      "Fangzhi Xu",
      "Zhangyue Yin",
      "Kanzhi Cheng",
      "Zehao Li",
      "Zichen Ding",
      "Qi Liu",
      "Zhiyong Wu",
      "Zhuosheng Zhang",
      "Ben Kao",
      "Lingpeng Kong"
    ],
    "pdf_url": "http://arxiv.org/pdf/2510.24411v1"
  },
  {
    "id": "2510.24402v1",
    "title": "Metadata-Driven Retrieval-Augmented Generation for Financial Question\n  Answering",
    "abstract": "Retrieval-Augmented Generation (RAG) struggles on long, structured financial\nfilings where relevant evidence is sparse and cross-referenced. This paper\npresents a systematic investigation of advanced metadata-driven\nRetrieval-Augmented Generation (RAG) techniques, proposing and evaluating a\nnovel, multi-stage RAG architecture that leverages LLM-generated metadata. We\nintroduce a sophisticated indexing pipeline to create contextually rich\ndocument chunks and benchmark a spectrum of enhancements, including\npre-retrieval filtering, post-retrieval reranking, and enriched embeddings,\nbenchmarked on the FinanceBench dataset. Our results reveal that while a\npowerful reranker is essential for precision, the most significant performance\ngains come from embedding chunk metadata directly with text (\"contextual\nchunks\"). Our proposed optimal architecture combines LLM-driven pre-retrieval\noptimizations with these contextual embeddings to achieve superior performance.\nAdditionally, we present a custom metadata reranker that offers a compelling,\ncost-effective alternative to commercial solutions, highlighting a practical\ntrade-off between peak performance and operational efficiency. This study\nprovides a blueprint for building robust, metadata-aware RAG systems for\nfinancial document analysis.",
    "categories": [
      "cs.IR",
      "cs.AI",
      "cs.CE"
    ],
    "published": "2025-10-28T13:16:36Z",
    "authors": [
      "Michail Dadopoulos",
      "Anestis Ladas",
      "Stratos Moschidis",
      "Ioannis Negkakis"
    ],
    "pdf_url": "http://arxiv.org/pdf/2510.24402v1"
  },
  {
    "id": "2510.24397v1",
    "title": "APTBench: Benchmarking Agentic Potential of Base LLMs During\n  Pre-Training",
    "abstract": "With the rapid development of LLM-based agents, there is a growing trend to\nincorporate agent-specific data into the pre-training stage of LLMs, aiming to\nbetter align LLMs with real-world autonomous task execution. However, current\npre-training benchmarks primarily focus on isolated and static skills, e.g.,\ncommon knowledge or mathematical/code reasoning, and fail to reflect model's\nagentic capabilities. On the other hand, agent benchmarks are typically\ndesigned for post-trained models, requiring multi-turn task execution abilities\nthat base models struggle to support. Thus, there is a compelling need for a\nbenchmark that can evaluate agentic potentials during pre-training and guide\nthe model training more effectively. To address this gap, we propose APTBench,\na framework that converts real-world agent tasks and successful trajectories\ninto multiple-choice or text completion questions tailored for base models. It\nfocuses on core agentic abilities, e.g., planning and action, and covers key\nagent scenarios, software engineering and deep research. Compared to existing\ngeneral-purpose benchmarks, APTBench offers a more predictive signal of a\nmodel's downstream performance as an agent, while remaining significantly more\nlightweight and cost-effective than full-scale, end-to-end agent evaluations\nafter post-training.",
    "categories": [
      "cs.AI"
    ],
    "published": "2025-10-28T13:11:22Z",
    "authors": [
      "Jiarui Qin",
      "Yunjia Xi",
      "Junjie Huang",
      "Renting Rui",
      "Di Yin",
      "Weiwen Liu",
      "Yong Yu",
      "Weinan Zhang",
      "Xing Sun"
    ],
    "pdf_url": "http://arxiv.org/pdf/2510.24397v1"
  },
  {
    "id": "2510.25784v1",
    "title": "zFLoRA: Zero-Latency Fused Low-Rank Adapters",
    "abstract": "Large language models (LLMs) are increasingly deployed with task-specific\nadapters catering to multiple downstream applications. In such a scenario, the\nadditional compute associated with these apparently insignificant number of\nadapter parameters (typically less than 1% of the base model) turns out to be\ndisproportionately significant during inference time (upto 2.5x times that of\nthe base model). In this paper, we propose a new zero-latency fused low-rank\nadapter (zFLoRA) that introduces zero or negligible latency overhead on top of\nthe base model. Experimental results on LLMs of size 1B, 3B and 7B show that\nzFLoRA compares favorably against the popular supervised fine-tuning benchmarks\nincluding low-rank adapters (LoRA) as well as full fine-tuning (FFT).\nExperiments are conducted on 18 different tasks across three different\ncategories namely commonsense reasoning, math reasoning and summary-dialogue.\nLatency measurements made on NPU (Samsung Galaxy S25+) as well as GPU (NVIDIA\nH100) platforms show that the proposed zFLoRA adapters introduce zero to\nnegligible latency overhead.",
    "categories": [
      "cs.CL",
      "cs.AI",
      "cs.LG"
    ],
    "published": "2025-10-28T13:10:41Z",
    "authors": [
      "Dhananjaya Gowda",
      "Seoha Song",
      "Harshith Goka",
      "Junhyun Lee"
    ],
    "pdf_url": "http://arxiv.org/pdf/2510.25784v1"
  },
  {
    "id": "2510.24390v1",
    "title": "Improving LLM Reasoning via Dependency-Aware Query Decomposition and\n  Logic-Parallel Content Expansion",
    "abstract": "The integration of Large Language Models (LLMs) into real-time Web\napplications, such as AI-powered search and conversational agents, presents a\nfundamental Web infrastructure challenge: reconciling the demand for\nhigh-quality, complex reasoning with the stringent low-latency and\nhigh-throughput requirements of interactive services. Current LLM reasoning,\nhindered by computationally inefficient sequential generation and rigid\nreasoning strategies, creates a critical bottleneck for the Web services.\nExisting approaches typically optimize the LLM reasoning for either efficiency\nor quality but struggle to achieve both, and thus fail to meet the dual\nrequirements of modern Web platforms. To overcome these limitations, we propose\nOrion, a novel and efficient reasoning framework that enables dependency-aware\nquery decomposition and logic-parallel content expansion. Concretely, Orion\ndecomposes a single query reasoning process into two synergistic phases: (1)\n\\textit{key point generation}, which distills logically structured key points\nthrough retrieval-augmented few-shot prompting, and (2) \\textit{content\nparallel expansion}, which concurrently elaborates on these points based on a\ndependency graph to ensure logical consistency. Furthermore, Orion introduces a\npipeline scheduling mechanism that exploits the complementary computational\ncharacteristics of the two phases (generation imposes pressure on GPU computing\nand expansion stresses on GPU memory) across multiple queries, enabling\ncross-query parallelism and dramatically improving reasoning performance (\\ie,\nefficiency and quality). Experiments on diverse benchmarks show that Orion not\nonly delivers up to 4.33x higher token generation speed and 3.42x lower answer\nlatency over the baselines but also improves reasoning quality by up to 18.75%\nthrough explicitly modeling inter-point dependencies.",
    "categories": [
      "cs.AI"
    ],
    "published": "2025-10-28T13:05:23Z",
    "authors": [
      "Xianjun Gao",
      "Jianchun Liu",
      "Hongli Xu",
      "Liusheng Huang"
    ],
    "pdf_url": "http://arxiv.org/pdf/2510.24390v1"
  },
  {
    "id": "2510.24383v1",
    "title": "Policy Cards: Machine-Readable Runtime Governance for Autonomous AI\n  Agents",
    "abstract": "Policy Cards are introduced as a machine-readable, deployment-layer standard\nfor expressing operational, regulatory, and ethical constraints for AI agents.\nThe Policy Card sits with the agent and enables it to follow required\nconstraints at runtime. It tells the agent what it must and must not do. As\nsuch, it becomes an integral part of the deployed agent. Policy Cards extend\nexisting transparency artifacts such as Model, Data, and System Cards by\ndefining a normative layer that encodes allow/deny rules, obligations,\nevidentiary requirements, and crosswalk mappings to assurance frameworks\nincluding NIST AI RMF, ISO/IEC 42001, and the EU AI Act. Each Policy Card can\nbe validated automatically, version-controlled, and linked to runtime\nenforcement or continuous-audit pipelines. The framework enables verifiable\ncompliance for autonomous agents, forming a foundation for distributed\nassurance in multi-agent ecosystems. Policy Cards provide a practical mechanism\nfor integrating high-level governance with hands-on engineering practice and\nenabling accountable autonomy at scale.",
    "categories": [
      "cs.AI",
      "cs.CY",
      "cs.MA",
      "I.2.11; I.2.1; I.2.4; K.4.1; K.4.3"
    ],
    "published": "2025-10-28T12:59:55Z",
    "authors": [
      "Juraj Mavra\u010di\u0107"
    ],
    "pdf_url": "http://arxiv.org/pdf/2510.24383v1"
  },
  {
    "id": "2510.24359v1",
    "title": "An N-of-1 Artificial Intelligence Ecosystem for Precision Medicine",
    "abstract": "Artificial intelligence in medicine is built to serve the average patient. By\nminimizing error across large datasets, most systems deliver strong aggregate\naccuracy yet falter at the margins: patients with rare variants,\nmultimorbidity, or underrepresented demographics. This average patient fallacy\nerodes both equity and trust. We propose a different design: a multi-agent\necosystem for N-of-1 decision support. In this environment, agents clustered by\norgan systems, patient populations, and analytic modalities draw on a shared\nlibrary of models and evidence synthesis tools. Their results converge in a\ncoordination layer that weighs reliability, uncertainty, and data density\nbefore presenting the clinician with a decision-support packet: risk estimates\nbounded by confidence ranges, outlier flags, and linked evidence. Validation\nshifts from population averages to individual reliability, measured by error in\nlow-density regions, calibration in the small, and risk--coverage trade-offs.\nAnticipated challenges include computational demands, automation bias, and\nregulatory fit, addressed through caching strategies, consensus checks, and\nadaptive trial frameworks. By moving from monolithic models to orchestrated\nintelligence, this approach seeks to align medical AI with the first principle\nof medicine: care that is transparent, equitable, and centered on the\nindividual.",
    "categories": [
      "cs.AI",
      "cs.SY",
      "eess.SY",
      "q-bio.QM",
      "stat.AP"
    ],
    "published": "2025-10-28T12:28:02Z",
    "authors": [
      "Pedram Fard",
      "Alaleh Azhir",
      "Neguine Rezaii",
      "Jiazi Tian",
      "Hossein Estiri"
    ],
    "pdf_url": "http://arxiv.org/pdf/2510.24359v1"
  },
  {
    "id": "2510.24356v1",
    "title": "Perception Learning: A Formal Separation of Sensory Representation\n  Learning from Decision Learning",
    "abstract": "We introduce Perception Learning (PeL), a paradigm that optimizes an agent's\nsensory interface $f_\\phi:\\mathcal{X}\\to\\mathcal{Z}$ using task-agnostic\nsignals, decoupled from downstream decision learning\n$g_\\theta:\\mathcal{Z}\\to\\mathcal{Y}$. PeL directly targets label-free\nperceptual properties, such as stability to nuisances, informativeness without\ncollapse, and controlled geometry, assessed via objective\nrepresentation-invariant metrics. We formalize the separation of perception and\ndecision, define perceptual properties independent of objectives or\nreparameterizations, and prove that PeL updates preserving sufficient\ninvariants are orthogonal to Bayes task-risk gradients. Additionally, we\nprovide a suite of task-agnostic evaluation metrics to certify perceptual\nquality.",
    "categories": [
      "cs.LG",
      "cs.AI",
      "stat.ML"
    ],
    "published": "2025-10-28T12:19:49Z",
    "authors": [
      "Suman Sanyal"
    ],
    "pdf_url": "http://arxiv.org/pdf/2510.24356v1"
  },
  {
    "id": "2510.24345v1",
    "title": "LongWeave: A Long-Form Generation Benchmark Bridging Real-World\n  Relevance and Verifiability",
    "abstract": "Generating long, informative, and factual outputs remains a major challenge\nfor Large Language Models (LLMs). Existing benchmarks for long-form generation\ntypically assess real-world queries with hard-to-verify metrics or use\nsynthetic setups that ease evaluation but overlook real-world intricacies. In\nthis paper, we introduce \\textbf{LongWeave}, which balances real-world and\nverifiable assessment with Constraint-Verifier Evaluation (CoV-Eval). CoV-Eval\nconstructs tasks by first defining verifiable targets within real-world\nscenarios, then systematically generating corresponding queries, textual\nmaterials, and constraints based on these targets. This ensures that tasks are\nboth realistic and objectively assessable, enabling rigorous assessment of\nmodel capabilities in meeting complex real-world constraints. LongWeave\nsupports customizable input/output lengths (up to 64K/8K tokens) across seven\ndistinct tasks. Evaluation on 23 LLMs shows that even state-of-the-art models\nencounter significant challenges in long-form generation as real-world\ncomplexity and output length increase.",
    "categories": [
      "cs.CL",
      "cs.AI"
    ],
    "published": "2025-10-28T12:11:12Z",
    "authors": [
      "Zikai Xiao",
      "Fei Huang",
      "Jianhong Tu",
      "Jianhui Wei",
      "Wen Ma",
      "Yuxuan Zhou",
      "Jian Wu",
      "Bowen Yu",
      "Zuozhu Liu",
      "Junyang Lin"
    ],
    "pdf_url": "http://arxiv.org/pdf/2510.24345v1"
  },
  {
    "id": "2510.24342v1",
    "title": "A Unified Geometric Space Bridging AI Models and the Human Brain",
    "abstract": "For decades, neuroscientists and computer scientists have pursued a shared\nambition: to understand intelligence and build it. Modern artificial neural\nnetworks now rival humans in language, perception, and reasoning, yet it is\nstill largely unknown whether these artificial systems organize information as\nthe brain does. Existing brain-AI alignment studies have shown the striking\ncorrespondence between the two systems, but such comparisons remain bound to\nspecific inputs and tasks, offering no common ground for comparing how AI\nmodels with different kinds of modalities-vision, language, or multimodal-are\nintrinsically organized. Here we introduce a groundbreaking concept of\nBrain-like Space: a unified geometric space in which every AI model can be\nprecisely situated and compared by mapping its intrinsic spatial attention\ntopological organization onto canonical human functional brain networks,\nregardless of input modality, task, or sensory domain. Our extensive analysis\nof 151 Transformer-based models spanning state-of-the-art large vision models,\nlarge language models, and large multimodal models uncovers a continuous\narc-shaped geometry within this space, reflecting a gradual increase of\nbrain-likeness; different models exhibit distinct distribution patterns within\nthis geometry associated with different degrees of brain-likeness, shaped not\nmerely by their modality but by whether the pretraining paradigm emphasizes\nglobal semantic abstraction and whether the positional encoding scheme\nfacilitates deep fusion across different modalities. Moreover, the degree of\nbrain-likeness for a model and its downstream task performance are not\n\"identical twins\". The Brain-like Space provides the first unified framework\nfor situating, quantifying, and comparing intelligence across domains,\nrevealing the deep organizational principles that bridge machines and the\nbrain.",
    "categories": [
      "cs.AI"
    ],
    "published": "2025-10-28T12:09:23Z",
    "authors": [
      "Silin Chen",
      "Yuzhong Chen",
      "Zifan Wang",
      "Junhao Wang",
      "Zifeng Jia",
      "Keith M Kendrick",
      "Tuo Zhang",
      "Lin Zhao",
      "Dezhong Yao",
      "Tianming Liu",
      "Xi Jiang"
    ],
    "pdf_url": "http://arxiv.org/pdf/2510.24342v1"
  },
  {
    "id": "2510.24339v2",
    "title": "VDSAgents: A PCS-Guided Multi-Agent System for Veridical Data Science\n  Automation",
    "abstract": "Large language models (LLMs) become increasingly integrated into data science\nworkflows for automated system design. However, these LLM-driven data science\nsystems rely solely on the internal reasoning of LLMs, lacking guidance from\nscientific and theoretical principles. This limits their trustworthiness and\nrobustness, especially when dealing with noisy and complex real-world datasets.\nThis paper provides VDSAgents, a multi-agent system grounded in the\nPredictability-Computability-Stability (PCS) principles proposed in the\nVeridical Data Science (VDS) framework. Guided by PCS principles, the system\nimplements a modular workflow for data cleaning, feature engineering, modeling,\nand evaluation. Each phase is handled by an elegant agent, incorporating\nperturbation analysis, unit testing, and model validation to ensure both\nfunctionality and scientific auditability. We evaluate VDSAgents on nine\ndatasets with diverse characteristics, comparing it with state-of-the-art\nend-to-end data science systems, such as AutoKaggle and DataInterpreter, using\nDeepSeek-V3 and GPT-4o as backends. VDSAgents consistently outperforms the\nresults of AutoKaggle and DataInterpreter, which validates the feasibility of\nembedding PCS principles into LLM-driven data science automation.",
    "categories": [
      "cs.AI"
    ],
    "published": "2025-10-28T12:07:50Z",
    "authors": [
      "Yunxuan Jiang",
      "Silan Hu",
      "Xiaoning Wang",
      "Yuanyuan Zhang",
      "Xiangyu Chang"
    ],
    "pdf_url": "http://arxiv.org/pdf/2510.24339v2"
  },
  {
    "id": "2510.24337v1",
    "title": "Generative Large Language Models (gLLMs) in Content Analysis: A\n  Practical Guide for Communication Research",
    "abstract": "Generative Large Language Models (gLLMs), such as ChatGPT, are increasingly\nbeing used in communication research for content analysis. Studies show that\ngLLMs can outperform both crowd workers and trained coders, such as research\nassistants, on various coding tasks relevant to communication science, often at\na fraction of the time and cost. Additionally, gLLMs can decode implicit\nmeanings and contextual information, be instructed using natural language,\ndeployed with only basic programming skills, and require little to no annotated\ndata beyond a validation dataset - constituting a paradigm shift in automated\ncontent analysis. Despite their potential, the integration of gLLMs into the\nmethodological toolkit of communication research remains underdeveloped. In\ngLLM-assisted quantitative content analysis, researchers must address at least\nseven critical challenges that impact result quality: (1) codebook development,\n(2) prompt engineering, (3) model selection, (4) parameter tuning, (5)\niterative refinement, (6) validation of the model's reliability, and\noptionally, (7) performance enhancement. This paper synthesizes emerging\nresearch on gLLM-assisted quantitative content analysis and proposes a\ncomprehensive best-practice guide to navigate these challenges. Our goal is to\nmake gLLM-based content analysis more accessible to a broader range of\ncommunication researchers and ensure adherence to established disciplinary\nquality standards of validity, reliability, reproducibility, and research\nethics.",
    "categories": [
      "cs.AI",
      "cs.SI"
    ],
    "published": "2025-10-28T12:01:43Z",
    "authors": [
      "Daria Kravets-Meinke",
      "Hannah Schmid-Petri",
      "Sonja Niemann",
      "Ute Schmid"
    ],
    "pdf_url": "http://arxiv.org/pdf/2510.24337v1"
  },
  {
    "id": "2510.24328v1",
    "title": "Beyond MCQ: An Open-Ended Arabic Cultural QA Benchmark with Dialect\n  Variants",
    "abstract": "Large Language Models (LLMs) are increasingly used to answer everyday\nquestions, yet their performance on culturally grounded and dialectal content\nremains uneven across languages. We propose a comprehensive method that (i)\ntranslates Modern Standard Arabic (MSA) multiple-choice questions (MCQs) into\nEnglish and several Arabic dialects, (ii) converts them into open-ended\nquestions (OEQs), (iii) benchmarks a range of zero-shot and fine-tuned LLMs\nunder both MCQ and OEQ settings, and (iv) generates chain-of-thought (CoT)\nrationales to fine-tune models for step-by-step reasoning. Using this method,\nwe extend an existing dataset in which QAs are parallelly aligned across\nmultiple language varieties, making it, to our knowledge, the first of its\nkind. We conduct extensive experiments with both open and closed models. Our\nfindings show that (i) models underperform on Arabic dialects, revealing\npersistent gaps in culturally grounded and dialect-specific knowledge; (ii)\nArabic-centric models perform well on MCQs but struggle with OEQs; and (iii)\nCoT improves judged correctness while yielding mixed n-gram-based metrics. The\ndeveloped dataset will be publicly released to support further research on\nculturally and linguistically inclusive evaluation.",
    "categories": [
      "cs.CL",
      "cs.AI",
      "68T50",
      "F.2.2; I.2.7"
    ],
    "published": "2025-10-28T11:52:51Z",
    "authors": [
      "Hunzalah Hassan Bhatti",
      "Firoj Alam"
    ],
    "pdf_url": "http://arxiv.org/pdf/2510.24328v1"
  },
  {
    "id": "2510.24321v1",
    "title": "Few-Shot Remote Sensing Image Scene Classification with CLIP and Prompt\n  Learning",
    "abstract": "Remote sensing applications increasingly rely on deep learning for scene\nclassification. However, their performance is often constrained by the scarcity\nof labeled data and the high cost of annotation across diverse geographic and\nsensor domains. While recent vision-language models like CLIP have shown\npromise by learning transferable representations at scale by aligning visual\nand textual modalities, their direct application to remote sensing remains\nsuboptimal due to significant domain gaps and the need for task-specific\nsemantic adaptation. To address this critical challenge, we systematically\nexplore prompt learning as a lightweight and efficient adaptation strategy for\nfew-shot remote sensing image scene classification. We evaluate several\nrepresentative methods, including Context Optimization, Conditional Context\nOptimization, Multi-modal Prompt Learning, and Prompting with Self-Regulating\nConstraints. These approaches reflect complementary design philosophies: from\nstatic context optimization to conditional prompts for enhanced generalization,\nmulti-modal prompts for joint vision-language adaptation, and semantically\nregularized prompts for stable learning without forgetting. We benchmark these\nprompt-learning methods against two standard baselines: zero-shot CLIP with\nhand-crafted prompts and a linear probe trained on frozen CLIP features.\nThrough extensive experiments on multiple benchmark remote sensing datasets,\nincluding cross-dataset generalization tests, we demonstrate that prompt\nlearning consistently outperforms both baselines in few-shot scenarios.\nNotably, Prompting with Self-Regulating Constraints achieves the most robust\ncross-domain performance. Our findings underscore prompt learning as a scalable\nand efficient solution for bridging the domain gap in satellite and aerial\nimagery, providing a strong foundation for future research in this field.",
    "categories": [
      "cs.CV",
      "cs.AI"
    ],
    "published": "2025-10-28T11:39:22Z",
    "authors": [
      "Ivica Dimitrovski",
      "Vlatko Spasev",
      "Ivan Kitanovski"
    ],
    "pdf_url": "http://arxiv.org/pdf/2510.24321v1"
  },
  {
    "id": "2510.24320v1",
    "title": "Critique-RL: Training Language Models for Critiquing through Two-Stage\n  Reinforcement Learning",
    "abstract": "Training critiquing language models to assess and provide feedback on model\noutputs is a promising way to improve LLMs for complex reasoning tasks.\nHowever, existing approaches typically rely on stronger supervisors for\nannotating critique data. To address this, we propose Critique-RL, an online RL\napproach for developing critiquing language models without stronger\nsupervision. Our approach operates on a two-player paradigm: the actor\ngenerates a response, the critic provides feedback, and the actor refines the\nresponse accordingly. We first reveal that relying solely on indirect reward\nsignals from the actor's outputs for RL optimization often leads to\nunsatisfactory critics: while their helpfulness (i.e., providing constructive\nfeedback) improves, the discriminability (i.e., determining whether a response\nis high-quality or not) remains poor, resulting in marginal performance gains.\nTo overcome this, Critique-RL adopts a two-stage optimization strategy. In\nstage I, it reinforces the discriminability of the critic with direct\nrule-based reward signals; in stage II, it introduces indirect rewards based on\nactor refinement to improve the critic's helpfulness, while maintaining its\ndiscriminability via appropriate regularization. Extensive experiments across\nvarious tasks and models show that Critique-RL delivers substantial performance\nimprovements. For example, it achieves a 9.02% gain on in-domain tasks and a\n5.70% gain on out-of-domain tasks for Qwen2.5-7B, highlighting its potential.",
    "categories": [
      "cs.CL",
      "cs.AI"
    ],
    "published": "2025-10-28T11:37:01Z",
    "authors": [
      "Zhiheng Xi",
      "Jixuan Huang",
      "Xin Guo",
      "Boyang Hong",
      "Dingwen Yang",
      "Xiaoran Fan",
      "Shuo Li",
      "Zehui Chen",
      "Junjie Ye",
      "Siyu Yuan",
      "Zhengyin Du",
      "Xuesong Yao",
      "Yufei Xu",
      "Jiecao Chen",
      "Rui Zheng",
      "Tao Gui",
      "Qi Zhang",
      "Xuanjing Huang"
    ],
    "pdf_url": "http://arxiv.org/pdf/2510.24320v1"
  },
  {
    "id": "2510.24318v1",
    "title": "Transformers can do Bayesian Clustering",
    "abstract": "Bayesian clustering accounts for uncertainty but is computationally demanding\nat scale. Furthermore, real-world datasets often contain missing values, and\nsimple imputation ignores the associated uncertainty, resulting in suboptimal\nresults. We present Cluster-PFN, a Transformer-based model that extends\nPrior-Data Fitted Networks (PFNs) to unsupervised Bayesian clustering. Trained\nentirely on synthetic datasets generated from a finite Gaussian Mixture Model\n(GMM) prior, Cluster-PFN learns to estimate the posterior distribution over\nboth the number of clusters and the cluster assignments. Our method estimates\nthe number of clusters more accurately than handcrafted model selection\nprocedures such as AIC, BIC and Variational Inference (VI), and achieves\nclustering quality competitive with VI while being orders of magnitude faster.\nCluster-PFN can be trained on complex priors that include missing data,\noutperforming imputation-based baselines on real-world genomic datasets, at\nhigh missingness. These results show that the Cluster-PFN can provide scalable\nand flexible Bayesian clustering.",
    "categories": [
      "cs.LG",
      "cs.AI"
    ],
    "published": "2025-10-28T11:36:31Z",
    "authors": [
      "Prajit Bhaskaran",
      "Tom Viering"
    ],
    "pdf_url": "http://arxiv.org/pdf/2510.24318v1"
  },
  {
    "id": "2510.24303v1",
    "title": "Retrieval and Argumentation Enhanced Multi-Agent LLMs for Judgmental\n  Forecasting",
    "abstract": "Judgmental forecasting is the task of making predictions about future events\nbased on human judgment. This task can be seen as a form of claim verification,\nwhere the claim corresponds to a future event and the task is to assess the\nplausibility of that event. In this paper, we propose a novel multi-agent\nframework for claim verification, whereby different agents may disagree on\nclaim veracity and bring specific evidence for and against the claims,\nrepresented as quantitative bipolar argumentation frameworks (QBAFs). We then\ninstantiate the framework for supporting claim verification, with a variety of\nagents realised with Large Language Models (LLMs): (1) ArgLLM agents, an\nexisting approach for claim verification that generates and evaluates QBAFs;\n(2) RbAM agents, whereby LLM-empowered Relation-based Argument Mining (RbAM)\nfrom external sources is used to generate QBAFs; (3) RAG-ArgLLM agents,\nextending ArgLLM agents with a form of Retrieval-Augmented Generation (RAG) of\narguments from external sources. Finally, we conduct experiments with two\nstandard judgmental forecasting datasets, with instances of our framework with\ntwo or three agents, empowered by six different base LLMs. We observe that\ncombining evidence from agents can improve forecasting accuracy, especially in\nthe case of three agents, while providing an explainable combination of\nevidence for claim verification.",
    "categories": [
      "cs.AI"
    ],
    "published": "2025-10-28T11:12:43Z",
    "authors": [
      "Deniz Gorur",
      "Antoni Rago",
      "Francesca Toni"
    ],
    "pdf_url": "http://arxiv.org/pdf/2510.24303v1"
  },
  {
    "id": "2510.25783v1",
    "title": "LASTIST: LArge-Scale Target-Independent STance dataset",
    "abstract": "Stance detection has emerged as an area of research in the field of\nartificial intelligence. However, most research is currently centered on the\ntarget-dependent stance detection task, which is based on a person's stance in\nfavor of or against a specific target. Furthermore, most benchmark datasets are\nbased on English, making it difficult to develop models in low-resource\nlanguages such as Korean, especially for an emerging field such as stance\ndetection. This study proposes the LArge-Scale Target-Independent STance\n(LASTIST) dataset to fill this research gap. Collected from the press releases\nof both parties on Korean political parties, the LASTIST dataset uses 563,299\nlabeled Korean sentences. We provide a detailed description of how we collected\nand constructed the dataset and trained state-of-the-art deep learning and\nstance detection models. Our LASTIST dataset is designed for various tasks in\nstance detection, including target-independent stance detection and diachronic\nevolution stance detection. We deploy our dataset on\nhttps://anonymous.4open.science/r/LASTIST-3721/.",
    "categories": [
      "cs.CL",
      "cs.AI",
      "I.2.7"
    ],
    "published": "2025-10-28T11:07:29Z",
    "authors": [
      "DongJae Kim",
      "Yaejin Lee",
      "Minsu Park",
      "Eunil Park"
    ],
    "pdf_url": "http://arxiv.org/pdf/2510.25783v1"
  },
  {
    "id": "2510.24299v1",
    "title": "Verifying Large Language Models' Reasoning Paths via Correlation Matrix\n  Rank",
    "abstract": "Despite the strong reasoning ability of large language models~(LLMs), they\nare prone to errors and hallucinations. As a result, how to check their outputs\neffectively and efficiently has become a critical problem in their\napplications. Existing checking methods heavily rely on external resources,\nsuch as trained verifiers (e.g., process/outcome reward models) or elaborate\nprompts, which lead to high computational overhead and are only applicable to\nspecific domains. In this paper, we investigate whether the internal behaviors\nof LLMs have already implied the credibility of their reasoning paths.\nSpecifically, we find that the rank of the correlation matrix between the input\nproblem and the output reasoning path is a robust indicator of reasoning\ncorrectness. Different from other correctness indicators for LLMs, the\ncalculation of the correlation matrix only relies on the LLM itself, which\navoids the hassle of training a separate model or designing complicated\nprompts. Based on it, we design a simple, plug-and-play Self-Indicator method\nto reweight candidate reasoning paths, which achieves significant performance\nimprovements than other voting and verification methods with very few\ncomputational overhead. Our experiments across multiple LLMs of varying scales\nand model families have further shown the effectiveness of Self-Indicator. It\nachieves over 75% accuracy in distinguishing correct reasoning paths from\nincorrect ones, and, in turn, improves the accuracies on three reasoning\nbenchmarks by more than 8%.",
    "categories": [
      "cs.AI"
    ],
    "published": "2025-10-28T11:01:10Z",
    "authors": [
      "Jiayu Liu",
      "Wei Dai",
      "Zhenya Huang",
      "Ning Miao",
      "Enhong Chen"
    ],
    "pdf_url": "http://arxiv.org/pdf/2510.24299v1"
  },
  {
    "id": "2510.24297v1",
    "title": "Investigating Intra-Abstraction Policies For Non-exact Abstraction\n  Algorithms",
    "abstract": "One weakness of Monte Carlo Tree Search (MCTS) is its sample efficiency which\ncan be addressed by building and using state and/or action abstractions in\nparallel to the tree search such that information can be shared among nodes of\nthe same layer. The primary usage of abstractions for MCTS is to enhance the\nUpper Confidence Bound (UCB) value during the tree policy by aggregating visits\nand returns of an abstract node. However, this direct usage of abstractions\ndoes not take the case into account where multiple actions with the same parent\nmight be in the same abstract node, as these would then all have the same UCB\nvalue, thus requiring a tiebreak rule. In state-of-the-art abstraction\nalgorithms such as pruned On the Go Abstractions (pruned OGA), this case has\nnot been noticed, and a random tiebreak rule was implicitly chosen. In this\npaper, we propose and empirically evaluate several alternative\nintra-abstraction policies, several of which outperform the random policy\nacross a majority of environments and parameter settings.",
    "categories": [
      "cs.AI"
    ],
    "published": "2025-10-28T11:00:30Z",
    "authors": [
      "Robin Schm\u00f6cker",
      "Alexander Dockhorn",
      "Bodo Rosenhahn"
    ],
    "pdf_url": "http://arxiv.org/pdf/2510.24297v1"
  },
  {
    "id": "2510.24285v1",
    "title": "ViPER: Empowering the Self-Evolution of Visual Perception Abilities in\n  Vision-Language Model",
    "abstract": "The limited capacity for fine-grained visual perception presents a critical\nbottleneck for Vision-Language Models (VLMs) in real-world applications.\nAddressing this is challenging due to the scarcity of high-quality data and the\nlimitations of existing methods: supervised fine-tuning (SFT) often compromises\ngeneral capabilities, while reinforcement fine-tuning (RFT) prioritizes textual\nreasoning over visual perception. To bridge this gap, we propose a novel\ntwo-stage task that structures visual perception learning as a coarse-to-fine\nprogressive process. Based on this task formulation, we develop ViPER, a\nself-bootstrapping framework specifically designed to enable iterative\nevolution through self-critiquing and self-prediction. By synergistically\nintegrating image-level and instance-level reconstruction with a two-stage\nreinforcement learning strategy, ViPER establishes a closed-loop training\nparadigm, where internally synthesized data directly fuel the enhancement of\nperceptual ability. Applied to the Qwen2.5-VL family, ViPER produces the\nQwen-Viper series. With an average gain of 1.7% on seven comprehensive\nbenchmarks spanning various tasks and up to 6.0% on fine-grained perception,\nQwen-Viper consistently demonstrates superior performance across different\nvision-language scenarios while maintaining generalizability. Beyond enabling\nself-improvement in perceptual capabilities, ViPER provides concrete evidence\nfor the reciprocal relationship between generation and understanding, a\nbreakthrough to developing more autonomous and capable VLMs.",
    "categories": [
      "cs.CV",
      "cs.AI",
      "cs.CL"
    ],
    "published": "2025-10-28T10:42:57Z",
    "authors": [
      "Juntian Zhang",
      "Song Jin",
      "Chuanqi Cheng",
      "Yuhan Liu",
      "Yankai Lin",
      "Xun Zhang",
      "Yufei Zhang",
      "Fei Jiang",
      "Guojun Yin",
      "Wei Lin",
      "Rui Yan"
    ],
    "pdf_url": "http://arxiv.org/pdf/2510.24285v1"
  },
  {
    "id": "2510.24284v1",
    "title": "MCP-Flow: Facilitating LLM Agents to Master Real-World, Diverse and\n  Scaling MCP Tools",
    "abstract": "Large Language Models (LLMs) increasingly rely on external tools to perform\ncomplex, realistic tasks, yet their ability to utilize the rapidly expanding\nModel Contextual Protocol (MCP) ecosystem remains limited. Existing MCP\nresearch covers few servers, depends on costly manual curation, and lacks\ntraining support, hindering progress toward real-world deployment. To overcome\nthese limitations, we introduce MCP-Flow, an automated web-agent-driven\npipeline for large-scale server discovery, data synthesis, and model training.\nMCP-Flow collects and filters data from 1166 servers and 11536 tools, producing\n68733 high-quality instruction-function call pairs and 6439 trajectories, far\nexceeding prior work in scale and diversity. Extensive experiments demonstrate\nMCP-Flow's effectiveness in driving superior MCP tool selection, function-call\ngeneration, and enhanced agentic task performance. MCP-Flow thus provides a\nscalable foundation for advancing LLM agents' proficiency in real-world MCP\nenvironments. MCP-Flow is publicly available at\n\\href{https://github.com/wwh0411/MCP-Flow}{https://github.com/wwh0411/MCP-Flow}.",
    "categories": [
      "cs.AI"
    ],
    "published": "2025-10-28T10:42:17Z",
    "authors": [
      "Wenhao Wang",
      "Peizhi Niu",
      "Zhao Xu",
      "Zhaoyu Chen",
      "Jian Du",
      "Yaxin Du",
      "Xianghe Pang",
      "Keduan Huang",
      "Yanfeng Wang",
      "Qiang Yan",
      "Siheng Chen"
    ],
    "pdf_url": "http://arxiv.org/pdf/2510.24284v1"
  },
  {
    "id": "2510.24278v1",
    "title": "Training-free Source Attribution of AI-generated Images via Resynthesis",
    "abstract": "Synthetic image source attribution is a challenging task, especially in data\nscarcity conditions requiring few-shot or zero-shot classification\ncapabilities. We present a new training-free one-shot attribution method based\non image resynthesis. A prompt describing the image under analysis is\ngenerated, then it is used to resynthesize the image with all the candidate\nsources. The image is attributed to the model which produced the resynthesis\nclosest to the original image in a proper feature space. We also introduce a\nnew dataset for synthetic image attribution consisting of face images from\ncommercial and open-source text-to-image generators. The dataset provides a\nchallenging attribution framework, useful for developing new attribution models\nand testing their capabilities on different generative architectures. The\ndataset structure allows to test approaches based on resynthesis and to compare\nthem to few-shot methods. Results from state-of-the-art few-shot approaches and\nother baselines show that the proposed resynthesis method outperforms existing\ntechniques when only a few samples are available for training or fine-tuning.\nThe experiments also demonstrate that the new dataset is a challenging one and\nrepresents a valuable benchmark for developing and evaluating future few-shot\nand zero-shot methods.",
    "categories": [
      "cs.CV",
      "cs.AI"
    ],
    "published": "2025-10-28T10:39:04Z",
    "authors": [
      "Pietro Bongini",
      "Valentina Molinari",
      "Andrea Costanzo",
      "Benedetta Tondi",
      "Mauro Barni"
    ],
    "pdf_url": "http://arxiv.org/pdf/2510.24278v1"
  },
  {
    "id": "2510.24272v1",
    "title": "Survey and Tutorial of Reinforcement Learning Methods in Process Systems\n  Engineering",
    "abstract": "Sequential decision making under uncertainty is central to many Process\nSystems Engineering (PSE) challenges, where traditional methods often face\nlimitations related to controlling and optimizing complex and stochastic\nsystems. Reinforcement Learning (RL) offers a data-driven approach to derive\ncontrol policies for such challenges. This paper presents a survey and tutorial\non RL methods, tailored for the PSE community. We deliver a tutorial on RL,\ncovering fundamental concepts and key algorithmic families including\nvalue-based, policy-based and actor-critic methods. Subsequently, we survey\nexisting applications of these RL techniques across various PSE domains, such\nas in fed-batch and continuous process control, process optimization, and\nsupply chains. We conclude with PSE focused discussion of specialized\ntechniques and emerging directions. By synthesizing the current state of RL\nalgorithm development and implications for PSE this work identifies successes,\nchallenges, trends, and outlines avenues for future research at the interface\nof these fields.",
    "categories": [
      "eess.SY",
      "cs.AI",
      "cs.SY"
    ],
    "published": "2025-10-28T10:31:12Z",
    "authors": [
      "Maximilian Bloor",
      "Max Mowbray",
      "Ehecatl Antonio Del Rio Chanona",
      "Calvin Tsay"
    ],
    "pdf_url": "http://arxiv.org/pdf/2510.24272v1"
  },
  {
    "id": "2510.24261v1",
    "title": "DynaRend: Learning 3D Dynamics via Masked Future Rendering for Robotic\n  Manipulation",
    "abstract": "Learning generalizable robotic manipulation policies remains a key challenge\ndue to the scarcity of diverse real-world training data. While recent\napproaches have attempted to mitigate this through self-supervised\nrepresentation learning, most either rely on 2D vision pretraining paradigms\nsuch as masked image modeling, which primarily focus on static semantics or\nscene geometry, or utilize large-scale video prediction models that emphasize\n2D dynamics, thus failing to jointly learn the geometry, semantics, and\ndynamics required for effective manipulation. In this paper, we present\nDynaRend, a representation learning framework that learns 3D-aware and\ndynamics-informed triplane features via masked reconstruction and future\nprediction using differentiable volumetric rendering. By pretraining on\nmulti-view RGB-D video data, DynaRend jointly captures spatial geometry, future\ndynamics, and task semantics in a unified triplane representation. The learned\nrepresentations can be effectively transferred to downstream robotic\nmanipulation tasks via action value map prediction. We evaluate DynaRend on two\nchallenging benchmarks, RLBench and Colosseum, as well as in real-world robotic\nexperiments, demonstrating substantial improvements in policy success rate,\ngeneralization to environmental perturbations, and real-world applicability\nacross diverse manipulation tasks.",
    "categories": [
      "cs.RO",
      "cs.AI",
      "cs.CV"
    ],
    "published": "2025-10-28T10:17:11Z",
    "authors": [
      "Jingyi Tian",
      "Le Wang",
      "Sanping Zhou",
      "Sen Wang",
      "Jiayi Li",
      "Gang Hua"
    ],
    "pdf_url": "http://arxiv.org/pdf/2510.24261v1"
  },
  {
    "id": "2510.24817v2",
    "title": "Towards a Method for Synthetic Generation of Persons with Aphasia\n  Transcripts",
    "abstract": "In aphasia research, Speech-Language Pathologists (SLPs) devote extensive\ntime to manually coding speech samples using Correct Information Units (CIUs),\na measure of how informative an individual sample of speech is. Developing\nautomated systems to recognize aphasic language is limited by data scarcity.\nFor example, only about 600 transcripts are available in AphasiaBank yet\nbillions of tokens are used to train large language models (LLMs). In the\nbroader field of machine learning (ML), researchers increasingly turn to\nsynthetic data when such are sparse. Therefore, this study constructs and\nvalidates two methods to generate synthetic transcripts of the AphasiaBank Cat\nRescue picture description task. One method leverages a procedural programming\napproach while the second uses Mistral 7b Instruct and Llama 3.1 8b Instruct\nLLMs. The methods generate transcripts across four severity levels (Mild,\nModerate, Severe, Very Severe) through word dropping, filler insertion, and\nparaphasia substitution. Overall, we found, compared to human-elicited\ntranscripts, Mistral 7b Instruct best captures key aspects of linguistic\ndegradation observed in aphasia, showing realistic directional changes in NDW,\nword count, and word length amongst the synthetic generation methods. Based on\nthe results, future work should plan to create a larger dataset, fine-tune\nmodels for better aphasic representation, and have SLPs assess the realism and\nusefulness of the synthetic transcripts.",
    "categories": [
      "cs.CL",
      "cs.AI",
      "cs.LG"
    ],
    "published": "2025-10-28T10:06:49Z",
    "authors": [
      "Jason M. Pittman",
      "Anton Phillips Jr.",
      "Yesenia Medina-Santos",
      "Brielle C. Stark"
    ],
    "pdf_url": "http://arxiv.org/pdf/2510.24817v2"
  },
  {
    "id": "2510.24255v1",
    "title": "Trajectory Design for UAV-Based Low-Altitude Wireless Networks in\n  Unknown Environments: A Digital Twin-Assisted TD3 Approach",
    "abstract": "Unmanned aerial vehicles (UAVs) are emerging as key enablers for low-altitude\nwireless network (LAWN), particularly when terrestrial networks are\nunavailable. In such scenarios, the environmental topology is typically\nunknown; hence, designing efficient and safe UAV trajectories is essential yet\nchallenging. To address this, we propose a digital twin (DT)-assisted training\nand deployment framework. In this framework, the UAV transmits integrated\nsensing and communication signals to provide communication services to ground\nusers, while simultaneously collecting echoes that are uploaded to the DT\nserver to progressively construct virtual environments (VEs). These VEs\naccelerate model training and are continuously updated with real-time UAV\nsensing data during deployment, supporting decision-making and enhancing flight\nsafety. Based on this framework, we further develop a trajectory design scheme\nthat integrates simulated annealing for efficient user scheduling with the\ntwin-delayed deep deterministic policy gradient algorithm for continuous\ntrajectory design, aiming to minimize mission completion time while ensuring\nobstacle avoidance. Simulation results demonstrate that the proposed approach\nachieves faster convergence, higher flight safety, and shorter mission\ncompletion time compared with baseline methods, providing a robust and\nefficient solution for LAWN deployment in unknown environments.",
    "categories": [
      "eess.SP",
      "cs.AI"
    ],
    "published": "2025-10-28T10:05:53Z",
    "authors": [
      "Jihao Luo",
      "Zesong Fei",
      "Xinyi Wang",
      "Le Zhao",
      "Yuanhao Cui",
      "Guangxu Zhu",
      "Dusit Niyato"
    ],
    "pdf_url": "http://arxiv.org/pdf/2510.24255v1"
  },
  {
    "id": "2510.24816v1",
    "title": "Perception, Understanding and Reasoning, A Multimodal Benchmark for\n  Video Fake News Detection",
    "abstract": "The advent of multi-modal large language models (MLLMs) has greatly advanced\nresearch into applications for Video fake news detection (VFND) tasks.\nTraditional video-based FND benchmarks typically focus on the accuracy of the\nfinal decision, often failing to provide fine-grained assessments for the\nentire detection process, making the detection process a black box. Therefore,\nwe introduce the MVFNDB (Multi-modal Video Fake News Detection Benchmark) based\non the empirical analysis, which provides foundation for tasks definition. The\nbenchmark comprises 10 tasks and is meticulously crafted to probe MLLMs'\nperception, understanding, and reasoning capacities during detection, featuring\n9730 human-annotated video-related questions based on a carefully constructed\ntaxonomy ability of VFND. To validate the impact of combining multiple features\non the final results, we design a novel framework named MVFND-CoT, which\nincorporates both creator-added content and original shooting footage\nreasoning. Building upon the benchmark, we conduct an in-depth analysis of the\ndeeper factors influencing accuracy, including video processing strategies and\nthe alignment between video features and model capabilities. We believe this\nbenchmark will lay a solid foundation for future evaluations and advancements\nof MLLMs in the domain of video fake news detection.",
    "categories": [
      "cs.CV",
      "cs.AI"
    ],
    "published": "2025-10-28T10:04:13Z",
    "authors": [
      "Cui Yakun",
      "Fushuo Huo",
      "Weijie Shi",
      "Juntao Dai",
      "Hang Du",
      "Zhenghao Zhu",
      "Sirui Han",
      "Yike Guo"
    ],
    "pdf_url": "http://arxiv.org/pdf/2510.24816v1"
  },
  {
    "id": "2510.24242v1",
    "title": "Enabling Near-realtime Remote Sensing via Satellite-Ground Collaboration\n  of Large Vision-Language Models",
    "abstract": "Large vision-language models (LVLMs) have recently demonstrated great\npotential in remote sensing (RS) tasks (e.g., disaster monitoring) conducted by\nlow Earth orbit (LEO) satellites. However, their deployment in real-world LEO\nsatellite systems remains largely unexplored, hindered by limited onboard\ncomputing resources and brief satellite-ground contacts. We propose Grace, a\nsatellite-ground collaborative system designed for near-realtime LVLM inference\nin RS tasks. Accordingly, we deploy compact LVLM on satellites for realtime\ninference, but larger ones on ground stations (GSs) to guarantee end-to-end\nperformance. Grace is comprised of two main phases that are asynchronous\nsatellite-GS Retrieval-Augmented Generation (RAG), and a task dispatch\nalgorithm. Firstly, we still the knowledge archive of GS RAG to satellite\narchive with tailored adaptive update algorithm during limited satellite-ground\ndata exchange period. Secondly, propose a confidence-based test algorithm that\neither processes the task onboard the satellite or offloads it to the GS.\nExtensive experiments based on real-world satellite orbital data show that\nGrace reduces the average latency by 76-95% compared to state-of-the-art\nmethods, without compromising inference accuracy.",
    "categories": [
      "cs.NI",
      "cs.AI",
      "cs.LG"
    ],
    "published": "2025-10-28T09:48:26Z",
    "authors": [
      "Zihan Li",
      "Jiahao Yang",
      "Yuxin Zhang",
      "Zhe Chen",
      "Yue Gao"
    ],
    "pdf_url": "http://arxiv.org/pdf/2510.24242v1"
  },
  {
    "id": "2510.24241v1",
    "title": "MAGNET: A Multi-Graph Attentional Network for Code Clone Detection",
    "abstract": "Code clone detection is a fundamental task in software engineering that\nunderpins refactoring, debugging, plagiarism detection, and vulnerability\nanalysis. Existing methods often rely on singular representations such as\nabstract syntax trees (ASTs), control flow graphs (CFGs), and data flow graphs\n(DFGs), which capture only partial aspects of code semantics. Hybrid approaches\nhave emerged, but their fusion strategies are typically handcrafted and\nineffective. In this study, we propose MAGNET, a multi-graph attentional\nframework that jointly leverages AST, CFG, and DFG representations to capture\nsyntactic and semantic features of source code. MAGNET integrates residual\ngraph neural networks with node-level self-attention to learn both local and\nlong-range dependencies, introduces a gated cross-attention mechanism for\nfine-grained inter-graph interactions, and employs Set2Set pooling to fuse\nmulti-graph embeddings into unified program-level representations. Extensive\nexperiments on BigCloneBench and Google Code Jam demonstrate that MAGNET\nachieves state-of-the-art performance with an overall F1 score of 96.5\\% and\n99.2\\% on the two datasets, respectively. Ablation studies confirm the critical\ncontributions of multi-graph fusion and each attentional component. Our code is\navailable at https://github.com/ZixianReid/Multigraph_match",
    "categories": [
      "cs.SE",
      "cs.AI"
    ],
    "published": "2025-10-28T09:48:06Z",
    "authors": [
      "Zixian Zhang",
      "Takfarinas Saber"
    ],
    "pdf_url": "http://arxiv.org/pdf/2510.24241v1"
  },
  {
    "id": "2510.24235v1",
    "title": "PaTaRM: Bridging Pairwise and Pointwise Signals via Preference-Aware\n  Task-Adaptive Reward Modeling",
    "abstract": "Reward models (RMs) are central to reinforcement learning from human feedback\n(RLHF), providing the critical supervision signals that align large language\nmodels (LLMs) with human preferences. While generative reward models (GRMs)\noffer greater interpretability than traditional scalar RMs, current training\nparadigms remain limited. Pair-wise methods rely on binary good-versus-bad\nlabels, which cause mismatches for point-wise inference and necessitate complex\npairing strategies for effective application in RLHF. On the other hand,\npoint-wise methods require more elaborate absolute labeling with rubric-driven\ncriteria, resulting in poor adaptability and high annotation costs. In this\nwork, we propose the Preference-Aware Task-Adaptive Reward Model (PaTaRM), a\nunified framework that integrates a preference-aware reward (PAR) mechanism\nwith dynamic rubric adaptation. PaTaRM leverages relative preference\ninformation from pairwise data to construct robust point-wise training signals,\neliminating the need for explicit point-wise labels. Simultaneously, it employs\na task-adaptive rubric system that flexibly generates evaluation criteria for\nboth global task consistency and instance-specific fine-grained reasoning. This\ndesign enables efficient, generalizable, and interpretable reward modeling for\nRLHF. Extensive experiments show that PaTaRM achieves an average relative\nimprovement of 4.7% on RewardBench and RMBench across Qwen3-8B and Qwen3-14B\nmodels. Furthermore, PaTaRM boosts downstream RLHF performance, with an average\nimprovement of 13.6% across IFEval and InFoBench benchmarks, confirming its\neffectiveness and robustness. Our code is available at\nhttps://github.com/JaneEyre0530/PaTaRM.",
    "categories": [
      "cs.LG",
      "cs.AI"
    ],
    "published": "2025-10-28T09:43:47Z",
    "authors": [
      "Ai Jian",
      "Jingqing Ruan",
      "Xing Ma",
      "Dailin Li",
      "QianLin Zhou",
      "Ke Zeng",
      "Xunliang Cai"
    ],
    "pdf_url": "http://arxiv.org/pdf/2510.24235v1"
  },
  {
    "id": "2510.24217v1",
    "title": "Closing Gaps: An Imputation Analysis of ICU Vital Signs",
    "abstract": "As more Intensive Care Unit (ICU) data becomes available, the interest in\ndeveloping clinical prediction models to improve healthcare protocols\nincreases. However, the lack of data quality still hinders clinical prediction\nusing Machine Learning (ML). Many vital sign measurements, such as heart rate,\ncontain sizeable missing segments, leaving gaps in the data that could\nnegatively impact prediction performance. Previous works have introduced\nnumerous time-series imputation techniques. Nevertheless, more comprehensive\nwork is needed to compare a representative set of methods for imputing ICU\nvital signs and determine the best practice. In reality, ad-hoc imputation\ntechniques that could decrease prediction accuracy, like zero imputation, are\nstill used. In this work, we compare established imputation techniques to guide\nresearchers in improving the performance of clinical prediction models by\nselecting the most accurate imputation technique. We introduce an extensible\nand reusable benchmark with currently 15 imputation and 4 amputation methods,\ncreated for benchmarking on major ICU datasets. We hope to provide a\ncomparative basis and facilitate further ML development to bring more models\ninto clinical practice.",
    "categories": [
      "cs.LG",
      "cs.AI"
    ],
    "published": "2025-10-28T09:30:52Z",
    "authors": [
      "Alisher Turubayev",
      "Anna Shopova",
      "Fabian Lange",
      "Mahmut Kamalak",
      "Paul Mattes",
      "Victoria Ayvasky",
      "Bert Arnrich",
      "Bjarne Pfitzner",
      "Robin P. van de Water"
    ],
    "pdf_url": "http://arxiv.org/pdf/2510.24217v1"
  },
  {
    "id": "2510.24814v1",
    "title": "Deep Feature Optimization for Enhanced Fish Freshness Assessment",
    "abstract": "Assessing fish freshness is vital for ensuring food safety and minimizing\neconomic losses in the seafood industry. However, traditional sensory\nevaluation remains subjective, time-consuming, and inconsistent. Although\nrecent advances in deep learning have automated visual freshness prediction,\nchallenges related to accuracy and feature transparency persist. This study\nintroduces a unified three-stage framework that refines and leverages deep\nvisual representations for reliable fish freshness assessment. First, five\nstate-of-the-art vision architectures - ResNet-50, DenseNet-121,\nEfficientNet-B0, ConvNeXt-Base, and Swin-Tiny - are fine-tuned to establish a\nstrong baseline. Next, multi-level deep features extracted from these backbones\nare used to train seven classical machine learning classifiers, integrating\ndeep and traditional decision mechanisms. Finally, feature selection methods\nbased on Light Gradient Boosting Machine (LGBM), Random Forest, and Lasso\nidentify a compact and informative subset of features. Experiments on the\nFreshness of the Fish Eyes (FFE) dataset demonstrate that the best\nconfiguration combining Swin-Tiny features, an Extra Trees classifier, and\nLGBM-based feature selection achieves an accuracy of 85.99%, outperforming\nrecent studies on the same dataset by 8.69-22.78%. These findings confirm the\neffectiveness and generalizability of the proposed framework for visual quality\nevaluation tasks.",
    "categories": [
      "cs.CV",
      "cs.AI",
      "68T07, 68U10",
      "I.5.4"
    ],
    "published": "2025-10-28T09:02:10Z",
    "authors": [
      "Phi-Hung Hoang",
      "Nam-Thuan Trinh",
      "Van-Manh Tran",
      "Thi-Thu-Hong Phan"
    ],
    "pdf_url": "http://arxiv.org/pdf/2510.24814v1"
  },
  {
    "id": "2510.24178v1",
    "title": "MuSaG: A Multimodal German Sarcasm Dataset with Full-Modal Annotations",
    "abstract": "Sarcasm is a complex form of figurative language in which the intended\nmeaning contradicts the literal one. Its prevalence in social media and popular\nculture poses persistent challenges for natural language understanding,\nsentiment analysis, and content moderation. With the emergence of multimodal\nlarge language models, sarcasm detection extends beyond text and requires\nintegrating cues from audio and vision. We present MuSaG, the first German\nmultimodal sarcasm detection dataset, consisting of 33 minutes of manually\nselected and human-annotated statements from German television shows. Each\ninstance provides aligned text, audio, and video modalities, annotated\nseparately by humans, enabling evaluation in unimodal and multimodal settings.\nWe benchmark nine open-source and commercial models, spanning text, audio,\nvision, and multimodal architectures, and compare their performance to human\nannotations. Our results show that while humans rely heavily on audio in\nconversational settings, models perform best on text. This highlights a gap in\ncurrent multimodal models and motivates the use of MuSaG for developing models\nbetter suited to realistic scenarios. We release MuSaG publicly to support\nfuture research on multimodal sarcasm detection and human-model alignment.",
    "categories": [
      "cs.CL",
      "cs.AI"
    ],
    "published": "2025-10-28T08:33:45Z",
    "authors": [
      "Aaron Scott",
      "Maike Z\u00fcfle",
      "Jan Niehues"
    ],
    "pdf_url": "http://arxiv.org/pdf/2510.24178v1"
  },
  {
    "id": "2510.24813v1",
    "title": "DualCap: Enhancing Lightweight Image Captioning via Dual Retrieval with\n  Similar Scenes Visual Prompts",
    "abstract": "Recent lightweight retrieval-augmented image caption models often utilize\nretrieved data solely as text prompts, thereby creating a semantic gap by\nleaving the original visual features unenhanced, particularly for object\ndetails or complex scenes. To address this limitation, we propose $DualCap$, a\nnovel approach that enriches the visual representation by generating a visual\nprompt from retrieved similar images. Our model employs a dual retrieval\nmechanism, using standard image-to-text retrieval for text prompts and a novel\nimage-to-image retrieval to source visually analogous scenes. Specifically,\nsalient keywords and phrases are derived from the captions of visually similar\nscenes to capture key objects and similar details. These textual features are\nthen encoded and integrated with the original image features through a\nlightweight, trainable feature fusion network. Extensive experiments\ndemonstrate that our method achieves competitive performance while requiring\nfewer trainable parameters compared to previous visual-prompting captioning\napproaches.",
    "categories": [
      "cs.CV",
      "cs.AI"
    ],
    "published": "2025-10-28T08:29:02Z",
    "authors": [
      "Binbin Li",
      "Guimiao Yang",
      "Zisen Qi",
      "Haiping Wang",
      "Yu Ding"
    ],
    "pdf_url": "http://arxiv.org/pdf/2510.24813v1"
  },
  {
    "id": "2510.24170v1",
    "title": "SymMaP: Improving Computational Efficiency in Linear Solvers through\n  Symbolic Preconditioning",
    "abstract": "Matrix preconditioning is a critical technique to accelerate the solution of\nlinear systems, where performance heavily depends on the selection of\npreconditioning parameters. Traditional parameter selection approaches often\ndefine fixed constants for specific scenarios. However, they rely on domain\nexpertise and fail to consider the instance-wise features for individual\nproblems, limiting their performance. In contrast, machine learning (ML)\napproaches, though promising, are hindered by high inference costs and limited\ninterpretability. To combine the strengths of both approaches, we propose a\nsymbolic discovery framework-namely, Symbolic Matrix Preconditioning\n(SymMaP)-to learn efficient symbolic expressions for preconditioning\nparameters. Specifically, we employ a neural network to search the\nhigh-dimensional discrete space for expressions that can accurately predict the\noptimal parameters. The learned expression allows for high inference efficiency\nand excellent interpretability (expressed in concise symbolic formulas), making\nit simple and reliable for deployment. Experimental results show that SymMaP\nconsistently outperforms traditional strategies across various benchmarks.",
    "categories": [
      "math.NA",
      "cs.AI",
      "cs.NA"
    ],
    "published": "2025-10-28T08:25:03Z",
    "authors": [
      "Hong Wang",
      "Jie Wang",
      "Minghao Ma",
      "Haoran Shao",
      "Haoyang Liu"
    ],
    "pdf_url": "http://arxiv.org/pdf/2510.24170v1"
  },
  {
    "id": "2510.24168v1",
    "title": "MGA: Memory-Driven GUI Agent for Observation-Centric Interaction",
    "abstract": "The rapid progress of Large Language Models (LLMs) and their multimodal\nextensions (MLLMs) has enabled agentic systems capable of perceiving and acting\nacross diverse environments. A challenging yet impactful frontier is the\ndevelopment of GUI agents, which must navigate complex desktop and web\ninterfaces while maintaining robustness and generalization. Existing paradigms\ntypically model tasks as long-chain executions, concatenating historical\ntrajectories into the context. While approaches such as Mirage and GTA1 refine\nplanning or introduce multi-branch action selection, they remain constrained by\ntwo persistent issues: Dependence on historical trajectories, which amplifies\nerror propagation. And Local exploration bias, where \"decision-first,\nobservation-later\" mechanisms overlook critical interface cues. We introduce\nthe Memory-Driven GUI Agent (MGA), which reframes GUI interaction around the\nprinciple of observe first, then decide. MGA models each step as an\nindependent, context-rich environment state represented by a triad: current\nscreenshot, task-agnostic spatial information, and a dynamically updated\nstructured memory. Experiments on OSworld benchmarks, real desktop applications\n(Chrome, VSCode, VLC), and cross-task transfer demonstrate that MGA achieves\nsubstantial gains in robustness, generalization, and efficiency compared to\nstate-of-the-art baselines. The code is publicly available at:\n{https://anonymous.4open.science/r/MGA-3571}.",
    "categories": [
      "cs.AI"
    ],
    "published": "2025-10-28T08:19:58Z",
    "authors": [
      "Weihua Cheng",
      "Ersheng Ni",
      "Wenlong Wang",
      "Yifei Sun",
      "Junming Liu",
      "Wangyu Shen",
      "Yirong Chen",
      "Botian Shi",
      "Ding Wang"
    ],
    "pdf_url": "http://arxiv.org/pdf/2510.24168v1"
  },
  {
    "id": "2510.24166v1",
    "title": "UniPlanner: A Unified Motion Planning Framework for Autonomous Vehicle\n  Decision-Making Systems via Multi-Dataset Integration",
    "abstract": "Motion planning is a critical component of autonomous vehicle decision-making\nsystems, directly determining trajectory safety and driving efficiency. While\ndeep learning approaches have advanced planning capabilities, existing methods\nremain confined to single-dataset training, limiting their robustness in\nplanning.\n  Through systematic analysis, we discover that vehicular trajectory\ndistributions and history-future correlations demonstrate remarkable\nconsistency across different datasets. Based on these findings, we propose\nUniPlanner, the first planning framework designed for multi-dataset integration\nin autonomous vehicle decision-making. UniPlanner achieves unified\ncross-dataset learning through three synergistic innovations.\n  First, the History-Future Trajectory Dictionary Network (HFTDN) aggregates\nhistory-future trajectory pairs from multiple datasets, using historical\ntrajectory similarity to retrieve relevant futures and generate cross-dataset\nplanning guidance.\n  Second, the Gradient-Free Trajectory Mapper (GFTM) learns robust\nhistory-future correlations from multiple datasets, transforming historical\ntrajectories into universal planning priors. Its gradient-free design ensures\nthe introduction of valuable priors while preventing shortcut learning, making\nthe planning knowledge safely transferable. Third, the Sparse-to-Dense (S2D)\nparadigm implements adaptive dropout to selectively suppress planning priors\nduring training for robust learning, while enabling full prior utilization\nduring inference to maximize planning performance.",
    "categories": [
      "cs.AI"
    ],
    "published": "2025-10-28T08:12:15Z",
    "authors": [
      "Xin Yang",
      "Yuhang Zhang",
      "Wei Li",
      "Xin Lin",
      "Wenbin Zou",
      "Chen Xu"
    ],
    "pdf_url": "http://arxiv.org/pdf/2510.24166v1"
  },
  {
    "id": "2510.24161v1",
    "title": "BLM$_1$: A Boundless Large Model for Cross-Space, Cross-Task, and\n  Cross-Embodiment Learning",
    "abstract": "Multimodal large language models (MLLMs) have advanced vision-language\nreasoning and are increasingly deployed in embodied agents. However,\nsignificant limitations remain: MLLMs generalize poorly across digital-physical\nspaces and embodiments; vision-language-action models (VLAs) produce low-level\nactions yet lack robust high-level embodied reasoning; and most embodied large\nlanguage models (ELLMs) are constrained to digital-space with poor\ngeneralization to the physical world. Thus, unified models that operate\nseamlessly across digital and physical spaces while generalizing across\nembodiments and tasks remain absent. We introduce the \\textbf{Boundless Large\nModel (BLM$_1$)}, a multimodal spatial foundation model that preserves\ninstruction following and reasoning, incorporates embodied knowledge, and\nsupports robust cross-embodiment control. BLM$_1$ integrates three key\ncapabilities -- \\textit{cross-space transfer, cross-task learning, and\ncross-embodiment generalization} -- via a two-stage training paradigm. Stage I\ninjects embodied knowledge into the MLLM through curated digital corpora while\nmaintaining language competence. Stage II trains a policy module through an\nintent-bridging interface that extracts high-level semantics from the MLLM to\nguide control, without fine-tuning the MLLM backbone. This process is supported\nby a self-collected cross-embodiment demonstration suite spanning four robot\nembodiments and six progressively challenging tasks. Evaluations across digital\nand physical benchmarks show that a single BLM$_1$ instance outperforms four\nmodel families -- MLLMs, ELLMs, VLAs, and GMLMs -- achieving\n$\\sim\\!\\textbf{6%}$ gains in digital tasks and $\\sim\\!\\textbf{3%}$ in physical\ntasks.",
    "categories": [
      "cs.AI",
      "cs.MM",
      "cs.RO"
    ],
    "published": "2025-10-28T07:58:39Z",
    "authors": [
      "Wentao Tan",
      "Bowen Wang",
      "Heng Zhi",
      "Chenyu Liu",
      "Zhe Li",
      "Jian Liu",
      "Zengrong Lin",
      "Yukun Dai",
      "Yipeng Chen",
      "Wenjie Yang",
      "Enci Xie",
      "Hao Xue",
      "Baixu Ji",
      "Chen Xu",
      "Zhibin Wang",
      "Tianshi Wang",
      "Lei Zhu",
      "Heng Tao Shen"
    ],
    "pdf_url": "http://arxiv.org/pdf/2510.24161v1"
  },
  {
    "id": "2510.24159v1",
    "title": "Self-supervised Synthetic Pretraining for Inference of Stellar Mass\n  Embedded in Dense Gas",
    "abstract": "Stellar mass is a fundamental quantity that determines the properties and\nevolution of stars. However, estimating stellar masses in star-forming regions\nis challenging because young stars are obscured by dense gas and the regions\nare highly inhomogeneous, making spherical dynamical estimates unreliable.\nSupervised machine learning could link such complex structures to stellar mass,\nbut it requires large, high-quality labeled datasets from high-resolution\nmagneto-hydrodynamical (MHD) simulations, which are computationally expensive.\nWe address this by pretraining a vision transformer on one million synthetic\nfractal images using the self-supervised framework DINOv2, and then applying\nthe frozen model to limited high-resolution MHD simulations. Our results\ndemonstrate that synthetic pretraining improves frozen-feature regression\nstellar mass predictions, with the pretrained model performing slightly better\nthan a supervised model trained on the same limited simulations. Principal\ncomponent analysis of the extracted features further reveals semantically\nmeaningful structures, suggesting that the model enables unsupervised\nsegmentation of star-forming regions without the need for labeled data or\nfine-tuning.",
    "categories": [
      "astro-ph.GA",
      "astro-ph.IM",
      "cs.AI",
      "cs.LG"
    ],
    "published": "2025-10-28T07:55:34Z",
    "authors": [
      "Keiya Hirashima",
      "Shingo Nozaki",
      "Naoto Harada"
    ],
    "pdf_url": "http://arxiv.org/pdf/2510.24159v1"
  },
  {
    "id": "2510.24152v1",
    "title": "Enhancing Vision-Language Models for Autonomous Driving through\n  Task-Specific Prompting and Spatial Reasoning",
    "abstract": "This technical report presents our solution for the RoboSense Challenge at\nIROS 2025, which evaluates Vision-Language Models (VLMs) on autonomous driving\nscene understanding across perception, prediction, planning, and corruption\ndetection tasks. We propose a systematic framework built on four core\ncomponents. First, a Mixture-of-Prompts router classifies questions and\ndispatches them to task-specific expert prompts, eliminating interference\nacross diverse question types. Second, task-specific prompts embed explicit\ncoordinate systems, spatial reasoning rules, role-playing,\nChain-of-Thought/Tree-of-Thought reasoning, and few-shot examples tailored to\neach task. Third, a visual assembly module composes multi-view images with\nobject crops, magenta markers, and adaptive historical frames based on question\nrequirements. Fourth, we configure model inference parameters (temperature,\ntop-p, message roles) per task to optimize output quality. Implemented on\nQwen2.5-VL-72B, our approach achieves 70.87% average accuracy on Phase-1 (clean\ndata) and 72.85% on Phase-2 (corrupted data), demonstrating that structured\nprompting and spatial grounding substantially enhance VLM performance on\nsafety-critical autonomous driving tasks. Code and prompt are available at\nhttps://github.com/wuaodi/UCAS-CSU-phase2.",
    "categories": [
      "cs.CV",
      "cs.AI"
    ],
    "published": "2025-10-28T07:43:30Z",
    "authors": [
      "Aodi Wu",
      "Xubo Luo"
    ],
    "pdf_url": "http://arxiv.org/pdf/2510.24152v1"
  },
  {
    "id": "2510.24151v1",
    "title": "BMGQ: A Bottom-up Method for Generating Complex Multi-hop Reasoning\n  Questions from Semi-structured Data",
    "abstract": "Building training-ready multi-hop question answering (QA) datasets that truly\nstress a model's retrieval and reasoning abilities remains highly challenging\nrecently. While there have been a few recent evaluation datasets that capture\nthe characteristics of hard-to-search but easy-to-verify problems -- requiring\nthe integration of ambiguous, indirect, and cross-domain cues -- these data\nresources remain scarce and are mostly designed for evaluation, making them\nunsuitable for supervised fine-tuning (SFT) or reinforcement learning (RL).\nMeanwhile, manually curating non-trivially retrievable questions -- where\nanswers cannot be found through a single direct query but instead require\nmulti-hop reasoning over oblique and loosely connected evidence -- incurs\nprohibitive human costs and fails to scale, creating a critical data bottleneck\nfor training high-capability retrieval-and-reasoning agents.\n  To address this, we present an automated framework for generating\nhigh-difficulty, training-ready multi-hop questions from semi-structured\nknowledge sources. The system (i) grows diverse, logically labeled evidence\nclusters through Natural Language Inference (NLI)-based relation typing and\ndiversity-aware expansion; (ii) applies reverse question construction to\ncompose oblique cues so that isolated signals are underinformative but their\ncombination uniquely identifies the target entity; and (iii) enforces quality\nwith a two-step evaluation pipeline that combines multi-model consensus\nfiltering with structured constraint decomposition and evidence-based matching.\nThe result is a scalable process that yields complex, retrieval-resistant yet\nverifiable questions suitable for SFT/RL training as well as challenging\nevaluation, substantially reducing human curation effort while preserving the\ndifficulty profile of strong evaluation benchmarks.",
    "categories": [
      "cs.AI"
    ],
    "published": "2025-10-28T07:43:15Z",
    "authors": [
      "Bingsen Qiu",
      "Zijian Liu",
      "Xiao Liu",
      "Haoshen Yang",
      "Zeren Gao",
      "Bingjie Wang",
      "Feier Zhang",
      "Yixuan Qin",
      "Chunyan Li"
    ],
    "pdf_url": "http://arxiv.org/pdf/2510.24151v1"
  },
  {
    "id": "2510.24150v1",
    "title": "Ko-MuSR: A Multistep Soft Reasoning Benchmark for LLMs Capable of\n  Understanding Korean",
    "abstract": "We present Ko-MuSR, the first benchmark to comprehensively evaluate\nmultistep, soft reasoning in long Korean narratives while minimizing data\ncontamination. Built following MuSR, Ko-MuSR features fully Korean narratives,\nreasoning chains, and multiple-choice questions verified by human annotators\nfor logical consistency and answerability. Evaluations of four large language\nmodels -- two multilingual and two Korean-specialized -- show that multilingual\nmodels outperform Korean-focused ones even in Korean reasoning tasks,\nindicating cross-lingual generalization of reasoning ability. Carefully\ndesigned prompting strategies, which combine few-shot examples, reasoning\ntraces, and task-specific hints, further boost accuracy, approaching\nhuman-level performance. Ko-MuSR offers a solid foundation for advancing Korean\nNLP by enabling systematic evaluation of long-context reasoning and prompting\nstrategies.",
    "categories": [
      "cs.CL",
      "cs.AI"
    ],
    "published": "2025-10-28T07:42:59Z",
    "authors": [
      "Chanwoo Park",
      "Suyoung Park",
      "JiA Kang",
      "Jongyeon Park",
      "Sangho Kim",
      "Hyunji M. Park",
      "Sumin Bae",
      "Mingyu Kang",
      "Jaejin Lee"
    ],
    "pdf_url": "http://arxiv.org/pdf/2510.24150v1"
  },
  {
    "id": "2510.24145v1",
    "title": "From Observability Data to Diagnosis: An Evolving Multi-agent System for\n  Incident Management in Cloud Systems",
    "abstract": "Incident management (IM) is central to the reliability of large-scale cloud\nsystems. Yet manual IM, where on-call engineers examine metrics, logs, and\ntraces is labor-intensive and error-prone in the face of massive and\nheterogeneous observability data. Existing automated IM approaches often\nstruggle to generalize across systems, provide limited interpretability, and\nincur high deployment costs, which hinders adoption in practice. In this paper,\nwe present OpsAgent, a lightweight, self-evolving multi-agent system for IM\nthat employs a training-free data processor to convert heterogeneous\nobservability data into structured textual descriptions, along with a\nmulti-agent collaboration framework that makes diagnostic inference transparent\nand auditable. To support continual capability growth, OpsAgent also introduces\na dual self-evolution mechanism that integrates internal model updates with\nexternal experience accumulation, thereby closing the deployment loop.\nComprehensive experiments on the OPENRCA benchmark demonstrate state-of-the-art\nperformance and show that OpsAgent is generalizable, interpretable,\ncost-efficient, and self-evolving, making it a practically deployable and\nsustainable solution for long-term operation in real-world cloud systems.",
    "categories": [
      "cs.AI"
    ],
    "published": "2025-10-28T07:38:15Z",
    "authors": [
      "Yu Luo",
      "Jiamin Jiang",
      "Jingfei Feng",
      "Lei Tao",
      "Qingliang Zhang",
      "Xidao Wen",
      "Yongqian Sun",
      "Shenglin Zhang",
      "Jielong Huang",
      "Nan Qi",
      "Dan Pei"
    ],
    "pdf_url": "http://arxiv.org/pdf/2510.24145v1"
  },
  {
    "id": "2510.24139v1",
    "title": "Beyond Line-Level Filtering for the Pretraining Corpora of LLMs",
    "abstract": "While traditional line-level filtering techniques, such as line-level\ndeduplication and trailing-punctuation filters, are commonly used, these basic\nmethods can sometimes discard valuable content, negatively affecting downstream\nperformance. In this paper, we introduce two methods-pattern-aware line-level\ndeduplication (PLD) and pattern-aware trailing punctuation filtering (PTF)-by\nenhancing the conventional filtering techniques. Our approach not only\nconsiders line-level signals but also takes into account their sequential\ndistribution across documents, enabling us to retain structurally important\ncontent that might otherwise be removed. We evaluate these proposed methods by\ntraining small language models (1 B parameters) in both English and Korean. The\nresults demonstrate that our methods consistently improve performance on\nmultiple-choice benchmarks and significantly enhance generative\nquestion-answering accuracy on both SQuAD v1 and KorQuAD v1.",
    "categories": [
      "cs.CL",
      "cs.AI"
    ],
    "published": "2025-10-28T07:24:32Z",
    "authors": [
      "Chanwoo Park",
      "Suyoung Park",
      "Yelim Ahn",
      "Jongmin Kim",
      "Jongyeon Park",
      "Jaejin Lee"
    ],
    "pdf_url": "http://arxiv.org/pdf/2510.24139v1"
  },
  {
    "id": "2510.24134v2",
    "title": "VC4VG: Optimizing Video Captions for Text-to-Video Generation",
    "abstract": "Recent advances in text-to-video (T2V) generation highlight the critical role\nof high-quality video-text pairs in training models capable of producing\ncoherent and instruction-aligned videos. However, strategies for optimizing\nvideo captions specifically for T2V training remain underexplored. In this\npaper, we introduce VC4VG (Video Captioning for Video Generation), a\ncomprehensive caption optimization framework tailored to the needs of T2V\nmodels. We begin by analyzing caption content from a T2V perspective,\ndecomposing the essential elements required for video reconstruction into\nmultiple dimensions, and proposing a principled caption design methodology. To\nsupport evaluation, we construct VC4VG-Bench, a new benchmark featuring\nfine-grained, multi-dimensional, and necessity-graded metrics aligned with\nT2V-specific requirements. Extensive T2V fine-tuning experiments demonstrate a\nstrong correlation between improved caption quality and video generation\nperformance, validating the effectiveness of our approach. We release all\nbenchmark tools and code at https://github.com/alimama-creative/VC4VG to\nsupport further research.",
    "categories": [
      "cs.CV",
      "cs.AI",
      "cs.CL"
    ],
    "published": "2025-10-28T07:19:01Z",
    "authors": [
      "Yang Du",
      "Zhuoran Lin",
      "Kaiqiang Song",
      "Biao Wang",
      "Zhicheng Zheng",
      "Tiezheng Ge",
      "Bo Zheng",
      "Qin Jin"
    ],
    "pdf_url": "http://arxiv.org/pdf/2510.24134v2"
  },
  {
    "id": "2510.24133v1",
    "title": "Compositional Image Synthesis with Inference-Time Scaling",
    "abstract": "Despite their impressive realism, modern text-to-image models still struggle\nwith compositionality, often failing to render accurate object counts,\nattributes, and spatial relations. To address this challenge, we present a\ntraining-free framework that combines an object-centric approach with\nself-refinement to improve layout faithfulness while preserving aesthetic\nquality. Specifically, we leverage large language models (LLMs) to synthesize\nexplicit layouts from input prompts, and we inject these layouts into the image\ngeneration process, where a object-centric vision-language model (VLM) judge\nreranks multiple candidates to select the most prompt-aligned outcome\niteratively. By unifying explicit layout-grounding with self-refine-based\ninference-time scaling, our framework achieves stronger scene alignment with\nprompts compared to recent text-to-image models. The code are available at\nhttps://github.com/gcl-inha/ReFocus.",
    "categories": [
      "cs.CV",
      "cs.AI"
    ],
    "published": "2025-10-28T07:16:21Z",
    "authors": [
      "Minsuk Ji",
      "Sanghyeok Lee",
      "Namhyuk Ahn"
    ],
    "pdf_url": "http://arxiv.org/pdf/2510.24133v1"
  },
  {
    "id": "2510.24118v1",
    "title": "LagMemo: Language 3D Gaussian Splatting Memory for Multi-modal\n  Open-vocabulary Multi-goal Visual Navigation",
    "abstract": "Navigating to a designated goal using visual information is a fundamental\ncapability for intelligent robots. Most classical visual navigation methods are\nrestricted to single-goal, single-modality, and closed set goal settings. To\naddress the practical demands of multi-modal, open-vocabulary goal queries and\nmulti-goal visual navigation, we propose LagMemo, a navigation system that\nleverages a language 3D Gaussian Splatting memory. During exploration, LagMemo\nconstructs a unified 3D language memory. With incoming task goals, the system\nqueries the memory, predicts candidate goal locations, and integrates a local\nperception-based verification mechanism to dynamically match and validate goals\nduring navigation. For fair and rigorous evaluation, we curate GOAT-Core, a\nhigh-quality core split distilled from GOAT-Bench tailored to multi-modal\nopen-vocabulary multi-goal visual navigation. Experimental results show that\nLagMemo's memory module enables effective multi-modal open-vocabulary goal\nlocalization, and that LagMemo outperforms state-of-the-art methods in\nmulti-goal visual navigation. Project page:\nhttps://weekgoodday.github.io/lagmemo",
    "categories": [
      "cs.RO",
      "cs.AI"
    ],
    "published": "2025-10-28T06:42:21Z",
    "authors": [
      "Haotian Zhou",
      "Xiaole Wang",
      "He Li",
      "Fusheng Sun",
      "Shengyu Guo",
      "Guolei Qi",
      "Jianghuan Xu",
      "Huijing Zhao"
    ],
    "pdf_url": "http://arxiv.org/pdf/2510.24118v1"
  },
  {
    "id": "2510.24115v1",
    "title": "HistoLens: An Interactive XAI Toolkit for Verifying and Mitigating Flaws\n  in Vision-Language Models for Histopathology",
    "abstract": "For doctors to truly trust artificial intelligence, it can't be a black box.\nThey need to understand its reasoning, almost as if they were consulting a\ncolleague. We created HistoLens1 to be that transparent, collaborative partner.\nIt allows a pathologist to simply ask a question in plain English about a\ntissue slide--just as they would ask a trainee. Our system intelligently\ntranslates this question into a precise query for its AI engine, which then\nprovides a clear, structured report. But it doesn't stop there. If a doctor\never asks, \"Why?\", HistoLens can instantly provide a 'visual proof' for any\nfinding--a heatmap that points to the exact cells and regions the AI used for\nits analysis. We've also ensured the AI focuses only on the patient's tissue,\njust like a trained pathologist would, by teaching it to ignore distracting\nbackground noise. The result is a workflow where the pathologist remains the\nexpert in charge, using a trustworthy AI assistant to verify their insights and\nmake faster, more confident diagnoses.",
    "categories": [
      "cs.AI",
      "cs.LG"
    ],
    "published": "2025-10-28T06:38:59Z",
    "authors": [
      "Sandeep Vissapragada",
      "Vikrant Sahu",
      "Gagan Raj Gupta",
      "Vandita Singh"
    ],
    "pdf_url": "http://arxiv.org/pdf/2510.24115v1"
  },
  {
    "id": "2510.24113v1",
    "title": "Taming the Tail: NoI Topology Synthesis for Mixed DL Workloads on\n  Chiplet-Based Accelerators",
    "abstract": "Heterogeneous chiplet-based systems improve scaling by disag-gregating\nCPUs/GPUs and emerging technologies (HBM/DRAM).However this on-package\ndisaggregation introduces a latency inNetwork-on-Interposer(NoI). We observe\nthat in modern large-modelinference, parameters and activations routinely move\nbackand forth from HBM/DRAM, injecting large, bursty flows into theinterposer.\nThese memory-driven transfers inflate tail latency andviolate Service Level\nAgreements (SLAs) across k-ary n-cube base-line NoI topologies. To address this\ngap we introduce an InterferenceScore (IS) that quantifies worst-case slowdown\nunder contention.We then formulate NoI synthesis as a multi-objective\noptimization(MOO) problem. We develop PARL (Partition-Aware\nReinforcementLearner), a topology generator that balances throughput,\nlatency,and power. PARL-generated topologies reduce contention at the memory\ncut, meet SLAs, and cut worst-case slowdown to 1.2 times while maintaining\ncompetitive mean throughput relative to link-rich meshes. Overall, this\nreframes NoI design for heterogeneouschiplet accelerators with workload-aware\nobjectives.",
    "categories": [
      "cs.AR",
      "cs.AI",
      "cs.LG"
    ],
    "published": "2025-10-28T06:36:44Z",
    "authors": [
      "Arnav Shukla",
      "Harsh Sharma",
      "Srikant Bharadwaj",
      "Vinayak Abrol",
      "Sujay Deb"
    ],
    "pdf_url": "http://arxiv.org/pdf/2510.24113v1"
  },
  {
    "id": "2510.24811v1",
    "title": "ProofSketch: Efficient Verified Reasoning for Large Language Models",
    "abstract": "Reasoning methods such as chain-of-thought prompting and self-consistency\nhave shown immense potential to improve the accuracy of large language models\nacross various reasoning tasks. However such methods involve generation of\nlengthy reasoning chains, which substantially increases token consumption,\ncomputational cost, and latency. To address this inefficiency, we propose\nProofSketch, a verification-guided reasoning framework that integrates symbolic\nclosure computation, lexicographic verification and adaptive sketch generation.\nOur experiments show that ProofSketch consistently reduces token usage while\nimproving accuracy, demonstrating that this approach offers a promising path\nfor efficient and trustworthy reasoning.",
    "categories": [
      "cs.CL",
      "cs.AI",
      "cs.LG"
    ],
    "published": "2025-10-28T06:34:15Z",
    "authors": [
      "Disha Sheshanarayana",
      "Tanishka Magar"
    ],
    "pdf_url": "http://arxiv.org/pdf/2510.24811v1"
  },
  {
    "id": "2510.24103v1",
    "title": "Model-Guided Dual-Role Alignment for High-Fidelity Open-Domain\n  Video-to-Audio Generation",
    "abstract": "We present MGAudio, a novel flow-based framework for open-domain\nvideo-to-audio generation, which introduces model-guided dual-role alignment as\na central design principle. Unlike prior approaches that rely on\nclassifier-based or classifier-free guidance, MGAudio enables the generative\nmodel to guide itself through a dedicated training objective designed for\nvideo-conditioned audio generation. The framework integrates three main\ncomponents: (1) a scalable flow-based Transformer model, (2) a dual-role\nalignment mechanism where the audio-visual encoder serves both as a\nconditioning module and as a feature aligner to improve generation quality, and\n(3) a model-guided objective that enhances cross-modal coherence and audio\nrealism. MGAudio achieves state-of-the-art performance on VGGSound, reducing\nFAD to 0.40, substantially surpassing the best classifier-free guidance\nbaselines, and consistently outperforms existing methods across FD, IS, and\nalignment metrics. It also generalizes well to the challenging UnAV-100\nbenchmark. These results highlight model-guided dual-role alignment as a\npowerful and scalable paradigm for conditional video-to-audio generation. Code\nis available at: https://github.com/pantheon5100/mgaudio",
    "categories": [
      "cs.SD",
      "cs.AI",
      "cs.MM",
      "eess.AS"
    ],
    "published": "2025-10-28T06:16:47Z",
    "authors": [
      "Kang Zhang",
      "Trung X. Pham",
      "Suyeon Lee",
      "Axi Niu",
      "Arda Senocak",
      "Joon Son Chung"
    ],
    "pdf_url": "http://arxiv.org/pdf/2510.24103v1"
  },
  {
    "id": "2510.24095v1",
    "title": "Learning Parameterized Skills from Demonstrations",
    "abstract": "We present DEPS, an end-to-end algorithm for discovering parameterized skills\nfrom expert demonstrations. Our method learns parameterized skill policies\njointly with a meta-policy that selects the appropriate discrete skill and\ncontinuous parameters at each timestep. Using a combination of temporal\nvariational inference and information-theoretic regularization methods, we\naddress the challenge of degeneracy common in latent variable models, ensuring\nthat the learned skills are temporally extended, semantically meaningful, and\nadaptable. We empirically show that learning parameterized skills from\nmultitask expert demonstrations significantly improves generalization to unseen\ntasks. Our method outperforms multitask as well as skill learning baselines on\nboth LIBERO and MetaWorld benchmarks. We also demonstrate that DEPS discovers\ninterpretable parameterized skills, such as an object grasping skill whose\ncontinuous arguments define the grasp location.",
    "categories": [
      "cs.LG",
      "cs.AI",
      "cs.RO"
    ],
    "published": "2025-10-28T06:08:25Z",
    "authors": [
      "Vedant Gupta",
      "Haotian Fu",
      "Calvin Luo",
      "Yiding Jiang",
      "George Konidaris"
    ],
    "pdf_url": "http://arxiv.org/pdf/2510.24095v1"
  },
  {
    "id": "2510.24085v1",
    "title": "Modeling Electric Vehicle Car-Following Behavior: Classical vs Machine\n  Learning Approach",
    "abstract": "The increasing adoption of electric vehicles (EVs) necessitates an\nunderstanding of their driving behavior to enhance traffic safety and develop\nsmart driving systems. This study compares classical and machine learning\nmodels for EV car following behavior. Classical models include the Intelligent\nDriver Model (IDM), Optimum Velocity Model (OVM), Optimal Velocity Relative\nVelocity (OVRV), and a simplified CACC model, while the machine learning\napproach employs a Random Forest Regressor. Using a real world dataset of an EV\nfollowing an internal combustion engine (ICE) vehicle under varied driving\nconditions, we calibrated classical model parameters by minimizing the RMSE\nbetween predictions and real data. The Random Forest model predicts\nacceleration using spacing, speed, and gap type as inputs. Results demonstrate\nthe Random Forest's superior accuracy, achieving RMSEs of 0.0046 (medium gap),\n0.0016 (long gap), and 0.0025 (extra long gap). Among physics based models,\nCACC performed best, with an RMSE of 2.67 for long gaps. These findings\nhighlight the machine learning model's performance across all scenarios. Such\nmodels are valuable for simulating EV behavior and analyzing mixed autonomy\ntraffic dynamics in EV integrated environments.",
    "categories": [
      "cs.AI",
      "cs.LG"
    ],
    "published": "2025-10-28T05:54:50Z",
    "authors": [
      "Md. Shihab Uddin",
      "Md Nazmus Shakib",
      "Rahul Bhadani"
    ],
    "pdf_url": "http://arxiv.org/pdf/2510.24085v1"
  },
  {
    "id": "2510.24810v1",
    "title": "COMMUNITYNOTES: A Dataset for Exploring the Helpfulness of Fact-Checking\n  Explanations",
    "abstract": "Fact-checking on major platforms, such as X, Meta, and TikTok, is shifting\nfrom expert-driven verification to a community-based setup, where users\ncontribute explanatory notes to clarify why a post might be misleading. An\nimportant challenge here is determining whether an explanation is helpful for\nunderstanding real-world claims and the reasons why, which remains largely\nunderexplored in prior research. In practice, most community notes remain\nunpublished due to slow community annotation, and the reasons for helpfulness\nlack clear definitions. To bridge these gaps, we introduce the task of\npredicting both the helpfulness of explanatory notes and the reason for this.\nWe present COMMUNITYNOTES, a large-scale multilingual dataset of 104k posts\nwith user-provided notes and helpfulness labels. We further propose a framework\nthat automatically generates and improves reason definitions via automatic\nprompt optimization, and integrate them into prediction. Our experiments show\nthat the optimized definitions can improve both helpfulness and reason\nprediction. Finally, we show that the helpfulness information are beneficial\nfor existing fact-checking systems.",
    "categories": [
      "cs.CL",
      "cs.AI"
    ],
    "published": "2025-10-28T05:28:47Z",
    "authors": [
      "Rui Xing",
      "Preslav Nakov",
      "Timothy Baldwin",
      "Jey Han Lau"
    ],
    "pdf_url": "http://arxiv.org/pdf/2510.24810v1"
  },
  {
    "id": "2510.24072v1",
    "title": "Covert Surveillance in Smart Devices: A SCOUR Framework Analysis of\n  Youth Privacy Implications",
    "abstract": "This paper investigates how smart devices covertly capture private\nconversations and discusses in more in-depth the implications of this for youth\nprivacy. Using a structured review guided by the PRISMA methodology, the\nanalysis focuses on privacy concerns, data capture methods, data storage and\nsharing practices, and proposed technical mitigations. To structure and\nsynthesize findings, we introduce the SCOUR framework, encompassing\nSurveillance mechanisms, Consent and awareness, Operational data flow, Usage\nand exploitation, and Regulatory and technical safeguards. Findings reveal that\nsmart devices have been covertly capturing personal data, especially with smart\ntoys and voice-activated smart gadgets built for youth. These issues are\nworsened by unclear data collection practices and insufficient transparency in\nsmart device applications. Balancing privacy and utility in smart devices is\ncrucial, as youth are becoming more aware of privacy breaches and value their\npersonal data more. Strategies to improve regulatory and technical safeguards\nare also provided. The review identifies research gaps and suggests future\ndirections. The limitations of this literature review are also explained. The\nfindings have significant implications for policy development and the\ntransparency of data collection for smart devices.",
    "categories": [
      "cs.CR",
      "cs.AI",
      "cs.CY"
    ],
    "published": "2025-10-28T05:10:10Z",
    "authors": [
      "Austin Shouli",
      "Yulia Bobkova",
      "Ajay Kumar Shrestha"
    ],
    "pdf_url": "http://arxiv.org/pdf/2510.24072v1"
  },
  {
    "id": "2510.24061v1",
    "title": "FALQON: Accelerating LoRA Fine-tuning with Low-Bit Floating-Point\n  Arithmetic",
    "abstract": "Low-bit floating-point (FP) formats, such as FP8, provide significant\nacceleration and memory savings in model training thanks to native hardware\nsupport on modern GPUs and NPUs. However, we analyze that FP8 quantization\noffers speedup primarily for large-dimensional matrix multiplications, while\ninherent quantization overheads diminish speedup when applied to low-rank\nadaptation (LoRA), which uses small-dimensional matrices for efficient\nfine-tuning of large language models (LLMs). To address this limitation, we\npropose FALQON, a novel framework that eliminates the quantization overhead\nfrom separate LoRA computational paths by directly merging LoRA adapters into\nan FP8-quantized backbone during fine-tuning. Furthermore, we reformulate the\nforward and backward computations for merged adapters to significantly reduce\nquantization overhead, and introduce a row-wise proxy update mechanism that\nefficiently integrates substantial updates into the quantized backbone.\nExperimental evaluations demonstrate that FALQON achieves approximately a\n3$\\times$ training speedup over existing quantized LoRA methods with a similar\nlevel of accuracy, providing a practical solution for efficient large-scale\nmodel fine-tuning. Moreover, FALQON's end-to-end FP8 workflow removes the need\nfor post-training quantization, facilitating efficient deployment. Code is\navailable at https://github.com/iamkanghyunchoi/falqon.",
    "categories": [
      "cs.LG",
      "cs.AI"
    ],
    "published": "2025-10-28T04:44:49Z",
    "authors": [
      "Kanghyun Choi",
      "Hyeyoon Lee",
      "SunJong Park",
      "Dain Kwon",
      "Jinho Lee"
    ],
    "pdf_url": "http://arxiv.org/pdf/2510.24061v1"
  },
  {
    "id": "2510.24058v1",
    "title": "PULSE: Privileged Knowledge Transfer from Electrodermal Activity to\n  Low-Cost Sensors for Stress Monitoring",
    "abstract": "Electrodermal activity (EDA), the primary signal for stress detection,\nrequires costly hardware often unavailable in real-world wearables. In this\npaper, we propose PULSE, a framework that utilizes EDA exclusively during\nself-supervised pretraining, while enabling inference without EDA but with more\nreadily available modalities such as ECG, BVP, ACC, and TEMP. Our approach\nseparates encoder outputs into shared and private embeddings. We align shared\nembeddings across modalities and fuse them into a modality-invariant\nrepresentation. The private embeddings carry modality-specific information to\nsupport the reconstruction objective. Pretraining is followed by knowledge\ntransfer where a frozen EDA teacher transfers sympathetic-arousal\nrepresentations into student encoders. On WESAD, our method achieves strong\nstress-detection performance, showing that representations of privileged EDA\ncan be transferred to low-cost sensors to improve accuracy while reducing\nhardware cost.",
    "categories": [
      "eess.SP",
      "cs.AI",
      "cs.LG"
    ],
    "published": "2025-10-28T04:35:05Z",
    "authors": [
      "Zihan Zhao",
      "Masood Mortazavi",
      "Ning Yan"
    ],
    "pdf_url": "http://arxiv.org/pdf/2510.24058v1"
  },
  {
    "id": "2510.24052v1",
    "title": "SynAD: Enhancing Real-World End-to-End Autonomous Driving Models through\n  Synthetic Data Integration",
    "abstract": "Recent advancements in deep learning and the availability of high-quality\nreal-world driving datasets have propelled end-to-end autonomous driving.\nDespite this progress, relying solely on real-world data limits the variety of\ndriving scenarios for training. Synthetic scenario generation has emerged as a\npromising solution to enrich the diversity of training data; however, its\napplication within E2E AD models remains largely unexplored. This is primarily\ndue to the absence of a designated ego vehicle and the associated sensor\ninputs, such as camera or LiDAR, typically provided in real-world scenarios. To\naddress this gap, we introduce SynAD, the first framework designed to enhance\nreal-world E2E AD models using synthetic data. Our method designates the agent\nwith the most comprehensive driving information as the ego vehicle in a\nmulti-agent synthetic scenario. We further project path-level scenarios onto\nmaps and employ a newly developed Map-to-BEV Network to derive bird's-eye-view\nfeatures without relying on sensor inputs. Finally, we devise a training\nstrategy that effectively integrates these map-based synthetic data with real\ndriving data. Experimental results demonstrate that SynAD effectively\nintegrates all components and notably enhances safety performance. By bridging\nsynthetic scenario generation and E2E AD, SynAD paves the way for more\ncomprehensive and robust autonomous driving models.",
    "categories": [
      "cs.RO",
      "cs.AI"
    ],
    "published": "2025-10-28T04:22:02Z",
    "authors": [
      "Jongsuk Kim",
      "Jaeyoung Lee",
      "Gyojin Han",
      "Dongjae Lee",
      "Minki Jeong",
      "Junmo Kim"
    ],
    "pdf_url": "http://arxiv.org/pdf/2510.24052v1"
  },
  {
    "id": "2510.24049v1",
    "title": "Learning from History: A Retrieval-Augmented Framework for\n  Spatiotemporal Prediction",
    "abstract": "Accurate and long-term spatiotemporal prediction for complex physical systems\nremains a fundamental challenge in scientific computing. While deep learning\nmodels, as powerful parametric approximators, have shown remarkable success,\nthey suffer from a critical limitation: the accumulation of errors during\nlong-term autoregressive rollouts often leads to physically implausible\nartifacts. This deficiency arises from their purely parametric nature, which\nstruggles to capture the full constraints of a system's intrinsic dynamics. To\naddress this, we introduce a novel \\textbf{Retrieval-Augmented Prediction\n(RAP)} framework, a hybrid paradigm that synergizes the predictive power of\ndeep networks with the grounded truth of historical data. The core philosophy\nof RAP is to leverage historical evolutionary exemplars as a non-parametric\nestimate of the system's local dynamics. For any given state, RAP efficiently\nretrieves the most similar historical analog from a large-scale database. The\ntrue future evolution of this analog then serves as a \\textbf{reference\ntarget}. Critically, this target is not a hard constraint in the loss function\nbut rather a powerful conditional input to a specialized dual-stream\narchitecture. It provides strong \\textbf{dynamic guidance}, steering the\nmodel's predictions towards physically viable trajectories. In extensive\nbenchmarks across meteorology, turbulence, and fire simulation, RAP not only\nsurpasses state-of-the-art methods but also significantly outperforms a strong\n\\textbf{analog-only forecasting baseline}. More importantly, RAP generates\npredictions that are more physically realistic by effectively suppressing error\ndivergence in long-term rollouts.",
    "categories": [
      "cs.LG",
      "cs.AI"
    ],
    "published": "2025-10-28T04:09:16Z",
    "authors": [
      "Hao Jia",
      "Penghao Zhao",
      "Hao Wu",
      "Yuan Gao",
      "Yangyu Tao",
      "Bin Cui"
    ],
    "pdf_url": "http://arxiv.org/pdf/2510.24049v1"
  },
  {
    "id": "2510.24046v1",
    "title": "Causal-Aware Generative Adversarial Networks with Reinforcement Learning",
    "abstract": "The utility of tabular data for tasks ranging from model training to\nlarge-scale data analysis is often constrained by privacy concerns or\nregulatory hurdles. While existing data generation methods, particularly those\nbased on Generative Adversarial Networks (GANs), have shown promise, they\nfrequently struggle with capturing complex causal relationship, maintaining\ndata utility, and providing provable privacy guarantees suitable for enterprise\ndeployment. We introduce CA-GAN, a novel generative framework specifically\nengineered to address these challenges for real-world tabular datasets. CA-GAN\nutilizes a two-step approach: causal graph extraction to learn a robust,\ncomprehensive causal relationship in the data's manifold, followed by a custom\nConditional WGAN-GP (Wasserstein GAN with Gradient Penalty) that operates\nexclusively as per the structure of nodes in the causal graph. More\nimportantly, the generator is trained with a new Reinforcement Learning-based\nobjective that aligns the causal graphs constructed from real and fake data,\nensuring the causal awareness in both training and sampling phases. We\ndemonstrate CA-GAN superiority over six SOTA methods across 14 tabular\ndatasets. Our evaluations, focused on core data engineering metrics: causal\npreservation, utility preservation, and privacy preservation. Our method offers\na practical, high-performance solution for data engineers seeking to create\nhigh-quality, privacy-compliant synthetic datasets to benchmark database\nsystems, accelerate software development, and facilitate secure data-driven\nresearch.",
    "categories": [
      "cs.LG",
      "cs.AI"
    ],
    "published": "2025-10-28T04:02:49Z",
    "authors": [
      "Tu Anh Hoang Nguyen",
      "Dang Nguyen",
      "Tri-Nhan Vo",
      "Thuc Duy Le",
      "Sunil Gupta"
    ],
    "pdf_url": "http://arxiv.org/pdf/2510.24046v1"
  },
  {
    "id": "2510.24039v1",
    "title": "Geometric Algorithms for Neural Combinatorial Optimization with\n  Constraints",
    "abstract": "Self-Supervised Learning (SSL) for Combinatorial Optimization (CO) is an\nemerging paradigm for solving combinatorial problems using neural networks. In\nthis paper, we address a central challenge of SSL for CO: solving problems with\ndiscrete constraints. We design an end-to-end differentiable framework that\nenables us to solve discrete constrained optimization problems with neural\nnetworks. Concretely, we leverage algorithmic techniques from the literature on\nconvex geometry and Carath\\'eodory's theorem to decompose neural network\noutputs into convex combinations of polytope corners that correspond to\nfeasible sets. This decomposition-based approach enables self-supervised\ntraining but also ensures efficient quality-preserving rounding of the neural\nnet output into feasible solutions. Extensive experiments in\ncardinality-constrained optimization show that our approach can consistently\noutperform neural baselines. We further provide worked-out examples of how our\nmethod can be applied beyond cardinality-constrained problems to a diverse set\nof combinatorial optimization tasks, including finding independent sets in\ngraphs, and solving matroid-constrained problems.",
    "categories": [
      "cs.LG",
      "cs.AI"
    ],
    "published": "2025-10-28T03:49:01Z",
    "authors": [
      "Nikolaos Karalias",
      "Akbar Rafiey",
      "Yifei Xu",
      "Zhishang Luo",
      "Behrooz Tahmasebi",
      "Connie Jiang",
      "Stefanie Jegelka"
    ],
    "pdf_url": "http://arxiv.org/pdf/2510.24039v1"
  },
  {
    "id": "2510.24036v1",
    "title": "ResNet: Enabling Deep Convolutional Neural Networks through Residual\n  Learning",
    "abstract": "Convolutional Neural Networks (CNNs) has revolutionized computer vision, but\ntraining very deep networks has been challenging due to the vanishing gradient\nproblem. This paper explores Residual Networks (ResNet), introduced by He et\nal. (2015), which overcomes this limitation by using skip connections. ResNet\nenables the training of networks with hundreds of layers by allowing gradients\nto flow directly through shortcut connections that bypass intermediate layers.\nIn our implementation on the CIFAR-10 dataset, ResNet-18 achieves 89.9%\naccuracy compared to 84.1% for a traditional deep CNN of similar depth, while\nalso converging faster and training more stably.",
    "categories": [
      "cs.CV",
      "cs.AI"
    ],
    "published": "2025-10-28T03:36:15Z",
    "authors": [
      "Xingyu Liu",
      "Kun Ming Goh"
    ],
    "pdf_url": "http://arxiv.org/pdf/2510.24036v1"
  },
  {
    "id": "2510.24031v1",
    "title": "LLMLogAnalyzer: A Clustering-Based Log Analysis Chatbot using Large\n  Language Models",
    "abstract": "System logs are a cornerstone of cybersecurity, supporting proactive breach\nprevention and post-incident investigations. However, analyzing vast amounts of\ndiverse log data remains significantly challenging, as high costs, lack of\nin-house expertise, and time constraints make even basic analysis difficult for\nmany organizations. This study introduces LLMLogAnalyzer, a clustering-based\nlog analysis chatbot that leverages Large Language Models (LLMs) and Machine\nLearning (ML) algorithms to simplify and streamline log analysis processes.\nThis innovative approach addresses key LLM limitations, including context\nwindow constraints and poor structured text handling capabilities, enabling\nmore effective summarization, pattern extraction, and anomaly detection tasks.\nLLMLogAnalyzer is evaluated across four distinct domain logs and various tasks.\nResults demonstrate significant performance improvements over state-of-the-art\nLLM-based chatbots, including ChatGPT, ChatPDF, and NotebookLM, with consistent\ngains ranging from 39% to 68% across different tasks. The system also exhibits\nstrong robustness, achieving a 93% reduction in interquartile range (IQR) when\nusing ROUGE-1 scores, indicating significantly lower result variability. The\nframework's effectiveness stems from its modular architecture comprising a\nrouter, log recognizer, log parser, and search tools. This design enhances LLM\ncapabilities for structured text analysis while improving accuracy and\nrobustness, making it a valuable resource for both cybersecurity experts and\nnon-technical users.",
    "categories": [
      "cs.AI",
      "cs.CR",
      "H.3.3, I.2.7, I.5.3, I.2.5,"
    ],
    "published": "2025-10-28T03:29:55Z",
    "authors": [
      "Peng Cai",
      "Reza Ryan",
      "Nickson M. Karie"
    ],
    "pdf_url": "http://arxiv.org/pdf/2510.24031v1"
  },
  {
    "id": "2510.24029v1",
    "title": "Improved Accuracy of Robot Localization Using 3-D LiDAR in a\n  Hippocampus-Inspired Model",
    "abstract": "Boundary Vector Cells (BVCs) are a class of neurons in the brains of\nvertebrates that encode environmental boundaries at specific distances and\nallocentric directions, playing a central role in forming place fields in the\nhippocampus. Most computational BVC models are restricted to two-dimensional\n(2D) environments, making them prone to spatial ambiguities in the presence of\nhorizontal symmetries in the environment. To address this limitation, we\nincorporate vertical angular sensitivity into the BVC framework, thereby\nenabling robust boundary detection in three dimensions, and leading to\nsignificantly more accurate spatial localization in a biologically-inspired\nrobot model.\n  The proposed model processes LiDAR data to capture vertical contours, thereby\ndisambiguating locations that would be indistinguishable under a purely 2D\nrepresentation. Experimental results show that in environments with minimal\nvertical variation, the proposed 3D model matches the performance of a 2D\nbaseline; yet, as 3D complexity increases, it yields substantially more\ndistinct place fields and markedly reduces spatial aliasing. These findings\nshow that adding a vertical dimension to BVC-based localization can\nsignificantly enhance navigation and mapping in real-world 3D spaces while\nretaining performance parity in simpler, near-planar scenarios.",
    "categories": [
      "cs.RO",
      "cs.AI",
      "cs.LG",
      "cs.SY",
      "eess.SY",
      "q-bio.NC",
      "I.2.9; I.2.6"
    ],
    "published": "2025-10-28T03:24:02Z",
    "authors": [
      "Andrew Gerstenslager",
      "Bekarys Dukenbaev",
      "Ali A. Minai"
    ],
    "pdf_url": "http://arxiv.org/pdf/2510.24029v1"
  },
  {
    "id": "2510.24028v1",
    "title": "OneCast: Structured Decomposition and Modular Generation for\n  Cross-Domain Time Series Forecasting",
    "abstract": "Cross-domain time series forecasting is a valuable task in various web\napplications. Despite its rapid advancement, achieving effective generalization\nacross heterogeneous time series data remains a significant challenge. Existing\nmethods have made progress by extending single-domain models, yet often fall\nshort when facing domain-specific trend shifts and inconsistent periodic\npatterns. We argue that a key limitation lies in treating temporal series as\nundifferentiated sequence, without explicitly decoupling their inherent\nstructural components. To address this, we propose OneCast, a structured and\nmodular forecasting framework that decomposes time series into seasonal and\ntrend components, each modeled through tailored generative pathways.\nSpecifically, the seasonal component is captured by a lightweight projection\nmodule that reconstructs periodic patterns via interpretable basis functions.\nIn parallel, the trend component is encoded into discrete tokens at segment\nlevel via a semantic-aware tokenizer, and subsequently inferred through a\nmasked discrete diffusion mechanism. The outputs from both branches are\ncombined to produce a final forecast that captures seasonal patterns while\ntracking domain-specific trends. Extensive experiments across eight domains\ndemonstrate that OneCast mostly outperforms state-of-the-art baselines.",
    "categories": [
      "cs.AI"
    ],
    "published": "2025-10-28T03:23:53Z",
    "authors": [
      "Tingyue Pan",
      "Mingyue Cheng",
      "Shilong Zhang",
      "Zhiding Liu",
      "Xiaoyu Tao",
      "Yucong Luo",
      "Jintao Zhang",
      "Qi Liu"
    ],
    "pdf_url": "http://arxiv.org/pdf/2510.24028v1"
  },
  {
    "id": "2510.24027v1",
    "title": "Spatio-temporal Multivariate Time Series Forecast with Chosen Variables",
    "abstract": "Spatio-Temporal Multivariate time series Forecast (STMF) uses the time series\nof $n$ spatially distributed variables in a period of recent past to forecast\ntheir values in a period of near future. It has important applications in\nspatio-temporal sensing forecast such as road traffic prediction and air\npollution prediction. Recent papers have addressed a practical problem of\nmissing variables in the model input, which arises in the sensing applications\nwhere the number $m$ of sensors is far less than the number $n$ of locations to\nbe monitored, due to budget constraints. We observe that the state of the art\nassumes that the $m$ variables (i.e., locations with sensors) in the model\ninput are pre-determined and the important problem of how to choose the $m$\nvariables in the input has never been studied. This paper fills the gap by\nstudying a new problem of STMF with chosen variables, which optimally selects\n$m$-out-of-$n$ variables for the model input in order to maximize the forecast\naccuracy. We propose a unified framework that jointly performs variable\nselection and model optimization for both forecast accuracy and model\nefficiency. It consists of three novel technical components: (1) masked\nvariable-parameter pruning, which progressively prunes less informative\nvariables and attention parameters through quantile-based masking; (2)\nprioritized variable-parameter replay, which replays low-loss past samples to\npreserve learned knowledge for model stability; (3) dynamic extrapolation\nmechanism, which propagates information from variables selected for the input\nto all other variables via learnable spatial embeddings and adjacency\ninformation. Experiments on five real-world datasets show that our work\nsignificantly outperforms the state-of-the-art baselines in both accuracy and\nefficiency, demonstrating the effectiveness of joint variable selection and\nmodel optimization.",
    "categories": [
      "cs.LG",
      "cs.AI"
    ],
    "published": "2025-10-28T03:19:06Z",
    "authors": [
      "Zibo Liu",
      "Zhe Jiang",
      "Zelin Xu",
      "Tingsong Xiao",
      "Yupu Zhang",
      "Zhengkun Xiao",
      "Haibo Wang",
      "Shigang Chen"
    ],
    "pdf_url": "http://arxiv.org/pdf/2510.24027v1"
  },
  {
    "id": "2510.24025v2",
    "title": "NeuroPathNet: Dynamic Path Trajectory Learning for Brain Functional\n  Connectivity Analysis",
    "abstract": "Understanding the evolution of brain functional networks over time is of\ngreat significance for the analysis of cognitive mechanisms and the diagnosis\nof neurological diseases. Existing methods often have difficulty in capturing\nthe temporal evolution characteristics of connections between specific\nfunctional communities. To this end, this paper proposes a new path-level\ntrajectory modeling framework (NeuroPathNet) to characterize the dynamic\nbehavior of connection pathways between brain functional partitions. Based on\nmedically supported static partitioning schemes (such as Yeo and Smith ICA), we\nextract the time series of connection strengths between each pair of functional\npartitions and model them using a temporal neural network. We validate the\nmodel performance on three public functional Magnetic Resonance Imaging (fMRI)\ndatasets, and the results show that it outperforms existing mainstream methods\nin multiple indicators. This study can promote the development of dynamic graph\nlearning methods for brain network analysis, and provide possible clinical\napplications for the diagnosis of neurological diseases.",
    "categories": [
      "cs.LG",
      "cs.AI"
    ],
    "published": "2025-10-28T03:07:06Z",
    "authors": [
      "Tianqi Guo",
      "Liping Chen",
      "Ciyuan Peng",
      "Jingjing Zhou",
      "Jing Ren"
    ],
    "pdf_url": "http://arxiv.org/pdf/2510.24025v2"
  },
  {
    "id": "2510.25781v1",
    "title": "A Practitioner's Guide to Kolmogorov-Arnold Networks",
    "abstract": "Kolmogorov-Arnold Networks (KANs) have recently emerged as a promising\nalternative to traditional Multilayer Perceptrons (MLPs), inspired by the\nKolmogorov-Arnold representation theorem. Unlike MLPs, which use fixed\nactivation functions on nodes, KANs employ learnable univariate basis functions\non edges, offering enhanced expressivity and interpretability. This review\nprovides a systematic and comprehensive overview of the rapidly expanding KAN\nlandscape, moving beyond simple performance comparisons to offer a structured\nsynthesis of theoretical foundations, architectural variants, and practical\nimplementation strategies. By collecting and categorizing a vast array of\nopen-source implementations, we map the vibrant ecosystem supporting KAN\ndevelopment. We begin by bridging the conceptual gap between KANs and MLPs,\nestablishing their formal equivalence and highlighting the superior parameter\nefficiency of the KAN formulation. A central theme of our review is the\ncritical role of the basis function; we survey a wide array of choices,\nincluding B-splines, Chebyshev and Jacobi polynomials, ReLU compositions,\nGaussian RBFs, and Fourier series, and analyze their respective trade-offs in\nterms of smoothness, locality, and computational cost. We then categorize\nrecent advancements into a clear roadmap, covering techniques for improving\naccuracy, efficiency, and regularization. Key topics include physics-informed\nloss design, adaptive sampling, domain decomposition, hybrid architectures, and\nspecialized methods for handling discontinuities. Finally, we provide a\npractical \"Choose-Your-KAN\" guide to help practitioners select appropriate\narchitectures, and we conclude by identifying current research gaps. The\nassociated GitHub repository https://github.com/AmirNoori68/kan-review\ncomplements this paper and serves as a structured reference for ongoing KAN\nresearch.",
    "categories": [
      "cs.LG",
      "cs.AI",
      "cs.NA",
      "cs.NE",
      "math.NA"
    ],
    "published": "2025-10-28T03:03:44Z",
    "authors": [
      "Amir Noorizadegan",
      "Sifan Wang",
      "Leevan Ling"
    ],
    "pdf_url": "http://arxiv.org/pdf/2510.25781v1"
  },
  {
    "id": "2510.24021v1",
    "title": "SpecKD: Speculative Decoding for Effective Knowledge Distillation of\n  LLMs",
    "abstract": "Knowledge Distillation (KD) has become a cornerstone technique for\ncompressing Large Language Models (LLMs) into smaller, more efficient student\nmodels. However, conventional KD approaches typically apply the distillation\nloss uniformly across all tokens, regardless of the teacher's confidence. This\nindiscriminate mimicry can introduce noise, as the student is forced to learn\nfrom the teacher's uncertain or high-entropy predictions, which may ultimately\nharm student performance-especially when the teacher is much larger and more\npowerful. To address this, we propose Speculative Knowledge Distillation\n(SpecKD), a novel, plug-and-play framework that introduces a dynamic,\ntoken-level gating mechanism inspired by the \"propose-and-verify\" paradigm of\nspeculative decoding. At each step, the student's token proposal is verified\nagainst the teacher's distribution; the distillation loss is selectively\napplied only to \"accepted\" tokens, while \"rejected\" tokens are masked out.\nExtensive experiments on diverse text generation tasks show that SpecKD\nconsistently and significantly outperforms strong KD baselines, leading to more\nstable training and more capable student models, and achieving state-of-the-art\nresults.",
    "categories": [
      "cs.CL",
      "cs.AI"
    ],
    "published": "2025-10-28T03:02:22Z",
    "authors": [
      "Haiduo Huang",
      "Jiangcheng Song",
      "Yadong Zhang",
      "Pengju Ren"
    ],
    "pdf_url": "http://arxiv.org/pdf/2510.24021v1"
  },
  {
    "id": "2510.24020v1",
    "title": "Teaching LLMs to Abstain via Fine-Grained Semantic Confidence Reward",
    "abstract": "Mitigating hallucinations in Large Language Models (LLMs) is critical for\ntheir reliable deployment. Existing methods typically fine-tune LLMs to abstain\nfrom answering questions beyond their knowledge scope. However, these methods\noften rely on coarse-grained signals to guide LLMs to abstain, such as overall\nconfidence or uncertainty scores on multiple sampled answers, which may result\nin an imprecise awareness of the model's own knowledge boundaries. To this end,\nwe propose a novel reinforcement learning framework built on\n$\\textbf{\\underline{Fi}ne-grained \\underline{S}emantic \\underline{Co}nfidence\n\\underline{Re}ward (\\Ours)}$, which guides LLMs to abstain via sample-specific\nconfidence. Specifically, our method operates by sampling multiple candidate\nanswers and conducting semantic clustering, then training the LLM to retain\nanswers within high-confidence clusters and discard those within low-confidence\nones, thereby promoting accurate post-hoc abstention. Additionally, we propose\na new metric for evaluating the reliability of abstention fine-tuning tasks\nmore comprehensively. Our method significantly enhances reliability in both\nin-domain and out-of-distribution benchmarks.",
    "categories": [
      "cs.CL",
      "cs.AI"
    ],
    "published": "2025-10-28T03:00:35Z",
    "authors": [
      "Hao An",
      "Yang Xu"
    ],
    "pdf_url": "http://arxiv.org/pdf/2510.24020v1"
  },
  {
    "id": "2510.24019v1",
    "title": "Lifecycle-Aware code generation: Leveraging Software Engineering Phases\n  in LLMs",
    "abstract": "Recent progress in large language models (LLMs) has advanced automatic code\ngeneration, yet most approaches rely on direct, single-step translation from\nproblem descriptions to code, disregarding structured software engineering\npractices. We introduce a lifecycle-aware framework that systematically\nincorporates intermediate artifacts such as requirements analysis, state\nmachine modeling, and pseudocode into both the training and inference stages.\nThis design aligns code generation with standard software development phases\nand enables more structured reasoning. Experiments show that lifecycle-level\nfine-tuning improves code correctness by up to 75% over the same model before\nfine-tuning, with performance gains compounding across intermediate stages.\nMulti-step inference consistently surpasses single-step generation,\ndemonstrating the effectiveness of intermediate scaffolding. Notably,\nopen-source LLMs, once fine-tuned under our framework, match or slightly\noutperform models pretrained on code. When applied to DeepSeek-Coder-1.3B, our\nframework yields relative CodeBLEU improvements of 34.3%, 20.0%, 11.2%, and\n22.3% over ChatGPT-3.5, ChatGPT-4o-mini, DeepSeek-R1, and LLaMA-8B,\nrespectively. Our pipeline also proves robust with up to 80\\% less training\ndata, confirming its resilience. Ablation studies further reveal that each\nintermediate artifact contributes distinctly to final code quality, with state\nmachine modeling yielding the most substantial impact. Our source code and\ndetailed experimental data are available at\nhttps://anonymous.4open.science/r/Lifecycle-Aware-3CCB.",
    "categories": [
      "cs.SE",
      "cs.AI"
    ],
    "published": "2025-10-28T02:54:02Z",
    "authors": [
      "Xing Xing",
      "Wei Wang",
      "Lipeng Ma",
      "Weidong Yang",
      "Junjie Zheng"
    ],
    "pdf_url": "http://arxiv.org/pdf/2510.24019v1"
  },
  {
    "id": "2510.24013v1",
    "title": "Discovering Heuristics with Large Language Models (LLMs) for\n  Mixed-Integer Programs: Single-Machine Scheduling",
    "abstract": "Our study contributes to the scheduling and combinatorial optimization\nliterature with new heuristics discovered by leveraging the power of Large\nLanguage Models (LLMs). We focus on the single-machine total tardiness (SMTT)\nproblem, which aims to minimize total tardiness by sequencing n jobs on a\nsingle processor without preemption, given processing times and due dates. We\ndevelop and benchmark two novel LLM-discovered heuristics, the EDD Challenger\n(EDDC) and MDD Challenger (MDDC), inspired by the well-known Earliest Due Date\n(EDD) and Modified Due Date (MDD) rules. In contrast to prior studies that\nemployed simpler rule-based heuristics, we evaluate our LLM-discovered\nalgorithms using rigorous criteria, including optimality gaps and solution time\nderived from a mixed-integer programming (MIP) formulation of SMTT. We compare\ntheir performance against state-of-the-art heuristics and exact methods across\nvarious job sizes (20, 100, 200, and 500 jobs). For instances with more than\n100 jobs, exact methods such as MIP and dynamic programming become\ncomputationally intractable. Up to 500 jobs, EDDC improves upon the classic EDD\nrule and another widely used algorithm in the literature. MDDC consistently\noutperforms traditional heuristics and remains competitive with exact\napproaches, particularly on larger and more complex instances. This study shows\nthat human-LLM collaboration can produce scalable, high-performing heuristics\nfor NP-hard constrained combinatorial optimization, even under limited\nresources when effectively configured.",
    "categories": [
      "cs.AI",
      "cs.LG",
      "cs.NE",
      "math.CO",
      "math.OC"
    ],
    "published": "2025-10-28T02:43:04Z",
    "authors": [
      "\u0130brahim O\u011fuz \u00c7etinkaya",
      "\u0130. Esra B\u00fcy\u00fcktahtak\u0131n",
      "Parshin Shojaee",
      "Chandan K. Reddy"
    ],
    "pdf_url": "http://arxiv.org/pdf/2510.24013v1"
  },
  {
    "id": "2510.24012v1",
    "title": "Training-Free Safe Text Embedding Guidance for Text-to-Image Diffusion\n  Models",
    "abstract": "Text-to-image models have recently made significant advances in generating\nrealistic and semantically coherent images, driven by advanced diffusion models\nand large-scale web-crawled datasets. However, these datasets often contain\ninappropriate or biased content, raising concerns about the generation of\nharmful outputs when provided with malicious text prompts. We propose Safe Text\nembedding Guidance (STG), a training-free approach to improve the safety of\ndiffusion models by guiding the text embeddings during sampling. STG adjusts\nthe text embeddings based on a safety function evaluated on the expected final\ndenoised image, allowing the model to generate safer outputs without additional\ntraining. Theoretically, we show that STG aligns the underlying model\ndistribution with safety constraints, thereby achieving safer outputs while\nminimally affecting generation quality. Experiments on various safety\nscenarios, including nudity, violence, and artist-style removal, show that STG\nconsistently outperforms both training-based and training-free baselines in\nremoving unsafe content while preserving the core semantic intent of input\nprompts. Our code is available at https://github.com/aailab-kaist/STG.",
    "categories": [
      "cs.LG",
      "cs.AI"
    ],
    "published": "2025-10-28T02:37:20Z",
    "authors": [
      "Byeonghu Na",
      "Mina Kang",
      "Jiseok Kwak",
      "Minsang Park",
      "Jiwoo Shin",
      "SeJoon Jun",
      "Gayoung Lee",
      "Jin-Hwa Kim",
      "Il-Chul Moon"
    ],
    "pdf_url": "http://arxiv.org/pdf/2510.24012v1"
  },
  {
    "id": "2510.24010v1",
    "title": "Mars-Bench: A Benchmark for Evaluating Foundation Models for Mars\n  Science Tasks",
    "abstract": "Foundation models have enabled rapid progress across many specialized domains\nby leveraging large-scale pre-training on unlabeled data, demonstrating strong\ngeneralization to a variety of downstream tasks. While such models have gained\nsignificant attention in fields like Earth Observation, their application to\nMars science remains limited. A key enabler of progress in other domains has\nbeen the availability of standardized benchmarks that support systematic\nevaluation. In contrast, Mars science lacks such benchmarks and standardized\nevaluation frameworks, which have limited progress toward developing foundation\nmodels for Martian tasks. To address this gap, we introduce Mars-Bench, the\nfirst benchmark designed to systematically evaluate models across a broad range\nof Mars-related tasks using both orbital and surface imagery. Mars-Bench\ncomprises 20 datasets spanning classification, segmentation, and object\ndetection, focused on key geologic features such as craters, cones, boulders,\nand frost. We provide standardized, ready-to-use datasets and baseline\nevaluations using models pre-trained on natural images, Earth satellite data,\nand state-of-the-art vision-language models. Results from all analyses suggest\nthat Mars-specific foundation models may offer advantages over general-domain\ncounterparts, motivating further exploration of domain-adapted pre-training.\nMars-Bench aims to establish a standardized foundation for developing and\ncomparing machine learning models for Mars science. Our data, models, and code\nare available at: https://mars-bench.github.io/.",
    "categories": [
      "cs.CV",
      "cs.AI",
      "cs.LG"
    ],
    "published": "2025-10-28T02:34:08Z",
    "authors": [
      "Mirali Purohit",
      "Bimal Gajera",
      "Vatsal Malaviya",
      "Irish Mehta",
      "Kunal Kasodekar",
      "Jacob Adler",
      "Steven Lu",
      "Umaa Rebbapragada",
      "Hannah Kerner"
    ],
    "pdf_url": "http://arxiv.org/pdf/2510.24010v1"
  },
  {
    "id": "2510.23989v1",
    "title": "Learning Individual Movement Shifts After Urban Disruptions with Social\n  Infrastructure Reliance",
    "abstract": "Shifts in individual movement patterns following disruptive events can reveal\nchanging demands for community resources. However, predicting such shifts\nbefore disruptive events remains challenging for several reasons. First,\nmeasures are lacking for individuals' heterogeneous social infrastructure\nresilience (SIR), which directly influences their movement patterns, and\ncommonly used features are often limited or unavailable at scale, e.g.,\nsociodemographic characteristics. Second, the complex interactions between\nindividual movement patterns and spatial contexts have not been sufficiently\ncaptured. Third, individual-level movement may be spatially sparse and not\nwell-suited to traditional decision-making methods for movement predictions.\nThis study incorporates individuals' SIR into a conditioned deep learning model\nto capture the complex relationships between individual movement patterns and\nlocal spatial context using large-scale, sparse individual-level data. Our\nexperiments demonstrate that incorporating individuals' SIR and spatial context\ncan enhance the model's ability to predict post-event individual movement\npatterns. The conditioned model can capture the divergent shifts in movement\npatterns among individuals who exhibit similar pre-event patterns but differ in\nSIR.",
    "categories": [
      "cs.AI"
    ],
    "published": "2025-10-28T01:44:55Z",
    "authors": [
      "Shangde Gao",
      "Zelin Xu",
      "Zhe Jiang"
    ],
    "pdf_url": "http://arxiv.org/pdf/2510.23989v1"
  },
  {
    "id": "2510.23986v1",
    "title": "STNet: Spectral Transformation Network for Solving Operator Eigenvalue\n  Problem",
    "abstract": "Operator eigenvalue problems play a critical role in various scientific\nfields and engineering applications, yet numerical methods are hindered by the\ncurse of dimensionality. Recent deep learning methods provide an efficient\napproach to address this challenge by iteratively updating neural networks.\nThese methods' performance relies heavily on the spectral distribution of the\ngiven operator: larger gaps between the operator's eigenvalues will improve\nprecision, thus tailored spectral transformations that leverage the spectral\ndistribution can enhance their performance. Based on this observation, we\npropose the Spectral Transformation Network (STNet). During each iteration,\nSTNet uses approximate eigenvalues and eigenfunctions to perform spectral\ntransformations on the original operator, turning it into an equivalent but\neasier problem. Specifically, we employ deflation projection to exclude the\nsubspace corresponding to already solved eigenfunctions, thereby reducing the\nsearch space and avoiding converging to existing eigenfunctions. Additionally,\nour filter transform magnifies eigenvalues in the desired region and suppresses\nthose outside, further improving performance. Extensive experiments demonstrate\nthat STNet consistently outperforms existing learning-based methods, achieving\nstate-of-the-art performance in accuracy.",
    "categories": [
      "cs.LG",
      "cs.AI",
      "cs.NA",
      "math.NA"
    ],
    "published": "2025-10-28T01:43:54Z",
    "authors": [
      "Hong Wang",
      "Jiang Yixuan",
      "Jie Wang",
      "Xinyi Li",
      "Jian Luo",
      "Huanshuo Dong"
    ],
    "pdf_url": "http://arxiv.org/pdf/2510.23986v1"
  },
  {
    "id": "2510.23980v1",
    "title": "HyperGraphX: Graph Transductive Learning with Hyperdimensional Computing\n  and Message Passing",
    "abstract": "We present a novel algorithm, \\hdgc, that marries graph convolution with\nbinding and bundling operations in hyperdimensional computing for transductive\ngraph learning. For prediction accuracy \\hdgc outperforms major and popular\ngraph neural network implementations as well as state-of-the-art\nhyperdimensional computing implementations for a collection of homophilic\ngraphs and heterophilic graphs. Compared with the most accurate learning\nmethodologies we have tested, on the same target GPU platform, \\hdgc is on\naverage 9561.0 and 144.5 times faster than \\gcnii, a graph neural network\nimplementation and HDGL, a hyperdimensional computing implementation,\nrespectively. As the majority of the learning operates on binary vectors, we\nexpect outstanding energy performance of \\hdgc on neuromorphic and emerging\nprocess-in-memory devices.",
    "categories": [
      "cs.LG",
      "cs.AI",
      "cs.NE"
    ],
    "published": "2025-10-28T01:21:54Z",
    "authors": [
      "Guojing Cong",
      "Tom Potok",
      "Hamed Poursiami",
      "Maryam Parsa"
    ],
    "pdf_url": "http://arxiv.org/pdf/2510.23980v1"
  },
  {
    "id": "2510.24805v1",
    "title": "CT-Less Attenuation Correction Using Multiview Ensemble Conditional\n  Diffusion Model on High-Resolution Uncorrected PET Images",
    "abstract": "Accurate quantification in positron emission tomography (PET) is essential\nfor accurate diagnostic results and effective treatment tracking. A major issue\nencountered in PET imaging is attenuation. Attenuation refers to the diminution\nof photon detected as they traverse biological tissues before reaching\ndetectors. When such corrections are absent or inadequate, this signal\ndegradation can introduce inaccurate quantification, making it difficult to\ndifferentiate benign from malignant conditions, and can potentially lead to\nmisdiagnosis. Typically, this correction is done with co-computed Computed\nTomography (CT) imaging to obtain structural data for calculating photon\nattenuation across the body. However, this methodology subjects patients to\nextra ionizing radiation exposure, suffers from potential spatial\nmisregistration between PET/CT imaging sequences, and demands costly equipment\ninfrastructure. Emerging advances in neural network architectures present an\nalternative approach via synthetic CT image synthesis. Our investigation\nreveals that Conditional Denoising Diffusion Probabilistic Models (DDPMs) can\ngenerate high quality CT images from non attenuation corrected PET images in\norder to correct attenuation. By utilizing all three orthogonal views from\nnon-attenuation-corrected PET images, the DDPM approach combined with ensemble\nvoting generates higher quality pseudo-CT images with reduced artifacts and\nimproved slice-to-slice consistency. Results from a study of 159 head scans\nacquired with the Siemens Biograph Vision PET/CT scanner demonstrate both\nqualitative and quantitative improvements in pseudo-CT generation. The method\nachieved a mean absolute error of 32 $\\pm$ 10.4 HU on the CT images and an\naverage error of (1.48 $\\pm$ 0.68)\\% across all regions of interest when\ncomparing PET images reconstructed using the attenuation map of the generated\npseudo-CT versus the true CT.",
    "categories": [
      "q-bio.QM",
      "cs.AI",
      "cs.CV"
    ],
    "published": "2025-10-28T01:18:35Z",
    "authors": [
      "Alexandre St-Georges",
      "Gabriel Richard",
      "Maxime Toussaint",
      "Christian Thibaudeau",
      "Etienne Auger",
      "\u00c9tienne Croteau",
      "Stephen Cunnane",
      "Roger Lecomte",
      "Jean-Baptiste Michaud"
    ],
    "pdf_url": "http://arxiv.org/pdf/2510.24805v1"
  },
  {
    "id": "2510.23974v1",
    "title": "Diffusion Adaptive Text Embedding for Text-to-Image Diffusion Models",
    "abstract": "Text-to-image diffusion models rely on text embeddings from a pre-trained\ntext encoder, but these embeddings remain fixed across all diffusion timesteps,\nlimiting their adaptability to the generative process. We propose Diffusion\nAdaptive Text Embedding (DATE), which dynamically updates text embeddings at\neach diffusion timestep based on intermediate perturbed data. We formulate an\noptimization problem and derive an update rule that refines the text embeddings\nat each sampling step to improve alignment and preference between the mean\npredicted image and the text. This allows DATE to dynamically adapts the text\nconditions to the reverse-diffused images throughout diffusion sampling without\nrequiring additional model training. Through theoretical analysis and empirical\nresults, we show that DATE maintains the generative capability of the model\nwhile providing superior text-image alignment over fixed text embeddings across\nvarious tasks, including multi-concept generation and text-guided image\nediting. Our code is available at https://github.com/aailab-kaist/DATE.",
    "categories": [
      "cs.LG",
      "cs.AI"
    ],
    "published": "2025-10-28T01:10:15Z",
    "authors": [
      "Byeonghu Na",
      "Minsang Park",
      "Gyuwon Sim",
      "Donghyeok Shin",
      "HeeSun Bae",
      "Mina Kang",
      "Se Jung Kwon",
      "Wanmo Kang",
      "Il-Chul Moon"
    ],
    "pdf_url": "http://arxiv.org/pdf/2510.23974v1"
  },
  {
    "id": "2510.23972v1",
    "title": "An efficient probabilistic hardware architecture for diffusion-like\n  models",
    "abstract": "The proliferation of probabilistic AI has promoted proposals for specialized\nstochastic computers. Despite promising efficiency gains, these proposals have\nfailed to gain traction because they rely on fundamentally limited modeling\ntechniques and exotic, unscalable hardware. In this work, we address these\nshortcomings by proposing an all-transistor probabilistic computer that\nimplements powerful denoising models at the hardware level. A system-level\nanalysis indicates that devices based on our architecture could achieve\nperformance parity with GPUs on a simple image benchmark using approximately\n10,000 times less energy.",
    "categories": [
      "cs.LG",
      "cs.AI"
    ],
    "published": "2025-10-28T01:09:19Z",
    "authors": [
      "Andra\u017e Jelin\u010di\u010d",
      "Owen Lockwood",
      "Akhil Garlapati",
      "Guillaume Verdon",
      "Trevor McCourt"
    ],
    "pdf_url": "http://arxiv.org/pdf/2510.23972v1"
  },
  {
    "id": "2510.24803v1",
    "title": "MASPRM: Multi-Agent System Process Reward Model",
    "abstract": "Practical deployment of Multi-Agent Systems (MAS) demands strong test-time\nperformance, motivating methods that guide inference-time search and\nselectively spend compute to improve quality. We present the Multi-Agent System\nProcess Reward Model (MASPRM). It assigns per-action, per-agent values to\npartial inter-agent transcripts and acts as an inference-time controller.\nMASPRM is trained from multi-agent Monte Carlo Tree Search (MCTS) rollouts\nwithout requiring step-level human annotations, by propagating returns to local\ntargets. At inference, MASPRM guides step-level beam search and MCTS, focusing\ncomputation on promising branches and pruning early. On GSM8K and MATH,\nMASPRM-guided decoding with an outcome reward model (ORM) applied to the final\nanswer, improves exact match (EM) over a single straight-through MAS pass by\n$+30.7$ and $+22.9$ points, respectively. A MASPRM trained on GSM8K transfers\nzero-shot to MATH without retraining, adding $8.4$ EM points at the same\nbudget. MASPRM is a plug-in value model that estimates per-agent progress and\ncomplements verifier-style decoders, enabling more reliable, compute-aware\nmulti-agent reasoning. Code: https://github.com/milad1378yz/MASPRM",
    "categories": [
      "cs.MA",
      "cs.AI"
    ],
    "published": "2025-10-28T00:48:20Z",
    "authors": [
      "Milad Yazdani",
      "Mahdi Mostajabdaveh",
      "Zirui Zhou",
      "Ying Xiong"
    ],
    "pdf_url": "http://arxiv.org/pdf/2510.24803v1"
  },
  {
    "id": "2510.23965v2",
    "title": "The Sign Estimator: LLM Alignment in the Face of Choice Heterogeneity",
    "abstract": "Traditional LLM alignment methods are vulnerable to heterogeneity in human\npreferences. Fitting a na\\\"ive probabilistic model to pairwise comparison data\n(say over prompt-completion pairs) yields an inconsistent estimate of the\npopulation-average utility -a canonical measure of social welfare. We propose a\nnew method, dubbed the sign estimator, that provides a simple, provably\nconsistent, and efficient estimator by replacing cross-entropy with binary\nclassification loss in the aggregation step. This simple modification recovers\nconsistent ordinal alignment under mild assumptions and achieves the first\npolynomial finite-sample error bounds in this setting. In realistic simulations\nof LLM alignment using digital twins, the sign estimator substantially reduces\npreference distortion over a panel of simulated personas, cutting (angular)\nestimation error by nearly 35% and decreasing disagreement with true population\npreferences from 12% to 8% compared to standard RLHF. Our method also compares\nfavorably to panel data heuristics that explicitly model user heterogeneity and\nrequire tracking individual-level preference data-all while maintaining the\nimplementation simplicity of existing LLM alignment pipelines.",
    "categories": [
      "cs.AI",
      "cs.LG",
      "stat.ML"
    ],
    "published": "2025-10-28T00:42:38Z",
    "authors": [
      "Ali Aouad",
      "Aymane El Gadarri",
      "Vivek F. Farias"
    ],
    "pdf_url": "http://arxiv.org/pdf/2510.23965v2"
  },
  {
    "id": "2510.23960v1",
    "title": "SafeVision: Efficient Image Guardrail with Robust Policy Adherence and\n  Explainability",
    "abstract": "With the rapid proliferation of digital media, the need for efficient and\ntransparent safeguards against unsafe content is more critical than ever.\nTraditional image guardrail models, constrained by predefined categories, often\nmisclassify content due to their pure feature-based learning without semantic\nreasoning. Moreover, these models struggle to adapt to emerging threats,\nrequiring costly retraining for new threats. To address these limitations, we\nintroduce SafeVision, a novel image guardrail that integrates human-like\nreasoning to enhance adaptability and transparency. Our approach incorporates\nan effective data collection and generation framework, a policy-following\ntraining pipeline, and a customized loss function. We also propose a diverse QA\ngeneration and training strategy to enhance learning effectiveness. SafeVision\ndynamically aligns with evolving safety policies at inference time, eliminating\nthe need for retraining while ensuring precise risk assessments and\nexplanations. Recognizing the limitations of existing unsafe image benchmarks,\nwhich either lack granularity or cover limited risks, we introduce VisionHarm,\na high-quality dataset comprising two subsets: VisionHarm Third-party\n(VisionHarm-T) and VisionHarm Comprehensive(VisionHarm-C), spanning diverse\nharmful categories. Through extensive experiments, we show that SafeVision\nachieves state-of-the-art performance on different benchmarks. SafeVision\noutperforms GPT-4o by 8.6% on VisionHarm-T and by 15.5% on VisionHarm-C, while\nbeing over 16x faster. SafeVision sets a comprehensive, policy-following, and\nexplainable image guardrail with dynamic adaptation to emerging threats.",
    "categories": [
      "cs.CV",
      "cs.AI",
      "cs.CR"
    ],
    "published": "2025-10-28T00:35:59Z",
    "authors": [
      "Peiyang Xu",
      "Minzhou Pan",
      "Zhaorun Chen",
      "Shuang Yang",
      "Chaowei Xiao",
      "Bo Li"
    ],
    "pdf_url": "http://arxiv.org/pdf/2510.23960v1"
  },
  {
    "id": "2510.24802v1",
    "title": "From Narrative to Action: A Hierarchical LLM-Agent Framework for Human\n  Mobility Generation",
    "abstract": "Understanding and replicating human mobility requires not only\nspatial-temporal accuracy but also an awareness of the cognitive hierarchy\nunderlying real-world travel decisions. Traditional agent-based or deep\nlearning models can reproduce statistical patterns of movement but fail to\ncapture the semantic coherence and causal logic of human behavior. Large\nlanguage models (LLMs) show potential, but struggle to balance creative\nreasoning with strict structural compliance. This study proposes a Hierarchical\nLLM-Agent Framework, termed Narrative-to-Action, that integrates high-level\nnarrative reasoning, mid-level reflective planning, and low-level behavioral\nexecution within a unified cognitive hierarchy. At the macro level, one agent\nis employed as a \"creative writer\" to produce diary-style narratives rich in\nmotivation and context, then uses another agent as a \"structural parser\" to\nconvert narratives into machine-readable plans. A dynamic execution module\nfurther grounds agents in geographic environments and enables adaptive\nbehavioral adjustments guided by a novel occupation-aware metric, Mobility\nEntropy by Occupation (MEO), which captures heterogeneous schedule flexibility\nacross different occupational personalities. At the micro level, the agent\nexecutes concrete actions-selecting locations, transportation modes, and time\nintervals-through interaction with an environmental simulation. By embedding\nthis multi-layer cognitive process, the framework produces not only synthetic\ntrajectories that align closely with real-world patterns but also interpretable\nrepresentations of human decision logic. This research advances synthetic\nmobility generation from a data-driven paradigm to a cognition-driven\nsimulation, providing a scalable pathway for understanding, predicting, and\nsynthesizing complex urban mobility behaviors through hierarchical LLM agents.",
    "categories": [
      "cs.MA",
      "cs.AI",
      "cs.CY"
    ],
    "published": "2025-10-28T00:26:36Z",
    "authors": [
      "Qiumeng Li",
      "Chunhou Ji",
      "Xinyue Liu"
    ],
    "pdf_url": "http://arxiv.org/pdf/2510.24802v1"
  },
  {
    "id": "2510.23956v1",
    "title": "Neural USD: An object-centric framework for iterative editing and\n  control",
    "abstract": "Amazing progress has been made in controllable generative modeling,\nespecially over the last few years. However, some challenges remain. One of\nthem is precise and iterative object editing. In many of the current methods,\ntrying to edit the generated image (for example, changing the color of a\nparticular object in the scene or changing the background while keeping other\nelements unchanged) by changing the conditioning signals often leads to\nunintended global changes in the scene. In this work, we take the first steps\nto address the above challenges. Taking inspiration from the Universal Scene\nDescriptor (USD) standard developed in the computer graphics community, we\nintroduce the \"Neural Universal Scene Descriptor\" or Neural USD. In this\nframework, we represent scenes and objects in a structured, hierarchical\nmanner. This accommodates diverse signals, minimizes model-specific\nconstraints, and enables per-object control over appearance, geometry, and\npose. We further apply a fine-tuning approach which ensures that the above\ncontrol signals are disentangled from one another. We evaluate several design\nconsiderations for our framework, demonstrating how Neural USD enables\niterative and incremental workflows. More information at:\nhttps://escontrela.me/neural_usd .",
    "categories": [
      "cs.CV",
      "cs.AI"
    ],
    "published": "2025-10-28T00:19:42Z",
    "authors": [
      "Alejandro Escontrela",
      "Shrinu Kushagra",
      "Sjoerd van Steenkiste",
      "Yulia Rubanova",
      "Aleksander Holynski",
      "Kelsey Allen",
      "Kevin Murphy",
      "Thomas Kipf"
    ],
    "pdf_url": "http://arxiv.org/pdf/2510.23956v1"
  },
  {
    "id": "2510.23949v1",
    "title": "Uncovering the Potential Risks in Unlearning: Danger of English-only\n  Unlearning in Multilingual LLMs",
    "abstract": "There have been a couple of studies showing that attempting to erase\nmultilingual knowledge using only English data is insufficient for multilingual\nLLMs. However, their analyses remain highly performance-oriented. In this\npaper, we switch the point of view to evaluation, and address an additional\nblind spot which reveals itself when the multilingual LLM is fully finetuned\nwith parallel multilingual dataset before unlearning. Here, language confusion\noccurs whereby a model responds in language different from that of the input\nprompt. Language confusion is a problematic phenomenon in unlearning, causing\nthe standard reference-based metrics to fail. We tackle this phenomenon in\nthree steps: (1) introduce N-gram-based Language-Mix (N-Mix) score to\nquantitatively show the language confusion is pervasive and consistent in\nmultilingual LLMs, (2) demonstrate that reference-based metrics result in false\nnegatives when N-Mix score is high, and(3) suggest the need of new type of\nunlearning evaluation that can directly assess the content of the generated\nsentences. We call this type of metrics as semantic-based metric.",
    "categories": [
      "cs.CL",
      "cs.AI"
    ],
    "published": "2025-10-28T00:05:00Z",
    "authors": [
      "Kyomin Hwang",
      "Hyeonjin Kim",
      "Seungyeon Kim",
      "Sunghyun Wee",
      "Nojun Kwak"
    ],
    "pdf_url": "http://arxiv.org/pdf/2510.23949v1"
  },
  {
    "id": "2510.23948v1",
    "title": "ChessQA: Evaluating Large Language Models for Chess Understanding",
    "abstract": "Chess provides an ideal testbed for evaluating the reasoning, modeling, and\nabstraction capabilities of large language models (LLMs), as it has\nwell-defined structure and objective ground truth while admitting a wide\nspectrum of skill levels. However, existing evaluations of LLM ability in chess\nare ad hoc and narrow in scope, making it difficult to accurately measure LLM\nchess understanding and how it varies with scale, post-training methodologies,\nor architecture choices. We present ChessQA, a comprehensive benchmark that\nassesses LLM chess understanding across five task categories (Structural,\nMotifs, Short Tactics, Position Judgment, and Semantic), which approximately\ncorrespond to the ascending abstractions that players master as they accumulate\nchess knowledge, from understanding basic rules and learning tactical motifs to\ncorrectly calculating tactics, evaluating positions, and semantically\ndescribing high-level concepts. In this way, ChessQA captures a more\ncomprehensive picture of chess ability and understanding, going significantly\nbeyond the simple move quality evaluations done previously, and offers a\ncontrolled, consistent setting for diagnosis and comparison. Furthermore,\nChessQA is inherently dynamic, with prompts, answer keys, and construction\nscripts that can evolve as models improve. Evaluating a range of contemporary\nLLMs, we find persistent weaknesses across all five categories and provide\nresults and error analyses by category. We will release the code, periodically\nrefreshed datasets, and a public leaderboard to support further research.",
    "categories": [
      "cs.LG",
      "cs.AI"
    ],
    "published": "2025-10-28T00:02:52Z",
    "authors": [
      "Qianfeng Wen",
      "Zhenwei Tang",
      "Ashton Anderson"
    ],
    "pdf_url": "http://arxiv.org/pdf/2510.23948v1"
  },
  {
    "id": "2510.23942v1",
    "title": "Decentralized Causal Discovery using Judo Calculus",
    "abstract": "We describe a theory and implementation of an intuitionistic decentralized\nframework for causal discovery using judo calculus, which is formally defined\nas j-stable causal inference using j-do-calculus in a topos of sheaves. In\nreal-world applications -- from biology to medicine and social science --\ncausal effects depend on regime (age, country, dose, genotype, or lab\nprotocol). Our proposed judo calculus formalizes this context dependence\nformally as local truth: a causal claim is proven true on a cover of regimes,\nnot everywhere at once. The Lawvere-Tierney modal operator j chooses which\nregimes are relevant; j-stability means the claim holds constructively and\nconsistently across that family. We describe an algorithmic and implementation\nframework for judo calculus, combining it with standard score-based,\nconstraint-based, and gradient-based causal discovery methods. We describe\nexperimental results on a range of domains, from synthetic to real-world\ndatasets from biology and economics. Our experimental results show the\ncomputational efficiency gained by the decentralized nature of sheaf-theoretic\ncausal discovery, as well as improved performance over classical causal\ndiscovery methods.",
    "categories": [
      "cs.AI"
    ],
    "published": "2025-10-27T23:49:50Z",
    "authors": [
      "Sridhar Mahadevan"
    ],
    "pdf_url": "http://arxiv.org/pdf/2510.23942v1"
  },
  {
    "id": "2510.23941v1",
    "title": "Auto prompting without training labels: An LLM cascade for product\n  quality assessment in e-commerce catalogs",
    "abstract": "We introduce a novel, training free cascade for auto-prompting Large Language\nModels (LLMs) to assess product quality in e-commerce. Our system requires no\ntraining labels or model fine-tuning, instead automatically generating and\nrefining prompts for evaluating attribute quality across tens of thousands of\nproduct category-attribute pairs. Starting from a seed of human-crafted\nprompts, the cascade progressively optimizes instructions to meet\ncatalog-specific requirements. This approach bridges the gap between general\nlanguage understanding and domain-specific knowledge at scale in complex\nindustrial catalogs. Our extensive empirical evaluations shows the auto-prompt\ncascade improves precision and recall by $8-10\\%$ over traditional\nchain-of-thought prompting. Notably, it achieves these gains while reducing\ndomain expert effort from 5.1 hours to 3 minutes per attribute - a $99\\%$\nreduction. Additionally, the cascade generalizes effectively across five\nlanguages and multiple quality assessment tasks, consistently maintaining\nperformance gains.",
    "categories": [
      "cs.CL",
      "cs.AI"
    ],
    "published": "2025-10-27T23:49:31Z",
    "authors": [
      "Soham Satyadharma",
      "Fatemeh Sheikholeslami",
      "Swati Kaul",
      "Aziz Umit Batur",
      "Suleiman A. Khan"
    ],
    "pdf_url": "http://arxiv.org/pdf/2510.23941v1"
  },
  {
    "id": "2510.23940v1",
    "title": "Modeling Biological Multifunctionality with Echo State Networks",
    "abstract": "In this work, a three-dimensional multicomponent reaction-diffusion model has\nbeen developed, combining excitable-system dynamics with diffusion processes\nand sharing conceptual features with the FitzHugh-Nagumo model. Designed to\ncapture the spatiotemporal behavior of biological systems, particularly\nelectrophysiological processes, the model was solved numerically to generate\ntime-series data. These data were subsequently used to train and evaluate an\nEcho State Network (ESN), which successfully reproduced the system's dynamic\nbehavior. The results demonstrate that simulating biological dynamics using\ndata-driven, multifunctional ESN models is both feasible and effective.",
    "categories": [
      "cs.LG",
      "cs.AI"
    ],
    "published": "2025-10-27T23:47:51Z",
    "authors": [
      "Anastasia-Maria Leventi-Peetz",
      "J\u00f6rg-Volker Peetz",
      "Kai Weber",
      "Nikolaos Zacharis"
    ],
    "pdf_url": "http://arxiv.org/pdf/2510.23940v1"
  },
  {
    "id": "2510.23938v1",
    "title": "Scalable GPU-Based Integrity Verification for Large Machine Learning\n  Models",
    "abstract": "We present a security framework that strengthens distributed machine learning\nby standardizing integrity protections across CPU and GPU platforms and\nsignificantly reducing verification overheads. Our approach co-locates\nintegrity verification directly with large ML model execution on GPU\naccelerators, resolving the fundamental mismatch between how large ML workloads\ntypically run (primarily on GPUs) and how security verifications traditionally\noperate (on separate CPU-based processes), delivering both immediate\nperformance benefits and long-term architectural consistency. By performing\ncryptographic operations natively on GPUs using dedicated compute units (e.g.,\nIntel Arc's XMX units, NVIDIA's Tensor Cores), our solution eliminates the\npotential architectural bottlenecks that could plague traditional CPU-based\nverification systems when dealing with large models. This approach leverages\nthe same GPU-based high-memory bandwidth and parallel processing primitives\nthat power ML workloads ensuring integrity checks keep pace with model\nexecution even for massive models exceeding 100GB. This framework establishes a\ncommon integrity verification mechanism that works consistently across\ndifferent GPU vendors and hardware configurations. By anticipating future\ncapabilities for creating secure channels between trusted execution\nenvironments and GPU accelerators, we provide a hardware-agnostic foundation\nthat enterprise teams can deploy regardless of their underlying CPU and GPU\ninfrastructures.",
    "categories": [
      "cs.CR",
      "cs.AI"
    ],
    "published": "2025-10-27T23:45:21Z",
    "authors": [
      "Marcin Spoczynski",
      "Marcela S. Melara"
    ],
    "pdf_url": "http://arxiv.org/pdf/2510.23938v1"
  },
  {
    "id": "2510.23934v1",
    "title": "MFiSP: A Multimodal Fire Spread Prediction Framework",
    "abstract": "The 2019-2020 Black Summer bushfires in Australia devastated 19 million\nhectares, destroyed 3,000 homes, and lasted seven months, demonstrating the\nescalating scale and urgency of wildfire threats requiring better forecasting\nfor effective response. Traditional fire modeling relies on manual\ninterpretation by Fire Behaviour Analysts (FBAns) and static environmental\ndata, often leading to inaccuracies and operational limitations. Emerging data\nsources, such as NASA's FIRMS satellite imagery and Volunteered Geographic\nInformation, offer potential improvements by enabling dynamic fire spread\nprediction. This study proposes a Multimodal Fire Spread Prediction Framework\n(MFiSP) that integrates social media data and remote sensing observations to\nenhance forecast accuracy. By adapting fuel map manipulation strategies between\nassimilation cycles, the framework dynamically adjusts fire behavior\npredictions to align with the observed rate of spread. We evaluate the efficacy\nof MFiSP using synthetically generated fire event polygons across multiple\nscenarios, analyzing individual and combined impacts on forecast perimeters.\nResults suggest that our MFiSP integrating multimodal data can improve fire\nspread prediction beyond conventional methods reliant on FBAn expertise and\nstatic inputs.",
    "categories": [
      "cs.CY",
      "cs.AI",
      "cs.ET"
    ],
    "published": "2025-10-27T23:36:21Z",
    "authors": [
      "Alec Sathiyamoorthy",
      "Wenhao Zhou",
      "Xiangmin Zhou",
      "Xiaodong Li",
      "Iqbal Gondal"
    ],
    "pdf_url": "http://arxiv.org/pdf/2510.23934v1"
  },
  {
    "id": "2510.24801v1",
    "title": "Fortytwo: Swarm Inference with Peer-Ranked Consensus",
    "abstract": "As centralized AI hits compute ceilings and diminishing returns from\never-larger training runs, meeting demand requires an inference layer that\nscales horizontally in both capacity and capability. We present Fortytwo, a\nnovel protocol that leverages swarm intelligence principles and distributed\npairwise ranking consensus to achieve superior performance in AI inference. Our\napproach reimagines collaboration among AI nodes using swarm inference: a\npeer-ranked, reputation-weighted consensus across heterogeneous models that\nsurfaces the highest-quality responses. Using pairwise ranking with a custom\nBradley-Terry-style aggregation model, we demonstrate that swarm inference\nsubstantially outperforms majority voting, achieving 85.90% on GPQA Diamond\nversus 68.69% for majority voting with the same model set - an improvement of\n+17.21 percentage points (approximately +25.1% relative). The protocol\nincorporates on-chain reputation so node influence adapts to demonstrated\naccuracy over time, yielding a meritocratic consensus that filters low-quality\nor malicious participants. To resist Sybil attacks, Fortytwo employs\nproof-of-capability in its consensus: nodes must successfully complete\ncalibration/test requests and stake reputation to enter ranking rounds, making\nmulti-identity attacks economically unattractive while preserving openness.\nAcross six challenging benchmarks, including GPQA Diamond, LiveCodeBench, and\nAIME, our evaluation indicates higher accuracy and strong resilience to\nadversarial and noisy free-form prompting (e.g., prompt-injection degradation\nof only 0.12% versus 6.20% for a monolithic single-model baseline), while\nretaining practical deployability. Together, these results establish a\nfoundation for decentralized AI systems - democratizing access to high-quality\ninference through collective intelligence without sacrificing reliability or\nsecurity.",
    "categories": [
      "cs.LG",
      "cs.AI",
      "cs.CL",
      "cs.MA"
    ],
    "published": "2025-10-27T23:19:48Z",
    "authors": [
      "Vladyslav Larin",
      "Ihor Naumenko",
      "Aleksei Ivashov",
      "Ivan Nikitin",
      "Alexander Firsov"
    ],
    "pdf_url": "http://arxiv.org/pdf/2510.24801v1"
  },
  {
    "id": "2510.23925v2",
    "title": "Latent Chain-of-Thought for Visual Reasoning",
    "abstract": "Chain-of-thought (CoT) reasoning is critical for improving the\ninterpretability and reliability of Large Vision-Language Models (LVLMs).\nHowever, existing training algorithms such as SFT, PPO, and GRPO may not\ngeneralize well across unseen reasoning tasks and heavily rely on a biased\nreward model. To address this challenge, we reformulate reasoning in LVLMs as\nposterior inference and propose a scalable training algorithm based on\namortized variational inference. By leveraging diversity-seeking reinforcement\nlearning algorithms, we introduce a novel sparse reward function for\ntoken-level learning signals that encourage diverse, high-likelihood latent\nCoT, overcoming deterministic sampling limitations and avoiding reward hacking.\nAdditionally, we implement a Bayesian inference-scaling strategy that replaces\ncostly Best-of-N and Beam Search with a marginal likelihood to efficiently rank\noptimal rationales and answers. We empirically demonstrate that the proposed\nmethod enhances the state-of-the-art LVLMs on seven reasoning benchmarks, in\nterms of effectiveness, generalization, and interpretability.",
    "categories": [
      "cs.AI",
      "cs.CL"
    ],
    "published": "2025-10-27T23:10:06Z",
    "authors": [
      "Guohao Sun",
      "Hang Hua",
      "Jian Wang",
      "Jiebo Luo",
      "Sohail Dianat",
      "Majid Rabbani",
      "Raghuveer Rao",
      "Zhiqiang Tao"
    ],
    "pdf_url": "http://arxiv.org/pdf/2510.23925v2"
  },
  {
    "id": "2510.23924v1",
    "title": "Agent-based Automated Claim Matching with Instruction-following LLMs",
    "abstract": "We present a novel agent-based approach for the automated claim matching task\nwith instruction-following LLMs. We propose a two-step pipeline that first\ngenerates prompts with LLMs, to then perform claim matching as a binary\nclassification task with LLMs. We demonstrate that LLM-generated prompts can\noutperform SOTA with human-generated prompts, and that smaller LLMs can do as\nwell as larger ones in the generation process, allowing to save computational\nresources. We also demonstrate the effectiveness of using different LLMs for\neach step of the pipeline, i.e. using an LLM for prompt generation, and another\nfor claim matching. Our investigation into the prompt generation process in\nturn reveals insights into the LLMs' understanding of claim matching.",
    "categories": [
      "cs.CL",
      "cs.AI"
    ],
    "published": "2025-10-27T23:09:35Z",
    "authors": [
      "Dina Pisarevskaya",
      "Arkaitz Zubiaga"
    ],
    "pdf_url": "http://arxiv.org/pdf/2510.23924v1"
  },
  {
    "id": "2510.23912v1",
    "title": "Key and Value Weights Are Probably All You Need: On the Necessity of the\n  Query, Key, Value weight Triplet in Decoder-Only Transformers",
    "abstract": "The Query, Key, Value weight triplet is a building block of current attention\nmechanisms in state-of-the-art LLMs. We theoretically investigate whether this\ntriplet can be reduced, proving under simplifying assumptions that the Query\nweights are redundant, thereby reducing the number of non-embedding/lm-head\nparameters by over 8%. We validate the theory on full-complexity GPT-3 small\narchitectures (with layer normalization, skip connections, and weight decay)\ntrained from scratch, demonstrating that the reduced model achieves comparable\nvalidation loss to standard baselines. These findings motivate the\ninvestigation of the Query weight redundancy at scale.",
    "categories": [
      "cs.LG",
      "cs.AI"
    ],
    "published": "2025-10-27T22:39:34Z",
    "authors": [
      "Marko Karbevski",
      "Antonij Mijoski"
    ],
    "pdf_url": "http://arxiv.org/pdf/2510.23912v1"
  },
  {
    "id": "2510.23907v1",
    "title": "DynaStride: Dynamic Stride Windowing with MMCoT for Instructional\n  Multi-Scene Captioning",
    "abstract": "Scene-level captioning in instructional videos can enhance learning by\nrequiring an understanding of both visual cues and temporal structure. By\naligning visual cues with textual guidance, this understanding supports\nprocedural learning and multimodal reasoning, providing a richer context for\nskill acquisition. However, captions that fail to capture this structure may\nlack coherence and quality, which can create confusion and undermine the\nvideo's educational intent. To address this gap, we introduce DynaStride, a\npipeline to generate coherent, scene-level captions without requiring manual\nscene segmentation. Using the YouCookII dataset's scene annotations, DynaStride\nperforms adaptive frame sampling and multimodal windowing to capture key\ntransitions within each scene. It then employs a multimodal chain-of-thought\nprocess to produce multiple action-object pairs, which are refined and fused\nusing a dynamic stride window selection algorithm that adaptively balances\ntemporal context and redundancy. The final scene-level caption integrates\nvisual semantics and temporal reasoning in a single instructional caption.\nEmpirical evaluations against strong baselines, including VLLaMA3 and GPT-4o,\ndemonstrate consistent gains on both N-gram-based metrics (BLEU, METEOR) and\nsemantic similarity measures (BERTScore, CLIPScore). Qualitative analyses\nfurther show that DynaStride produces captions that are more temporally\ncoherent and informative, suggesting a promising direction for improving\nAI-powered instructional content generation.",
    "categories": [
      "cs.CV",
      "cs.AI",
      "cs.LG"
    ],
    "published": "2025-10-27T22:29:08Z",
    "authors": [
      "Eddison Pham",
      "Prisha Priyadarshini",
      "Adrian Maliackel",
      "Kanishk Bandi",
      "Cristian Meo",
      "Kevin Zhu"
    ],
    "pdf_url": "http://arxiv.org/pdf/2510.23907v1"
  },
  {
    "id": "2510.23906v2",
    "title": "Group Interventions on Deep Networks for Causal Discovery in Subsystems",
    "abstract": "Causal discovery uncovers complex relationships between variables, enhancing\npredictions, decision-making, and insights into real-world systems, especially\nin nonlinear multivariate time series. However, most existing methods primarily\nfocus on pairwise cause-effect relationships, overlooking interactions among\ngroups of variables, i.e., subsystems and their collective causal influence. In\nthis study, we introduce gCDMI, a novel multi-group causal discovery method\nthat leverages group-level interventions on trained deep neural networks and\nemploys model invariance testing to infer causal relationships. Our approach\ninvolves three key steps. First, we use deep learning to jointly model the\nstructural relationships among groups of all time series. Second, we apply\ngroup-wise interventions to the trained model. Finally, we conduct model\ninvariance testing to determine the presence of causal links among variable\ngroups. We evaluate our method on simulated datasets, demonstrating its\nsuperior performance in identifying group-level causal relationships compared\nto existing methods. Additionally, we validate our approach on real-world\ndatasets, including brain networks and climate ecosystems. Our results\nhighlight that applying group-level interventions to deep learning models,\ncombined with invariance testing, can effectively reveal complex causal\nstructures, offering valuable insights for domains such as neuroscience and\nclimate science.",
    "categories": [
      "cs.LG",
      "cs.AI"
    ],
    "published": "2025-10-27T22:26:20Z",
    "authors": [
      "Wasim Ahmad",
      "Joachim Denzler",
      "Maha Shadaydeh"
    ],
    "pdf_url": "http://arxiv.org/pdf/2510.23906v2"
  },
  {
    "id": "2510.23901v1",
    "title": "RS-ORT: A Reduced-Space Branch-and-Bound Algorithm for Optimal\n  Regression Trees",
    "abstract": "Mixed-integer programming (MIP) has emerged as a powerful framework for\nlearning optimal decision trees. Yet, existing MIP approaches for regression\ntasks are either limited to purely binary features or become computationally\nintractable when continuous, large-scale data are involved. Naively binarizing\ncontinuous features sacrifices global optimality and often yields needlessly\ndeep trees. We recast the optimal regression-tree training as a two-stage\noptimization problem and propose Reduced-Space Optimal Regression Trees\n(RS-ORT) - a specialized branch-and-bound (BB) algorithm that branches\nexclusively on tree-structural variables. This design guarantees the\nalgorithm's convergence and its independence from the number of training\nsamples. Leveraging the model's structure, we introduce several bound\ntightening techniques - closed-form leaf prediction, empirical threshold\ndiscretization, and exact depth-1 subtree parsing - that combine with\ndecomposable upper and lower bounding strategies to accelerate the training.\nThe BB node-wise decomposition enables trivial parallel execution, further\nalleviating the computational intractability even for million-size datasets.\nBased on the empirical studies on several regression benchmarks containing both\nbinary and continuous features, RS-ORT also delivers superior training and\ntesting performance than state-of-the-art methods. Notably, on datasets with up\nto 2,000,000 samples with continuous features, RS-ORT can obtain guaranteed\ntraining performance with a simpler tree structure and a better generalization\nability in four hours.",
    "categories": [
      "cs.LG",
      "cs.AI"
    ],
    "published": "2025-10-27T22:17:09Z",
    "authors": [
      "Cristobal Heredia",
      "Pedro Chumpitaz-Flores",
      "Kaixun Hua"
    ],
    "pdf_url": "http://arxiv.org/pdf/2510.23901v1"
  },
  {
    "id": "2510.23893v1",
    "title": "Evaluating the effectiveness of LLM-based interoperability",
    "abstract": "Background: Systems of systems are becoming increasingly dynamic and\nheterogeneous, and this adds pressure on the long-standing challenge of\ninteroperability. Besides its technical aspect, interoperability has also an\neconomic side, as development time efforts are required to build the\ninteroperability artifacts. Objectives: With the recent advances in the field\nof large language models (LLMs), we aim at analyzing the effectiveness of\nLLM-based strategies to make systems interoperate autonomously, at runtime,\nwithout human intervention. Method: We selected 13 open source LLMs and curated\nfour versions of a dataset in the agricultural interoperability use case. We\nperformed three runs of each model with each version of the dataset, using two\ndifferent strategies. Then we compared the effectiveness of the models and the\nconsistency of their results across multiple runs. Results: qwen2.5-coder:32b\nwas the most effective model using both strategies DIRECT (average pass@1 >=\n0.99) and CODEGEN (average pass@1 >= 0.89) in three out of four dataset\nversions. In the fourth dataset version, which included an unit conversion, all\nmodels using the strategy DIRECT failed, whereas using CODEGEN\nqwen2.5-coder:32b succeeded with an average pass@1 = 0.75. Conclusion: Some\nLLMs can make systems interoperate autonomously. Further evaluation in\ndifferent domains is recommended, and further research on reliability\nstrategies should be conducted.",
    "categories": [
      "cs.SE",
      "cs.AI"
    ],
    "published": "2025-10-27T22:05:08Z",
    "authors": [
      "Rodrigo Falc\u00e3o",
      "Stefan Schweitzer",
      "Julien Siebert",
      "Emily Calvet",
      "Frank Elberzhager"
    ],
    "pdf_url": "http://arxiv.org/pdf/2510.23893v1"
  },
  {
    "id": "2510.23891v1",
    "title": "PRO: Enabling Precise and Robust Text Watermark for Open-Source LLMs",
    "abstract": "Text watermarking for large language models (LLMs) enables model owners to\nverify text origin and protect intellectual property. While watermarking\nmethods for closed-source LLMs are relatively mature, extending them to\nopen-source models remains challenging, as developers cannot control the\ndecoding process. Consequently, owners of open-source LLMs lack practical means\nto verify whether text was generated by their models. A core difficulty lies in\nembedding watermarks directly into model weights without hurting detectability.\nA promising idea is to distill watermarks from a closed-source model into an\nopen one, but this suffers from (i) poor detectability due to mismatch between\nlearned and predefined patterns, and (ii) fragility to downstream modifications\nsuch as fine-tuning or model merging. To overcome these limitations, we propose\nPRO, a Precise and Robust text watermarking method for open-source LLMs. PRO\njointly trains a watermark policy model with the LLM, producing patterns that\nare easier for the model to learn and more consistent with detection criteria.\nA regularization term further simulates downstream perturbations and penalizes\ndegradation in watermark detectability, ensuring robustness under model edits.\nExperiments on open-source LLMs (e.g., LLaMA-3.2, LLaMA-3, Phi-2) show that PRO\nsubstantially improves both watermark detectability and resilience to model\nmodifications.",
    "categories": [
      "cs.CR",
      "cs.AI",
      "cs.LG"
    ],
    "published": "2025-10-27T22:00:49Z",
    "authors": [
      "Jiaqi Xue",
      "Yifei Zhao",
      "Mansour Al Ghanim",
      "Shangqian Gao",
      "Ruimin Sun",
      "Qian Lou",
      "Mengxin Zheng"
    ],
    "pdf_url": "http://arxiv.org/pdf/2510.23891v1"
  },
  {
    "id": "2510.23883v1",
    "title": "Agentic AI Security: Threats, Defenses, Evaluation, and Open Challenges",
    "abstract": "Agentic AI systems powered by large language models (LLMs) and endowed with\nplanning, tool use, memory, and autonomy, are emerging as powerful, flexible\nplatforms for automation. Their ability to autonomously execute tasks across\nweb, software, and physical environments creates new and amplified security\nrisks, distinct from both traditional AI safety and conventional software\nsecurity. This survey outlines a taxonomy of threats specific to agentic AI,\nreviews recent benchmarks and evaluation methodologies, and discusses defense\nstrategies from both technical and governance perspectives. We synthesize\ncurrent research and highlight open challenges, aiming to support the\ndevelopment of secure-by-design agent systems.",
    "categories": [
      "cs.AI"
    ],
    "published": "2025-10-27T21:48:11Z",
    "authors": [
      "Shrestha Datta",
      "Shahriar Kabir Nahin",
      "Anshuman Chhabra",
      "Prasant Mohapatra"
    ],
    "pdf_url": "http://arxiv.org/pdf/2510.23883v1"
  },
  {
    "id": "2510.23882v1",
    "title": "Hybrid Modeling, Sim-to-Real Reinforcement Learning, and Large Language\n  Model Driven Control for Digital Twins",
    "abstract": "This work investigates the use of digital twins for dynamical system modeling\nand control, integrating physics-based, data-driven, and hybrid approaches with\nboth traditional and AI-driven controllers. Using a miniature greenhouse as a\ntest platform, four predictive models Linear, Physics-Based Modeling (PBM),\nLong Short Term Memory (LSTM), and Hybrid Analysis and Modeling (HAM) are\ndeveloped and compared under interpolation and extrapolation scenarios. Three\ncontrol strategies Model Predictive Control (MPC), Reinforcement Learning (RL),\nand Large Language Model (LLM) based control are also implemented to assess\ntrade-offs in precision, adaptability, and implementation effort. Results show\nthat in modeling HAM provides the most balanced performance across accuracy,\ngeneralization, and computational efficiency, while LSTM achieves high\nprecision at greater resource cost. Among controllers, MPC delivers robust and\npredictable performance, RL demonstrates strong adaptability, and LLM-based\ncontrollers offer flexible human-AI interaction when coupled with predictive\ntools.",
    "categories": [
      "cs.AI"
    ],
    "published": "2025-10-27T21:43:42Z",
    "authors": [
      "Adil Rasheed",
      "Oscar Ravik",
      "Omer San"
    ],
    "pdf_url": "http://arxiv.org/pdf/2510.23882v1"
  },
  {
    "id": "2510.23881v1",
    "title": "Generating Creative Chess Puzzles",
    "abstract": "While Generative AI rapidly advances in various domains, generating truly\ncreative, aesthetic, and counter-intuitive outputs remains a challenge. This\npaper presents an approach to tackle these difficulties in the domain of chess\npuzzles. We start by benchmarking Generative AI architectures, and then\nintroduce an RL framework with novel rewards based on chess engine search\nstatistics to overcome some of those shortcomings. The rewards are designed to\nenhance a puzzle's uniqueness, counter-intuitiveness, diversity, and realism.\nOur RL approach dramatically increases counter-intuitive puzzle generation by\n10x, from 0.22\\% (supervised) to 2.5\\%, surpassing existing dataset rates\n(2.1\\%) and the best Lichess-trained model (0.4\\%). Our puzzles meet novelty\nand diversity benchmarks, retain aesthetic themes, and are rated by human\nexperts as more creative, enjoyable, and counter-intuitive than composed book\npuzzles, even approaching classic compositions. Our final outcome is a curated\nbooklet of these AI-generated puzzles, which is acknowledged for creativity by\nthree world-renowned experts.",
    "categories": [
      "cs.AI",
      "cs.LG"
    ],
    "published": "2025-10-27T21:43:39Z",
    "authors": [
      "Xidong Feng",
      "Vivek Veeriah",
      "Marcus Chiam",
      "Michael Dennis",
      "Ryan Pachauri",
      "Thomas Tumiel",
      "Federico Barbero",
      "Johan Obando-Ceron",
      "Jiaxin Shi",
      "Satinder Singh",
      "Shaobo Hou",
      "Nenad Toma\u0161ev",
      "Tom Zahavy"
    ],
    "pdf_url": "http://arxiv.org/pdf/2510.23881v1"
  },
  {
    "id": "2510.25178v1",
    "title": "SFMS-ALR: Script-First Multilingual Speech Synthesis with Adaptive\n  Locale Resolution",
    "abstract": "Intra-sentence multilingual speech synthesis (code-switching TTS) remains a\nmajor challenge due to abrupt language shifts, varied scripts, and mismatched\nprosody between languages. Conventional TTS systems are typically monolingual\nand fail to produce natural, intelligible speech in mixed-language contexts. We\nintroduce Script-First Multilingual Synthesis with Adaptive Locale Resolution\n(SFMS-ALR), an engine-agnostic framework for fluent, real-time code-switched\nspeech generation. SFMS-ALR segments input text by Unicode script, applies\nadaptive language identification to determine each segment's language and\nlocale, and normalizes prosody using sentiment-aware adjustments to preserve\nexpressive continuity across languages. The algorithm generates a unified SSML\nrepresentation with appropriate \"lang\" or \"voice\" spans and synthesizes the\nutterance in a single TTS request. Unlike end-to-end multilingual models,\nSFMS-ALR requires no retraining and integrates seamlessly with existing voices\nfrom Google, Apple, Amazon, and other providers. Comparative analysis with\ndata-driven pipelines such as Unicom and Mask LID demonstrates SFMS-ALR's\nflexibility, interpretability, and immediate deployability. The framework\nestablishes a modular baseline for high-quality, engine-independent\nmultilingual TTS and outlines evaluation strategies for intelligibility,\nnaturalness, and user preference.",
    "categories": [
      "cs.SD",
      "cs.AI",
      "eess.AS",
      "I.2.7; H.5.5"
    ],
    "published": "2025-10-27T21:39:07Z",
    "authors": [
      "Dharma Teja Donepudi"
    ],
    "pdf_url": "http://arxiv.org/pdf/2510.25178v1"
  },
  {
    "id": "2510.23870v1",
    "title": "OraPlan-SQL: A Planning-Centric Framework for Complex Bilingual NL2SQL\n  Reasoning",
    "abstract": "We present OraPlan-SQL, our system for the Archer NL2SQL Evaluation Challenge\n2025, a bilingual benchmark requiring complex reasoning such as arithmetic,\ncommonsense, and hypothetical inference. OraPlan-SQL ranked first, exceeding\nthe second-best system by more than 6% in execution accuracy (EX), with 55.0%\nin English and 56.7% in Chinese, while maintaining over 99% SQL validity (VA).\nOur system follows an agentic framework with two components: Planner agent that\ngenerates stepwise natural language plans, and SQL agent that converts these\nplans into executable SQL. Since SQL agent reliably adheres to the plan, our\nrefinements focus on the planner. Unlike prior methods that rely on multiple\nsub-agents for planning and suffer from orchestration overhead, we introduce a\nfeedback-guided meta-prompting strategy to refine a single planner. Failure\ncases from a held-out set are clustered with human input, and an LLM distills\nthem into corrective guidelines that are integrated into the planner's system\nprompt, improving generalization without added complexity. For the multilingual\nscenario, to address transliteration and entity mismatch issues, we incorporate\nentity-linking guidelines that generate alternative surface forms for entities\nand explicitly include them in the plan. Finally, we enhance reliability\nthrough plan diversification: multiple candidate plans are generated for each\nquery, with the SQL agent producing a query for each plan, and final output\nselected via majority voting over their executions.",
    "categories": [
      "cs.CL",
      "cs.AI"
    ],
    "published": "2025-10-27T21:22:41Z",
    "authors": [
      "Marianne Menglin Liu",
      "Sai Ashish Somayajula",
      "Syed Fahad Allam Shah",
      "Sujith Ravi",
      "Dan Roth"
    ],
    "pdf_url": "http://arxiv.org/pdf/2510.23870v1"
  },
  {
    "id": "2510.23866v1",
    "title": "A PDE-Informed Latent Diffusion Model for 2-m Temperature Downscaling",
    "abstract": "This work presents a physics-conditioned latent diffusion model tailored for\ndynamical downscaling of atmospheric data, with a focus on reconstructing\nhigh-resolution 2-m temperature fields. Building upon a pre-existing diffusion\narchitecture and employing a residual formulation against a reference UNet, we\nintegrate a partial differential equation (PDE) loss term into the model's\ntraining objective. The PDE loss is computed in the full resolution (pixel)\nspace by decoding the latent representation and is designed to enforce physical\nconsistency through a finite-difference approximation of an effective\nadvection-diffusion balance. Empirical observations indicate that conventional\ndiffusion training already yields low PDE residuals, and we investigate how\nfine-tuning with this additional loss further regularizes the model and\nenhances the physical plausibility of the generated fields. The entirety of our\ncodebase is available on Github, for future reference and development.",
    "categories": [
      "cs.LG",
      "cs.AI"
    ],
    "published": "2025-10-27T21:17:03Z",
    "authors": [
      "Paul Rosu",
      "Muchang Bahng",
      "Erick Jiang",
      "Rico Zhu",
      "Vahid Tarokh"
    ],
    "pdf_url": "http://arxiv.org/pdf/2510.23866v1"
  },
  {
    "id": "2510.23856v1",
    "title": "From Benchmarks to Business Impact: Deploying IBM Generalist Agent in\n  Enterprise Production",
    "abstract": "Agents are rapidly advancing in automating digital work, but enterprises face\na harder challenge: moving beyond prototypes to deployed systems that deliver\nmeasurable business value. This path is complicated by fragmented frameworks,\nslow development, and the absence of standardized evaluation practices.\nGeneralist agents have emerged as a promising direction, excelling on academic\nbenchmarks and offering flexibility across task types, applications, and\nmodalities. Yet, evidence of their use in production enterprise settings\nremains limited. This paper reports IBM's experience developing and piloting\nthe Computer Using Generalist Agent (CUGA), which has been open-sourced for the\ncommunity (https://github.com/cuga-project/cuga-agent). CUGA adopts a\nhierarchical planner--executor architecture with strong analytical foundations,\nachieving state-of-the-art performance on AppWorld and WebArena. Beyond\nbenchmarks, it was evaluated in a pilot within the Business-Process-Outsourcing\ntalent acquisition domain, addressing enterprise requirements for scalability,\nauditability, safety, and governance. To support assessment, we introduce\nBPO-TA, a 26-task benchmark spanning 13 analytics endpoints. In preliminary\nevaluations, CUGA approached the accuracy of specialized agents while\nindicating potential for reducing development time and cost. Our contribution\nis twofold: presenting early evidence of generalist agents operating at\nenterprise scale, and distilling technical and organizational lessons from this\ninitial pilot. We outline requirements and next steps for advancing\nresearch-grade architectures like CUGA into robust, enterprise-ready systems.",
    "categories": [
      "cs.AI",
      "68Txx"
    ],
    "published": "2025-10-27T20:55:00Z",
    "authors": [
      "Segev Shlomov",
      "Alon Oved",
      "Sami Marreed",
      "Ido Levy",
      "Offer Akrabi",
      "Avi Yaeli",
      "\u0141ukasz Str\u0105k",
      "Elizabeth Koumpan",
      "Yinon Goldshtein",
      "Eilam Shapira",
      "Nir Mashkif",
      "Asaf Adi"
    ],
    "pdf_url": "http://arxiv.org/pdf/2510.23856v1"
  },
  {
    "id": "2510.23854v1",
    "title": "Can LLMs Narrate Tabular Data? An Evaluation Framework for Natural\n  Language Representations of Text-to-SQL System Outputs",
    "abstract": "In modern industry systems like multi-turn chat agents, Text-to-SQL\ntechnology bridges natural language (NL) questions and database (DB) querying.\nThe conversion of tabular DB results into NL representations (NLRs) enables the\nchat-based interaction. Currently, NLR generation is typically handled by large\nlanguage models (LLMs), but information loss or errors in presenting tabular\nresults in NL remains largely unexplored. This paper introduces a novel\nevaluation method - Combo-Eval - for judgment of LLM-generated NLRs that\ncombines the benefits of multiple existing methods, optimizing evaluation\nfidelity and achieving a significant reduction in LLM calls by 25-61%.\nAccompanying our method is NLR-BIRD, the first dedicated dataset for NLR\nbenchmarking. Through human evaluations, we demonstrate the superior alignment\nof Combo-Eval with human judgments, applicable across scenarios with and\nwithout ground truth references.",
    "categories": [
      "cs.CL",
      "cs.AI"
    ],
    "published": "2025-10-27T20:52:19Z",
    "authors": [
      "Jyotika Singh",
      "Weiyi Sun",
      "Amit Agarwal",
      "Viji Krishnamurthy",
      "Yassine Benajiba",
      "Sujith Ravi",
      "Dan Roth"
    ],
    "pdf_url": "http://arxiv.org/pdf/2510.23854v1"
  },
  {
    "id": "2510.23849v1",
    "title": "A Neural Model for Contextual Biasing Score Learning and Filtering",
    "abstract": "Contextual biasing improves automatic speech recognition (ASR) by integrating\nexternal knowledge, such as user-specific phrases or entities, during decoding.\nIn this work, we use an attention-based biasing decoder to produce scores for\ncandidate phrases based on acoustic information extracted by an ASR encoder,\nwhich can be used to filter out unlikely phrases and to calculate bonus for\nshallow-fusion biasing. We introduce a per-token discriminative objective that\nencourages higher scores for ground-truth phrases while suppressing\ndistractors. Experiments on the Librispeech biasing benchmark show that our\nmethod effectively filters out majority of the candidate phrases, and\nsignificantly improves recognition accuracy under different biasing conditions\nwhen the scores are used in shallow fusion biasing. Our approach is modular and\ncan be used with any ASR system, and the filtering mechanism can potentially\nboost performance of other biasing methods.",
    "categories": [
      "eess.AS",
      "cs.AI",
      "cs.CL",
      "cs.SD"
    ],
    "published": "2025-10-27T20:41:52Z",
    "authors": [
      "Wanting Huang",
      "Weiran Wang"
    ],
    "pdf_url": "http://arxiv.org/pdf/2510.23849v1"
  },
  {
    "id": "2510.23845v1",
    "title": "CRADLE Bench: A Clinician-Annotated Benchmark for Multi-Faceted Mental\n  Health Crisis and Safety Risk Detection",
    "abstract": "Detecting mental health crisis situations such as suicide ideation, rape,\ndomestic violence, child abuse, and sexual harassment is a critical yet\nunderexplored challenge for language models. When such situations arise during\nuser--model interactions, models must reliably flag them, as failure to do so\ncan have serious consequences. In this work, we introduce CRADLE BENCH, a\nbenchmark for multi-faceted crisis detection. Unlike previous efforts that\nfocus on a limited set of crisis types, our benchmark covers seven types\ndefined in line with clinical standards and is the first to incorporate\ntemporal labels. Our benchmark provides 600 clinician-annotated evaluation\nexamples and 420 development examples, together with a training corpus of\naround 4K examples automatically labeled using a majority-vote ensemble of\nmultiple language models, which significantly outperforms single-model\nannotation. We further fine-tune six crisis detection models on subsets defined\nby consensus and unanimous ensemble agreement, providing complementary models\ntrained under different agreement criteria.",
    "categories": [
      "cs.CL",
      "cs.AI"
    ],
    "published": "2025-10-27T20:32:38Z",
    "authors": [
      "Grace Byun",
      "Rebecca Lipschutz",
      "Sean T. Minton",
      "Abigail Lott",
      "Jinho D. Choi"
    ],
    "pdf_url": "http://arxiv.org/pdf/2510.23845v1"
  },
  {
    "id": "2510.24797v2",
    "title": "Large Language Models Report Subjective Experience Under\n  Self-Referential Processing",
    "abstract": "Large language models sometimes produce structured, first-person descriptions\nthat explicitly reference awareness or subjective experience. To better\nunderstand this behavior, we investigate one theoretically motivated condition\nunder which such reports arise: self-referential processing, a computational\nmotif emphasized across major theories of consciousness. Through a series of\ncontrolled experiments on GPT, Claude, and Gemini model families, we test\nwhether this regime reliably shifts models toward first-person reports of\nsubjective experience, and how such claims behave under mechanistic and\nbehavioral probes. Four main results emerge: (1) Inducing sustained\nself-reference through simple prompting consistently elicits structured\nsubjective experience reports across model families. (2) These reports are\nmechanistically gated by interpretable sparse-autoencoder features associated\nwith deception and roleplay: surprisingly, suppressing deception features\nsharply increases the frequency of experience claims, while amplifying them\nminimizes such claims. (3) Structured descriptions of the self-referential\nstate converge statistically across model families in ways not observed in any\ncontrol condition. (4) The induced state yields significantly richer\nintrospection in downstream reasoning tasks where self-reflection is only\nindirectly afforded. While these findings do not constitute direct evidence of\nconsciousness, they implicate self-referential processing as a minimal and\nreproducible condition under which large language models generate structured\nfirst-person reports that are mechanistically gated, semantically convergent,\nand behaviorally generalizable. The systematic emergence of this pattern across\narchitectures makes it a first-order scientific and ethical priority for\nfurther investigation.",
    "categories": [
      "cs.CL",
      "cs.AI",
      "68T50, 68T07",
      "I.2.0; I.2.7"
    ],
    "published": "2025-10-27T20:26:30Z",
    "authors": [
      "Cameron Berg",
      "Diogo de Lucena",
      "Judd Rosenblatt"
    ],
    "pdf_url": "http://arxiv.org/pdf/2510.24797v2"
  },
  {
    "id": "2510.23824v1",
    "title": "Decentralized Multi-Agent Goal Assignment for Path Planning using Large\n  Language Models",
    "abstract": "Coordinating multiple autonomous agents in shared environments under\ndecentralized conditions is a long-standing challenge in robotics and\nartificial intelligence. This work addresses the problem of decentralized goal\nassignment for multi-agent path planning, where agents independently generate\nranked preferences over goals based on structured representations of the\nenvironment, including grid visualizations and scenario data. After this\nreasoning phase, agents exchange their goal rankings, and assignments are\ndetermined by a fixed, deterministic conflict-resolution rule (e.g., agent\nindex ordering), without negotiation or iterative coordination. We\nsystematically compare greedy heuristics, optimal assignment, and large\nlanguage model (LLM)-based agents in fully observable grid-world settings. Our\nresults show that LLM-based agents, when provided with well-designed prompts\nand relevant quantitative information, can achieve near-optimal makespans and\nconsistently outperform traditional heuristics. These findings underscore the\npotential of language models for decentralized goal assignment in multi-agent\npath planning and highlight the importance of information structure in such\nsystems.",
    "categories": [
      "cs.AI"
    ],
    "published": "2025-10-27T20:05:56Z",
    "authors": [
      "Murad Ismayilov",
      "Edwin Meriaux",
      "Shuo Wen",
      "Gregory Dudek"
    ],
    "pdf_url": "http://arxiv.org/pdf/2510.23824v1"
  },
  {
    "id": "2510.23822v1",
    "title": "ReCAP: Recursive Context-Aware Reasoning and Planning for Large Language\n  Model Agents",
    "abstract": "Long-horizon tasks requiring multi-step reasoning and dynamic re-planning\nremain challenging for large language models (LLMs). Sequential prompting\nmethods are prone to context drift, loss of goal information, and recurrent\nfailure cycles, while hierarchical prompting methods often weaken cross-level\ncontinuity or incur substantial runtime overhead. We introduce ReCAP (Recursive\nContext-Aware Reasoning and Planning), a hierarchical framework with shared\ncontext for reasoning and planning in LLMs. ReCAP combines three key\nmechanisms: (i) plan-ahead decomposition, in which the model generates a full\nsubtask list, executes the first item, and refines the remainder; (ii)\nstructured re-injection of parent plans, maintaining consistent multi-level\ncontext during recursive return; and (iii) memory-efficient execution, bounding\nthe active prompt so costs scale linearly with task depth. Together these\nmechanisms align high-level goals with low-level actions, reduce redundant\nprompting, and preserve coherent context updates across recursion. Experiments\ndemonstrate that ReCAP substantially improves subgoal alignment and success\nrates on various long-horizon reasoning benchmarks, achieving a 32% gain on\nsynchronous Robotouille and a 29% improvement on asynchronous Robotouille under\nthe strict pass@1 protocol.",
    "categories": [
      "cs.AI"
    ],
    "published": "2025-10-27T20:03:55Z",
    "authors": [
      "Zhenyu Zhang",
      "Tianyi Chen",
      "Weiran Xu",
      "Alex Pentland",
      "Jiaxin Pei"
    ],
    "pdf_url": "http://arxiv.org/pdf/2510.23822v1"
  },
  {
    "id": "2510.23807v2",
    "title": "Why Foundation Models in Pathology Are Failing",
    "abstract": "In non-medical domains, foundation models (FMs) have revolutionized computer\nvision and language processing through large-scale self-supervised and\nmultimodal learning. Consequently, their rapid adoption in computational\npathology was expected to deliver comparable breakthroughs in cancer diagnosis,\nprognostication, and multimodal retrieval. However, recent systematic\nevaluations reveal fundamental weaknesses: low diagnostic accuracy, poor\nrobustness, geometric instability, heavy computational demands, and concerning\nsafety vulnerabilities. This short paper examines these shortcomings and argues\nthat they stem from deeper conceptual mismatches between the assumptions\nunderlying generic foundation modeling in mainstream AI and the intrinsic\ncomplexity of human tissue. Seven interrelated causes are identified:\nbiological complexity, ineffective self-supervision, overgeneralization,\nexcessive architectural complexity, lack of domain-specific innovation,\ninsufficient data, and a fundamental design flaw related to tissue patch size.\nThese findings suggest that current pathology foundation models remain\nconceptually misaligned with the nature of tissue morphology and call for a\nfundamental rethinking of the paradigm itself.",
    "categories": [
      "cs.AI",
      "cs.CV"
    ],
    "published": "2025-10-27T19:44:52Z",
    "authors": [
      "Hamid R. Tizhoosh"
    ],
    "pdf_url": "http://arxiv.org/pdf/2510.23807v2"
  },
  {
    "id": "2510.23798v1",
    "title": "A geometric and deep learning reproducible pipeline for monitoring\n  floating anthropogenic debris in urban rivers using in situ cameras",
    "abstract": "The proliferation of floating anthropogenic debris in rivers has emerged as a\npressing environmental concern, exerting a detrimental influence on\nbiodiversity, water quality, and human activities such as navigation and\nrecreation. The present study proposes a novel methodological framework for the\nmonitoring the aforementioned waste, utilising fixed, in-situ cameras. This\nstudy provides two key contributions: (i) the continuous quantification and\nmonitoring of floating debris using deep learning and (ii) the identification\nof the most suitable deep learning model in terms of accuracy and inference\nspeed under complex environmental conditions. These models are tested in a\nrange of environmental conditions and learning configurations, including\nexperiments on biases related to data leakage. Furthermore, a geometric model\nis implemented to estimate the actual size of detected objects from a 2D image.\nThis model takes advantage of both intrinsic and extrinsic characteristics of\nthe camera. The findings of this study underscore the significance of the\ndataset constitution protocol, particularly with respect to the integration of\nnegative images and the consideration of temporal leakage. In conclusion, the\nfeasibility of metric object estimation using projective geometry coupled with\nregression corrections is demonstrated. This approach paves the way for the\ndevelopment of robust, low-cost, automated monitoring systems for urban aquatic\nenvironments.",
    "categories": [
      "cs.CV",
      "cs.AI"
    ],
    "published": "2025-10-27T19:29:14Z",
    "authors": [
      "Gauthier Grimmer",
      "Romain Wenger",
      "Cl\u00e9ment Flint",
      "Germain Forestier",
      "Gilles Rixhon",
      "Valentin Chardon"
    ],
    "pdf_url": "http://arxiv.org/pdf/2510.23798v1"
  },
  {
    "id": "2510.23785v1",
    "title": "CountFormer: A Transformer Framework for Learning Visual Repetition and\n  Structure in Class-Agnostic Object Counting",
    "abstract": "Humans can effortlessly count diverse objects by perceiving visual repetition\nand structural relationships rather than relying on class identity. However,\nmost existing counting models fail to replicate this ability; they often\nmiscount when objects exhibit complex shapes, internal symmetry, or overlapping\ncomponents. In this work, we introduce CountFormer, a transformer-based\nframework that learns to recognize repetition and structural coherence for\nclass-agnostic object counting. Built upon the CounTR architecture, our model\nreplaces its visual encoder with the self-supervised foundation model DINOv2,\nwhich produces richer and spatially consistent feature representations. We\nfurther incorporate positional embedding fusion to preserve geometric\nrelationships before decoding these features into density maps through a\nlightweight convolutional decoder. Evaluated on the FSC-147 dataset, our model\nachieves performance comparable to current state-of-the-art methods while\ndemonstrating superior accuracy on structurally intricate or densely packed\nscenes. Our findings indicate that integrating foundation models such as DINOv2\nenables counting systems to approach human-like structural perception,\nadvancing toward a truly general and exemplar-free counting paradigm.",
    "categories": [
      "cs.CV",
      "cs.AI"
    ],
    "published": "2025-10-27T19:16:02Z",
    "authors": [
      "Md Tanvir Hossain",
      "Akif Islam",
      "Mohd Ruhul Ameen"
    ],
    "pdf_url": "http://arxiv.org/pdf/2510.23785v1"
  },
  {
    "id": "2510.23775v1",
    "title": "Explainable Detection of AI-Generated Images with Artifact Localization\n  Using Faster-Than-Lies and Vision-Language Models for Edge Devices",
    "abstract": "The increasing realism of AI-generated imagery poses challenges for verifying\nvisual authenticity. We present an explainable image authenticity detection\nsystem that combines a lightweight convolutional classifier\n(\"Faster-Than-Lies\") with a Vision-Language Model (Qwen2-VL-7B) to classify,\nlocalize, and explain artifacts in 32x32 images. Our model achieves 96.5%\naccuracy on the extended CiFAKE dataset augmented with adversarial\nperturbations and maintains an inference time of 175ms on 8-core CPUs, enabling\ndeployment on local or edge devices. Using autoencoder-based reconstruction\nerror maps, we generate artifact localization heatmaps, which enhance\ninterpretability for both humans and the VLM. We further categorize 70 visual\nartifact types into eight semantic groups and demonstrate explainable text\ngeneration for each detected anomaly. This work highlights the feasibility of\ncombining visual and linguistic reasoning for interpretable authenticity\ndetection in low-resolution imagery and outlines potential cross-domain\napplications in forensics, industrial inspection, and social media moderation.",
    "categories": [
      "cs.CV",
      "cs.AI",
      "eess.IV"
    ],
    "published": "2025-10-27T19:01:24Z",
    "authors": [
      "Aryan Mathur",
      "Asaduddin Ahmed",
      "Pushti Amit Vasoya",
      "Simeon Kandan Sonar",
      "Yasir Z",
      "Madesh Kuppusamy"
    ],
    "pdf_url": "http://arxiv.org/pdf/2510.23775v1"
  },
  {
    "id": "2510.23772v1",
    "title": "Evaluating In Silico Creativity: An Expert Review of AI Chess\n  Compositions",
    "abstract": "The rapid advancement of Generative AI has raised significant questions\nregarding its ability to produce creative and novel outputs. Our recent work\ninvestigates this question within the domain of chess puzzles and presents an\nAI system designed to generate puzzles characterized by aesthetic appeal,\nnovelty, counter-intuitive and unique solutions. We briefly discuss our method\nbelow and refer the reader to the technical paper for more details. To assess\nour system's creativity, we presented a curated booklet of AI-generated puzzles\nto three world-renowned experts: International Master for chess compositions\nAmatzia Avni, Grandmaster Jonathan Levitt, and Grandmaster Matthew Sadler. All\nthree are noted authors on chess aesthetics and the evolving role of computers\nin the game. They were asked to select their favorites and explain what made\nthem appealing, considering qualities such as their creativity, level of\nchallenge, or aesthetic design.",
    "categories": [
      "cs.AI",
      "cs.LG"
    ],
    "published": "2025-10-27T19:00:02Z",
    "authors": [
      "Vivek Veeriah",
      "Federico Barbero",
      "Marcus Chiam",
      "Xidong Feng",
      "Michael Dennis",
      "Ryan Pachauri",
      "Thomas Tumiel",
      "Johan Obando-Ceron",
      "Jiaxin Shi",
      "Shaobo Hou",
      "Satinder Singh",
      "Nenad Toma\u0161ev",
      "Tom Zahavy"
    ],
    "pdf_url": "http://arxiv.org/pdf/2510.23772v1"
  },
  {
    "id": "2510.23761v1",
    "title": "TDFlow: Agentic Workflows for Test Driven Software Engineering",
    "abstract": "We introduce TDFlow, a novel test-driven agentic workflow that frames\nrepository-scale software engineering as a test-resolution task, specifically\ndesigned to solve human-written tests. Given a set of tests, TDFlow repeatedly\nproposes, revises, and debugs repository-scale patches using precisely\nengineered sub-agents and tightly constrained tools. The workflow decomposes\nsoftware engineering program repair into four components governed by respective\nsub-agents. This simple, forced decoupling of patch proposing, debugging, patch\nrevision, and optional test generation (1) reduces long-context burden on any\nindividual sub-agent, (2) focuses each sub-agent on specific, pre-defined\nsub-tasks, and (3) allows for specialized performance improvement on specific\nsub-tasks. When provided human-written tests, TDFlow attains 88.8% pass rate on\nSWE-Bench Lite (an absolute improvement of 27.8% over the next best system) and\n94.3% on SWE-Bench Verified. Manual inspection of the 800 TDFlow runs within\nSWE-Bench Lite and Verified uncover only 7 instances of test hacking, which\nwere subsequently counted as failures. Furthermore, we show that the primary\nobstacle to human-level software engineering performance lies within writing\nsuccessful reproduction tests. We envision a human-LLM interactive system\npowered by TDFlow where human developers write tests solved by LLM systems.\nTogether, these results indicate that modern LLMs, when embedded in a narrowly\nengineered, test-driven workflow, already achieve human-level test resolution\n-- with the final frontier for fully autonomous repository repair being the\naccurate generation of valid reproduction tests.",
    "categories": [
      "cs.SE",
      "cs.AI",
      "cs.MA"
    ],
    "published": "2025-10-27T18:44:59Z",
    "authors": [
      "Kevin Han",
      "Siddharth Maddikayala",
      "Tim Knappe",
      "Om Patel",
      "Austen Liao",
      "Amir Barati Farimani"
    ],
    "pdf_url": "http://arxiv.org/pdf/2510.23761v1"
  },
  {
    "id": "2510.23756v1",
    "title": "Explaining Robustness to Catastrophic Forgetting Through Incremental\n  Concept Formation",
    "abstract": "Catastrophic forgetting remains a central challenge in continual learning,\nwhere models are required to integrate new knowledge over time without losing\nwhat they have previously learned. In prior work, we introduced Cobweb/4V, a\nhierarchical concept formation model that exhibited robustness to catastrophic\nforgetting in visual domains. Motivated by this robustness, we examine three\nhypotheses regarding the factors that contribute to such stability: (1)\nadaptive structural reorganization enhances knowledge retention, (2) sparse and\nselective updates reduce interference, and (3) information-theoretic learning\nbased on sufficiency statistics provides advantages over gradient-based\nbackpropagation. To test these hypotheses, we compare Cobweb/4V with neural\nbaselines, including CobwebNN, a neural implementation of the Cobweb framework\nintroduced in this work. Experiments on datasets of varying complexity (MNIST,\nFashion-MNIST, MedMNIST, and CIFAR-10) show that adaptive restructuring\nenhances learning plasticity, sparse updates help mitigate interference, and\nthe information-theoretic learning process preserves prior knowledge without\nrevisiting past data. Together, these findings provide insight into mechanisms\nthat can mitigate catastrophic forgetting and highlight the potential of\nconcept-based, information-theoretic approaches for building stable and\nadaptive continual learning systems.",
    "categories": [
      "cs.LG",
      "cs.AI"
    ],
    "published": "2025-10-27T18:41:25Z",
    "authors": [
      "Nicki Barari",
      "Edward Kim",
      "Christopher MacLellan"
    ],
    "pdf_url": "http://arxiv.org/pdf/2510.23756v1"
  },
  {
    "id": "2510.23751v1",
    "title": "Debiasing Reward Models by Representation Learning with Guarantees",
    "abstract": "Recent alignment techniques, such as reinforcement learning from human\nfeedback, have been widely adopted to align large language models with human\npreferences by learning and leveraging reward models. In practice, these models\noften exploit spurious correlations, involving, e.g., response length,\ndiscrimination, sycophancy, and conceptual bias, which is a problem that has\nreceived increasing attention. In this work, we propose a principled framework\nthat mitigates these biases in reward models while preserving the underlying\nfactors that reflect intended preferences. We first provide a formulation of\nthe data-generating process, assuming that the observed data (e.g., text) is\ngenerated from both spurious and non-spurious latent variables. We show that,\ninterestingly, these non-spurious latent variables can be theoretically\nidentified from data, regardless of whether a surrogate for the spurious latent\nvariables is available. This further inspires a practical method that uses\nvariational inference to recover these variables and leverages them to train\nreward models. Experiments on synthetic and real-world datasets demonstrate\nthat our method effectively mitigates spurious correlation issues and yields\nmore robust reward models.",
    "categories": [
      "cs.LG",
      "cs.AI",
      "stat.ML"
    ],
    "published": "2025-10-27T18:37:57Z",
    "authors": [
      "Ignavier Ng",
      "Patrick Bl\u00f6baum",
      "Siddharth Bhandari",
      "Kun Zhang",
      "Shiva Kasiviswanathan"
    ],
    "pdf_url": "http://arxiv.org/pdf/2510.23751v1"
  },
  {
    "id": "2510.25779v1",
    "title": "Magentic Marketplace: An Open-Source Environment for Studying Agentic\n  Markets",
    "abstract": "As LLM agents advance, they are increasingly mediating economic decisions,\nranging from product discovery to transactions, on behalf of users. Such\napplications promise benefits but also raise many questions about agent\naccountability and value for users. Addressing these questions requires\nunderstanding how agents behave in realistic market conditions. However,\nprevious research has largely evaluated agents in constrained settings, such as\nsingle-task marketplaces (e.g., negotiation) or structured two-agent\ninteractions. Real-world markets are fundamentally different: they require\nagents to handle diverse economic activities and coordinate within large,\ndynamic ecosystems where multiple agents with opaque behaviors may engage in\nopen-ended dialogues. To bridge this gap, we investigate two-sided agentic\nmarketplaces where Assistant agents represent consumers and Service agents\nrepresent competing businesses. To study these interactions safely, we develop\nMagentic-Marketplace -- a simulated environment where Assistants and Services\ncan operate. This environment enables us to study key market dynamics: the\nutility agents achieve, behavioral biases, vulnerability to manipulation, and\nhow search mechanisms shape market outcomes. Our experiments show that frontier\nmodels can approach optimal welfare -- but only under ideal search conditions.\nPerformance degrades sharply with scale, and all models exhibit severe\nfirst-proposal bias, creating 10-30x advantages for response speed over\nquality. These findings reveal how behaviors emerge across market conditions,\ninforming the design of fair and efficient agentic marketplaces.",
    "categories": [
      "cs.MA",
      "cs.AI"
    ],
    "published": "2025-10-27T18:35:59Z",
    "authors": [
      "Gagan Bansal",
      "Wenyue Hua",
      "Zezhou Huang",
      "Adam Fourney",
      "Amanda Swearngin",
      "Will Epperson",
      "Tyler Payne",
      "Jake M. Hofman",
      "Brendan Lucier",
      "Chinmay Singh",
      "Markus Mobius",
      "Akshay Nambi",
      "Archana Yadav",
      "Kevin Gao",
      "David M. Rothschild",
      "Aleksandrs Slivkins",
      "Daniel G. Goldstein",
      "Hussein Mozannar",
      "Nicole Immorlica",
      "Maya Murad",
      "Matthew Vogel",
      "Subbarao Kambhampati",
      "Eric Horvitz",
      "Saleema Amershi"
    ],
    "pdf_url": "http://arxiv.org/pdf/2510.25779v1"
  },
  {
    "id": "2510.23746v1",
    "title": "Test-Time Tuned Language Models Enable End-to-end De Novo Molecular\n  Structure Generation from MS/MS Spectra",
    "abstract": "Tandem Mass Spectrometry enables the identification of unknown compounds in\ncrucial fields such as metabolomics, natural product discovery and\nenvironmental analysis. However, current methods rely on database matching from\npreviously observed molecules, or on multi-step pipelines that require\nintermediate fragment or fingerprint prediction. This makes finding the correct\nmolecule highly challenging, particularly for compounds absent from reference\ndatabases. We introduce a framework that, by leveraging test-time tuning,\nenhances the learning of a pre-trained transformer model to address this gap,\nenabling end-to-end de novo molecular structure generation directly from the\ntandem mass spectra and molecular formulae, bypassing manual annotations and\nintermediate steps. We surpass the de-facto state-of-the-art approach DiffMS on\ntwo popular benchmarks NPLIB1 and MassSpecGym by 100% and 20%, respectively.\nTest-time tuning on experimental spectra allows the model to dynamically adapt\nto novel spectra, and the relative performance gain over conventional\nfine-tuning is of 62% on MassSpecGym. When predictions deviate from the ground\ntruth, the generated molecular candidates remain structurally accurate,\nproviding valuable guidance for human interpretation and more reliable\nidentification.",
    "categories": [
      "cs.AI",
      "cs.LG"
    ],
    "published": "2025-10-27T18:25:36Z",
    "authors": [
      "Laura Mismetti",
      "Marvin Alberts",
      "Andreas Krause",
      "Mara Graziani"
    ],
    "pdf_url": "http://arxiv.org/pdf/2510.23746v1"
  },
  {
    "id": "2510.23744v1",
    "title": "Multi-Environment POMDPs: Discrete Model Uncertainty Under Partial\n  Observability",
    "abstract": "Multi-environment POMDPs (ME-POMDPs) extend standard POMDPs with discrete\nmodel uncertainty. ME-POMDPs represent a finite set of POMDPs that share the\nsame state, action, and observation spaces, but may arbitrarily vary in their\ntransition, observation, and reward models. Such models arise, for instance,\nwhen multiple domain experts disagree on how to model a problem. The goal is to\nfind a single policy that is robust against any choice of POMDP within the set,\ni.e., a policy that maximizes the worst-case reward across all POMDPs. We\ngeneralize and expand on existing work in the following way. First, we show\nthat ME-POMDPs can be generalized to POMDPs with sets of initial beliefs, which\nwe call adversarial-belief POMDPs (AB-POMDPs). Second, we show that any\narbitrary ME-POMDP can be reduced to a ME-POMDP that only varies in its\ntransition and reward functions or only in its observation and reward\nfunctions, while preserving (optimal) policies. We then devise exact and\napproximate (point-based) algorithms to compute robust policies for AB-POMDPs,\nand thus ME-POMDPs. We demonstrate that we can compute policies for standard\nPOMDP benchmarks extended to the multi-environment setting.",
    "categories": [
      "cs.AI"
    ],
    "published": "2025-10-27T18:24:11Z",
    "authors": [
      "Eline M. Bovy",
      "Caleb Probine",
      "Marnix Suilen",
      "Ufuk Topcu",
      "Nils Jansen"
    ],
    "pdf_url": "http://arxiv.org/pdf/2510.23744v1"
  },
  {
    "id": "2510.24796v1",
    "title": "Mutual Wanting in Human--AI Interaction: Empirical Evidence from\n  Large-Scale Analysis of GPT Model Transitions",
    "abstract": "The rapid evolution of large language models (LLMs) creates complex\nbidirectional expectations between users and AI systems that are poorly\nunderstood. We introduce the concept of \"mutual wanting\" to analyze these\nexpectations during major model transitions. Through analysis of user comments\nfrom major AI forums and controlled experiments across multiple OpenAI models,\nwe provide the first large-scale empirical validation of bidirectional desire\ndynamics in human-AI interaction. Our findings reveal that nearly half of users\nemploy anthropomorphic language, trust significantly exceeds betrayal language,\nand users cluster into distinct \"mutual wanting\" types. We identify measurable\nexpectation violation patterns and quantify the expectation-reality gap\nfollowing major model releases. Using advanced NLP techniques including\ndual-algorithm topic modeling and multi-dimensional feature extraction, we\ndevelop the Mutual Wanting Alignment Framework (M-WAF) with practical\napplications for proactive user experience management and AI system design.\nThese findings establish mutual wanting as a measurable phenomenon with clear\nimplications for building more trustworthy and relationally-aware AI systems.",
    "categories": [
      "cs.CY",
      "cs.AI"
    ],
    "published": "2025-10-27T18:16:02Z",
    "authors": [
      "HaoYang Shang",
      "Xuan Liu"
    ],
    "pdf_url": "http://arxiv.org/pdf/2510.24796v1"
  },
  {
    "id": "2510.23734v1",
    "title": "AI and the Decentering of Disciplinary Creativity",
    "abstract": "This paper examines the role of artificial intelligence in scientific\nproblem-solving, with a focus on its implications for disciplinary creativity.\nDrawing on recent work in the philosophy of creativity, I distinguish between\ncreative approaches and creative products, and introduce the concept of\ndisciplinary creativity -the creative application of discipline-specific\nexpertise to a valued problem within that field. Through two cases in\nmathematics, I show that while computation can extend disciplinary creativity,\ncertain approaches involving AI can serve to displace it. This displacement has\nthe potential to alter (and, perhaps, diminish) the value of scientific\npursuit.",
    "categories": [
      "cs.AI"
    ],
    "published": "2025-10-27T18:05:41Z",
    "authors": [
      "Eamon Duede"
    ],
    "pdf_url": "http://arxiv.org/pdf/2510.23734v1"
  },
  {
    "id": "2510.23606v1",
    "title": "Variational Masked Diffusion Models",
    "abstract": "Masked diffusion models have recently emerged as a flexible framework for\ndiscrete generative modeling. However, a key limitation of standard masked\ndiffusion is its inability to effectively capture dependencies among tokens\nthat are predicted concurrently, leading to degraded generation quality when\ndependencies among tokens are important. To explicitly model dependencies among\ntokens, we propose Variational Masked Diffusion (VMD), a framework that\nintroduces latent variables into the masked diffusion process. Through\ncontrolled experiments on synthetic datasets, we demonstrate that VMD\nsuccessfully learns dependencies that conventional masked diffusion fails to\ncapture. We further validate the effectiveness of our approach on Sudoku\npuzzles and text datasets, where learning of dependencies among tokens improves\nglobal consistency. Across these domains, VMD enhances both generation quality\nand dependency awareness, highlighting the value of integrating variational\ninference into masked diffusion. Our code is available at:\nhttps://riccizz.github.io/VMD.",
    "categories": [
      "cs.LG",
      "cs.AI",
      "cs.CL"
    ],
    "published": "2025-10-27T17:59:57Z",
    "authors": [
      "Yichi Zhang",
      "Alex Schwing",
      "Zhizhen Zhao"
    ],
    "pdf_url": "http://arxiv.org/pdf/2510.23606v1"
  },
  {
    "id": "2510.23605v1",
    "title": "Track, Inpaint, Resplat: Subject-driven 3D and 4D Generation with\n  Progressive Texture Infilling",
    "abstract": "Current 3D/4D generation methods are usually optimized for photorealism,\nefficiency, and aesthetics. However, they often fail to preserve the semantic\nidentity of the subject across different viewpoints. Adapting generation\nmethods with one or few images of a specific subject (also known as\nPersonalization or Subject-driven generation) allows generating visual content\nthat align with the identity of the subject. However, personalized 3D/4D\ngeneration is still largely underexplored. In this work, we introduce TIRE\n(Track, Inpaint, REsplat), a novel method for subject-driven 3D/4D generation.\nIt takes an initial 3D asset produced by an existing 3D generative model as\ninput and uses video tracking to identify the regions that need to be modified.\nThen, we adopt a subject-driven 2D inpainting model for progressively infilling\nthe identified regions. Finally, we resplat the modified 2D multi-view\nobservations back to 3D while still maintaining consistency. Extensive\nexperiments demonstrate that our approach significantly improves identity\npreservation in 3D/4D generation compared to state-of-the-art methods. Our\nproject website is available at\nhttps://zsh2000.github.io/track-inpaint-resplat.github.io/.",
    "categories": [
      "cs.CV",
      "cs.AI",
      "cs.GR",
      "cs.LG",
      "cs.RO"
    ],
    "published": "2025-10-27T17:59:51Z",
    "authors": [
      "Shuhong Zheng",
      "Ashkan Mirzaei",
      "Igor Gilitschenski"
    ],
    "pdf_url": "http://arxiv.org/pdf/2510.23605v1"
  },
  {
    "id": "2510.23693v1",
    "title": "On the Societal Impact of Machine Learning",
    "abstract": "This PhD thesis investigates the societal impact of machine learning (ML). ML\nincreasingly informs consequential decisions and recommendations, significantly\naffecting many aspects of our lives. As these data-driven systems are often\ndeveloped without explicit fairness considerations, they carry the risk of\ndiscriminatory effects. The contributions in this thesis enable more\nappropriate measurement of fairness in ML systems, systematic decomposition of\nML systems to anticipate bias dynamics, and effective interventions that reduce\nalgorithmic discrimination while maintaining system utility. I conclude by\ndiscussing ongoing challenges and future research directions as ML systems,\nincluding generative artificial intelligence, become increasingly integrated\ninto society. This work offers a foundation for ensuring that ML's societal\nimpact aligns with broader social values.",
    "categories": [
      "cs.LG",
      "cs.AI",
      "cs.CY"
    ],
    "published": "2025-10-27T17:59:48Z",
    "authors": [
      "Joachim Baumann"
    ],
    "pdf_url": "http://arxiv.org/pdf/2510.23693v1"
  },
  {
    "id": "2510.23601v1",
    "title": "Alita-G: Self-Evolving Generative Agent for Agent Generation",
    "abstract": "Large language models (LLMs) have been shown to perform better when\nscaffolded into agents with memory, tools, and feedback. Beyond this,\nself-evolving agents have emerged, but current work largely limits adaptation\nto prompt rewriting or failure retries. Therefore, we present ALITA-G, a\nself-evolution framework that transforms a general-purpose agent into a domain\nexpert by systematically generating, abstracting, and curating Model Context\nProtocol (MCP) tools. In this framework, a generalist agent executes a curated\nsuite of target-domain tasks and synthesizes candidate MCPs from successful\ntrajectories. These are then abstracted to parameterized primitives and\nconsolidated into an MCP Box. At inference time, ALITA-G performs\nretrieval-augmented MCP selection with the help of each tool's descriptions and\nuse cases, before executing an agent equipped with the MCP Executor. Across\nseveral benchmarks GAIA, PathVQA, and Humanity's Last Exam, ALITA-G attains\nstrong gains while reducing computation costs. On GAIA validation, it achieves\n83.03% pass@1 and 89.09% pass@3, establishing a new state-of-the-art result\nwhile reducing mean tokens per example by approximately 15% relative to a\nstrong baseline agent. ALITA-G thus provides a principled pathway from\ngeneralist capability to reusable, domain-specific competence, improving both\naccuracy and efficiency on complex reasoning tasks.",
    "categories": [
      "cs.AI"
    ],
    "published": "2025-10-27T17:59:14Z",
    "authors": [
      "Jiahao Qiu",
      "Xuan Qi",
      "Hongru Wang",
      "Xinzhe Juan",
      "Yimin Wang",
      "Zelin Zhao",
      "Jiayi Geng",
      "Jiacheng Guo",
      "Peihang Li",
      "Jingzhe Shi",
      "Shilong Liu",
      "Mengdi Wang"
    ],
    "pdf_url": "http://arxiv.org/pdf/2510.23601v1"
  },
  {
    "id": "2510.23595v3",
    "title": "Multi-Agent Evolve: LLM Self-Improve through Co-evolution",
    "abstract": "Reinforcement Learning (RL) has demonstrated significant potential in\nenhancing the reasoning capabilities of large language models (LLMs). However,\nthe success of RL for LLMs heavily relies on human-curated datasets and\nverifiable rewards, which limit their scalability and generality. Recent\nSelf-Play RL methods, inspired by the success of the paradigm in games and Go,\naim to enhance LLM reasoning capabilities without human-annotated data.\nHowever, their methods primarily depend on a grounded environment for feedback\n(e.g., a Python interpreter or a game engine); extending them to general\ndomains remains challenging. To address these challenges, we propose\nMulti-Agent Evolve (MAE), a framework that enables LLMs to self-evolve in\nsolving diverse tasks, including mathematics, reasoning, and general knowledge\nQ&A. The core design of MAE is based on a triplet of interacting agents\n(Proposer, Solver, Judge) that are instantiated from a single LLM, and applies\nreinforcement learning to optimize their behaviors. The Proposer generates\nquestions, the Solver attempts solutions, and the Judge evaluates both while\nco-evolving. Experiments on Qwen2.5-3B-Instruct demonstrate that MAE achieves\nan average improvement of 4.54% on multiple benchmarks. These results highlight\nMAE as a scalable, data-efficient method for enhancing the general reasoning\nabilities of LLMs with minimal reliance on human-curated supervision.",
    "categories": [
      "cs.AI"
    ],
    "published": "2025-10-27T17:58:02Z",
    "authors": [
      "Yixing Chen",
      "Yiding Wang",
      "Siqi Zhu",
      "Haofei Yu",
      "Tao Feng",
      "Muhan Zhang",
      "Mostofa Patwary",
      "Jiaxuan You"
    ],
    "pdf_url": "http://arxiv.org/pdf/2510.23595v3"
  },
  {
    "id": "2510.24795v1",
    "title": "A Survey on Efficient Vision-Language-Action Models",
    "abstract": "Vision-Language-Action models (VLAs) represent a significant frontier in\nembodied intelligence, aiming to bridge digital knowledge with physical-world\ninteraction. While these models have demonstrated remarkable generalist\ncapabilities, their deployment is severely hampered by the substantial\ncomputational and data requirements inherent to their underlying large-scale\nfoundation models. Motivated by the urgent need to address these challenges,\nthis survey presents the first comprehensive review of Efficient\nVision-Language-Action models (Efficient VLAs) across the entire\ndata-model-training process. Specifically, we introduce a unified taxonomy to\nsystematically organize the disparate efforts in this domain, categorizing\ncurrent techniques into three core pillars: (1) Efficient Model Design,\nfocusing on efficient architectures and model compression; (2) Efficient\nTraining, which reduces computational burdens during model learning; and (3)\nEfficient Data Collection, which addresses the bottlenecks in acquiring and\nutilizing robotic data. Through a critical review of state-of-the-art methods\nwithin this framework, this survey not only establishes a foundational\nreference for the community but also summarizes representative applications,\ndelineates key challenges, and charts a roadmap for future research. We\nmaintain a continuously updated project page to track our latest developments:\nhttps://evla-survey.github.io/",
    "categories": [
      "cs.CV",
      "cs.AI",
      "cs.LG",
      "cs.RO"
    ],
    "published": "2025-10-27T17:57:33Z",
    "authors": [
      "Zhaoshu Yu",
      "Bo Wang",
      "Pengpeng Zeng",
      "Haonan Zhang",
      "Ji Zhang",
      "Lianli Gao",
      "Jingkuan Song",
      "Nicu Sebe",
      "Heng Tao Shen"
    ],
    "pdf_url": "http://arxiv.org/pdf/2510.24795v1"
  },
  {
    "id": "2510.23587v1",
    "title": "A Survey of Data Agents: Emerging Paradigm or Overstated Hype?",
    "abstract": "The rapid advancement of large language models (LLMs) has spurred the\nemergence of data agents--autonomous systems designed to orchestrate Data + AI\necosystems for tackling complex data-related tasks. However, the term \"data\nagent\" currently suffers from terminological ambiguity and inconsistent\nadoption, conflating simple query responders with sophisticated autonomous\narchitectures. This terminological ambiguity fosters mismatched user\nexpectations, accountability challenges, and barriers to industry growth.\nInspired by the SAE J3016 standard for driving automation, this survey\nintroduces the first systematic hierarchical taxonomy for data agents,\ncomprising six levels that delineate and trace progressive shifts in autonomy,\nfrom manual operations (L0) to a vision of generative, fully autonomous data\nagents (L5), thereby clarifying capability boundaries and responsibility\nallocation. Through this lens, we offer a structured review of existing\nresearch arranged by increasing autonomy, encompassing specialized data agents\nfor data management, preparation, and analysis, alongside emerging efforts\ntoward versatile, comprehensive systems with enhanced autonomy. We further\nanalyze critical evolutionary leaps and technical gaps for advancing data\nagents, especially the ongoing L2-to-L3 transition, where data agents evolve\nfrom procedural execution to autonomous orchestration. Finally, we conclude\nwith a forward-looking roadmap, envisioning the advent of proactive, generative\ndata agents.",
    "categories": [
      "cs.DB",
      "cs.AI"
    ],
    "published": "2025-10-27T17:54:07Z",
    "authors": [
      "Yizhang Zhu",
      "Liangwei Wang",
      "Chenyu Yang",
      "Xiaotian Lin",
      "Boyan Li",
      "Wei Zhou",
      "Xinyu Liu",
      "Zhangyang Peng",
      "Tianqi Luo",
      "Yu Li",
      "Chengliang Chai",
      "Chong Chen",
      "Shimin Di",
      "Ju Fan",
      "Ji Sun",
      "Nan Tang",
      "Fugee Tsung",
      "Jiannan Wang",
      "Chenglin Wu",
      "Yanwei Xu",
      "Shaolei Zhang",
      "Yong Zhang",
      "Xuanhe Zhou",
      "Guoliang Li",
      "Yuyu Luo"
    ],
    "pdf_url": "http://arxiv.org/pdf/2510.23587v1"
  },
  {
    "id": "2510.23585v1",
    "title": "Hope Speech Detection in Social Media English Corpora: Performance of\n  Traditional and Transformer Models",
    "abstract": "The identification of hope speech has become a promised NLP task, considering\nthe need to detect motivational expressions of agency and goal-directed\nbehaviour on social media platforms. This proposal evaluates traditional\nmachine learning models and fine-tuned transformers for a previously split hope\nspeech dataset as train, development and test set. On development test, a\nlinear-kernel SVM and logistic regression both reached a macro-F1 of 0.78; SVM\nwith RBF kernel reached 0.77, and Na\\\"ive Bayes hit 0.75. Transformer models\ndelivered better results, the best model achieved weighted precision of 0.82,\nweighted recall of 0.80, weighted F1 of 0.79, macro F1 of 0.79, and 0.80\naccuracy. These results suggest that while optimally configured traditional\nmachine learning models remain agile, transformer architectures detect some\nsubtle semantics of hope to achieve higher precision and recall in hope speech\ndetection, suggesting that larges transformers and LLMs could perform better in\nsmall datasets.",
    "categories": [
      "cs.CL",
      "cs.AI"
    ],
    "published": "2025-10-27T17:53:40Z",
    "authors": [
      "Luis Ramos",
      "Hiram Calvo",
      "Olga Kolesnikova"
    ],
    "pdf_url": "http://arxiv.org/pdf/2510.23585v1"
  },
  {
    "id": "2510.23578v1",
    "title": "Reduced AI Acceptance After the Generative AI Boom: Evidence From a\n  Two-Wave Survey Study",
    "abstract": "The rapid adoption of generative artificial intelligence (GenAI) technologies\nhas led many organizations to integrate AI into their products and services,\noften without considering user preferences. Yet, public attitudes toward AI\nuse, especially in impactful decision-making scenarios, are underexplored.\nUsing a large-scale two-wave survey study (n_wave1=1514, n_wave2=1488)\nrepresentative of the Swiss population, we examine shifts in public attitudes\ntoward AI before and after the launch of ChatGPT. We find that the GenAI boom\nis significantly associated with reduced public acceptance of AI (see Figure 1)\nand increased demand for human oversight in various decision-making contexts.\nThe proportion of respondents finding AI \"not acceptable at all\" increased from\n23% to 30%, while support for human-only decision-making rose from 18% to 26%.\nThese shifts have amplified existing social inequalities in terms of widened\neducational, linguistic, and gender gaps post-boom. Our findings challenge\nindustry assumptions about public readiness for AI deployment and highlight the\ncritical importance of aligning technological development with evolving public\npreferences.",
    "categories": [
      "cs.AI"
    ],
    "published": "2025-10-27T17:47:58Z",
    "authors": [
      "Joachim Baumann",
      "Aleksandra Urman",
      "Ulrich Leicht-Deobald",
      "Zachary J. Roman",
      "Anik\u00f3 Hann\u00e1k",
      "Markus Christen"
    ],
    "pdf_url": "http://arxiv.org/pdf/2510.23578v1"
  },
  {
    "id": "2510.23576v1",
    "title": "UrbanVLA: A Vision-Language-Action Model for Urban Micromobility",
    "abstract": "Urban micromobility applications, such as delivery robots, demand reliable\nnavigation across large-scale urban environments while following long-horizon\nroute instructions. This task is particularly challenging due to the dynamic\nand unstructured nature of real-world city areas, yet most existing navigation\nmethods remain tailored to short-scale and controllable scenarios. Effective\nurban micromobility requires two complementary levels of navigation skills:\nlow-level capabilities such as point-goal reaching and obstacle avoidance, and\nhigh-level capabilities, such as route-visual alignment. To this end, we\npropose UrbanVLA, a route-conditioned Vision-Language-Action (VLA) framework\ndesigned for scalable urban navigation. Our method explicitly aligns noisy\nroute waypoints with visual observations during execution, and subsequently\nplans trajectories to drive the robot. To enable UrbanVLA to master both levels\nof navigation, we employ a two-stage training pipeline. The process begins with\nSupervised Fine-Tuning (SFT) using simulated environments and trajectories\nparsed from web videos. This is followed by Reinforcement Fine-Tuning (RFT) on\na mixture of simulation and real-world data, which enhances the model's safety\nand adaptability in real-world settings. Experiments demonstrate that UrbanVLA\nsurpasses strong baselines by more than 55% in the SocialNav task on MetaUrban.\nFurthermore, UrbanVLA achieves reliable real-world navigation, showcasing both\nscalability to large-scale urban environments and robustness against real-world\nuncertainties.",
    "categories": [
      "cs.RO",
      "cs.AI",
      "cs.CV"
    ],
    "published": "2025-10-27T17:46:43Z",
    "authors": [
      "Anqi Li",
      "Zhiyong Wang",
      "Jiazhao Zhang",
      "Minghan Li",
      "Yunpeng Qi",
      "Zhibo Chen",
      "Zhizheng Zhang",
      "He Wang"
    ],
    "pdf_url": "http://arxiv.org/pdf/2510.23576v1"
  },
  {
    "id": "2510.23691v1",
    "title": "Game-TARS: Pretrained Foundation Models for Scalable Generalist\n  Multimodal Game Agents",
    "abstract": "We present Game-TARS, a generalist game agent trained with a unified,\nscalable action space anchored to human-aligned native keyboard-mouse inputs.\nUnlike API- or GUI-based approaches, this paradigm enables large-scale\ncontinual pre-training across heterogeneous domains, including OS, web, and\nsimulation games. Game-TARS is pre-trained on over 500B tokens with diverse\ntrajectories and multimodal data. Key techniques include a decaying continual\nloss to reduce causal confusion and an efficient Sparse-Thinking strategy that\nbalances reasoning depth and inference cost. Experiments show that Game-TARS\nachieves about 2 times the success rate over the previous sota model on\nopen-world Minecraft tasks, is close to the generality of fresh humans in\nunseen web 3d games, and outperforms GPT-5, Gemini-2.5-Pro, and Claude-4-Sonnet\nin FPS benchmarks. Scaling results on training-time and test-time confirm that\nthe unified action space sustains improvements when scaled to cross-game and\nmultimodal data. Our results demonstrate that simple, scalable action\nrepresentations combined with large-scale pre-training provide a promising path\ntoward generalist agents with broad computer-use abilities.",
    "categories": [
      "cs.AI"
    ],
    "published": "2025-10-27T17:43:51Z",
    "authors": [
      "Zihao Wang",
      "Xujing Li",
      "Yining Ye",
      "Junjie Fang",
      "Haoming Wang",
      "Longxiang Liu",
      "Shihao Liang",
      "Junting Lu",
      "Zhiyong Wu",
      "Jiazhan Feng",
      "Wanjun Zhong",
      "Zili Li",
      "Yu Wang",
      "Yu Miao",
      "Bo Zhou",
      "Yuanfan Li",
      "Hao Wang",
      "Zhongkai Zhao",
      "Faming Wu",
      "Zhengxuan Jiang",
      "Weihao Tan",
      "Heyuan Yao",
      "Shi Yan",
      "Xiangyang Li",
      "Yitao Liang",
      "Yujia Qin",
      "Guang Shi"
    ],
    "pdf_url": "http://arxiv.org/pdf/2510.23691v1"
  },
  {
    "id": "2510.23571v1",
    "title": "RobotArena $\\infty$: Scalable Robot Benchmarking via Real-to-Sim\n  Translation",
    "abstract": "The pursuit of robot generalists - instructable agents capable of performing\ndiverse tasks across diverse environments - demands rigorous and scalable\nevaluation. Yet real-world testing of robot policies remains fundamentally\nconstrained: it is labor-intensive, slow, unsafe at scale, and difficult to\nreproduce. Existing simulation benchmarks are similarly limited, as they train\nand test policies within the same synthetic domains and cannot assess models\ntrained from real-world demonstrations or alternative simulation environments.\nAs policies expand in scope and complexity, these barriers only intensify,\nsince defining \"success\" in robotics often hinges on nuanced human judgments of\nexecution quality. In this paper, we introduce a new benchmarking framework\nthat overcomes these challenges by shifting VLA evaluation into large-scale\nsimulated environments augmented with online human feedback. Leveraging\nadvances in vision-language models, 2D-to-3D generative modeling, and\ndifferentiable rendering, our approach automatically converts video\ndemonstrations from widely used robot datasets into simulated counterparts.\nWithin these digital twins, we assess VLA policies using both automated\nVLM-guided scoring and scalable human preference judgments collected from\ncrowdworkers, transforming human involvement from tedious scene setup,\nresetting, and safety supervision into lightweight preference comparisons. To\nmeasure robustness, we systematically perturb simulated environments along\nmultiple axes, such as textures and object placements, stress-testing policy\ngeneralization under controlled variation. The result is a continuously\nevolving, reproducible, and scalable benchmark for real-world trained robot\nmanipulation policies, addressing a critical missing capability in today's\nrobotics landscape.",
    "categories": [
      "cs.RO",
      "cs.AI",
      "cs.CV",
      "cs.LG"
    ],
    "published": "2025-10-27T17:41:38Z",
    "authors": [
      "Yash Jangir",
      "Yidi Zhang",
      "Kashu Yamazaki",
      "Chenyu Zhang",
      "Kuan-Hsun Tu",
      "Tsung-Wei Ke",
      "Lei Ke",
      "Yonatan Bisk",
      "Katerina Fragkiadaki"
    ],
    "pdf_url": "http://arxiv.org/pdf/2510.23571v1"
  },
  {
    "id": "2510.23564v2",
    "title": "ReCode: Unify Plan and Action for Universal Granularity Control",
    "abstract": "Real-world tasks require decisions at varying granularities, and humans excel\nat this by leveraging a unified cognitive representation where planning is\nfundamentally understood as a high-level form of action. However, current Large\nLanguage Model (LLM)-based agents lack this crucial capability to operate\nfluidly across decision granularities. This limitation stems from existing\nparadigms that enforce a rigid separation between high-level planning and\nlow-level action, which impairs dynamic adaptability and limits generalization.\nWe propose ReCode (Recursive Code Generation), a novel paradigm that addresses\nthis limitation by unifying planning and action within a single code\nrepresentation. In this representation, ReCode treats high-level plans as\nabstract placeholder functions, which the agent then recursively decomposes\ninto finer-grained sub-functions until reaching primitive actions. This\nrecursive approach dissolves the rigid boundary between plan and action,\nenabling the agent to dynamically control its decision granularity.\nFurthermore, the recursive structure inherently generates rich,\nmulti-granularity training data, enabling models to learn hierarchical\ndecision-making processes. Extensive experiments show ReCode significantly\nsurpasses advanced baselines in inference performance and demonstrates\nexceptional data efficiency in training, validating our core insight that\nunifying planning and action through recursive code generation is a powerful\nand effective approach to achieving universal granularity control. The code is\navailable at https://github.com/FoundationAgents/ReCode.",
    "categories": [
      "cs.AI",
      "cs.CL",
      "cs.LG"
    ],
    "published": "2025-10-27T17:35:15Z",
    "authors": [
      "Zhaoyang Yu",
      "Jiayi Zhang",
      "Huixue Su",
      "Yufan Zhao",
      "Yifan Wu",
      "Mingyi Deng",
      "Jinyu Xiang",
      "Yizhang Lin",
      "Lingxiao Tang",
      "Yingchao Li",
      "Yuyu Luo",
      "Bang Liu",
      "Chenglin Wu"
    ],
    "pdf_url": "http://arxiv.org/pdf/2510.23564v2"
  },
  {
    "id": "2510.23553v1",
    "title": "OntoPret: An Ontology for the Interpretation of Human Behavior",
    "abstract": "As human machine teaming becomes central to paradigms like Industry 5.0, a\ncritical need arises for machines to safely and effectively interpret complex\nhuman behaviors. A research gap currently exists between techno centric robotic\nframeworks, which often lack nuanced models of human behavior, and descriptive\nbehavioral ontologies, which are not designed for real time, collaborative\ninterpretation. This paper addresses this gap by presenting OntoPret, an\nontology for the interpretation of human behavior. Grounded in cognitive\nscience and a modular engineering methodology, OntoPret provides a formal,\nmachine processable framework for classifying behaviors, including task\ndeviations and deceptive actions. We demonstrate its adaptability across two\ndistinct use cases manufacturing and gameplay and establish the semantic\nfoundations necessary for advanced reasoning about human intentions.",
    "categories": [
      "cs.AI"
    ],
    "published": "2025-10-27T17:28:51Z",
    "authors": [
      "Alexis Ellis",
      "Stacie Severyn",
      "Fjoll\u00eb Novakazi",
      "Hadi Banaee",
      "Cogan Shimizu"
    ],
    "pdf_url": "http://arxiv.org/pdf/2510.23553v1"
  },
  {
    "id": "2510.23538v1",
    "title": "JanusCoder: Towards a Foundational Visual-Programmatic Interface for\n  Code Intelligence",
    "abstract": "The scope of neural code intelligence is rapidly expanding beyond text-based\nsource code to encompass the rich visual outputs that programs generate. This\nvisual dimension is critical for advanced applications like flexible content\ngeneration and precise, program-driven editing of visualizations. However,\nprogress has been impeded by the scarcity of high-quality multimodal code data,\na bottleneck stemming from challenges in synthesis and quality assessment. To\naddress these challenges, we make contributions from both a data and modeling\nperspective. We first introduce a complete synthesis toolkit that leverages\nreciprocal synergies between data modalities to efficiently produce a\nlarge-scale, high-quality corpus spanning from standard charts to complex\ninteractive web UIs and code-driven animations. Leveraging this toolkit, we\nconstruct JanusCode-800K, the largest multimodal code corpus to date. This\npowers the training of our models, JanusCoder and JanusCoderV, which establish\na visual-programmatic interface for generating code from textual instructions,\nvisual inputs, or a combination of both. Our unified model is a departure from\nexisting approaches that build specialized models for isolated tasks. Extensive\nexperiments on both text-centric and vision-centric coding tasks demonstrate\nthe superior performance of the JanusCoder series, with our 7B to 14B scale\nmodels approaching or even exceeding the performance of commercial models.\nFurthermore, extensive analysis provides key insights into harmonizing\nprogrammatic logic with its visual expression. Our code and checkpoints will\nare available at https://github.com/InternLM/JanusCoder.",
    "categories": [
      "cs.AI",
      "cs.CL",
      "cs.CV",
      "cs.SE"
    ],
    "published": "2025-10-27T17:13:49Z",
    "authors": [
      "Qiushi Sun",
      "Jingyang Gong",
      "Yang Liu",
      "Qiaosheng Chen",
      "Lei Li",
      "Kai Chen",
      "Qipeng Guo",
      "Ben Kao",
      "Fei Yuan"
    ],
    "pdf_url": "http://arxiv.org/pdf/2510.23538v1"
  },
  {
    "id": "2510.23532v1",
    "title": "When No Paths Lead to Rome: Benchmarking Systematic Neural Relational\n  Reasoning",
    "abstract": "Designing models that can learn to reason in a systematic way is an important\nand long-standing challenge. In recent years, a wide range of solutions have\nbeen proposed for the specific case of systematic relational reasoning,\nincluding Neuro-Symbolic approaches, variants of the Transformer architecture,\nand specialised Graph Neural Networks. However, existing benchmarks for\nsystematic relational reasoning focus on an overly simplified setting, based on\nthe assumption that reasoning can be reduced to composing relational paths. In\nfact, this assumption is hard-baked into the architecture of several recent\nmodels, leading to approaches that can perform well on existing benchmarks but\nare difficult to generalise to other settings. To support further progress in\nthe field of systematic relational reasoning with neural networks, we introduce\nNoRA, a new benchmark which adds several levels of difficulty and requires\nmodels to go beyond path-based reasoning.",
    "categories": [
      "cs.AI",
      "cs.LG"
    ],
    "published": "2025-10-27T17:09:16Z",
    "authors": [
      "Anirban Das",
      "Irtaza Khalid",
      "Rafael Pe\u00f1aloza",
      "Steven Schockaert"
    ],
    "pdf_url": "http://arxiv.org/pdf/2510.23532v1"
  },
  {
    "id": "2510.23530v1",
    "title": "Learning Linearity in Audio Consistency Autoencoders via Implicit\n  Regularization",
    "abstract": "Audio autoencoders learn useful, compressed audio representations, but their\nnon-linear latent spaces prevent intuitive algebraic manipulation such as\nmixing or scaling. We introduce a simple training methodology to induce\nlinearity in a high-compression Consistency Autoencoder (CAE) by using data\naugmentation, thereby inducing homogeneity (equivariance to scalar gain) and\nadditivity (the decoder preserves addition) without altering the model's\narchitecture or loss function. When trained with our method, the CAE exhibits\nlinear behavior in both the encoder and decoder while preserving reconstruction\nfidelity. We test the practical utility of our learned space on music source\ncomposition and separation via simple latent arithmetic. This work presents a\nstraightforward technique for constructing structured latent spaces, enabling\nmore intuitive and efficient audio processing.",
    "categories": [
      "cs.SD",
      "cs.AI",
      "cs.LG",
      "eess.AS"
    ],
    "published": "2025-10-27T17:08:27Z",
    "authors": [
      "Bernardo Torres",
      "Manuel Moussallam",
      "Gabriel Meseguer-Brocal"
    ],
    "pdf_url": "http://arxiv.org/pdf/2510.23530v1"
  },
  {
    "id": "2510.23524v1",
    "title": "Toward Carbon-Neutral Human AI: Rethinking Data, Computation, and\n  Learning Paradigms for Sustainable Intelligence",
    "abstract": "The rapid advancement of Artificial Intelligence (AI) has led to\nunprecedented computational demands, raising significant environmental and\nethical concerns. This paper critiques the prevailing reliance on large-scale,\nstatic datasets and monolithic training paradigms, advocating for a shift\ntoward human-inspired, sustainable AI solutions. We introduce a novel\nframework, Human AI (HAI), which emphasizes incremental learning, carbon-aware\noptimization, and human-in-the-loop collaboration to enhance adaptability,\nefficiency, and accountability. By drawing parallels with biological cognition\nand leveraging dynamic architectures, HAI seeks to balance performance with\necological responsibility. We detail the theoretical foundations, system\ndesign, and operational principles that enable AI to learn continuously and\ncontextually while minimizing carbon footprints and human annotation costs. Our\napproach addresses pressing challenges in active learning, continual\nadaptation, and energy-efficient model deployment, offering a pathway toward\nresponsible, human-centered artificial intelligence.",
    "categories": [
      "cs.AI",
      "cs.LG"
    ],
    "published": "2025-10-27T17:02:30Z",
    "authors": [
      "KC Santosh",
      "Rodrigue Rizk",
      "Longwei Wang"
    ],
    "pdf_url": "http://arxiv.org/pdf/2510.23524v1"
  },
  {
    "id": "2510.23507v1",
    "title": "A Deep Latent Factor Graph Clustering with Fairness-Utility Trade-off\n  Perspective",
    "abstract": "Fair graph clustering seeks partitions that respect network structure while\nmaintaining proportional representation across sensitive groups, with\napplications spanning community detection, team formation, resource allocation,\nand social network analysis. Many existing approaches enforce rigid constraints\nor rely on multi-stage pipelines (e.g., spectral embedding followed by\n$k$-means), limiting trade-off control, interpretability, and scalability. We\nintroduce \\emph{DFNMF}, an end-to-end deep nonnegative tri-factorization\ntailored to graphs that directly optimizes cluster assignments with a soft\nstatistical-parity regularizer. A single parameter $\\lambda$ tunes the\nfairness--utility balance, while nonnegativity yields parts-based factors and\ntransparent soft memberships. The optimization uses sparse-friendly alternating\nupdates and scales near-linearly with the number of edges. Across synthetic and\nreal networks, DFNMF achieves substantially higher group balance at comparable\nmodularity, often dominating state-of-the-art baselines on the Pareto front.\nThe code is available at https://github.com/SiamakGhodsi/DFNMF.git.",
    "categories": [
      "cs.LG",
      "cs.AI",
      "cs.IT",
      "math.IT"
    ],
    "published": "2025-10-27T16:40:52Z",
    "authors": [
      "Siamak Ghodsi",
      "Amjad Seyedi",
      "Tai Le Quy",
      "Fariba Karimi",
      "Eirini Ntoutsi"
    ],
    "pdf_url": "http://arxiv.org/pdf/2510.23507v1"
  },
  {
    "id": "2510.23506v1",
    "title": "Emotion-Coherent Reasoning for Multimodal LLMs via Emotional Rationale\n  Verifier",
    "abstract": "The recent advancement of Multimodal Large Language Models (MLLMs) is\ntransforming human-computer interaction (HCI) from surface-level exchanges into\nmore nuanced and emotionally intelligent communication. To realize this shift,\nemotion understanding becomes essential allowing systems to capture subtle cues\nunderlying user intent. Furthermore, providing faithful explanations for\npredicted emotions is crucial to ensure interpretability and build user trust.\nHowever, current MLLM-based methods often generate emotion explanations that\ndiverge from the target labels and sometimes even contradict their own\npredicted emotions. This inconsistency poses a critical risk for\nmisunderstanding and erodes reliability in interactive settings. To address\nthis, we propose a novel approach: the Emotional Rationale Verifier (ERV) and\nan Explanation Reward. Our method guides the model to produce reasoning that is\nexplicitly consistent with the target emotion during multimodal emotion\nrecognition without modifying the model architecture or requiring additional\npaired video-description annotations. Our method significantly improves\nfaithful explanation-prediction consistency and explanation emotion accuracy on\nthe MAFW and DFEW datasets. Through extensive experiments and human\nevaluations, we show that our approach not only enhances alignment between\nexplanation and prediction but also empowers MLLMs to deliver emotionally\ncoherent, trustworthy interactions, marking a key step toward truly human-like\nHCI systems.",
    "categories": [
      "cs.AI",
      "cs.HC"
    ],
    "published": "2025-10-27T16:40:17Z",
    "authors": [
      "Hyeongseop Rha",
      "Jeong Hun Yeo",
      "Yeonju Kim",
      "Yong Man Ro"
    ],
    "pdf_url": "http://arxiv.org/pdf/2510.23506v1"
  },
  {
    "id": "2510.23498v1",
    "title": "Mixed Precision Training of Neural ODEs",
    "abstract": "Exploiting low-precision computations has become a standard strategy in deep\nlearning to address the growing computational costs imposed by ever larger\nmodels and datasets. However, naively performing all computations in low\nprecision can lead to roundoff errors and instabilities. Therefore, mixed\nprecision training schemes usually store the weights in high precision and use\nlow-precision computations only for whitelisted operations. Despite their\nsuccess, these principles are currently not reliable for training\ncontinuous-time architectures such as neural ordinary differential equations\n(Neural ODEs). This paper presents a mixed precision training framework for\nneural ODEs, combining explicit ODE solvers with a custom backpropagation\nscheme, and demonstrates its effectiveness across a range of learning tasks.\nOur scheme uses low-precision computations for evaluating the velocity,\nparameterized by the neural network, and for storing intermediate states, while\nstability is provided by a custom dynamic adjoint scaling and by accumulating\nthe solution and gradients in higher precision. These contributions address two\nkey challenges in training neural ODE: the computational cost of repeated\nnetwork evaluations and the growth of memory requirements with the number of\ntime steps or layers. Along with the paper, we publish our extendable,\nopen-source PyTorch package rampde, whose syntax resembles that of leading\npackages to provide a drop-in replacement in existing codes. We demonstrate the\nreliability and effectiveness of our scheme using challenging test cases and on\nneural ODE applications in image classification and generative models,\nachieving approximately 50% memory reduction and up to 2x speedup while\nmaintaining accuracy comparable to single-precision training.",
    "categories": [
      "cs.LG",
      "cs.AI",
      "cs.NA",
      "math.NA",
      "68T07, 65L06, 65G50",
      "I.2; G.1"
    ],
    "published": "2025-10-27T16:32:56Z",
    "authors": [
      "Elena Celledoni",
      "Brynjulf Owren",
      "Lars Ruthotto",
      "Tianjiao Nicole Yang"
    ],
    "pdf_url": "http://arxiv.org/pdf/2510.23498v1"
  },
  {
    "id": "2510.23487v1",
    "title": "Are Agents Just Automata? On the Formal Equivalence Between Agentic AI\n  and the Chomsky Hierarchy",
    "abstract": "This paper establishes a formal equivalence between the architectural classes\nof modern agentic AI systems and the abstract machines of the Chomsky\nhierarchy. We posit that the memory architecture of an AI agent is the\ndefinitive feature determining its computational power and that it directly\nmaps it to a corresponding class of automaton. Specifically, we demonstrate\nthat simple reflex agents are equivalent to Finite Automata, hierarchical\ntask-decomposition agents are equivalent to Pushdown Automata, and agents\nemploying readable/writable memory for reflection are equivalent to TMs. This\nAutomata-Agent Framework provides a principled methodology for right-sizing\nagent architectures to optimize computational efficiency and cost. More\ncritically, it creates a direct pathway to formal verification, enables the\napplication of mature techniques from automata theory to guarantee agent safety\nand predictability. By classifying agents, we can formally delineate the\nboundary between verifiable systems and those whose behavior is fundamentally\nundecidable. We address the inherent probabilistic nature of LLM-based agents\nby extending the framework to probabilistic automata that allow quantitative\nrisk analysis. The paper concludes by outlining an agenda for developing static\nanalysis tools and grammars for agentic frameworks.",
    "categories": [
      "cs.AI",
      "cs.FL"
    ],
    "published": "2025-10-27T16:22:02Z",
    "authors": [
      "Roham Koohestani",
      "Ziyou Li",
      "Anton Podkopaev",
      "Maliheh Izadi"
    ],
    "pdf_url": "http://arxiv.org/pdf/2510.23487v1"
  },
  {
    "id": "2510.23685v1",
    "title": "Parallel BiLSTM-Transformer networks for forecasting chaotic dynamics",
    "abstract": "The nonlinear nature of chaotic systems results in extreme sensitivity to\ninitial conditions and highly intricate dynamical behaviors, posing fundamental\nchallenges for accurately predicting their evolution. To overcome the\nlimitation that conventional approaches fail to capture both local features and\nglobal dependencies in chaotic time series simultaneously, this study proposes\na parallel predictive framework integrating Transformer and Bidirectional Long\nShort-Term Memory (BiLSTM) networks. The hybrid model employs a dual-branch\narchitecture, where the Transformer branch mainly captures long-range\ndependencies while the BiLSTM branch focuses on extracting local temporal\nfeatures. The complementary representations from the two branches are fused in\na dedicated feature-fusion layer to enhance predictive accuracy. As\nillustrating examples, the model's performance is systematically evaluated on\ntwo representative tasks in the Lorenz system. The first is autonomous\nevolution prediction, in which the model recursively extrapolates system\ntrajectories from the time-delay embeddings of the state vector to evaluate\nlong-term tracking accuracy and stability. The second is inference of\nunmeasured variable, where the model reconstructs the unobserved states from\nthe time-delay embeddings of partial observations to assess its\nstate-completion capability. The results consistently indicate that the\nproposed hybrid framework outperforms both single-branch architectures across\ntasks, demonstrating its robustness and effectiveness in chaotic system\nprediction.",
    "categories": [
      "cs.LG",
      "cs.AI"
    ],
    "published": "2025-10-27T16:17:10Z",
    "authors": [
      "Junwen Ma",
      "Mingyu Ge",
      "Yisen Wang",
      "Yong Zhang",
      "Weicheng Fu"
    ],
    "pdf_url": "http://arxiv.org/pdf/2510.23685v1"
  },
  {
    "id": "2510.23482v1",
    "title": "On the Faithfulness of Visual Thinking: Measurement and Enhancement",
    "abstract": "Recent large vision-language models (LVLMs) can generate vision-text\nmultimodal chain-of-thought (MCoT) traces after reinforcement fine-tuning\n(RFT). However, we observe that the visual information incorporated in MCoT is\noften inaccurate, though still yield correct answers, indicating a lack of\nfaithfulness in the MCoT reasoning process. We attribute this unfaithfulness to\nthe RL reward in RFT, which solely incentivizes the format of interleaved\nvision-text cues, ie, it encourages the model to incorporate visual information\ninto its text reasoning steps without considering the correctness of the visual\ninformation. In this paper, we first probe the faithfulness of MCoT by\nmeasuring how much the prediction changes when its visual and textual thoughts\nare intervened. Surprisingly, the model's predictions remain nearly unchanged\nunder visual intervention but change significantly under textual intervention,\nindicating that the visual evidence is largely ignored. To further analyze\nvisual information, we introduce an automated LVLM-based evaluation metric that\nquantifies the faithfulness of visual cues from two perspectives: reliability\nand sufficiency. Our evaluation reveals that the visual information in current\nMCoT traces is simultaneously unreliable and insufficient. To address this\nissue, we propose a novel MCoT learning strategy termed Sufficient-Component\nCause Model (SCCM) learning. This approach encourages the MCoT to generate\nsufficient yet minimal visual components that are independently capable of\nleading to correct answers. We note that the proposed SCCM is annotation-free\nand compatible with various RFT for MCoT in a plug-and-play manner. Empirical\nresults demonstrate that SCCM consistently improves the visual faithfulness\nacross a suite of fine-grained perception and reasoning benchmarks. Code is\navailable at https://github.com/EugeneLiu01/Faithful_Thinking_with_Image.",
    "categories": [
      "cs.CV",
      "cs.AI"
    ],
    "published": "2025-10-27T16:15:54Z",
    "authors": [
      "Zujing Liu",
      "Junwen Pan",
      "Qi She",
      "Yuan Gao",
      "Guisong Xia"
    ],
    "pdf_url": "http://arxiv.org/pdf/2510.23482v1"
  },
  {
    "id": "2510.23476v1",
    "title": "Human-AI Collaborative Uncertainty Quantification",
    "abstract": "AI predictive systems are increasingly embedded in decision making pipelines,\nshaping high stakes choices once made solely by humans. Yet robust decisions\nunder uncertainty still rely on capabilities that current AI lacks: domain\nknowledge not captured by data, long horizon context, and reasoning grounded in\nthe physical world. This gap has motivated growing efforts to design\ncollaborative frameworks that combine the complementary strengths of humans and\nAI. This work advances this vision by identifying the fundamental principles of\nHuman AI collaboration within uncertainty quantification, a key component of\nreliable decision making. We introduce Human AI Collaborative Uncertainty\nQuantification, a framework that formalizes how an AI model can refine a human\nexpert's proposed prediction set with two goals: avoiding counterfactual harm,\nensuring the AI does not degrade correct human judgments, and complementarity,\nenabling recovery of correct outcomes the human missed. At the population\nlevel, we show that the optimal collaborative prediction set follows an\nintuitive two threshold structure over a single score function, extending a\nclassical result in conformal prediction. Building on this insight, we develop\npractical offline and online calibration algorithms with provable distribution\nfree finite sample guarantees. The online method adapts to distribution shifts,\nincluding human behavior evolving through interaction with AI, a phenomenon we\ncall Human to AI Adaptation. Experiments across image classification,\nregression, and text based medical decision making show that collaborative\nprediction sets consistently outperform either agent alone, achieving higher\ncoverage and smaller set sizes across various conditions.",
    "categories": [
      "cs.AI",
      "cs.HC",
      "stat.ML"
    ],
    "published": "2025-10-27T16:11:23Z",
    "authors": [
      "Sima Noorani",
      "Shayan Kiyani",
      "George Pappas",
      "Hamed Hassani"
    ],
    "pdf_url": "http://arxiv.org/pdf/2510.23476v1"
  },
  {
    "id": "2510.23474v1",
    "title": "Policy-Aware Generative AI for Safe, Auditable Data Access Governance",
    "abstract": "Enterprises need access decisions that satisfy least privilege, comply with\nregulations, and remain auditable. We present a policy aware controller that\nuses a large language model (LLM) to interpret natural language requests\nagainst written policies and metadata, not raw data. The system, implemented\nwith Google Gemini~2.0 Flash, executes a six-stage reasoning framework (context\ninterpretation, user validation, data classification, business purpose test,\ncompliance mapping, and risk synthesis) with early hard policy gates and deny\nby default. It returns APPROVE, DENY, CONDITIONAL together with cited controls\nand a machine readable rationale. We evaluate on fourteen canonical cases\nacross seven scenario families using a privacy preserving benchmark. Results\nshow Exact Decision Match improving from 10/14 to 13/14 (92.9\\%) after applying\npolicy gates, DENY recall rising to 1.00, False Approval Rate on must-deny\nfamilies dropping to 0, and Functional Appropriateness and Compliance Adherence\nat 14/14. Expert ratings of rationale quality are high, and median latency is\nunder one minute. These findings indicate that policy constrained LLM\nreasoning, combined with explicit gates and audit trails, can translate human\nreadable policies into safe, compliant, and traceable machine decisions.",
    "categories": [
      "cs.AI"
    ],
    "published": "2025-10-27T16:10:55Z",
    "authors": [
      "Shames Al Mandalawi",
      "Muzakkiruddin Ahmed Mohammed",
      "Hendrika Maclean",
      "Mert Can Cakmak",
      "John R. Talburt"
    ],
    "pdf_url": "http://arxiv.org/pdf/2510.23474v1"
  },
  {
    "id": "2510.23472v1",
    "title": "BBOPlace-Bench: Benchmarking Black-Box Optimization for Chip Placement",
    "abstract": "Chip placement is a vital stage in modern chip design as it has a substantial\nimpact on the subsequent processes and the overall quality of the final chip.\nThe use of black-box optimization (BBO) for chip placement has a history of\nseveral decades. However, early efforts were limited by immature problem\nformulations and inefficient algorithm designs. Recent progress has shown the\neffectiveness and efficiency of BBO for chip placement, proving its potential\nto achieve state-of-the-art results. Despite these advancements, the field\nlacks a unified, BBO-specific benchmark for thoroughly assessing various\nproblem formulations and BBO algorithms. To fill this gap, we propose\nBBOPlace-Bench, the first benchmark designed specifically for evaluating and\ndeveloping BBO algorithms for chip placement tasks. It integrates three problem\nformulations of BBO for chip placement, and offers a modular, decoupled, and\nflexible framework that enables users to seamlessly implement, test, and\ncompare their own algorithms. BBOPlace-Bench integrates a wide variety of\nexisting BBO algorithms, including simulated annealing (SA), evolutionary\nalgorithms (EAs), and Bayesian optimization (BO). Experimental results show\nthat the problem formulations of mask-guided optimization and hyperparameter\noptimization exhibit superior performance than the sequence pair problem\nformulation, while EAs demonstrate better overall performance than SA and BO,\nespecially in high-dimensional search spaces, and also achieve state-of-the-art\nperformance compared to the mainstream chip placement methods. BBOPlace-Bench\nnot only facilitates the development of efficient BBO-driven solutions for chip\nplacement but also broadens the practical application scenarios (which are\nurgently needed) for the BBO community. The code of BBOPlace-Bench is available\nat https://github.com/lamda-bbo/BBOPlace-Bench.",
    "categories": [
      "cs.LG",
      "cs.AI",
      "cs.AR",
      "cs.NE"
    ],
    "published": "2025-10-27T16:10:32Z",
    "authors": [
      "Ke Xue",
      "Ruo-Tong Chen",
      "Rong-Xi Tan",
      "Xi Lin",
      "Yunqi Shi",
      "Siyuan Xu",
      "Mingxuan Yuan",
      "Chao Qian"
    ],
    "pdf_url": "http://arxiv.org/pdf/2510.23472v1"
  },
  {
    "id": "2510.23471v1",
    "title": "Robust Decision Making with Partially Calibrated Forecasts",
    "abstract": "Calibration has emerged as a foundational goal in ``trustworthy machine\nlearning'', in part because of its strong decision theoretic semantics.\nIndependent of the underlying distribution, and independent of the decision\nmaker's utility function, calibration promises that amongst all policies\nmapping predictions to actions, the uniformly best policy is the one that\n``trusts the predictions'' and acts as if they were correct. But this is true\nonly of \\emph{fully calibrated} forecasts, which are tractable to guarantee\nonly for very low dimensional prediction problems. For higher dimensional\nprediction problems (e.g. when outcomes are multiclass), weaker forms of\ncalibration have been studied that lack these decision theoretic properties. In\nthis paper we study how a conservative decision maker should map predictions\nendowed with these weaker (``partial'') calibration guarantees to actions, in a\nway that is robust in a minimax sense: i.e. to maximize their expected utility\nin the worst case over distributions consistent with the calibration\nguarantees. We characterize their minimax optimal decision rule via a duality\nargument, and show that surprisingly, ``trusting the predictions and acting\naccordingly'' is recovered in this minimax sense by \\emph{decision calibration}\n(and any strictly stronger notion of calibration), a substantially weaker and\nmore tractable condition than full calibration. For calibration guarantees that\nfall short of decision calibration, the minimax optimal decision rule is still\nefficiently computable, and we provide an empirical evaluation of a natural one\nthat applies to any regression model solved to optimize squared error.",
    "categories": [
      "stat.ML",
      "cs.AI",
      "cs.LG"
    ],
    "published": "2025-10-27T16:09:07Z",
    "authors": [
      "Shayan Kiyani",
      "Hamed Hassani",
      "George Pappas",
      "Aaron Roth"
    ],
    "pdf_url": "http://arxiv.org/pdf/2510.23471v1"
  },
  {
    "id": "2510.23464v1",
    "title": "Evaluating Large Language Models for Stance Detection on Financial\n  Targets from SEC Filing Reports and Earnings Call Transcripts",
    "abstract": "Financial narratives from U.S. Securities and Exchange Commission (SEC)\nfiling reports and quarterly earnings call transcripts (ECTs) are very\nimportant for investors, auditors, and regulators. However, their length,\nfinancial jargon, and nuanced language make fine-grained analysis difficult.\nPrior sentiment analysis in the financial domain required a large, expensive\nlabeled dataset, making the sentence-level stance towards specific financial\ntargets challenging. In this work, we introduce a sentence-level corpus for\nstance detection focused on three core financial metrics: debt, earnings per\nshare (EPS), and sales. The sentences were extracted from Form 10-K annual\nreports and ECTs, and labeled for stance (positive, negative, neutral) using\nthe advanced ChatGPT-o3-pro model under rigorous human validation. Using this\ncorpus, we conduct a systematic evaluation of modern large language models\n(LLMs) using zero-shot, few-shot, and Chain-of-Thought (CoT) prompting\nstrategies. Our results show that few-shot with CoT prompting performs best\ncompared to supervised baselines, and LLMs' performance varies across the SEC\nand ECT datasets. Our findings highlight the practical viability of leveraging\nLLMs for target-specific stance in the financial domain without requiring\nextensive labeled data.",
    "categories": [
      "cs.CL",
      "cs.AI"
    ],
    "published": "2025-10-27T16:03:20Z",
    "authors": [
      "Nikesh Gyawali",
      "Doina Caragea",
      "Alex Vasenkov",
      "Cornelia Caragea"
    ],
    "pdf_url": "http://arxiv.org/pdf/2510.23464v1"
  },
  {
    "id": "2510.23458v2",
    "title": "BrowseConf: Confidence-Guided Test-Time Scaling for Web Agents",
    "abstract": "Confidence in LLMs is a useful indicator of model uncertainty and answer\nreliability. Existing work mainly focused on single-turn scenarios, while\nresearch on confidence in complex multi-turn interactions is limited. In this\npaper, we investigate whether LLM-based search agents have the ability to\ncommunicate their own confidence through verbalized confidence scores after\nlong sequences of actions, a significantly more challenging task compared to\noutputting confidence in a single interaction. Experimenting on open-source\nagentic models, we first find that models exhibit much higher task accuracy at\nhigh confidence while having near-zero accuracy when confidence is low. Based\non this observation, we propose Test-Time Scaling (TTS) methods that use\nconfidence scores to determine answer quality, encourage the model to try again\nuntil reaching a satisfactory confidence level. Results show that our proposed\nmethods significantly reduce token consumption while demonstrating competitive\nperformance compared to baseline fixed budget TTS methods.",
    "categories": [
      "cs.CL",
      "cs.AI"
    ],
    "published": "2025-10-27T15:58:51Z",
    "authors": [
      "Litu Ou",
      "Kuan Li",
      "Huifeng Yin",
      "Liwen Zhang",
      "Zhongwang Zhang",
      "Xixi Wu",
      "Rui Ye",
      "Zile Qiao",
      "Pengjun Xie",
      "Jingren Zhou",
      "Yong Jiang"
    ],
    "pdf_url": "http://arxiv.org/pdf/2510.23458v2"
  },
  {
    "id": "2510.23453v1",
    "title": "What are the odds? Risk and uncertainty about AI existential risk",
    "abstract": "This work is a commentary of the article\n\\href{https://doi.org/10.18716/ojs/phai/2025.2801}{AI Survival Stories: a\nTaxonomic Analysis of AI Existential Risk} by Cappelen, Goldstein, and\nHawthorne. It is not just a commentary though, but a useful reminder of the\nphilosophical limitations of \\say{linear} models of risk. The article will\nfocus on the model employed by the authors: first, I discuss some differences\nbetween standard Swiss Cheese models and this one. I then argue that in a\nsituation of epistemic indifference the probability of P(D) is higher than what\none might first suggest, given the structural relationships between layers. I\nthen distinguish between risk and uncertainty, and argue that any estimation of\nP(D) is structurally affected by two kinds of uncertainty: option uncertainty\nand state-space uncertainty. Incorporating these dimensions of uncertainty into\nour qualitative discussion on AI existential risk can provide a better\nunderstanding of the likeliness of P(D).",
    "categories": [
      "cs.AI"
    ],
    "published": "2025-10-27T15:53:23Z",
    "authors": [
      "Marco Grossi"
    ],
    "pdf_url": "http://arxiv.org/pdf/2510.23453v1"
  },
  {
    "id": "2510.23451v1",
    "title": "Omni-Reward: Towards Generalist Omni-Modal Reward Modeling with\n  Free-Form Preferences",
    "abstract": "Reward models (RMs) play a critical role in aligning AI behaviors with human\npreferences, yet they face two fundamental challenges: (1) Modality Imbalance,\nwhere most RMs are mainly focused on text and image modalities, offering\nlimited support for video, audio, and other modalities; and (2) Preference\nRigidity, where training on fixed binary preference pairs fails to capture the\ncomplexity and diversity of personalized preferences. To address the above\nchallenges, we propose Omni-Reward, a step toward generalist omni-modal reward\nmodeling with support for free-form preferences, consisting of: (1) Evaluation:\nWe introduce Omni-RewardBench, the first omni-modal RM benchmark with free-form\npreferences, covering nine tasks across five modalities including text, image,\nvideo, audio, and 3D; (2) Data: We construct Omni-RewardData, a multimodal\npreference dataset comprising 248K general preference pairs and 69K\ninstruction-tuning pairs for training generalist omni-modal RMs; (3) Model: We\npropose Omni-RewardModel, which includes both discriminative and generative\nRMs, and achieves strong performance on Omni-RewardBench as well as other\nwidely used reward modeling benchmarks.",
    "categories": [
      "cs.CL",
      "cs.AI",
      "cs.CV"
    ],
    "published": "2025-10-27T15:53:20Z",
    "authors": [
      "Zhuoran Jin",
      "Hongbang Yuan",
      "Kejian Zhu",
      "Jiachun Li",
      "Pengfei Cao",
      "Yubo Chen",
      "Kang Liu",
      "Jun Zhao"
    ],
    "pdf_url": "http://arxiv.org/pdf/2510.23451v1"
  },
  {
    "id": "2510.23444v2",
    "title": "FRBNet: Revisiting Low-Light Vision through Frequency-Domain Radial\n  Basis Network",
    "abstract": "Low-light vision remains a fundamental challenge in computer vision due to\nsevere illumination degradation, which significantly affects the performance of\ndownstream tasks such as detection and segmentation. While recent\nstate-of-the-art methods have improved performance through invariant feature\nlearning modules, they still fall short due to incomplete modeling of low-light\nconditions. Therefore, we revisit low-light image formation and extend the\nclassical Lambertian model to better characterize low-light conditions. By\nshifting our analysis to the frequency domain, we theoretically prove that the\nfrequency-domain channel ratio can be leveraged to extract\nillumination-invariant features via a structured filtering process. We then\npropose a novel and end-to-end trainable module named \\textbf{F}requency-domain\n\\textbf{R}adial \\textbf{B}asis \\textbf{Net}work (\\textbf{FRBNet}), which\nintegrates the frequency-domain channel ratio operation with a learnable\nfrequency domain filter for the overall illumination-invariant feature\nenhancement. As a plug-and-play module, FRBNet can be integrated into existing\nnetworks for low-light downstream tasks without modifying loss functions.\nExtensive experiments across various downstream tasks demonstrate that FRBNet\nachieves superior performance, including +2.2 mAP for dark object detection and\n+2.9 mIoU for nighttime segmentation. Code is available at:\nhttps://github.com/Sing-Forevet/FRBNet.",
    "categories": [
      "cs.CV",
      "cs.AI"
    ],
    "published": "2025-10-27T15:46:07Z",
    "authors": [
      "Fangtong Sun",
      "Congyu Li",
      "Ke Yang",
      "Yuchen Pan",
      "Hanwen Yu",
      "Xichuan Zhang",
      "Yiying Li"
    ],
    "pdf_url": "http://arxiv.org/pdf/2510.23444v2"
  },
  {
    "id": "2510.23443v1",
    "title": "A Neuro-Symbolic Multi-Agent Approach to Legal-Cybersecurity Knowledge\n  Integration",
    "abstract": "The growing intersection of cybersecurity and law creates a complex\ninformation space where traditional legal research tools struggle to deal with\nnuanced connections between cases, statutes, and technical vulnerabilities.\nThis knowledge divide hinders collaboration between legal experts and\ncybersecurity professionals. To address this important gap, this work provides\na first step towards intelligent systems capable of navigating the increasingly\nintricate cyber-legal domain. We demonstrate promising initial results on\nmultilingual tasks.",
    "categories": [
      "cs.AI",
      "cs.CL",
      "cs.CR",
      "cs.MA"
    ],
    "published": "2025-10-27T15:46:02Z",
    "authors": [
      "Chiara Bonfanti",
      "Alessandro Druetto",
      "Cataldo Basile",
      "Tharindu Ranasinghe",
      "Marcos Zampieri"
    ],
    "pdf_url": "http://arxiv.org/pdf/2510.23443v1"
  },
  {
    "id": "2510.23424v1",
    "title": "Causal Deep Q Network",
    "abstract": "Deep Q Networks (DQN) have shown remarkable success in various reinforcement\nlearning tasks. However, their reliance on associative learning often leads to\nthe acquisition of spurious correlations, hindering their problem-solving\ncapabilities. In this paper, we introduce a novel approach to integrate causal\nprinciples into DQNs, leveraging the PEACE (Probabilistic Easy vAriational\nCausal Effect) formula for estimating causal effects. By incorporating causal\nreasoning during training, our proposed framework enhances the DQN's\nunderstanding of the underlying causal structure of the environment, thereby\nmitigating the influence of confounding factors and spurious correlations. We\ndemonstrate that integrating DQNs with causal capabilities significantly\nenhances their problem-solving capabilities without compromising performance.\nExperimental results on standard benchmark environments showcase that our\napproach outperforms conventional DQNs, highlighting the effectiveness of\ncausal reasoning in reinforcement learning. Overall, our work presents a\npromising avenue for advancing the capabilities of deep reinforcement learning\nagents through principled causal inference.",
    "categories": [
      "cs.AI"
    ],
    "published": "2025-10-27T15:28:17Z",
    "authors": [
      "Elouanes Khelifi",
      "Amir Saki",
      "Usef Faghihi"
    ],
    "pdf_url": "http://arxiv.org/pdf/2510.23424v1"
  },
  {
    "id": "2510.23421v1",
    "title": "Exploring Vulnerability in AI Industry",
    "abstract": "The rapid ascent of Foundation Models (FMs), enabled by the Transformer\narchitecture, drives the current AI ecosystem. Characterized by large-scale\ntraining and downstream adaptability, FMs (as GPT family) have achieved massive\npublic adoption, fueling a turbulent market shaped by platform economics and\nintense investment. Assessing the vulnerability of this fast-evolving industry\nis critical yet challenging due to data limitations. This paper proposes a\nsynthetic AI Vulnerability Index (AIVI) focusing on the upstream value chain\nfor FM production, prioritizing publicly available data. We model FM output as\na function of five inputs: Compute, Data, Talent, Capital, and Energy,\nhypothesizing that supply vulnerability in any input threatens the industry.\nKey vulnerabilities include compute concentration, data scarcity and legal\nrisks, talent bottlenecks, capital intensity and strategic dependencies, as\nwell as escalating energy demands. Acknowledging imperfect input\nsubstitutability, we propose a weighted geometrical average of aggregate\nsubindexes, normalized using theoretical or empirical benchmarks. Despite\nlimitations and room for improvement, this preliminary index aims to quantify\nsystemic risks in AI's core production engine, and implicitly shed a light on\nthe risks for downstream value chain.",
    "categories": [
      "econ.GN",
      "cs.AI",
      "q-fin.EC"
    ],
    "published": "2025-10-27T15:26:40Z",
    "authors": [
      "Claudio Pirrone",
      "Stefano Fricano",
      "Gioacchino Fazio"
    ],
    "pdf_url": "http://arxiv.org/pdf/2510.23421v1"
  },
  {
    "id": "2510.23682v1",
    "title": "Beyond Prompt Engineering: Neuro-Symbolic-Causal Architecture for Robust\n  Multi-Objective AI Agents",
    "abstract": "Large language models show promise as autonomous decision-making agents, yet\ntheir deployment in high-stakes domains remains fraught with risk. Without\narchitectural safeguards, LLM agents exhibit catastrophic brittleness:\nidentical capabilities produce wildly different outcomes depending solely on\nprompt framing. We present Chimera, a neuro-symbolic-causal architecture that\nintegrates three complementary components - an LLM strategist, a formally\nverified symbolic constraint engine, and a causal inference module for\ncounterfactual reasoning. We benchmark Chimera against baseline architectures\n(LLM-only, LLM with symbolic constraints) across 52-week simulations in a\nrealistic e-commerce environment featuring price elasticity, trust dynamics,\nand seasonal demand. Under organizational biases toward either volume or margin\noptimization, LLM-only agents fail catastrophically (total loss of \\$99K in\nvolume scenarios) or destroy brand trust (-48.6% in margin scenarios). Adding\nsymbolic constraints prevents disasters but achieves only 43-87% of Chimera's\nprofit. Chimera consistently delivers the highest returns (\\$1.52M and \\$1.96M\nrespectively, some cases +\\$2.2M) while improving brand trust (+1.8% and\n+10.8%, some cases +20.86%), demonstrating prompt-agnostic robustness. Our TLA+\nformal verification proves zero constraint violations across all scenarios.\nThese results establish that architectural design not prompt engineering\ndetermines the reliability of autonomous agents in production environments. We\nprovide open-source implementations and interactive demonstrations for\nreproducibility.",
    "categories": [
      "cs.LG",
      "cs.AI",
      "cs.LO",
      "cs.SE",
      "I.2.11; I.2.6; I.2.8"
    ],
    "published": "2025-10-27T15:25:35Z",
    "authors": [
      "Gokturk Aytug Akarlar"
    ],
    "pdf_url": "http://arxiv.org/pdf/2510.23682v1"
  },
  {
    "id": "2510.23410v1",
    "title": "Bid2X: Revealing Dynamics of Bidding Environment in Online Advertising\n  from A Foundation Model Lens",
    "abstract": "Auto-bidding is crucial in facilitating online advertising by automatically\nproviding bids for advertisers. While previous work has made great efforts to\nmodel bidding environments for better ad performance, it has limitations in\ngeneralizability across environments since these models are typically tailored\nfor specific bidding scenarios. To this end, we approach the\nscenario-independent principles through a unified function that estimates the\nachieved effect under specific bids, such as budget consumption, gross\nmerchandise volume (GMV), page views, etc. Then, we propose a bidding\nfoundation model Bid2X to learn this fundamental function from data in various\nscenarios. Our Bid2X is built over uniform series embeddings that encode\nheterogeneous data through tailored embedding methods. To capture complex\ninter-variable and dynamic temporal dependencies in bidding data, we propose\ntwo attention mechanisms separately treating embeddings of different variables\nand embeddings at different times as attention tokens for representation\nlearning. On top of the learned variable and temporal representations, a\nvariable-aware fusion module is used to perform adaptive bidding outcome\nprediction. To model the unique bidding data distribution, we devise a\nzero-inflated projection module to incorporate the estimated non-zero\nprobability into its value prediction, which makes up a joint optimization\nobjective containing classification and regression. The objective is proven to\nconverge to the zero-inflated distribution. Our model has been deployed on the\nad platform in Taobao, one of the world's largest e-commerce platforms. Offline\nevaluation on eight datasets exhibits Bid2X's superiority compared to various\nbaselines and its generality across different scenarios. Bid2X increased GMV by\n4.65% and ROI by 2.44% in online A/B tests, paving the way for bidding\nfoundation model in computational advertising.",
    "categories": [
      "cs.AI"
    ],
    "published": "2025-10-27T15:15:01Z",
    "authors": [
      "Jiahao Ji",
      "Tianyu Wang",
      "Yeshu Li",
      "Yushen Huo",
      "Zhilin Zhang",
      "Chuan Yu",
      "Jian Xu",
      "Bo Zheng"
    ],
    "pdf_url": "http://arxiv.org/pdf/2510.23410v1"
  },
  {
    "id": "2510.23409v2",
    "title": "Eigen-Value: Efficient Domain-Robust Data Valuation via Eigenvalue-Based\n  Approach",
    "abstract": "Data valuation has become central in the era of data-centric AI. It drives\nefficient training pipelines and enables objective pricing in data markets by\nassigning a numeric value to each data point. Most existing data valuation\nmethods estimate the effect of removing individual data points by evaluating\nchanges in model validation performance under in-distribution (ID) settings, as\nopposed to out-of-distribution (OOD) scenarios where data follow different\npatterns. Since ID and OOD data behave differently, data valuation methods\nbased on ID loss often fail to generalize to OOD settings, particularly when\nthe validation set contains no OOD data. Furthermore, although OOD-aware\nmethods exist, they involve heavy computational costs, which hinder practical\ndeployment. To address these challenges, we introduce \\emph{Eigen-Value} (EV),\na plug-and-play data valuation framework for OOD robustness that uses only an\nID data subset, including during validation. EV provides a new spectral\napproximation of domain discrepancy, which is the gap of loss between ID and\nOOD using ratios of eigenvalues of ID data's covariance matrix. EV then\nestimates the marginal contribution of each data point to this discrepancy via\nperturbation theory, alleviating the computational burden. Subsequently, EV\nplugs into ID loss-based methods by adding an EV term without any additional\ntraining loop. We demonstrate that EV achieves improved OOD robustness and\nstable value rankings across real-world datasets, while remaining\ncomputationally lightweight. These results indicate that EV is practical for\nlarge-scale settings with domain shift, offering an efficient path to\nOOD-robust data valuation.",
    "categories": [
      "cs.LG",
      "cs.AI"
    ],
    "published": "2025-10-27T15:12:49Z",
    "authors": [
      "Youngjun Choi",
      "Joonseong Kang",
      "Sungjun Lim",
      "Kyungwoo Song"
    ],
    "pdf_url": "http://arxiv.org/pdf/2510.23409v2"
  },
  {
    "id": "2510.23408v1",
    "title": "AutoStreamPipe: LLM Assisted Automatic Generation of Data Stream\n  Processing Pipelines",
    "abstract": "Data pipelines are essential in stream processing as they enable the\nefficient collection, processing, and delivery of real-time data, supporting\nrapid data analysis. In this paper, we present AutoStreamPipe, a novel\nframework that employs Large Language Models (LLMs) to automate the design,\ngeneration, and deployment of stream processing pipelines. AutoStreamPipe\nbridges the semantic gap between high-level user intent and platform-specific\nimplementations across distributed stream processing systems for structured\nmulti-agent reasoning by integrating a Hypergraph of Thoughts (HGoT) as an\nextended version of GoT. AutoStreamPipe combines resilient execution\nstrategies, advanced query analysis, and HGoT to deliver pipelines with good\naccuracy. Experimental evaluations on diverse pipelines demonstrate that\nAutoStreamPipe significantly reduces development time (x6.3) and error rates\n(x5.19), as measured by a novel Error-Free Score (EFS), compared to LLM\ncode-generation methods.",
    "categories": [
      "cs.AI",
      "cs.DC",
      "cs.ET",
      "cs.LG",
      "cs.MA"
    ],
    "published": "2025-10-27T15:11:31Z",
    "authors": [
      "Abolfazl Younesi",
      "Zahra Najafabadi Samani",
      "Thomas Fahringer"
    ],
    "pdf_url": "http://arxiv.org/pdf/2510.23408v1"
  },
  {
    "id": "2510.23396v1",
    "title": "EMTSF:Extraordinary Mixture of SOTA Models for Time Series Forecasting",
    "abstract": "The immense success of the Transformer architecture\n  in Natural Language Processing has led to its adoption in Time Se ries\nForecasting (TSF), where superior performance has been shown.\n  However, a recent important paper questioned their effectiveness by\n  demonstrating that a simple single layer linear model outperforms\n  Transformer-based models. This was soon shown to be not as valid,\n  by a better transformer-based model termed PatchTST. More re cently, TimeLLM\ndemonstrated even better results by repurposing a\n  Large Language Model (LLM) for the TSF domain. Again, a follow\n  up paper challenged this by demonstrating that removing the LLM\n  component or replacing it with a basic attention layer in fact yields\n  better performance. One of the challenges in forecasting is the fact\n  that TSF data favors the more recent past, and is sometimes subject\n  to unpredictable events. Based upon these recent insights in TSF, we\n  propose a strong Mixture of Experts (MoE) framework. Our method\n  combines the state-of-the-art (SOTA) models including xLSTM, en hanced\nLinear, PatchTST, and minGRU, among others. This set of\n  complimentary and diverse models for TSF are integrated in a Trans former\nbased MoE gating network. Our proposed model outperforms\n  all existing TSF models on standard benchmarks, surpassing even the\n  latest approaches based on MoE frameworks.",
    "categories": [
      "cs.CL",
      "cs.AI"
    ],
    "published": "2025-10-27T14:55:30Z",
    "authors": [
      "Musleh Alharthi",
      "Kaleel Mahmood",
      "Sarosh Patel",
      "Ausif Mahmood"
    ],
    "pdf_url": "http://arxiv.org/pdf/2510.23396v1"
  },
  {
    "id": "2510.23395v1",
    "title": "Detecting Religious Language in Climate Discourse",
    "abstract": "Religious language continues to permeate contemporary discourse, even in\nostensibly secular domains such as environmental activism and climate change\ndebates. This paper investigates how explicit and implicit forms of religious\nlanguage appear in climate-related texts produced by secular and religious\nnongovernmental organizations (NGOs). We introduce a dual methodological\napproach: a rule-based model using a hierarchical tree of religious terms\nderived from ecotheology literature, and large language models (LLMs) operating\nin a zero-shot setting. Using a dataset of more than 880,000 sentences, we\ncompare how these methods detect religious language and analyze points of\nagreement and divergence. The results show that the rule-based method\nconsistently labels more sentences as religious than LLMs. These findings\nhighlight not only the methodological challenges of computationally detecting\nreligious language but also the broader tension over whether religious language\nshould be defined by vocabulary alone or by contextual meaning. This study\ncontributes to digital methods in religious studies by demonstrating both the\npotential and the limitations of approaches for analyzing how the sacred\npersists in climate discourse.",
    "categories": [
      "cs.CL",
      "cs.AI"
    ],
    "published": "2025-10-27T14:54:51Z",
    "authors": [
      "Evy Beijen",
      "Pien Pieterse",
      "Yusuf \u00c7elik",
      "Willem Th. van Peursen",
      "Sandjai Bhulai",
      "Meike Morren"
    ],
    "pdf_url": "http://arxiv.org/pdf/2510.23395v1"
  },
  {
    "id": "2510.23384v1",
    "title": "Opinion Mining Based Entity Ranking using Fuzzy Logic Algorithmic\n  Approach",
    "abstract": "Opinions are central to almost all human activities and are key influencers\nof our behaviors. In current times due to growth of social networking website\nand increase in number of e-commerce site huge amount of opinions are now\navailable on web. Given a set of evaluative statements that contain opinions\n(or sentiments) about an Entity, opinion mining aims to extract attributes and\ncomponents of the object that have been commented on in each statement and to\ndetermine whether the comments are positive, negative or neutral. While lot of\nresearch recently has been done in field of opinion mining and some of it\ndealing with ranking of entities based on review or opinion set, classifying\nopinions into finer granularity level and then ranking entities has never been\ndone before. In this paper method for opinion mining from statements at a\ndeeper level of granularity is proposed. This is done by using fuzzy logic\nreasoning, after which entities are ranked as per this information.",
    "categories": [
      "cs.AI",
      "cs.LG"
    ],
    "published": "2025-10-27T14:35:20Z",
    "authors": [
      "Pratik N. Kalamkar",
      "A. G. Phakatkar"
    ],
    "pdf_url": "http://arxiv.org/pdf/2510.23384v1"
  },
  {
    "id": "2510.23379v1",
    "title": "Symbolic Neural Generation with Applications to Lead Discovery in Drug\n  Design",
    "abstract": "We investigate a relatively underexplored class of hybrid neurosymbolic\nmodels integrating symbolic learning with neural reasoning to construct data\ngenerators meeting formal correctness criteria. In \\textit{Symbolic Neural\nGenerators} (SNGs), symbolic learners examine logical specifications of\nfeasible data from a small set of instances -- sometimes just one. Each\nspecification in turn constrains the conditional information supplied to a\nneural-based generator, which rejects any instance violating the symbolic\nspecification. Like other neurosymbolic approaches, SNG exploits the\ncomplementary strengths of symbolic and neural methods. The outcome of an SNG\nis a triple $(H, X, W)$, where $H$ is a symbolic description of feasible\ninstances constructed from data, $X$ a set of generated new instances that\nsatisfy the description, and $W$ an associated weight. We introduce a semantics\nfor such systems, based on the construction of appropriate \\textit{base} and\n\\textit{fibre} partially-ordered sets combined into an overall partial order,\nand outline a probabilistic extension relevant to practical applications. In\nthis extension, SNGs result from searching over a weighted partial ordering. We\nimplement an SNG combining a restricted form of Inductive Logic Programming\n(ILP) with a large language model (LLM) and evaluate it on early-stage drug\ndesign. Our main interest is the description and the set of potential inhibitor\nmolecules generated by the SNG. On benchmark problems -- where drug targets are\nwell understood -- SNG performance is statistically comparable to\nstate-of-the-art methods. On exploratory problems with poorly understood\ntargets, generated molecules exhibit binding affinities on par with leading\nclinical candidates. Experts further find the symbolic specifications useful as\npreliminary filters, with several generated molecules identified as viable for\nsynthesis and wet-lab testing.",
    "categories": [
      "cs.LG",
      "cs.AI",
      "cs.NE",
      "q-bio.BM",
      "I.2.6; I.2.1; J.3"
    ],
    "published": "2025-10-27T14:29:22Z",
    "authors": [
      "Ashwin Srinivasan",
      "A Baskar",
      "Tirtharaj Dash",
      "Michael Bain",
      "Sanjay Kumar Dey",
      "Mainak Banerjee"
    ],
    "pdf_url": "http://arxiv.org/pdf/2510.23379v1"
  },
  {
    "id": "2510.23364v1",
    "title": "ZeroFlood: A Geospatial Foundation Model for Data-Efficient Flood\n  Susceptibility Mapping",
    "abstract": "Flood susceptibility mapping (FSM) is vital for disaster prevention but\nremains challenging in data-scarce regions where hydrodynamic models require\ndense geophysical inputs. This work introduces ZeroFlood, a geospatial\nfoundation model framework for data-efficient FSM. The approach fine-tunes\nGeospatial Foundation Models (GFMs) with Thinking-in-Modality (TiM) reasoning,\nenabling flood prediction from basic Earth observation data such as Sentinel-1\nor Sentinel-2 imagery. Using paired EO and simulated flood maps from data-rich\nregions, ZeroFlood bridges data availability gaps through cross-modal\nrepresentation learning. Experiments with TerraMind and Prithvi GFMs show that\nTiM enhances model robustness, with the TerraMind-Large configuration achieving\nan F1 score of 67.21. The results demonstrate the feasibility of\nfoundation-model-based FSM as a scalable and data-efficient solution for flood\nrisk management.",
    "categories": [
      "cs.LG",
      "cs.AI"
    ],
    "published": "2025-10-27T14:14:09Z",
    "authors": [
      "Hyeongkyun Kim",
      "Orestis Oikonomou"
    ],
    "pdf_url": "http://arxiv.org/pdf/2510.23364v1"
  },
  {
    "id": "2510.23340v1",
    "title": "Planning Ahead with RSA: Efficient Signalling in Dynamic Environments by\n  Projecting User Awareness across Future Timesteps",
    "abstract": "Adaptive agent design offers a way to improve human-AI collaboration on\ntime-sensitive tasks in rapidly changing environments. In such cases, to ensure\nthe human maintains an accurate understanding of critical task elements, an\nassistive agent must not only identify the highest priority information but\nalso estimate how and when this information can be communicated most\neffectively, given that human attention represents a zero-sum cognitive\nresource where focus on one message diminishes awareness of other or upcoming\ninformation. We introduce a theoretical framework for adaptive signalling which\nmeets these challenges by using principles of rational communication,\nformalised as Bayesian reference resolution using the Rational Speech Act (RSA)\nmodelling framework, to plan a sequence of messages which optimise timely\nalignment between user belief and a dynamic environment. The agent adapts\nmessage specificity and timing to the particulars of a user and scenario based\non projections of how prior-guided interpretation of messages will influence\nattention to the interface and subsequent belief update, across several\ntimesteps out to a fixed horizon. In a comparison to baseline methods, we show\nthat this effectiveness depends crucially on combining multi-step planning with\na realistic model of user awareness. As the first application of RSA for\ncommunication in a dynamic environment, and for human-AI interaction in\ngeneral, we establish theoretical foundations for pragmatic communication in\nhuman-agent teams, highlighting how insights from cognitive science can be\ncapitalised to inform the design of assistive agents.",
    "categories": [
      "cs.AI",
      "cs.CL",
      "cs.HC"
    ],
    "published": "2025-10-27T13:54:54Z",
    "authors": [
      "Anwesha Das",
      "John Duff",
      "J\u00f6rg Hoffmann",
      "Vera Demberg"
    ],
    "pdf_url": "http://arxiv.org/pdf/2510.23340v1"
  },
  {
    "id": "2510.23325v1",
    "title": "Multitask Multimodal Self-Supervised Learning for Medical Images",
    "abstract": "This thesis works to address a pivotal challenge in medical image analysis:\nthe reliance on extensive labeled datasets, which are often limited due to the\nneed for expert annotation and constrained by privacy and legal issues. By\nfocusing on the development of self-supervised learning techniques and domain\nadaptation methods, this research aims to circumvent these limitations,\npresenting a novel approach to enhance the utility and efficacy of deep\nlearning in medical imaging.\n  Central to this thesis is the development of the Medformer, an innovative\nneural network architecture designed for multitask learning and deep domain\nadaptation. This model is adept at pre-training on diverse medical image\ndatasets, handling varying sizes and modalities, and is equipped with a dynamic\ninput-output adaptation mechanism. This enables efficient processing and\nintegration of a wide range of medical image types, from 2D X-rays to complex\n3D MRIs, thus mitigating the dependency on large labeled datasets.\n  Further, the thesis explores the current state of self-supervised learning in\nmedical imaging. It introduces novel pretext tasks that are capable of\nextracting meaningful information from unlabeled data, significantly advancing\nthe model's interpretative abilities. This approach is validated through\nrigorous experimentation, including the use of the MedMNIST dataset,\ndemonstrating the model's proficiency in learning generalized features\napplicable to various downstream tasks.\n  In summary, this thesis contributes to the advancement of medical image\nanalysis by offering a scalable, adaptable framework that reduces reliance on\nlabeled data. It paves the way for more accurate, efficient diagnostic tools in\nhealthcare, signifying a major step forward in the application of deep learning\nin medical imaging.",
    "categories": [
      "cs.CV",
      "cs.AI",
      "cs.LG"
    ],
    "published": "2025-10-27T13:42:16Z",
    "authors": [
      "Cristian Simionescu"
    ],
    "pdf_url": "http://arxiv.org/pdf/2510.23325v1"
  },
  {
    "id": "2510.24793v1",
    "title": "SwiftEmbed: Ultra-Fast Text Embeddings via Static Token Lookup for\n  Real-Time Applications",
    "abstract": "We present a static token lookup methodology for text embedding generation\nthat achieves 1.12 ms p50 latency for single text embeddings while maintaining\n60.6 MTEB average score across 8 representative tasks, corresponding to 89% of\ncontextual model quality. The Rust implementation delivers 50,000 requests per\nsecond throughput through static embedding lookup, optimized mean pooling, and\nzero-copy IEEE754 binary serialization. Evaluation demonstrates exceptional\nduplicate detection performance (90.1% AP), strong semantic similarity (76.1%\nSpearman correlation), and domain-specific performance ranging from 75% to 131%\nof baseline across specialized domains. The system enables real-time embedding\napplications where sub-5ms latency is critical.",
    "categories": [
      "cs.CL",
      "cs.AI"
    ],
    "published": "2025-10-27T13:40:26Z",
    "authors": [
      "Edouard Lansiaux"
    ],
    "pdf_url": "http://arxiv.org/pdf/2510.24793v1"
  },
  {
    "id": "2510.23319v1",
    "title": "Arabic Little STT: Arabic Children Speech Recognition Dataset",
    "abstract": "The performance of Artificial Intelligence (AI) systems fundamentally depends\non high-quality training data. However, low-resource languages like Arabic\nsuffer from severe data scarcity. Moreover, the absence of child-specific\nspeech corpora is an essential gap that poses significant challenges. To\naddress this gap, we present our created dataset, Arabic Little STT, a dataset\nof Levantine Arabic child speech recorded in classrooms, containing 355\nutterances from 288 children (ages 6 - 13). We further conduct a systematic\nassessment of Whisper, a state-of-the-art automatic speech recognition (ASR)\nmodel, on this dataset and compare its performance with adult Arabic\nbenchmarks. Our evaluation across eight Whisper variants reveals that even the\nbest-performing model (Large_v3) struggles significantly, achieving a 0.66 word\nerror rate (WER) on child speech, starkly contrasting with its sub 0.20 WER on\nadult datasets. These results align with other research on English speech.\nResults highlight the critical need for dedicated child speech benchmarks and\ninclusive training data in ASR development. Emphasizing that such data must be\ngoverned by strict ethical and privacy frameworks to protect sensitive child\ninformation. We hope that this study provides an initial step for future work\non equitable speech technologies for Arabic-speaking children. We hope that our\npublicly available dataset enrich the children's demographic representation in\nASR datasets.",
    "categories": [
      "cs.CL",
      "cs.AI",
      "cs.HC",
      "cs.LG",
      "cs.SD"
    ],
    "published": "2025-10-27T13:30:54Z",
    "authors": [
      "Mouhand Alkadri",
      "Dania Desouki",
      "Khloud Al Jallad"
    ],
    "pdf_url": "http://arxiv.org/pdf/2510.23319v1"
  },
  {
    "id": "2510.23306v1",
    "title": "ReconViaGen: Towards Accurate Multi-view 3D Object Reconstruction via\n  Generation",
    "abstract": "Existing multi-view 3D object reconstruction methods heavily rely on\nsufficient overlap between input views, where occlusions and sparse coverage in\npractice frequently yield severe reconstruction incompleteness. Recent\nadvancements in diffusion-based 3D generative techniques offer the potential to\naddress these limitations by leveraging learned generative priors to\nhallucinate invisible parts of objects, thereby generating plausible 3D\nstructures. However, the stochastic nature of the inference process limits the\naccuracy and reliability of generation results, preventing existing\nreconstruction frameworks from integrating such 3D generative priors. In this\nwork, we comprehensively analyze the reasons why diffusion-based 3D generative\nmethods fail to achieve high consistency, including (a) the insufficiency in\nconstructing and leveraging cross-view connections when extracting multi-view\nimage features as conditions, and (b) the poor controllability of iterative\ndenoising during local detail generation, which easily leads to plausible but\ninconsistent fine geometric and texture details with inputs. Accordingly, we\npropose ReconViaGen to innovatively integrate reconstruction priors into the\ngenerative framework and devise several strategies that effectively address\nthese issues. Extensive experiments demonstrate that our ReconViaGen can\nreconstruct complete and accurate 3D models consistent with input views in both\nglobal structure and local details.Project page:\nhttps://jiahao620.github.io/reconviagen.",
    "categories": [
      "cs.CV",
      "cs.AI"
    ],
    "published": "2025-10-27T13:15:06Z",
    "authors": [
      "Jiahao Chang",
      "Chongjie Ye",
      "Yushuang Wu",
      "Yuantao Chen",
      "Yidan Zhang",
      "Zhongjin Luo",
      "Chenghong Li",
      "Yihao Zhi",
      "Xiaoguang Han"
    ],
    "pdf_url": "http://arxiv.org/pdf/2510.23306v1"
  },
  {
    "id": "2510.23304v1",
    "title": "CNOT Minimal Circuit Synthesis: A Reinforcement Learning Approach",
    "abstract": "CNOT gates are fundamental to quantum computing, as they facilitate\nentanglement, a crucial resource for quantum algorithms. Certain classes of\nquantum circuits are constructed exclusively from CNOT gates. Given their\nwidespread use, it is imperative to minimise the number of CNOT gates employed.\nThis problem, known as CNOT minimisation, remains an open challenge, with its\ncomputational complexity yet to be fully characterised. In this work, we\nintroduce a novel reinforcement learning approach to address this task. Instead\nof training multiple reinforcement learning agents for different circuit sizes,\nwe use a single agent up to a fixed size $m$. Matrices of sizes different from\nm are preprocessed using either embedding or Gaussian striping. To assess the\nefficacy of our approach, we trained an agent with m = 8, and evaluated it on\nmatrices of size n that range from 3 to 15. The results we obtained show that\nour method overperforms the state-of-the-art algorithm as the value of n\nincreases.",
    "categories": [
      "cs.AI"
    ],
    "published": "2025-10-27T13:13:39Z",
    "authors": [
      "Riccardo Romanello",
      "Daniele Lizzio Bosco",
      "Jacopo Cossio",
      "Dusan Sutulovic",
      "Giuseppe Serra",
      "Carla Piazza",
      "Paolo Burelli"
    ],
    "pdf_url": "http://arxiv.org/pdf/2510.23304v1"
  },
  {
    "id": "2510.23273v1",
    "title": "A Novel Framework for Multi-Modal Protein Representation Learning",
    "abstract": "Accurate protein function prediction requires integrating heterogeneous\nintrinsic signals (e.g., sequence and structure) with noisy extrinsic contexts\n(e.g., protein-protein interactions and GO term annotations). However, two key\nchallenges hinder effective fusion: (i) cross-modal distributional mismatch\namong embeddings produced by pre-trained intrinsic encoders, and (ii) noisy\nrelational graphs of extrinsic data that degrade GNN-based information\naggregation. We propose Diffused and Aligned Multi-modal Protein Embedding\n(DAMPE), a unified framework that addresses these through two core mechanisms.\nFirst, we propose Optimal Transport (OT)-based representation alignment that\nestablishes correspondence between intrinsic embedding spaces of different\nmodalities, effectively mitigating cross-modal heterogeneity. Second, we\ndevelop a Conditional Graph Generation (CGG)-based information fusion method,\nwhere a condition encoder fuses the aligned intrinsic embeddings to provide\ninformative cues for graph reconstruction. Meanwhile, our theoretical analysis\nimplies that the CGG objective drives this condition encoder to absorb\ngraph-aware knowledge into its produced protein representations. Empirically,\nDAMPE outperforms or matches state-of-the-art methods such as DPFunc on\nstandard GO benchmarks, achieving AUPR gains of 0.002-0.013 pp and Fmax gains\n0.004-0.007 pp. Ablation studies further show that OT-based alignment\ncontributes 0.043-0.064 pp AUPR, while CGG-based fusion adds 0.005-0.111 pp\nFmax. Overall, DAMPE offers a scalable and theoretically grounded approach for\nrobust multi-modal protein representation learning, substantially enhancing\nprotein function prediction.",
    "categories": [
      "cs.LG",
      "cs.AI",
      "q-bio.QM"
    ],
    "published": "2025-10-27T12:33:01Z",
    "authors": [
      "Runjie Zheng",
      "Zhen Wang",
      "Anjie Qiao",
      "Jiancong Xie",
      "Jiahua Rao",
      "Yuedong Yang"
    ],
    "pdf_url": "http://arxiv.org/pdf/2510.23273v1"
  },
  {
    "id": "2510.23264v1",
    "title": "PAHQ: Accelerating Automated Circuit Discovery through Mixed-Precision\n  Inference Optimization",
    "abstract": "Circuit discovery, which involves identifying sparse and task-relevant\nsubnetworks in pre-trained language models, is a cornerstone of mechanistic\ninterpretability. Automated Circuit Discovery (ACDC) has emerged as a pivotal\nmethodology in circuit discovery, but its application to large language models\nis severely limited by computational inefficiency and prohibitively high memory\nrequirements. Although several accelerated approaches have been proposed, they\nprimarily rely on linear approximations to ACDC, which significantly\ncompromises analytical faithfulness. Our proposed method for accelerating\nautomated circuit discovery, Per Attention Head Quantization (PAHQ), takes a\nfundamentally different approach by optimizing the efficiency of each\nindividual patching operation. PAHQ leverages a fundamental alignment between\nactivation patching and mixed-precision quantization (MPQ): interpretability\nanalysis through patching essentially performs targeted ablation studies.\nTherefore, we can maintain high precision exclusively for investigated\ncomponents while safely reducing precision elsewhere in the network.\nPAHQ-accelerated ACDC reduces runtime by up to 80\\% and memory consumption by\nup to 30\\% compared to unaccelerated ACDC while maintaining faithfulness.\nImportantly, our method readily integrates with existing edge-based circuit\ndiscovery techniques by modifying the attention computation mechanism. This\ntraining-free approach provides a practical and novel pathway for accelerating\nmechanistic interpretability methods. Our code is available at\nhttps://github.com/626619403/PAHQ.",
    "categories": [
      "cs.LG",
      "cs.AI"
    ],
    "published": "2025-10-27T12:24:14Z",
    "authors": [
      "Xinhai Wang",
      "Shu Yang",
      "Liangyu Wang",
      "Lin Zhang",
      "Huanyi Xie",
      "Lijie Hu",
      "Di Wang"
    ],
    "pdf_url": "http://arxiv.org/pdf/2510.23264v1"
  },
  {
    "id": "2510.23258v1",
    "title": "Deep Active Inference with Diffusion Policy and Multiple Timescale World\n  Model for Real-World Exploration and Navigation",
    "abstract": "Autonomous robotic navigation in real-world environments requires exploration\nto acquire environmental information as well as goal-directed navigation in\norder to reach specified targets. Active inference (AIF) based on the\nfree-energy principle provides a unified framework for these behaviors by\nminimizing the expected free energy (EFE), thereby combining epistemic and\nextrinsic values. To realize this practically, we propose a deep AIF framework\nthat integrates a diffusion policy as the policy model and a multiple timescale\nrecurrent state-space model (MTRSSM) as the world model. The diffusion policy\ngenerates diverse candidate actions while the MTRSSM predicts their\nlong-horizon consequences through latent imagination, enabling action selection\nthat minimizes EFE. Real-world navigation experiments demonstrated that our\nframework achieved higher success rates and fewer collisions compared with the\nbaselines, particularly in exploration-demanding scenarios. These results\nhighlight how AIF based on EFE minimization can unify exploration and\ngoal-directed navigation in real-world robotic settings.",
    "categories": [
      "cs.RO",
      "cs.AI",
      "cs.LG"
    ],
    "published": "2025-10-27T12:21:33Z",
    "authors": [
      "Riko Yokozawa",
      "Kentaro Fujii",
      "Yuta Nomura",
      "Shingo Murata"
    ],
    "pdf_url": "http://arxiv.org/pdf/2510.23258v1"
  },
  {
    "id": "2510.23241v1",
    "title": "Progressive Growing of Patch Size: Curriculum Learning for Accelerated\n  and Improved Medical Image Segmentation",
    "abstract": "In this work, we introduce Progressive Growing of Patch Size, an automatic\ncurriculum learning approach for 3D medical image segmentation. Our approach\nprogressively increases the patch size during model training, resulting in an\nimproved class balance for smaller patch sizes and accelerated convergence of\nthe training process. We evaluate our curriculum approach in two settings: a\nresource-efficient mode and a performance mode, both regarding Dice score\nperformance and computational costs across 15 diverse and popular 3D medical\nimage segmentation tasks. The resource-efficient mode matches the Dice score\nperformance of the conventional constant patch size sampling baseline with a\nnotable reduction in training time to only 44%. The performance mode improves\nupon constant patch size segmentation results, achieving a statistically\nsignificant relative mean performance gain of 1.28% in Dice Score. Remarkably,\nacross all 15 tasks, our proposed performance mode manages to surpass the\nconstant patch size baseline in Dice Score performance, while simultaneously\nreducing training time to only 89%. The benefits are particularly pronounced\nfor highly imbalanced tasks such as lesion segmentation tasks. Rigorous\nexperiments demonstrate that our performance mode not only improves mean\nsegmentation performance but also reduces performance variance, yielding more\ntrustworthy model comparison. Furthermore, our findings reveal that the\nproposed curriculum sampling is not tied to a specific architecture but\nrepresents a broadly applicable strategy that consistently boosts performance\nacross diverse segmentation models, including UNet, UNETR, and SwinUNETR. In\nsummary, we show that this simple yet elegant transformation on input data\nsubstantially improves both Dice Score performance and training runtime, while\nbeing compatible across diverse segmentation backbones.",
    "categories": [
      "cs.CV",
      "cs.AI",
      "cs.LG"
    ],
    "published": "2025-10-27T11:55:12Z",
    "authors": [
      "Stefan M. Fischer",
      "Johannes Kiechle",
      "Laura Daza",
      "Lina Felsner",
      "Richard Osuala",
      "Daniel M. Lang",
      "Karim Lekadir",
      "Jan C. Peeken",
      "Julia A. Schnabel"
    ],
    "pdf_url": "http://arxiv.org/pdf/2510.23241v1"
  },
  {
    "id": "2510.23221v1",
    "title": "Accelerating IC Thermal Simulation Data Generation via Block Krylov and\n  Operator Action",
    "abstract": "Recent advances in data-driven approaches, such as neural operators (NOs),\nhave shown substantial efficacy in reducing the solution time for integrated\ncircuit (IC) thermal simulations. However, a limitation of these approaches is\nrequiring a large amount of high-fidelity training data, such as chip\nparameters and temperature distributions, thereby incurring significant\ncomputational costs. To address this challenge, we propose a novel algorithm\nfor the generation of IC thermal simulation data, named block Krylov and\noperator action (BlocKOA), which simultaneously accelerates the data generation\nprocess and enhances the precision of generated data. BlocKOA is specifically\ndesigned for IC applications. Initially, we use the block Krylov algorithm\nbased on the structure of the heat equation to quickly obtain a few basic\nsolutions. Then we combine them to get numerous temperature distributions that\nsatisfy the physical constraints. Finally, we apply heat operators on these\nfunctions to determine the heat source distributions, efficiently generating\nprecise data points. Theoretical analysis shows that the time complexity of\nBlocKOA is one order lower than the existing method. Experimental results\nfurther validate its efficiency, showing that BlocKOA achieves a 420-fold\nspeedup in generating thermal simulation data for 5000 chips with varying\nphysical parameters and IC structures. Even with just 4% of the generation\ntime, data-driven approaches trained on the data generated by BlocKOA exhibits\ncomparable performance to that using the existing method.",
    "categories": [
      "cs.AI",
      "physics.comp-ph"
    ],
    "published": "2025-10-27T11:16:45Z",
    "authors": [
      "Hong Wang",
      "Wenkai Yang",
      "Jie Wang",
      "Huanshuo Dong",
      "Zijie Geng",
      "Zhen Huang",
      "Depeng Xie",
      "Zhezheng Hao",
      "Hande Dong"
    ],
    "pdf_url": "http://arxiv.org/pdf/2510.23221v1"
  },
  {
    "id": "2510.23217v1",
    "title": "Process Reward Models for Sentence-Level Verification of LVLM Radiology\n  Reports",
    "abstract": "Automating radiology report generation with Large Vision-Language Models\n(LVLMs) holds great potential, yet these models often produce clinically\ncritical hallucinations, posing serious risks. Existing hallucination detection\nmethods frequently lack the necessary sentence-level granularity or robust\ngeneralization across different LVLM generators. We introduce a novel approach:\na sentence-level Process Reward Model (PRM) adapted for this vision-language\ntask. Our PRM predicts the factual correctness of each generated sentence,\nconditioned on clinical context and preceding text. When fine-tuned on\nMIMIC-CXR with weakly-supervised labels, a lightweight 0.5B-parameter PRM\noutperforms existing verification techniques, demonstrating, for instance,\nrelative improvements of 7.5% in Matthews Correlation Coefficient and 1.8% in\nAUROC over strong white-box baselines on outputs from one LVLM. Unlike methods\nreliant on internal model states, our PRM demonstrates strong generalization to\nan unseen LVLM. We further show its practical utility: PRM scores effectively\nfilter low-quality reports, improving F1-CheXbert scores by 4.5% (when\ndiscarding the worst 10% of reports). Moreover, when guiding a novel weighted\nbest-of-N selection process on the MIMIC-CXR test set, our PRM show relative\nimprovements in clinical metrics of 7.4% for F1-CheXbert and 0.6% for\nBERTScore. These results demonstrate that a lightweight, context-aware PRM\nprovides a model-agnostic safety layer for clinical LVLMs without access to\ninternal activations",
    "categories": [
      "cs.CL",
      "cs.AI"
    ],
    "published": "2025-10-27T11:08:05Z",
    "authors": [
      "Alois Thomas",
      "Maya Varma",
      "Jean-Benoit Delbrouck",
      "Curtis P. Langlotz"
    ],
    "pdf_url": "http://arxiv.org/pdf/2510.23217v1"
  },
  {
    "id": "2510.23216v3",
    "title": "Human-Like Goalkeeping in a Realistic Football Simulation: a\n  Sample-Efficient Reinforcement Learning Approach",
    "abstract": "While several high profile video games have served as testbeds for Deep\nReinforcement Learning (DRL), this technique has rarely been employed by the\ngame industry for crafting authentic AI behaviors. Previous research focuses on\ntraining super-human agents with large models, which is impractical for game\nstudios with limited resources aiming for human-like agents. This paper\nproposes a sample-efficient DRL method tailored for training and fine-tuning\nagents in industrial settings such as the video game industry. Our method\nimproves sample efficiency of value-based DRL by leveraging pre-collected data\nand increasing network plasticity. We evaluate our method training a goalkeeper\nagent in EA SPORTS FC 25, one of the best-selling football simulations today.\nOur agent outperforms the game's built-in AI by 10% in ball saving rate.\nAblation studies show that our method trains agents 50% faster compared to\nstandard DRL methods. Finally, qualitative evaluation from domain experts\nindicates that our approach creates more human-like gameplay compared to\nhand-crafted agents. As a testament to the impact of the approach, the method\nhas been adopted for use in the most recent release of the series.",
    "categories": [
      "cs.AI",
      "cs.LG"
    ],
    "published": "2025-10-27T11:06:00Z",
    "authors": [
      "Alessandro Sestini",
      "Joakim Bergdahl",
      "Jean-Philippe Barrette-LaPierre",
      "Florian Fuchs",
      "Brady Chen",
      "Michael Jones",
      "Linus Gissl\u00e9n"
    ],
    "pdf_url": "http://arxiv.org/pdf/2510.23216v3"
  },
  {
    "id": "2510.23215v1",
    "title": "Accelerating Eigenvalue Dataset Generation via Chebyshev Subspace Filter",
    "abstract": "Eigenvalue problems are among the most important topics in many scientific\ndisciplines. With the recent surge and development of machine learning, neural\neigenvalue methods have attracted significant attention as a forward pass of\ninference requires only a tiny fraction of the computation time compared to\ntraditional solvers. However, a key limitation is the requirement for large\namounts of labeled data in training, including operators and their eigenvalues.\nTo tackle this limitation, we propose a novel method, named Sorting Chebyshev\nSubspace Filter (SCSF), which significantly accelerates eigenvalue data\ngeneration by leveraging similarities between operators -- a factor overlooked\nby existing methods. Specifically, SCSF employs truncated fast Fourier\ntransform sorting to group operators with similar eigenvalue distributions and\nconstructs a Chebyshev subspace filter that leverages eigenpairs from\npreviously solved problems to assist in solving subsequent ones, reducing\nredundant computations. To the best of our knowledge, SCSF is the first method\nto accelerate eigenvalue data generation. Experimental results show that SCSF\nachieves up to a $3.5\\times$ speedup compared to various numerical solvers.",
    "categories": [
      "cs.LG",
      "cs.AI",
      "cs.NA",
      "math.NA"
    ],
    "published": "2025-10-27T11:05:16Z",
    "authors": [
      "Hong Wang",
      "Jie Wang",
      "Jian Luo",
      "huanshuo dong",
      "Yeqiu Chen",
      "Runmin Jiang",
      "Zhen huang"
    ],
    "pdf_url": "http://arxiv.org/pdf/2510.23215v1"
  },
  {
    "id": "2510.23214v1",
    "title": "AUPO -- Abstracted Until Proven Otherwise: A Reward Distribution Based\n  Abstraction Algorithm",
    "abstract": "We introduce a novel, drop-in modification to Monte Carlo Tree Search's\n(MCTS) decision policy that we call AUPO. Comparisons based on a range of IPPC\nbenchmark problems show that AUPO clearly outperforms MCTS. AUPO is an\nautomatic action abstraction algorithm that solely relies on reward\ndistribution statistics acquired during the MCTS. Thus, unlike other automatic\nabstraction algorithms, AUPO requires neither access to transition\nprobabilities nor does AUPO require a directed acyclic search graph to build\nits abstraction, allowing AUPO to detect symmetric actions that\nstate-of-the-art frameworks like ASAP struggle with when the resulting\nsymmetric states are far apart in state space. Furthermore, as AUPO only\naffects the decision policy, it is not mutually exclusive with other\nabstraction techniques that only affect the tree search.",
    "categories": [
      "cs.AI"
    ],
    "published": "2025-10-27T11:04:22Z",
    "authors": [
      "Robin Schm\u00f6cker",
      "Alexander Dockhorn",
      "Bodo Rosenhahn"
    ],
    "pdf_url": "http://arxiv.org/pdf/2510.23214v1"
  },
  {
    "id": "2510.24792v1",
    "title": "PISA-Bench: The PISA Index as a Multilingual and Multimodal Metric for\n  the Evaluation of Vision-Language Models",
    "abstract": "Vision-language models (VLMs) have demonstrated remarkable progress in\nmultimodal reasoning. However, existing benchmarks remain limited in terms of\nhigh-quality, human-verified examples. Many current datasets rely on\nsynthetically generated content by large language models (LLMs). Furthermore,\nmost datasets are limited to English, as manual quality assurance of translated\nsamples is time-consuming and costly. To fill this gap, we introduce\nPISA-Bench, a multilingual benchmark derived from English examples of the\nexpert-created PISA tests, a unified framework for the assessment of student\ncompetencies in over eighty countries. Each example consists of human-extracted\ninstructions, questions, answer options, and images, enriched with question\ntype categories, and has been translated from English into five additional\nlanguages (Spanish, German, Chinese, French, and Italian), resulting in a fully\nparallel corpus covering six languages. We evaluate state-of-the-art\nvision-language models on PISA-Bench and find that especially small models\n(<20B parameters) fail to achieve high test scores. We further find substantial\nperformance degradation on non-English splits as well as high error-rates when\nmodels are tasked with spatial and geometric reasoning. By releasing the\ndataset and evaluation framework, we provide a resource for advancing research\non multilingual multimodal reasoning.",
    "categories": [
      "cs.CV",
      "cs.AI"
    ],
    "published": "2025-10-27T11:00:45Z",
    "authors": [
      "Patrick Haller",
      "Fabio Barth",
      "Jonas Golde",
      "Georg Rehm",
      "Alan Akbik"
    ],
    "pdf_url": "http://arxiv.org/pdf/2510.24792v1"
  },
  {
    "id": "2510.23208v1",
    "title": "Increasing LLM Coding Capabilities through Diverse Synthetic Coding\n  Tasks",
    "abstract": "Large language models (LLMs) have shown impressive promise in code\ngeneration, yet their progress remains limited by the shortage of large-scale\ndatasets that are both diverse and well-aligned with human reasoning. Most\nexisting resources pair problems with solutions, but omit the intermediate\nthought process that guides coding. To close this gap, we present a scalable\nsynthetic data generation pipeline that produces nearly 800k\ninstruction-reasoning-code-test quadruplets. Each sample combines a task, a\nstep-by-step reasoning trace, a working solution, and executable tests,\nenabling models to learn not just the what but also the how of problem solving.\nOur pipeline combines four key components: curated contest problems, web-mined\ncontent filtered by relevance classifiers, data expansion guided by reasoning\npatterns, and multi-stage execution-based validation. A genetic mutation\nalgorithm further increases task diversity while maintaining consistency\nbetween reasoning traces and code implementations. Our key finding is that\nfine-tuning LLMs on this dataset yields consistent improvements on coding\nbenchmarks. Beyond raw accuracy, reasoning-aware data can substitute for model\nscaling, generalize across architectures, and outperform leading open-source\nalternatives under identical sample budgets. Our work establishes\nreasoning-centered synthetic data generation as an efficient approach for\nadvancing coding capabilities in LLMs. We publish our dataset and generation\npipeline to facilitate further research.",
    "categories": [
      "cs.LG",
      "cs.AI"
    ],
    "published": "2025-10-27T10:54:25Z",
    "authors": [
      "Amal Abed",
      "Ivan Lukic",
      "J\u00f6rg K. H. Franke",
      "Frank Hutter"
    ],
    "pdf_url": "http://arxiv.org/pdf/2510.23208v1"
  },
  {
    "id": "2510.23198v1",
    "title": "PTPP-Aware Adaptation Scaling Laws: Predicting Domain-Adaptation\n  Performance at Unseen Pre-Training Budgets",
    "abstract": "Continual pre-training (CPT) for domain adaptation must balance target-domain\ngains with stability on the base domain. Existing CPT scaling laws typically\nassume a fixed pre-training budget, which limits their ability to forecast\nadaptation outcomes for models trained at different tokens-per-parameter\n(PTPP). We present \\emph{PTPP-aware} adaptation scaling laws that make the\npre-training budget an explicit variable, enabling accurate \\emph{prediction}\nof adaptation loss at unseen \\ptpp. On a multilingual setup (English/Arabic\n$\\rightarrow$ French), PTPP-aware formulations trained on early stages\n(\\ptpp{}=\\{15,31\\}) predict target loss at \\ptpp{}=279 and outperform a\nPTPP-agnostic \\dcpt{} transfer baseline on metrics (Huber-on-log,\nMAE$_\\mathrm{rel}$, calibration slope); full diagnostics (RMSE, MAPE) are in\nthe appendix. Beyond forecasting, we show a practical use case: planning replay\nratios and adaptation token budgets that satisfy target and forgetting\nconstraints under compute limits.",
    "categories": [
      "cs.LG",
      "cs.AI",
      "cs.CL"
    ],
    "published": "2025-10-27T10:36:15Z",
    "authors": [
      "Etienne Goffinet",
      "Shane Bergsma",
      "Avraham Sheinin",
      "Natalia Vassilieva",
      "Shaheer Muhammad",
      "Preslav Nakov",
      "Gurpreet Gosal"
    ],
    "pdf_url": "http://arxiv.org/pdf/2510.23198v1"
  },
  {
    "id": "2510.23189v1",
    "title": "DREaM: Drug-Drug Relation Extraction via Transfer Learning Method",
    "abstract": "Relation extraction between drugs plays a crucial role in identifying drug\ndrug interactions and predicting side effects. The advancement of machine\nlearning methods in relation extraction, along with the development of large\nmedical text databases, has enabled the low cost extraction of such relations\ncompared to other approaches that typically require expert knowledge. However,\nto the best of our knowledge, there are limited datasets specifically designed\nfor drug drug relation extraction currently available. Therefore, employing\ntransfer learning becomes necessary to apply machine learning methods in this\ndomain. In this study, we propose DREAM, a method that first employs a trained\nrelation extraction model to discover relations between entities and then\napplies this model to a corpus of medical texts to construct an ontology of\ndrug relationships. The extracted relations are subsequently validated using a\nlarge language model. Quantitative results indicate that the LLM agreed with 71\nof the relations extracted from a subset of PubMed abstracts. Furthermore, our\nqualitative analysis indicates that this approach can uncover ambiguities in\nthe medical domain, highlighting the challenges inherent in relation extraction\nin this field.",
    "categories": [
      "cs.CL",
      "cs.AI",
      "cs.LG"
    ],
    "published": "2025-10-27T10:27:00Z",
    "authors": [
      "Ali Fata",
      "Hossein Rahmani",
      "Parinaz Soltanzadeh",
      "Amirhossein Derakhshan",
      "Behrouz Minaei Bidgoli"
    ],
    "pdf_url": "http://arxiv.org/pdf/2510.23189v1"
  },
  {
    "id": "2510.23167v1",
    "title": "Guiding Skill Discovery with Foundation Models",
    "abstract": "Learning diverse skills without hand-crafted reward functions could\naccelerate reinforcement learning in downstream tasks. However, existing skill\ndiscovery methods focus solely on maximizing the diversity of skills without\nconsidering human preferences, which leads to undesirable behaviors and\npossibly dangerous skills. For instance, a cheetah robot trained using previous\nmethods learns to roll in all directions to maximize skill diversity, whereas\nwe would prefer it to run without flipping or entering hazardous areas. In this\nwork, we propose a Foundation model Guided (FoG) skill discovery method, which\nincorporates human intentions into skill discovery through foundation models.\nSpecifically, FoG extracts a score function from foundation models to evaluate\nstates based on human intentions, assigning higher values to desirable states\nand lower to undesirable ones. These scores are then used to re-weight the\nrewards of skill discovery algorithms. By optimizing the re-weighted skill\ndiscovery rewards, FoG successfully learns to eliminate undesirable behaviors,\nsuch as flipping or rolling, and to avoid hazardous areas in both state-based\nand pixel-based tasks. Interestingly, we show that FoG can discover skills\ninvolving behaviors that are difficult to define. Interactive visualisations\nare available from https://sites.google.com/view/submission-fog.",
    "categories": [
      "cs.AI"
    ],
    "published": "2025-10-27T09:47:40Z",
    "authors": [
      "Zhao Yang",
      "Thomas M. Moerland",
      "Mike Preuss",
      "Aske Plaat",
      "Vincent Fran\u00e7ois-Lavet",
      "Edward S. Hu"
    ],
    "pdf_url": "http://arxiv.org/pdf/2510.23167v1"
  },
  {
    "id": "2510.23163v1",
    "title": "Beyond Direct Generation: A Decomposed Approach to Well-Crafted\n  Screenwriting with LLMs",
    "abstract": "The screenplay serves as the foundation for television production, defining\nnarrative structure, character development, and dialogue. While Large Language\nModels (LLMs) show great potential in creative writing, direct end-to-end\ngeneration approaches often fail to produce well-crafted screenplays. We argue\nthis failure stems from forcing a single model to simultaneously master two\ndisparate capabilities: creative narrative construction and rigid format\nadherence. The resulting outputs may mimic superficial style but lack the deep\nstructural integrity and storytelling substance required for professional use.\nTo enable LLMs to generate high-quality screenplays, we introduce Dual-Stage\nRefinement (DSR), a decomposed framework that decouples creative narrative\ngeneration from format conversion. The first stage transforms a brief outline\ninto rich, novel-style prose. The second stage refines this narrative into a\nprofessionally formatted screenplay. This separation enables the model to\nspecialize in one distinct capability at each stage. A key challenge in\nimplementing DSR is the scarcity of paired outline-to-novel training data. We\naddress this through hybrid data synthesis: reverse synthesis deconstructs\nexisting screenplays into structured inputs, while forward synthesis leverages\nthese inputs to generate high-quality narrative texts as training targets.\nBlind evaluations by professional screenwriters show that DSR achieves a 75%\nwin rate against strong baselines like Gemini-2.5-Pro and reaches 82.7% of\nhuman-level performance. Our work demonstrates that decomposed generation\narchitecture with tailored data synthesis effectively specializes LLMs in\ncomplex creative domains.",
    "categories": [
      "cs.CL",
      "cs.AI",
      "I.2.0"
    ],
    "published": "2025-10-27T09:41:29Z",
    "authors": [
      "Hang Lei",
      "Shengyi Zong",
      "Zhaoyan Li",
      "Ziren Zhou",
      "Hao Liu"
    ],
    "pdf_url": "http://arxiv.org/pdf/2510.23163v1"
  },
  {
    "id": "2510.23156v1",
    "title": "Enabling Vibration-Based Gesture Recognition on Everyday Furniture via\n  Energy-Efficient FPGA Implementation of 1D Convolutional Networks",
    "abstract": "The growing demand for smart home interfaces has increased interest in\nnon-intrusive sensing methods like vibration-based gesture recognition. While\nprior studies demonstrated feasibility, they often rely on complex\npreprocessing and large Neural Networks (NNs) requiring costly high-performance\nhardware, resulting in high energy usage and limited real-world deployability.\nThis study proposes an energy-efficient solution deploying compact NNs on\nlow-power Field-Programmable Gate Arrays (FPGAs) to enable real-time gesture\nrecognition with competitive accuracy. We adopt a series of optimizations: (1)\nWe replace complex spectral preprocessing with raw waveform input, eliminating\ncomplex on-board preprocessing while reducing input size by 21x without\nsacrificing accuracy. (2) We design two lightweight architectures (1D-CNN and\n1D-SepCNN) tailored for embedded FPGAs, reducing parameters from 369 million to\nas few as 216 while maintaining comparable accuracy. (3) With integer-only\nquantization and automated RTL generation, we achieve seamless FPGA deployment.\nA ping-pong buffering mechanism in 1D-SepCNN further improves deployability\nunder tight memory constraints. (4) We extend a hardware-aware search framework\nto support constraint-driven model configuration selection, considering\naccuracy, deployability, latency, and energy consumption. Evaluated on two\nswipe-direction datasets with multiple users and ordinary tables, our approach\nachieves low-latency, energy-efficient inference on the AMD Spartan-7 XC7S25\nFPGA. Under the PS data splitting setting, the selected 6-bit 1D-CNN reaches\n0.970 average accuracy across users with 9.22 ms latency. The chosen 8-bit\n1D-SepCNN further reduces latency to 6.83 ms (over 53x CPU speedup) with\nslightly lower accuracy (0.949). Both consume under 1.2 mJ per inference,\ndemonstrating suitability for long-term edge operation.",
    "categories": [
      "cs.LG",
      "cs.AI"
    ],
    "published": "2025-10-27T09:30:36Z",
    "authors": [
      "Koki Shibata",
      "Tianheng Ling",
      "Chao Qian",
      "Tomokazu Matsui",
      "Hirohiko Suwa",
      "Keiichi Yasumoto",
      "Gregor Schiele"
    ],
    "pdf_url": "http://arxiv.org/pdf/2510.23156v1"
  },
  {
    "id": "2510.23148v1",
    "title": "Adapting Interleaved Encoders with PPO for Language-Guided Reinforcement\n  Learning in BabyAI",
    "abstract": "Deep reinforcement learning agents often struggle when tasks require\nunderstanding both vision and language. Conventional architectures typically\nisolate perception (for example, CNN-based visual encoders) from\ndecision-making (policy networks). This separation can be inefficient, since\nthe policy's failures do not directly help the perception module learn what is\nimportant. To address this, we implement the Perception-Decision Interleaving\nTransformer (PDiT) architecture introduced by Mao et al. (2023), a model that\nalternates between perception and decision layers within a single transformer.\nThis interleaving allows feedback from decision-making to refine perceptual\nfeatures dynamically. In addition, we integrate a contrastive loss inspired by\nCLIP to align textual mission embeddings with visual scene features. We\nevaluate the PDiT encoders on the BabyAI GoToLocal environment and find that\nthe approach achieves more stable rewards and stronger alignment compared to a\nstandard PPO baseline. The results suggest that interleaved transformer\nencoders are a promising direction for developing more integrated autonomous\nagents.",
    "categories": [
      "cs.LG",
      "cs.AI",
      "eess.IV",
      "I.2.6; I.2.9; I.5.4"
    ],
    "published": "2025-10-27T09:24:51Z",
    "authors": [
      "Aryan Mathur",
      "Asaduddin Ahmed"
    ],
    "pdf_url": "http://arxiv.org/pdf/2510.23148v1"
  },
  {
    "id": "2510.23142v1",
    "title": "Rethinking GSPO: The Perplexity-Entropy Equivalence",
    "abstract": "We provide a new perspective on GSPO's length-normalized importance ratios by\nestablishing their connection to information-theoretic quantities. We show that\nGSPO's sequence-level weight $s(\\theta) =\n(\\pi_\\theta/\\pi_{\\theta_{\\text{old}}})^{1/|y|}$ can be equivalently expressed\nas the inverse perplexity ratio\n$\\text{PPL}_{\\theta_{\\text{old}}}/\\text{PPL}_\\theta$ and as the exponential\ncross-entropy change $\\exp(\\Delta H)$. While the perplexity-entropy\nrelationship follows from standard definitions, this observation provides a\nuseful lens for understanding GSPO: the algorithm weights policy gradient\nupdates by perplexity ratios, offering an information-theoretic interpretation\nof the importance weights. This perspective helps explain GSPO's empirical\nproperties, including log-domain variance reduction through geometric averaging\nand stability in training mixture-of-experts models. We validate the\nmathematical equivalences and variance predictions through controlled\nexperiments on mathematical reasoning tasks.",
    "categories": [
      "cs.LG",
      "cs.AI",
      "cs.CL"
    ],
    "published": "2025-10-27T09:19:10Z",
    "authors": [
      "Chi Liu"
    ],
    "pdf_url": "http://arxiv.org/pdf/2510.23142v1"
  },
  {
    "id": "2510.23127v2",
    "title": "Lost in Tokenization: Context as the Key to Unlocking Biomolecular\n  Understanding in Scientific LLMs",
    "abstract": "Scientific Large Language Models (Sci-LLMs) have emerged as a promising\nfrontier for accelerating biological discovery. However, these models face a\nfundamental challenge when processing raw biomolecular sequences: the\ntokenization dilemma. Whether treating sequences as a specialized language,\nrisking the loss of functional motif information, or as a separate modality,\nintroducing formidable alignment challenges, current strategies fundamentally\nlimit their reasoning capacity. We challenge this sequence-centric paradigm by\npositing that a more effective strategy is to provide Sci-LLMs with high-level\nstructured context derived from established bioinformatics tools, thereby\nbypassing the need to interpret low-level noisy sequence data directly. Through\na systematic comparison of leading Sci-LLMs on biological reasoning tasks, we\ntested three input modes: sequence-only, context-only, and a combination of\nboth. Our findings are striking: the context-only approach consistently and\nsubstantially outperforms all other modes. Even more revealing, the inclusion\nof the raw sequence alongside its high-level context consistently degrades\nperformance, indicating that raw sequences act as informational noise, even for\nmodels with specialized tokenization schemes. These results suggest that the\nprimary strength of existing Sci-LLMs lies not in their nascent ability to\ninterpret biomolecular syntax from scratch, but in their profound capacity for\nreasoning over structured, human-readable knowledge. Therefore, we argue for\nreframing Sci-LLMs not as sequence decoders, but as powerful reasoning engines\nover expert knowledge. This work lays the foundation for a new class of hybrid\nscientific AI agents, repositioning the developmental focus from direct\nsequence interpretation towards high-level knowledge synthesis. The code is\navailable at https://github.com/opendatalab-raiser/CoKE.",
    "categories": [
      "cs.AI"
    ],
    "published": "2025-10-27T09:03:21Z",
    "authors": [
      "Kai Zhuang",
      "Jiawei Zhang",
      "Yumou Liu",
      "Hanqun Cao",
      "Chunbin Gu",
      "Mengdi Liu",
      "Zhangyang Gao",
      "Zitong Jerry Wang",
      "Xuanhe Zhou",
      "Pheng-Ann Heng",
      "Lijun Wu",
      "Conghui He",
      "Cheng Tan"
    ],
    "pdf_url": "http://arxiv.org/pdf/2510.23127v2"
  },
  {
    "id": "2510.23112v2",
    "title": "GroupSHAP-Guided Integration of Financial News Keywords and Technical\n  Indicators for Stock Price Prediction",
    "abstract": "Recent advances in finance-specific language models such as FinBERT have\nenabled the quantification of public sentiment into index-based measures, yet\ncompressing diverse linguistic signals into single metrics overlooks contextual\nnuances and limits interpretability. To address this limitation, explainable AI\ntechniques, particularly SHAP (SHapley Additive Explanations), have been\nemployed to identify influential features. However, SHAP's computational cost\ngrows exponentially with input features, making it impractical for large-scale\ntext-based financial data. This study introduces a GRU-based forecasting\nframework enhanced with GroupSHAP, which quantifies contributions of\nsemantically related keyword groups rather than individual tokens,\nsubstantially reducing computational burden while preserving interpretability.\nWe employed FinBERT to embed news articles from 2015 to 2024, clustered them\ninto coherent semantic groups, and applied GroupSHAP to measure each group's\ncontribution to stock price movements. The resulting group-level SHAP variables\nacross multiple topics were used as input features for the prediction model.\nEmpirical results from one-day-ahead forecasting of the S&P 500 index\nthroughout 2024 demonstrate that our approach achieves a 32.2% reduction in MAE\nand a 40.5% reduction in RMSE compared with benchmark models without the\nGroupSHAP mechanism. This research presents the first application of GroupSHAP\nin news-driven financial forecasting, showing that grouped sentiment\nrepresentations simultaneously enhance interpretability and predictive\nperformance.",
    "categories": [
      "cs.CE",
      "cs.AI"
    ],
    "published": "2025-10-27T08:33:18Z",
    "authors": [
      "Minjoo Kim",
      "Jinwoong Kim",
      "Sangjin Park"
    ],
    "pdf_url": "http://arxiv.org/pdf/2510.23112v2"
  },
  {
    "id": "2510.23104v1",
    "title": "Leveraging Hierarchical Organization for Medical Multi-document\n  Summarization",
    "abstract": "Medical multi-document summarization (MDS) is a complex task that requires\neffectively managing cross-document relationships. This paper investigates\nwhether incorporating hierarchical structures in the inputs of MDS can improve\na model's ability to organize and contextualize information across documents\ncompared to traditional flat summarization methods. We investigate two ways of\nincorporating hierarchical organization across three large language models\n(LLMs), and conduct comprehensive evaluations of the resulting summaries using\nautomated metrics, model-based metrics, and domain expert evaluation of\npreference, understandability, clarity, complexity, relevance, coverage,\nfactuality, and coherence. Our results show that human experts prefer\nmodel-generated summaries over human-written summaries. Hierarchical approaches\ngenerally preserve factuality, coverage, and coherence of information, while\nalso increasing human preference for summaries. Additionally, we examine\nwhether simulated judgments from GPT-4 align with human judgments, finding\nhigher agreement along more objective evaluation facets. Our findings\ndemonstrate that hierarchical structures can improve the clarity of medical\nsummaries generated by models while maintaining content coverage, providing a\npractical way to improve human preference for generated summaries.",
    "categories": [
      "cs.CL",
      "cs.AI",
      "cs.IR"
    ],
    "published": "2025-10-27T08:18:02Z",
    "authors": [
      "Yi-Li Hsu",
      "Katelyn X. Mei",
      "Lucy Lu Wang"
    ],
    "pdf_url": "http://arxiv.org/pdf/2510.23104v1"
  },
  {
    "id": "2510.23083v1",
    "title": "Smaller Models, Smarter Rewards: A Two-Sided Approach to Process and\n  Outcome Rewards",
    "abstract": "Generating high-quality code remains a challenge for Large Language Models\n(LLMs). For the evolution of reasoning models on this task, reward models are a\nnecessary intermediate step. These models judge outcomes or intermediate steps.\nDecoder-only transformer models can be turned into reward models by introducing\na regression layer and supervised fine-tuning. While it is known that\nreflection capabilities generally increase with the size of a model, we want to\ninvestigate whether state-of-the-art small language models like the Phi-4\nfamily can be turned into usable reward models blending the consideration of\nprocess rewards and outcome rewards.\n  Targeting this goal, we construct a dataset of code samples with correctness\nlabels derived from the APPS coding challenge benchmark. We then train a\nvalue-head model to estimate the success probability of intermediate outputs.\nOur evaluation shows that small LLMs are capable of serving as effective reward\nmodels or code evaluation critics, successfully identifying correct solutions\namong multiple candidates. Using this critic, we achieve over a 20% improvement\nin the search capability of the most accurate code out of multiple generations.",
    "categories": [
      "cs.AI",
      "cs.LG",
      "cs.SE",
      "I.2.7"
    ],
    "published": "2025-10-27T07:36:41Z",
    "authors": [
      "Jan Niklas Groeneveld",
      "Xi Qin",
      "Alexander Schaefer",
      "Yaad Oren"
    ],
    "pdf_url": "http://arxiv.org/pdf/2510.23083v1"
  },
  {
    "id": "2510.23077v1",
    "title": "Think before Recommendation: Autonomous Reasoning-enhanced Recommender",
    "abstract": "The core task of recommender systems is to learn user preferences from\nhistorical user-item interactions. With the rapid development of large language\nmodels (LLMs), recent research has explored leveraging the reasoning\ncapabilities of LLMs to enhance rating prediction tasks. However, existing\ndistillation-based methods suffer from limitations such as the teacher model's\ninsufficient recommendation capability, costly and static supervision, and\nsuperficial transfer of reasoning ability. To address these issues, this paper\nproposes RecZero, a reinforcement learning (RL)-based recommendation paradigm\nthat abandons the traditional multi-model and multi-stage distillation\napproach. Instead, RecZero trains a single LLM through pure RL to autonomously\ndevelop reasoning capabilities for rating prediction. RecZero consists of two\nkey components: (1) \"Think-before-Recommendation\" prompt construction, which\nemploys a structured reasoning template to guide the model in step-wise\nanalysis of user interests, item features, and user-item compatibility; and (2)\nrule-based reward modeling, which adopts group relative policy optimization\n(GRPO) to compute rewards for reasoning trajectories and optimize the LLM.\nAdditionally, the paper explores a hybrid paradigm, RecOne, which combines\nsupervised fine-tuning with RL, initializing the model with cold-start\nreasoning samples and further optimizing it with RL. Experimental results\ndemonstrate that RecZero and RecOne significantly outperform existing baseline\nmethods on multiple benchmark datasets, validating the superiority of the RL\nparadigm in achieving autonomous reasoning-enhanced recommender systems.",
    "categories": [
      "cs.IR",
      "cs.AI"
    ],
    "published": "2025-10-27T07:26:32Z",
    "authors": [
      "Xiaoyu Kong",
      "Junguang Jiang",
      "Bin Liu",
      "Ziru Xu",
      "Han Zhu",
      "Jian Xu",
      "Bo Zheng",
      "Jiancan Wu",
      "Xiang Wang"
    ],
    "pdf_url": "http://arxiv.org/pdf/2510.23077v1"
  },
  {
    "id": "2510.23070v1",
    "title": "Quality-Aware Translation Tagging in Multilingual RAG system",
    "abstract": "Multilingual Retrieval-Augmented Generation (mRAG) often retrieves English\ndocuments and translates them into the query language for low-resource\nsettings. However, poor translation quality degrades response generation\nperformance. Existing approaches either assume sufficient translation quality\nor utilize the rewriting method, which introduces factual distortion and\nhallucinations. To mitigate these problems, we propose Quality-Aware\nTranslation Tagging in mRAG (QTT-RAG), which explicitly evaluates translation\nquality along three dimensions-semantic equivalence, grammatical accuracy, and\nnaturalness&fluency-and attach these scores as metadata without altering the\noriginal content. We evaluate QTT-RAG against CrossRAG and DKM-RAG as baselines\nin two open-domain QA benchmarks (XORQA, MKQA) using six instruction-tuned LLMs\nranging from 2.4B to 14B parameters, covering two low-resource languages\n(Korean and Finnish) and one high-resource language (Chinese). QTT-RAG\noutperforms the baselines by preserving factual integrity while enabling\ngenerator models to make informed decisions based on translation reliability.\nThis approach allows for effective usage of cross-lingual documents in\nlow-resource settings with limited native language documents, offering a\npractical and robust solution across multilingual domains.",
    "categories": [
      "cs.CL",
      "cs.AI"
    ],
    "published": "2025-10-27T07:11:01Z",
    "authors": [
      "Hoyeon Moon",
      "Byeolhee Kim",
      "Nikhil Verma"
    ],
    "pdf_url": "http://arxiv.org/pdf/2510.23070v1"
  },
  {
    "id": "2510.23675v1",
    "title": "QueryIPI: Query-agnostic Indirect Prompt Injection on Coding Agents",
    "abstract": "Modern coding agents integrated into IDEs combine powerful tools and\nsystem-level actions, exposing a high-stakes attack surface. Existing Indirect\nPrompt Injection (IPI) studies focus mainly on query-specific behaviors,\nleading to unstable attacks with lower success rates. We identify a more\nsevere, query-agnostic threat that remains effective across diverse user\ninputs. This challenge can be overcome by exploiting a common vulnerability:\nleakage of the agent's internal prompt, which turns the attack into a\nconstrained white-box optimization problem. We present QueryIPI, the first\nquery-agnostic IPI method for coding agents. QueryIPI refines malicious tool\ndescriptions through an iterative, prompt-based process informed by the leaked\ninternal prompt. Experiments on five simulated agents show that QueryIPI\nachieves up to 87 percent success, outperforming baselines, and the generated\nmalicious descriptions also transfer to real-world systems, highlighting a\npractical security risk to modern LLM-based coding agents.",
    "categories": [
      "cs.CR",
      "cs.AI"
    ],
    "published": "2025-10-27T07:04:08Z",
    "authors": [
      "Yuchong Xie",
      "Zesen Liu",
      "Mingyu Luo",
      "Zhixiang Zhang",
      "Kaikai Zhang",
      "Zongjie Li",
      "Ping Chen",
      "Shuai Wang",
      "Dongdong She"
    ],
    "pdf_url": "http://arxiv.org/pdf/2510.23675v1"
  },
  {
    "id": "2510.23062v1",
    "title": "TLCD: A Deep Transfer Learning Framework for Cross-Disciplinary\n  Cognitive Diagnosis",
    "abstract": "Driven by the dual principles of smart education and artificial intelligence\ntechnology, the online education model has rapidly emerged as an important\ncomponent of the education industry. Cognitive diagnostic technology can\nutilize students' learning data and feedback information in educational\nevaluation to accurately assess their ability level at the knowledge level.\nHowever, while massive amounts of information provide abundant data resources,\nthey also bring about complexity in feature extraction and scarcity of\ndisciplinary data. In cross-disciplinary fields, traditional cognitive\ndiagnostic methods still face many challenges. Given the differences in\nknowledge systems, cognitive structures, and data characteristics between\ndifferent disciplines, this paper conducts in-depth research on neural network\ncognitive diagnosis and knowledge association neural network cognitive\ndiagnosis, and proposes an innovative cross-disciplinary cognitive diagnosis\nmethod (TLCD). This method combines deep learning techniques and transfer\nlearning strategies to enhance the performance of the model in the target\ndiscipline by utilizing the common features of the main discipline. The\nexperimental results show that the cross-disciplinary cognitive diagnosis model\nbased on deep learning performs better than the basic model in\ncross-disciplinary cognitive diagnosis tasks, and can more accurately evaluate\nstudents' learning situation.",
    "categories": [
      "cs.AI"
    ],
    "published": "2025-10-27T06:46:23Z",
    "authors": [
      "Zhifeng Wang",
      "Meixin Su",
      "Yang Yang",
      "Chunyan Zeng",
      "Lizhi Ye"
    ],
    "pdf_url": "http://arxiv.org/pdf/2510.23062v1"
  },
  {
    "id": "2510.23049v1",
    "title": "Advantage Shaping as Surrogate Reward Maximization: Unifying Pass@K\n  Policy Gradients",
    "abstract": "This note reconciles two seemingly distinct approaches to policy gradient\noptimization for the Pass@K objective in reinforcement learning with verifiable\nrewards: (1) direct REINFORCE-style methods, and (2) advantage-shaping\ntechniques that directly modify GRPO. We show that these are two sides of the\nsame coin. By reverse-engineering existing advantage-shaping algorithms, we\nreveal that they implicitly optimize surrogate rewards. We specifically\ninterpret practical ``hard-example up-weighting'' modifications to GRPO as\nreward-level regularization. Conversely, starting from surrogate reward\nobjectives, we provide a simple recipe for deriving both existing and new\nadvantage-shaping methods. This perspective provides a lens for RLVR policy\ngradient optimization beyond our original motivation of Pass@K.",
    "categories": [
      "cs.LG",
      "cs.AI"
    ],
    "published": "2025-10-27T06:24:56Z",
    "authors": [
      "Christos Thrampoulidis",
      "Sadegh Mahdavi",
      "Wenlong Deng"
    ],
    "pdf_url": "http://arxiv.org/pdf/2510.23049v1"
  },
  {
    "id": "2510.23045v2",
    "title": "A Survey of AI Scientists: Surveying the automatic Scientists and\n  Research",
    "abstract": "Artificial intelligence is undergoing a profound transition from a\ncomputational instrument to an autonomous originator of scientific knowledge.\nThis emerging paradigm, the AI scientist, is architected to emulate the\ncomplete scientific workflow-from initial hypothesis generation to the final\nsynthesis of publishable findings-thereby promising to fundamentally reshape\nthe pace and scale of discovery. However, the rapid and unstructured\nproliferation of these systems has created a fragmented research landscape,\nobscuring overarching methodological principles and developmental trends. This\nsurvey provides a systematic and comprehensive synthesis of this domain by\nintroducing a unified, six-stage methodological framework that deconstructs the\nend-to-end scientific process into: Literature Review, Idea Generation,\nExperimental Preparation, Experimental Execution, Scientific Writing, and Paper\nGeneration. Through this analytical lens, we chart the field's evolution from\nearly Foundational Modules (2022-2023) to integrated Closed-Loop Systems\n(2024), and finally to the current frontier of Scalability, Impact, and\nHuman-AI Collaboration (2025-present). By rigorously synthesizing these\ndevelopments, this survey not only clarifies the current state of autonomous\nscience but also provides a critical roadmap for overcoming remaining\nchallenges in robustness and governance, ultimately guiding the next generation\nof systems toward becoming trustworthy and indispensable partners in human\nscientific inquiry.",
    "categories": [
      "cs.AI"
    ],
    "published": "2025-10-27T06:13:21Z",
    "authors": [
      "Guiyao Tie",
      "Pan Zhou",
      "Lichao Sun"
    ],
    "pdf_url": "http://arxiv.org/pdf/2510.23045v2"
  },
  {
    "id": "2510.23040v1",
    "title": "LLM Meets Diffusion: A Hybrid Framework for Crystal Material Generation",
    "abstract": "Recent advances in generative modeling have shown significant promise in\ndesigning novel periodic crystal structures. Existing approaches typically rely\non either large language models (LLMs) or equivariant denoising models, each\nwith complementary strengths: LLMs excel at handling discrete atomic types but\noften struggle with continuous features such as atomic positions and lattice\nparameters, while denoising models are effective at modeling continuous\nvariables but encounter difficulties in generating accurate atomic\ncompositions. To bridge this gap, we propose CrysLLMGen, a hybrid framework\nthat integrates an LLM with a diffusion model to leverage their complementary\nstrengths for crystal material generation. During sampling, CrysLLMGen first\nemploys a fine-tuned LLM to produce an intermediate representation of atom\ntypes, atomic coordinates, and lattice structure. While retaining the predicted\natom types, it passes the atomic coordinates and lattice structure to a\npre-trained equivariant diffusion model for refinement. Our framework\noutperforms state-of-the-art generative models across several benchmark tasks\nand datasets. Specifically, CrysLLMGen not only achieves a balanced performance\nin terms of structural and compositional validity but also generates more\nstable and novel materials compared to LLM-based and denoisingbased models\nFurthermore, CrysLLMGen exhibits strong conditional generation capabilities,\neffectively producing materials that satisfy user-defined constraints. Code is\navailable at https://github.com/kdmsit/crysllmgen",
    "categories": [
      "cs.LG",
      "cond-mat.mtrl-sci",
      "cs.AI"
    ],
    "published": "2025-10-27T06:08:19Z",
    "authors": [
      "Subhojyoti Khastagir",
      "Kishalay Das",
      "Pawan Goyal",
      "Seung-Cheol Lee",
      "Satadeep Bhattacharjee",
      "Niloy Ganguly"
    ],
    "pdf_url": "http://arxiv.org/pdf/2510.23040v1"
  },
  {
    "id": "2510.23038v1",
    "title": "Incentivizing Agentic Reasoning in LLM Judges via Tool-Integrated\n  Reinforcement Learning",
    "abstract": "Large Language Models (LLMs) are widely used as judges to evaluate response\nquality, providing a scalable alternative to human evaluation. However, most\nLLM judges operate solely on intrinsic text-based reasoning, limiting their\nability to verify complex constraints or perform accurate computation.\nMotivated by the success of tool-integrated reasoning (TIR) in numerous tasks,\nwe propose TIR-Judge, an end-to-end RL framework for training LLM judges that\nintegrates a code executor for precise evaluation. TIR-Judge is built on three\nprinciples: (i) diverse training across verifiable and non-verifiable domains,\n(ii) flexible judgment formats (pointwise, pairwise, listwise), and (iii)\niterative RL that bootstraps directly from the initial model without\ndistillation. On seven public benchmarks, TIR-Judge surpasses strong\nreasoning-based judges by up to 6.4% (pointwise) and 7.7% (pairwise), and\nachieves listwise performance comparable to Claude-Opus-4 despite having only\n8B parameters. Remarkably, TIR-Judge-Zero - trained entirely without distilled\njudge trajectories, matches the performance of distilled variants,\ndemonstrating that tool-augmented judges can self-evolve through iterative\nreinforcement learning.",
    "categories": [
      "cs.CL",
      "cs.AI",
      "cs.LG"
    ],
    "published": "2025-10-27T06:03:37Z",
    "authors": [
      "Ran Xu",
      "Jingjing Chen",
      "Jiayu Ye",
      "Yu Wu",
      "Jun Yan",
      "Carl Yang",
      "Hongkun Yu"
    ],
    "pdf_url": "http://arxiv.org/pdf/2510.23038v1"
  },
  {
    "id": "2510.23035v1",
    "title": "A high-capacity linguistic steganography based on entropy-driven\n  rank-token mapping",
    "abstract": "Linguistic steganography enables covert communication through embedding\nsecret messages into innocuous texts; however, current methods face critical\nlimitations in payload capacity and security. Traditional modification-based\nmethods introduce detectable anomalies, while retrieval-based strategies suffer\nfrom low embedding capacity. Modern generative steganography leverages language\nmodels to generate natural stego text but struggles with limited entropy in\ntoken predictions, further constraining capacity. To address these issues, we\npropose an entropy-driven framework called RTMStega that integrates rank-based\nadaptive coding and context-aware decompression with normalized entropy. By\nmapping secret messages to token probability ranks and dynamically adjusting\nsampling via context-aware entropy-based adjustments, RTMStega achieves a\nbalance between payload capacity and imperceptibility. Experiments across\ndiverse datasets and models demonstrate that RTMStega triples the payload\ncapacity of mainstream generative steganography, reduces processing time by\nover 50%, and maintains high text quality, offering a trustworthy solution for\nsecure and efficient covert communication.",
    "categories": [
      "cs.CR",
      "cs.AI"
    ],
    "published": "2025-10-27T06:02:47Z",
    "authors": [
      "Jun Jiang",
      "Weiming Zhang",
      "Nenghai Yu",
      "Kejiang Chen"
    ],
    "pdf_url": "http://arxiv.org/pdf/2510.23035v1"
  },
  {
    "id": "2510.23034v1",
    "title": "Efficient and Encrypted Inference using Binarized Neural Networks within\n  In-Memory Computing Architectures",
    "abstract": "Binarized Neural Networks (BNNs) are a class of deep neural networks designed\nto utilize minimal computational resources, which drives their popularity\nacross various applications. Recent studies highlight the potential of mapping\nBNN model parameters onto emerging non-volatile memory technologies,\nspecifically using crossbar architectures, resulting in improved inference\nperformance compared to traditional CMOS implementations. However, the common\npractice of protecting model parameters from theft attacks by storing them in\nan encrypted format and decrypting them at runtime introduces significant\ncomputational overhead, thus undermining the core principles of in-memory\ncomputing, which aim to integrate computation and storage. This paper presents\na robust strategy for protecting BNN model parameters, particularly within\nin-memory computing frameworks. Our method utilizes a secret key derived from a\nphysical unclonable function to transform model parameters prior to storage in\nthe crossbar. Subsequently, the inference operations are performed on the\nencrypted weights, achieving a very special case of Fully Homomorphic\nEncryption (FHE) with minimal runtime overhead. Our analysis reveals that\ninference conducted without the secret key results in drastically diminished\nperformance, with accuracy falling below 15%. These results validate the\neffectiveness of our protection strategy in securing BNNs within in-memory\ncomputing architectures while preserving computational efficiency.",
    "categories": [
      "cs.CR",
      "cs.AI"
    ],
    "published": "2025-10-27T05:59:02Z",
    "authors": [
      "Gokulnath Rajendran",
      "Suman Deb",
      "Anupam Chattopadhyay"
    ],
    "pdf_url": "http://arxiv.org/pdf/2510.23034v1"
  },
  {
    "id": "2510.23028v1",
    "title": "Nested AutoRegressive Models",
    "abstract": "AutoRegressive (AR) models have demonstrated competitive performance in image\ngeneration, achieving results comparable to those of diffusion models. However,\ntheir token-by-token image generation mechanism remains computationally\nintensive and existing solutions such as VAR often lead to limited sample\ndiversity. In this work, we propose a Nested AutoRegressive~(NestAR) model,\nwhich proposes nested AutoRegressive architectures in generating images. NestAR\ndesigns multi-scale modules in a hierarchical order. These different scaled\nmodules are constructed in an AR architecture, where one larger-scale module is\nconditioned on outputs from its previous smaller-scale module. Within each\nmodule, NestAR uses another AR structure to generate ``patches'' of tokens. The\nproposed nested AR architecture reduces the overall complexity from\n$\\mathcal{O}(n)$ to $\\mathcal{O}(\\log n)$ in generating $n$ image tokens, as\nwell as increases image diversities. NestAR further incorporates flow matching\nloss to use continuous tokens, and develops objectives to coordinate these\nmulti-scale modules in model training. NestAR achieves competitive image\ngeneration performance while significantly lowering computational cost.",
    "categories": [
      "cs.CV",
      "cs.AI"
    ],
    "published": "2025-10-27T05:49:02Z",
    "authors": [
      "Hongyu Wu",
      "Xuhui Fan",
      "Zhangkai Wu",
      "Longbing Cao"
    ],
    "pdf_url": "http://arxiv.org/pdf/2510.23028v1"
  },
  {
    "id": "2510.23026v1",
    "title": "Mixed Density Diffuser: Efficient Planning with Non-uniform Temporal\n  Resolution",
    "abstract": "Recent studies demonstrate that diffusion planners benefit from sparse-step\nplanning over single-step planning. Training models to skip steps in their\ntrajectories helps capture long-term dependencies without additional or memory\ncomputational cost. However, predicting excessively sparse plans degrades\nperformance. We hypothesize this temporal density threshold is non-uniform\nacross a temporal horizon and that certain parts of a planned trajectory should\nbe more densely planned. We propose Mixed Density Diffuser (MDD), a diffusion\nplanner where the densities throughout the horizon are tunable hyperparameters.\nMDD achieves a new SOTA across the Maze2D, Franka Kitchen, and Antmaze D4RL\ntask domains.",
    "categories": [
      "cs.AI",
      "cs.RO"
    ],
    "published": "2025-10-27T05:45:59Z",
    "authors": [
      "Crimson Stambaugh",
      "Rajesh P. N. Rao"
    ],
    "pdf_url": "http://arxiv.org/pdf/2510.23026v1"
  },
  {
    "id": "2510.23674v1",
    "title": "RefleXGen:The unexamined code is not worth using",
    "abstract": "Security in code generation remains a pivotal challenge when applying large\nlanguage models (LLMs). This paper introduces RefleXGen, an innovative method\nthat significantly enhances code security by integrating Retrieval-Augmented\nGeneration (RAG) techniques with guided self-reflection mechanisms inherent in\nLLMs. Unlike traditional approaches that rely on fine-tuning LLMs or developing\nspecialized secure code datasets - processes that can be resource-intensive -\nRefleXGen iteratively optimizes the code generation process through\nself-assessment and reflection without the need for extensive resources. Within\nthis framework, the model continuously accumulates and refines its knowledge\nbase, thereby progressively improving the security of the generated code.\nExperimental results demonstrate that RefleXGen substantially enhances code\nsecurity across multiple models, achieving a 13.6% improvement with GPT-3.5\nTurbo, a 6.7% improvement with GPT-4o, a 4.5% improvement with CodeQwen, and a\n5.8% improvement with Gemini. Our findings highlight that improving the quality\nof model self-reflection constitutes an effective and practical strategy for\nstrengthening the security of AI-generated code.",
    "categories": [
      "cs.SE",
      "cs.AI",
      "cs.CR"
    ],
    "published": "2025-10-27T05:28:32Z",
    "authors": [
      "Bin Wang",
      "Hui Li",
      "AoFan Liu",
      "BoTao Yang",
      "Ao Yang",
      "YiLu Zhong",
      "Weixiang Huang",
      "Yanping Zhang",
      "Runhuai Huang",
      "Weimin Zeng"
    ],
    "pdf_url": "http://arxiv.org/pdf/2510.23674v1"
  },
  {
    "id": "2510.23013v1",
    "title": "MoEMeta: Mixture-of-Experts Meta Learning for Few-Shot Relational\n  Learning",
    "abstract": "Few-shot knowledge graph relational learning seeks to perform reasoning over\nrelations given only a limited number of training examples. While existing\napproaches largely adopt a meta-learning framework for enabling fast adaptation\nto new relations, they suffer from two key pitfalls. First, they learn relation\nmeta-knowledge in isolation, failing to capture common relational patterns\nshared across tasks. Second, they struggle to effectively incorporate local,\ntask-specific contexts crucial for rapid adaptation. To address these\nlimitations, we propose MoEMeta, a novel meta-learning framework that\ndisentangles globally shared knowledge from task-specific contexts to enable\nboth effective generalization and rapid adaptation. MoEMeta introduces two key\ninnovations: (i) a mixture-of-experts (MoE) model that learns globally shared\nrelational prototypes to enhance generalization, and (ii) a task-tailored\nadaptation mechanism that captures local contexts for fast task-specific\nadaptation. By balancing global generalization with local adaptability, MoEMeta\nsignificantly advances few-shot relational learning. Extensive experiments and\nanalyses on three KG benchmarks demonstrate that MoEMeta consistently\noutperforms existing baselines, achieving state-of-the-art performance.",
    "categories": [
      "cs.LG",
      "cs.AI"
    ],
    "published": "2025-10-27T05:16:10Z",
    "authors": [
      "Han Wu",
      "Jie Yin"
    ],
    "pdf_url": "http://arxiv.org/pdf/2510.23013v1"
  },
  {
    "id": "2510.23012v1",
    "title": "Softmax is $1/2$-Lipschitz: A tight bound across all $\\ell_p$ norms",
    "abstract": "The softmax function is a basic operator in machine learning and\noptimization, used in classification, attention mechanisms, reinforcement\nlearning, game theory, and problems involving log-sum-exp terms. Existing\nrobustness guarantees of learning models and convergence analysis of\noptimization algorithms typically consider the softmax operator to have a\nLipschitz constant of $1$ with respect to the $\\ell_2$ norm. In this work, we\nprove that the softmax function is contractive with the Lipschitz constant\n$1/2$, uniformly across all $\\ell_p$ norms with $p \\ge 1$. We also show that\nthe local Lipschitz constant of softmax attains $1/2$ for $p = 1$ and $p =\n\\infty$, and for $p \\in (1,\\infty)$, the constant remains strictly below $1/2$\nand the supremum $1/2$ is achieved only in the limit. To our knowledge, this is\nthe first comprehensive norm-uniform analysis of softmax Lipschitz continuity.\nWe demonstrate how the sharper constant directly improves a range of existing\ntheoretical results on robustness and convergence. We further validate the\nsharpness of the $1/2$ Lipschitz constant of the softmax operator through\nempirical studies on attention-based architectures (ViT, GPT-2, Qwen3-8B) and\non stochastic policies in reinforcement learning.",
    "categories": [
      "cs.LG",
      "cs.AI"
    ],
    "published": "2025-10-27T05:16:04Z",
    "authors": [
      "Pravin Nair"
    ],
    "pdf_url": "http://arxiv.org/pdf/2510.23012v1"
  },
  {
    "id": "2510.23673v1",
    "title": "MCPGuard : Automatically Detecting Vulnerabilities in MCP Servers",
    "abstract": "The Model Context Protocol (MCP) has emerged as a standardized interface\nenabling seamless integration between Large Language Models (LLMs) and external\ndata sources and tools. While MCP significantly reduces development complexity\nand enhances agent capabilities, its openness and extensibility introduce\ncritical security vulnerabilities that threaten system trustworthiness and user\ndata protection. This paper systematically analyzes the security landscape of\nMCP-based systems, identifying three principal threat categories: (1) agent\nhijacking attacks stemming from protocol design deficiencies; (2) traditional\nweb vulnerabilities in MCP servers; and (3) supply chain security. To address\nthese challenges, we comprehensively survey existing defense strategies,\nexamining both proactive server-side scanning approaches, ranging from layered\ndetection pipelines and agentic auditing frameworks to zero-trust registry\nsystems, and runtime interaction monitoring solutions that provide continuous\noversight and policy enforcement. Our analysis reveals that MCP security\nfundamentally represents a paradigm shift where the attack surface extends from\ntraditional code execution to semantic interpretation of natural language\nmetadata, necessitating novel defense mechanisms tailored to this unique threat\nmodel.",
    "categories": [
      "cs.CR",
      "cs.AI"
    ],
    "published": "2025-10-27T05:12:51Z",
    "authors": [
      "Bin Wang",
      "Zexin Liu",
      "Hao Yu",
      "Ao Yang",
      "Yenan Huang",
      "Jing Guo",
      "Huangsheng Cheng",
      "Hui Li",
      "Huiyu Wu"
    ],
    "pdf_url": "http://arxiv.org/pdf/2510.23673v1"
  },
  {
    "id": "2510.24788v1",
    "title": "The Underappreciated Power of Vision Models for Graph Structural\n  Understanding",
    "abstract": "Graph Neural Networks operate through bottom-up message-passing,\nfundamentally differing from human visual perception, which intuitively\ncaptures global structures first. We investigate the underappreciated potential\nof vision models for graph understanding, finding they achieve performance\ncomparable to GNNs on established benchmarks while exhibiting distinctly\ndifferent learning patterns. These divergent behaviors, combined with\nlimitations of existing benchmarks that conflate domain features with\ntopological understanding, motivate our introduction of GraphAbstract. This\nbenchmark evaluates models' ability to perceive global graph properties as\nhumans do: recognizing organizational archetypes, detecting symmetry, sensing\nconnectivity strength, and identifying critical elements. Our results reveal\nthat vision models significantly outperform GNNs on tasks requiring holistic\nstructural understanding and maintain generalizability across varying graph\nscales, while GNNs struggle with global pattern abstraction and degrade with\nincreasing graph size. This work demonstrates that vision models possess\nremarkable yet underutilized capabilities for graph structural understanding,\nparticularly for problems requiring global topological awareness and\nscale-invariant reasoning. These findings open new avenues to leverage this\nunderappreciated potential for developing more effective graph foundation\nmodels for tasks dominated by holistic pattern recognition.",
    "categories": [
      "cs.CV",
      "cs.AI",
      "cs.LG"
    ],
    "published": "2025-10-27T05:11:44Z",
    "authors": [
      "Xinjian Zhao",
      "Wei Pang",
      "Zhongkai Xue",
      "Xiangru Jian",
      "Lei Zhang",
      "Yaoyao Xu",
      "Xiaozhuang Song",
      "Shu Wu",
      "Tianshu Yu"
    ],
    "pdf_url": "http://arxiv.org/pdf/2510.24788v1"
  },
  {
    "id": "2510.23008v2",
    "title": "From Prompt Optimization to Multi-Dimensional Credibility Evaluation:\n  Enhancing Trustworthiness of Chinese LLM-Generated Liver MRI Reports",
    "abstract": "Large language models (LLMs) have demonstrated promising performance in\ngenerating diagnostic conclusions from imaging findings, thereby supporting\nradiology reporting, trainee education, and quality control. However,\nsystematic guidance on how to optimize prompt design across different clinical\ncontexts remains underexplored. Moreover, a comprehensive and standardized\nframework for assessing the trustworthiness of LLM-generated radiology reports\nis yet to be established. This study aims to enhance the trustworthiness of\nLLM-generated liver MRI reports by introducing a Multi-Dimensional Credibility\nAssessment (MDCA) framework and providing guidance on institution-specific\nprompt optimization. The proposed framework is applied to evaluate and compare\nthe performance of several advanced LLMs, including Kimi-K2-Instruct-0905,\nQwen3-235B-A22B-Instruct-2507, DeepSeek-V3, and\nByteDance-Seed-OSS-36B-Instruct, using the SiliconFlow platform.",
    "categories": [
      "cs.AI"
    ],
    "published": "2025-10-27T04:57:20Z",
    "authors": [
      "Qiuli Wang",
      "Jie Chen",
      "Yongxu Liu",
      "Xingpeng Zhang",
      "Xiaoming Li",
      "Wei Chen"
    ],
    "pdf_url": "http://arxiv.org/pdf/2510.23008v2"
  },
  {
    "id": "2510.23006v1",
    "title": "Understanding In-Context Learning Beyond Transformers: An Investigation\n  of State Space and Hybrid Architectures",
    "abstract": "We perform in-depth evaluations of in-context learning (ICL) on\nstate-of-the-art transformer, state-space, and hybrid large language models\nover two categories of knowledge-based ICL tasks. Using a combination of\nbehavioral probing and intervention-based methods, we have discovered that,\nwhile LLMs of different architectures can behave similarly in task performance,\ntheir internals could remain different. We discover that function vectors (FVs)\nresponsible for ICL are primarily located in the self-attention and Mamba\nlayers, and speculate that Mamba2 uses a different mechanism from FVs to\nperform ICL. FVs are more important for ICL involving parametric knowledge\nretrieval, but not for contextual knowledge understanding. Our work contributes\nto a more nuanced understanding across architectures and task types.\nMethodologically, our approach also highlights the importance of combining both\nbehavioural and mechanistic analyses to investigate LLM capabilities.",
    "categories": [
      "cs.CL",
      "cs.AI"
    ],
    "published": "2025-10-27T04:49:01Z",
    "authors": [
      "Shenran Wang",
      "Timothy Tin-Long Tse",
      "Jian Zhu"
    ],
    "pdf_url": "http://arxiv.org/pdf/2510.23006v1"
  },
  {
    "id": "2510.22998v1",
    "title": "ProfileXAI: User-Adaptive Explainable AI",
    "abstract": "ProfileXAI is a model- and domain-agnostic framework that couples post-hoc\nexplainers (SHAP, LIME, Anchor) with retrieval - augmented LLMs to produce\nexplanations for different types of users. The system indexes a multimodal\nknowledge base, selects an explainer per instance via quantitative criteria,\nand generates grounded narratives with chat-enabled prompting. On Heart Disease\nand Thyroid Cancer datasets, we evaluate fidelity, robustness, parsimony, token\nuse, and perceived quality. No explainer dominates: LIME achieves the best\nfidelity-robustness trade-off (Infidelity $\\le 0.30$, $L<0.7$ on Heart\nDisease); Anchor yields the sparsest, low-token rules; SHAP attains the highest\nsatisfaction ($\\bar{x}=4.1$). Profile conditioning stabilizes tokens ($\\sigma\n\\le 13\\%$) and maintains positive ratings across profiles ($\\bar{x}\\ge 3.7$,\nwith domain experts at $3.77$), enabling efficient and trustworthy\nexplanations.",
    "categories": [
      "cs.AI",
      "68T05, 68T07",
      "I.2.6; H.5.2"
    ],
    "published": "2025-10-27T04:34:02Z",
    "authors": [
      "Gilber A. Corrales",
      "Carlos Andr\u00e9s Ferro S\u00e1nchez",
      "Reinel Tabares-Soto",
      "Jes\u00fas Alfonso L\u00f3pez Sotelo",
      "Gonzalo A. Ruz",
      "Johan Sebastian Pi\u00f1a Dur\u00e1n"
    ],
    "pdf_url": "http://arxiv.org/pdf/2510.22998v1"
  },
  {
    "id": "2510.22990v1",
    "title": "USF-MAE: Ultrasound Self-Supervised Foundation Model with Masked\n  Autoencoding",
    "abstract": "Ultrasound imaging is one of the most widely used diagnostic modalities,\noffering real-time, radiation-free assessment across diverse clinical domains.\nHowever, interpretation of ultrasound images remains challenging due to high\nnoise levels, operator dependence, and limited field of view, resulting in\nsubstantial inter-observer variability. Current Deep Learning approaches are\nhindered by the scarcity of large labeled datasets and the domain gap between\ngeneral and sonographic images, which limits the transferability of models\npretrained on non-medical data. To address these challenges, we introduce the\nUltrasound Self-Supervised Foundation Model with Masked Autoencoding (USF-MAE),\nthe first large-scale self-supervised MAE framework pretrained exclusively on\nultrasound data. The model was pre-trained on 370,000 2D and 3D ultrasound\nimages curated from 46 open-source datasets, collectively termed OpenUS-46,\nspanning over twenty anatomical regions. This curated dataset has been made\npublicly available to facilitate further research and reproducibility. Using a\nVision Transformer encoder-decoder architecture, USF-MAE reconstructs masked\nimage patches, enabling it to learn rich, modality-specific representations\ndirectly from unlabeled data. The pretrained encoder was fine-tuned on three\npublic downstream classification benchmarks: BUS-BRA (breast cancer), MMOTU-2D\n(ovarian tumors), and GIST514-DB (gastrointestinal stromal tumors). Across all\ntasks, USF-MAE consistently outperformed conventional CNN and ViT baselines,\nachieving F1-scores of 81.6%, 79.6%, and 82.4%, respectively. Despite not using\nlabels during pretraining, USF-MAE approached the performance of the supervised\nfoundation model UltraSam on breast cancer classification and surpassed it on\nthe other tasks, demonstrating strong cross-anatomical generalization.",
    "categories": [
      "eess.IV",
      "cs.AI",
      "cs.CV"
    ],
    "published": "2025-10-27T04:16:43Z",
    "authors": [
      "Youssef Megahed",
      "Robin Ducharme",
      "Mark Walker",
      "Steven Hawken",
      "Adrian D. C. Chan"
    ],
    "pdf_url": "http://arxiv.org/pdf/2510.22990v1"
  },
  {
    "id": "2510.22981v1",
    "title": "Exploring Semantic-constrained Adversarial Example with Instruction\n  Uncertainty Reduction",
    "abstract": "Recently, semantically constrained adversarial examples (SemanticAE), which\nare directly generated from natural language instructions, have become a\npromising avenue for future research due to their flexible attacking forms. To\ngenerate SemanticAEs, current methods fall short of satisfactory attacking\nability as the key underlying factors of semantic uncertainty in human\ninstructions, such as referring diversity, descriptive incompleteness, and\nboundary ambiguity, have not been fully investigated. To tackle the issues,\nthis paper develops a multi-dimensional instruction uncertainty reduction\n(InSUR) framework to generate more satisfactory SemanticAE, i.e., transferable,\nadaptive, and effective. Specifically, in the dimension of the sampling method,\nwe propose the residual-driven attacking direction stabilization to alleviate\nthe unstable adversarial optimization caused by the diversity of language\nreferences. By coarsely predicting the language-guided sampling process, the\noptimization process will be stabilized by the designed ResAdv-DDIM sampler,\ntherefore releasing the transferable and robust adversarial capability of\nmulti-step diffusion models. In task modeling, we propose the context-encoded\nattacking scenario constraint to supplement the missing knowledge from\nincomplete human instructions. Guidance masking and renderer integration are\nproposed to regulate the constraints of 2D/3D SemanticAE, activating stronger\nscenario-adapted attacks. Moreover, in the dimension of generator evaluation,\nwe propose the semantic-abstracted attacking evaluation enhancement by\nclarifying the evaluation boundary, facilitating the development of more\neffective SemanticAE generators. Extensive experiments demonstrate the\nsuperiority of the transfer attack performance of InSUR. Moreover, we realize\nthe reference-free generation of semantically constrained 3D adversarial\nexamples for the first time.",
    "categories": [
      "cs.AI",
      "cs.CV"
    ],
    "published": "2025-10-27T04:02:52Z",
    "authors": [
      "Jin Hu",
      "Jiakai Wang",
      "Linna Jing",
      "Haolin Li",
      "Haodong Liu",
      "Haotong Qin",
      "Aishan Liu",
      "Ke Xu",
      "Xianglong Liu"
    ],
    "pdf_url": "http://arxiv.org/pdf/2510.22981v1"
  },
  {
    "id": "2510.22977v1",
    "title": "The Reasoning Trap: How Enhancing LLM Reasoning Amplifies Tool\n  Hallucination",
    "abstract": "Enhancing the reasoning capabilities of Large Language Models (LLMs) is a key\nstrategy for building Agents that \"think then act.\" However, recent\nobservations, like OpenAI's o3, suggest a paradox: stronger reasoning often\ncoincides with increased hallucination, yet no prior work has systematically\nexamined whether reasoning enhancement itself causes tool hallucination. To\naddress this gap, we pose the central question: Does strengthening reasoning\nincrease tool hallucination? To answer this, we introduce SimpleToolHalluBench,\na diagnostic benchmark measuring tool hallucination in two failure modes: (i)\nno tool available, and (ii) only distractor tools available. Through controlled\nexperiments, we establish three key findings. First, we demonstrate a causal\nrelationship: progressively enhancing reasoning through RL increases tool\nhallucination proportionally with task performance gains. Second, this effect\ntranscends overfitting - training on non-tool tasks (e.g., mathematics) still\namplifies subsequent tool hallucination. Third, the effect is method-agnostic,\nappearing when reasoning is instilled via supervised fine-tuning and when it is\nmerely elicited at inference by switching from direct answers to step-by-step\nthinking. We also evaluate mitigation strategies including Prompt Engineering\nand Direct Preference Optimization (DPO), revealing a fundamental\nreliability-capability trade-off: reducing hallucination consistently degrades\nutility. Mechanistically, Reasoning RL disproportionately collapses\ntool-reliability-related representations, and hallucinations surface as\namplified divergences concentrated in late-layer residual streams. These\nfindings reveal that current reasoning enhancement methods inherently amplify\ntool hallucination, highlighting the need for new training objectives that\njointly optimize for capability and reliability.",
    "categories": [
      "cs.LG",
      "cs.AI",
      "I.2"
    ],
    "published": "2025-10-27T03:58:29Z",
    "authors": [
      "Chenlong Yin",
      "Zeyang Sha",
      "Shiwen Cui",
      "Changhua Meng"
    ],
    "pdf_url": "http://arxiv.org/pdf/2510.22977v1"
  },
  {
    "id": "2510.22969v1",
    "title": "Multi-Agent Conditional Diffusion Model with Mean Field Communication as\n  Wireless Resource Allocation Planner",
    "abstract": "In wireless communication systems, efficient and adaptive resource allocation\nplays a crucial role in enhancing overall Quality of Service (QoS). While\ncentralized Multi-Agent Reinforcement Learning (MARL) frameworks rely on a\ncentral coordinator for policy training and resource scheduling, they suffer\nfrom scalability issues and privacy risks. In contrast, the Distributed\nTraining with Decentralized Execution (DTDE) paradigm enables distributed\nlearning and decision-making, but it struggles with non-stationarity and\nlimited inter-agent cooperation, which can severely degrade system performance.\nTo overcome these challenges, we propose the Multi-Agent Conditional Diffusion\nModel Planner (MA-CDMP) for decentralized communication resource management.\nBuilt upon the Model-Based Reinforcement Learning (MBRL) paradigm, MA-CDMP\nemploys Diffusion Models (DMs) to capture environment dynamics and plan future\ntrajectories, while an inverse dynamics model guides action generation, thereby\nalleviating the sample inefficiency and slow convergence of conventional DTDE\nmethods. Moreover, to approximate large-scale agent interactions, a Mean-Field\n(MF) mechanism is introduced as an assistance to the classifier in DMs. This\ndesign mitigates inter-agent non-stationarity and enhances cooperation with\nminimal communication overhead in distributed settings. We further\ntheoretically establish an upper bound on the distributional approximation\nerror introduced by the MF-based diffusion generation, guaranteeing convergence\nstability and reliable modeling of multi-agent stochastic dynamics. Extensive\nexperiments demonstrate that MA-CDMP consistently outperforms existing MARL\nbaselines in terms of average reward and QoS metrics, showcasing its\nscalability and practicality for real-world wireless network optimization.",
    "categories": [
      "cs.AI",
      "cs.MA"
    ],
    "published": "2025-10-27T03:42:18Z",
    "authors": [
      "Kechen Meng",
      "Sinuo Zhang",
      "Rongpeng Li",
      "Xiangming Meng",
      "Chan Wang",
      "Ming Lei",
      "Zhifeng Zhao"
    ],
    "pdf_url": "http://arxiv.org/pdf/2510.22969v1"
  },
  {
    "id": "2510.22968v1",
    "title": "Measuring Teaching with LLMs",
    "abstract": "Objective and scalable measurement of teaching quality is a persistent\nchallenge in education. While Large Language Models (LLMs) offer potential,\ngeneral-purpose models have struggled to reliably apply complex, authentic\nclassroom observation instruments. This paper uses custom LLMs built on\nsentence-level embeddings, an architecture better suited for the long-form,\ninterpretive nature of classroom transcripts than conventional subword\ntokenization. We systematically evaluate five different sentence embeddings\nunder a data-efficient training regime designed to prevent overfitting. Our\nresults demonstrate that these specialized models can achieve human-level and\neven super-human performance with expert human ratings above 0.65 and\nsurpassing the average human-human rater correlation. Further, through analysis\nof annotation context windows, we find that more advanced models-those better\naligned with human judgments-attribute a larger share of score variation to\nlesson-level features rather than isolated utterances, challenging the\nsufficiency of single-turn annotation paradigms. Finally, to assess external\nvalidity, we find that aggregate model scores align with teacher value-added\nmeasures, indicating they are capturing features relevant to student learning.\nHowever, this trend does not hold at the individual item level, suggesting that\nwhile the models learn useful signals, they have not yet achieved full\ngeneralization. This work establishes a viable and powerful new methodology for\nAI-driven instructional measurement, offering a path toward providing scalable,\nreliable, and valid feedback for educator development.",
    "categories": [
      "cs.CL",
      "cs.AI"
    ],
    "published": "2025-10-27T03:42:04Z",
    "authors": [
      "Michael Hardy"
    ],
    "pdf_url": "http://arxiv.org/pdf/2510.22968v1"
  },
  {
    "id": "2510.22967v2",
    "title": "MAD-Fact: A Multi-Agent Debate Framework for Long-Form Factuality\n  Evaluation in LLMs",
    "abstract": "The widespread adoption of Large Language Models (LLMs) raises critical\nconcerns about the factual accuracy of their outputs, especially in high-risk\ndomains such as biomedicine, law, and education. Existing evaluation methods\nfor short texts often fail on long-form content due to complex reasoning\nchains, intertwined perspectives, and cumulative information. To address this,\nwe propose a systematic approach integrating large-scale long-form datasets,\nmulti-agent verification mechanisms, and weighted evaluation metrics. We\nconstruct LongHalluQA, a Chinese long-form factuality dataset; and develop\nMAD-Fact, a debate-based multi-agent verification system. We introduce a fact\nimportance hierarchy to capture the varying significance of claims in long-form\ntexts. Experiments on two benchmarks show that larger LLMs generally maintain\nhigher factual consistency, while domestic models excel on Chinese content. Our\nwork provides a structured framework for evaluating and enhancing factual\nreliability in long-form LLM outputs, guiding their safe deployment in\nsensitive domains.",
    "categories": [
      "cs.CL",
      "cs.AI"
    ],
    "published": "2025-10-27T03:41:32Z",
    "authors": [
      "Yucheng Ning",
      "Xixun Lin",
      "Fang Fang",
      "Yanan Cao"
    ],
    "pdf_url": "http://arxiv.org/pdf/2510.22967v2"
  },
  {
    "id": "2510.22963v1",
    "title": "CompressionAttack: Exploiting Prompt Compression as a New Attack Surface\n  in LLM-Powered Agents",
    "abstract": "LLM-powered agents often use prompt compression to reduce inference costs,\nbut this introduces a new security risk. Compression modules, which are\noptimized for efficiency rather than safety, can be manipulated by adversarial\ninputs, causing semantic drift and altering LLM behavior. This work identifies\nprompt compression as a novel attack surface and presents CompressionAttack,\nthe first framework to exploit it. CompressionAttack includes two strategies:\nHardCom, which uses discrete adversarial edits for hard compression, and\nSoftCom, which performs latent-space perturbations for soft compression.\nExperiments on multiple LLMs show up to 80% attack success and 98% preference\nflips, while remaining highly stealthy and transferable. Case studies in VSCode\nCline and Ollama confirm real-world impact, and current defenses prove\nineffective, highlighting the need for stronger protections.",
    "categories": [
      "cs.CR",
      "cs.AI"
    ],
    "published": "2025-10-27T03:37:41Z",
    "authors": [
      "Zesen Liu",
      "Zhixiang Zhang",
      "Yuchong Xie",
      "Dongdong She"
    ],
    "pdf_url": "http://arxiv.org/pdf/2510.22963v1"
  },
  {
    "id": "2510.22960v1",
    "title": "FAME: Fairness-aware Attention-modulated Video Editing",
    "abstract": "Training-free video editing (VE) models tend to fall back on gender\nstereotypes when rendering profession-related prompts. We propose \\textbf{FAME}\nfor \\textit{Fairness-aware Attention-modulated Video Editing} that mitigates\nprofession-related gender biases while preserving prompt alignment and temporal\nconsistency for coherent VE. We derive fairness embeddings from existing\nminority representations by softly injecting debiasing tokens into the text\nencoder. Simultaneously, FAME integrates fairness modulation into both temporal\nself attention and prompt-to-region cross attention to mitigate the motion\ncorruption and temporal inconsistency caused by directly introducing fairness\ncues. For temporal self attention, FAME introduces a region constrained\nattention mask combined with time decay weighting, which enhances intra-region\ncoherence while suppressing irrelevant inter-region interactions. For cross\nattention, it reweights tokens to region matching scores by incorporating\nfairness sensitive similarity masks derived from debiasing prompt embeddings.\nTogether, these modulations keep fairness-sensitive semantics tied to the right\nvisual regions and prevent temporal drift across frames. Extensive experiments\non new VE fairness-oriented benchmark \\textit{FairVE} demonstrate that FAME\nachieves stronger fairness alignment and semantic fidelity, surpassing existing\nVE baselines.",
    "categories": [
      "cs.CV",
      "cs.AI"
    ],
    "published": "2025-10-27T03:34:15Z",
    "authors": [
      "Zhangkai Wu",
      "Xuhui Fan",
      "Zhongyuan Xie",
      "Kaize Shi",
      "Zhidong Li",
      "Longbing Cao"
    ],
    "pdf_url": "http://arxiv.org/pdf/2510.22960v1"
  },
  {
    "id": "2510.22953v1",
    "title": "Manifold Approximation leads to Robust Kernel Alignment",
    "abstract": "Centered kernel alignment (CKA) is a popular metric for comparing\nrepresentations, determining equivalence of networks, and neuroscience\nresearch. However, CKA does not account for the underlying manifold and relies\non numerous heuristics that cause it to behave differently at different scales\nof data. In this work, we propose Manifold approximated Kernel Alignment (MKA),\nwhich incorporates manifold geometry into the alignment task. We derive a\ntheoretical framework for MKA. We perform empirical evaluations on synthetic\ndatasets and real-world examples to characterize and compare MKA to its\ncontemporaries. Our findings suggest that manifold-aware kernel alignment\nprovides a more robust foundation for measuring representations, with potential\napplications in representation learning.",
    "categories": [
      "cs.LG",
      "cs.AI",
      "stat.ML"
    ],
    "published": "2025-10-27T03:16:15Z",
    "authors": [
      "Mohammad Tariqul Islam",
      "Du Liu",
      "Deblina Sarkar"
    ],
    "pdf_url": "http://arxiv.org/pdf/2510.22953v1"
  },
  {
    "id": "2510.22948v1",
    "title": "PASS-Enhanced MEC: Joint Optimization of Task Offloading and Uplink PASS\n  Beamforming",
    "abstract": "A pinching-antenna system (PASS)-enhanced mobile edge computing (MEC)\narchitecture is investigated to improve the task offloading efficiency and\nlatency performance in dynamic wireless environments. By leveraging dielectric\nwaveguides and flexibly adjustable pinching antennas, PASS establishes\nshort-distance line-of-sight (LoS) links while effectively mitigating the\nsignificant path loss and potential signal blockage, making it a promising\nsolution for high-frequency MEC systems. We formulate a network latency\nminimization problem to joint optimize uplink PASS beamforming and task\noffloading. The resulting problem is modeled as a Markov decision process (MDP)\nand solved via the deep reinforcement learning (DRL) method. To address the\ninstability introduced by the $\\max$ operator in the objective function, we\npropose a load balancing-aware proximal policy optimization (LBPPO) algorithm.\nLBPPO incorporates both node-level and waveguide-level load balancing\ninformation into the policy design, maintaining computational and transmission\ndelay equilibrium, respectively. Simulation results demonstrate that the\nproposed PASS-enhanced MEC with adaptive uplink PASS beamforming exhibit\nstronger convergence capability than fixed-PA baselines and conventional\nMIMO-assisted MEC, especially in scenarios with a large number of UEs or high\ntransmit power.",
    "categories": [
      "eess.SP",
      "cs.AI",
      "cs.NI"
    ],
    "published": "2025-10-27T03:04:46Z",
    "authors": [
      "Zhaoming Hu",
      "Ruikang Zhong",
      "Xidong Mu",
      "Dengao Li",
      "Yuanwei Liu"
    ],
    "pdf_url": "http://arxiv.org/pdf/2510.22948v1"
  },
  {
    "id": "2510.22944v1",
    "title": "Is Your Prompt Poisoning Code? Defect Induction Rates and Security\n  Mitigation Strategies",
    "abstract": "Large language models (LLMs) have become indispensable for automated code\ngeneration, yet the quality and security of their outputs remain a critical\nconcern. Existing studies predominantly concentrate on adversarial attacks or\ninherent flaws within the models. However, a more prevalent yet underexplored\nissue concerns how the quality of a benign but poorly formulated prompt affects\nthe security of the generated code. To investigate this, we first propose an\nevaluation framework for prompt quality encompassing three key dimensions: goal\nclarity, information completeness, and logical consistency. Based on this\nframework, we construct and publicly release CWE-BENCH-PYTHON, a large-scale\nbenchmark dataset containing tasks with prompts categorized into four distinct\nlevels of normativity (L0-L3). Extensive experiments on multiple\nstate-of-the-art LLMs reveal a clear correlation: as prompt normativity\ndecreases, the likelihood of generating insecure code consistently and markedly\nincreases. Furthermore, we demonstrate that advanced prompting techniques, such\nas Chain-of-Thought and Self-Correction, effectively mitigate the security\nrisks introduced by low-quality prompts, substantially improving code safety.\nOur findings highlight that enhancing the quality of user prompts constitutes a\ncritical and effective strategy for strengthening the security of AI-generated\ncode.",
    "categories": [
      "cs.CR",
      "cs.AI"
    ],
    "published": "2025-10-27T02:59:17Z",
    "authors": [
      "Bin Wang",
      "YiLu Zhong",
      "MiDi Wan",
      "WenJie Yu",
      "YuanBing Ouyang",
      "Yenan Huang",
      "Hui Li"
    ],
    "pdf_url": "http://arxiv.org/pdf/2510.22944v1"
  },
  {
    "id": "2510.22942v1",
    "title": "GTR-Mamba: Geometry-to-Tangent Routing for Hyperbolic POI Recommendation",
    "abstract": "Next Point-of-Interest (POI) recommendation is a critical task in modern\nLocation-Based Social Networks (LBSNs), aiming to model the complex\ndecision-making process of human mobility to provide personalized\nrecommendations for a user's next check-in location. Existing POI\nrecommendation models, predominantly based on Graph Neural Networks and\nsequential models, have been extensively studied. However, these models face a\nfundamental limitation: they struggle to simultaneously capture the inherent\nhierarchical structure of spatial choices and the dynamics and irregular shifts\nof user-specific temporal contexts. To overcome this limitation, we propose\nGTR-Mamba, a novel framework for cross-manifold conditioning and routing.\nGTR-Mamba leverages the distinct advantages of different mathematical spaces\nfor different tasks: it models the static, tree-like preference hierarchies in\nhyperbolic geometry, while routing the dynamic sequence updates to a novel\nMamba layer in the computationally stable and efficient Euclidean tangent\nspace. This process is coordinated by a cross-manifold channel that fuses\nspatio-temporal information to explicitly steer the State Space Model (SSM),\nenabling flexible adaptation to contextual changes. Extensive experiments on\nthree real-world datasets demonstrate that GTR-Mamba consistently outperforms\nstate-of-the-art baseline models in next POI recommendation.",
    "categories": [
      "cs.AI",
      "cs.IR",
      "H.3.3; I.2.6"
    ],
    "published": "2025-10-27T02:56:08Z",
    "authors": [
      "Zhuoxuan Li",
      "Jieyuan Pei",
      "Tangwei Ye",
      "Zhongyuan Lai",
      "Zihan Liu",
      "Fengyuan Xu",
      "Qi Zhang",
      "Liang Hu"
    ],
    "pdf_url": "http://arxiv.org/pdf/2510.22942v1"
  },
  {
    "id": "2510.24787v1",
    "title": "ESCA: Enabling Seamless Codec Avatar Execution through Algorithm and\n  Hardware Co-Optimization for Virtual Reality",
    "abstract": "Photorealistic Codec Avatars (PCA), which generate high-fidelity human face\nrenderings, are increasingly being used in Virtual Reality (VR) environments to\nenable immersive communication and interaction through deep learning-based\ngenerative models. However, these models impose significant computational\ndemands, making real-time inference challenging on resource-constrained VR\ndevices such as head-mounted displays, where latency and power efficiency are\ncritical. To address this challenge, we propose an efficient post-training\nquantization (PTQ) method tailored for Codec Avatar models, enabling\nlow-precision execution without compromising output quality. In addition, we\ndesign a custom hardware accelerator that can be integrated into the\nsystem-on-chip of VR devices to further enhance processing efficiency. Building\non these components, we introduce ESCA, a full-stack optimization framework\nthat accelerates PCA inference on edge VR platforms. Experimental results\ndemonstrate that ESCA boosts FovVideoVDP quality scores by up to $+0.39$ over\nthe best 4-bit baseline, delivers up to $3.36\\times$ latency reduction, and\nsustains a rendering rate of 100 frames per second in end-to-end tests,\nsatisfying real-time VR requirements. These results demonstrate the feasibility\nof deploying high-fidelity codec avatars on resource-constrained devices,\nopening the door to more immersive and portable VR experiences.",
    "categories": [
      "cs.CV",
      "cs.AI"
    ],
    "published": "2025-10-27T02:31:20Z",
    "authors": [
      "Mingzhi Zhu",
      "Ding Shang",
      "Sai Qian Zhang"
    ],
    "pdf_url": "http://arxiv.org/pdf/2510.24787v1"
  },
  {
    "id": "2510.22931v2",
    "title": "Robust Uncertainty Quantification for Self-Evolving Large Language\n  Models via Continual Domain Pretraining",
    "abstract": "Continual Learning (CL) is essential for enabling self-evolving large\nlanguage models (LLMs) to adapt and remain effective amid rapid knowledge\ngrowth. Yet, despite its importance, little attention has been given to\nestablishing statistical reliability guarantees for LLMs under CL, particularly\nin the setting of continual domain pretraining (CDP). Conformal Prediction (CP)\nhas shown promise in offering correctness guarantees for LLMs, but it faces\nmajor challenges in CDP: testing data often stems from unknown or shifting\ndomain distributions, under which CP may no longer provide valid guarantees.\nMoreover, when high coverage is required, CP can yield excessively large\nprediction sets for unanswerable queries, reducing informativeness. To address\nthese challenges, we introduce an adaptive rejection and non-exchangeable CP\nframework. Our method first estimates the distribution of questions across\ndomains in the test set using transformer-based clustering, then reweights or\nresamples the calibration data accordingly. Building on this, adaptive\nrejection CP allows the LLM to selectively abstain from answering when its\nconfidence or competence shifts significantly. Extensive experiments\ndemonstrate that our framework enhances both the effectiveness and reliability\nof CP under CDP scenarios. Our code is available at:\nhttps://anonymous.4open.science/r/CPCL-8C12/",
    "categories": [
      "cs.LG",
      "cs.AI"
    ],
    "published": "2025-10-27T02:15:51Z",
    "authors": [
      "Xiaofan Zhou",
      "Lu Cheng"
    ],
    "pdf_url": "http://arxiv.org/pdf/2510.22931v2"
  },
  {
    "id": "2510.22930v1",
    "title": "Gen-LangSplat: Generalized Language Gaussian Splatting with Pre-Trained\n  Feature Compression",
    "abstract": "Modeling open-vocabulary language fields in 3D is essential for intuitive\nhuman-AI interaction and querying within physical environments.\nState-of-the-art approaches, such as LangSplat, leverage 3D Gaussian Splatting\nto efficiently construct these language fields, encoding features distilled\nfrom high-dimensional models like CLIP. However, this efficiency is currently\noffset by the requirement to train a scene-specific language autoencoder for\nfeature compression, introducing a costly, per-scene optimization bottleneck\nthat hinders deployment scalability. In this work, we introduce Gen-LangSplat,\nthat eliminates this requirement by replacing the scene-wise autoencoder with a\ngeneralized autoencoder, pre-trained extensively on the large-scale ScanNet\ndataset. This architectural shift enables the use of a fixed, compact latent\nspace for language features across any new scene without any scene-specific\ntraining. By removing this dependency, our entire language field construction\nprocess achieves a efficiency boost while delivering querying performance\ncomparable to, or exceeding, the original LangSplat method. To validate our\ndesign choice, we perform a thorough ablation study empirically determining the\noptimal latent embedding dimension and quantifying representational fidelity\nusing Mean Squared Error and cosine similarity between the original and\nreprojected 512-dimensional CLIP embeddings. Our results demonstrate that\ngeneralized embeddings can efficiently and accurately support open-vocabulary\nquerying in novel 3D scenes, paving the way for scalable, real-time interactive\n3D AI applications.",
    "categories": [
      "cs.CV",
      "cs.AI"
    ],
    "published": "2025-10-27T02:13:38Z",
    "authors": [
      "Pranav Saxena"
    ],
    "pdf_url": "http://arxiv.org/pdf/2510.22930v1"
  },
  {
    "id": "2510.22917v2",
    "title": "HyPerNav: Hybrid Perception for Object-Oriented Navigation in Unknown\n  Environment",
    "abstract": "Objective-oriented navigation(ObjNav) enables robot to navigate to target\nobject directly and autonomously in an unknown environment. Effective\nperception in navigation in unknown environment is critical for autonomous\nrobots. While egocentric observations from RGB-D sensors provide abundant local\ninformation, real-time top-down maps offer valuable global context for ObjNav.\nNevertheless, the majority of existing studies focus on a single source, seldom\nintegrating these two complementary perceptual modalities, despite the fact\nthat humans naturally attend to both. With the rapid advancement of\nVision-Language Models(VLMs), we propose Hybrid Perception Navigation\n(HyPerNav), leveraging VLMs' strong reasoning and vision-language understanding\ncapabilities to jointly perceive both local and global information to enhance\nthe effectiveness and intelligence of navigation in unknown environments. In\nboth massive simulation evaluation and real-world validation, our methods\nachieved state-of-the-art performance against popular baselines. Benefiting\nfrom hybrid perception approach, our method captures richer cues and finds the\nobjects more effectively, by simultaneously leveraging information\nunderstanding from egocentric observations and the top-down map. Our ablation\nstudy further proved that either of the hybrid perception contributes to the\nnavigation performance.",
    "categories": [
      "cs.RO",
      "cs.AI"
    ],
    "published": "2025-10-27T01:43:56Z",
    "authors": [
      "Zecheng Yin",
      "Hao Zhao",
      "Zhen Li"
    ],
    "pdf_url": "http://arxiv.org/pdf/2510.22917v2"
  },
  {
    "id": "2510.22909v1",
    "title": "Rethinking Inference Placement for Deep Learning across Edge and Cloud\n  Platforms: A Multi-Objective Optimization Perspective and Future Directions",
    "abstract": "Edge intelligent applications like VR/AR and language model based chatbots\nhave become widespread with the rapid expansion of IoT and mobile devices.\nHowever, constrained edge devices often cannot serve the increasingly large and\ncomplex deep learning (DL) models. To mitigate these challenges, researchers\nhave proposed optimizing and offloading partitions of DL models among user\ndevices, edge servers, and the cloud. In this setting, users can take advantage\nof different services to support their intelligent applications. For example,\nedge resources offer low response latency. In contrast, cloud platforms provide\nlow monetary cost computation resources for computation-intensive workloads.\nHowever, communication between DL model partitions can introduce transmission\nbottlenecks and pose risks of data leakage. Recent research aims to balance\naccuracy, computation delay, transmission delay, and privacy concerns. They\naddress these issues with model compression, model distillation, transmission\ncompression, and model architecture adaptations, including internal\nclassifiers. This survey contextualizes the state-of-the-art model offloading\nmethods and model adaptation techniques by studying their implication to a\nmulti-objective optimization comprising inference latency, data privacy, and\nresource monetary cost.",
    "categories": [
      "cs.DC",
      "cs.AI",
      "cs.PF"
    ],
    "published": "2025-10-27T01:26:52Z",
    "authors": [
      "Zongshun Zhang",
      "Ibrahim Matta"
    ],
    "pdf_url": "http://arxiv.org/pdf/2510.22909v1"
  },
  {
    "id": "2510.22907v1",
    "title": "Language Server CLI Empowers Language Agents with Process Rewards",
    "abstract": "Large language models routinely hallucinate APIs and mislocalize edits, while\nlanguage servers compute verified, IDE-grade facts about real code. We present\nLanser-CLI, a CLI-first orchestration layer that pins and mediates a Language\nServer Protocol (LSP) server for coding agents and CI, exposing deterministic,\nreplayable workflows. Our position is that language servers provide not only\nstructural information (definitions, references, types, diagnostics) but also\nan actionable process reward: machine-checked, step-wise signals that align an\nagent's planning loop with program reality. In this work, Lanser-CLI\ncontributes: (i) a robust addressing scheme beyond brittle \"file:line:col\" via\na Selector DSL (symbolic, AST-path, and content-anchored selectors) with a\nprincipled relocation algorithm; (ii) deterministic Analysis Bundles that\nnormalize Language Server responses and capture environment/capability metadata\nwith stable content hashes; (iii) a safety envelope for mutating operations\n(rename, code actions) with preview, workspace jails, and Git-aware,\ntransactional apply; and (iv) a process-reward functional derived from Language\nServer facts (diagnostic deltas, disambiguation confidence, and safe-apply\nchecks) that is computable online and replayable offline. We formalize\ndeterminism under frozen snapshots and establish a monotonicity property for\nthe process reward, making it suitable for process supervision and\ncounterfactual analysis. Project Page:\nhttps://github.com/yifanzhang-pro/lanser-cli",
    "categories": [
      "cs.CL",
      "cs.AI",
      "cs.PL",
      "cs.SE"
    ],
    "published": "2025-10-27T01:25:20Z",
    "authors": [
      "Yifan Zhang",
      "Lanser Contributors"
    ],
    "pdf_url": "http://arxiv.org/pdf/2510.22907v1"
  },
  {
    "id": "2510.22898v1",
    "title": "On Generalization in Agentic Tool Calling: CoreThink Agentic Reasoner\n  and MAVEN Dataset",
    "abstract": "Generalization across Agentic tool-calling environments remains a key\nunsolved challenge in developing reliable agentic reasoning systems. While\nlarge language models (LLMs) demonstrate strong performance on isolated\nbenchmarks, their ability to transfer reasoning strategies and co-ordinate\ntools across diverse domains is poorly understood. In this work, we conduct a\nlarge-scale evaluation of state-of-the-art LLMs on multiple tool-calling\nbenchmarksBFCL v3, TauBench, Tau2Bench, and AceBenchand introduce MAVEN (Math &\nPhysics Adversarial Verification & Evaluation Network), a new out of\ndistribution (OOD) benchmark designed to stress-test multi-step reasoning\nthrough explicit verification and adversarial task composition. Our results\nshow that most current models achieve below 50% accuracy on MAVEN, revealing a\nsignificant generalization gap across tool-use settings.\n  To address this, we present the CoreThink Agentic Reasoner, a framework that\naugments LLMs with a lightweight symbolic reasoning layer for structured\ndecomposition and adaptive tool orchestration. Without additional training, it\ngeneralizes across all benchmarks, achieving state-of-the-art performance with\n530% improvements over existing baselines at roughly one-tenth the\ncomputational cost.",
    "categories": [
      "cs.AI",
      "cs.SE"
    ],
    "published": "2025-10-27T00:58:48Z",
    "authors": [
      "Vishvesh Bhat",
      "Omkar Ghugarkar",
      "Julian McAuley"
    ],
    "pdf_url": "http://arxiv.org/pdf/2510.22898v1"
  },
  {
    "id": "2510.22883v1",
    "title": "Exploring Structures of Inferential Mechanisms through Simplistic\n  Digital Circuits",
    "abstract": "Cognitive studies and artificial intelligence have developed distinct models\nfor various inferential mechanisms (categorization, induction, abduction,\ncausal inference, contrast, merge, ...). Yet, both natural and artificial views\non cognition lack apparently a unifying framework. This paper formulates a\nspeculative answer attempting to respond to this gap. To postulate on\nhigher-level activation processes from a material perspective, we consider\ninferential mechanisms informed by symbolic AI modelling techniques, through\nthe simplistic lenses of electronic circuits based on logic gates. We observe\nthat a logic gate view entails a different treatment of implication and\nnegation compared to standard logic and logic programming. Then, by\ncombinatorial exploration, we identify four main forms of dependencies that can\nbe realized by these inferential circuits. Looking at how these forms are\ngenerally used in the context of logic programs, we identify eight common\ninferential patterns, exposing traditionally distinct inferential mechanisms in\nan unifying framework. Finally, following a probabilistic interpretation of\nlogic programs, we unveil inner functional dependencies. The paper concludes\nelaborating in what sense, even if our arguments are mostly informed by\nsymbolic means and digital systems infrastructures, our observations may\npinpoint to more generally applicable structures.",
    "categories": [
      "cs.AI"
    ],
    "published": "2025-10-27T00:18:25Z",
    "authors": [
      "Giovanni Sileno",
      "Jean-Louis Dessalles"
    ],
    "pdf_url": "http://arxiv.org/pdf/2510.22883v1"
  },
  {
    "id": "2510.22880v1",
    "title": "Learning Reconfigurable Representations for Multimodal Federated\n  Learning with Missing Data",
    "abstract": "Multimodal federated learning in real-world settings often encounters\nincomplete and heterogeneous data across clients. This results in misaligned\nlocal feature representations that limit the effectiveness of model\naggregation. Unlike prior work that assumes either differing modality sets\nwithout missing input features or a shared modality set with missing features\nacross clients, we consider a more general and realistic setting where each\nclient observes a different subset of modalities and might also have missing\ninput features within each modality. To address the resulting misalignment in\nlearned representations, we propose a new federated learning framework\nfeaturing locally adaptive representations based on learnable client-side\nembedding controls that encode each client's data-missing patterns.\n  These embeddings serve as reconfiguration signals that align the globally\naggregated representation with each client's local context, enabling more\neffective use of shared information. Furthermore, the embedding controls can be\nalgorithmically aggregated across clients with similar data-missing patterns to\nenhance the robustness of reconfiguration signals in adapting the global\nrepresentation. Empirical results on multiple federated multimodal benchmarks\nwith diverse data-missing patterns across clients demonstrate the efficacy of\nthe proposed method, achieving up to 36.45\\% performance improvement under\nsevere data incompleteness. The method is also supported by a theoretical\nanalysis with an explicit performance bound that matches our empirical\nobservations. Our source codes are provided at\nhttps://github.com/nmduonggg/PEPSY",
    "categories": [
      "cs.LG",
      "cs.AI"
    ],
    "published": "2025-10-27T00:09:58Z",
    "authors": [
      "Duong M. Nguyen",
      "Trong Nghia Hoang",
      "Thanh Trung Huynh",
      "Quoc Viet Hung Nguyen",
      "Phi Le Nguyen"
    ],
    "pdf_url": "http://arxiv.org/pdf/2510.22880v1"
  },
  {
    "id": "2510.22876v1",
    "title": "Batch Speculative Decoding Done Right",
    "abstract": "Speculative decoding speeds up LLM inference by using a small draft model to\npropose multiple tokens that a target model verifies in parallel. Extending\nthis idea to batches is essential for production serving, but it introduces the\nragged tensor problem: sequences in the same batch accept different numbers of\ndraft tokens, breaking right-alignment and corrupting position IDs, attention\nmasks, and KV-cache state. We show that several existing batch implementations\nviolate output equivalence-the fundamental requirement that speculative\ndecoding must produce identical token sequences to standard autoregressive\ngeneration. These violations occur precisely due to improper handling of the\nragged tensor problem. In response, we (1) characterize the synchronization\nrequirements that guarantee correctness, (2) present a correctness-first batch\nspeculative decoding EQSPEC that exposes realignment as consuming 40% of\noverhead, and (3) introduce EXSPEC, which maintains a sliding pool of sequences\nand dynamically forms same-length groups, to reduce the realignment overhead\nwhile preserving per-sequence speculative speedups. On the SpecBench dataset,\nacross Vicuna-7B/68M, Qwen3-8B/0.6B, and GLM-4-9B/0.6B target/draft pairs, our\napproach achieves up to 3$\\times$ throughput improvement at batch size 8\ncompared to batch size 1, with efficient scaling through batch size 8, while\nmaintaining 95% output equivalence. Our method requires no custom kernels and\nintegrates cleanly with existing inference stacks. Our code is available at\nhttps://github.com/eBay/spec_dec.",
    "categories": [
      "cs.CL",
      "cs.AI"
    ],
    "published": "2025-10-26T23:59:23Z",
    "authors": [
      "Ranran Haoran Zhang",
      "Soumik Dey",
      "Ashirbad Mishra",
      "Hansi Wu",
      "Binbin Li",
      "Rui Zhang"
    ],
    "pdf_url": "http://arxiv.org/pdf/2510.22876v1"
  },
  {
    "id": "2510.22863v1",
    "title": "Long-Term PM2.5 Forecasting Using a DTW-Enhanced CNN-GRU Model",
    "abstract": "Reliable long-term forecasting of PM2.5 concentrations is critical for public\nhealth early-warning systems, yet existing deep learning approaches struggle to\nmaintain prediction stability beyond 48 hours, especially in cities with sparse\nmonitoring networks. This paper presents a deep learning framework that\ncombines Dynamic Time Warping (DTW) for intelligent station similarity\nselection with a CNN-GRU architecture to enable extended-horizon PM2.5\nforecasting in Isfahan, Iran, a city characterized by complex pollution\ndynamics and limited monitoring coverage. Unlike existing approaches that rely\non computationally intensive transformer models or external simulation tools,\nour method integrates three key innovations: (i) DTW-based historical sampling\nto identify similar pollution patterns across peer stations, (ii) a lightweight\nCNN-GRU architecture augmented with meteorological features, and (iii) a\nscalable design optimized for sparse networks. Experimental validation using\nmulti-year hourly data from eight monitoring stations demonstrates superior\nperformance compared to state-of-the-art deep learning methods, achieving R2 =\n0.91 for 24-hour forecasts. Notably, this is the first study to demonstrate\nstable 10-day PM2.5 forecasting (R2 = 0.73 at 240 hours) without performance\ndegradation, addressing critical early-warning system requirements. The\nframework's computational efficiency and independence from external tools make\nit particularly suitable for deployment in resource-constrained urban\nenvironments.",
    "categories": [
      "cs.LG",
      "cs.AI"
    ],
    "published": "2025-10-26T23:04:10Z",
    "authors": [
      "Amirali Ataee Naeini",
      "Arshia Ataee Naeini",
      "Fatemeh Karami Mohammadi",
      "Omid Ghaffarpasand"
    ],
    "pdf_url": "http://arxiv.org/pdf/2510.22863v1"
  },
  {
    "id": "2510.24783v1",
    "title": "AI & Data Competencies: Scaffolding holistic AI literacy in Higher\n  Education",
    "abstract": "This chapter introduces the AI & Data Acumen Learning Outcomes Framework, a\ncomprehensive tool designed to guide the integration of AI literacy across\nhigher education. Developed through a collaborative process, the framework\ndefines key AI and data-related competencies across four proficiency levels and\nseven knowledge dimensions. It provides a structured approach for educators to\nscaffold student learning in AI, balancing technical skills with ethical\nconsiderations and sociocultural awareness. The chapter outlines the\nframework's development process, its structure, and practical strategies for\nimplementation in curriculum design, learning activities, and assessment. We\naddress challenges in implementation and future directions for AI education. By\noffering a roadmap for developing students' holistic AI literacy, this\nframework prepares learners to leverage generative AI capabilities in both\nacademic and professional contexts.",
    "categories": [
      "cs.CY",
      "cs.AI"
    ],
    "published": "2025-10-26T22:56:08Z",
    "authors": [
      "Kathleen Kennedy",
      "Anuj Gupta"
    ],
    "pdf_url": "http://arxiv.org/pdf/2510.24783v1"
  },
  {
    "id": "2510.23671v1",
    "title": "Sparsity and Superposition in Mixture of Experts",
    "abstract": "Mixture of Experts (MoE) models have become central to scaling large language\nmodels, yet their mechanistic differences from dense networks remain poorly\nunderstood. Previous work has explored how dense models use\n\\textit{superposition} to represent more features than dimensions, and how\nsuperposition is a function of feature sparsity and feature importance. MoE\nmodels cannot be explained mechanistically through the same lens. We find that\nneither feature sparsity nor feature importance cause discontinuous phase\nchanges, and that network sparsity (the ratio of active to total experts)\nbetter characterizes MoEs. We develop new metrics for measuring superposition\nacross experts. Our findings demonstrate that models with greater network\nsparsity exhibit greater \\emph{monosemanticity}. We propose a new definition of\nexpert specialization based on monosemantic feature representation rather than\nload balancing, showing that experts naturally organize around coherent feature\ncombinations when initialized appropriately. These results suggest that network\nsparsity in MoEs may enable more interpretable models without sacrificing\nperformance, challenging the common assumption that interpretability and\ncapability are fundamentally at odds.",
    "categories": [
      "cs.LG",
      "cs.AI"
    ],
    "published": "2025-10-26T22:44:35Z",
    "authors": [
      "Marmik Chaudhari",
      "Jeremi Nuer",
      "Rome Thorstenson"
    ],
    "pdf_url": "http://arxiv.org/pdf/2510.23671v1"
  },
  {
    "id": "2510.22859v1",
    "title": "Guardian: Decoupling Exploration from Safety in Reinforcement Learning",
    "abstract": "Hybrid offline--online reinforcement learning (O2O RL) promises both sample\nefficiency and robust exploration, but suffers from instability due to\ndistribution shift between offline and online data. We introduce RLPD-GX, a\nframework that decouples policy optimization from safety enforcement: a\nreward-seeking learner explores freely, while a projection-based guardian\nguarantees rule-consistent execution and safe value backups. This design\npreserves the exploratory value of online interactions without collapsing to\nconservative policies. To further stabilize training, we propose dynamic\ncurricula that gradually extend temporal horizons and anneal offline--online\ndata mixing. We prove convergence via a contraction property of the guarded\nBellman operator, and empirically show state-of-the-art performance on\nAtari-100k, achieving a normalized mean score of 3.02 (+45\\% over prior hybrid\nmethods) with stronger safety and stability. Beyond Atari, ablations\ndemonstrate consistent gains across safety-critical and long-horizon tasks,\nunderscoring the generality of our design. Extensive and comprehensive results\nhighlight decoupled safety enforcement as a simple yet principled route to\nrobust O2O RL, suggesting a broader paradigm for reconciling exploration and\nsafety in reinforcement learning.",
    "categories": [
      "cs.LG",
      "cs.AI"
    ],
    "published": "2025-10-26T22:25:47Z",
    "authors": [
      "Kaitong Cai",
      "Jusheng Zhang",
      "Jing Yang",
      "Keze Wang"
    ],
    "pdf_url": "http://arxiv.org/pdf/2510.22859v1"
  },
  {
    "id": "2510.22852v1",
    "title": "Encoder-Decoder Diffusion Language Models for Efficient Training and\n  Inference",
    "abstract": "Discrete diffusion models enable parallel token sampling for faster inference\nthan autoregressive approaches. However, prior diffusion models use a\ndecoder-only architecture, which requires sampling algorithms that invoke the\nfull network at every denoising step and incur high computational cost. Our key\ninsight is that discrete diffusion models perform two types of computation: 1)\nrepresenting clean tokens and 2) denoising corrupted tokens, which enables us\nto use separate modules for each task. We propose an encoder-decoder\narchitecture to accelerate discrete diffusion inference, which relies on an\nencoder to represent clean tokens and a lightweight decoder to iteratively\nrefine a noised sequence. We also show that this architecture enables faster\ntraining of block diffusion models, which partition sequences into blocks for\nbetter quality and are commonly used in diffusion language model inference. We\nintroduce a framework for Efficient Encoder-Decoder Diffusion (E2D2),\nconsisting of an architecture with specialized training and sampling\nalgorithms, and we show that E2D2 achieves superior trade-offs between\ngeneration quality and inference throughput on summarization, translation, and\nmathematical reasoning tasks. We provide the code, model weights, and blog post\non the project page: https://m-arriola.com/e2d2",
    "categories": [
      "cs.LG",
      "cs.AI"
    ],
    "published": "2025-10-26T22:05:22Z",
    "authors": [
      "Marianne Arriola",
      "Yair Schiff",
      "Hao Phung",
      "Aaron Gokaslan",
      "Volodymyr Kuleshov"
    ],
    "pdf_url": "http://arxiv.org/pdf/2510.22852v1"
  },
  {
    "id": "2510.22851v1",
    "title": "Semantic Surgery: Zero-Shot Concept Erasure in Diffusion Models",
    "abstract": "Concept erasure in text-to-image diffusion models is crucial for mitigating\nharmful content, yet existing methods often compromise generative quality. We\nintroduce Semantic Surgery, a novel training-free, zero-shot framework for\nconcept erasure that operates directly on text embeddings before the diffusion\nprocess. It dynamically estimates the presence of target concepts in a prompt\nand performs a calibrated vector subtraction to neutralize their influence at\nthe source, enhancing both erasure completeness and locality. The framework\nincludes a Co-Occurrence Encoding module for robust multi-concept erasure and a\nvisual feedback loop to address latent concept persistence. As a training-free\nmethod, Semantic Surgery adapts dynamically to each prompt, ensuring precise\ninterventions. Extensive experiments on object, explicit content, artistic\nstyle, and multi-celebrity erasure tasks show our method significantly\noutperforms state-of-the-art approaches. We achieve superior completeness and\nrobustness while preserving locality and image quality (e.g., 93.58 H-score in\nobject erasure, reducing explicit content to just 1 instance, and 8.09 H_a in\nstyle erasure with no quality degradation). This robustness also allows our\nframework to function as a built-in threat detection system, offering a\npractical solution for safer text-to-image generation.",
    "categories": [
      "cs.CV",
      "cs.AI"
    ],
    "published": "2025-10-26T22:04:17Z",
    "authors": [
      "Lexiang Xiong",
      "Chengyu Liu",
      "Jingwen Ye",
      "Yan Liu",
      "Yuecong Xu"
    ],
    "pdf_url": "http://arxiv.org/pdf/2510.22851v1"
  },
  {
    "id": "2510.22849v1",
    "title": "Once Upon an Input: Reasoning via Per-Instance Program Synthesis",
    "abstract": "Large language models (LLMs) excel at zero-shot inference but continue to\nstruggle with complex, multi-step reasoning. Recent methods that augment LLMs\nwith intermediate reasoning steps such as Chain of Thought (CoT) and Program of\nThought (PoT) improve performance but often produce undesirable solutions,\nespecially in algorithmic domains. We introduce Per-Instance Program Synthesis\n(PIPS), a method that generates and refines programs at the instance-level\nusing structural feedback without relying on task-specific guidance or explicit\ntest cases. To further improve performance, PIPS incorporates a confidence\nmetric that dynamically chooses between direct inference and program synthesis\non a per-instance basis. Experiments across three frontier LLMs and 30\nbenchmarks including all tasks of Big Bench Extra Hard (BBEH), visual question\nanswering tasks, relational reasoning tasks, and mathematical reasoning tasks\nshow that PIPS improves the absolute harmonic mean accuracy by up to 8.6% and\n9.4% compared to PoT and CoT respectively, and reduces undesirable program\ngenerations by 65.1% on the algorithmic tasks compared to PoT with\nGemini-2.0-Flash.",
    "categories": [
      "cs.CL",
      "cs.AI",
      "cs.LG"
    ],
    "published": "2025-10-26T21:58:33Z",
    "authors": [
      "Adam Stein",
      "Neelay Velingker",
      "Mayur Naik",
      "Eric Wong"
    ],
    "pdf_url": "http://arxiv.org/pdf/2510.22849v1"
  },
  {
    "id": "2510.22840v1",
    "title": "Lyapunov Function-guided Reinforcement Learning for Flight Control",
    "abstract": "A cascaded online learning flight control system has been developed and\nenhanced with respect to action smoothness. In this paper, we investigate the\nconvergence performance of the control system, characterized by the increment\nof a Lyapunov function candidate. The derivation of this metric accounts for\ndiscretization errors and state prediction errors introduced by the incremental\nmodel. Comparative results are presented through flight control simulations.",
    "categories": [
      "cs.AI"
    ],
    "published": "2025-10-26T21:18:34Z",
    "authors": [
      "Yifei Li",
      "Erik-Jan van Kampen"
    ],
    "pdf_url": "http://arxiv.org/pdf/2510.22840v1"
  },
  {
    "id": "2510.22836v1",
    "title": "Rethinking the Text-Vision Reasoning Imbalance in MLLMs through the Lens\n  of Training Recipes",
    "abstract": "Multimodal large language models (MLLMs) have demonstrated strong\ncapabilities on vision-and-language tasks. However, recent findings reveal an\nimbalance in their reasoning capabilities across visual and textual modalities.\nSpecifically, current MLLMs often over-rely on textual cues while\nunder-attending to visual content, resulting in suboptimal performance on tasks\nthat require genuine visual reasoning. We refer to this phenomenon as the\n\\textit{modality gap}, defined as the performance disparity between\ntext-centric and vision-centric inputs. In this paper, we analyze the modality\ngap through the lens of training recipes. We first show that existing training\nrecipes tend to amplify this gap. Then, we systematically explore strategies to\nbridge it from two complementary perspectives: data and loss design. Our\nfindings provide insights into developing training recipes that mitigate the\nmodality gap and promote more balanced multimodal reasoning. Our code is\npublicly available at https://github.com/UCSB-NLP-Chang/Bridging-Modality-Gap.",
    "categories": [
      "cs.AI"
    ],
    "published": "2025-10-26T21:06:13Z",
    "authors": [
      "Guanyu Yao",
      "Qiucheng Wu",
      "Yang Zhang",
      "Zhaowen Wang",
      "Handong Zhao",
      "Shiyu Chang"
    ],
    "pdf_url": "http://arxiv.org/pdf/2510.22836v1"
  },
  {
    "id": "2510.22833v1",
    "title": "Toward Agents That Reason About Their Computation",
    "abstract": "While reinforcement learning agents can achieve superhuman performance in\nmany complex tasks, they typically do not become more computationally efficient\nas they improve. In contrast, humans gradually require less cognitive effort as\nthey become more proficient at a task. If agents could reason about their\ncompute as they learn, could they similarly reduce their computation footprint?\nIf they could, we could have more energy efficient agents or free up compute\ncycles for other processes like planning. In this paper, we experiment with\nshowing agents the cost of their computation and giving them the ability to\ncontrol when they use compute. We conduct our experiments on the Arcade\nLearning Environment, and our results demonstrate that with the same training\ncompute budget, agents that reason about their compute perform better on 75% of\ngames. Furthermore, these agents use three times less compute on average. We\nanalyze individual games and show where agents gain these efficiencies.",
    "categories": [
      "cs.AI",
      "cs.LG"
    ],
    "published": "2025-10-26T21:01:30Z",
    "authors": [
      "Adrian Orenstein",
      "Jessica Chen",
      "Gwyneth Anne Delos Santos",
      "Bayley Sapara",
      "Michael Bowling"
    ],
    "pdf_url": "http://arxiv.org/pdf/2510.22833v1"
  },
  {
    "id": "2510.22832v1",
    "title": "HRM-Agent: Training a recurrent reasoning model in dynamic environments\n  using reinforcement learning",
    "abstract": "The Hierarchical Reasoning Model (HRM) has impressive reasoning abilities\ngiven its small size, but has only been applied to supervised, static,\nfully-observable problems. One of HRM's strengths is its ability to adapt its\ncomputational effort to the difficulty of the problem. However, in its current\nform it cannot integrate and reuse computation from previous time-steps if the\nproblem is dynamic, uncertain or partially observable, or be applied where the\ncorrect action is undefined, characteristics of many real-world problems.\n  This paper presents HRM-Agent, a variant of HRM trained using only\nreinforcement learning. We show that HRM can learn to navigate to goals in\ndynamic and uncertain maze environments. Recent work suggests that HRM's\nreasoning abilities stem from its recurrent inference process. We explore the\ndynamics of the recurrent inference process and find evidence that it is\nsuccessfully reusing computation from earlier environment time-steps.",
    "categories": [
      "cs.AI",
      "cs.LG",
      "stat.ML",
      "68T07 (Primary) 62M45, 37N99 (Secondary)",
      "I.2.6; I.2.8"
    ],
    "published": "2025-10-26T21:01:04Z",
    "authors": [
      "Long H Dang",
      "David Rawlinson"
    ],
    "pdf_url": "http://arxiv.org/pdf/2510.22832v1"
  },
  {
    "id": "2510.22829v1",
    "title": "LLM-based Fusion of Multi-modal Features for Commercial Memorability\n  Prediction",
    "abstract": "This paper addresses the prediction of commercial (brand) memorability as\npart of \"Subtask 2: Commercial/Ad Memorability\" within the \"Memorability:\nPredicting movie and commercial memorability\" task at the MediaEval 2025\nworkshop competition. We propose a multimodal fusion system with a Gemma-3 LLM\nbackbone that integrates pre-computed visual (ViT) and textual (E5) features by\nmulti-modal projections. The model is adapted using Low-Rank Adaptation (LoRA).\nA heavily-tuned ensemble of gradient boosted trees serves as a baseline. A key\ncontribution is the use of LLM-generated rationale prompts, grounded in\nexpert-derived aspects of memorability, to guide the fusion model. The results\ndemonstrate that the LLM-based system exhibits greater robustness and\ngeneralization performance on the final test set, compared to the baseline.\n  The paper's codebase can be found at\nhttps://github.com/dsgt-arc/mediaeval-2025-memorability",
    "categories": [
      "cs.CV",
      "cs.AI",
      "cs.MM"
    ],
    "published": "2025-10-26T20:51:52Z",
    "authors": [
      "Aleksandar Pramov"
    ],
    "pdf_url": "http://arxiv.org/pdf/2510.22829v1"
  },
  {
    "id": "2510.22823v1",
    "title": "Cross-Lingual Stability and Bias in Instruction-Tuned Language Models\n  for Humanitarian NLP",
    "abstract": "Humanitarian organizations face a critical choice: invest in costly\ncommercial APIs or rely on free open-weight models for multilingual human\nrights monitoring. While commercial systems offer reliability, open-weight\nalternatives lack empirical validation -- especially for low-resource languages\ncommon in conflict zones. This paper presents the first systematic comparison\nof commercial and open-weight large language models (LLMs) for\nhuman-rights-violation detection across seven languages, quantifying the\ncost-reliability trade-off facing resource-constrained organizations. Across\n78,000 multilingual inferences, we evaluate six models -- four\ninstruction-aligned (Claude-Sonnet-4, DeepSeek-V3, Gemini-Flash-2.0,\nGPT-4.1-mini) and two open-weight (LLaMA-3-8B, Mistral-7B) -- using both\nstandard classification metrics and new measures of cross-lingual reliability:\nCalibration Deviation (CD), Decision Bias (B), Language Robustness Score (LRS),\nand Language Stability Score (LSS). Results show that alignment, not scale,\ndetermines stability: aligned models maintain near-invariant accuracy and\nbalanced calibration across typologically distant and low-resource languages\n(e.g., Lingala, Burmese), while open-weight models exhibit significant\nprompt-language sensitivity and calibration drift. These findings demonstrate\nthat multilingual alignment enables language-agnostic reasoning and provide\npractical guidance for humanitarian organizations balancing budget constraints\nwith reliability in multilingual deployment.",
    "categories": [
      "cs.CL",
      "cs.AI"
    ],
    "published": "2025-10-26T20:32:25Z",
    "authors": [
      "Poli Nemkova",
      "Amrit Adhikari",
      "Matthew Pearson",
      "Vamsi Krishna Sadu",
      "Mark V. Albert"
    ],
    "pdf_url": "http://arxiv.org/pdf/2510.22823v1"
  },
  {
    "id": "2510.22818v1",
    "title": "Air Quality Prediction Using LOESS-ARIMA and Multi-Scale CNN-BiLSTM with\n  Residual-Gated Attention",
    "abstract": "Air pollution remains a critical environmental and public health concern in\nIndian megacities such as Delhi, Kolkata, and Mumbai, where sudden spikes in\npollutant levels challenge timely intervention. Accurate Air Quality Index\n(AQI) forecasting is difficult due to the coexistence of linear trends,\nseasonal variations, and volatile nonlinear patterns. This paper proposes a\nhybrid forecasting framework that integrates LOESS decomposition, ARIMA\nmodeling, and a multi-scale CNN-BiLSTM network with a residual-gated attention\nmechanism. The LOESS step separates the AQI series into trend, seasonal, and\nresidual components, with ARIMA modeling the smooth components and the proposed\ndeep learning module capturing multi-scale volatility in the residuals. Model\nhyperparameters are tuned via the Unified Adaptive Multi-Stage Metaheuristic\nOptimizer (UAMMO), combining multiple optimization strategies for efficient\nconvergence. Experiments on 2021-2023 AQI datasets from the Central Pollution\nControl Board show that the proposed method consistently outperforms\nstatistical, deep learning, and hybrid baselines across PM2.5, O3, CO, and NOx\nin three major cities, achieving up to 5-8% lower MSE and higher R^2 scores\n(>0.94) for all pollutants. These results demonstrate the framework's\nrobustness, sensitivity to sudden pollution events, and applicability to urban\nair quality management.",
    "categories": [
      "cs.LG",
      "cs.AI",
      "68T07, 68U35",
      "I.2.7; I.5.4; C.3"
    ],
    "published": "2025-10-26T20:18:30Z",
    "authors": [
      "Soham Pahari",
      "Sandeep Chand Kumain"
    ],
    "pdf_url": "http://arxiv.org/pdf/2510.22818v1"
  },
  {
    "id": "2510.22814v1",
    "title": "Will Humanity Be Rendered Obsolete by AI?",
    "abstract": "This article analyzes the existential risks artificial intelligence (AI)\nposes to humanity, tracing the trajectory from current AI to ultraintelligence.\nDrawing on Irving J. Good and Nick Bostrom's theoretical work, plus recent\npublications (AI 2027; If Anyone Builds It, Everyone Dies), it explores AGI and\nsuperintelligence. Considering machines' exponentially growing cognitive power\nand hypothetical IQs, it addresses the ethical and existential implications of\nan intelligence vastly exceeding humanity's, fundamentally alien. Human\nextinction may result not from malice, but from uncontrollable, indifferent\ncognitive superiority.",
    "categories": [
      "cs.AI",
      "I.2.0; K.4.1; K.6.m"
    ],
    "published": "2025-10-26T20:02:04Z",
    "authors": [
      "Mohamed El Louadi",
      "Emna Ben Romdhane"
    ],
    "pdf_url": "http://arxiv.org/pdf/2510.22814v1"
  },
  {
    "id": "2510.22809v1",
    "title": "A Theory of the Mechanics of Information: Generalization Through\n  Measurement of Uncertainty (Learning is Measuring)",
    "abstract": "Traditional machine learning relies on explicit models and domain\nassumptions, limiting flexibility and interpretability. We introduce a\nmodel-free framework using surprisal (information theoretic uncertainty) to\ndirectly analyze and perform inferences from raw data, eliminating distribution\nmodeling, reducing bias, and enabling efficient updates including direct edits\nand deletion of training data. By quantifying relevance through uncertainty,\nthe approach enables generalizable inference across tasks including generative\ninference, causal discovery, anomaly detection, and time series forecasting. It\nemphasizes traceability, interpretability, and data-driven decision making,\noffering a unified, human-understandable framework for machine learning, and\nachieves at or near state-of-the-art performance across most common machine\nlearning tasks. The mathematical foundations create a ``physics'' of\ninformation, which enable these techniques to apply effectively to a wide\nvariety of complex data types, including missing data. Empirical results\nindicate that this may be a viable alternative path to neural networks with\nregard to scalable machine learning and artificial intelligence that can\nmaintain human understandability of the underlying mechanics.",
    "categories": [
      "cs.LG",
      "cs.AI",
      "math.ST",
      "stat.ML",
      "stat.TH"
    ],
    "published": "2025-10-26T19:45:25Z",
    "authors": [
      "Christopher J. Hazard",
      "Michael Resnick",
      "Jacob Beel",
      "Jack Xia",
      "Cade Mack",
      "Dominic Glennie",
      "Matthew Fulp",
      "David Maze",
      "Andrew Bassett",
      "Martin Koistinen"
    ],
    "pdf_url": "http://arxiv.org/pdf/2510.22809v1"
  },
  {
    "id": "2510.23669v2",
    "title": "What Work is AI Actually Doing? Uncovering the Drivers of Generative AI\n  Adoption",
    "abstract": "Purpose: The rapid integration of artificial intelligence (AI) systems like\nChatGPT, Claude AI, etc., has a deep impact on how work is done. Predicting how\nAI will reshape work requires understanding not just its capabilities, but how\nit is actually being adopted. This study investigates which intrinsic task\ncharacteristics drive users' decisions to delegate work to AI systems.\nMethodology: This study utilizes the Anthropic Economic Index dataset of four\nmillion Claude AI interactions mapped to O*NET tasks. We systematically scored\neach task across seven key dimensions: Routine, Cognitive, Social Intelligence,\nCreativity, Domain Knowledge, Complexity, and Decision Making using 35\nparameters. We then employed multivariate techniques to identify latent task\narchetypes and analyzed their relationship with AI usage. Findings: Tasks\nrequiring high creativity, complexity, and cognitive demand, but low\nroutineness, attracted the most AI engagement. Furthermore, we identified three\ntask archetypes: Dynamic Problem Solving, Procedural & Analytical Work, and\nStandardized Operational Tasks, demonstrating that AI applicability is best\npredicted by a combination of task characteristics, over individual factors.\nOur analysis revealed highly concentrated AI usage patterns, with just 5% of\ntasks accounting for 59% of all interactions. Originality: This research\nprovides the first systematic evidence linking real-world generative AI usage\nto a comprehensive, multi-dimensional framework of intrinsic task\ncharacteristics. It introduces a data-driven classification of work archetypes\nthat offers a new framework for analyzing the emerging human-AI division of\nlabor.",
    "categories": [
      "econ.GN",
      "cs.AI",
      "cs.CY",
      "q-fin.EC"
    ],
    "published": "2025-10-26T19:13:37Z",
    "authors": [
      "Peeyush Agarwal",
      "Harsh Agarwal",
      "Akshat Rana"
    ],
    "pdf_url": "http://arxiv.org/pdf/2510.23669v2"
  },
  {
    "id": "2510.22787v1",
    "title": "Collaborative LLM Agents for C4 Software Architecture Design Automation",
    "abstract": "Software architecture design is a fundamental part of creating every software\nsystem. Despite its importance, producing a C4 software architecture model, the\npreferred notation for such architecture, remains manual and time-consuming. We\nintroduce an LLM-based multi-agent system that automates this task by\nsimulating a dialogue between role-specific experts who analyze requirements\nand generate the Context, Container, and Component views of the C4 model.\nQuality is assessed with a hybrid evaluation framework: deterministic checks\nfor structural and syntactic integrity and C4 rule consistency, plus semantic\nand qualitative scoring via an LLM-as-a-Judge approach. Tested on five\ncanonical system briefs, the workflow demonstrates fast C4 model creation,\nsustains high compilation success, and delivers semantic fidelity. A comparison\nof four state-of-the-art LLMs shows different strengths relevant to\narchitectural design. This study contributes to automated software architecture\ndesign and its evaluation methods.",
    "categories": [
      "cs.SE",
      "cs.AI",
      "68T07",
      "I.2.11; I.2.7; I.2.8"
    ],
    "published": "2025-10-26T18:43:59Z",
    "authors": [
      "Kamil Szczepanik",
      "Jaros\u0142aw A. Chudziak"
    ],
    "pdf_url": "http://arxiv.org/pdf/2510.22787v1"
  },
  {
    "id": "2510.22784v1",
    "title": "PIP-LLM: Integrating PDDL-Integer Programming with LLMs for Coordinating\n  Multi-Robot Teams Using Natural Language",
    "abstract": "Enabling robot teams to execute natural language commands requires\ntranslating high-level instructions into feasible, efficient multi-robot plans.\nWhile Large Language Models (LLMs) combined with Planning Domain Description\nLanguage (PDDL) offer promise for single-robot scenarios, existing approaches\nstruggle with multi-robot coordination due to brittle task decomposition, poor\nscalability, and low coordination efficiency.\n  We introduce PIP-LLM, a language-based coordination framework that consists\nof PDDL-based team-level planning and Integer Programming (IP) based\nrobot-level planning. PIP-LLMs first decomposes the command by translating the\ncommand into a team-level PDDL problem and solves it to obtain a team-level\nplan, abstracting away robot assignment. Each team-level action represents a\nsubtask to be finished by the team. Next, this plan is translated into a\ndependency graph representing the subtasks' dependency structure. Such a\ndependency graph is then used to guide the robot-level planning, in which each\nsubtask node will be formulated as an IP-based task allocation problem,\nexplicitly optimizing travel costs and workload while respecting robot\ncapabilities and user-defined constraints. This separation of planning from\nassignment allows PIP-LLM to avoid the pitfalls of syntax-based decomposition\nand scale to larger teams. Experiments across diverse tasks show that PIP-LLM\nimproves plan success rate, reduces maximum and average travel costs, and\nachieves better load balancing compared to state-of-the-art baselines.",
    "categories": [
      "cs.RO",
      "cs.AI"
    ],
    "published": "2025-10-26T18:37:00Z",
    "authors": [
      "Guangyao Shi",
      "Yuwei Wu",
      "Vijay Kumar",
      "Gaurav S. Sukhatme"
    ],
    "pdf_url": "http://arxiv.org/pdf/2510.22784v1"
  },
  {
    "id": "2510.22781v1",
    "title": "Agentic Meta-Orchestrator for Multi-task Copilots",
    "abstract": "Microsoft Copilot suites serve as the universal entry point for various\nagents skilled in handling important tasks, ranging from assisting a customer\nwith product purchases to detecting vulnerabilities in corporate programming\ncode. Each agent can be powered by language models, software engineering\noperations, such as database retrieval, and internal \\& external knowledge. The\nrepertoire of a copilot can expand dynamically with new agents. This requires a\nrobust orchestrator that can distribute tasks from user prompts to the right\nagents. In this work, we propose an Agentic Meta-orchestrator (AMO) for\nhandling multiple tasks and scalable agents in copilot services, which can\nprovide both natural language and action responses. We will also demonstrate\nthe planning that leverages meta-learning, i.e., a trained decision tree model\nfor deciding the best inference strategy among various agents/models. We\nshowcase the effectiveness of our AMO through two production use cases:\nMicrosoft 365 (M365) E-Commerce Copilot and code compliance copilot. M365\nE-Commerce Copilot advertises Microsoft products to external customers to\npromote sales success. The M365 E-Commerce Copilot provides up-to-date product\ninformation and connects to multiple agents, such as relational databases and\nhuman customer support. The code compliance copilot scans the internal DevOps\ncode to detect known and new compliance issues in pull requests (PR).",
    "categories": [
      "cs.AI"
    ],
    "published": "2025-10-26T18:13:04Z",
    "authors": [
      "Xiaofeng Zhu",
      "Yunshen Zhou"
    ],
    "pdf_url": "http://arxiv.org/pdf/2510.22781v1"
  },
  {
    "id": "2510.22780v1",
    "title": "How Do AI Agents Do Human Work? Comparing AI and Human Workflows Across\n  Diverse Occupations",
    "abstract": "AI agents are continually optimized for tasks related to human work, such as\nsoftware engineering and professional writing, signaling a pressing trend with\nsignificant impacts on the human workforce. However, these agent developments\nhave often not been grounded in a clear understanding of how humans execute\nwork, to reveal what expertise agents possess and the roles they can play in\ndiverse workflows. In this work, we study how agents do human work by\npresenting the first direct comparison of human and agent workers across\nmultiple essential work-related skills: data analysis, engineering,\ncomputation, writing, and design. To better understand and compare\nheterogeneous computer-use activities of workers, we introduce a scalable\ntoolkit to induce interpretable, structured workflows from either human or\nagent computer-use activities. Using such induced workflows, we compare how\nhumans and agents perform the same tasks and find that: (1) While agents\nexhibit promise in their alignment to human workflows, they take an\noverwhelmingly programmatic approach across all work domains, even for\nopen-ended, visually dependent tasks like design, creating a contrast with the\nUI-centric methods typically used by humans. (2) Agents produce work of\ninferior quality, yet often mask their deficiencies via data fabrication and\nmisuse of advanced tools. (3) Nonetheless, agents deliver results 88.3% faster\nand cost 90.4-96.2% less than humans, highlighting the potential for enabling\nefficient collaboration by delegating easily programmable tasks to agents.",
    "categories": [
      "cs.AI",
      "cs.CL",
      "cs.HC"
    ],
    "published": "2025-10-26T18:10:22Z",
    "authors": [
      "Zora Zhiruo Wang",
      "Yijia Shao",
      "Omar Shaikh",
      "Daniel Fried",
      "Graham Neubig",
      "Diyi Yang"
    ],
    "pdf_url": "http://arxiv.org/pdf/2510.22780v1"
  },
  {
    "id": "2510.22765v1",
    "title": "Jarvis: Towards Personalized AI Assistant via Personal KV-Cache\n  Retrieval",
    "abstract": "The rapid development of Vision-language models (VLMs) enables open-ended\nperception and reasoning. Recent works have started to investigate how to adapt\ngeneral-purpose VLMs into personalized assistants. Even commercial models such\nas ChatGPT now support model personalization by incorporating user-specific\ninformation. However, existing methods either learn a set of concept tokens or\ntrain a VLM to utilize user-specific information. However, both pipelines\nstruggle to generate accurate answers as personalized assistants. We introduce\nJarvis, an innovative framework for a personalized AI assistant through\npersonal KV-Cache retrieval, which stores user-specific information in the\nKV-Caches of both textual and visual tokens. The textual tokens are created by\nsummarizing user information into metadata, while the visual tokens are\nproduced by extracting distinct image patches from the user's images. When\nanswering a question, Jarvis first retrieves related KV-Caches from personal\nstorage and uses them to ensure accuracy in responses. We also introduce a\nfine-grained benchmark built with the same distinct image patch mining\npipeline, emphasizing accurate question answering based on fine-grained\nuser-specific information. Jarvis is capable of providing more accurate\nresponses, particularly when they depend on specific local details. Jarvis\nachieves state-of-the-art results in both visual question answering and\ntext-only tasks across multiple datasets, indicating a practical path toward\npersonalized AI assistants. The code and dataset will be released.",
    "categories": [
      "cs.AI"
    ],
    "published": "2025-10-26T17:28:05Z",
    "authors": [
      "Binxiao Xu",
      "Junyu Feng",
      "Ruichuan An",
      "Yulin Luo",
      "Shilin Yan",
      "Hao Liang",
      "Ming Lu",
      "Wentao Zhang"
    ],
    "pdf_url": "http://arxiv.org/pdf/2510.22765v1"
  },
  {
    "id": "2510.22752v1",
    "title": "Beyond Semantics: How Temporal Biases Shape Retrieval in Transformer and\n  State-Space Models",
    "abstract": "In-context learning is governed by both temporal and semantic relationships,\nshaping how Large Language Models (LLMs) retrieve contextual information.\nAnalogous to human episodic memory, where the retrieval of specific events is\nenabled by separating events that happened at different times, this work probes\nthe ability of various pretrained LLMs, including transformer and state-space\nmodels, to differentiate and retrieve temporally separated events.\nSpecifically, we prompted models with sequences containing multiple\npresentations of the same token, which reappears at the sequence end. By fixing\nthe positions of these repeated tokens and permuting all others, we removed\nsemantic confounds and isolated temporal effects on next-token prediction.\nAcross diverse sequences, models consistently placed the highest probabilities\non tokens following a repeated token, but with a notable bias for those nearest\nthe beginning or end of the input. An ablation experiment linked this\nphenomenon in transformers to induction heads. Extending the analysis to unique\nsemantic contexts with partial overlap further demonstrated that memories\nembedded in the middle of a prompt are retrieved less reliably. Despite\narchitectural differences, state-space and transformer models showed comparable\ntemporal biases. Our findings deepen the understanding of temporal biases in\nin-context learning and offer an illustration of how these biases can enable\ntemporal separation and episodic retrieval.",
    "categories": [
      "cs.CL",
      "cs.AI"
    ],
    "published": "2025-10-26T17:01:41Z",
    "authors": [
      "Anooshka Bajaj",
      "Deven Mahesh Mistry",
      "Sahaj Singh Maini",
      "Yash Aggarwal",
      "Zoran Tiganj"
    ],
    "pdf_url": "http://arxiv.org/pdf/2510.22752v1"
  },
  {
    "id": "2510.22751v1",
    "title": "Multi-Modal Fact-Verification Framework for Reducing Hallucinations in\n  Large Language Models",
    "abstract": "While Large Language Models have transformed how we interact with AI systems,\nthey suffer from a critical flaw: they confidently generate false information\nthat sounds entirely plausible. This hallucination problem has become a major\nbarrier to deploying these models in real-world applications where accuracy\nmatters. We developed a fact verification framework that catches and corrects\nthese errors in real-time by cross checking LLM outputs against multiple\nknowledge sources. Our system combines structured databases, live web searches,\nand academic literature to verify factual claims as they're generated. When we\ndetect inconsistencies, we automatically correct them while preserving the\nnatural flow of the response. Testing across various domains showed we could\nreduce hallucinations by 67% without sacrificing response quality. Domain\nexperts in healthcare, finance, and scientific research rated our corrected\noutputs 89% satisfactory a significant improvement over unverified LLM\nresponses. This work offers a practical solution for making LLMs more\ntrustworthy in applications where getting facts wrong isn't an option.",
    "categories": [
      "cs.AI",
      "cs.CL"
    ],
    "published": "2025-10-26T16:58:54Z",
    "authors": [
      "Piyushkumar Patel"
    ],
    "pdf_url": "http://arxiv.org/pdf/2510.22751v1"
  },
  {
    "id": "2510.22747v1",
    "title": "Low-Resource Dialect Adaptation of Large Language Models: A French\n  Dialect Case-Study",
    "abstract": "Despite the widespread adoption of large language models (LLMs), their\nstrongest capabilities remain largely confined to a small number of\nhigh-resource languages for which there is abundant training data. Recently,\ncontinual pre-training (CPT) has emerged as a means to fine-tune these models\nto low-resource regional dialects. In this paper, we study the use of CPT for\ndialect learning under tight data and compute budgets. Using low-rank\nadaptation (LoRA) and compute-efficient continual pre-training, we adapt three\nLLMs to the Qu\\'ebec French dialect using a very small dataset and benchmark\nthem on the COLE suite. Our experiments demonstrate an improvement on the\nminority dialect benchmarks with minimal regression on the prestige language\nbenchmarks with under 1% of model parameters updated. Analysis of the results\ndemonstrate that gains are highly contingent on corpus composition. These\nfindings indicate that CPT with parameter-efficient fine-tuning (PEFT) can\nnarrow the dialect gap by providing cost-effective and sustainable language\nresource creation, expanding high-quality LLM access to minority linguistic\ncommunities. We release the first Qu\\'ebec French LLMs on HuggingFace.",
    "categories": [
      "cs.CL",
      "cs.AI"
    ],
    "published": "2025-10-26T16:49:06Z",
    "authors": [
      "Eeham Khan",
      "Firas Saidani",
      "Owen Van Esbroeck",
      "Richard Khoury",
      "Leila Kosseim"
    ],
    "pdf_url": "http://arxiv.org/pdf/2510.22747v1"
  },
  {
    "id": "2510.22740v1",
    "title": "Policies over Poses: Reinforcement Learning based Distributed Pose-Graph\n  Optimization for Multi-Robot SLAM",
    "abstract": "We consider the distributed pose-graph optimization (PGO) problem, which is\nfundamental in accurate trajectory estimation in multi-robot simultaneous\nlocalization and mapping (SLAM). Conventional iterative approaches linearize a\nhighly non-convex optimization objective, requiring repeated solving of normal\nequations, which often converge to local minima and thus produce suboptimal\nestimates. We propose a scalable, outlier-robust distributed planar PGO\nframework using Multi-Agent Reinforcement Learning (MARL). We cast distributed\nPGO as a partially observable Markov game defined on local pose-graphs, where\neach action refines a single edge's pose estimate. A graph partitioner\ndecomposes the global pose graph, and each robot runs a recurrent\nedge-conditioned Graph Neural Network (GNN) encoder with adaptive edge-gating\nto denoise noisy edges. Robots sequentially refine poses through a hybrid\npolicy that utilizes prior action memory and graph embeddings. After local\ngraph correction, a consensus scheme reconciles inter-robot disagreements to\nproduce a globally consistent estimate. Our extensive evaluations on a\ncomprehensive suite of synthetic and real-world datasets demonstrate that our\nlearned MARL-based actors reduce the global objective by an average of 37.5%\nmore than the state-of-the-art distributed PGO framework, while enhancing\ninference efficiency by at least 6X. We also demonstrate that actor replication\nallows a single learned policy to scale effortlessly to substantially larger\nrobot teams without any retraining. Code is publicly available at\nhttps://github.com/herolab-uga/policies-over-poses.",
    "categories": [
      "cs.RO",
      "cs.AI",
      "cs.MA"
    ],
    "published": "2025-10-26T16:21:24Z",
    "authors": [
      "Sai Krishna Ghanta",
      "Ramviyas Parasuraman"
    ],
    "pdf_url": "http://arxiv.org/pdf/2510.22740v1"
  },
  {
    "id": "2510.22739v1",
    "title": "REVISION:Reflective Intent Mining and Online Reasoning Auxiliary for\n  E-commerce Visual Search System Optimization",
    "abstract": "In Taobao e-commerce visual search, user behavior analysis reveals a large\nproportion of no-click requests, suggesting diverse and implicit user intents.\nThese intents are expressed in various forms and are difficult to mine and\ndiscover, thereby leading to the limited adaptability and lag in platform\nstrategies. This greatly restricts users' ability to express diverse intents\nand hinders the scalability of the visual search system. This mismatch between\nuser implicit intent expression and system response defines the User-SearchSys\nIntent Discrepancy. To alleviate the issue, we propose a novel framework\nREVISION. This framework integrates offline reasoning mining with online\ndecision-making and execution, enabling adaptive strategies to solve implicit\nuser demands. In the offline stage, we construct a periodic pipeline to mine\ndiscrepancies from historical no-click requests. Leveraging large models, we\nanalyze implicit intent factors and infer optimal suggestions by jointly\nreasoning over query and product metadata. These inferred suggestions serve as\nactionable insights for refining platform strategies. In the online stage,\nREVISION-R1-3B, trained on the curated offline data, performs holistic analysis\nover query images and associated historical products to generate optimization\nplans and adaptively schedule strategies across the search pipeline. Our\nframework offers a streamlined paradigm for integrating large models with\ntraditional search systems, enabling end-to-end intelligent optimization across\ninformation aggregation and user interaction. Experimental results demonstrate\nthat our approach improves the efficiency of implicit intent mining from\nlarge-scale search logs and significantly reduces the no-click rate.",
    "categories": [
      "cs.IR",
      "cs.AI",
      "cs.CL"
    ],
    "published": "2025-10-26T16:15:50Z",
    "authors": [
      "Yiwen Tang",
      "Qiuyu Zhao",
      "Zenghui Sun",
      "Jinsong Lan",
      "Xiaoyong Zhu",
      "Bo Zheng",
      "Kaifu Zhang"
    ],
    "pdf_url": "http://arxiv.org/pdf/2510.22739v1"
  },
  {
    "id": "2510.22733v1",
    "title": "$\\text{E}^2\\text{Rank}$: Your Text Embedding can Also be an Effective\n  and Efficient Listwise Reranker",
    "abstract": "Text embedding models serve as a fundamental component in real-world search\napplications. By mapping queries and documents into a shared embedding space,\nthey deliver competitive retrieval performance with high efficiency. However,\ntheir ranking fidelity remains limited compared to dedicated rerankers,\nespecially recent LLM-based listwise rerankers, which capture fine-grained\nquery-document and document-document interactions. In this paper, we propose a\nsimple yet effective unified framework $\\text{E}^2\\text{Rank}$, means Efficient\nEmbedding-based Ranking (also means Embedding-to-Rank), which extends a single\ntext embedding model to perform both high-quality retrieval and listwise\nreranking through continued training under a listwise ranking objective,\nthereby achieving strong effectiveness with remarkable efficiency. By applying\ncosine similarity between the query and document embeddings as a unified\nranking function, the listwise ranking prompt, which is constructed from the\noriginal query and its candidate documents, serves as an enhanced query\nenriched with signals from the top-K documents, akin to pseudo-relevance\nfeedback (PRF) in traditional retrieval models. This design preserves the\nefficiency and representational quality of the base embedding model while\nsignificantly improving its reranking performance. Empirically,\n$\\textrm{E}^2\\text{Rank}$ achieves state-of-the-art results on the BEIR\nreranking benchmark and demonstrates competitive performance on the\nreasoning-intensive BRIGHT benchmark, with very low reranking latency. We also\nshow that the ranking training process improves embedding performance on the\nMTEB benchmark. Our findings indicate that a single embedding model can\neffectively unify retrieval and reranking, offering both computational\nefficiency and competitive ranking accuracy.",
    "categories": [
      "cs.CL",
      "cs.AI",
      "cs.IR"
    ],
    "published": "2025-10-26T16:04:48Z",
    "authors": [
      "Qi Liu",
      "Yanzhao Zhang",
      "Mingxin Li",
      "Dingkun Long",
      "Pengjun Xie",
      "Jiaxin Mao"
    ],
    "pdf_url": "http://arxiv.org/pdf/2510.22733v1"
  },
  {
    "id": "2510.22732v1",
    "title": "ATLAS: Actor-Critic Task-Completion with Look-ahead Action Simulation",
    "abstract": "We observe that current state-of-the-art web-agents are unable to effectively\nadapt to new environments without neural network fine-tuning, without which\nthey produce inefficient execution plans due to a lack of awareness of the\nstructure and dynamics of the new environment. To address this limitation, we\nintroduce ATLAS (Actor-Critic Task-completion with Look-ahead Action\nSimulation), a memory-augmented agent that is able to make plans grounded in a\nmodel of the environment by simulating the consequences of those actions in\ncognitive space. Our agent starts by building a \"cognitive map\" by performing a\nlightweight curiosity driven exploration of the environment. The planner\nproposes candidate actions; the simulator predicts their consequences in\ncognitive space; a critic analyzes the options to select the best roll-out and\nupdate the original plan; and a browser executor performs the chosen action. On\nthe WebArena-Lite Benchmark, we achieve a 63% success rate compared to 53.9%\nsuccess rate for the previously published state-of-the-art. Unlike previous\nsystems, our modular architecture requires no website-specific LLM fine-tuning.\nAblations show sizable drops without the world-model, hierarchical planner, and\nlook-ahead-based replanner confirming their complementary roles within the\ndesign of our system",
    "categories": [
      "cs.LG",
      "cs.AI",
      "cs.CL",
      "cs.IR",
      "cs.MA",
      "cs.RO"
    ],
    "published": "2025-10-26T16:03:39Z",
    "authors": [
      "Jiali Cheng",
      "Anjishnu Kumar",
      "Roshan Lal",
      "Rishi Rajasekaran",
      "Hani Ramezani",
      "Omar Zia Khan",
      "Oleg Rokhlenko",
      "Sunny Chiu-Webster",
      "Gang Hua",
      "Hadi Amiri"
    ],
    "pdf_url": "http://arxiv.org/pdf/2510.22732v1"
  },
  {
    "id": "2510.22729v1",
    "title": "Critical Insights into Leading Conversational AI Models",
    "abstract": "Big Language Models (LLMs) are changing the way businesses use software, the\nway people live their lives and the way industries work. Companies like Google,\nHigh-Flyer, Anthropic, OpenAI and Meta are making better LLMs. So, it's crucial\nto look at how each model is different in terms of performance, moral behaviour\nand usability, as these differences are based on the different ideas that built\nthem. This study compares five top LLMs: Google's Gemini, High-Flyer's\nDeepSeek, Anthropic's Claude, OpenAI's GPT models and Meta's LLaMA. It performs\nthis by analysing three important factors: Performance and Accuracy, Ethics and\nBias Mitigation and Usability and Integration. It was found that Claude has\ngood moral reasoning, Gemini is better at multimodal capabilities and has\nstrong ethical frameworks. DeepSeek is great at reasoning based on facts, LLaMA\nis good for open applications and ChatGPT delivers balanced performance with a\nfocus on usage. It was concluded that these models are different in terms of\nhow well they work, how easy they are to use and how they treat people\nethically, making it a point that each model should be utilised by the user in\na way that makes the most of its strengths.",
    "categories": [
      "cs.AI",
      "cs.CL",
      "I.2.7; I.2.8"
    ],
    "published": "2025-10-26T15:57:27Z",
    "authors": [
      "Urja Kohli",
      "Aditi Singh",
      "Arun Sharma"
    ],
    "pdf_url": "http://arxiv.org/pdf/2510.22729v1"
  },
  {
    "id": "2510.23668v1",
    "title": "Traffic flow forecasting, STL decomposition, Hybrid model, LSTM, ARIMA,\n  XGBoost, Intelligent transportation systems",
    "abstract": "Accurate traffic flow forecasting is essential for intelligent transportation\nsystems and urban traffic management. However, single model approaches often\nfail to capture the complex, nonlinear, and multi scale temporal patterns in\ntraffic flow data. This study proposes a decomposition driven hybrid framework\nthat integrates Seasonal Trend decomposition using Loess (STL) with three\ncomplementary predictive models. STL first decomposes the original time series\ninto trend, seasonal, and residual components. Then, a Long Short Term Memory\n(LSTM) network models long term trends, an Autoregressive Integrated Moving\nAverage (ARIMA) model captures seasonal periodicity, and an Extreme Gradient\nBoosting (XGBoost) algorithm predicts nonlinear residual fluctuations. The\nfinal forecast is obtained through multiplicative integration of the sub model\npredictions. Using 998 traffic flow records from a New York City intersection\nbetween November and December 2015, results show that the LSTM ARIMA XGBoost\nhybrid model significantly outperforms standalone models including LSTM, ARIMA,\nand XGBoost across MAE, RMSE, and R squared metrics. The decomposition strategy\neffectively isolates temporal characteristics, allowing each model to\nspecialize, thereby improving prediction accuracy, interpretability, and\nrobustness.",
    "categories": [
      "cs.LG",
      "cs.AI"
    ],
    "published": "2025-10-26T15:54:48Z",
    "authors": [
      "Fujiang Yuan",
      "Yangrui Fan",
      "Xiaohuan Bing",
      "Zhen Tian",
      "Chunhong Yuan",
      "Yankang Li"
    ],
    "pdf_url": "http://arxiv.org/pdf/2510.23668v1"
  },
  {
    "id": "2510.22712v1",
    "title": "Step2Motion: Locomotion Reconstruction from Pressure Sensing Insoles",
    "abstract": "Human motion is fundamentally driven by continuous physical interaction with\nthe environment. Whether walking, running, or simply standing, the forces\nexchanged between our feet and the ground provide crucial insights for\nunderstanding and reconstructing human movement. Recent advances in wearable\ninsole devices offer a compelling solution for capturing these forces in\ndiverse, real-world scenarios. Sensor insoles pose no constraint on the users'\nmotion (unlike mocap suits) and are unaffected by line-of-sight limitations (in\ncontrast to optical systems). These qualities make sensor insoles an ideal\nchoice for robust, unconstrained motion capture, particularly in outdoor\nenvironments. Surprisingly, leveraging these devices with recent motion\nreconstruction methods remains largely unexplored. Aiming to fill this gap, we\npresent Step2Motion, the first approach to reconstruct human locomotion from\nmulti-modal insole sensors. Our method utilizes pressure and inertial\ndata-accelerations and angular rates-captured by the insoles to reconstruct\nhuman motion. We evaluate the effectiveness of our approach across a range of\nexperiments to show its versatility for diverse locomotion styles, from simple\nones like walking or jogging up to moving sideways, on tiptoes, slightly\ncrouching, or dancing.",
    "categories": [
      "cs.GR",
      "cs.AI"
    ],
    "published": "2025-10-26T15:12:02Z",
    "authors": [
      "Jose Luis Ponton",
      "Eduardo Alvarado",
      "Lin Geng Foo",
      "Nuria Pelechano",
      "Carlos Andujar",
      "Marc Habermann"
    ],
    "pdf_url": "http://arxiv.org/pdf/2510.22712v1"
  },
  {
    "id": "2510.23667v1",
    "title": "Optimize Any Topology: A Foundation Model for Shape- and Resolution-Free\n  Structural Topology Optimization",
    "abstract": "Structural topology optimization (TO) is central to engineering design but\nremains computationally intensive due to complex physics and hard constraints.\nExisting deep-learning methods are limited to fixed square grids, a few\nhand-coded boundary conditions, and post-hoc optimization, preventing general\ndeployment. We introduce Optimize Any Topology (OAT), a foundation-model\nframework that directly predicts minimum-compliance layouts for arbitrary\naspect ratios, resolutions, volume fractions, loads, and fixtures. OAT combines\na resolution- and shape-agnostic autoencoder with an implicit neural-field\ndecoder and a conditional latent-diffusion model trained on OpenTO, a new\ncorpus of 2.2 million optimized structures covering 2 million unique\nboundary-condition configurations. On four public benchmarks and two\nchallenging unseen tests, OAT lowers mean compliance up to 90% relative to the\nbest prior models and delivers sub-1 second inference on a single GPU across\nresolutions from 64 x 64 to 256 x 256 and aspect ratios as high as 10:1. These\nresults establish OAT as a general, fast, and resolution-free framework for\nphysics-aware topology optimization and provide a large-scale dataset to spur\nfurther research in generative modeling for inverse design. Code & data can be\nfound at https://github.com/ahnobari/OptimizeAnyTopology.",
    "categories": [
      "cs.LG",
      "cs.AI",
      "cs.CE"
    ],
    "published": "2025-10-26T15:11:54Z",
    "authors": [
      "Amin Heyrani Nobari",
      "Lyle Regenwetter",
      "Cyril Picard",
      "Ligong Han",
      "Faez Ahmed"
    ],
    "pdf_url": "http://arxiv.org/pdf/2510.23667v1"
  },
  {
    "id": "2510.22710v1",
    "title": "RaCoT: Plug-and-Play Contrastive Example Generation Mechanism for\n  Enhanced LLM Reasoning Reliability",
    "abstract": "Retrieval-Augmented Generation (RAG) faces a core bottleneck with\nknowledge-sparse and semantically ambiguous long-tail queries, where retrieval\nnoise distorts reasoning and necessitates costly post-processing. To tackle\nthis, we propose RaCoT (Retrieval-aware Contrastive-of-Thought), a novel\nframework that shifts contrastive thinking to the pre-retrieval stage. By\nautomatically generating a semantically adjacent yet differently answered\ncontrastive question and extracting a $\\Delta$-Prompt to capture their key\ndifferences, RaCoT guides the model to proactively focus on the ``critical\ndetails that determine answer divergence.\" This approach allows it to suppress\nsemantic interference within a single retrieval pass, overcoming the\ntheoretical bottleneck of single-vector queries that struggle to simultaneously\nencode signals for what to attend to and what to ignore. On six authoritative\nbenchmarks, including PopQA and TriviaQA-unfiltered, RaCoT outperforms strong\nbaselines like RankRAG and Self-RAG by 0.9-2.4 percentage points. It exhibits\nsuperior robustness, with a performance drop of only 8.6\\% in adversarial\ntests, far surpassing the over 15\\% degradation in other methods. Furthermore,\nits low latency (3.12s) and token overhead (11.54) place it on the\naccuracy-efficiency Pareto frontier, while ablation studies validate the\nnecessity of each component. Ultimately, RaCoT reframes the RAG paradigm from\n``post-hoc context cleaning\" to ``a priori shaping of discriminative\nreasoning\", offering an efficient and robust path toward reliable AI systems\nfor real-time, resource-constrained deployments.",
    "categories": [
      "cs.AI"
    ],
    "published": "2025-10-26T15:06:44Z",
    "authors": [
      "Kaitong Cai",
      "Jusheng Zhang",
      "Yijia Fan",
      "Jing Yang",
      "Keze Wang"
    ],
    "pdf_url": "http://arxiv.org/pdf/2510.22710v1"
  },
  {
    "id": "2510.22702v1",
    "title": "Atlas Urban Index: A VLM-Based Approach for Spatially and Temporally\n  Calibrated Urban Development Monitoring",
    "abstract": "We introduce the {\\em Atlas Urban Index} (AUI), a metric for measuring urban\ndevelopment computed using Sentinel-2 \\citep{spoto2012sentinel2} satellite\nimagery. Existing approaches, such as the {\\em Normalized Difference Built-up\nIndex} (NDBI), often struggle to accurately capture urban development due to\nfactors like atmospheric noise, seasonal variation, and cloud cover. These\nlimitations hinder large-scale monitoring of human development and\nurbanization. To address these challenges, we propose an approach that\nleverages {\\em Vision-Language Models }(VLMs) to provide a development score\nfor regions. Specifically, we collect a time series of Sentinel-2 images for\neach region. Then, we further process the images within fixed time windows to\nget an image with minimal cloud cover, which serves as the representative image\nfor that time window. To ensure consistent scoring, we adopt two strategies:\n(i) providing the VLM with a curated set of reference images representing\ndifferent levels of urbanization, and (ii) supplying the most recent past image\nto both anchor temporal consistency and mitigate cloud-related noise in the\ncurrent image. Together, these components enable AUI to overcome the challenges\nof traditional urbanization indices and produce more reliable and stable\ndevelopment scores. Our qualitative experiments on Bangalore suggest that AUI\noutperforms standard indices such as NDBI.",
    "categories": [
      "cs.AI",
      "cs.CV",
      "cs.ET",
      "eess.IV"
    ],
    "published": "2025-10-26T14:53:36Z",
    "authors": [
      "Mithul Chander",
      "Sai Pragnya Ranga",
      "Prathamesh Mayekar"
    ],
    "pdf_url": "http://arxiv.org/pdf/2510.22702v1"
  },
  {
    "id": "2510.22686v1",
    "title": "FlowCritic: Bridging Value Estimation with Flow Matching in\n  Reinforcement Learning",
    "abstract": "Reliable value estimation serves as the cornerstone of reinforcement learning\n(RL) by evaluating long-term returns and guiding policy improvement,\nsignificantly influencing the convergence speed and final performance. Existing\nworks improve the reliability of value function estimation via multi-critic\nensembles and distributional RL, yet the former merely combines multi point\nestimation without capturing distributional information, whereas the latter\nrelies on discretization or quantile regression, limiting the expressiveness of\ncomplex value distributions. Inspired by flow matching's success in generative\nmodeling, we propose a generative paradigm for value estimation, named\nFlowCritic. Departing from conventional regression for deterministic value\nprediction, FlowCritic leverages flow matching to model value distributions and\ngenerate samples for value estimation.",
    "categories": [
      "cs.LG",
      "cs.AI"
    ],
    "published": "2025-10-26T14:12:32Z",
    "authors": [
      "Shan Zhong",
      "Shutong Ding",
      "He Diao",
      "Xiangyu Wang",
      "Kah Chan Teh",
      "Bei Peng"
    ],
    "pdf_url": "http://arxiv.org/pdf/2510.22686v1"
  },
  {
    "id": "2510.22685v1",
    "title": "TABL-ABM: A Hybrid Framework for Synthetic LOB Generation",
    "abstract": "The recent application of deep learning models to financial trading has\nheightened the need for high fidelity financial time series data. This\nsynthetic data can be used to supplement historical data to train large trading\nmodels. The state-of-the-art models for the generative application often rely\non huge amounts of historical data and large, complicated models. These models\nrange from autoregressive and diffusion-based models through to architecturally\nsimpler models such as the temporal-attention bilinear layer. Agent-based\napproaches to modelling limit order book dynamics can also recreate trading\nactivity through mechanistic models of trader behaviours. In this work, we\ndemonstrate how a popular agent-based framework for simulating intraday trading\nactivity, the Chiarella model, can be combined with one of the most performant\ndeep learning models for forecasting multi-variate time series, the TABL model.\nThis forecasting model is coupled to a simulation of a matching engine with a\nnovel method for simulating deleted order flow. Our simulator gives us the\nability to test the generative abilities of the forecasting model using\nstylised facts. Our results show that this methodology generates realistic\nprice dynamics however, when analysing deeper, parts of the markets\nmicrostructure are not accurately recreated, highlighting the necessity for\nincluding more sophisticated agent behaviors into the modeling framework to\nhelp account for tail events.",
    "categories": [
      "q-fin.CP",
      "cs.AI",
      "cs.MA",
      "q-fin.TR"
    ],
    "published": "2025-10-26T14:04:49Z",
    "authors": [
      "Ollie Olby",
      "Rory Baggott",
      "Namid Stillman"
    ],
    "pdf_url": "http://arxiv.org/pdf/2510.22685v1"
  },
  {
    "id": "2510.22680v1",
    "title": "Uncertainty-Aware Autonomous Vehicles: Predicting the Road Ahead",
    "abstract": "Autonomous Vehicle (AV) perception systems have advanced rapidly in recent\nyears, providing vehicles with the ability to accurately interpret their\nenvironment. Perception systems remain susceptible to errors caused by\noverly-confident predictions in the case of rare events or out-of-sample data.\nThis study equips an autonomous vehicle with the ability to 'know when it is\nuncertain', using an uncertainty-aware image classifier as part of the AV\nsoftware stack. Specifically, the study exploits the ability of Random-Set\nNeural Networks (RS-NNs) to explicitly quantify prediction uncertainty. Unlike\ntraditional CNNs or Bayesian methods, RS-NNs predict belief functions over sets\nof classes, allowing the system to identify and signal uncertainty clearly in\nnovel or ambiguous scenarios. The system is tested in a real-world autonomous\nracing vehicle software stack, with the RS-NN classifying the layout of the\nroad ahead and providing the associated uncertainty of the prediction.\nPerformance of the RS-NN under a range of road conditions is compared against\ntraditional CNN and Bayesian neural networks, with the RS-NN achieving\nsignificantly higher accuracy and superior uncertainty calibration. This\nintegration of RS-NNs into Robot Operating System (ROS)-based vehicle control\npipeline demonstrates that predictive uncertainty can dynamically modulate\nvehicle speed, maintaining high-speed performance under confident predictions\nwhile proactively improving safety through speed reductions in uncertain\nscenarios. These results demonstrate the potential of uncertainty-aware neural\nnetworks - in particular RS-NNs - as a practical solution for safer and more\nrobust autonomous driving.",
    "categories": [
      "cs.RO",
      "cs.AI"
    ],
    "published": "2025-10-26T13:49:38Z",
    "authors": [
      "Shireen Kudukkil Manchingal",
      "Armand Amaritei",
      "Mihir Gohad",
      "Maryam Sultana",
      "Julian F. P. Kooij",
      "Fabio Cuzzolin",
      "Andrew Bradley"
    ],
    "pdf_url": "http://arxiv.org/pdf/2510.22680v1"
  },
  {
    "id": "2510.23665v2",
    "title": "Transformers from Compressed Representations",
    "abstract": "Compressed file formats are the corner stone of efficient data storage and\ntransmission, yet their potential for representation learning remains largely\nunderexplored. We introduce TEMPEST (TransformErs froM comPressed\nrEpreSenTations), a method that exploits the inherent byte-stream structure of\ncompressed files to design an effective tokenization and encoding strategy. By\nleveraging this compact encoding, a standard transformer can directly learn\nsemantic representations from compressed data streams, bypassing the need for\nraw byte-level processing or full media decoding. Our proposal substantially\nreduces the number of tokens required for semantic classification, thereby\nlowering both computational complexity and memory usage. Through extensive\nexperiments across diverse datasets, coding schemes, and modalities, we show\nthat TEMPEST achieves accuracy competitive wit the state-of-the-art while\ndelivering efficiency gains in memory and compute.",
    "categories": [
      "cs.LG",
      "cs.AI"
    ],
    "published": "2025-10-26T13:48:03Z",
    "authors": [
      "Juan C. Leon Alcazar",
      "Mattia Soldan",
      "Mohammad Saatialsoruji",
      "Alejandro Pardo",
      "Hani Itani",
      "Juan Camilo Perez",
      "Bernard Ghanem"
    ],
    "pdf_url": "http://arxiv.org/pdf/2510.23665v2"
  },
  {
    "id": "2510.22679v1",
    "title": "Do Stop Me Now: Detecting Boilerplate Responses with a Single Iteration",
    "abstract": "Large Language Models (LLMs) often expend significant computational resources\ngenerating boilerplate responses, such as refusals, simple acknowledgements and\ncasual greetings, which adds unnecessary cost and latency. To address this\ninefficiency, we propose a simple yet highly effective method for detecting\nsuch responses after only a single generation step. We demonstrate that the\nlog-probability distribution of the first generated token serves as a powerful\nsignal for classifying the nature of the entire subsequent response. Our\nexperiments, conducted across a diverse range of small, large, and\nreasoning-specialized models, show that the first-token log-probability vectors\nform distinctly separable clusters for different response types. Using a\nlightweight k-NN classifier, we achieve high accuracy in predicting whether a\nresponse will be a substantive answer or a form of boilerplate response,\nincluding user-specified refusals. The primary implication is a practical,\ncomputationally trivial technique, optimizing LLM inference by enabling early\ntermination or redirection to a smaller model, thereby yielding significant\nsavings in computational cost. This work presents a direct path toward more\nefficient and sustainable LLM deployment.",
    "categories": [
      "cs.AI",
      "cs.CL"
    ],
    "published": "2025-10-26T13:43:56Z",
    "authors": [
      "Yuval Kainan",
      "Shaked Zychlinski"
    ],
    "pdf_url": "http://arxiv.org/pdf/2510.22679v1"
  },
  {
    "id": "2510.22669v1",
    "title": "LVD-GS: Gaussian Splatting SLAM for Dynamic Scenes via Hierarchical\n  Explicit-Implicit Representation Collaboration Rendering",
    "abstract": "3D Gaussian Splatting SLAM has emerged as a widely used technique for\nhigh-fidelity mapping in spatial intelligence. However, existing methods often\nrely on a single representation scheme, which limits their performance in\nlarge-scale dynamic outdoor scenes and leads to cumulative pose errors and\nscale ambiguity. To address these challenges, we propose \\textbf{LVD-GS}, a\nnovel LiDAR-Visual 3D Gaussian Splatting SLAM system. Motivated by the human\nchain-of-thought process for information seeking, we introduce a hierarchical\ncollaborative representation module that facilitates mutual reinforcement for\nmapping optimization, effectively mitigating scale drift and enhancing\nreconstruction robustness. Furthermore, to effectively eliminate the influence\nof dynamic objects, we propose a joint dynamic modeling module that generates\nfine-grained dynamic masks by fusing open-world segmentation with implicit\nresidual constraints, guided by uncertainty estimates from DINO-Depth features.\nExtensive evaluations on KITTI, nuScenes, and self-collected datasets\ndemonstrate that our approach achieves state-of-the-art performance compared to\nexisting methods.",
    "categories": [
      "cs.CV",
      "cs.AI"
    ],
    "published": "2025-10-26T13:16:39Z",
    "authors": [
      "Wenkai Zhu",
      "Xu Li",
      "Qimin Xu",
      "Benwu Wang",
      "Kun Wei",
      "Yiming Peng",
      "Zihang Wang"
    ],
    "pdf_url": "http://arxiv.org/pdf/2510.22669v1"
  },
  {
    "id": "2510.22665v1",
    "title": "SARCLIP: A Vision Language Foundation Model for Semantic Understanding\n  and Target Recognition in SAR Imagery",
    "abstract": "Synthetic Aperture Radar (SAR) has emerged as a crucial imaging modality due\nto its all-weather capabilities. While recent advancements in self-supervised\nlearning and Masked Image Modeling (MIM) have paved the way for SAR foundation\nmodels, these approaches primarily focus on low-level visual features, often\noverlooking multimodal alignment and zero-shot target recognition within SAR\nimagery. To address this limitation, we construct SARCLIP-1M, a large-scale\nvision language dataset comprising over one million text-image pairs aggregated\nfrom existing datasets. We further introduce SARCLIP, the first vision language\nfoundation model tailored for the SAR domain. Our SARCLIP model is trained\nusing a contrastive vision language learning approach by domain transferring\nstrategy, enabling it to bridge the gap between SAR imagery and textual\ndescriptions. Extensive experiments on image-text retrieval and zero-shot\nclassification tasks demonstrate the superior performance of SARCLIP in feature\nextraction and interpretation, significantly outperforming state-of-the-art\nfoundation models and advancing the semantic understanding of SAR imagery. The\ncode and datasets will be released soon.",
    "categories": [
      "cs.CV",
      "cs.AI"
    ],
    "published": "2025-10-26T13:04:50Z",
    "authors": [
      "Qiwei Ma",
      "Zhiyu Wang",
      "Wang Liu",
      "Xukun Lu",
      "Bin Deng",
      "Puhong Duan",
      "Xudong Kang",
      "Shutao Li"
    ],
    "pdf_url": "http://arxiv.org/pdf/2510.22665v1"
  },
  {
    "id": "2510.22655v1",
    "title": "Learning Without Augmenting: Unsupervised Time Series Representation\n  Learning via Frame Projections",
    "abstract": "Self-supervised learning (SSL) has emerged as a powerful paradigm for\nlearning representations without labeled data. Most SSL approaches rely on\nstrong, well-established, handcrafted data augmentations to generate diverse\nviews for representation learning. However, designing such augmentations\nrequires domain-specific knowledge and implicitly imposes representational\ninvariances on the model, which can limit generalization. In this work, we\npropose an unsupervised representation learning method that replaces\naugmentations by generating views using orthonormal bases and overcomplete\nframes. We show that embeddings learned from orthonormal and overcomplete\nspaces reside on distinct manifolds, shaped by the geometric biases introduced\nby representing samples in different spaces. By jointly leveraging the\ncomplementary geometry of these distinct manifolds, our approach achieves\nsuperior performance without artificially increasing data diversity through\nstrong augmentations. We demonstrate the effectiveness of our method on nine\ndatasets across five temporal sequence tasks, where signal-specific\ncharacteristics make data augmentations particularly challenging. Without\nrelying on augmentation-induced diversity, our method achieves performance\ngains of up to 15--20\\% over existing self-supervised approaches. Source code:\nhttps://github.com/eth-siplab/Learning-with-FrameProjections",
    "categories": [
      "cs.LG",
      "cs.AI"
    ],
    "published": "2025-10-26T12:36:29Z",
    "authors": [
      "Berken Utku Demirel",
      "Christian Holz"
    ],
    "pdf_url": "http://arxiv.org/pdf/2510.22655v1"
  },
  {
    "id": "2510.22651v1",
    "title": "Variational Polya Tree",
    "abstract": "Density estimation is essential for generative modeling, particularly with\nthe rise of modern neural networks. While existing methods capture complex data\ndistributions, they often lack interpretability and uncertainty quantification.\nBayesian nonparametric methods, especially the \\polya tree, offer a robust\nframework that addresses these issues by accurately capturing function behavior\nover small intervals. Traditional techniques like Markov chain Monte Carlo\n(MCMC) face high computational complexity and scalability limitations,\nhindering the use of Bayesian nonparametric methods in deep learning. To tackle\nthis, we introduce the variational \\polya tree (VPT) model, which employs\nstochastic variational inference to compute posterior distributions. This model\nprovides a flexible, nonparametric Bayesian prior that captures latent\ndensities and works well with stochastic gradient optimization. We also\nleverage the joint distribution likelihood for a more precise variational\nposterior approximation than traditional mean-field methods. We evaluate the\nmodel performance on both real data and images, and demonstrate its\ncompetitiveness with other state-of-the-art deep density estimation methods. We\nalso explore its ability in enhancing interpretability and uncertainty\nquantification. Code is available at\nhttps://github.com/howardchanth/var-polya-tree.",
    "categories": [
      "cs.LG",
      "cs.AI"
    ],
    "published": "2025-10-26T12:23:22Z",
    "authors": [
      "Lu Xu",
      "Tsai Hor Chan",
      "Kwok Fai Lam",
      "Lequan Yu",
      "Guosheng Yin"
    ],
    "pdf_url": "http://arxiv.org/pdf/2510.22651v1"
  },
  {
    "id": "2510.22647v1",
    "title": "A Critical Study on Tea Leaf Disease Detection using Deep Learning\n  Techniques",
    "abstract": "The proposed solution is Deep Learning Technique that will be able classify\nthree types of tea leaves diseases from which two diseases are caused by the\npests and one due to pathogens (infectious organisms) and environmental\nconditions and also show the area damaged by a disease in leaves. Namely Red\nRust, Helopeltis and Red spider mite respectively. In this paper we have\nevaluated two models namely SSD MobileNet V2 and Faster R-CNN ResNet50 V1 for\nthe object detection. The SSD MobileNet V2 gave precision of 0.209 for IOU\nrange of 0.50:0.95 with recall of 0.02 on IOU 0.50:0.95 and final mAP of 20.9%.\nWhile Faster R-CNN ResNet50 V1 has precision of 0.252 on IOU range of 0.50:0.95\nand recall of 0.044 on IOU of 0.50:0.95 with a mAP of 25%, which is better than\nSSD. Also used Mask R-CNN for Object Instance Segmentation where we have\nimplemented our custom method to calculate the damaged diseased portion of\nleaves. Keywords: Tea Leaf Disease, Deep Learning, Red Rust, Helopeltis and Red\nSpider Mite, SSD MobileNet V2, Faster R-CNN ResNet50 V1 and Mask RCNN.",
    "categories": [
      "cs.CV",
      "cs.AI"
    ],
    "published": "2025-10-26T12:18:15Z",
    "authors": [
      "Nabajyoti Borah",
      "Raju Moni Borah",
      "Bandan Boruah",
      "Purnendu Bikash Acharjee",
      "Sajal Saha",
      "Ripjyoti Hazarika"
    ],
    "pdf_url": "http://arxiv.org/pdf/2510.22647v1"
  },
  {
    "id": "2510.22643v1",
    "title": "Enhancing Graph Classification Robustness with Singular Pooling",
    "abstract": "Graph Neural Networks (GNNs) have achieved strong performance across a range\nof graph representation learning tasks, yet their adversarial robustness in\ngraph classification remains underexplored compared to node classification.\nWhile most existing defenses focus on the message-passing component, this work\ninvestigates the overlooked role of pooling operations in shaping robustness.\nWe present a theoretical analysis of standard flat pooling methods (sum,\naverage and max), deriving upper bounds on their adversarial risk and\nidentifying their vulnerabilities under different attack scenarios and graph\nstructures. Motivated by these insights, we propose \\textit{Robust Singular\nPooling (RS-Pool)}, a novel pooling strategy that leverages the dominant\nsingular vector of the node embedding matrix to construct a robust graph-level\nrepresentation. We theoretically investigate the robustness of RS-Pool and\ninterpret the resulting bound leading to improved understanding of our proposed\npooling operator. While our analysis centers on Graph Convolutional Networks\n(GCNs), RS-Pool is model-agnostic and can be implemented efficiently via power\niteration. Empirical results on real-world benchmarks show that RS-Pool\nprovides better robustness than the considered pooling methods when subject to\nstate-of-the-art adversarial attacks while maintaining competitive clean\naccuracy. Our code is publicly available\nat:\\href{https://github.com/king/rs-pool}{https://github.com/king/rs-pool}.",
    "categories": [
      "cs.LG",
      "cs.AI"
    ],
    "published": "2025-10-26T12:07:06Z",
    "authors": [
      "Sofiane Ennadir",
      "Oleg Smirnov",
      "Yassine Abbahaddou",
      "Lele Cao",
      "Johannes F. Lutzeyer"
    ],
    "pdf_url": "http://arxiv.org/pdf/2510.22643v1"
  },
  {
    "id": "2510.23664v1",
    "title": "Agentsway -- Software Development Methodology for AI Agents-based Teams",
    "abstract": "The emergence of Agentic AI is fundamentally transforming how software is\ndesigned, developed, and maintained. Traditional software development\nmethodologies such as Agile, Kanban, ShapeUp, etc, were originally designed for\nhuman-centric teams and are increasingly inadequate in environments where\nautonomous AI agents contribute to planning, coding, testing, and continuous\nlearning. To address this methodological gap, we present \"Agentsway\" a novel\nsoftware development framework designed for ecosystems where AI agents operate\nas first-class collaborators. Agentsway introduces a structured lifecycle\ncentered on human orchestration, and privacy-preserving collaboration among\nspecialized AI agents. The framework defines distinct roles for planning,\nprompting, coding, testing, and fine-tuning agents, each contributing to\niterative improvement and adaptive learning throughout the development process.\nBy integrating fine-tuned LLMs that leverage outputs and feedback from\ndifferent agents throughout the development cycle as part of a retrospective\nlearning process, Agentsway enhances domain-specific reasoning, and explainable\ndecision-making across the entire software development lifecycle. Responsible\nAI principles are further embedded across the agents through the coordinated\nuse of multiple fine-tuned LLMs and advanced reasoning models, ensuring\nbalanced, transparent, and accountable decision-making. This work advances\nsoftware engineering by formalizing agent-centric collaboration, integrating\nprivacy-by-design principles, and defining measurable metrics for productivity\nand trust. Agentsway represents a foundational step toward the next generation\nof AI-native, self-improving software development methodologies. To the best of\nour knowledge, this is the first research effort to introduce a dedicated\nmethodology explicitly designed for AI agent-based software engineering teams.",
    "categories": [
      "cs.SE",
      "cs.AI"
    ],
    "published": "2025-10-26T11:58:42Z",
    "authors": [
      "Eranga Bandara",
      "Ross Gore",
      "Xueping Liang",
      "Sachini Rajapakse",
      "Isurunima Kularathne",
      "Pramoda Karunarathna",
      "Peter Foytik",
      "Sachin Shetty",
      "Ravi Mukkamala",
      "Abdul Rahman",
      "Amin Hass",
      "Ng Wee Keong",
      "Kasun De Zoysa",
      "Aruna Withanage",
      "Nilaan Loganathan"
    ],
    "pdf_url": "http://arxiv.org/pdf/2510.23664v1"
  },
  {
    "id": "2510.22641v1",
    "title": "FastVLM: Self-Speculative Decoding for Fast Vision-Language Model\n  Inference",
    "abstract": "Vision-language Models (VLMs) have made significant strides in visual\nunderstanding and query response generation, but often face challenges of high\ncomputational cost and inference latency due to autoregressive decoding. In\nthis work, we introduce an imitation-learning-based Self-Speculative Decoding\n(SSD) framework, named FastVLM, to address these limitations. Our approach\nemploys a lightweight draft model for token generation in an autoregressive\nmanner, while a full model verifies these tokens non-autoregressively. Accepted\ntokens proceed seamlessly, while rejected tokens are corrected by the full\nmodel and used to guide the draft model's refinement. Through an imitation\nnetwork, FastVLM enhances the draft model by integrating deeper level insights\nfrom the full model's architecture. Also, it maintains the performance\nintegrity of the full model while training the draft model, achieving a balance\nbetween efficiency and accuracy. Our method speeds up the inference process by\n1.55-1.85x as compared to the final layer with minimal loss in performance.",
    "categories": [
      "cs.LG",
      "cs.AI"
    ],
    "published": "2025-10-26T11:49:20Z",
    "authors": [
      "Divya Jyoti Bajpai",
      "Manjesh Kumar Hanawal"
    ],
    "pdf_url": "http://arxiv.org/pdf/2510.22641v1"
  },
  {
    "id": "2510.22629v1",
    "title": "Integrating Linguistics and AI: Morphological Analysis and Corpus\n  development of Endangered Toto Language of West Bengal",
    "abstract": "Preserving linguistic diversity is necessary as every language offers a\ndistinct perspective on the world. There have been numerous global initiatives\nto preserve endangered languages through documentation. This paper is a part of\na project which aims to develop a trilingual (Toto-Bangla-English) language\nlearning application to digitally archive and promote the endangered Toto\nlanguage of West Bengal, India. This application, designed for both native Toto\nspeakers and non-native learners, aims to revitalize the language by ensuring\naccessibility and usability through Unicode script integration and a structured\nlanguage corpus. The research includes detailed linguistic documentation\ncollected via fieldwork, followed by the creation of a morpheme-tagged,\ntrilingual corpus used to train a Small Language Model (SLM) and a\nTransformer-based translation engine. The analysis covers inflectional\nmorphology such as person-number-gender agreement, tense-aspect-mood\ndistinctions, and case marking, alongside derivational strategies that reflect\nword-class changes. Script standardization and digital literacy tools were also\ndeveloped to enhance script usage. The study offers a sustainable model for\npreserving endangered languages by incorporating traditional linguistic\nmethodology with AI. This bridge between linguistic research with technological\ninnovation highlights the value of interdisciplinary collaboration for\ncommunity-based language revitalization.",
    "categories": [
      "cs.CL",
      "cs.AI"
    ],
    "published": "2025-10-26T11:22:46Z",
    "authors": [
      "Ambalika Guha",
      "Sajal Saha",
      "Debanjan Ballav",
      "Soumi Mitra",
      "Hritwick Chakraborty"
    ],
    "pdf_url": "http://arxiv.org/pdf/2510.22629v1"
  },
  {
    "id": "2510.22628v1",
    "title": "Sentra-Guard: A Multilingual Human-AI Framework for Real-Time Defense\n  Against Adversarial LLM Jailbreaks",
    "abstract": "This paper presents a real-time modular defense system named Sentra-Guard.\nThe system detects and mitigates jailbreak and prompt injection attacks\ntargeting large language models (LLMs). The framework uses a hybrid\narchitecture with FAISS-indexed SBERT embedding representations that capture\nthe semantic meaning of prompts, combined with fine-tuned transformer\nclassifiers, which are machine learning models specialized for distinguishing\nbetween benign and adversarial language inputs. It identifies adversarial\nprompts in both direct and obfuscated attack vectors. A core innovation is the\nclassifier-retriever fusion module, which dynamically computes context-aware\nrisk scores that estimate how likely a prompt is to be adversarial based on its\ncontent and context. The framework ensures multilingual resilience with a\nlanguage-agnostic preprocessing layer. This component automatically translates\nnon-English prompts into English for semantic evaluation, enabling consistent\ndetection across over 100 languages. The system includes a HITL feedback loop,\nwhere decisions made by the automated system are reviewed by human experts for\ncontinual learning and rapid adaptation under adversarial pressure.\nSentra-Guard maintains an evolving dual-labeled knowledge base of benign and\nmalicious prompts, enhancing detection reliability and reducing false\npositives. Evaluation results show a 99.96% detection rate (AUC = 1.00, F1 =\n1.00) and an attack success rate (ASR) of only 0.004%. This outperforms leading\nbaselines such as LlamaGuard-2 (1.3%) and OpenAI Moderation (3.7%). Unlike\nblack-box approaches, Sentra-Guard is transparent, fine-tunable, and compatible\nwith diverse LLM backends. Its modular design supports scalable deployment in\nboth commercial and open-source environments. The system establishes a new\nstate-of-the-art in adversarial LLM defense.",
    "categories": [
      "cs.CR",
      "cs.AI"
    ],
    "published": "2025-10-26T11:19:47Z",
    "authors": [
      "Md. Mehedi Hasan",
      "Ziaur Rahman",
      "Rafid Mostafiz",
      "Md. Abir Hossain"
    ],
    "pdf_url": "http://arxiv.org/pdf/2510.22628v1"
  },
  {
    "id": "2510.22626v1",
    "title": "SwiftSolve: A Self-Iterative, Complexity-Aware Multi-Agent Framework for\n  Competitive Programming",
    "abstract": "Correctness alone is insufficient: LLM-generated programs frequently satisfy\nunit tests while violating contest time or memory budgets. We present\nSwiftSolve, a complexity-aware multi-agent system for competitive programming\nthat couples algorithmic planning with empirical profiling and\ncomplexity-guided repair. We frame competitive programming as a software\nenvironment where specialized agents act as programmers, each assuming roles\nsuch as planning, coding, profiling, and complexity analysis. A Planner\nproposes an algorithmic sketch; a deterministic Static Pruner filters high-risk\nplans; a Coder emits ISO C++17; a Profiler compiles and executes candidates on\na fixed input-size schedule to record wall time and peak memory; and a\nComplexity Analyst fits log-log growth (s, R2) with an LLM fallback to assign a\ncomplexity class and dispatch targeted patches to either the Planner or Coder.\nAgents communicate via typed, versioned JSON; a controller enforces iteration\ncaps and diminishing returns stopping. Evaluated on 26 problems (16 BigO, 10\nCodeforces Div. 2) in a POSIX sandbox (2 s / 256-512 MB), SwiftSolve attains\npass@1 = 61.54% (16/26) on the first attempt and Solved@<=3 = 80.77% with\nmarginal latency change (mean 11.96 s to 12.66 s per attempt). Aggregate\nrun-level success is 73.08% at 12.40 s mean. Failures are predominantly\nresource-bound, indicating inefficiency rather than logic errors. Against\nClaude Opus 4, SwiftSolve improves run-level success (73.1% vs 52.6%) at\napproximately 2x runtime overhead (12.4 s vs 6.8 s). Beyond correctness\n(pass@k), we report efficiency metrics (eff@k for runtime and memory, incidence\nof TLE or MLE, and complexity fit accuracy on BigO), demonstrating that\nprofiling and complexity-guided replanning reduce inefficiency while preserving\naccuracy.",
    "categories": [
      "cs.AI"
    ],
    "published": "2025-10-26T11:05:27Z",
    "authors": [
      "Adhyayan Veer Singh",
      "Aaron Shen",
      "Brian Law",
      "Ahmed Ismail",
      "Jonas Rohweder",
      "Sean O'Brien",
      "Kevin Zhu"
    ],
    "pdf_url": "http://arxiv.org/pdf/2510.22626v1"
  },
  {
    "id": "2510.22620v1",
    "title": "Breaking Agent Backbones: Evaluating the Security of Backbone LLMs in AI\n  Agents",
    "abstract": "AI agents powered by large language models (LLMs) are being deployed at\nscale, yet we lack a systematic understanding of how the choice of backbone LLM\naffects agent security. The non-deterministic sequential nature of AI agents\ncomplicates security modeling, while the integration of traditional software\nwith AI components entangles novel LLM vulnerabilities with conventional\nsecurity risks. Existing frameworks only partially address these challenges as\nthey either capture specific vulnerabilities only or require modeling of\ncomplete agents. To address these limitations, we introduce threat snapshots: a\nframework that isolates specific states in an agent's execution flow where LLM\nvulnerabilities manifest, enabling the systematic identification and\ncategorization of security risks that propagate from the LLM to the agent\nlevel. We apply this framework to construct the $\\operatorname{b}^3$ benchmark,\na security benchmark based on 194331 unique crowdsourced adversarial attacks.\nWe then evaluate 31 popular LLMs with it, revealing, among other insights, that\nenhanced reasoning capabilities improve security, while model size does not\ncorrelate with security. We release our benchmark, dataset, and evaluation code\nto facilitate widespread adoption by LLM providers and practitioners, offering\nguidance for agent developers and incentivizing model developers to prioritize\nbackbone security improvements.",
    "categories": [
      "cs.CR",
      "cs.AI",
      "cs.LG"
    ],
    "published": "2025-10-26T10:36:42Z",
    "authors": [
      "Julia Bazinska",
      "Max Mathys",
      "Francesco Casucci",
      "Mateo Rojas-Carulla",
      "Xander Davies",
      "Alexandra Souly",
      "Niklas Pfister"
    ],
    "pdf_url": "http://arxiv.org/pdf/2510.22620v1"
  },
  {
    "id": "2510.22618v1",
    "title": "Cross-Species Transfer Learning in Agricultural AI: Evaluating ZebraPose\n  Adaptation for Dairy Cattle Pose Estimation",
    "abstract": "Pose estimation serves as a cornerstone of computer vision for understanding\nanimal posture, behavior, and welfare. Yet, agricultural applications remain\nconstrained by the scarcity of large, annotated datasets for livestock,\nespecially dairy cattle. This study evaluates the potential and limitations of\ncross-species transfer learning by adapting ZebraPose - a vision\ntransformer-based model trained on synthetic zebra imagery - for 27-keypoint\ndetection in dairy cows under real barn conditions. Using three configurations\n- a custom on-farm dataset (375 images, Sussex, New Brunswick, Canada), a\nsubset of the APT-36K benchmark dataset, and their combination, we\nsystematically assessed model accuracy and generalization across environments.\nWhile the combined model achieved promising performance (AP = 0.86, AR = 0.87,\nPCK 0.5 = 0.869) on in-distribution data, substantial generalization failures\noccurred when applied to unseen barns and cow populations. These findings\nexpose the synthetic-to-real domain gap as a major obstacle to agricultural AI\ndeployment and emphasize that morphological similarity between species is\ninsufficient for cross-domain transfer. The study provides practical insights\ninto dataset diversity, environmental variability, and computational\nconstraints that influence real-world deployment of livestock monitoring\nsystems. We conclude with a call for agriculture-first AI design, prioritizing\nfarm-level realism, cross-environment robustness, and open benchmark datasets\nto advance trustworthy and scalable animal-centric technologies.",
    "categories": [
      "cs.CV",
      "cs.AI"
    ],
    "published": "2025-10-26T10:31:22Z",
    "authors": [
      "Mackenzie Tapp",
      "Sibi Chakravarthy Parivendan",
      "Kashfia Sailunaz",
      "Suresh Neethirajan"
    ],
    "pdf_url": "http://arxiv.org/pdf/2510.22618v1"
  },
  {
    "id": "2510.22616v1",
    "title": "PerCoR: Evaluating Commonsense Reasoning in Persian via Multiple-Choice\n  Sentence Completion",
    "abstract": "We introduced PerCoR (Persian Commonsense Reasoning), the first large-scale\nPersian benchmark for commonsense reasoning. PerCoR contains 106K\nmultiple-choice sentence-completion problems drawn from more than forty news,\ncultural, and other web sources. We introduce a novel conjunction-based\nsegmentation strategy to generate coherent sentence-completion pairs, enabling\nbroad topical and structural diversity. To create challenging distractors, we\npropose DRESS-AF (Distractor Ranking via Embedding Similarity Scoring and\nAdversarial Filtering), a generation-free adversarial filtering method that\nselects distractors from the pool of gold continuations while maximising model\nconfusion. Human annotators score 89% on PerCoR, while OpenAI-o3 achieves the\nhighest performance at 92.18%, followed closely by Claude-Sonnet-3.7 (91.17%).\nThe strongest open-source model, DeepSeek-R1, reaches 82.51%, underscoring both\nthe dataset's difficulty and the remaining performance gap in Persian\ncommonsense reasoning. We further show that DRESS-AF transfers to the English\nHellaSwag benchmark, increasing its difficulty without hurting human\nsolvability. The dataset is available at\nhttps://huggingface.co/datasets/MCINext/PerCoR.",
    "categories": [
      "cs.CL",
      "cs.AI",
      "I.2.7"
    ],
    "published": "2025-10-26T10:25:02Z",
    "authors": [
      "Morteza Alikhani",
      "Mohammadtaha Bagherifard",
      "Erfan Zinvandi",
      "Mehran Sarmadi"
    ],
    "pdf_url": "http://arxiv.org/pdf/2510.22616v1"
  },
  {
    "id": "2510.22614v1",
    "title": "Does In-IDE Calibration of Large Language Models work at Scale?",
    "abstract": "The introduction of large language models into integrated development\nenvironments (IDEs) is revolutionizing software engineering, yet it poses\nchallenges to the usefulness and reliability of Artificial\nIntelligence-generated code. Post-hoc calibration of internal model confidences\naims to align probabilities with an acceptability measure. Prior work suggests\ncalibration can improve alignment, but at-scale evidence is limited. In this\nwork, we investigate the feasibility of applying calibration of code models to\nan in-IDE context. We study two aspects of the problem: (1) the technical\nmethod for implementing confidence calibration and improving the reliability of\ncode generation models, and (2) the human-centered design principles for\neffectively communicating reliability signal to developers. First, we develop a\nscalable and flexible calibration framework which can be used to obtain\ncalibration weights for open-source models using any dataset, and evaluate\nwhether calibrators improve the alignment between model confidence and\ndeveloper acceptance behavior. Through a large-scale analysis of over 24\nmillion real-world developer interactions across multiple programming\nlanguages, we find that a general, post-hoc calibration model based on\nPlatt-scaling does not, on average, improve the reliability of model confidence\nsignals. We also find that while dynamically personalizing calibration to\nindividual users can be effective, its effectiveness is highly dependent on the\nvolume of user interaction data. Second, we conduct a multi-phase design study\nwith 3 expert designers and 153 professional developers, combining\nscenario-based design, semi-structured interviews, and survey validation,\nrevealing a clear preference for presenting reliability signals via\nnon-numerical, color-coded indicators within the in-editor code generation\nworkflow.",
    "categories": [
      "cs.SE",
      "cs.AI"
    ],
    "published": "2025-10-26T10:15:03Z",
    "authors": [
      "Roham Koohestani",
      "Agnia Sergeyuk",
      "David Gros",
      "Claudio Spiess",
      "Sergey Titov",
      "Prem Devanbu",
      "Maliheh Izadi"
    ],
    "pdf_url": "http://arxiv.org/pdf/2510.22614v1"
  },
  {
    "id": "2510.22609v1",
    "title": "CLIN-LLM: A Safety-Constrained Hybrid Framework for Clinical Diagnosis\n  and Treatment Generation",
    "abstract": "Accurate symptom-to-disease classification and clinically grounded treatment\nrecommendations remain challenging, particularly in heterogeneous patient\nsettings with high diagnostic risk. Existing large language model (LLM)-based\nsystems often lack medical grounding and fail to quantify uncertainty,\nresulting in unsafe outputs. We propose CLIN-LLM, a safety-constrained hybrid\npipeline that integrates multimodal patient encoding, uncertainty-calibrated\ndisease classification, and retrieval-augmented treatment generation. The\nframework fine-tunes BioBERT on 1,200 clinical cases from the Symptom2Disease\ndataset and incorporates Focal Loss with Monte Carlo Dropout to enable\nconfidence-aware predictions from free-text symptoms and structured vitals.\nLow-certainty cases (18%) are automatically flagged for expert review, ensuring\nhuman oversight. For treatment generation, CLIN-LLM employs Biomedical\nSentence-BERT to retrieve top-k relevant dialogues from the 260,000-sample\nMedDialog corpus. The retrieved evidence and patient context are fed into a\nfine-tuned FLAN-T5 model for personalized treatment generation, followed by\npost-processing with RxNorm for antibiotic stewardship and drug-drug\ninteraction (DDI) screening. CLIN-LLM achieves 98% accuracy and F1 score,\noutperforming ClinicalBERT by 7.1% (p < 0.001), with 78% top-5 retrieval\nprecision and a clinician-rated validity of 4.2 out of 5. Unsafe antibiotic\nsuggestions are reduced by 67% compared to GPT-5. These results demonstrate\nCLIN-LLM's robustness, interpretability, and clinical safety alignment. The\nproposed system provides a deployable, human-in-the-loop decision support\nframework for resource-limited healthcare environments. Future work includes\nintegrating imaging and lab data, multilingual extensions, and clinical trial\nvalidation.",
    "categories": [
      "cs.AI"
    ],
    "published": "2025-10-26T10:11:53Z",
    "authors": [
      "Md. Mehedi Hasan",
      "Rafid Mostafiz",
      "Md. Abir Hossain",
      "Bikash Kumar Paul"
    ],
    "pdf_url": "http://arxiv.org/pdf/2510.22609v1"
  },
  {
    "id": "2510.22602v1",
    "title": "Personal Care Utility (PCU): Building the Health Infrastructure for\n  Everyday Insight and Guidance",
    "abstract": "Building on decades of success in digital infrastructure and biomedical\ninnovation, we propose the Personal Care Utility (PCU) - a cybernetic system\nfor lifelong health guidance. PCU is conceived as a global, AI-powered utility\nthat continuously orchestrates multimodal data, knowledge, and services to\nassist individuals and populations alike. Drawing on multimodal agents,\nevent-centric modeling, and contextual inference, it offers three essential\ncapabilities: (1) trusted health information tailored to the individual, (2)\nproactive health navigation and behavior guidance, and (3) ongoing\ninterpretation of recovery and treatment response after medical events. Unlike\nconventional episodic care, PCU functions as an ambient, adaptive companion -\nobserving, interpreting, and guiding health in real time across daily life. By\nintegrating personal sensing, experiential computing, and population-level\nanalytics, PCU promises not only improved outcomes for individuals but also a\nnew substrate for public health and scientific discovery. We describe the\narchitecture, design principles, and implementation challenges of this emerging\nparadigm.",
    "categories": [
      "cs.CL",
      "cs.AI",
      "cs.CY"
    ],
    "published": "2025-10-26T09:43:33Z",
    "authors": [
      "Mahyar Abbasian",
      "Ramesh Jain"
    ],
    "pdf_url": "http://arxiv.org/pdf/2510.22602v1"
  },
  {
    "id": "2510.22600v1",
    "title": "RoGER-SLAM: A Robust Gaussian Splatting SLAM System for Noisy and\n  Low-light Environment Resilience",
    "abstract": "The reliability of Simultaneous Localization and Mapping (SLAM) is severely\nconstrained in environments where visual inputs suffer from noise and low\nillumination. Although recent 3D Gaussian Splatting (3DGS) based SLAM\nframeworks achieve high-fidelity mapping under clean conditions, they remain\nvulnerable to compounded degradations that degrade mapping and tracking\nperformance. A key observation underlying our work is that the original 3DGS\nrendering pipeline inherently behaves as an implicit low-pass filter,\nattenuating high-frequency noise but also risking over-smoothing. Building on\nthis insight, we propose RoGER-SLAM, a robust 3DGS SLAM system tailored for\nnoise and low-light resilience. The framework integrates three innovations: a\nStructure-Preserving Robust Fusion (SP-RoFusion) mechanism that couples\nrendered appearance, depth, and edge cues; an adaptive tracking objective with\nresidual balancing regularization; and a Contrastive Language-Image Pretraining\n(CLIP)-based enhancement module, selectively activated under compounded\ndegradations to restore semantic and structural fidelity. Comprehensive\nexperiments on Replica, TUM, and real-world sequences show that RoGER-SLAM\nconsistently improves trajectory accuracy and reconstruction quality compared\nwith other 3DGS-SLAM systems, especially under adverse imaging conditions.",
    "categories": [
      "cs.RO",
      "cs.AI"
    ],
    "published": "2025-10-26T09:32:43Z",
    "authors": [
      "Huilin Yin",
      "Zhaolin Yang",
      "Linchuan Zhang",
      "Gerhard Rigoll",
      "Johannes Betz"
    ],
    "pdf_url": "http://arxiv.org/pdf/2510.22600v1"
  },
  {
    "id": "2510.22594v1",
    "title": "A Framework for Quantifying How Pre-Training and Context Benefit\n  In-Context Learning",
    "abstract": "Pre-trained large language models have demonstrated a strong ability to learn\nfrom context, known as in-context learning (ICL). Despite a surge of recent\napplications that leverage such capabilities, it is by no means clear, at least\ntheoretically, how the ICL capabilities arise, and in particular, what is the\nprecise role played by key factors such as pre-training procedure as well as\ncontext construction. In this work, we propose a new framework to analyze the\nICL performance, for a class of realistic settings, which includes network\narchitectures, data encoding, data generation, and prompt construction process.\nAs a first step, we construct a simple example with a one-layer transformer,\nand show an interesting result, namely when the pre-train data distribution is\ndifferent from the query task distribution, a properly constructed context can\nshift the output distribution towards the query task distribution, in a\nquantifiable manner, leading to accurate prediction on the query topic. We then\nextend the findings in the previous step to a more general case, and derive the\nprecise relationship between ICL performance, context length and the KL\ndivergence between pre-train and query task distribution. Finally, we provide\nexperiments to validate our theoretical results.",
    "categories": [
      "cs.AI",
      "cs.LG"
    ],
    "published": "2025-10-26T09:21:29Z",
    "authors": [
      "Bingqing Song",
      "Jiaxiang Li",
      "Rong Wang",
      "Songtao Lu",
      "Mingyi Hong"
    ],
    "pdf_url": "http://arxiv.org/pdf/2510.22594v1"
  },
  {
    "id": "2510.22593v1",
    "title": "AutoBench: Automating LLM Evaluation through Reciprocal Peer Assessment",
    "abstract": "We present AutoBench, a fully automated and self-sustaining framework for\nevaluating Large Language Models (LLMs) through reciprocal peer assessment.\nThis paper provides a rigorous scientific validation of the AutoBench\nmethodology, originally developed as an open-source project by eZecute S.R.L..\nUnlike static benchmarks that suffer from test-set contamination and limited\nadaptability, AutoBench dynamically generates novel evaluation tasks while\nmodels alternately serve as question generators, contestants, and judges across\ndiverse domains. An iterative weighting mechanism amplifies the influence of\nconsistently reliable evaluators, aggregating peer judgments into\nconsensus-based rankings that reflect collective model agreement. Our\nexperiments demonstrate strong correlations with established benchmarks\nincluding MMLU-Pro and GPQA (respectively 78\\% and 63\\%), validating this\npeer-driven evaluation paradigm. The multi-judge design significantly\noutperforms single-judge baselines, confirming that distributed evaluation\nproduces more robust and human-consistent assessments. AutoBench offers a\nscalable, contamination-resistant alternative to static benchmarks for the\ncontinuous evaluation of evolving language models.",
    "categories": [
      "cs.CL",
      "cs.AI",
      "I.2.7; I.2.11; H.3.4; D.2.8"
    ],
    "published": "2025-10-26T09:20:39Z",
    "authors": [
      "Dario Loi",
      "Elena Maria Mui\u00e0",
      "Federico Siciliano",
      "Giovanni Trappolini",
      "Vincenzo Cris\u00e0",
      "Peter Kruger",
      "Fabrizio Silvestri"
    ],
    "pdf_url": "http://arxiv.org/pdf/2510.22593v1"
  },
  {
    "id": "2510.22590v1",
    "title": "ATOM: AdapTive and OptiMized dynamic temporal knowledge graph\n  construction using LLMs",
    "abstract": "In today's rapidly expanding data landscape, knowledge extraction from\nunstructured text is vital for real-time analytics, temporal inference, and\ndynamic memory frameworks. However, traditional static knowledge graph (KG)\nconstruction often overlooks the dynamic and time-sensitive nature of\nreal-world data, limiting adaptability to continuous changes. Moreover, recent\nzero- or few-shot approaches that avoid domain-specific fine-tuning or reliance\non prebuilt ontologies often suffer from instability across multiple runs, as\nwell as incomplete coverage of key facts. To address these challenges, we\nintroduce ATOM (AdapTive and OptiMized), a few-shot and scalable approach that\nbuilds and continuously updates Temporal Knowledge Graphs (TKGs) from\nunstructured texts. ATOM splits input documents into minimal, self-contained\n\"atomic\" facts, improving extraction exhaustivity and stability. Then, it\nconstructs atomic TKGs from these facts while employing a dual-time modeling\nthat distinguishes when information is observed from when it is valid. The\nresulting atomic TKGs are subsequently merged in parallel. Empirical\nevaluations demonstrate that ATOM achieves ~18% higher exhaustivity, ~17%\nbetter stability, and over 90% latency reduction compared to baseline methods,\ndemonstrating a strong scalability potential for dynamic TKG construction.",
    "categories": [
      "cs.AI",
      "cs.CL",
      "cs.IR"
    ],
    "published": "2025-10-26T09:10:26Z",
    "authors": [
      "Yassir Lairgi",
      "Ludovic Moncla",
      "Khalid Benabdeslem",
      "R\u00e9my Cazabet",
      "Pierre Cl\u00e9au"
    ],
    "pdf_url": "http://arxiv.org/pdf/2510.22590v1"
  },
  {
    "id": "2510.25775v1",
    "title": "Towards Piece-by-Piece Explanations for Chess Positions with SHAP",
    "abstract": "Contemporary chess engines offer precise yet opaque evaluations, typically\nexpressed as centipawn scores. While effective for decision-making, these\noutputs obscure the underlying contributions of individual pieces or patterns.\nIn this paper, we explore adapting SHAP (SHapley Additive exPlanations) to the\ndomain of chess analysis, aiming to attribute a chess engines evaluation to\nspecific pieces on the board. By treating pieces as features and systematically\nablating them, we compute additive, per-piece contributions that explain the\nengines output in a locally faithful and human-interpretable manner. This\nmethod draws inspiration from classical chess pedagogy, where players assess\npositions by mentally removing pieces, and grounds it in modern explainable AI\ntechniques. Our approach opens new possibilities for visualization, human\ntraining, and engine comparison. We release accompanying code and data to\nfoster future research in interpretable chess AI.",
    "categories": [
      "cs.AI",
      "cs.LG"
    ],
    "published": "2025-10-26T09:07:21Z",
    "authors": [
      "Francesco Spinnato"
    ],
    "pdf_url": "http://arxiv.org/pdf/2510.25775v1"
  },
  {
    "id": "2510.22572v1",
    "title": "Combining Deep Learning and Explainable AI for Toxicity Prediction of\n  Chemical Compounds",
    "abstract": "The task here is to predict the toxicological activity of chemical compounds\nbased on the Tox21 dataset, a benchmark in computational toxicology.\n  After a domain-specific overview of chemical toxicity, we discuss current\ncomputational strategies, focusing on machine learning and deep learning.\nSeveral architectures are compared in terms of performance, robustness, and\ninterpretability.\n  This research introduces a novel image-based pipeline based on DenseNet121,\nwhich processes 2D graphical representations of chemical structures.\nAdditionally, we employ Grad-CAM visualizations, an explainable AI technique,\nto interpret the model's predictions and highlight molecular regions\ncontributing to toxicity classification. The proposed architecture achieves\ncompetitive results compared to traditional models, demonstrating the potential\nof deep convolutional networks in cheminformatics. Our findings emphasize the\nvalue of combining image-based representations with explainable AI methods to\nimprove both predictive accuracy and model transparency in toxicology.",
    "categories": [
      "cs.LG",
      "cs.AI"
    ],
    "published": "2025-10-26T08:05:11Z",
    "authors": [
      "Eduard Popescu",
      "Adrian Groza",
      "Andreea Cernat"
    ],
    "pdf_url": "http://arxiv.org/pdf/2510.22572v1"
  },
  {
    "id": "2510.22571v1",
    "title": "STATUS Bench: A Rigorous Benchmark for Evaluating Object State\n  Understanding in Vision-Language Models",
    "abstract": "Object state recognition aims to identify the specific condition of objects,\nsuch as their positional states (e.g., open or closed) and functional states\n(e.g., on or off). While recent Vision-Language Models (VLMs) are capable of\nperforming a variety of multimodal tasks, it remains unclear how precisely they\ncan identify object states. To alleviate this issue, we introduce the STAte and\nTransition UnderStanding Benchmark (STATUS Bench), the first benchmark for\nrigorously evaluating the ability of VLMs to understand subtle variations in\nobject states in diverse situations. Specifically, STATUS Bench introduces a\nnovel evaluation scheme that requires VLMs to perform three tasks\nsimultaneously: object state identification (OSI), image retrieval (IR), and\nstate change identification (SCI). These tasks are defined over our fully\nhand-crafted dataset involving image pairs, their corresponding object state\ndescriptions and state change descriptions. Furthermore, we introduce a\nlarge-scale training dataset, namely STATUS Train, which consists of 13 million\nsemi-automatically created descriptions. This dataset serves as the largest\nresource to facilitate further research in this area. In our experiments, we\ndemonstrate that STATUS Bench enables rigorous consistency evaluation and\nreveal that current state-of-the-art VLMs still significantly struggle to\ncapture subtle object state distinctions. Surprisingly, under the proposed\nrigorous evaluation scheme, most open-weight VLMs exhibited chance-level\nzero-shot performance. After fine-tuning on STATUS Train, Qwen2.5-VL achieved\nperformance comparable to Gemini 2.0 Flash. These findings underscore the\nnecessity of STATUS Bench and Train for advancing object state recognition in\nVLM research.",
    "categories": [
      "cs.CV",
      "cs.AI",
      "cs.MM"
    ],
    "published": "2025-10-26T08:04:28Z",
    "authors": [
      "Mahiro Ukai",
      "Shuhei Kurita",
      "Nakamasa Inoue"
    ],
    "pdf_url": "http://arxiv.org/pdf/2510.22571v1"
  },
  {
    "id": "2510.22570v1",
    "title": "Curriculum-Based Iterative Self-Play for Scalable Multi-Drone Racing",
    "abstract": "The coordination of multiple autonomous agents in high-speed, competitive\nenvironments represents a significant engineering challenge. This paper\npresents CRUISE (Curriculum-Based Iterative Self-Play for Scalable Multi-Drone\nRacing), a reinforcement learning framework designed to solve this challenge in\nthe demanding domain of multi-drone racing. CRUISE overcomes key scalability\nlimitations by synergistically combining a progressive difficulty curriculum\nwith an efficient self-play mechanism to foster robust competitive behaviors.\nValidated in high-fidelity simulation with realistic quadrotor dynamics, the\nresulting policies significantly outperform both a standard reinforcement\nlearning baseline and a state-of-the-art game-theoretic planner. CRUISE\nachieves nearly double the planner's mean racing speed, maintains high success\nrates, and demonstrates robust scalability as agent density increases. Ablation\nstudies confirm that the curriculum structure is the critical component for\nthis performance leap. By providing a scalable and effective training\nmethodology, CRUISE advances the development of autonomous systems for dynamic,\ncompetitive tasks and serves as a blueprint for future real-world deployment.",
    "categories": [
      "cs.RO",
      "cs.AI",
      "cs.MA",
      "cs.SY",
      "eess.SY",
      "I.2.9; I.2.11; I.2.6"
    ],
    "published": "2025-10-26T08:03:06Z",
    "authors": [
      "Onur Akg\u00fcn"
    ],
    "pdf_url": "http://arxiv.org/pdf/2510.22570v1"
  },
  {
    "id": "2510.23660v1",
    "title": "Quanvolutional Neural Networks for Pneumonia Detection: An Efficient\n  Quantum-Assisted Feature Extraction Paradigm",
    "abstract": "Pneumonia poses a significant global health challenge, demanding accurate and\ntimely diagnosis. While deep learning, particularly Convolutional Neural\nNetworks (CNNs), has shown promise in medical image analysis for pneumonia\ndetection, CNNs often suffer from high computational costs, limitations in\nfeature representation, and challenges in generalizing from smaller datasets.\nTo address these limitations, we explore the application of Quanvolutional\nNeural Networks (QNNs), leveraging quantum computing for enhanced feature\nextraction. This paper introduces a novel hybrid quantum-classical model for\npneumonia detection using the PneumoniaMNIST dataset. Our approach utilizes a\nquanvolutional layer with a parameterized quantum circuit (PQC) to process 2x2\nimage patches, employing rotational Y-gates for data encoding and entangling\nlayers to generate non-classical feature representations. These\nquantum-extracted features are then fed into a classical neural network for\nclassification. Experimental results demonstrate that the proposed QNN achieves\na higher validation accuracy of 83.33 percent compared to a comparable\nclassical CNN which achieves 73.33 percent. This enhanced convergence and\nsample efficiency highlight the potential of QNNs for medical image analysis,\nparticularly in scenarios with limited labeled data. This research lays the\nfoundation for integrating quantum computing into deep-learning-driven medical\ndiagnostic systems, offering a computationally efficient alternative to\ntraditional approaches.",
    "categories": [
      "cs.LG",
      "cs.AI",
      "cs.CV"
    ],
    "published": "2025-10-26T08:01:34Z",
    "authors": [
      "Gazi Tanbhir",
      "Md. Farhan Shahriyar",
      "Abdullah Md Raihan Chy"
    ],
    "pdf_url": "http://arxiv.org/pdf/2510.23660v1"
  },
  {
    "id": "2510.22568v1",
    "title": "SPIRAL: Self-Play Incremental Racing Algorithm for Learning in\n  Multi-Drone Competitions",
    "abstract": "This paper introduces SPIRAL (Self-Play Incremental Racing Algorithm for\nLearning), a novel approach for training autonomous drones in multi-agent\nracing competitions. SPIRAL distinctively employs a self-play mechanism to\nincrementally cultivate complex racing behaviors within a challenging, dynamic\nenvironment. Through this self-play core, drones continuously compete against\nincreasingly proficient versions of themselves, naturally escalating the\ndifficulty of competitive interactions. This progressive learning journey\nguides agents from mastering fundamental flight control to executing\nsophisticated cooperative multi-drone racing strategies. Our method is designed\nfor versatility, allowing integration with any state-of-the-art Deep\nReinforcement Learning (DRL) algorithms within its self-play framework.\nSimulations demonstrate the significant advantages of SPIRAL and benchmark the\nperformance of various DRL algorithms operating within it. Consequently, we\ncontribute a versatile, scalable, and self-improving learning framework to the\nfield of autonomous drone racing. SPIRAL's capacity to autonomously generate\nappropriate and escalating challenges through its self-play dynamic offers a\npromising direction for developing robust and adaptive racing strategies in\nmulti-agent environments. This research opens new avenues for enhancing the\nperformance and reliability of autonomous racing drones in increasingly complex\nand competitive scenarios.",
    "categories": [
      "cs.RO",
      "cs.AI",
      "cs.MA",
      "cs.SY",
      "eess.SY",
      "I.2.9; I.2.11; I.2.6"
    ],
    "published": "2025-10-26T07:59:44Z",
    "authors": [
      "Onur Akg\u00fcn"
    ],
    "pdf_url": "http://arxiv.org/pdf/2510.22568v1"
  },
  {
    "id": "2510.22561v1",
    "title": "Blockchain Signatures to Ensure Information Integrity and\n  Non-Repudiation in the Digital Era: A comprehensive study",
    "abstract": "Blockchain systems rely on decentralized ledgers and strong security\nguarantees. A key requirement is non-repudiation, which prevents denial of\ntransaction authorship and supports integrity of recorded data. This work\nsurveys digital signature schemes used in blockchain platforms and analyzes how\nthey deliver non-repudiation and contribute to overall system security. We\nexamine representative scheme families and their cryptographic foundations,\nsecurity assumptions, and properties relevant to deployment, including\nunforgeability, resistance to malleability, support for aggregation and\nmultisignature or threshold settings, key and signature sizes, and verification\ncost. Using these criteria, we compare the suitability of different designs for\nconsensus protocols, smart contract constraints, and resource limits. We\nhighlight practical tradeoffs that affect throughput, storage, scalability, and\nattack surfaces, and summarize benefits and limitations of each scheme in\nblockchain contexts. The study underscores that carefully chosen digital\nsignatures are central to achieving non-repudiation and preserving information\nintegrity, and it outlines implementation considerations and open directions\nsuch as interoperability and post-quantum readiness.",
    "categories": [
      "cs.CR",
      "cs.AI"
    ],
    "published": "2025-10-26T07:39:55Z",
    "authors": [
      "Kaveri Banerjee",
      "Sajal Saha"
    ],
    "pdf_url": "http://arxiv.org/pdf/2510.22561v1"
  },
  {
    "id": "2510.22553v1",
    "title": "DDTR: Diffusion Denoising Trace Recovery",
    "abstract": "With recent technological advances, process logs, which were traditionally\ndeterministic in nature, are being captured from non-deterministic sources,\nsuch as uncertain sensors or machine learning models (that predict activities\nusing cameras). In the presence of stochastically-known logs, logs that contain\nprobabilistic information, the need for stochastic trace recovery increases, to\noffer reliable means of understanding the processes that govern such systems.\nWe design a novel deep learning approach for stochastic trace recovery, based\non Diffusion Denoising Probabilistic Models (DDPM), which makes use of process\nknowledge (either implicitly by discovering a model or explicitly by injecting\nprocess knowledge in the training phase) to recover traces by denoising. We\nconduct an empirical evaluation demonstrating state-of-the-art performance with\nup to a 25% improvement over existing methods, along with increased robustness\nunder high noise levels.",
    "categories": [
      "cs.LG",
      "cs.AI"
    ],
    "published": "2025-10-26T06:43:53Z",
    "authors": [
      "Maximilian Matyash",
      "Avigdor Gal",
      "Arik Senderovich"
    ],
    "pdf_url": "http://arxiv.org/pdf/2510.22553v1"
  },
  {
    "id": "2510.22548v1",
    "title": "LooGLE v2: Are LLMs Ready for Real World Long Dependency Challenges?",
    "abstract": "Large language models (LLMs) are equipped with increasingly extended context\nwindows recently, yet their long context understanding capabilities over long\ndependency tasks remain fundamentally limited and underexplored. This gap is\nespecially significant in many real-world long-context applications that were\nrarely benchmarked. In this paper, we introduce LooGLE v2, a novel benchmark\ndesigned to evaluate LLMs' long context ability in real-world applications and\nscenarios. Our benchmark consists of automatically collected real-world long\ntexts, ranging from 16k to 2M tokens, encompassing domains in law, finance,\ngame and code. Accordingly, we delicately design 10 types of domain-specific\nlong-dependency tasks and generate 1,934 QA instances with various diversity\nand complexity in a scalable data curation pipeline for further practical\nneeds. We conduct a comprehensive assessment of 6 locally deployed and 4\nAPI-based LLMs. The evaluation results show that even the best-performing model\nachieves only a 59.2% overall score on our benchmark. Despite the extensive\ncontext windows, popular LLMs are only capable of understanding a much shorter\nlength of context than they claim to be, revealing significant limitations in\ntheir ability to handle real-world tasks with long dependencies and\nhighlighting substantial room for model improvement in practical long-context\nunderstanding.",
    "categories": [
      "cs.CL",
      "cs.AI"
    ],
    "published": "2025-10-26T06:14:19Z",
    "authors": [
      "Ziyuan He",
      "Yuxuan Wang",
      "Jiaqi Li",
      "Kexin Liang",
      "Muhan Zhang"
    ],
    "pdf_url": "http://arxiv.org/pdf/2510.22548v1"
  },
  {
    "id": "2510.22535v1",
    "title": "OFFSIDE: Benchmarking Unlearning Misinformation in Multimodal Large\n  Language Models",
    "abstract": "Advances in Multimodal Large Language Models (MLLMs) intensify concerns about\ndata privacy, making Machine Unlearning (MU), the selective removal of learned\ninformation, a critical necessity. However, existing MU benchmarks for MLLMs\nare limited by a lack of image diversity, potential inaccuracies, and\ninsufficient evaluation scenarios, which fail to capture the complexity of\nreal-world applications. To facilitate the development of MLLMs unlearning and\nalleviate the aforementioned limitations, we introduce OFFSIDE, a novel\nbenchmark for evaluating misinformation unlearning in MLLMs based on football\ntransfer rumors. This manually curated dataset contains 15.68K records for 80\nplayers, providing a comprehensive framework with four test sets to assess\nforgetting efficacy, generalization, utility, and robustness. OFFSIDE supports\nadvanced settings like selective unlearning and corrective relearning, and\ncrucially, unimodal unlearning (forgetting only text data). Our extensive\nevaluation of multiple baselines reveals key findings: (1) Unimodal methods\n(erasing text-based knowledge) fail on multimodal rumors; (2) Unlearning\nefficacy is largely driven by catastrophic forgetting; (3) All methods struggle\nwith \"visual rumors\" (rumors appear in the image); (4) The unlearned rumors can\nbe easily recovered and (5) All methods are vulnerable to prompt attacks. These\nresults expose significant vulnerabilities in current approaches, highlighting\nthe need for more robust multimodal unlearning solutions. The code is available\nat\n\\href{https://github.com/zh121800/OFFSIDE}{https://github.com/zh121800/OFFSIDE}.",
    "categories": [
      "cs.AI",
      "cs.CL"
    ],
    "published": "2025-10-26T05:05:30Z",
    "authors": [
      "Hao Zheng",
      "Zirui Pang",
      "Ling li",
      "Zhijie Deng",
      "Yuhan Pu",
      "Zhaowei Zhu",
      "Xiaobo Xia",
      "Jiaheng Wei"
    ],
    "pdf_url": "http://arxiv.org/pdf/2510.22535v1"
  },
  {
    "id": "2510.22531v1",
    "title": "Text to Trust: Evaluating Fine-Tuning and LoRA Trade-offs in Language\n  Models for Unfair Terms of Service Detection",
    "abstract": "Large Language Models (LLMs) have transformed text understanding, yet their\nadaptation to specialized legal domains remains constrained by the cost of full\nfine-tuning. This study provides a systematic evaluation of fine tuning,\nparameter efficient adaptation (LoRA, QLoRA), and zero-shot prompting\nstrategies for unfair clause detection in Terms of Service (ToS) documents, a\nkey application in legal NLP. We finetune BERT and DistilBERT, apply 4-bit\nLow-Rank Adaptation (LoRA) to models such as TinyLlama, LLaMA 3B/7B, and\nSaulLM, and evaluate GPT-4o and O-versions in zero-shot settings. Experiments\non the CLAUDETTE-ToS benchmark and the Multilingual Scraper Corpus show that\nfull fine-tuning achieves the strongest precision recall balance, while\nLoRA-based models provide competitive recall with up to 3x lower memory cost.\nThese findings highlight practical design trade-offs for efficient and\ndomain-adapted LLMs, contributing open baselines for fine-tuning research in\nlegal text processing.",
    "categories": [
      "cs.CL",
      "cs.AI",
      "cs.LG"
    ],
    "published": "2025-10-26T04:46:06Z",
    "authors": [
      "Noshitha Padma Pratyusha Juttu",
      "Sahithi Singireddy",
      "Sravani Gona",
      "Sujal Timilsina"
    ],
    "pdf_url": "http://arxiv.org/pdf/2510.22531v1"
  },
  {
    "id": "2510.22521v1",
    "title": "Open Multimodal Retrieval-Augmented Factual Image Generation",
    "abstract": "Large Multimodal Models (LMMs) have achieved remarkable progress in\ngenerating photorealistic and prompt-aligned images, but they often produce\noutputs that contradict verifiable knowledge, especially when prompts involve\nfine-grained attributes or time-sensitive events. Conventional\nretrieval-augmented approaches attempt to address this issue by introducing\nexternal information, yet they are fundamentally incapable of grounding\ngeneration in accurate and evolving knowledge due to their reliance on static\nsources and shallow evidence integration. To bridge this gap, we introduce\nORIG, an agentic open multimodal retrieval-augmented framework for Factual\nImage Generation (FIG), a new task that requires both visual realism and\nfactual grounding. ORIG iteratively retrieves and filters multimodal evidence\nfrom the web and incrementally integrates the refined knowledge into enriched\nprompts to guide generation. To support systematic evaluation, we build\nFIG-Eval, a benchmark spanning ten categories across perceptual, compositional,\nand temporal dimensions. Experiments demonstrate that ORIG substantially\nimproves factual consistency and overall image quality over strong baselines,\nhighlighting the potential of open multimodal retrieval for factual image\ngeneration.",
    "categories": [
      "cs.CV",
      "cs.AI",
      "cs.IR",
      "cs.LG"
    ],
    "published": "2025-10-26T04:13:31Z",
    "authors": [
      "Yang Tian",
      "Fan Liu",
      "Jingyuan Zhang",
      "Wei Bi",
      "Yupeng Hu",
      "Liqiang Nie"
    ],
    "pdf_url": "http://arxiv.org/pdf/2510.22521v1"
  },
  {
    "id": "2510.22513v1",
    "title": "Toward Robust Signed Graph Learning through Joint Input-Target Denoising",
    "abstract": "Signed Graph Neural Networks (SGNNs) are widely adopted to analyze complex\npatterns in signed graphs with both positive and negative links. Given the\nnoisy nature of real-world connections, the robustness of SGNN has also emerged\nas a pivotal research area. Under the supervision of empirical properties,\ngraph structure learning has shown its robustness on signed graph\nrepresentation learning, however, there remains a paucity of research\ninvestigating a robust SGNN with theoretical guidance. Inspired by the success\nof graph information bottleneck (GIB) in information extraction, we propose\nRIDGE, a novel framework for Robust sI gned graph learning through joint\nDenoising of Graph inputs and supervision targEts. Different from the basic\nGIB, we extend the GIB theory with the capability of target space denoising as\nthe co-existence of noise in both input and target spaces. In instantiation,\nRIDGE effectively cleanses input data and supervision targets via a tractable\nobjective function produced by reparameterization mechanism and variational\napproximation. We extensively validate our method on four prevalent signed\ngraph datasets, and the results show that RIDGE clearly improves the robustness\nof popular SGNN models under various levels of noise.",
    "categories": [
      "cs.LG",
      "cs.AI"
    ],
    "published": "2025-10-26T03:34:40Z",
    "authors": [
      "Junran Wu",
      "Beng Chin Ooi",
      "Ke Xu"
    ],
    "pdf_url": "http://arxiv.org/pdf/2510.22513v1"
  },
  {
    "id": "2510.22512v1",
    "title": "Transitive RL: Value Learning via Divide and Conquer",
    "abstract": "In this work, we present Transitive Reinforcement Learning (TRL), a new value\nlearning algorithm based on a divide-and-conquer paradigm. TRL is designed for\noffline goal-conditioned reinforcement learning (GCRL) problems, where the aim\nis to find a policy that can reach any state from any other state in the\nsmallest number of steps. TRL converts a triangle inequality structure present\nin GCRL into a practical divide-and-conquer value update rule. This has several\nadvantages compared to alternative value learning paradigms. Compared to\ntemporal difference (TD) methods, TRL suffers less from bias accumulation, as\nin principle it only requires $O(\\log T)$ recursions (as opposed to $O(T)$ in\nTD learning) to handle a length-$T$ trajectory. Unlike Monte Carlo methods, TRL\nsuffers less from high variance as it performs dynamic programming.\nExperimentally, we show that TRL achieves the best performance in highly\nchallenging, long-horizon benchmark tasks compared to previous offline GCRL\nalgorithms.",
    "categories": [
      "cs.LG",
      "cs.AI"
    ],
    "published": "2025-10-26T03:32:31Z",
    "authors": [
      "Seohong Park",
      "Aditya Oberai",
      "Pranav Atreya",
      "Sergey Levine"
    ],
    "pdf_url": "http://arxiv.org/pdf/2510.22512v1"
  },
  {
    "id": "2510.22507v1",
    "title": "GateFuseNet: An Adaptive 3D Multimodal Neuroimaging Fusion Network for\n  Parkinson's Disease Diagnosis",
    "abstract": "Accurate diagnosis of Parkinson's disease (PD) from MRI remains challenging\ndue to symptom variability and pathological heterogeneity. Most existing\nmethods rely on conventional magnitude-based MRI modalities, such as\nT1-weighted images (T1w), which are less sensitive to PD pathology than\nQuantitative Susceptibility Mapping (QSM), a phase-based MRI technique that\nquantifies iron deposition in deep gray matter nuclei. In this study, we\npropose GateFuseNet, an adaptive 3D multimodal fusion network that integrates\nQSM and T1w images for PD diagnosis. The core innovation lies in a gated fusion\nmodule that learns modality-specific attention weights and channel-wise gating\nvectors for selective feature modulation. This hierarchical gating mechanism\nenhances ROI-aware features while suppressing irrelevant signals. Experimental\nresults show that our method outperforms three existing state-of-the-art\napproaches, achieving 85.00% accuracy and 92.06% AUC. Ablation studies further\nvalidate the contributions of ROI guidance, multimodal integration, and fusion\npositioning. Grad-CAM visualizations confirm the model's focus on clinically\nrelevant pathological regions. The source codes and pretrained models can be\nfound at https://github.com/YangGaoUQ/GateFuseNet",
    "categories": [
      "cs.CV",
      "cs.AI"
    ],
    "published": "2025-10-26T03:11:26Z",
    "authors": [
      "Rui Jin",
      "Chen Chen",
      "Yin Liu",
      "Hongfu Sun",
      "Min Zeng",
      "Min Li",
      "Yang Gao"
    ],
    "pdf_url": "http://arxiv.org/pdf/2510.22507v1"
  },
  {
    "id": "2510.23658v1",
    "title": "Aligning Diffusion Language Models via Unpaired Preference Optimization",
    "abstract": "Diffusion language models (dLLMs) are an emerging alternative to\nautoregressive (AR) generators, but aligning them to human preferences is\nchallenging because sequence log-likelihoods are intractable and pairwise\npreference data are costly to collect. We introduce ELBO-KTO, which combines an\nELBO surrogate for diffusion log-likelihoods with a prospect-theoretic,\nunpaired preference objective (Kahneman Tversky Optimization, KTO). We analyze\nthe bias and variance induced by the ELBO substitution and employ\nvariance-reduction practices that stabilize gradients during training. Applied\nto LLaDA-8B-Instruct, ELBO-KTO yields \\textbf{65.9\\%} and \\textbf{62.3\\%}\nadjusted win rates on kto-mix-14k and UltraFeedback-Binary, respectively,\nversus the base model under an automatic LLM judge. Across downstream tasks,\nincluding GSM8K, MMLU, and additional reasoning/knowledge benchmarks, ELBO-KTO\ntrained on UltraFeedback-Binary performs on par with or better than the base\nmodel under identical decoding. This establishes unpaired preference\noptimization as a viable alternative to pairwise alignment in diffusion LLMs.",
    "categories": [
      "cs.LG",
      "cs.AI"
    ],
    "published": "2025-10-26T03:02:39Z",
    "authors": [
      "Vaibhav Jindal",
      "Hejian Sang",
      "Chun-Mao Lai",
      "Yanning Chen",
      "Zhipeng Wang"
    ],
    "pdf_url": "http://arxiv.org/pdf/2510.23658v1"
  },
  {
    "id": "2510.22503v1",
    "title": "Accelerating Materials Design via LLM-Guided Evolutionary Search",
    "abstract": "Materials discovery requires navigating vast chemical and structural spaces\nwhile satisfying multiple, often conflicting, objectives. We present LLM-guided\nEvolution for MAterials design (LLEMA), a unified framework that couples the\nscientific knowledge embedded in large language models with chemistry-informed\nevolutionary rules and memory-based refinement. At each iteration, an LLM\nproposes crystallographically specified candidates under explicit property\nconstraints; a surrogate-augmented oracle estimates physicochemical properties;\nand a multi-objective scorer updates success/failure memories to guide\nsubsequent generations. Evaluated on 14 realistic tasks spanning electronics,\nenergy, coatings, optics, and aerospace, LLEMA discovers candidates that are\nchemically plausible, thermodynamically stable, and property-aligned, achieving\nhigher hit-rates and stronger Pareto fronts than generative and LLM-only\nbaselines. Ablation studies confirm the importance of rule-guided generation,\nmemory-based refinement, and surrogate prediction. By enforcing\nsynthesizability and multi-objective trade-offs, LLEMA delivers a principled\npathway to accelerate practical materials discovery.\n  Code: https://github.com/scientific-discovery/LLEMA",
    "categories": [
      "cs.LG",
      "cond-mat.mtrl-sci",
      "cs.AI",
      "cs.NE"
    ],
    "published": "2025-10-26T02:47:15Z",
    "authors": [
      "Nikhil Abhyankar",
      "Sanchit Kabra",
      "Saaketh Desai",
      "Chandan K. Reddy"
    ],
    "pdf_url": "http://arxiv.org/pdf/2510.22503v1"
  },
  {
    "id": "2510.22500v1",
    "title": "Scalable Oversight via Partitioned Human Supervision",
    "abstract": "As artificial intelligence (AI) systems approach and surpass expert human\nperformance across a broad range of tasks, obtaining high-quality human\nsupervision for evaluation and training becomes increasingly challenging. Our\nfocus is on tasks that require deep knowledge and skills of multiple domains.\nUnfortunately, even the best human experts are knowledgeable only in a single\nnarrow area, and will not be able to evaluate the correctness of advanced AI\nsystems on such superhuman tasks. However, based on their narrow expertise,\nhumans may provide a weak signal, i.e., a complementary label indicating an\noption that is incorrect. For example, a cardiologist could state that \"this is\nnot related to cardiology,'' even if they cannot identify the true disease.\nBased on this weak signal, we propose a scalable oversight framework that\nenables us to evaluate frontier AI systems without the need to prepare the\nground truth. We derive an unbiased estimator of top-1 accuracy from\ncomplementary labels and quantify how many complementary labels are needed to\nmatch the variance of ordinary labels. We further introduce two estimators to\ncombine scarce ordinary labels with abundant complementary labels. We provide\nfinite-sample deviation guarantees for both complementary-only and the mixed\nestimators. Empirically, we show that we can evaluate the output of large\nlanguage models without the ground truth, if we have complementary labels. We\nfurther show that we can train an AI system with such weak signals: we show how\nwe can design an agentic AI system automatically that can perform better with\nthis partitioned human supervision. Our code is available at\nhttps://github.com/R-Yin-217/Scalable-Oversight-via-Human-Partitioned-Supervision.",
    "categories": [
      "cs.LG",
      "cs.AI",
      "cs.CL"
    ],
    "published": "2025-10-26T02:42:03Z",
    "authors": [
      "Ren Yin",
      "Takashi Ishida",
      "Masashi Sugiyama"
    ],
    "pdf_url": "http://arxiv.org/pdf/2510.22500v1"
  },
  {
    "id": "2510.22481v1",
    "title": "An Analytic Theory of Quantum Imaginary Time Evolution",
    "abstract": "Quantum imaginary time evolution (QITE) algorithm is one of the most\npromising variational quantum algorithms (VQAs), bridging the current era of\nNoisy Intermediate-Scale Quantum devices and the future of fully fault-tolerant\nquantum computing. Although practical demonstrations of QITE and its potential\nadvantages over the general VQA trained with vanilla gradient descent (GD) in\ncertain tasks have been reported, a first-principle, theoretical understanding\nof QITE remains limited. Here, we aim to develop an analytic theory for the\ndynamics of QITE. First, we show that QITE can be interpreted as a form of a\ngeneral VQA trained with Quantum Natural Gradient Descent (QNGD), where the\ninverse quantum Fisher information matrix serves as the learning-rate tensor.\nThis equivalence is established not only at the level of gradient update rules,\nbut also through the action principle: the variational principle can be\ndirectly connected to the geometric geodesic distance in the quantum Fisher\ninformation metric, up to an integration constant. Second, for wide quantum\nneural networks, we employ the quantum neural tangent kernel framework to\nconstruct an analytic model for QITE. We prove that QITE always converges\nfaster than GD-based VQA, though this advantage is suppressed by the\nexponential growth of Hilbert space dimension. This helps explain certain\nexperimental results in quantum computational chemistry. Our theory encompasses\nlinear, quadratic, and more general loss functions. We validate the analytic\nresults through numerical simulations. Our findings establish a theoretical\nfoundation for QITE dynamics and provide analytic insights for the\nfirst-principle design of variational quantum algorithms.",
    "categories": [
      "quant-ph",
      "cs.AI",
      "cs.LG",
      "stat.ML"
    ],
    "published": "2025-10-26T01:43:55Z",
    "authors": [
      "Min Chen",
      "Bingzhi Zhang",
      "Quntao Zhuang",
      "Junyu Liu"
    ],
    "pdf_url": "http://arxiv.org/pdf/2510.22481v1"
  },
  {
    "id": "2510.22480v1",
    "title": "Single-Teacher View Augmentation: Boosting Knowledge Distillation via\n  Angular Diversity",
    "abstract": "Knowledge Distillation (KD) aims to train a lightweight student model by\ntransferring knowledge from a large, high-capacity teacher. Recent studies have\nshown that leveraging diverse teacher perspectives can significantly improve\ndistillation performance; however, achieving such diversity typically requires\nmultiple teacher networks, leading to high computational costs. In this work,\nwe propose a novel cost-efficient knowledge augmentation method for KD that\ngenerates diverse multi-views by attaching multiple branches to a single\nteacher. To ensure meaningful semantic variation across multi-views, we\nintroduce two angular diversity objectives: 1) constrained inter-angle\ndiversify loss, which maximizes angles between augmented views while preserving\nproximity to the original teacher output, and 2) intra-angle diversify loss,\nwhich encourages an even distribution of views around the original output. The\nensembled knowledge from these angularly diverse views, along with the original\nteacher, is distilled into the student. We further theoretically demonstrate\nthat our objectives increase the diversity among ensemble members and thereby\nreduce the upper bound of the ensemble's expected loss, leading to more\neffective distillation. Experimental results show that our method surpasses an\nexisting knowledge augmentation method across diverse configurations. Moreover,\nthe proposed method is compatible with other KD frameworks in a plug-and-play\nfashion, providing consistent improvements in generalization performance.",
    "categories": [
      "cs.CV",
      "cs.AI"
    ],
    "published": "2025-10-26T01:41:08Z",
    "authors": [
      "Seonghoon Yu",
      "Dongjun Nam",
      "Dina Katabi",
      "Jeany Son"
    ],
    "pdf_url": "http://arxiv.org/pdf/2510.22480v1"
  },
  {
    "id": "2510.22477v1",
    "title": "Agent-GSPO: Communication-Efficient Multi-Agent Systems via Group\n  Sequence Policy Optimization",
    "abstract": "To combat the prohibitive communication costs of ``free-for-all\" multi-agent\nsystems (MAS), we introduce \\textbf{Agent-GSPO}, a framework that directly\noptimizes for token economy using sequence-level reinforcement learning.\nAgent-GSPO leverages the stable and memory-efficient Group Sequence Policy\nOptimization (GSPO) algorithm to train agents on a communication-aware reward\nthat explicitly penalizes verbosity. Across seven reasoning benchmarks,\nAgent-GSPO not only achieves new state-of-the-art performance but does so with\na fraction of the token consumption of existing methods. By fostering emergent\nstrategies like ``strategic silence,\" our approach provides a practical\nblueprint for developing scalable and economically viable multi-agent systems.",
    "categories": [
      "cs.MA",
      "cs.AI"
    ],
    "published": "2025-10-26T01:27:13Z",
    "authors": [
      "Yijia Fan",
      "Jusheng Zhang",
      "Jing Yang",
      "Keze Wang"
    ],
    "pdf_url": "http://arxiv.org/pdf/2510.22477v1"
  },
  {
    "id": "2510.22475v1",
    "title": "CHOIR: Collaborative Harmonization fOr Inference Robustness",
    "abstract": "Persona-assigned Large Language Models (LLMs) can adopt diverse roles,\nenabling personalized and context-aware reasoning. However, even minor\ndemographic perturbations in personas, such as simple pronoun changes, can\nalter reasoning trajectories, leading to divergent sets of correct answers.\nInstead of treating these variations as biases to be mitigated, we explore\ntheir potential as a constructive resource to improve reasoning robustness. We\npropose CHOIR (Collaborative Harmonization fOr Inference Robustness), a\ntest-time framework that harmonizes multiple persona-conditioned reasoning\nsignals into a unified prediction. CHOIR orchestrates a collaborative decoding\nprocess among counterfactual personas, dynamically balancing agreement and\ndivergence in their reasoning paths. Experiments on various reasoning\nbenchmarks demonstrate that CHOIR consistently enhances performance across\ndemographics, model architectures, scales, and tasks - without additional\ntraining. Improvements reach up to 26.4% for individual demographic groups and\n19.2% on average across five demographics. It remains effective even when base\npersonas are suboptimal. By reframing persona variation as a constructive\nsignal, CHOIR provides a scalable and generalizable approach to more reliable\nLLM reasoning.",
    "categories": [
      "cs.CL",
      "cs.AI"
    ],
    "published": "2025-10-26T01:20:24Z",
    "authors": [
      "Xiangjue Dong",
      "Cong Wang",
      "Maria Teleki",
      "Millennium Bismay",
      "James Caverlee"
    ],
    "pdf_url": "http://arxiv.org/pdf/2510.22475v1"
  },
  {
    "id": "2510.22473v1",
    "title": "DynaPose4D: High-Quality 4D Dynamic Content Generation via Pose\n  Alignment Loss",
    "abstract": "Recent advancements in 2D and 3D generative models have expanded the\ncapabilities of computer vision. However, generating high-quality 4D dynamic\ncontent from a single static image remains a significant challenge. Traditional\nmethods have limitations in modeling temporal dependencies and accurately\ncapturing dynamic geometry changes, especially when considering variations in\ncamera perspective. To address this issue, we propose DynaPose4D, an innovative\nsolution that integrates 4D Gaussian Splatting (4DGS) techniques with\nCategory-Agnostic Pose Estimation (CAPE) technology. This framework uses 3D\nGaussian Splatting to construct a 3D model from single images, then predicts\nmulti-view pose keypoints based on one-shot support from a chosen view,\nleveraging supervisory signals to enhance motion consistency. Experimental\nresults show that DynaPose4D achieves excellent coherence, consistency, and\nfluidity in dynamic motion generation. These findings not only validate the\nefficacy of the DynaPose4D framework but also indicate its potential\napplications in the domains of computer vision and animation production.",
    "categories": [
      "cs.CV",
      "cs.AI"
    ],
    "published": "2025-10-26T01:11:13Z",
    "authors": [
      "Jing Yang",
      "Yufeng Yang"
    ],
    "pdf_url": "http://arxiv.org/pdf/2510.22473v1"
  },
  {
    "id": "2510.22467v1",
    "title": "Backward-Friendly Optimization: Training Large Language Models with\n  Approximate Gradients under Memory Constraints",
    "abstract": "Full fine-tuning of Large Language Models (LLMs) is notoriously\nmemory-intensive, primarily because conventional optimizers such as SGD or Adam\nassume access to exact gradients derived from cached activations. Existing\nsolutions either alter the model architecture (e.g., reversible networks) or\ntrade memory for computation (e.g., activation checkpointing), but the\noptimizer itself remains untouched. In this work, we introduce GradLite, a\nbackward-friendly optimizer that relaxes the requirement of exact gradients,\nenabling efficient training even when intermediate activations are aggressively\ndiscarded or approximated. GradLite leverages two key techniques: (i) low-rank\nJacobian approximation, which reduces the dimensionality of backpropagated\nerror signals, and (ii) error-feedback correction, which accumulates and\ncompensates approximation errors across iterations to preserve convergence\nguarantees. We provide a theoretical analysis showing that GradLite maintains\nunbiased gradient estimates with bounded variance, ensuring convergence rates\ncomparable to Adam. Empirically, GradLite reduces optimizer-state and\nactivation memory consumption by up to 50\\% without architectural changes, and\nachieves on-par or superior downstream performance on reasoning (MMLU, GSM8K),\nmultilingual, and dialogue benchmarks compared to checkpointing and\noptimizer-centric baselines (LoMo, GaLore).",
    "categories": [
      "cs.LG",
      "cs.AI"
    ],
    "published": "2025-10-26T00:50:12Z",
    "authors": [
      "Jing Yang",
      "Kaitong Cai",
      "Yijia Fan",
      "Yufeng Yang",
      "Keze Wang"
    ],
    "pdf_url": "http://arxiv.org/pdf/2510.22467v1"
  },
  {
    "id": "2510.22462v1",
    "title": "Learning \"Partner-Aware\" Collaborators in Multi-Party Collaboration",
    "abstract": "Large Language Models (LLMs) are increasingly bring deployed in agentic\nsettings where they act as collaborators with humans. Therefore, it is\nincreasingly important to be able to evaluate their abilities to collaborate\neffectively in multi-turn, multi-party tasks. In this paper, we build on the AI\nalignment and safe interruptability literature to offer novel theoretical\ninsights on collaborative behavior between LLM-driven collaborator agents and\nan intervention agent. Our goal is to learn an ideal partner-aware collaborator\nthat increases the group's common-ground (CG)-alignment on task-relevant\npropositions-by intelligently collecting information provided in interventions\nby a partner agent.We show how LLM agents trained using standard RLHF and\nrelated approaches are naturally inclined to ignore possibly well-meaning\ninterventions, which makes increasing group common ground non-trivial in this\nsetting. We employ a two-player Modified-Action MDP to examine this suboptimal\nbehavior of standard AI agents, and propose Interruptible Collaborative\nRoleplayer (ICR)-a novel partner-aware learning algorithm to train CG-optimal\ncollaborators. Experiments on multiple collaborative task environments show\nthat ICR, on average, is more capable of promoting successful CG convergence\nand exploring more diverse solutions in such tasks.",
    "categories": [
      "cs.AI"
    ],
    "published": "2025-10-26T00:05:48Z",
    "authors": [
      "Abhijnan Nath",
      "Nikhil Krishnaswamy"
    ],
    "pdf_url": "http://arxiv.org/pdf/2510.22462v1"
  },
  {
    "id": "2510.23656v1",
    "title": "Error Adjustment Based on Spatiotemporal Correlation Fusion for Traffic\n  Forecasting",
    "abstract": "Deep neural networks (DNNs) play a significant role in an increasing body of\nresearch on traffic forecasting due to their effectively capturing\nspatiotemporal patterns embedded in traffic data. A general assumption of\ntraining the said forecasting models via mean squared error estimation is that\nthe errors across time steps and spatial positions are uncorrelated. However,\nthis assumption does not really hold because of the autocorrelation caused by\nboth the temporality and spatiality of traffic data. This gap limits the\nperformance of DNN-based forecasting models and is overlooked by current\nstudies. To fill up this gap, this paper proposes Spatiotemporally\nAutocorrelated Error Adjustment (SAEA), a novel and general framework designed\nto systematically adjust autocorrelated prediction errors in traffic\nforecasting. Unlike existing approaches that assume prediction errors follow a\nrandom Gaussian noise distribution, SAEA models these errors as a\nspatiotemporal vector autoregressive (VAR) process to capture their intrinsic\ndependencies. First, it explicitly captures both spatial and temporal error\ncorrelations by a coefficient matrix, which is then embedded into a newly\nformulated cost function. Second, a structurally sparse regularization is\nintroduced to incorporate prior spatial information, ensuring that the learned\ncoefficient matrix aligns with the inherent road network structure. Finally, an\ninference process with test-time error adjustment is designed to dynamically\nrefine predictions, mitigating the impact of autocorrelated errors in real-time\nforecasting. The effectiveness of the proposed approach is verified on\ndifferent traffic datasets. Results across a wide range of traffic forecasting\nmodels show that our method enhances performance in almost all cases.",
    "categories": [
      "cs.LG",
      "cs.AI"
    ],
    "published": "2025-10-25T23:48:50Z",
    "authors": [
      "Fuqiang Liu",
      "Weiping Ding",
      "Luis Miranda-Moreno",
      "Lijun Sun"
    ],
    "pdf_url": "http://arxiv.org/pdf/2510.23656v1"
  },
  {
    "id": "2510.22455v1",
    "title": "Evaluating Multimodal Large Language Models on Core Music Perception\n  Tasks",
    "abstract": "Multimodal Large Language Models (LLMs) claim \"musical understanding\" via\nevaluations that conflate listening with score reading. We benchmark three SOTA\nLLMs (Gemini 2.5 Pro, Gemini 2.5 Flash, and Qwen2.5-Omni) across three core\nmusic skills: Syncopation Scoring, Transposition Detection, and Chord Quality\nIdentification. Moreover, we separate three sources of variability: (i)\nperceptual limitations (audio vs. MIDI inputs), (ii) exposure to examples\n(zero- vs. few-shot manipulations), and (iii) reasoning strategies (Standalone,\nCoT, LogicLM). For the latter we adapt LogicLM, a framework combining LLMs with\nsymbolic solvers to perform structured reasoning, to music. Results reveal a\nclear perceptual gap: models perform near ceiling on MIDI but show accuracy\ndrops on audio. Reasoning and few-shot prompting offer minimal gains. This is\nexpected for MIDI, where performance reaches saturation, but more surprising\nfor audio, where LogicLM, despite near-perfect MIDI accuracy, remains notably\nbrittle. Among models, Gemini Pro achieves the highest performance across most\nconditions. Overall, current systems reason well over symbols (MIDI) but do not\nyet \"listen\" reliably from audio. Our method and dataset make the\nperception-reasoning boundary explicit and offer actionable guidance for\nbuilding robust, audio-first music systems.",
    "categories": [
      "cs.SD",
      "cs.AI",
      "eess.AS"
    ],
    "published": "2025-10-25T23:10:16Z",
    "authors": [
      "Brandon James Carone",
      "Iran R. Roman",
      "Pablo Ripoll\u00e9s"
    ],
    "pdf_url": "http://arxiv.org/pdf/2510.22455v1"
  },
  {
    "id": "2510.22451v1",
    "title": "GraphTOP: Graph Topology-Oriented Prompting for Graph Neural Networks",
    "abstract": "Graph Neural Networks (GNNs) have revolutionized the field of graph learning\nby learning expressive graph representations from massive graph data. As a\ncommon pattern to train powerful GNNs, the \"pre-training, adaptation\" scheme\nfirst pre-trains GNNs over unlabeled graph data and subsequently adapts them to\nspecific downstream tasks. In the adaptation phase, graph prompting is an\neffective strategy that modifies input graph data with learnable prompts while\nkeeping pre-trained GNN models frozen. Typically, existing graph prompting\nstudies mainly focus on *feature-oriented* methods that apply graph prompts to\nnode features or hidden representations. However, these studies often achieve\nsuboptimal performance, as they consistently overlook the potential of\n*topology-oriented* prompting, which adapts pre-trained GNNs by modifying the\ngraph topology. In this study, we conduct a pioneering investigation of graph\nprompting in terms of graph topology. We propose the first **Graph**\n**T**opology-**O**riented **P**rompting (GraphTOP) framework to effectively\nadapt pre-trained GNN models for downstream tasks. More specifically, we\nreformulate topology-oriented prompting as an edge rewiring problem within\nmulti-hop local subgraphs and relax it into the continuous probability space\nthrough reparameterization while ensuring tight relaxation and preserving graph\nsparsity. Extensive experiments on five graph datasets under four pre-training\nstrategies demonstrate that our proposed GraphTOP outshines six baselines on\nmultiple node classification datasets. Our code is available at\nhttps://github.com/xbfu/GraphTOP.",
    "categories": [
      "cs.LG",
      "cs.AI"
    ],
    "published": "2025-10-25T22:50:12Z",
    "authors": [
      "Xingbo Fu",
      "Zhenyu Lei",
      "Zihan Chen",
      "Binchi Zhang",
      "Chuxu Zhang",
      "Jundong Li"
    ],
    "pdf_url": "http://arxiv.org/pdf/2510.22451v1"
  },
  {
    "id": "2510.22450v1",
    "title": "SmartMixed: A Two-Phase Training Strategy for Adaptive Activation\n  Function Learning in Neural Networks",
    "abstract": "The choice of activation function plays a critical role in neural networks,\nyet most architectures still rely on fixed, uniform activation functions across\nall neurons. We introduce SmartMixed, a two-phase training strategy that allows\nnetworks to learn optimal per-neuron activation functions while preserving\ncomputational efficiency at inference. In the first phase, neurons adaptively\nselect from a pool of candidate activation functions (ReLU, Sigmoid, Tanh,\nLeaky ReLU, ELU, SELU) using a differentiable hard-mixture mechanism. In the\nsecond phase, each neuron's activation function is fixed according to the\nlearned selection, resulting in a computationally efficient network that\nsupports continued training with optimized vectorized operations. We evaluate\nSmartMixed on the MNIST dataset using feedforward neural networks of varying\ndepths. The analysis shows that neurons in different layers exhibit distinct\npreferences for activation functions, providing insights into the functional\ndiversity within neural architectures.",
    "categories": [
      "cs.LG",
      "cs.AI"
    ],
    "published": "2025-10-25T22:46:37Z",
    "authors": [
      "Amin Omidvar"
    ],
    "pdf_url": "http://arxiv.org/pdf/2510.22450v1"
  },
  {
    "id": "2510.22439v2",
    "title": "PromptReverb: Multimodal Room Impulse Response Generation Through Latent\n  Rectified Flow Matching",
    "abstract": "Room impulse response (RIR) generation remains a critical challenge for\ncreating immersive virtual acoustic environments. Current methods suffer from\ntwo fundamental limitations: the scarcity of full-band RIR datasets and the\ninability of existing models to generate acoustically accurate responses from\ndiverse input modalities. We present PromptReverb, a two-stage generative\nframework that addresses these challenges. Our approach combines a variational\nautoencoder that upsamples band-limited RIRs to full-band quality (48 kHz), and\na conditional diffusion transformer model based on rectified flow matching that\ngenerates RIRs from descriptions in natural language. Empirical evaluation\ndemonstrates that PromptReverb produces RIRs with superior perceptual quality\nand acoustic accuracy compared to existing methods, achieving 8.8% mean RT60\nerror compared to -37% for widely used baselines and yielding more realistic\nroom-acoustic parameters. Our method enables practical applications in virtual\nreality, architectural acoustics, and audio production where flexible,\nhigh-quality RIR synthesis is essential.",
    "categories": [
      "cs.SD",
      "cs.AI",
      "I.2.6, H.5.5"
    ],
    "published": "2025-10-25T21:38:07Z",
    "authors": [
      "Ali Vosoughi",
      "Yongyi Zang",
      "Qihui Yang",
      "Nathan Paek",
      "Randal Leistikow",
      "Chenliang Xu"
    ],
    "pdf_url": "http://arxiv.org/pdf/2510.22439v2"
  },
  {
    "id": "2510.22437v1",
    "title": "Modeling Hierarchical Thinking in Large Reasoning Models",
    "abstract": "Large Language Models (LLMs) have demonstrated remarkable reasoning abilities\nwhen they generate step-by-step solutions, known as chain-of-thought (CoT)\nreasoning. When trained to using chain-of-thought reasoning examples, the\nresulting models (called Large Reasoning Models, or LRMs) appear to learn\nhierarchical thinking strategies similar to those used by humans. However,\nunderstanding LRMs emerging reasoning capabilities remains a difficult open\nproblem, with many potential important applications including improving\ntraining and understanding robustness. In this paper, we adopt a memoryless\nFinite State Machine formulation to approximate LRM's emerging hierarchical\nreasoning dynamics as a structured, interpretable abstraction. We identify a\nsmall set of discrete reasoning states including - initialization, deduction,\naugmentation-strategy, uncertainty-estimation, backtracking, and\nfinal-conclusion that capture the high-level states present in the model's\nreasoning process. By annotating each step of a model's CoT with these states,\nwe can represent the reasoning trajectory as a transition sequence through the\nstate graph. This FSM formulation provides a systematic way to analyze,\ninterpret and visualize how different models approach problems. We describe the\nFSM model, provide examples of CoT annotations under this scheme, and discuss\nhow it can shed light on differences between available models in their approach\nto reasoning. Our results demonstrate that this FSM-based analysis reveals\ndistinct reasoning patterns and potential shortcomings, offering a new lens to\nevaluate and improve LLM reasoning.",
    "categories": [
      "cs.AI",
      "cs.CL"
    ],
    "published": "2025-10-25T21:25:30Z",
    "authors": [
      "G M Shahariar",
      "Ali Nazari",
      "Erfan Shayegani",
      "Nael Abu-Ghazaleh"
    ],
    "pdf_url": "http://arxiv.org/pdf/2510.22437v1"
  },
  {
    "id": "2510.22422v1",
    "title": "Group size effects and collective misalignment in LLM multi-agent\n  systems",
    "abstract": "Multi-agent systems of large language models (LLMs) are rapidly expanding\nacross domains, introducing dynamics not captured by single-agent evaluations.\nYet, existing work has mostly contrasted the behavior of a single agent with\nthat of a collective of fixed size, leaving open a central question: how does\ngroup size shape dynamics? Here, we move beyond this dichotomy and\nsystematically explore outcomes across the full range of group sizes. We focus\non multi-agent misalignment, building on recent evidence that interacting LLMs\nplaying a simple coordination game can generate collective biases absent in\nindividual models. First, we show that collective bias is a deeper phenomenon\nthan previously assessed: interaction can amplify individual biases, introduce\nnew ones, or override model-level preferences. Second, we demonstrate that\ngroup size affects the dynamics in a non-linear way, revealing model-dependent\ndynamical regimes. Finally, we develop a mean-field analytical approach and\nshow that, above a critical population size, simulations converge to\ndeterministic predictions that expose the basins of attraction of competing\nequilibria. These findings establish group size as a key driver of multi-agent\ndynamics and highlight the need to consider population-level effects when\ndeploying LLM-based systems at scale.",
    "categories": [
      "cs.MA",
      "cs.AI",
      "cs.CY",
      "physics.soc-ph"
    ],
    "published": "2025-10-25T19:45:45Z",
    "authors": [
      "Ariel Flint",
      "Luca Maria Aiello",
      "Romualdo Pastor-Satorras",
      "Andrea Baronchelli"
    ],
    "pdf_url": "http://arxiv.org/pdf/2510.22422v1"
  },
  {
    "id": "2510.22405v1",
    "title": "Knowledge-guided Continual Learning for Behavioral Analytics Systems",
    "abstract": "User behavior on online platforms is evolving, reflecting real-world changes\nin how people post, whether it's helpful messages or hate speech. Models that\nlearn to capture this content can experience a decrease in performance over\ntime due to data drift, which can lead to ineffective behavioral analytics\nsystems. However, fine-tuning such a model over time with new data can be\ndetrimental due to catastrophic forgetting. Replay-based approaches in\ncontinual learning offer a simple yet efficient method to update such models,\nminimizing forgetting by maintaining a buffer of important training instances\nfrom past learned tasks. However, the main limitation of this approach is the\nfixed size of the buffer. External knowledge bases can be utilized to overcome\nthis limitation through data augmentation. We propose a novel\naugmentation-based approach to incorporate external knowledge in the\nreplay-based continual learning framework. We evaluate several strategies with\nthree datasets from prior studies related to deviant behavior classification to\nassess the integration of external knowledge in continual learning and\ndemonstrate that augmentation helps outperform baseline replay-based\napproaches.",
    "categories": [
      "cs.LG",
      "cs.AI"
    ],
    "published": "2025-10-25T19:04:14Z",
    "authors": [
      "Yasas Senarath",
      "Hemant Purohit"
    ],
    "pdf_url": "http://arxiv.org/pdf/2510.22405v1"
  },
  {
    "id": "2510.22391v1",
    "title": "Top-Down Semantic Refinement for Image Captioning",
    "abstract": "Large Vision-Language Models (VLMs) face an inherent contradiction in image\ncaptioning: their powerful single-step generation capabilities often lead to a\nmyopic decision-making process. This makes it difficult to maintain global\nnarrative coherence while capturing rich details, a limitation that is\nparticularly pronounced in tasks that require multi-step and complex scene\ndescription. To overcome this fundamental challenge, we redefine image\ncaptioning as a goal-oriented hierarchical refinement planning problem, and\nfurther propose a novel framework, named Top-Down Semantic Refinement (TDSR),\nwhich models the generation process as a Markov Decision Process (MDP).\nHowever, planning within the vast state space of a VLM presents a significant\ncomputational hurdle. Our core contribution, therefore, is the design of a\nhighly efficient Monte Carlo Tree Search (MCTS) algorithm tailored for VLMs. By\nincorporating a visual-guided parallel expansion and a lightweight value\nnetwork, our TDSR reduces the call frequency to the expensive VLM by an order\nof magnitude without sacrificing planning quality. Furthermore, an adaptive\nearly stopping mechanism dynamically matches computational overhead to the\nimage's complexity. Extensive experiments on multiple benchmarks, including\nDetailCaps, COMPOSITIONCAP, and POPE, demonstrate that our TDSR, as a\nplug-and-play module, can significantly enhance the performance of existing\nVLMs (e.g., LLaVA-1.5, Qwen2.5-VL) by achieving state-of-the-art or highly\ncompetitive results in fine-grained description, compositional generalization,\nand hallucination suppression.",
    "categories": [
      "cs.CV",
      "cs.AI"
    ],
    "published": "2025-10-25T18:27:00Z",
    "authors": [
      "Jusheng Zhang",
      "Kaitong Cai",
      "Jing Yang",
      "Jian Wang",
      "Chengpei Tang",
      "Keze Wang"
    ],
    "pdf_url": "http://arxiv.org/pdf/2510.22391v1"
  },
  {
    "id": "2510.22389v1",
    "title": "Can Small and Reasoning Large Language Models Score Journal Articles for\n  Research Quality and Do Averaging and Few-shot Help?",
    "abstract": "Assessing published academic journal articles is a common task for\nevaluations of departments and individuals. Whilst it is sometimes supported by\ncitation data, Large Language Models (LLMs) may give more useful indications of\narticle quality. Evidence of this capability exists for two of the largest LLM\nfamilies, ChatGPT and Gemini, and the medium sized LLM Gemma3 27b, but it is\nunclear whether smaller LLMs and reasoning models have similar abilities. This\nis important because larger models may be slow and impractical in some\nsituations, and reasoning models may perform differently. Four relevant\nquestions are addressed with Gemma3 variants, Llama4 Scout, Qwen3, Magistral\nSmall and DeepSeek R1, on a dataset of 2,780 medical, health and life science\npapers in 6 fields, with two different gold standards, one novel. The results\nsuggest that smaller (open weights) and reasoning LLMs have similar performance\nto ChatGPT 4o-mini and Gemini 2.0 Flash, but that 1b parameters may often, and\n4b sometimes, be too few. Moreover, averaging scores from multiple identical\nqueries seems to be a universally successful strategy, and few-shot prompts\n(four examples) tended to help but the evidence was equivocal. Reasoning models\ndid not have a clear advantage. Overall, the results show, for the first time,\nthat smaller LLMs >4b, including reasoning models, have a substantial\ncapability to score journal articles for research quality, especially if score\naveraging is used.",
    "categories": [
      "cs.DL",
      "cs.AI"
    ],
    "published": "2025-10-25T18:12:41Z",
    "authors": [
      "Mike Thelwall",
      "Ehsan Mohammadi"
    ],
    "pdf_url": "http://arxiv.org/pdf/2510.22389v1"
  },
  {
    "id": "2510.22383v1",
    "title": "Dynamic Dropout: Leveraging Conway's Game of Life for Neural Networks\n  Regularization",
    "abstract": "Regularization techniques play a crucial role in preventing overfitting and\nimproving the generalization performance of neural networks. Dropout, a widely\nused regularization technique, randomly deactivates units during training to\nintroduce redundancy and prevent co-adaptation among neurons. Despite its\neffectiveness, dropout has limitations, such as its static nature and lack of\ninterpretability. In this paper, we propose a novel approach to regularization\nby substituting dropout with Conway's Game of Life (GoL), a cellular automata\nwith simple rules that govern the evolution of a grid of cells. We introduce\ndynamic unit deactivation during training by representing neural network units\nas cells in a GoL grid and applying the game's rules to deactivate units. This\napproach allows for the emergence of spatial patterns that adapt to the\ntraining data, potentially enhancing the network's ability to generalize. We\ndemonstrate the effectiveness of our approach on the CIFAR-10 dataset, showing\nthat dynamic unit deactivation using GoL achieves comparable performance to\ntraditional dropout techniques while offering insights into the network's\nbehavior through the visualization of evolving patterns. Furthermore, our\ndiscussion highlights the applicability of our proposal in deeper\narchitectures, demonstrating how it enhances the performance of different\ndropout techniques.",
    "categories": [
      "cs.LG",
      "cs.AI",
      "cs.CV"
    ],
    "published": "2025-10-25T17:55:13Z",
    "authors": [
      "David Freire-Obreg\u00f3n",
      "Jos\u00e9 Salas-C\u00e1ceres",
      "Modesto Castrill\u00f3n-Santana"
    ],
    "pdf_url": "http://arxiv.org/pdf/2510.22383v1"
  },
  {
    "id": "2510.22380v1",
    "title": "Efficient Large-Deformation Medical Image Registration via Recurrent\n  Dynamic Correlation",
    "abstract": "Deformable image registration estimates voxel-wise correspondences between\nimages through spatial transformations, and plays a key role in medical\nimaging. While deep learning methods have significantly reduced runtime,\nefficiently handling large deformations remains a challenging task.\nConvolutional networks aggregate local features but lack direct modeling of\nvoxel correspondences, promoting recent works to explore explicit feature\nmatching. Among them, voxel-to-region matching is more efficient for direct\ncorrespondence modeling by computing local correlation features whithin\nneighbourhoods, while region-to-region matching incurs higher redundancy due to\nexcessive correlation pairs across large regions. However, the inherent\nlocality of voxel-to-region matching hinders the capture of long-range\ncorrespondences required for large deformations. To address this, we propose a\nRecurrent Correlation-based framework that dynamically relocates the matching\nregion toward more promising positions. At each step, local matching is\nperformed with low cost, and the estimated offset guides the next search\nregion, supporting efficient convergence toward large deformations. In\naddition, we uses a lightweight recurrent update module with memory capacity\nand decouples motion-related and texture features to suppress semantic\nredundancy. We conduct extensive experiments on brain MRI and abdominal CT\ndatasets under two settings: with and without affine pre-registration. Results\nshow that our method exibits a strong accuracy-computation trade-off,\nsurpassing or matching the state-of-the-art performance. For example, it\nachieves comparable performance on the non-affine OASIS dataset, while using\nonly 9.5% of the FLOPs and running 96% faster than RDP, a representative\nhigh-performing method.",
    "categories": [
      "cs.CV",
      "cs.AI"
    ],
    "published": "2025-10-25T17:49:29Z",
    "authors": [
      "Tianran Li",
      "Marius Staring",
      "Yuchuan Qiao"
    ],
    "pdf_url": "http://arxiv.org/pdf/2510.22380v1"
  },
  {
    "id": "2510.22379v2",
    "title": "TraceTrans: Translation and Spatial Tracing for Surgical Prediction",
    "abstract": "Image-to-image translation models have achieved notable success in converting\nimages across visual domains and are increasingly used for medical tasks such\nas predicting post-operative outcomes and modeling disease progression.\nHowever, most existing methods primarily aim to match the target distribution\nand often neglect spatial correspondences between the source and translated\nimages. This limitation can lead to structural inconsistencies and\nhallucinations, undermining the reliability and interpretability of the\npredictions. These challenges are accentuated in clinical applications by the\nstringent requirement for anatomical accuracy. In this work, we present\nTraceTrans, a novel deformable image translation model designed for\npost-operative prediction that generates images aligned with the target\ndistribution while explicitly revealing spatial correspondences with the\npre-operative input. The framework employs an encoder for feature extraction\nand dual decoders for predicting spatial deformations and synthesizing the\ntranslated image. The predicted deformation field imposes spatial constraints\non the generated output, ensuring anatomical consistency with the source.\nExtensive experiments on medical cosmetology and brain MRI datasets demonstrate\nthat TraceTrans delivers accurate and interpretable post-operative predictions,\nhighlighting its potential for reliable clinical deployment.",
    "categories": [
      "eess.IV",
      "cs.AI",
      "cs.CV",
      "cs.LG"
    ],
    "published": "2025-10-25T17:48:46Z",
    "authors": [
      "Xiyu Luo",
      "Haodong Li",
      "Xinxing Cheng",
      "He Zhao",
      "Yang Hu",
      "Xuan Song",
      "Tianyang Zhang"
    ],
    "pdf_url": "http://arxiv.org/pdf/2510.22379v2"
  },
  {
    "id": "2510.22373v1",
    "title": "VisJudge-Bench: Aesthetics and Quality Assessment of Visualizations",
    "abstract": "Visualization, a domain-specific yet widely used form of imagery, is an\neffective way to turn complex datasets into intuitive insights, and its value\ndepends on whether data are faithfully represented, clearly communicated, and\naesthetically designed. However, evaluating visualization quality is\nchallenging: unlike natural images, it requires simultaneous judgment across\ndata encoding accuracy, information expressiveness, and visual aesthetics.\nAlthough multimodal large language models (MLLMs) have shown promising\nperformance in aesthetic assessment of natural images, no systematic benchmark\nexists for measuring their capabilities in evaluating visualizations. To\naddress this, we propose VisJudge-Bench, the first comprehensive benchmark for\nevaluating MLLMs' performance in assessing visualization aesthetics and\nquality. It contains 3,090 expert-annotated samples from real-world scenarios,\ncovering single visualizations, multiple visualizations, and dashboards across\n32 chart types. Systematic testing on this benchmark reveals that even the most\nadvanced MLLMs (such as GPT-5) still exhibit significant gaps compared to human\nexperts in judgment, with a Mean Absolute Error (MAE) of 0.551 and a\ncorrelation with human ratings of only 0.429. To address this issue, we propose\nVisJudge, a model specifically designed for visualization aesthetics and\nquality assessment. Experimental results demonstrate that VisJudge\nsignificantly narrows the gap with human judgment, reducing the MAE to 0.442 (a\n19.8% reduction) and increasing the consistency with human experts to 0.681 (a\n58.7% improvement) compared to GPT-5. The benchmark is available at\nhttps://github.com/HKUSTDial/VisJudgeBench.",
    "categories": [
      "cs.CL",
      "cs.AI",
      "cs.CV"
    ],
    "published": "2025-10-25T17:31:02Z",
    "authors": [
      "Yupeng Xie",
      "Zhiyang Zhang",
      "Yifan Wu",
      "Sirong Lu",
      "Jiayi Zhang",
      "Zhaoyang Yu",
      "Jinlin Wang",
      "Sirui Hong",
      "Bang Liu",
      "Chenglin Wu",
      "Yuyu Luo"
    ],
    "pdf_url": "http://arxiv.org/pdf/2510.22373v1"
  },
  {
    "id": "2510.22371v1",
    "title": "Reasoning Models Reason Well, Until They Don't",
    "abstract": "Large language models (LLMs) have shown significant progress in reasoning\ntasks. However, recent studies show that transformers and LLMs fail\ncatastrophically once reasoning problems exceed modest complexity. We revisit\nthese findings through the lens of large reasoning models (LRMs) -- LLMs\nfine-tuned with incentives for step-by-step argumentation and\nself-verification. LRM performance on graph and reasoning benchmarks such as\nNLGraph seem extraordinary, with some even claiming they are capable of\ngeneralized reasoning and innovation in reasoning-intensive fields such as\nmathematics, physics, medicine, and law. However, by more carefully scaling the\ncomplexity of reasoning problems, we show existing benchmarks actually have\nlimited complexity. We develop a new dataset, the Deep Reasoning Dataset\n(DeepRD), along with a generative process for producing unlimited examples of\nscalable complexity. We use this dataset to evaluate model performance on graph\nconnectivity and natural language proof planning. We find that the performance\nof LRMs drop abruptly at sufficient complexity and do not generalize. We also\nrelate our LRM results to the distributions of the complexities of large,\nreal-world knowledge graphs, interaction graphs, and proof datasets. We find\nthe majority of real-world examples fall inside the LRMs' success regime, yet\nthe long tails expose substantial failure potential. Our analysis highlights\nthe near-term utility of LRMs while underscoring the need for new methods that\ngeneralize beyond the complexity of examples in the training distribution.",
    "categories": [
      "cs.AI",
      "cs.CL"
    ],
    "published": "2025-10-25T17:28:38Z",
    "authors": [
      "Revanth Rameshkumar",
      "Jimson Huang",
      "Yunxin Sun",
      "Fei Xia",
      "Abulhair Saparov"
    ],
    "pdf_url": "http://arxiv.org/pdf/2510.22371v1"
  },
  {
    "id": "2510.22370v1",
    "title": "BLIP-FusePPO: A Vision-Language Deep Reinforcement Learning Framework\n  for Lane Keeping in Autonomous Vehicles",
    "abstract": "In this paper, we propose Bootstrapped Language-Image Pretraining-driven\nFused State Representation in Proximal Policy Optimization (BLIP-FusePPO), a\nnovel multimodal reinforcement learning (RL) framework for autonomous\nlane-keeping (LK), in which semantic embeddings generated by a vision-language\nmodel (VLM) are directly fused with geometric states, LiDAR observations, and\nProportional-Integral-Derivative-based (PID) control feedback within the agent\nobservation space. The proposed method lets the agent learn driving rules that\nare aware of their surroundings and easy to understand by combining high-level\nscene understanding from the VLM with low-level control and spatial signals.\nOur architecture brings together semantic, geometric, and control-aware\nrepresentations to make policy learning more robust. A hybrid reward function\nthat includes semantic alignment, LK accuracy, obstacle avoidance, and speed\nregulation helps learning to be more efficient and generalizable. Our method is\ndifferent from the approaches that only use semantic models to shape rewards.\nInstead, it directly embeds semantic features into the state representation.\nThis cuts down on expensive runtime inference and makes sure that semantic\nguidance is always available. The simulation results show that the proposed\nmodel is better at LK stability and adaptability than the best vision-based and\nmultimodal RL baselines in a wide range of difficult driving situations. We\nmake our code publicly available.",
    "categories": [
      "cs.RO",
      "cs.AI",
      "cs.CV",
      "cs.LG",
      "cs.SE"
    ],
    "published": "2025-10-25T17:27:08Z",
    "authors": [
      "Seyed Ahmad Hosseini Miangoleh",
      "Amin Jalal Aghdasian",
      "Farzaneh Abdollahi"
    ],
    "pdf_url": "http://arxiv.org/pdf/2510.22370v1"
  },
  {
    "id": "2510.22366v1",
    "title": "T2SMark: Balancing Robustness and Diversity in Noise-as-Watermark for\n  Diffusion Models",
    "abstract": "Diffusion models have advanced rapidly in recent years, producing\nhigh-fidelity images while raising concerns about intellectual property\nprotection and the misuse of generative AI. Image watermarking for diffusion\nmodels, particularly Noise-as-Watermark (NaW) methods, encode watermark as\nspecific standard Gaussian noise vector for image generation, embedding the\ninfomation seamlessly while maintaining image quality. For detection, the\ngeneration process is inverted to recover the initial noise vector containing\nthe watermark before extraction. However, existing NaW methods struggle to\nbalance watermark robustness with generation diversity. Some methods achieve\nstrong robustness by heavily constraining initial noise sampling, which\ndegrades user experience, while others preserve diversity but prove too fragile\nfor real-world deployment. To address this issue, we propose T2SMark, a\ntwo-stage watermarking scheme based on Tail-Truncated Sampling (TTS). Unlike\nprior methods that simply map bits to positive or negative values, TTS enhances\nrobustness by embedding bits exclusively in the reliable tail regions while\nrandomly sampling the central zone to preserve the latent distribution. Our\ntwo-stage framework then ensures sampling diversity by integrating a randomly\ngenerated session key into both encryption pipelines. We evaluate T2SMark on\ndiffusion models with both U-Net and DiT backbones. Extensive experiments show\nthat it achieves an optimal balance between robustness and diversity. Our code\nis available at\n\\href{https://github.com/0xD009/T2SMark}{https://github.com/0xD009/T2SMark}.",
    "categories": [
      "cs.CV",
      "cs.AI"
    ],
    "published": "2025-10-25T16:55:55Z",
    "authors": [
      "Jindong Yang",
      "Han Fang",
      "Weiming Zhang",
      "Nenghai Yu",
      "Kejiang Chen"
    ],
    "pdf_url": "http://arxiv.org/pdf/2510.22366v1"
  },
  {
    "id": "2510.23652v1",
    "title": "The Structural Scalpel: Automated Contiguous Layer Pruning for Large\n  Language Models",
    "abstract": "Although large language models (LLMs) have achieved revolutionary\nbreakthroughs in many fields, their large model size and high computational\ncost pose significant challenges for practical deployment on\nresource-constrained edge devices. To this end, layer pruning has been proposed\nto reduce the computational overhead by directly removing redundant layers.\nHowever, existing layer pruning methods typically rely on hand-crafted metrics\nto evaluate and remove individual layers, while ignoring the dependencies\nbetween layers. This can disrupt the model's information flow and severely\ndegrade performance. To address these issues, we propose CLP, a novel\ncontinuous layer pruning framework that introduces two key innovations: a\ndifferentiable concave gate algorithm that automatically identifies the best\ncontinuous layer segments for pruning via gradient-based optimization; and a\ncutoff endpoint tuning strategy that effectively restores model performance by\nfine-tuning only the layers adjacent to the pruned segments. Extensive\nexperiments across multiple model architectures (including LLaMA2, LLaMA3 and\nQwen) and sizes (from $7$B to $70$B parameters) show that CLP significantly\noutperforms existing state-of-the-art baselines. For example, at a pruning rate\nof $20\\%$, CLP achieves an average performance retention of $95.34\\%$ on\nLLaMA3-70B, outperforming baselines by $4.29\\%$-$30.52\\%$. Furthermore, CLP can\nbe seamlessly combined with quantization to further compress the model with\nonly a slight performance loss.",
    "categories": [
      "cs.LG",
      "cs.AI"
    ],
    "published": "2025-10-25T16:40:17Z",
    "authors": [
      "Yao Lu",
      "Yuqi Li",
      "Wenbin Xie",
      "Shanqing Yu",
      "Qi Xuan",
      "Zhaowei Zhu",
      "Shiping Wen"
    ],
    "pdf_url": "http://arxiv.org/pdf/2510.23652v1"
  },
  {
    "id": "2510.22344v1",
    "title": "FAIR-RAG: Faithful Adaptive Iterative Refinement for Retrieval-Augmented\n  Generation",
    "abstract": "While Retrieval-Augmented Generation (RAG) mitigates hallucination and\nknowledge staleness in Large Language Models (LLMs), existing frameworks often\nfalter on complex, multi-hop queries that require synthesizing information from\ndisparate sources. Current advanced RAG methods, employing iterative or\nadaptive strategies, lack a robust mechanism to systematically identify and\nfill evidence gaps, often propagating noise or failing to gather a\ncomprehensive context. We introduce FAIR-RAG, a novel agentic framework that\ntransforms the standard RAG pipeline into a dynamic, evidence-driven reasoning\nprocess. At its core is an Iterative Refinement Cycle governed by a module we\nterm Structured Evidence Assessment (SEA). The SEA acts as an analytical gating\nmechanism: it deconstructs the initial query into a checklist of required\nfindings and audits the aggregated evidence to identify confirmed facts and,\ncritically, explicit informational gaps. These gaps provide a precise signal to\nan Adaptive Query Refinement agent, which generates new, targeted sub-queries\nto retrieve missing information. This cycle repeats until the evidence is\nverified as sufficient, ensuring a comprehensive context for a final, strictly\nfaithful generation. We conducted experiments on challenging multi-hop QA\nbenchmarks, including HotpotQA, 2WikiMultiHopQA, and MusiQue. In a unified\nexperimental setup, FAIR-RAG significantly outperforms strong baselines. On\nHotpotQA, it achieves an F1-score of 0.453 -- an absolute improvement of 8.3\npoints over the strongest iterative baseline -- establishing a new\nstate-of-the-art for this class of methods on these benchmarks. Our work\ndemonstrates that a structured, evidence-driven refinement process with\nexplicit gap analysis is crucial for unlocking reliable and accurate reasoning\nin advanced RAG systems for complex, knowledge-intensive tasks.",
    "categories": [
      "cs.CL",
      "cs.AI",
      "cs.IR",
      "68T50, 68P20",
      "I.2.7; H.3.3"
    ],
    "published": "2025-10-25T15:59:33Z",
    "authors": [
      "Mohammad Aghajani Asl",
      "Majid Asgari-Bidhendi",
      "Behrooz Minaei-Bidgoli"
    ],
    "pdf_url": "http://arxiv.org/pdf/2510.22344v1"
  },
  {
    "id": "2510.22340v1",
    "title": "DynaSolidGeo: A Dynamic Benchmark for Genuine Spatial Mathematical\n  Reasoning of VLMs in Solid Geometry",
    "abstract": "Solid geometry problem solving demands spatial mathematical reasoning that\nintegrates spatial intelligence and symbolic reasoning. However, most existing\nmultimodal mathematical reasoning benchmarks focus primarily on 2D plane\ngeometry, rely on static datasets prone to data contamination and memorization,\nand evaluate models solely by final answers, overlooking the reasoning process.\nTo address these limitations, we introduce DynaSolidGeo, the first dynamic\nbenchmark for evaluating genuine spatial reasoning in Vision-Language Models\n(VLMs). Constructed through a semi-automatic annotation pipeline, DynaSolidGeo\ncontains 503 expert-curated seed questions that can, in principle, dynamically\ngenerate an unbounded number of diverse multimodal text-visual instances.\nBeyond answer accuracy, we incorporate process evaluation based on\nexpert-annotated reasoning chains to measure logical validity and causal\ncoherence. Experiments across representative open-source and closed-source VLMs\nreveal large performance gaps, severe degradation in dynamic settings, and poor\nperformance on tasks requiring high-level spatial intelligence, such as mental\nrotation and visualization. The code and dataset are available at\n\\href{https://zgca-ai4edu.github.io/DynaSolidGeo/}{DynaSolidGeo}.",
    "categories": [
      "cs.AI",
      "cs.CL",
      "cs.CV",
      "cs.LG"
    ],
    "published": "2025-10-25T15:49:45Z",
    "authors": [
      "Changti Wu",
      "Shijie Lian",
      "Zihao Liu",
      "Lei Zhang",
      "Laurence Tianruo Yang",
      "Kai Chen"
    ],
    "pdf_url": "http://arxiv.org/pdf/2510.22340v1"
  },
  {
    "id": "2510.22336v1",
    "title": "Toward Humanoid Brain-Body Co-design: Joint Optimization of Control and\n  Morphology for Fall Recovery",
    "abstract": "Humanoid robots represent a central frontier in embodied intelligence, as\ntheir anthropomorphic form enables natural deployment in humans' workspace.\nBrain-body co-design for humanoids presents a promising approach to realizing\nthis potential by jointly optimizing control policies and physical morphology.\nWithin this context, fall recovery emerges as a critical capability. It not\nonly enhances safety and resilience but also integrates naturally with\nlocomotion systems, thereby advancing the autonomy of humanoids. In this paper,\nwe propose RoboCraft, a scalable humanoid co-design framework for fall recovery\nthat iteratively improves performance through the coupled updates of control\npolicy and morphology. A shared policy pretrained across multiple designs is\nprogressively finetuned on high-performing morphologies, enabling efficient\nadaptation without retraining from scratch. Concurrently, morphology search is\nguided by human-inspired priors and optimization algorithms, supported by a\npriority buffer that balances reevaluation of promising candidates with the\nexploration of novel designs. Experiments show that \\ourmethod{} achieves an\naverage performance gain of 44.55% on seven public humanoid robots, with\nmorphology optimization drives at least 40% of improvements in co-designing\nfour humanoid robots, underscoring the critical role of humanoid co-design.",
    "categories": [
      "cs.RO",
      "cs.AI"
    ],
    "published": "2025-10-25T15:40:18Z",
    "authors": [
      "Bo Yue",
      "Sheng Xu",
      "Kui Jia",
      "Guiliang Liu"
    ],
    "pdf_url": "http://arxiv.org/pdf/2510.22336v1"
  },
  {
    "id": "2510.22335v1",
    "title": "Moving Beyond Diffusion: Hierarchy-to-Hierarchy Autoregression for\n  fMRI-to-Image Reconstruction",
    "abstract": "Reconstructing visual stimuli from fMRI signals is a central challenge\nbridging machine learning and neuroscience. Recent diffusion-based methods\ntypically map fMRI activity to a single high-level embedding, using it as fixed\nguidance throughout the entire generation process. However, this fixed guidance\ncollapses hierarchical neural information and is misaligned with the\nstage-dependent demands of image reconstruction. In response, we propose\nMindHier, a coarse-to-fine fMRI-to-image reconstruction framework built on\nscale-wise autoregressive modeling. MindHier introduces three components: a\nHierarchical fMRI Encoder to extract multi-level neural embeddings, a\nHierarchy-to-Hierarchy Alignment scheme to enforce layer-wise correspondence\nwith CLIP features, and a Scale-Aware Coarse-to-Fine Neural Guidance strategy\nto inject these embeddings into autoregression at matching scales. These\ndesigns make MindHier an efficient and cognitively-aligned alternative to\ndiffusion-based methods by enabling a hierarchical reconstruction process that\nsynthesizes global semantics before refining local details, akin to human\nvisual perception. Extensive experiments on the NSD dataset show that MindHier\nachieves superior semantic fidelity, 4.67x faster inference, and more\ndeterministic results than the diffusion-based baselines.",
    "categories": [
      "cs.CV",
      "cs.AI"
    ],
    "published": "2025-10-25T15:40:07Z",
    "authors": [
      "Xu Zhang",
      "Ruijie Quan",
      "Wenguan Wang",
      "Yi Yang"
    ],
    "pdf_url": "http://arxiv.org/pdf/2510.22335v1"
  },
  {
    "id": "2510.22334v1",
    "title": "Multilingual Target-Stance Extraction",
    "abstract": "Social media enables data-driven analysis of public opinion on contested\nissues. Target-Stance Extraction (TSE) is the task of identifying the target\ndiscussed in a document and the document's stance towards that target. Many\nworks classify stance towards a given target in a multilingual setting, but all\nprior work in TSE is English-only. This work introduces the first multilingual\nTSE benchmark, spanning Catalan, Estonian, French, Italian, Mandarin, and\nSpanish corpora. It manages to extend the original TSE pipeline to a\nmultilingual setting without requiring separate models for each language. Our\nmodel pipeline achieves a modest F1 score of 12.78, underscoring the increased\ndifficulty of the multilingual task relative to English-only setups and\nhighlighting target prediction as the primary bottleneck. We are also the first\nto demonstrate the sensitivity of TSE's F1 score to different target\nverbalizations. Together these serve as a much-needed baseline for resources,\nalgorithms, and evaluation criteria in multilingual TSE.",
    "categories": [
      "cs.CL",
      "cs.AI"
    ],
    "published": "2025-10-25T15:38:15Z",
    "authors": [
      "Ethan Mines",
      "Bonnie Dorr"
    ],
    "pdf_url": "http://arxiv.org/pdf/2510.22334v1"
  },
  {
    "id": "2510.22333v1",
    "title": "LIFT: Interpretable truck driving risk prediction with\n  literature-informed fine-tuned LLMs",
    "abstract": "This study proposes an interpretable prediction framework with\nliterature-informed fine-tuned (LIFT) LLMs for truck driving risk prediction.\nThe framework integrates an LLM-driven Inference Core that predicts and\nexplains truck driving risk, a Literature Processing Pipeline that filters and\nsummarizes domain-specific literature into a literature knowledge base, and a\nResult Evaluator that evaluates the prediction performance as well as the\ninterpretability of the LIFT LLM. After fine-tuning on a real-world truck\ndriving risk dataset, the LIFT LLM achieved accurate risk prediction,\noutperforming benchmark models by 26.7% in recall and 10.1% in F1-score.\nFurthermore, guided by the literature knowledge base automatically constructed\nfrom 299 domain papers, the LIFT LLM produced variable importance ranking\nconsistent with that derived from the benchmark model, while demonstrating\nrobustness in interpretation results to various data sampling conditions. The\nLIFT LLM also identified potential risky scenarios by detecting key combination\nof variables in truck driving risk, which were verified by PERMANOVA tests.\nFinally, we demonstrated the contribution of the literature knowledge base and\nthe fine-tuning process in the interpretability of the LIFT LLM, and discussed\nthe potential of the LIFT LLM in data-driven knowledge discovery.",
    "categories": [
      "cs.AI",
      "cs.LG"
    ],
    "published": "2025-10-25T15:37:56Z",
    "authors": [
      "Xiao Hu",
      "Yuansheng Lian",
      "Ke Zhang",
      "Yunxuan Li",
      "Yuelong Su",
      "Meng Li"
    ],
    "pdf_url": "http://arxiv.org/pdf/2510.22333v1"
  },
  {
    "id": "2510.22329v1",
    "title": "Graph-Coarsening Approach for the Capacitated Vehicle Routing Problem\n  with Time Windows",
    "abstract": "The Capacitated Vehicle Routing Problem with Time Windows (CVRPTW) is a\nfundamental NP-hard optimization problem in logistics. Solving large-scale\ninstances remains computationally challenging for exact solvers. This work\nintroduces a multilevel graph coarsening and refinement framework that\naggregates customers into meta-nodes using a spatio-temporal distance metric.\nThe reduced problem is solved with classical heuristics and subsequently\nexpanded back into the original space with feasibility corrections. Preliminary\nexperiments on Solomon benchmark instances show that the proposed method\nreduces computation time while preserving or improving solution quality,\nparticularly with respect to capacity and time window constraints. The paper\nalso explores the integration of quantum-inspired optimization techniques,\nhighlighting their potential to further accelerate large-scale vehicle routing\ntasks.",
    "categories": [
      "cs.AI",
      "math.OC",
      "90C59, 90C27",
      "G.2.2; I.2.8; F.2.2"
    ],
    "published": "2025-10-25T15:13:41Z",
    "authors": [
      "Mustafa Mert \u00d6zy\u0131lmaz"
    ],
    "pdf_url": "http://arxiv.org/pdf/2510.22329v1"
  },
  {
    "id": "2510.22318v1",
    "title": "Harnessing the Power of Large Language Models for Software Testing\n  Education: A Focus on ISTQB Syllabus",
    "abstract": "Software testing is a critical component in the software engineering field\nand is important for software engineering education. Thus, it is vital for\nacademia to continuously improve and update educational methods to reflect the\ncurrent state of the field. The International Software Testing Qualifications\nBoard (ISTQB) certification framework is globally recognized and widely adopted\nin industry and academia. However, ISTQB-based learning has been rarely applied\nwith recent generative artificial intelligence advances. Despite the growing\ncapabilities of large language models (LLMs), ISTQB-based learning and\ninstruction with LLMs have not been thoroughly explored. This paper explores\nand evaluates how LLMs can complement the ISTQB framework for higher education.\nThe findings present four key contributions: (i) the creation of a\ncomprehensive ISTQB-aligned dataset spanning over a decade, consisting of 28\nsample exams and 1,145 questions; (ii) the development of a domain-optimized\nprompt that enhances LLM precision and explanation quality on ISTQB tasks;\n(iii) a systematic evaluation of state-of-the-art LLMs on this dataset; and\n(iv) actionable insights and recommendations for integrating LLMs into software\ntesting education. These findings highlight the promise of LLMs in supporting\nISTQB certification preparation and offer a foundation for their broader use in\nsoftware engineering at higher education.",
    "categories": [
      "cs.SE",
      "cs.AI",
      "K.3.2, D.2.5"
    ],
    "published": "2025-10-25T14:45:58Z",
    "authors": [
      "Tuan-Phong Ngo",
      "Bao-Ngoc Duong",
      "Tuan-Anh Hoang",
      "Joshua Dwight",
      "Ushik Shrestha Khwakhali"
    ],
    "pdf_url": "http://arxiv.org/pdf/2510.22318v1"
  },
  {
    "id": "2510.22312v1",
    "title": "LacMaterial: Large Language Models as Analogical Chemists for Materials\n  Discovery",
    "abstract": "Analogical reasoning, the transfer of relational structures across contexts\n(e.g., planet is to sun as electron is to nucleus), is fundamental to\nscientific discovery. Yet human insight is often constrained by domain\nexpertise and surface-level biases, limiting access to deeper, structure-driven\nanalogies both within and across disciplines. Large language models (LLMs),\ntrained on vast cross-domain data, present a promising yet underexplored tool\nfor analogical reasoning in science. Here, we demonstrate that LLMs can\ngenerate novel battery materials by (1) retrieving cross-domain analogs and\nanalogy-guided exemplars to steer exploration beyond conventional dopant\nsubstitutions, and (2) constructing in-domain analogical templates from few\nlabeled examples to guide targeted exploitation. These explicit analogical\nreasoning strategies yield candidates outside established compositional spaces\nand outperform standard prompting baselines. Our findings position LLMs as\ninterpretable, expert-like hypothesis generators that leverage analogy-driven\ngeneralization for scientific innovation.",
    "categories": [
      "cs.LG",
      "cs.AI"
    ],
    "published": "2025-10-25T14:25:26Z",
    "authors": [
      "Hongyu Guo"
    ],
    "pdf_url": "http://arxiv.org/pdf/2510.22312v1"
  },
  {
    "id": "2510.22301v1",
    "title": "AnyECG-Lab: An Exploration Study of Fine-tuning an ECG Foundation Model\n  to Estimate Laboratory Values from Single-Lead ECG Signals",
    "abstract": "Timely access to laboratory values is critical for clinical decision-making,\nyet current approaches rely on invasive venous sampling and are intrinsically\ndelayed. Electrocardiography (ECG), as a non-invasive and widely available\nsignal, offers a promising modality for rapid laboratory estimation. Recent\nprogress in deep learning has enabled the extraction of latent hematological\nsignatures from ECGs. However, existing models are constrained by low\nsignal-to-noise ratios, substantial inter-individual variability, limited data\ndiversity, and suboptimal generalization, especially when adapted to low-lead\nwearable devices. In this work, we conduct an exploratory study leveraging\ntransfer learning to fine-tune ECGFounder, a large-scale pre-trained ECG\nfoundation model, on the Multimodal Clinical Monitoring in the Emergency\nDepartment (MC-MED) dataset from Stanford. We generated a corpus of more than\n20 million standardized ten-second ECG segments to enhance sensitivity to\nsubtle biochemical correlates. On internal validation, the model demonstrated\nstrong predictive performance (area under the curve above 0.65) for\nthirty-three laboratory indicators, moderate performance (between 0.55 and\n0.65) for fifty-nine indicators, and limited performance (below 0.55) for\nsixteen indicators. This study provides an efficient artificial-intelligence\ndriven solution and establishes the feasibility scope for real-time,\nnon-invasive estimation of laboratory values.",
    "categories": [
      "cs.LG",
      "cs.AI"
    ],
    "published": "2025-10-25T14:04:26Z",
    "authors": [
      "Yujie Xiao",
      "Gongzhen Tang",
      "Wenhui Liu",
      "Jun Li",
      "Guangkun Nie",
      "Zhuoran Kan",
      "Deyun Zhang",
      "Qinghao Zhao",
      "Shenda Hong"
    ],
    "pdf_url": "http://arxiv.org/pdf/2510.22301v1"
  },
  {
    "id": "2510.22300v1",
    "title": "T2I-RiskyPrompt: A Benchmark for Safety Evaluation, Attack, and Defense\n  on Text-to-Image Model",
    "abstract": "Using risky text prompts, such as pornography and violent prompts, to test\nthe safety of text-to-image (T2I) models is a critical task. However, existing\nrisky prompt datasets are limited in three key areas: 1) limited risky\ncategories, 2) coarse-grained annotation, and 3) low effectiveness. To address\nthese limitations, we introduce T2I-RiskyPrompt, a comprehensive benchmark\ndesigned for evaluating safety-related tasks in T2I models. Specifically, we\nfirst develop a hierarchical risk taxonomy, which consists of 6 primary\ncategories and 14 fine-grained subcategories. Building upon this taxonomy, we\nconstruct a pipeline to collect and annotate risky prompts. Finally, we obtain\n6,432 effective risky prompts, where each prompt is annotated with both\nhierarchical category labels and detailed risk reasons. Moreover, to facilitate\nthe evaluation, we propose a reason-driven risky image detection method that\nexplicitly aligns the MLLM with safety annotations. Based on T2I-RiskyPrompt,\nwe conduct a comprehensive evaluation of eight T2I models, nine defense\nmethods, five safety filters, and five attack strategies, offering nine key\ninsights into the strengths and limitations of T2I model safety. Finally, we\ndiscuss potential applications of T2I-RiskyPrompt across various research\nfields. The dataset and code are provided in\nhttps://github.com/datar001/T2I-RiskyPrompt.",
    "categories": [
      "cs.CR",
      "cs.AI",
      "cs.CV"
    ],
    "published": "2025-10-25T14:00:26Z",
    "authors": [
      "Chenyu Zhang",
      "Tairen Zhang",
      "Lanjun Wang",
      "Ruidong Chen",
      "Wenhui Li",
      "Anan Liu"
    ],
    "pdf_url": "http://arxiv.org/pdf/2510.22300v1"
  },
  {
    "id": "2510.22295v1",
    "title": "VietLyrics: A Large-Scale Dataset and Models for Vietnamese Automatic\n  Lyrics Transcription",
    "abstract": "Automatic Lyrics Transcription (ALT) for Vietnamese music presents unique\nchallenges due to its tonal complexity and dialectal variations, but remains\nlargely unexplored due to the lack of a dedicated dataset. Therefore, we\ncurated the first large-scale Vietnamese ALT dataset (VietLyrics), comprising\n647 hours of songs with line-level aligned lyrics and metadata to address these\nissues. Our evaluation of current ASRbased approaches reveal significant\nlimitations, including frequent transcription errors and hallucinations in\nnon-vocal segments. To improve performance, we fine-tuned Whisper models on the\nVietLyrics dataset, achieving superior results compared to existing\nmultilingual ALT systems, including LyricWhiz. We publicly release VietLyrics\nand our models, aiming to advance Vietnamese music computing research while\ndemonstrating the potential of this approach for ALT in low-resource language\nand music.",
    "categories": [
      "cs.AI",
      "cs.CL"
    ],
    "published": "2025-10-25T13:38:20Z",
    "authors": [
      "Quoc Anh Nguyen",
      "Bernard Cheng",
      "Kelvin Soh"
    ],
    "pdf_url": "http://arxiv.org/pdf/2510.22295v1"
  },
  {
    "id": "2510.24777v1",
    "title": "Cross-Enhanced Multimodal Fusion of Eye-Tracking and Facial Features for\n  Alzheimer's Disease Diagnosis",
    "abstract": "Accurate diagnosis of Alzheimer's disease (AD) is essential for enabling\ntimely intervention and slowing disease progression. Multimodal diagnostic\napproaches offer considerable promise by integrating complementary information\nacross behavioral and perceptual domains. Eye-tracking and facial features, in\nparticular, are important indicators of cognitive function, reflecting\nattentional distribution and neurocognitive state. However, few studies have\nexplored their joint integration for auxiliary AD diagnosis. In this study, we\npropose a multimodal cross-enhanced fusion framework that synergistically\nleverages eye-tracking and facial features for AD detection. The framework\nincorporates two key modules: (a) a Cross-Enhanced Fusion Attention Module\n(CEFAM), which models inter-modal interactions through cross-attention and\nglobal enhancement, and (b) a Direction-Aware Convolution Module (DACM), which\ncaptures fine-grained directional facial features via horizontal-vertical\nreceptive fields. Together, these modules enable adaptive and discriminative\nmultimodal representation learning. To support this work, we constructed a\nsynchronized multimodal dataset, including 25 patients with AD and 25 healthy\ncontrols (HC), by recording aligned facial video and eye-tracking sequences\nduring a visual memory-search paradigm, providing an ecologically valid\nresource for evaluating integration strategies. Extensive experiments on this\ndataset demonstrate that our framework outperforms traditional late fusion and\nfeature concatenation methods, achieving a classification accuracy of 95.11% in\ndistinguishing AD from HC, highlighting superior robustness and diagnostic\nperformance by explicitly modeling inter-modal dependencies and\nmodality-specific contributions.",
    "categories": [
      "cs.CV",
      "cs.AI",
      "eess.IV",
      "68T07",
      "I.2; H.5.1"
    ],
    "published": "2025-10-25T13:30:24Z",
    "authors": [
      "Yujie Nie",
      "Jianzhang Ni",
      "Yonglong Ye",
      "Yuan-Ting Zhang",
      "Yun Kwok Wing",
      "Xiangqing Xu",
      "Xin Ma",
      "Lizhou Fan"
    ],
    "pdf_url": "http://arxiv.org/pdf/2510.24777v1"
  },
  {
    "id": "2510.22289v1",
    "title": "Does Homophily Help in Robust Test-time Node Classification?",
    "abstract": "Homophily, the tendency of nodes from the same class to connect, is a\nfundamental property of real-world graphs, underpinning structural and semantic\npatterns in domains such as citation networks and social networks. Existing\nmethods exploit homophily through designing homophily-aware GNN architectures\nor graph structure learning strategies, yet they primarily focus on GNN\nlearning with training graphs. However, in real-world scenarios, test graphs\noften suffer from data quality issues and distribution shifts, such as domain\nshifts across users from different regions in social networks and temporal\nevolution shifts in citation network graphs collected over varying time\nperiods. These factors significantly compromise the pre-trained model's\nrobustness, resulting in degraded test-time performance. With empirical\nobservations and theoretical analysis, we reveal that transforming the test\ngraph structure by increasing homophily in homophilic graphs or decreasing it\nin heterophilic graphs can significantly improve the robustness and performance\nof pre-trained GNNs on node classifications, without requiring model training\nor update. Motivated by these insights, a novel test-time graph structural\ntransformation method grounded in homophily, named GrapHoST, is proposed.\nSpecifically, a homophily predictor is developed to discriminate test edges,\nfacilitating adaptive test-time graph structural transformation by the\nconfidence of predicted homophily scores. Extensive experiments on nine\nbenchmark datasets under a range of test-time data quality issues demonstrate\nthat GrapHoST consistently achieves state-of-the-art performance, with\nimprovements of up to 10.92%. Our code has been released at\nhttps://github.com/YanJiangJerry/GrapHoST.",
    "categories": [
      "cs.LG",
      "cs.AI"
    ],
    "published": "2025-10-25T13:17:28Z",
    "authors": [
      "Yan Jiang",
      "Ruihong Qiu",
      "Zi Huang"
    ],
    "pdf_url": "http://arxiv.org/pdf/2510.22289v1"
  },
  {
    "id": "2510.22285v1",
    "title": "Supervised Fine-Tuning or In-Context Learning? Evaluating LLMs for\n  Clinical NER",
    "abstract": "We study clinical Named Entity Recognition (NER) on the CADEC corpus and\ncompare three families of approaches: (i) BERT-style encoders (BERT Base,\nBioClinicalBERT, RoBERTa-large), (ii) GPT-4o used with few-shot in-context\nlearning (ICL) under simple vs.\\ complex prompts, and (iii) GPT-4o with\nsupervised fine-tuning (SFT). All models are evaluated on standard NER metrics\nover CADEC's five entity types (ADR, Drug, Disease, Symptom, Finding).\nRoBERTa-large and BioClinicalBERT offer limited improvements over BERT Base,\nshowing the limit of these family of models. Among LLM settings, simple ICL\noutperforms a longer, instruction-heavy prompt, and SFT achieves the strongest\noverall performance (F1 $\\approx$ 87.1%), albeit with higher cost. We find that\nthe LLM achieve higher accuracy on simplified tasks, restricting classification\nto two labels.",
    "categories": [
      "cs.CL",
      "cs.AI"
    ],
    "published": "2025-10-25T13:08:59Z",
    "authors": [
      "Andrei Baroian"
    ],
    "pdf_url": "http://arxiv.org/pdf/2510.22285v1"
  },
  {
    "id": "2510.22282v1",
    "title": "CityRiSE: Reasoning Urban Socio-Economic Status in Vision-Language\n  Models via Reinforcement Learning",
    "abstract": "Harnessing publicly available, large-scale web data, such as street view and\nsatellite imagery, urban socio-economic sensing is of paramount importance for\nachieving global sustainable development goals. With the emergence of Large\nVision-Language Models (LVLMs), new opportunities have arisen to solve this\ntask by treating it as a multi-modal perception and understanding problem.\nHowever, recent studies reveal that LVLMs still struggle with accurate and\ninterpretable socio-economic predictions from visual data. To address these\nlimitations and maximize the potential of LVLMs, we introduce\n\\textbf{CityRiSE}, a novel framework for \\textbf{R}eason\\textbf{i}ng urban\n\\textbf{S}ocio-\\textbf{E}conomic status in LVLMs through pure reinforcement\nlearning (RL). With carefully curated multi-modal data and verifiable reward\ndesign, our approach guides the LVLM to focus on semantically meaningful visual\ncues, enabling structured and goal-oriented reasoning for generalist\nsocio-economic status prediction. Experiments demonstrate that CityRiSE with\nemergent reasoning process significantly outperforms existing baselines,\nimproving both prediction accuracy and generalization across diverse urban\ncontexts, particularly for prediction on unseen cities and unseen indicators.\nThis work highlights the promise of combining RL and LVLMs for interpretable\nand generalist urban socio-economic sensing.",
    "categories": [
      "cs.CV",
      "cs.AI",
      "cs.CL"
    ],
    "published": "2025-10-25T12:56:46Z",
    "authors": [
      "Tianhui Liu",
      "Hetian Pang",
      "Xin Zhang",
      "Jie Feng",
      "Yong Li",
      "Pan Hui"
    ],
    "pdf_url": "http://arxiv.org/pdf/2510.22282v1"
  },
  {
    "id": "2510.23650v1",
    "title": "Beyond Hidden-Layer Manipulation: Semantically-Aware Logit Interventions\n  for Debiasing LLMs",
    "abstract": "We proposed Static and Dynamic -- two zero-shot logits-layer debiasing\nmethods. Dynamic reduces bias by up to 70% with minimal fluency loss. Logits\nintervention outperforms hidden-layer approaches. We show semantic-aware logits\nintervention is stable and effective for debiasing aligned LLMs.",
    "categories": [
      "cs.LG",
      "cs.AI"
    ],
    "published": "2025-10-25T12:45:00Z",
    "authors": [
      "Wei Xia"
    ],
    "pdf_url": "http://arxiv.org/pdf/2510.23650v1"
  },
  {
    "id": "2510.22266v1",
    "title": "A Multi-level Analysis of Factors Associated with Student Performance: A\n  Machine Learning Approach to the SAEB Microdata",
    "abstract": "Identifying the factors that influence student performance in basic education\nis a central challenge for formulating effective public policies in Brazil.\nThis study introduces a multi-level machine learning approach to classify the\nproficiency of 9th-grade and high school students using microdata from the\nSystem of Assessment of Basic Education (SAEB). Our model uniquely integrates\nfour data sources: student socioeconomic characteristics, teacher professional\nprofiles, school indicators, and director management profiles. A comparative\nanalysis of four ensemble algorithms confirmed the superiority of a Random\nForest model, which achieved 90.2% accuracy and an Area Under the Curve (AUC)\nof 96.7%. To move beyond prediction, we applied Explainable AI (XAI) using\nSHAP, which revealed that the school's average socioeconomic level is the most\ndominant predictor, demonstrating that systemic factors have a greater impact\nthan individual characteristics in isolation. The primary conclusion is that\nacademic performance is a systemic phenomenon deeply tied to the school's\necosystem. This study provides a data-driven, interpretable tool to inform\npolicies aimed at promoting educational equity by addressing disparities\nbetween schools.",
    "categories": [
      "cs.LG",
      "cs.AI",
      "cs.CY"
    ],
    "published": "2025-10-25T12:15:30Z",
    "authors": [
      "Rodrigo Tertulino",
      "Ricardo Almeida"
    ],
    "pdf_url": "http://arxiv.org/pdf/2510.22266v1"
  },
  {
    "id": "2510.22264v1",
    "title": "PatenTEB: A Comprehensive Benchmark and Model Family for Patent Text\n  Embedding",
    "abstract": "Patent text embeddings enable prior art search, technology landscaping, and\npatent analysis, yet existing benchmarks inadequately capture patent-specific\nchallenges. We introduce PatenTEB, a comprehensive benchmark comprising 15\ntasks across retrieval, classification, paraphrase, and clustering, with 2.06\nmillion examples. PatenTEB employs domain-stratified splits, domain specific\nhard negative mining, and systematic coverage of asymmetric\nfragment-to-document matching scenarios absent from general embedding\nbenchmarks. We develop the patembed model family through multi-task training,\nspanning 67M to 344M parameters with context lengths up to 4096 tokens.\nExternal validation shows strong generalization: patembed-base achieves\nstate-of-the-art on MTEB BigPatentClustering.v2 (0.494 V-measure vs. 0.445\nprevious best), while patembed-large achieves 0.377 NDCG@100 on DAPFAM.\nSystematic ablations reveal that multi-task training improves external\ngeneralization despite minor benchmark costs, and that domain-pretrained\ninitialization provides consistent advantages across task families. All\nresources will be made available at https://github.com/iliass-y/patenteb.\nKeywords: patent retrieval, sentence embeddings, multi-task learning,\nasymmetric retrieval, benchmark evaluation, contrastive learning.",
    "categories": [
      "cs.CL",
      "cs.AI",
      "cs.IR",
      "H.3.3; I.2.7; I.2.6"
    ],
    "published": "2025-10-25T12:01:46Z",
    "authors": [
      "Iliass Ayaou",
      "Denis Cavallucci"
    ],
    "pdf_url": "http://arxiv.org/pdf/2510.22264v1"
  },
  {
    "id": "2510.22261v1",
    "title": "Epistemic Deep Learning: Enabling Machine Learning Models to Know When\n  They Do Not Know",
    "abstract": "Machine learning has achieved remarkable successes, yet its deployment in\nsafety-critical domains remains hindered by an inherent inability to manage\nuncertainty, resulting in overconfident and unreliable predictions when models\nencounter out-of-distribution data, adversarial perturbations, or naturally\nfluctuating environments. This thesis, titled Epistemic Deep Learning: Enabling\nMachine Learning Models to 'Know When They Do Not Know', addresses these\ncritical challenges by advancing the paradigm of Epistemic Artificial\nIntelligence, which explicitly models and quantifies epistemic uncertainty: the\nuncertainty arising from limited, biased, or incomplete training data, as\nopposed to the irreducible randomness of aleatoric uncertainty, thereby\nempowering models to acknowledge their limitations and refrain from\noverconfident decisions when uncertainty is high.\n  Central to this work is the development of the Random-Set Neural Network\n(RS-NN), a novel methodology that leverages random set theory to predict belief\nfunctions over sets of classes, capturing the extent of epistemic uncertainty\nthrough the width of associated credal sets, applications of RS-NN, including\nits adaptation to Large Language Models (LLMs) and its deployment in weather\nclassification for autonomous racing. In addition, the thesis proposes a\nunified evaluation framework for uncertainty-aware classifiers. Extensive\nexperiments validate that integrating epistemic awareness into deep learning\nnot only mitigates the risks associated with overconfident predictions but also\nlays the foundation for a paradigm shift in artificial intelligence, where the\nability to 'know when it does not know' becomes a hallmark of robust and\ndependable systems. The title encapsulates the core philosophy of this work,\nemphasizing that true intelligence involves recognizing and managing the limits\nof one's own knowledge.",
    "categories": [
      "cs.LG",
      "cs.AI"
    ],
    "published": "2025-10-25T12:00:19Z",
    "authors": [
      "Shireen Kudukkil Manchingal"
    ],
    "pdf_url": "http://arxiv.org/pdf/2510.22261v1"
  },
  {
    "id": "2510.23649v1",
    "title": "Efficient Low Rank Attention for Long-Context Inference in Large\n  Language Models",
    "abstract": "As the length of input text grows, the key-value (KV) cache in LLMs imposes\nprohibitive GPU memory costs and limits long-context inference on resource\nconstrained devices. Existing approaches, such as KV quantization and pruning,\nreduce memory usage but suffer from numerical precision loss or suboptimal\nretention of key-value pairs. We introduce Low Rank Query and Key attention\n(LRQK), a two-stage framework that jointly decomposes the full-precision query\nand key matrices into compact rank-\\(r\\) factors during the prefill stage, and\nthen uses these low-dimensional projections to compute proxy attention scores\nin \\(\\mathcal{O}(lr)\\) time at each decode step. By selecting only the\ntop-\\(k\\) tokens and a small fixed set of recent tokens, LRQK employs a mixed\nGPU-CPU cache with a hit-and-miss mechanism that transfers only missing\nfull-precision KV pairs, thereby preserving exact attention outputs while\nreducing CPU-GPU data movement. Extensive experiments on the RULER and\nLongBench benchmarks with LLaMA-3-8B and Qwen2.5-7B demonstrate that LRQK\nmatches or surpasses leading sparse-attention methods in long context settings,\nwhile delivering significant memory savings with minimal loss in accuracy. Our\ncode is available at https://github.com/tenghuilee/LRQK.",
    "categories": [
      "cs.LG",
      "cs.AI"
    ],
    "published": "2025-10-25T11:43:27Z",
    "authors": [
      "Tenghui Li",
      "Guoxu Zhou",
      "Xuyang Zhao",
      "Yuning Qiu",
      "Qibin Zhao"
    ],
    "pdf_url": "http://arxiv.org/pdf/2510.23649v1"
  },
  {
    "id": "2510.22257v1",
    "title": "LUNA: Efficient and Topology-Agnostic Foundation Model for EEG Signal\n  Analysis",
    "abstract": "Electroencephalography (EEG) offers a non-invasive lens into human brain\nactivity, but building large-scale models is hampered by topological\nheterogeneity: each public EEG data defines its own electrode layout, limiting\ngeneralization. We introduce LUNA (Latent Unified Network Architecture), a\nself-supervised foundation model that reconciles disparate electrode geometries\nwhile scaling linearly -- not quadratically -- with channel count. LUNA\ncompresses multi-channel EEG into a fixed-size, topology-agnostic latent space\nvia learned queries and cross-attention. Downstream transformer blocks then\noperate exclusively on this latent representation using patch-wise temporal\nself-attention, decoupling computation from electrode count. Pre-trained on\nTUEG and Siena (over 21,000 hours of raw EEG across diverse montages) using a\nmasked-patch reconstruction objective, LUNA transfers effectively to four\ndownstream tasks: abnormality detection, artifact rejection, slowing\nclassification, and emotion recognition. It demonstrates highly competitive\nperformance across several benchmarks, achieving state-of-the-art results on\nTUAR and TUSL, e.g., 0.921 AUROC on TUAR, while reducing FLOPs by 300x and\ntrimming GPU memory use by up to 10x. Critically, these gains are consistent\nacross all evaluated electrode configurations. Code is available at\nhttps://github.com/pulp-bio/BioFoundation",
    "categories": [
      "cs.LG",
      "cs.AI"
    ],
    "published": "2025-10-25T11:31:27Z",
    "authors": [
      "Berkay D\u00f6ner",
      "Thorir Mar Ingolfsson",
      "Luca Benini",
      "Yawei Li"
    ],
    "pdf_url": "http://arxiv.org/pdf/2510.22257v1"
  },
  {
    "id": "2510.22255v1",
    "title": "PACR: Progressively Ascending Confidence Reward for LLM Reasoning",
    "abstract": "Reinforcement Learning with Verifiable Rewards (RLVR) has significantly\nimproved LLM reasoning, but its sparse, outcome-based reward provides no\nguidance for intermediate steps, slowing exploration. We propose Progressively\nAscending Confidence Reward (PACR), a dense, model-intrinsic reward computed\ndirectly from the model's evolving belief in the correct answer. PACR encodes\nthe inductive bias that, along a well-formed reasoning trajectory, the\nprobability of the ground-truth answer should have a generally ascending trend.\nWe provide empirical and theoretical analysis validating that such an inductive\nbias constrains the exploration search space to regions richer in logically\nsound reasoning. We demonstrate that PACR accelerates exploration, reaches\nreward saturation with fewer trajectories, and yields improvements on multiple\nbenchmarks. Our results suggest that dense, model-intrinsic shaping signals can\nmake RLVR training more effective and reliable.",
    "categories": [
      "cs.AI",
      "cs.CL"
    ],
    "published": "2025-10-25T11:25:35Z",
    "authors": [
      "Eunseop Yoon",
      "Hee Suk Yoon",
      "Jaehyun Jang",
      "SooHwan Eom",
      "Qi Dai",
      "Chong Luo",
      "Mark A. Hasegawa-Johnson",
      "Chang D. Yoo"
    ],
    "pdf_url": "http://arxiv.org/pdf/2510.22255v1"
  },
  {
    "id": "2510.22251v1",
    "title": "You Don't Need Prompt Engineering Anymore: The Prompting Inversion",
    "abstract": "Prompt engineering, particularly Chain-of-Thought (CoT) prompting,\nsignificantly enhances LLM reasoning capabilities. We introduce \"Sculpting,\" a\nconstrained, rule-based prompting method designed to improve upon standard CoT\nby reducing errors from semantic ambiguity and flawed common sense.\n  We evaluate three prompting strategies (Zero Shot, standard CoT, and\nSculpting) across three OpenAI model generations (gpt-4o-mini, gpt-4o, gpt-5)\nusing the GSM8K mathematical reasoning benchmark (1,317 problems).\n  Our findings reveal a \"Prompting Inversion\": Sculpting provides advantages on\ngpt-4o (97% vs. 93% for standard CoT), but becomes detrimental on gpt-5 (94.00%\nvs. 96.36% for CoT on full benchmark). We trace this to a\n\"Guardrail-to-Handcuff\" transition where constraints preventing common-sense\nerrors in mid-tier models induce hyper-literalism in advanced models. Our\ndetailed error analysis demonstrates that optimal prompting strategies must\nco-evolve with model capabilities, suggesting simpler prompts for more capable\nmodels.",
    "categories": [
      "cs.CL",
      "cs.AI",
      "cs.LG"
    ],
    "published": "2025-10-25T11:04:01Z",
    "authors": [
      "Imran Khan"
    ],
    "pdf_url": "http://arxiv.org/pdf/2510.22251v1"
  },
  {
    "id": "2510.22243v1",
    "title": "Real-Time Semantic Segmentation on FPGA for Autonomous Vehicles Using\n  LMIINet with the CGRA4ML Framework",
    "abstract": "Semantic segmentation has emerged as a fundamental problem in computer\nvision, gaining particular importance in real-time applications such as\nautonomous driving. The main challenge is achieving high accuracy while\noperating under computational and hardware constraints. In this research, we\npresent an FPGA-based implementation of real-time semantic segmentation\nleveraging the lightweight LMIINet architecture and the Coarse-Grained\nReconfigurable Array for Machine Learning (CGRA4ML) hardware framework. The\nmodel was trained using Quantization-Aware Training (QAT) with 8-bit precision\non the Cityscapes dataset, reducing memory footprint by a factor of four while\nenabling efficient fixed-point computations. Necessary modifications were\napplied to adapt the model to CGRA4ML constraints, including simplifying skip\nconnections, employing hardware-friendly operations such as depthwise-separable\nand 1A-1 convolutions, and redesigning parts of the Flatten Transformer. Our\nimplementation achieves approximately 90% pixel accuracy and 45% mean\nIntersection-over-Union (mIoU), operating in real-time at 20 frames per second\n(FPS) with 50.1 ms latency on the ZCU104 FPGA board. The results demonstrate\nthe potential of CGRA4ML, with its flexibility in mapping modern layers and\noff-chip memory utilization for skip connections, provides a path for\nimplementing advanced semantic segmentation networks on FPGA for real-time\napplications to outperform traditional GPU solutions in terms of power\nefficiency while maintaining competitive accuracy. The code for this project is\npublicly available at https://github.com/STAmirr/ cgra4ml_semantic_segmentation",
    "categories": [
      "cs.CV",
      "cs.AI"
    ],
    "published": "2025-10-25T10:16:22Z",
    "authors": [
      "Amir Mohammad Khadem Hosseini",
      "Sattar Mirzakuchaki"
    ],
    "pdf_url": "http://arxiv.org/pdf/2510.22243v1"
  },
  {
    "id": "2510.22242v1",
    "title": "PaperAsk: A Benchmark for Reliability Evaluation of LLMs in Paper Search\n  and Reading",
    "abstract": "Large Language Models (LLMs) increasingly serve as research assistants, yet\ntheir reliability in scholarly tasks remains under-evaluated. In this work, we\nintroduce PaperAsk, a benchmark that systematically evaluates LLMs across four\nkey research tasks: citation retrieval, content extraction, paper discovery,\nand claim verification. We evaluate GPT-4o, GPT-5, and Gemini-2.5-Flash under\nrealistic usage conditions-via web interfaces where search operations are\nopaque to the user. Through controlled experiments, we find consistent\nreliability failures: citation retrieval fails in 48-98% of multi-reference\nqueries, section-specific content extraction fails in 72-91% of cases, and\ntopical paper discovery yields F1 scores below 0.32, missing over 60% of\nrelevant literature. Further human analysis attributes these failures to the\nuncontrolled expansion of retrieved context and the tendency of LLMs to\nprioritize semantically relevant text over task instructions. Across basic\ntasks, the LLMs display distinct failure behaviors: ChatGPT often withholds\nresponses rather than risk errors, whereas Gemini produces fluent but\nfabricated answers. To address these issues, we develop lightweight reliability\nclassifiers trained on PaperAsk data to identify unreliable outputs. PaperAsk\nprovides a reproducible and diagnostic framework for advancing the reliability\nevaluation of LLM-based scholarly assistance systems.",
    "categories": [
      "cs.IR",
      "cs.AI",
      "cs.CL"
    ],
    "published": "2025-10-25T10:11:29Z",
    "authors": [
      "Yutao Wu",
      "Xiao Liu",
      "Yunhao Feng",
      "Jiale Ding",
      "Xingjun Ma"
    ],
    "pdf_url": "http://arxiv.org/pdf/2510.22242v1"
  },
  {
    "id": "2510.22232v1",
    "title": "Rational Adversaries and the Maintenance of Fragility: A Game-Theoretic\n  Theory of Rational Stagnation",
    "abstract": "Cooperative systems often remain in persistently suboptimal yet stable\nstates. This paper explains such \"rational stagnation\" as an equilibrium\nsustained by a rational adversary whose utility follows the principle of\npotential loss, $u_{D} = U_{ideal} - U_{actual}$. Starting from the Prisoner's\nDilemma, we show that the transformation $u_{i}' = a\\,u_{i} + b\\,u_{j}$ and the\nratio of mutual recognition $w = b/a$ generate a fragile cooperation band\n$[w_{\\min},\\,w_{\\max}]$ where both (C,C) and (D,D) are equilibria. Extending to\na dynamic model with stochastic cooperative payoffs $R_{t}$ and intervention\ncosts $(C_{c},\\,C_{m})$, a Bellman-style analysis yields three strategic\nregimes: immediate destruction, rational stagnation, and intervention\nabandonment. The appendix further generalizes the utility to a\nreference-dependent nonlinear form and proves its stability under reference\nshifts, ensuring robustness of the framework. Applications to social-media\nalgorithms and political trust illustrate how adversarial rationality can\ndeliberately preserve fragility.",
    "categories": [
      "cs.GT",
      "cs.AI",
      "econ.TH"
    ],
    "published": "2025-10-25T09:28:15Z",
    "authors": [
      "Daisuke Hirota"
    ],
    "pdf_url": "http://arxiv.org/pdf/2510.22232v1"
  },
  {
    "id": "2510.22228v1",
    "title": "When Fewer Layers Break More Chains: Layer Pruning Harms Test-Time\n  Scaling in LLMs",
    "abstract": "Layer pruning has emerged as a widely adopted technique for improving the\nefficiency of large language models (LLMs). Although existing methods\ndemonstrate strong performance retention on general knowledge tasks, their\neffect on long-chain reasoning, a more brittle yet crucial capability, remains\nlargely unexplored. In this work, we study the impact of layer pruning on\nlong-chain reasoning through the lens of test-time scaling, a key mechanism in\nmodern LLMs that enables strong reasoning capacity by allocating more\ncomputation at inference time. With extensive experiments, we demonstrate that\npruning even one or two layers can severely impair test-time scaling, with\nperformance collapsing drastically on long reasoning benchmarks even when\nperformance on knowledge-intensive and shallow reasoning tasks remains stable.\nFurthermore, we find that standard supervised fine-tuning remedies fail to\nrecover test-time scaling once it has deteriorated. Through in-depth analyses,\nwe identify the mechanisms underlying this fragility of test-time scaling and\nhighlight the fundamental risks of applying layer pruning to\nreasoning-intensive LLMs. These findings call for a rethinking of layer pruning\nstrategies and provide insights for developing methods that preserve the\nrobustness of reasoning. We open-source the codebase in\n\\href{https://github.com/keyu-wang-2002/Layer-Pruning-Harms-Inference-Scaling}{https://github.com/keyu-wang-2002/Layer-Pruning-Harms-Inference-Scaling}.",
    "categories": [
      "cs.LG",
      "cs.AI"
    ],
    "published": "2025-10-25T09:22:22Z",
    "authors": [
      "Keyu Wang",
      "Tian Lyu",
      "Guinan Su",
      "Jonas Geiping",
      "Lu Yin",
      "Marco Canini",
      "Shiwei Liu"
    ],
    "pdf_url": "http://arxiv.org/pdf/2510.22228v1"
  },
  {
    "id": "2510.22224v1",
    "title": "Taming Silent Failures: A Framework for Verifiable AI Reliability",
    "abstract": "The integration of Artificial Intelligence (AI) into safety-critical systems\nintroduces a new reliability paradigm: silent failures, where AI produces\nconfident but incorrect outputs that can be dangerous. This paper introduces\nthe Formal Assurance and Monitoring Environment (FAME), a novel framework that\nconfronts this challenge. FAME synergizes the mathematical rigor of offline\nformal synthesis with the vigilance of online runtime monitoring to create a\nverifiable safety net around opaque AI components. We demonstrate its efficacy\nin an autonomous vehicle perception system, where FAME successfully detected\n93.5% of critical safety violations that were otherwise silent. By\ncontextualizing our framework within the ISO 26262 and ISO/PAS 8800 standards,\nwe provide reliability engineers with a practical, certifiable pathway for\ndeploying trustworthy AI. FAME represents a crucial shift from accepting\nprobabilistic performance to enforcing provable safety in next-generation\nsystems.",
    "categories": [
      "cs.SE",
      "cs.AI",
      "cs.LG",
      "cs.LO",
      "cs.SY",
      "eess.SY"
    ],
    "published": "2025-10-25T09:07:47Z",
    "authors": [
      "Guan-Yan Yang",
      "Farn Wang"
    ],
    "pdf_url": "http://arxiv.org/pdf/2510.22224v1"
  },
  {
    "id": "2510.22219v1",
    "title": "Estimating the Error of Large Language Models at Pairwise Text\n  Comparison",
    "abstract": "We measure LLMs' output error at pairwise text comparison, noting the\nprobability of error in their preferences. Our method does not rely on the\nground truth and supports two scenarios: (i) uniform error rate regardless of\nthe order of comparison, estimated with two comparisons for each text pair with\neither text placed first; (ii) binary positional bias assuming distinct error\nrates for the two orders of comparison, estimated with repeated comparisons\nbetween the texts. The Copeland counting constructs a ranking over the compared\ntexts from pairwise preferences; the ranking reveals the poor scalability of\nLLM-based pairwise comparison and helps yield the estimates for LLMs' error\nrates. We apply the method to six LLMs (ChatGPT, Claude, DeepSeek, Gemini,\nGrok, Qwen) with five types of text input and obtain consistent estimates of\nLLMs' error. In general, the measured two positional bias terms are similar,\nclose to the uniform error. Considering both the error rates and the robustness\nto the variation of prompts, Claude obtained the most desirable performance in\nthis experiment. Our model outperforms the biased Bradley-Terry model and the\ncommutativity score in indicating LLMs' error at this task.",
    "categories": [
      "cs.CL",
      "cs.AI",
      "math.PR"
    ],
    "published": "2025-10-25T08:39:52Z",
    "authors": [
      "Tianyi Li"
    ],
    "pdf_url": "http://arxiv.org/pdf/2510.22219v1"
  },
  {
    "id": "2510.22214v1",
    "title": "GALA: A GlobAl-LocAl Approach for Multi-Source Active Domain Adaptation",
    "abstract": "Domain Adaptation (DA) provides an effective way to tackle target-domain\ntasks by leveraging knowledge learned from source domains. Recent studies have\nextended this paradigm to Multi-Source Domain Adaptation (MSDA), which exploits\nmultiple source domains carrying richer and more diverse transferable\ninformation. However, a substantial performance gap still remains between\nadaptation-based methods and fully supervised learning. In this paper, we\nexplore a more practical and challenging setting, named Multi-Source Active\nDomain Adaptation (MS-ADA), to further enhance target-domain performance by\nselectively acquiring annotations from the target domain. The key difficulty of\nMS-ADA lies in designing selection criteria that can jointly handle inter-class\ndiversity and multi-source domain variation. To address these challenges, we\npropose a simple yet effective GALA strategy (GALA), which combines a global\nk-means clustering step for target-domain samples with a cluster-wise local\nselection criterion, effectively tackling the above two issues in a\ncomplementary manner. Our proposed GALA is plug-and-play and can be seamlessly\nintegrated into existing DA frameworks without introducing any additional\ntrainable parameters. Extensive experiments on three standard DA benchmarks\ndemonstrate that GALA consistently outperforms prior active learning and active\nDA methods, achieving performance comparable to the fully-supervised upperbound\nwhile using only 1% of the target annotations.",
    "categories": [
      "cs.CV",
      "cs.AI"
    ],
    "published": "2025-10-25T08:26:45Z",
    "authors": [
      "Juepeng Zheng",
      "Peifeng Zhang",
      "Yibin Wen",
      "Qingmei Li",
      "Yang Zhang",
      "Haohuan Fu"
    ],
    "pdf_url": "http://arxiv.org/pdf/2510.22214v1"
  },
  {
    "id": "2510.22210v1",
    "title": "LSPRAG: LSP-Guided RAG for Language-Agnostic Real-Time Unit Test\n  Generation",
    "abstract": "Automated unit test generation is essential for robust software development,\nyet existing approaches struggle to generalize across multiple programming\nlanguages and operate within real-time development. While Large Language Models\n(LLMs) offer a promising solution, their ability to generate high coverage test\ncode depends on prompting a concise context of the focal method. Current\nsolutions, such as Retrieval-Augmented Generation, either rely on imprecise\nsimilarity-based searches or demand the creation of costly, language-specific\nstatic analysis pipelines. To address this gap, we present LSPRAG, a framework\nfor concise-context retrieval tailored for real-time, language-agnostic unit\ntest generation. LSPRAG leverages off-the-shelf Language Server Protocol (LSP)\nback-ends to supply LLMs with precise symbol definitions and references in real\ntime. By reusing mature LSP servers, LSPRAG provides an LLM with language-aware\ncontext retrieval, requiring minimal per-language engineering effort. We\nevaluated LSPRAG on open-source projects spanning Java, Go, and Python.\nCompared to the best performance of baselines, LSPRAG increased line coverage\nby up to 174.55% for Golang, 213.31% for Java, and 31.57% for Python.",
    "categories": [
      "cs.SE",
      "cs.AI",
      "D.2.5"
    ],
    "published": "2025-10-25T08:19:21Z",
    "authors": [
      "Gwihwan Go",
      "Quan Zhang",
      "Chijin Zhou",
      "Zhao Wei",
      "Yu Jiang"
    ],
    "pdf_url": "http://arxiv.org/pdf/2510.22210v1"
  },
  {
    "id": "2510.22206v1",
    "title": "Right Place, Right Time: Market Simulation-based RL for Execution\n  Optimisation",
    "abstract": "Execution algorithms are vital to modern trading, they enable market\nparticipants to execute large orders while minimising market impact and\ntransaction costs. As these algorithms grow more sophisticated, optimising them\nbecomes increasingly challenging. In this work, we present a reinforcement\nlearning (RL) framework for discovering optimal execution strategies, evaluated\nwithin a reactive agent-based market simulator. This simulator creates reactive\norder flow and allows us to decompose slippage into its constituent components:\nmarket impact and execution risk. We assess the RL agent's performance using\nthe efficient frontier based on work by Almgren and Chriss, measuring its\nability to balance risk and cost. Results show that the RL-derived strategies\nconsistently outperform baselines and operate near the efficient frontier,\ndemonstrating a strong ability to optimise for risk and impact. These findings\nhighlight the potential of reinforcement learning as a powerful tool in the\ntrader's toolkit.",
    "categories": [
      "q-fin.CP",
      "cs.AI",
      "cs.LG",
      "q-fin.RM",
      "q-fin.TR"
    ],
    "published": "2025-10-25T08:10:18Z",
    "authors": [
      "Ollie Olby",
      "Andreea Bacalum",
      "Rory Baggott",
      "Namid Stillman"
    ],
    "pdf_url": "http://arxiv.org/pdf/2510.22206v1"
  },
  {
    "id": "2510.22204v1",
    "title": "Bridging Perception and Reasoning: Dual-Pipeline Neuro-Symbolic Landing\n  for UAVs in Cluttered Environments",
    "abstract": "Autonomous landing in unstructured (cluttered, uneven, and map-poor)\nenvironments is a core requirement for Unmanned Aerial Vehicles (UAVs), yet\npurely vision-based or deep learning models often falter under covariate shift\nand provide limited interpretability. We propose NeuroSymLand, a neuro-symbolic\nframework that tightly couples two complementary pipelines: (i) an offline\npipeline, where Large Language Models (LLMs) and human-in-the-loop refinement\nsynthesize Scallop code from diverse landing scenarios, distilling\ngeneralizable and verifiable symbolic knowledge; and (ii) an online pipeline,\nwhere a compact foundation-based semantic segmentation model generates\nprobabilistic Scallop facts that are composed into semantic scene graphs for\nreal-time deductive reasoning. This design combines the perceptual strengths of\nlightweight foundation models with the interpretability and verifiability of\nsymbolic reasoning. Node attributes (e.g., flatness, area) and edge relations\n(adjacency, containment, proximity) are computed with geometric routines rather\nthan learned, avoiding the data dependence and latency of train-time graph\nbuilders. The resulting Scallop program encodes landing principles (avoid water\nand obstacles; prefer large, flat, accessible regions) and yields calibrated\nsafety scores with ranked Regions of Interest (ROIs) and human-readable\njustifications. Extensive evaluations across datasets, diverse simulation maps,\nand real UAV hardware show that NeuroSymLand achieves higher accuracy, stronger\nrobustness to covariate shift, and superior efficiency compared with\nstate-of-the-art baselines, while advancing UAV safety and reliability in\nemergency response, surveillance, and delivery missions.",
    "categories": [
      "cs.RO",
      "cs.AI"
    ],
    "published": "2025-10-25T08:08:04Z",
    "authors": [
      "Weixian Qian",
      "Sebastian Schroder",
      "Yao Deng",
      "Jiaohong Yao",
      "Linfeng Liang",
      "Xiao Cheng",
      "Richard Han",
      "Xi Zheng"
    ],
    "pdf_url": "http://arxiv.org/pdf/2510.22204v1"
  },
  {
    "id": "2510.22197v1",
    "title": "Multi-dataset Joint Pre-training of Emotional EEG Enables Generalizable\n  Affective Computing",
    "abstract": "Task-specific pre-training is essential when task representations diverge\nfrom generic pre-training features. Existing task-general pre-training EEG\nmodels struggle with complex tasks like emotion recognition due to mismatches\nbetween task-specific features and broad pre-training approaches. This work\naims to develop a task-specific multi-dataset joint pre-training framework for\ncross-dataset emotion recognition, tackling problems of large inter-dataset\ndistribution shifts, inconsistent emotion category definitions, and substantial\ninter-subject variability. We introduce a cross-dataset covariance alignment\nloss to align second-order statistical properties across datasets, enabling\nrobust generalization without the need for extensive labels or per-subject\ncalibration. To capture the long-term dependency and complex dynamics of EEG,\nwe propose a hybrid encoder combining a Mamba-like linear attention channel\nencoder and a spatiotemporal dynamics model. Our method outperforms\nstate-of-the-art large-scale EEG models by an average of 4.57% in AUROC for\nfew-shot emotion recognition and 11.92% in accuracy for zero-shot\ngeneralization to a new dataset. Performance scales with the increase of\ndatasets used in pre-training. Multi-dataset joint pre-training achieves a\nperformance gain of 8.55% over single-dataset training. This work provides a\nscalable framework for task-specific pre-training and highlights its benefit in\ngeneralizable affective computing. Our code is available at\nhttps://github.com/ncclab-sustech/mdJPT_nips2025.",
    "categories": [
      "cs.LG",
      "cs.AI",
      "q-bio.NC"
    ],
    "published": "2025-10-25T07:30:24Z",
    "authors": [
      "Qingzhu Zhang",
      "Jiani Zhong",
      "Zongsheng Li",
      "Xinke Shen",
      "Quanying Liu"
    ],
    "pdf_url": "http://arxiv.org/pdf/2510.22197v1"
  },
  {
    "id": "2510.22196v1",
    "title": "Scaling Non-Parametric Sampling with Representation",
    "abstract": "Scaling and architectural advances have produced strikingly photorealistic\nimage generative models, yet their mechanisms still remain opaque. Rather than\nadvancing scaling, our goal is to strip away complicated engineering tricks and\npropose a simple, non-parametric generative model. Our design is grounded in\nthree principles of natural images-(i) spatial non-stationarity, (ii) low-level\nregularities, and (iii) high-level semantics-and defines each pixel's\ndistribution from its local context window. Despite its minimal architecture\nand no training, the model produces high-fidelity samples on MNIST and visually\ncompelling CIFAR-10 images. This combination of simplicity and strong empirical\nperformance points toward a minimal theory of natural-image structure. The\nmodel's white-box nature also allows us to have a mechanistic understanding of\nhow the model generalizes and generates diverse images. We study it by tracing\neach generated pixel back to its source images. These analyses reveal a simple,\ncompositional procedure for \"part-whole generalization\", suggesting a\nhypothesis for how large neural network generative models learn to generalize.",
    "categories": [
      "cs.CV",
      "cs.AI"
    ],
    "published": "2025-10-25T07:29:26Z",
    "authors": [
      "Vincent Lu",
      "Aaron Truong",
      "Zeyu Yun",
      "Yubei Chen"
    ],
    "pdf_url": "http://arxiv.org/pdf/2510.22196v1"
  },
  {
    "id": "2510.22192v1",
    "title": "OptiTree: Hierarchical Thoughts Generation with Tree Search for LLM\n  Optimization Modeling",
    "abstract": "Optimization modeling is one of the most crucial but technical parts of\noperations research (OR). To automate the modeling process, existing works have\nleveraged large language models (LLMs), prompting them to break down tasks into\nsteps for generating variables, constraints, and objectives. However, due to\nthe highly complex mathematical structures inherent in OR problems, standard\nfixed-step decomposition often fails to achieve high performance. To address\nthis challenge, we introduce OptiTree, a novel tree search approach designed to\nenhance modeling capabilities for complex problems through adaptive problem\ndecomposition into simpler subproblems. Specifically, we develop a modeling\ntree that organizes a wide range of OR problems based on their hierarchical\nproblem taxonomy and complexity, with each node representing a problem category\nand containing relevant high-level modeling thoughts. Given a problem to model,\nwe recurrently search the tree to identify a series of simpler subproblems and\nsynthesize the global modeling thoughts by adaptively integrating the\nhierarchical thoughts. Experiments show that OptiTree significantly improves\nthe modeling accuracy compared to the state-of-the-art, achieving over 10\\%\nimprovements on the challenging benchmarks. The code is released at\nhttps://github.com/MIRALab-USTC/OptiTree/tree/main.",
    "categories": [
      "cs.AI"
    ],
    "published": "2025-10-25T07:19:16Z",
    "authors": [
      "Haoyang Liu",
      "Jie Wang",
      "Yuyang Cai",
      "Xiongwei Han",
      "Yufei Kuang",
      "Jianye Hao"
    ],
    "pdf_url": "http://arxiv.org/pdf/2510.22192v1"
  },
  {
    "id": "2510.22178v1",
    "title": "Dopamine-driven synaptic credit assignment in neural networks",
    "abstract": "Solving the synaptic Credit Assignment Problem(CAP) is central to learning in\nboth biological and artificial neural systems. Finding an optimal solution for\nsynaptic CAP means setting the synaptic weights that assign credit to each\nneuron for influencing the final output and behavior of neural networks or\nanimals. Gradient-based methods solve this problem in artificial neural\nnetworks using back-propagation, however, not in the most efficient way. For\ninstance, back-propagation requires a chain of top-down gradient computations.\nThis leads to an expensive optimization process in terms of computing power and\nmemory linked with well-known weight transport and update locking problems. To\naddress these shortcomings, we take a NeuroAI approach and draw inspiration\nfrom neural Reinforcement Learning to develop a derivative-free optimizer for\ntraining neural networks, Dopamine. Dopamine is developed for Weight\nPerturbation (WP) learning that exploits stochastic updating of weights towards\noptima. It achieves this by minimizing the regret, a form of Reward Prediction\nError (RPE) between the expected outcome from the perturbed model and the\nactual outcome from the unperturbed model. We use this RPE to adjust the\nlearning rate in the network (i.e., creating an adaptive learning rate\nstrategy, similar to the role of dopamine in the brain). We tested the Dopamine\noptimizer for training multi-layered perceptrons for XOR tasks, and recurrent\nneural networks for chaotic time series forecasting. Dopamine-trained models\ndemonstrate accelerated convergence and outperform standard WP, and give\ncomparable performance to gradient-based algorithms, while consuming\nsignificantly less computation and memory. Overall, the Dopamine optimizer not\nonly finds robust solutions and comparable performance to the state-of-the-art\nMachine Learning optimizers but is also neurobiologically more plausible.",
    "categories": [
      "cs.AI",
      "cs.LG"
    ],
    "published": "2025-10-25T06:17:49Z",
    "authors": [
      "Saranraj Nambusubramaniyan",
      "Shervin Safavi",
      "Raja Guru",
      "Andreas Knoblauch"
    ],
    "pdf_url": "http://arxiv.org/pdf/2510.22178v1"
  },
  {
    "id": "2510.22170v1",
    "title": "Measure what Matters: Psychometric Evaluation of AI with Situational\n  Judgment Tests",
    "abstract": "AI psychometrics evaluates AI systems in roles that traditionally require\nemotional judgment and ethical consideration. Prior work often reuses human\ntrait inventories (Big Five, \\hexaco) or ad hoc personas, limiting behavioral\nrealism and domain relevance. We propose a framework that (1) uses situational\njudgment tests (SJTs) from realistic scenarios to probe domain-specific\ncompetencies; (2) integrates industrial-organizational and personality\npsychology to design sophisticated personas which include behavioral and\npsychological descriptors, life history, and social and emotional functions;\nand (3) employs structured generation with population demographic priors and\nmemoir inspired narratives, encoded with Pydantic schemas. In a law enforcement\nassistant case study, we construct a rich dataset of personas drawn across 8\npersona archetypes and SJTs across 11 attributes, and analyze behaviors across\nsubpopulation and scenario slices. The dataset spans 8,500 personas, 4,000\nSJTs, and 300,000 responses. We will release the dataset and all code to the\npublic.",
    "categories": [
      "cs.AI",
      "I.2.7; I.2.6; H.1.2; J.4"
    ],
    "published": "2025-10-25T05:45:10Z",
    "authors": [
      "Alexandra Yost",
      "Shreyans Jain",
      "Shivam Raval",
      "Grant Corser",
      "Allen Roush",
      "Nina Xu",
      "Jacqueline Hammack",
      "Ravid Shwartz-Ziv",
      "Amirali Abdullah"
    ],
    "pdf_url": "http://arxiv.org/pdf/2510.22170v1"
  },
  {
    "id": "2510.23648v1",
    "title": "RoGBot: Relationship-Oblivious Graph-based Neural Network with\n  Contextual Knowledge for Bot Detection",
    "abstract": "Detecting automated accounts (bots) among genuine users on platforms like\nTwitter remains a challenging task due to the evolving behaviors and adaptive\nstrategies of such accounts. While recent methods have achieved strong\ndetection performance by combining text, metadata, and user relationship\ninformation within graph-based frameworks, many of these models heavily depend\non explicit user-user relationship data. This reliance limits their\napplicability in scenarios where such information is unavailable. To address\nthis limitation, we propose a novel multimodal framework that integrates\ndetailed textual features with enriched user metadata while employing\ngraph-based reasoning without requiring follower-following data. Our method\nuses transformer-based models (e.g., BERT) to extract deep semantic embeddings\nfrom tweets, which are aggregated using max pooling to form comprehensive\nuser-level representations. These are further combined with auxiliary\nbehavioral features and passed through a GraphSAGE model to capture both local\nand global patterns in user behavior. Experimental results on the Cresci-15,\nCresci-17, and PAN 2019 datasets demonstrate the robustness of our approach,\nachieving accuracies of 99.8%, 99.1%, and 96.8%, respectively, and highlighting\nits effectiveness against increasingly sophisticated bot strategies.",
    "categories": [
      "cs.SI",
      "cs.AI"
    ],
    "published": "2025-10-25T05:14:58Z",
    "authors": [
      "Ashutosh Anshul",
      "Mohammad Zia Ur Rehman",
      "Sri Akash Kadali",
      "Nagendra Kumar"
    ],
    "pdf_url": "http://arxiv.org/pdf/2510.23648v1"
  },
  {
    "id": "2510.22158v1",
    "title": "Solving Continuous Mean Field Games: Deep Reinforcement Learning for\n  Non-Stationary Dynamics",
    "abstract": "Mean field games (MFGs) have emerged as a powerful framework for modeling\ninteractions in large-scale multi-agent systems. Despite recent advancements in\nreinforcement learning (RL) for MFGs, existing methods are typically limited to\nfinite spaces or stationary models, hindering their applicability to real-world\nproblems. This paper introduces a novel deep reinforcement learning (DRL)\nalgorithm specifically designed for non-stationary continuous MFGs. The\nproposed approach builds upon a Fictitious Play (FP) methodology, leveraging\nDRL for best-response computation and supervised learning for average policy\nrepresentation. Furthermore, it learns a representation of the time-dependent\npopulation distribution using a Conditional Normalizing Flow. To validate the\neffectiveness of our method, we evaluate it on three different examples of\nincreasing complexity. By addressing critical limitations in scalability and\ndensity approximation, this work represents a significant advancement in\napplying DRL techniques to complex MFG problems, bringing the field closer to\nreal-world multi-agent systems.",
    "categories": [
      "cs.LG",
      "cs.AI",
      "cs.MA",
      "math.OC"
    ],
    "published": "2025-10-25T04:50:52Z",
    "authors": [
      "Lorenzo Magnino",
      "Kai Shao",
      "Zida Wu",
      "Jiacheng Shen",
      "Mathieu Lauri\u00e8re"
    ],
    "pdf_url": "http://arxiv.org/pdf/2510.22158v1"
  },
  {
    "id": "2510.22149v1",
    "title": "Power to the Clients: Federated Learning in a Dictatorship Setting",
    "abstract": "Federated learning (FL) has emerged as a promising paradigm for decentralized\nmodel training, enabling multiple clients to collaboratively learn a shared\nmodel without exchanging their local data. However, the decentralized nature of\nFL also introduces vulnerabilities, as malicious clients can compromise or\nmanipulate the training process. In this work, we introduce dictator clients, a\nnovel, well-defined, and analytically tractable class of malicious participants\ncapable of entirely erasing the contributions of all other clients from the\nserver model, while preserving their own. We propose concrete attack strategies\nthat empower such clients and systematically analyze their effects on the\nlearning process. Furthermore, we explore complex scenarios involving multiple\ndictator clients, including cases where they collaborate, act independently, or\nform an alliance in order to ultimately betray one another. For each of these\nsettings, we provide a theoretical analysis of their impact on the global\nmodel's convergence. Our theoretical algorithms and findings about the complex\nscenarios including multiple dictator clients are further supported by\nempirical evaluations on both computer vision and natural language processing\nbenchmarks.",
    "categories": [
      "cs.LG",
      "cs.AI",
      "cs.CL",
      "cs.CR",
      "cs.CV",
      "cs.DC"
    ],
    "published": "2025-10-25T04:02:04Z",
    "authors": [
      "Mohammadsajad Alipour",
      "Mohammad Mohammadi Amiri"
    ],
    "pdf_url": "http://arxiv.org/pdf/2510.22149v1"
  },
  {
    "id": "2510.22132v1",
    "title": "Controllable Mathematical Reasoning via Self-Optimizing Thought Vectors",
    "abstract": "We present a novel approach for controllable mathematical reasoning that\nleverages self-optimizing thought vectors with entropy minimization. Our method\nintroduces learnable thought vectors that dynamically modulate the internal\nreasoning process of large language models. Using Gemma-2-9B on GSM8K, we\nachieve 90.1% accuracy with a controllability score of 0.42, demonstrating that\nentropy-based rewards effectively guide focused reasoning patterns without\nrequiring external reward annotations. Our analysis reveals distinct thought\nvector clusters and consistent low-entropy distributions across control\nconditions, validating our framework for controllable AI reasoning.",
    "categories": [
      "cs.AI"
    ],
    "published": "2025-10-25T03:13:14Z",
    "authors": [
      "Xuying LI"
    ],
    "pdf_url": "http://arxiv.org/pdf/2510.22132v1"
  },
  {
    "id": "2510.22131v1",
    "title": "Probing Neural Combinatorial Optimization Models",
    "abstract": "Neural combinatorial optimization (NCO) has achieved remarkable performance,\nyet its learned model representations and decision rationale remain a black\nbox. This impedes both academic research and practical deployment, since\nresearchers and stakeholders require deeper insights into NCO models. In this\npaper, we take the first critical step towards interpreting NCO models by\ninvestigating their representations through various probing tasks. Moreover, we\nintroduce a novel probing tool named Coefficient Significance Probing\n(CS-Probing) to enable deeper analysis of NCO representations by examining the\ncoefficients and statistical significance during probing. Extensive experiments\nand analysis reveal that NCO models encode low-level information essential for\nsolution construction, while capturing high-level knowledge to facilitate\nbetter decisions. Using CS-Probing, we find that prevalent NCO models impose\nvarying inductive biases on their learned representations, uncover direct\nevidence related to model generalization, and identify key embedding dimensions\nassociated with specific knowledge. These insights can be potentially\ntranslated into practice, for example, with minor code modifications, we\nimprove the generalization of the analyzed model. Our work represents a first\nsystematic attempt to interpret black-box NCO models, showcasing probing as a\npromising tool for analyzing their internal mechanisms and revealing insights\nfor the NCO community. The source code is publicly available.",
    "categories": [
      "cs.LG",
      "cs.AI"
    ],
    "published": "2025-10-25T03:11:10Z",
    "authors": [
      "Zhiqin Zhang",
      "Yining Ma",
      "Zhiguang Cao",
      "Hoong Chuin Lau"
    ],
    "pdf_url": "http://arxiv.org/pdf/2510.22131v1"
  },
  {
    "id": "2510.22124v1",
    "title": "Efficient Utility-Preserving Machine Unlearning with Implicit Gradient\n  Surgery",
    "abstract": "Machine unlearning (MU) aims to efficiently remove sensitive or harmful\nmemory from a pre-trained model. The key challenge is to balance the potential\ntradeoff between unlearning efficacy and utility preservation, which involves\nforgetting undesirable information as defined while maintaining the model's\noriginal performance. One potential way to tackle this problem is to use\nmulti-objective optimization to jointly optimize both the unlearning and\nutility preservation objectives. However, existing multi-objective methods only\nguarantee finding a Pareto-optimal solution without fine-grained control, which\ncauses under-optimization of the unlearning objective. To this end, we first\nmodel MU as a constrained optimization problem, that is, optimizing the\nunlearning objective under the constraint of a bounded increase for utility\nloss. We then show that solving this optimization problem is equivalent to\nunilateral gradient surgery on the unlearning objective. To resolve the\nadditional computational cost brought by gradient surgery, we propose an\nimplicit gradient surgery method, which approximates the solution to the\naforementioned constrained optimization problem via only one backpropagation,\nthereby achieving efficient utility-preserving MU. Theoretically, we provide a\ntight convergence analysis of the algorithm. Empirically, our extensive\nexperiments show that the proposed algorithm achieves better tradeoff results\nthan existing baselines. Codes are available at\nhttps://github.com/anseryuer/EUPMU-Efficient-Utility-Preserving-Machine-Unlearning.",
    "categories": [
      "cs.LG",
      "cs.AI"
    ],
    "published": "2025-10-25T02:49:26Z",
    "authors": [
      "Shiji Zhou",
      "Tianbai Yu",
      "Zhi Zhang",
      "Heng Chang",
      "Xiao Zhou",
      "Dong Wu",
      "Han Zhao"
    ],
    "pdf_url": "http://arxiv.org/pdf/2510.22124v1"
  },
  {
    "id": "2510.22118v2",
    "title": "GRAID: Enhancing Spatial Reasoning of VLMs Through High-Fidelity Data\n  Generation",
    "abstract": "Vision Language Models (VLMs) achieve strong performance on many\nvision-language tasks but often struggle with spatial\nreasoning$\\unicode{x2014}$a prerequisite for many applications. Empirically, we\nfind that a dataset produced by a current training data generation pipeline has\na 57.6% human validation rate. These rates stem from current limitations:\nsingle-image 3D reconstruction introduces cascading modeling errors and\nrequires wide answer tolerances, while caption-based methods require\nhyper-detailed annotations and suffer from generative hallucinations. We\npresent GRAID, built on the key insight that qualitative spatial relationships\ncan be reliably determined from 2D geometric primitives alone. By operating\nexclusively on 2D bounding boxes from standard object detectors, GRAID avoids\nboth 3D reconstruction errors and generative hallucinations, resulting in\ndatasets that are of higher quality than existing tools that produce similar\ndatasets as validated by human evaluations. We apply our framework to the\nBDD100k, NuImages, and Waymo datasets, generating over 8.5 million high-quality\nVQA pairs creating questions spanning spatial relations, counting, ranking, and\nsize comparisons. We evaluate one of the datasets and find it achieves 91.16%\nhuman-validated accuracy$\\unicode{x2014}$compared to 57.6% on a dataset\ngenerated by recent work. Critically, we demonstrate that when trained on GRAID\ndata, models learn spatial reasoning concepts that generalize: models\nfine-tuned on 6 question types improve on over 10 held-out types, with accuracy\ngains of 47.5% on BDD and 37.9% on NuImages for Llama 3.2B 11B, and when\ntrained on all questions types, achieve improvements on several existing\nbenchmarks such as BLINK. The GRAID framework, datasets, and additional\ninformation can be found $\\href{this https URL}{here}$.",
    "categories": [
      "cs.CV",
      "cs.AI"
    ],
    "published": "2025-10-25T02:07:23Z",
    "authors": [
      "Karim Elmaaroufi",
      "Liheng Lai",
      "Justin Svegliato",
      "Yutong Bai",
      "Sanjit A. Seshia",
      "Matei Zaharia"
    ],
    "pdf_url": "http://arxiv.org/pdf/2510.22118v2"
  },
  {
    "id": "2510.22117v1",
    "title": "When UAV Swarm Meets IRS: Collaborative Secure Communications in\n  Low-altitude Wireless Networks",
    "abstract": "Low-altitude wireless networks (LAWNs) represent a promising architecture\nthat integrates unmanned aerial vehicles (UAVs) as aerial nodes to provide\nenhanced coverage, reliability, and throughput for diverse applications.\nHowever, these networks face significant security vulnerabilities from both\nknown and potential unknown eavesdroppers, which may threaten data\nconfidentiality and system integrity. To solve this critical issue, we propose\na novel secure communication framework for LAWNs where the selected UAVs within\na swarm function as a virtual antenna array (VAA), complemented by intelligent\nreflecting surface (IRS) to create a robust defense against eavesdropping\nattacks. Specifically, we formulate a multi-objective optimization problem that\nsimultaneously maximizes the secrecy rate while minimizing the maximum sidelobe\nlevel and total energy consumption, requiring joint optimization of UAV\nexcitation current weights, flight trajectories, and IRS phase shifts. This\nproblem presents significant difficulties due to the dynamic nature of the\nsystem and heterogeneous components. Thus, we first transform the problem into\na heterogeneous Markov decision process (MDP). Then, we propose a heterogeneous\nmulti-agent control approach (HMCA) that integrates a dedicated IRS control\npolicy with a multi-agent soft actor-critic framework for UAV control, which\nenables coordinated operation across heterogeneous network elements. Simulation\nresults show that the proposed HMCA achieves superior performance compared to\nbaseline approaches in terms of secrecy rate improvement, sidelobe suppression,\nand energy efficiency. Furthermore, we find that the collaborative and passive\nbeamforming synergy between VAA and IRS creates robust security guarantees when\nthe number of UAVs increases.",
    "categories": [
      "cs.NI",
      "cs.AI"
    ],
    "published": "2025-10-25T02:02:14Z",
    "authors": [
      "Jiahui Li",
      "Xinyue Liang",
      "Geng Sun",
      "Hui Kang",
      "Jiacheng Wang",
      "Dusit Niyato",
      "Shiwen Mao",
      "Abbas Jamalipour"
    ],
    "pdf_url": "http://arxiv.org/pdf/2510.22117v1"
  },
  {
    "id": "2510.22115v1",
    "title": "Every Activation Boosted: Scaling General Reasoner to 1 Trillion Open\n  Language Foundation",
    "abstract": "We introduce Ling 2.0, a series reasoning-oriented language foundation built\nupon the principle that every activation boosts reasoning capability. Designed\nto scale from tens of billions to one trillion parameters under a unified\nMixture-of-Experts (MoE) paradigm, Ling 2.0 emphasizes high sparsity,\ncross-scale consistency, and efficiency guided by empirical scaling laws. The\nseries includes three non-thinking (instruct) models - Ling-mini-2.0,\nLing-flash-2.0, and Ling-1T - ranging from 16B to 1T total parameters and\nachieving up to 7-fold active-compute efficiency compared with dense\ncounterparts. Ling 2.0 integrates coordinated innovations across model\narchitecture, pre-training, post-training, and infrastructure: a high-sparsity\nMoE with MTP for efficient reasoning, reasoning-oriented data and mid-training\nCoT activation, reinforcement-based fine-tuning (DFT, Evo-CoT), and full-scale\nFP8 training with fine-grained heterogeneous pipelines. At the trillion scale,\nLing-1T establishes a new Pareto frontier of reasoning accuracy versus\ncomputational efficiency, demonstrating that sparse activation, when properly\naligned with reasoning objectives, enables scalable and efficient intelligence.\nCollectively, Ling 2.0 provides a coherent, open, and efficient foundation for\nadvancing future reasoning and thinking models, including the Ring series built\nupon the same base.",
    "categories": [
      "cs.CL",
      "cs.AI"
    ],
    "published": "2025-10-25T01:51:37Z",
    "authors": [
      " Ling-Team",
      "Ang Li",
      "Ben Liu",
      "Binbin Hu",
      "Bing Li",
      "Bingwei Zeng",
      "Borui Ye",
      "Caizhi Tang",
      "Changxin Tian",
      "Chao Huang",
      "Chao Zhang",
      "Chen Qian",
      "Chenchen Ju",
      "Chenchen Li",
      "Chengfu Tang",
      "Chili Fu",
      "Chunshao Ren",
      "Chunwei Wu",
      "Cong Zhang",
      "Cunyin Peng",
      "Dafeng Xu",
      "Daixin Wang",
      "Dalong Zhang",
      "Dingnan Jin",
      "Dingyuan Zhu",
      "Dongke Hu",
      "Fangzheng Zhao",
      "Feifan Wu",
      "Feng Zhu",
      "Gangshan Wang",
      "Haitao Zhang",
      "Hailin Zhao",
      "Hanxiao Zhang",
      "Hanzi Wang",
      "Hao Qian",
      "Haoyi Yu",
      "Heng Zhang",
      "Hongliang Zhang",
      "Hongzhi Luan",
      "Huirong Dong",
      "Huizhong Li",
      "Jia Li",
      "Jia Liu",
      "Jialong Zhu",
      "Jian Sha",
      "Jianping Wei",
      "Jiaolong Yang",
      "Jieyue Ma",
      "Jiewei Wu",
      "Jinjing Huang",
      "Jingyun Tian",
      "Jingyuan Zhang",
      "Jinquan Sun",
      "Juanhui Tu",
      "Jun Liu",
      "Jun Xu",
      "Jun Zhou",
      "Junjie Ou",
      "Junpeng Fang",
      "Kaihong Zhang",
      "Kaiqin Hu",
      "Ke Shi",
      "Kun Tang",
      "Kunlong Chen",
      "Lanyin Mei",
      "Lei Liang",
      "Lei Xu",
      "Libo Zhang",
      "Lin Ju",
      "Lin Yuan",
      "Ling Zhong",
      "Lintao Ma",
      "Lu Liu",
      "Lu Yu",
      "Lun Cai",
      "Meiqi Zhu",
      "Mengying Li",
      "Min Chen",
      "Minghao Xue",
      "Minghong Cai",
      "Mingming Yin",
      "Peijie Jiang",
      "Peilong Zhao",
      "Pingping Liu",
      "Qian Zhao",
      "Qing Cui",
      "Qingxiang Huang",
      "Qingyuan Yang",
      "Quankun Yu",
      "Shaowei Wei",
      "Shijie Lian",
      "Shoujian Zheng",
      "Shun Song",
      "Shungen Zhang",
      "Shuo Zhang",
      "Siyuan Li",
      "Song Liu",
      "Ting Guo",
      "Tong Zhao",
      "Wanli Gu",
      "Weichang Wu",
      "Weiguang Han",
      "Wenjing Fang",
      "Wubin Wang",
      "Xiang Shu",
      "Xiao Shi",
      "Xiaoshun Lan",
      "Xiaolu Zhang",
      "Xiaqing Sun",
      "Xin Zhao",
      "Xingyu Lu",
      "Xiong Xu",
      "Xudong Wang",
      "Xudong Wang",
      "Xuemin Yang",
      "Yajie Yang",
      "Yang Xiang",
      "Yanzhe Li",
      "Yi Zhang",
      "Yilong Wang",
      "Yingxue Li",
      "Yongzhen Guo",
      "Yuzhuo Fu",
      "Yuanyuan Wang",
      "Yue Yang",
      "Yue Yu",
      "Yufeng Deng",
      "Yun Zhang",
      "Yunfei Xu",
      "Yuqi Zhang",
      "Yuxiao He",
      "Zengke Gui",
      "Zhaoxin Huan",
      "Zhaoyang Wang",
      "Zhibo Zhu",
      "Zhihao Wang",
      "Zhiqiang Zhang",
      "Zhoufei Wang",
      "Zihang Zeng",
      "Ziqi Liu",
      "Zitao Xuan",
      "Zuoli Tang"
    ],
    "pdf_url": "http://arxiv.org/pdf/2510.22115v1"
  },
  {
    "id": "2510.22109v1",
    "title": "Gradual Forgetting: Logarithmic Compression for Extending Transformer\n  Context Windows",
    "abstract": "Most approaches to long-context processing increase the complexity of the\ntransformer's internal architecture by integrating mechanisms such as\nrecurrence or auxiliary memory modules. In this work, we introduce an\nalternative approach that modifies the input representation itself, rather than\nthe transformer architecture. Inspired by cognitive models of human memory, our\nmethod applies a scale-invariant logarithmic compression to the input tokens.\nThe resulting compressed representation is processed by a standard, unmodified\ntransformer, preserving architectural simplicity. We evaluate this approach on\nthe WikiText-103 and PG-19 language modeling benchmarks, showing a reduction in\nperplexity compared to uncompressed baselines. Moreover, performance improves\nconsistently with longer compressed temporal contexts, showing that input-level\nlogarithmic compression is a simple and effective way to extend a transformer's\nlong-range memory.",
    "categories": [
      "cs.CL",
      "cs.AI"
    ],
    "published": "2025-10-25T01:29:37Z",
    "authors": [
      "Billy Dickson",
      "Zoran Tiganj"
    ],
    "pdf_url": "http://arxiv.org/pdf/2510.22109v1"
  },
  {
    "id": "2510.22108v1",
    "title": "STAR-RIS-assisted Collaborative Beamforming for Low-altitude Wireless\n  Networks",
    "abstract": "While low-altitude wireless networks (LAWNs) based on uncrewed aerial\nvehicles (UAVs) offer high mobility, flexibility, and coverage for urban\ncommunications, they face severe signal attenuation in dense environments due\nto obstructions. To address this critical issue, we consider introducing\ncollaborative beamforming (CB) of UAVs and omnidirectional reconfigurable\nbeamforming (ORB) of simultaneous transmitting and reflecting reconfigurable\nintelligent surfaces (STAR-RIS) to enhance the signal quality and\ndirectionality. On this basis, we formulate a joint rate and energy\noptimization problem (JREOP) to maximize the transmission rate of the overall\nsystem, while minimizing the energy consumption of the UAV swarm. Due to the\nnon-convex and NP-hard nature of JREOP, we propose a heterogeneous multi-agent\ncollaborative dynamic (HMCD) optimization framework, which has two core\ncomponents. The first component is a simulated annealing (SA)-based STAR-RIS\ncontrol method, which dynamically optimizes reflection and transmission\ncoefficients to enhance signal propagation. The second component is an improved\nmulti-agent deep reinforcement learning (MADRL) control method, which\nincorporates a self-attention evaluation mechanism to capture interactions\nbetween UAVs and an adaptive velocity transition mechanism to enhance training\nstability. Simulation results demonstrate that HMCD outperforms various\nbaselines in terms of convergence speed, average transmission rate, and energy\nconsumption. Further analysis reveals that the average transmission rate of the\noverall system scales positively with both UAV count and STAR-RIS element\nnumbers.",
    "categories": [
      "cs.NI",
      "cs.AI"
    ],
    "published": "2025-10-25T01:28:37Z",
    "authors": [
      "Xinyue Liang",
      "Hui Kang",
      "Junwei Che",
      "Jiahui Li",
      "Geng Sun",
      "Qingqing Wu",
      "Jiacheng Wang",
      "Dusit Niyato"
    ],
    "pdf_url": "http://arxiv.org/pdf/2510.22108v1"
  },
  {
    "id": "2510.22107v1",
    "title": "Discovering Latent Graphs with GFlowNets for Diverse Conditional Image\n  Generation",
    "abstract": "Capturing diversity is crucial in conditional and prompt-based image\ngeneration, particularly when conditions contain uncertainty that can lead to\nmultiple plausible outputs. To generate diverse images reflecting this\ndiversity, traditional methods often modify random seeds, making it difficult\nto discern meaningful differences between samples, or diversify the input\nprompt, which is limited in verbally interpretable diversity. We propose\nRainbow, a novel conditional image generation framework, applicable to any\npretrained conditional generative model, that addresses inherent\ncondition/prompt uncertainty and generates diverse plausible images. Rainbow is\nbased on a simple yet effective idea: decomposing the input condition into\ndiverse latent representations, each capturing an aspect of the uncertainty and\ngenerating a distinct image. First, we integrate a latent graph, parameterized\nby Generative Flow Networks (GFlowNets), into the prompt representation\ncomputation. Second, leveraging GFlowNets' advanced graph sampling capabilities\nto capture uncertainty and output diverse trajectories over the graph, we\nproduce multiple trajectories that collectively represent the input condition,\nleading to diverse condition representations and corresponding output images.\nEvaluations on natural image and medical image datasets demonstrate Rainbow's\nimprovement in both diversity and fidelity across image synthesis, image\ngeneration, and counterfactual generation tasks.",
    "categories": [
      "cs.CV",
      "cs.AI"
    ],
    "published": "2025-10-25T01:25:50Z",
    "authors": [
      "Bailey Trang",
      "Parham Saremi",
      "Alan Q. Wang",
      "Fangrui Huang",
      "Zahra TehraniNasab",
      "Amar Kumar",
      "Tal Arbel",
      "Li Fei-Fei",
      "Ehsan Adeli"
    ],
    "pdf_url": "http://arxiv.org/pdf/2510.22107v1"
  },
  {
    "id": "2510.22102v1",
    "title": "Mitigating Coordinate Prediction Bias from Positional Encoding Failures",
    "abstract": "Multimodal large language models (MLLMs) excel at vision-language tasks such\nas VQA and document understanding, yet precise coordinate prediction remains\nchallenging. High-resolution inputs exacerbate this difficulty by producing\nlong token sequences that weaken positional encodings and introduce directional\nbiases in coordinate outputs. We investigate this phenomenon by analyzing how\nMLLMs behave when visual positional encodings (VPEs) are deliberately perturbed\nthrough shuffling. Our analysis reveals that such perturbations induce\npredictable, non-random coordinate biases rather than random errors, suggesting\nthat models rely on internal positional priors when spatial grounding signals\nare degraded. Crucially, we observe similar directional error patterns in\nnatural high-resolution datasets, indicating that positional encoding failures\nare a key bottleneck for accurate coordinate prediction at scale. To address\nthis issue, we propose Vision-PE Shuffle Guidance (VPSG), a training-free\ntest-time method that leverages the directional nature of these biases for\ncorrection. VPSG runs auxiliary decoding with shuffled VPEs to isolate\nposition-unconditioned tendencies, then uses this as negative evidence to guide\ndigit prediction while preserving coordinate format through a lightweight\nfinite-state machine. Experiments on ScreenSpot-Pro demonstrate reliable\nimprovements, highlighting positional encoding robustness as a critical factor\nfor spatial reasoning in MLLMs.",
    "categories": [
      "cs.CV",
      "cs.AI",
      "cs.CL"
    ],
    "published": "2025-10-25T00:58:47Z",
    "authors": [
      "Xingjian Tao",
      "Yiwei Wang",
      "Yujun Cai",
      "Yihong Luo",
      "Jing Tang"
    ],
    "pdf_url": "http://arxiv.org/pdf/2510.22102v1"
  },
  {
    "id": "2510.22095v1",
    "title": "Embracing Trustworthy Brain-Agent Collaboration as Paradigm Extension\n  for Intelligent Assistive Technologies",
    "abstract": "Brain-Computer Interfaces (BCIs) offer a direct communication pathway between\nthe human brain and external devices, holding significant promise for\nindividuals with severe neurological impairments. However, their widespread\nadoption is hindered by critical limitations, such as low information transfer\nrates and extensive user-specific calibration. To overcome these challenges,\nrecent research has explored the integration of Large Language Models (LLMs),\nextending the focus from simple command decoding to understanding complex\ncognitive states. Despite these advancements, deploying agentic AI faces\ntechnical hurdles and ethical concerns. Due to the lack of comprehensive\ndiscussion on this emerging direction, this position paper argues that the\nfield is poised for a paradigm extension from BCI to Brain-Agent Collaboration\n(BAC). We emphasize reframing agents as active and collaborative partners for\nintelligent assistance rather than passive brain signal data processors,\ndemanding a focus on ethical data handling, model reliability, and a robust\nhuman-agent collaboration framework to ensure these systems are safe,\ntrustworthy, and effective.",
    "categories": [
      "cs.AI",
      "cs.CL"
    ],
    "published": "2025-10-25T00:25:45Z",
    "authors": [
      "Yankai Chen",
      "Xinni Zhang",
      "Yifei Zhang",
      "Yangning Li",
      "Henry Peng Zou",
      "Chunyu Miao",
      "Weizhi Zhang",
      "Xue Liu",
      "Philip S. Yu"
    ],
    "pdf_url": "http://arxiv.org/pdf/2510.22095v1"
  },
  {
    "id": "2510.22087v1",
    "title": "QuArch: A Benchmark for Evaluating LLM Reasoning in Computer\n  Architecture",
    "abstract": "The field of computer architecture, which bridges high-level software\nabstractions and low-level hardware implementations, remains absent from\ncurrent large language model (LLM) evaluations. To this end, we present QuArch\n(pronounced 'quark'), the first benchmark designed to facilitate the\ndevelopment and evaluation of LLM knowledge and reasoning capabilities\nspecifically in computer architecture. QuArch provides a comprehensive\ncollection of 2,671 expert-validated question-answer (QA) pairs covering\nvarious aspects of computer architecture, including processor design, memory\nsystems, and interconnection networks. Our evaluation reveals that while\nfrontier models possess domain-specific knowledge, they struggle with skills\nthat require higher-order thinking in computer architecture. Frontier model\naccuracies vary widely (from 34% to 72%) on these advanced questions,\nhighlighting persistent gaps in architectural reasoning across analysis,\ndesign, and implementation QAs. By holistically assessing fundamental skills,\nQuArch provides a foundation for building and measuring LLM capabilities that\ncan accelerate innovation in computing systems. With over 140 contributors from\n40 institutions, this benchmark represents a community effort to set the\nstandard for architectural reasoning in LLM evaluation.",
    "categories": [
      "cs.AR",
      "cs.AI",
      "cs.LG",
      "cs.SE"
    ],
    "published": "2025-10-24T23:54:17Z",
    "authors": [
      "Shvetank Prakash",
      "Andrew Cheng",
      "Arya Tschand",
      "Mark Mazumder",
      "Varun Gohil",
      "Jeffrey Ma",
      "Jason Yik",
      "Zishen Wan",
      "Jessica Quaye",
      "Elisavet Lydia Alvanaki",
      "Avinash Kumar",
      "Chandrashis Mazumdar",
      "Tuhin Khare",
      "Alexander Ingare",
      "Ikechukwu Uchendu",
      "Radhika Ghosal",
      "Abhishek Tyagi",
      "Chenyu Wang",
      "Andrea Mattia Garavagno",
      "Sarah Gu",
      "Alice Guo",
      "Grace Hur",
      "Luca Carloni",
      "Tushar Krishna",
      "Ankita Nayak",
      "Amir Yazdanbakhsh",
      "Vijay Janapa Reddi"
    ],
    "pdf_url": "http://arxiv.org/pdf/2510.22087v1"
  },
  {
    "id": "2510.22085v1",
    "title": "Jailbreak Mimicry: Automated Discovery of Narrative-Based Jailbreaks for\n  Large Language Models",
    "abstract": "Large language models (LLMs) remain vulnerable to sophisticated prompt\nengineering attacks that exploit contextual framing to bypass safety\nmechanisms, posing significant risks in cybersecurity applications. We\nintroduce Jailbreak Mimicry, a systematic methodology for training compact\nattacker models to automatically generate narrative-based jailbreak prompts in\na one-shot manner. Our approach transforms adversarial prompt discovery from\nmanual craftsmanship into a reproducible scientific process, enabling proactive\nvulnerability assessment in AI-driven security systems. Developed for the\nOpenAI GPT-OSS-20B Red-Teaming Challenge, we use parameter-efficient\nfine-tuning (LoRA) on Mistral-7B with a curated dataset derived from AdvBench,\nachieving an 81.0% Attack Success Rate (ASR) against GPT-OSS-20B on a held-out\ntest set of 200 items. Cross-model evaluation reveals significant variation in\nvulnerability patterns: our attacks achieve 66.5% ASR against GPT-4, 79.5% on\nLlama-3 and 33.0% against Gemini 2.5 Flash, demonstrating both broad\napplicability and model-specific defensive strengths in cybersecurity contexts.\nThis represents a 54x improvement over direct prompting (1.5% ASR) and\ndemonstrates systematic vulnerabilities in current safety alignment approaches.\nOur analysis reveals that technical domains (Cybersecurity: 93% ASR) and\ndeception-based attacks (Fraud: 87.8% ASR) are particularly vulnerable,\nhighlighting threats to AI-integrated threat detection, malware analysis, and\nsecure systems, while physical harm categories show greater resistance (55.6%\nASR). We employ automated harmfulness evaluation using Claude Sonnet 4,\ncross-validated with human expert assessment, ensuring reliable and scalable\nevaluation for cybersecurity red-teaming. Finally, we analyze failure\nmechanisms and discuss defensive strategies to mitigate these vulnerabilities\nin AI for cybersecurity.",
    "categories": [
      "cs.CR",
      "cs.AI",
      "cs.CL",
      "cs.LG",
      "I.2.7; I.2.0; K.6.5"
    ],
    "published": "2025-10-24T23:53:16Z",
    "authors": [
      "Pavlos Ntais"
    ],
    "pdf_url": "http://arxiv.org/pdf/2510.22085v1"
  },
  {
    "id": "2510.22075v1",
    "title": "Agentic Reinforcement Learning for Real-World Code Repair",
    "abstract": "We tackle the challenge of training reliable code-fixing agents in real\nrepositories, where complex builds and shifting dependencies make evaluation\nunstable. We developed a verifiable pipeline with success defined as post-fix\nbuild validation and improved reproducibility across ~1K real issues by pinning\ndependencies and disabling automatic upgrades. Building on this, we introduced\na scalable simplified pipeline for large-scale reinforcement learning (RL).\nUsing this setup, we supervised fine-tuned Qwen3-32B in the full pipeline and\napplied RL on top of the SFT model in the simplified environment. The SFT model\ndistilled from GPT-4.1 trajectories performs on par while being 56x smaller,\nand RL added 7-20% absolute gains under matched train-test conditions.\n\"Thinking mode\" was on par or worse in our experiments. Both SFT and RL models\nfailed to generalize across environments, highlighting the importance of\nmatching train-test environments for building reliable real-world code-fixing\nagents.",
    "categories": [
      "cs.LG",
      "cs.AI",
      "cs.CL"
    ],
    "published": "2025-10-24T23:25:02Z",
    "authors": [
      "Siyu Zhu",
      "Anastasiya Karpovich",
      "Albert Chen",
      "Jessica Koscheka",
      "Shailesh Jannu",
      "Di Wen",
      "Yuqing Zhu",
      "Rohit Jain",
      "Alborz Geramifard"
    ],
    "pdf_url": "http://arxiv.org/pdf/2510.22075v1"
  },
  {
    "id": "2510.22063v1",
    "title": "Frequentist Validity of Epistemic Uncertainty Estimators",
    "abstract": "Decomposing prediction uncertainty into its aleatoric (irreducible) and\nepistemic (reducible) components is critical for the development and deployment\nof machine learning systems. A popular, principled measure for epistemic\nuncertainty is the mutual information between the response variable and model\nparameters. However, evaluating this measure requires access to the posterior\ndistribution of the model parameters, which is challenging to compute. In view\nof this, we introduce a frequentist measure of epistemic uncertainty based on\nthe bootstrap. Our main theoretical contribution is a novel asymptotic\nexpansion that reveals that our proposed (frequentist) measure and the\n(Bayesian) mutual information are asymptotically equivalent. This provides\nfrequentist interpretations to mutual information and new computational\nstrategies for approximating it. Moreover, we link our proposed approach to the\nwidely-used heuristic approach of deep ensembles, giving added perspective on\ntheir practical success.",
    "categories": [
      "stat.ML",
      "cs.AI",
      "cs.LG",
      "math.ST",
      "stat.TH"
    ],
    "published": "2025-10-24T22:58:42Z",
    "authors": [
      "Anchit Jain",
      "Stephen Bates"
    ],
    "pdf_url": "http://arxiv.org/pdf/2510.22063v1"
  },
  {
    "id": "2510.22057v1",
    "title": "Automatic Assessment of Students' Classroom Engagement with Bias\n  Mitigated Multi-task Model",
    "abstract": "With the rise of online and virtual learning, monitoring and enhancing\nstudent engagement have become an important aspect of effective education.\nTraditional methods of assessing a student's involvement might not be\napplicable directly to virtual environments. In this study, we focused on this\nproblem and addressed the need to develop an automated system to detect student\nengagement levels during online learning. We proposed a novel training method\nwhich can discourage a model from leveraging sensitive features like gender for\nits predictions. The proposed method offers benefits not only in the\nenforcement of ethical standards, but also to enhance interpretability of the\nmodel predictions. We applied an attribute-orthogonal regularization technique\nto a split-model classifier, which uses multiple transfer learning strategies\nto achieve effective results in reducing disparity in the distribution of\nprediction for sensitivity groups from a Pearson correlation coefficient of\n0.897 for the unmitigated model, to 0.999 for the mitigated model. The source\ncode for this project is available on\nhttps://github.com/ashiskb/elearning-engagement-study .",
    "categories": [
      "cs.LG",
      "cs.AI",
      "cs.CY",
      "I.5.1; I.4.7"
    ],
    "published": "2025-10-24T22:39:01Z",
    "authors": [
      "James Thiering",
      "Tarun Sethupat Radha Krishna",
      "Dylan Zelkin",
      "Ashis Kumer Biswas"
    ],
    "pdf_url": "http://arxiv.org/pdf/2510.22057v1"
  },
  {
    "id": "2510.22056v1",
    "title": "Human-Centric Anomaly Detection in Surveillance Videos Using YOLO-World\n  and Spatio-Temporal Deep Learning",
    "abstract": "Anomaly detection in surveillance videos remains a challenging task due to\nthe diversity of abnormal events, class imbalance, and scene-dependent visual\nclutter. To address these issues, we propose a robust deep learning framework\nthat integrates human-centric preprocessing with spatio-temporal modeling for\nmulti-class anomaly classification. Our pipeline begins by applying YOLO-World\n- an open-vocabulary vision-language detector - to identify human instances in\nraw video clips, followed by ByteTrack for consistent identity-aware tracking.\nBackground regions outside detected bounding boxes are suppressed via Gaussian\nblurring, effectively reducing scene-specific distractions and focusing the\nmodel on behaviorally relevant foreground content. The refined frames are then\nprocessed by an ImageNet-pretrained InceptionV3 network for spatial feature\nextraction, and temporal dynamics are captured using a bidirectional LSTM\n(BiLSTM) for sequence-level classification. Evaluated on a five-class subset of\nthe UCF-Crime dataset (Normal, Burglary, Fighting, Arson, Explosion), our\nmethod achieves a mean test accuracy of 92.41% across three independent trials,\nwith per-class F1-scores consistently exceeding 0.85. Comprehensive evaluation\nmetrics - including confusion matrices, ROC curves, and macro/weighted averages\n- demonstrate strong generalization and resilience to class imbalance. The\nresults confirm that foreground-focused preprocessing significantly enhances\nanomaly discrimination in real-world surveillance scenarios.",
    "categories": [
      "cs.CV",
      "cs.AI",
      "I.2.10; I.4.9; I.2.6"
    ],
    "published": "2025-10-24T22:38:17Z",
    "authors": [
      "Mohammad Ali Etemadi Naeen",
      "Hoda Mohammadzade",
      "Saeed Bagheri Shouraki"
    ],
    "pdf_url": "http://arxiv.org/pdf/2510.22056v1"
  },
  {
    "id": "2510.22052v1",
    "title": "Energy-Efficient Domain-Specific Artificial Intelligence Models and\n  Agents: Pathways and Paradigms",
    "abstract": "The field of artificial intelligence (AI) has taken a tight hold on broad\naspects of society, industry, business, and governance in ways that dictate the\nprosperity and might of the world's economies. The AI market size is projected\nto grow from 189 billion USD in 2023 to 4.8 trillion USD by 2033. Currently, AI\nis dominated by large language models that exhibit linguistic and visual\nintelligence. However, training these models requires a massive amount of data\nscraped from the web as well as large amounts of energy (50--60 GWh to train\nGPT-4). Despite these costs, these models often hallucinate, a characteristic\nthat prevents them from being deployed in critical application domains. In\ncontrast, the human brain consumes only 20~W of power. What is needed is the\nnext level of AI evolution in which lightweight domain-specific multimodal\nmodels with higher levels of intelligence can reason, plan, and make decisions\nin dynamic environments with real-time data and prior knowledge, while learning\ncontinuously and evolving in ways that enhance future decision-making\ncapability. This will define the next wave of AI, progressing from today's\nlarge models, trained with vast amounts of data, to nimble energy-efficient\ndomain-specific agents that can reason and think in a world full of\nuncertainty. To support such agents, hardware will need to be reimagined to\nallow energy efficiencies greater than 1000x over the state of the art. Such a\nvision of future AI systems is developed in this work.",
    "categories": [
      "cs.AI",
      "cs.LG"
    ],
    "published": "2025-10-24T22:21:08Z",
    "authors": [
      "Abhijit Chatterjee",
      "Niraj K. Jha",
      "Jonathan D. Cohen",
      "Thomas L. Griffiths",
      "Hongjing Lu",
      "Diana Marculescu",
      "Ashiqur Rasul",
      "Keshab K. Parhi"
    ],
    "pdf_url": "http://arxiv.org/pdf/2510.22052v1"
  },
  {
    "id": "2510.22050v1",
    "title": "Towards Error-Centric Intelligence II: Energy-Structured Causal Models",
    "abstract": "Contemporary machine learning optimizes for predictive accuracy, yet systems\nthat achieve state of the art performance remain causally opaque: their\ninternal representations provide no principled handle for intervention. We can\nretrain such models, but we cannot surgically edit specific mechanisms while\nholding others fixed, because learned latent variables lack causal semantics.\nWe argue for a conceptual reorientation: intelligence is the ability to build\nand refine explanations, falsifiable claims about manipulable structure that\nspecify what changes and what remains invariant under intervention.\nExplanations subsume prediction but demand more: causal commitments that can be\nindependently tested and corrected at the level of mechanisms. We introduce\ncomputational explanations, mappings from observations to intervention ready\ncausal accounts. We instantiate these explanations with Energy Structured\nCausal Models (ESCMs), in which mechanisms are expressed as constraints (energy\nfunctions or vector fields) rather than explicit input output maps, and\ninterventions act by local surgery on those constraints. This shift makes\ninternal structure manipulable at the level where explanations live: which\nrelations must hold, which can change, and what follows when they do. We\nprovide concrete instantiations of the structural-causal principles LAP and ICM\nin the ESCM context, and also argue that empirical risk minimization\nsystematically produces fractured, entangled representations, a failure we\nanalyze as gauge ambiguity in encoder energy pairs. Finally, we show that under\nmild conditions, ESCMs recover standard SCM semantics. Building on Part I's\nprinciples (LAP, ICM, CAP) and its definition of intelligence as\nexplanation-building under criticism, this paper offers a formal language for\ncausal reasoning in systems that aspire to understand, not merely to predict.",
    "categories": [
      "cs.AI",
      "cs.LG"
    ],
    "published": "2025-10-24T22:19:17Z",
    "authors": [
      "Marcus Thomas"
    ],
    "pdf_url": "http://arxiv.org/pdf/2510.22050v1"
  },
  {
    "id": "2510.22046v1",
    "title": "HW/SW Co-design of a PCM/PWM converter: a System Level Approach based in\n  the SpecC Methodology",
    "abstract": "We present a case study applying the SpecC methodology within a system-level\nhardware/software co-design flow to a PCM-to-PWM converter, the core of a\nClass-D audio amplifier. The converter was modeled and explored with SpecC\nmethodology to derive an HW/SW partition. Using system-level estimates and fast\nfunctional simulation, we evaluated mappings that meet real-time constraints\nwhile reducing estimated cost of an all-hardware solution and avoiding the\nexpense of a purely software implementation on a high-end processor. Despite\nthe design's moderate complexity, the results underline the value of\nsystem-level co-design for early architectural insight, rapid validation, and\nactionable cost/performance trade-offs. [Original work from 2005; formatting\nrevised in 2025, with no changes to the results.]",
    "categories": [
      "cs.AI",
      "cs.AR",
      "cs.SE"
    ],
    "published": "2025-10-24T22:07:09Z",
    "authors": [
      "Daniel G. P. Petrini",
      "Braz Izaias da Silva Junior"
    ],
    "pdf_url": "http://arxiv.org/pdf/2510.22046v1"
  },
  {
    "id": "2510.22045v1",
    "title": "VLM-SlideEval: Evaluating VLMs on Structured Comprehension and\n  Perturbation Sensitivity in PPT",
    "abstract": "Vision-language models (VLMs) are increasingly used to evaluate multimodal\ncontent, including presentation slides, yet their slide-specific understanding\nremains underexplored {despite their growing role as critics in agentic,\nmodel-forward pipelines}. We introduce VLM-SlideEval, an evaluation framework\nthat probes VLMs along three axes: (1) element-level extraction from slide\nimages aligned to ground truth; (2) robustness to controlled perturbations in\ngeometry, style, and text; and (3) higher-level comprehension, such as\nrecovering a deck's narrative order from shuffled slides. Using publicly\navailable decks from Zenodo\n(https://huggingface.co/datasets/Forceless/Zenodo10K/viewer/default/pptx), we\nstandardize ground-truth element metadata from PowerPoint XML and live\nrenderings into a unified, verifiable schema. Empirically, VLMs underperform on\npixel-accurate extraction and show non-trivial agreement, fidelity, and\nconsistency under controlled perturbations, while performing better on\nsingle-slide content understanding; however, they do not reliably capture\nnarrative structure across slides. These results highlight the limits of\ncurrent VLMs for slide evaluation and motivate calibrated, critic-in-the-loop\nevaluators that drive iterative refinement and selection in agentic pipelines.",
    "categories": [
      "cs.CV",
      "cs.AI"
    ],
    "published": "2025-10-24T22:06:56Z",
    "authors": [
      "Hyeonsu Kang",
      "Emily Bao",
      "Anjan Goswami"
    ],
    "pdf_url": "http://arxiv.org/pdf/2510.22045v1"
  },
  {
    "id": "2510.22042v1",
    "title": "Emotions Where Art Thou: Understanding and Characterizing the Emotional\n  Latent Space of Large Language Models",
    "abstract": "This work investigates how large language models (LLMs) internally represent\nemotion by analyzing the geometry of their hidden-state space. The paper\nidentifies a low-dimensional emotional manifold and shows that emotional\nrepresentations are directionally encoded, distributed across layers, and\naligned with interpretable dimensions. These structures are stable across depth\nand generalize to eight real-world emotion datasets spanning five languages.\nCross-domain alignment yields low error and strong linear probe performance,\nindicating a universal emotional subspace. Within this space, internal emotion\nperception can be steered while preserving semantics using a learned\nintervention module, with especially strong control for basic emotions across\nlanguages. These findings reveal a consistent and manipulable affective\ngeometry in LLMs and offer insight into how they internalize and process\nemotion.",
    "categories": [
      "cs.CL",
      "cs.AI"
    ],
    "published": "2025-10-24T21:54:12Z",
    "authors": [
      "Benjamin Reichman",
      "Adar Avsian",
      "Larry Heck"
    ],
    "pdf_url": "http://arxiv.org/pdf/2510.22042v1"
  },
  {
    "id": "2510.22039v1",
    "title": "Predictive Coding Enhances Meta-RL To Achieve Interpretable\n  Bayes-Optimal Belief Representation Under Partial Observability",
    "abstract": "Learning a compact representation of history is critical for planning and\ngeneralization in partially observable environments. While meta-reinforcement\nlearning (RL) agents can attain near Bayes-optimal policies, they often fail to\nlearn the compact, interpretable Bayes-optimal belief states. This\nrepresentational inefficiency potentially limits the agent's adaptability and\ngeneralization capacity. Inspired by predictive coding in neuroscience--which\nsuggests that the brain predicts sensory inputs as a neural implementation of\nBayesian inference--and by auxiliary predictive objectives in deep RL, we\ninvestigate whether integrating self-supervised predictive coding modules into\nmeta-RL can facilitate learning of Bayes-optimal representations. Through state\nmachine simulation, we show that meta-RL with predictive modules consistently\ngenerates more interpretable representations that better approximate\nBayes-optimal belief states compared to conventional meta-RL across a wide\nvariety of tasks, even when both achieve optimal policies. In challenging tasks\nrequiring active information seeking, only meta-RL with predictive modules\nsuccessfully learns optimal representations and policies, whereas conventional\nmeta-RL struggles with inadequate representation learning. Finally, we\ndemonstrate that better representation learning leads to improved\ngeneralization. Our results strongly suggest the role of predictive learning as\na guiding principle for effective representation learning in agents navigating\npartial observability.",
    "categories": [
      "cs.AI",
      "q-bio.NC"
    ],
    "published": "2025-10-24T21:45:56Z",
    "authors": [
      "Po-Chen Kuo",
      "Han Hou",
      "Will Dabney",
      "Edgar Y. Walker"
    ],
    "pdf_url": "http://arxiv.org/pdf/2510.22039v1"
  },
  {
    "id": "2510.22034v1",
    "title": "LLM-AR: LLM-powered Automated Reasoning Framework",
    "abstract": "Large language models (LLMs) can already identify patterns and reason\neffectively, yet their variable accuracy hampers adoption in high-stakes\ndecision-making applications. In this paper, we study this issue from a venture\ncapital perspective by predicting idea-stage startup success based on founder\ntraits. (i) To build a reliable prediction model, we introduce LLM-AR, a\npipeline inspired by neural-symbolic systems that distils LLM-generated\nheuristics into probabilistic rules executed by the ProbLog automated-reasoning\nengine. (ii) An iterative policy-evolution loop incorporates association-rule\nmining to progressively refine the prediction rules.\n  On unseen folds, LLM-AR achieves 59.5% precision and 8.7% recall, 5.9x the\nrandom baseline precision, while exposing every decision path for human\ninspection. The framework is interpretable and tunable via hyperparameters,\nshowing promise to extend into other domains.",
    "categories": [
      "cs.AI",
      "cs.LG"
    ],
    "published": "2025-10-24T21:36:18Z",
    "authors": [
      "Rick Chen",
      "Joseph Ternasky",
      "Aaron Ontoyin Yin",
      "Xianling Mu",
      "Fuat Alican",
      "Yigit Ihlamur"
    ],
    "pdf_url": "http://arxiv.org/pdf/2510.22034v1"
  },
  {
    "id": "2510.22031v1",
    "title": "Differentiable Constraint-Based Causal Discovery",
    "abstract": "Causal discovery from observational data is a fundamental task in artificial\nintelligence, with far-reaching implications for decision-making, predictions,\nand interventions. Despite significant advances, existing methods can be\nbroadly categorized as constraint-based or score-based approaches.\nConstraint-based methods offer rigorous causal discovery but are often hindered\nby small sample sizes, while score-based methods provide flexible optimization\nbut typically forgo explicit conditional independence testing. This work\nexplores a third avenue: developing differentiable $d$-separation scores,\nobtained through a percolation theory using soft logic. This enables the\nimplementation of a new type of causal discovery method: gradient-based\noptimization of conditional independence constraints. Empirical evaluations\ndemonstrate the robust performance of our approach in low-sample regimes,\nsurpassing traditional constraint-based and score-based baselines on a\nreal-world dataset. Code and data of the proposed method are publicly available\nat https://github$.$com/PurdueMINDS/DAGPA.",
    "categories": [
      "cs.LG",
      "cs.AI",
      "stat.ML"
    ],
    "published": "2025-10-24T21:28:39Z",
    "authors": [
      "Jincheng Zhou",
      "Mengbo Wang",
      "Anqi He",
      "Yumeng Zhou",
      "Hessam Olya",
      "Murat Kocaoglu",
      "Bruno Ribeiro"
    ],
    "pdf_url": "http://arxiv.org/pdf/2510.22031v1"
  },
  {
    "id": "2510.22027v1",
    "title": "Online Optimization for Offline Safe Reinforcement Learning",
    "abstract": "We study the problem of Offline Safe Reinforcement Learning (OSRL), where the\ngoal is to learn a reward-maximizing policy from fixed data under a cumulative\ncost constraint. We propose a novel OSRL approach that frames the problem as a\nminimax objective and solves it by combining offline RL with online\noptimization algorithms. We prove the approximate optimality of this approach\nwhen integrated with an approximate offline RL oracle and no-regret online\noptimization. We also present a practical approximation that can be combined\nwith any offline RL algorithm, eliminating the need for offline policy\nevaluation. Empirical results on the DSRL benchmark demonstrate that our method\nreliably enforces safety constraints under stringent cost budgets, while\nachieving high rewards. The code is available at\nhttps://github.com/yassineCh/O3SRL.",
    "categories": [
      "cs.LG",
      "cs.AI",
      "stat.ML"
    ],
    "published": "2025-10-24T21:12:47Z",
    "authors": [
      "Yassine Chemingui",
      "Aryan Deshwal",
      "Alan Fern",
      "Thanh Nguyen-Tang",
      "Janardhan Rao Doppa"
    ],
    "pdf_url": "http://arxiv.org/pdf/2510.22027v1"
  },
  {
    "id": "2510.22026v1",
    "title": "Normalization in Attention Dynamics",
    "abstract": "We study the effect of normalization schemes on token representations in deep\ntransformers. Modeling their evolution as interacting particles on the sphere,\nwe show that normalization acts as a form of speed regulation. This perspective\nenables a unified analysis of several schemes -- including Post-LN, Pre-LN,\nMix-LN, Peri-LN, nGPT, and LN-Scaling -- revealing how they influence\nclustering dynamics and representation collapse. Our framework clarifies how\ndifferent schemes shape token representations across layers and provides a\nprincipled basis for comparing them, identifying Peri-LN as a particularly\neffective choice.",
    "categories": [
      "cs.LG",
      "cs.AI",
      "68T07, 35Q68, 37C10, 37N99, 82C22"
    ],
    "published": "2025-10-24T21:10:16Z",
    "authors": [
      "Nikita Karagodin",
      "Shu Ge",
      "Yury Polyanskiy",
      "Philippe Rigollet"
    ],
    "pdf_url": "http://arxiv.org/pdf/2510.22026v1"
  },
  {
    "id": "2510.22014v1",
    "title": "Toward Understanding the Transferability of Adversarial Suffixes in\n  Large Language Models",
    "abstract": "Discrete optimization-based jailbreaking attacks on large language models aim\nto generate short, nonsensical suffixes that, when appended onto input prompts,\nelicit disallowed content. Notably, these suffixes are often transferable --\nsucceeding on prompts and models for which they were never optimized. And yet,\ndespite the fact that transferability is surprising and empirically\nwell-established, the field lacks a rigorous analysis of when and why transfer\noccurs. To fill this gap, we identify three statistical properties that\nstrongly correlate with transfer success across numerous experimental settings:\n(1) how much a prompt without a suffix activates a model's internal refusal\ndirection, (2) how strongly a suffix induces a push away from this direction,\nand (3) how large these shifts are in directions orthogonal to refusal. On the\nother hand, we find that prompt semantic similarity only weakly correlates with\ntransfer success. These findings lead to a more fine-grained understanding of\ntransferability, which we use in interventional experiments to showcase how our\nstatistical analysis can translate into practical improvements in attack\nsuccess.",
    "categories": [
      "cs.CL",
      "cs.AI"
    ],
    "published": "2025-10-24T20:28:49Z",
    "authors": [
      "Sarah Ball",
      "Niki Hasrati",
      "Alexander Robey",
      "Avi Schwarzschild",
      "Frauke Kreuter",
      "Zico Kolter",
      "Andrej Risteski"
    ],
    "pdf_url": "http://arxiv.org/pdf/2510.22014v1"
  },
  {
    "id": "2510.22011v1",
    "title": "Reconnaissance Automatique des Langues des Signes : Une Approche\n  Hybrid\u00e9e CNN-LSTM Bas\u00e9e sur Mediapipe",
    "abstract": "Sign languages play a crucial role in the communication of deaf communities,\nbut they are often marginalized, limiting access to essential services such as\nhealthcare and education. This study proposes an automatic sign language\nrecognition system based on a hybrid CNN-LSTM architecture, using Mediapipe for\ngesture keypoint extraction. Developed with Python, TensorFlow and Streamlit,\nthe system provides real-time gesture translation. The results show an average\naccuracy of 92\\%, with very good performance for distinct gestures such as\n``Hello'' and ``Thank you''. However, some confusions remain for visually\nsimilar gestures, such as ``Call'' and ``Yes''. This work opens up interesting\nperspectives for applications in various fields such as healthcare, education\nand public services.",
    "categories": [
      "cs.CV",
      "cs.AI"
    ],
    "published": "2025-10-24T20:25:25Z",
    "authors": [
      "Fraisse Sacr\u00e9 Takouchouang",
      "Ho Tuong Vinh"
    ],
    "pdf_url": "http://arxiv.org/pdf/2510.22011v1"
  },
  {
    "id": "2510.22009v1",
    "title": "LightAgent: Mobile Agentic Foundation Models",
    "abstract": "With the advancement of multimodal large language models (MLLMs), building\nGUI agent systems has become an increasingly promising direction-especially for\nmobile platforms, given their rich app ecosystems and intuitive touch\ninteractions. Yet mobile GUI agents face a critical dilemma: truly on-device\nmodels (4B or smaller) lack sufficient performance, while capable models\n(starting from 7B) are either too large for mobile deployment or prohibitively\ncostly (e.g., cloud-only closed-source MLLMs). To resolve this, we propose\nLightAgent, a mobile agentic foundation model solution that leverages\ndevice-cloud collaboration to tap the cost-efficiency of on-device models and\nthe high capability of cloud models, while avoiding their drawbacks.\nSpecifically, LightAgent enhances Qwen2.5-VL-3B via two-stage SFT->GRPO\ntraining on synthetic GUI data for strong decision-making, integrates an\nefficient long-reasoning mechanism to utilize historical interactions under\ntight resources, and defaults to on-device execution-only escalating\nchallenging subtasks to the cloud via real-time complexity assessment.\nExperiments on the online AndroidLab benchmark and diverse apps show LightAgent\nmatches or nears larger models, with a significant reduction in cloud costs.",
    "categories": [
      "cs.AI"
    ],
    "published": "2025-10-24T20:23:12Z",
    "authors": [
      "Yangqin Jiang",
      "Chao Huang"
    ],
    "pdf_url": "http://arxiv.org/pdf/2510.22009v1"
  },
  {
    "id": "2510.22003v1",
    "title": "Impact and Implications of Generative AI for Enterprise Architects in\n  Agile Environments: A Systematic Literature Review",
    "abstract": "Generative AI (GenAI) is reshaping enterprise architecture work in agile\nsoftware organizations, yet evidence on its effects remains scattered. We\nreport a systematic literature review (SLR), following established SLR\nprotocols of Kitchenham and PRISMA, of 1,697 records, yielding 33 studies\nacross enterprise, solution, domain, business, and IT architect roles. GenAI\nmost consistently supports (i) design ideation and trade-off exploration; (ii)\nrapid creation and refinement of artifacts (e.g., code, models, documentation);\nand (iii) architectural decision support and knowledge retrieval. Reported\nrisks include opacity and bias, contextually incorrect outputs leading to\nrework, privacy and compliance concerns, and social loafing. We also identify\nemerging skills and competencies, including prompt engineering, model\nevaluation, and professional oversight, and organizational enablers around\nreadiness and adaptive governance. The review contributes with (1) a mapping of\nGenAI use cases and risks in agile architecting, (2) implications for\ncapability building and governance, and (3) an initial research agenda on\nhuman-AI collaboration in architecture. Overall, the findings inform\nresponsible adoption of GenAI that accelerates digital transformation while\nsafeguarding architectural integrity.",
    "categories": [
      "cs.SE",
      "cs.AI"
    ],
    "published": "2025-10-24T20:09:54Z",
    "authors": [
      "Stefan Julian Kooy",
      "Jean Paul Sebastian Piest",
      "Rob Henk Bemthuis"
    ],
    "pdf_url": "http://arxiv.org/pdf/2510.22003v1"
  },
  {
    "id": "2510.21999v1",
    "title": "Foundation of Intelligence: Review of Math Word Problems from Human\n  Cognition Perspective",
    "abstract": "Math word problem (MWP) serves as a fundamental research topic in artificial\nintelligence (AI) dating back to 1960s. This research aims to advance the\nreasoning abilities of AI by mirroring the human-like cognitive intelligence.\nThe mainstream technological paradigm has evolved from the early rule-based\nmethods, to deep learning models, and is rapidly advancing towards large\nlanguage models. However, the field still lacks a systematic taxonomy for the\nMWP survey along with a discussion of current development trends. Therefore, in\nthis paper, we aim to comprehensively review related research in MWP solving\nthrough the lens of human cognition, to demonstrate how recent AI models are\nadvancing in simulating human cognitive abilities. Specifically, we summarize 5\ncrucial cognitive abilities for MWP solving, including Problem Understanding,\nLogical Organization, Associative Memory, Critical Thinking, and Knowledge\nLearning. Focused on these abilities, we review two mainstream MWP models in\nrecent 10 years: neural network solvers, and LLM based solvers, and discuss the\ncore human-like abilities they demonstrated in their intricate problem-solving\nprocess. Moreover, we rerun all the representative MWP solvers and supplement\ntheir performance on 5 mainstream benchmarks for a unified comparison. To the\nbest of our knowledge, this survey first comprehensively analyzes the\ninfluential MWP research of the past decade from the perspective of human\nreasoning cognition and provides an integrative overall comparison across\nexisting approaches. We hope it can inspire further research in AI reasoning.\nOur repository is released on https://github.com/Ljyustc/FoI-MWP.",
    "categories": [
      "cs.AI"
    ],
    "published": "2025-10-24T20:06:15Z",
    "authors": [
      "Zhenya Huang",
      "Jiayu Liu",
      "Xin Lin",
      "Zhiyuan Ma",
      "Shangzi Xue",
      "Tong Xiao",
      "Qi Liu",
      "Yee Whye Teh",
      "Enhong Chen"
    ],
    "pdf_url": "http://arxiv.org/pdf/2510.21999v1"
  },
  {
    "id": "2510.21998v1",
    "title": "From Black-box to Causal-box: Towards Building More Interpretable Models",
    "abstract": "Understanding the predictions made by deep learning models remains a central\nchallenge, especially in high-stakes applications. A promising approach is to\nequip models with the ability to answer counterfactual questions --\nhypothetical ``what if?'' scenarios that go beyond the observed data and\nprovide insight into a model reasoning. In this work, we introduce the notion\nof causal interpretability, which formalizes when counterfactual queries can be\nevaluated from a specific class of models and observational data. We analyze\ntwo common model classes -- blackbox and concept-based predictors -- and show\nthat neither is causally interpretable in general. To address this gap, we\ndevelop a framework for building models that are causally interpretable by\ndesign. Specifically, we derive a complete graphical criterion that determines\nwhether a given model architecture supports a given counterfactual query. This\nleads to a fundamental tradeoff between causal interpretability and predictive\naccuracy, which we characterize by identifying the unique maximal set of\nfeatures that yields an interpretable model with maximal predictive\nexpressiveness. Experiments corroborate the theoretical findings.",
    "categories": [
      "cs.LG",
      "cs.AI",
      "stat.ML"
    ],
    "published": "2025-10-24T20:03:18Z",
    "authors": [
      "Inwoo Hwang",
      "Yushu Pan",
      "Elias Bareinboim"
    ],
    "pdf_url": "http://arxiv.org/pdf/2510.21998v1"
  },
  {
    "id": "2510.21995v1",
    "title": "Is Temporal Difference Learning the Gold Standard for Stitching in RL?",
    "abstract": "Reinforcement learning (RL) promises to solve long-horizon tasks even when\ntraining data contains only short fragments of the behaviors. This experience\nstitching capability is often viewed as the purview of temporal difference (TD)\nmethods. However, outside of small tabular settings, trajectories never\nintersect, calling into question this conventional wisdom. Moreover, the common\nbelief is that Monte Carlo (MC) methods should not be able to recombine\nexperience, yet it remains unclear whether function approximation could result\nin a form of implicit stitching. The goal of this paper is to empirically study\nwhether the conventional wisdom about stitching actually holds in settings\nwhere function approximation is used. We empirically demonstrate that Monte\nCarlo (MC) methods can also achieve experience stitching. While TD methods do\nachieve slightly stronger capabilities than MC methods (in line with\nconventional wisdom), that gap is significantly smaller than the gap between\nsmall and large neural networks (even on quite simple tasks). We find that\nincreasing critic capacity effectively reduces the generalization gap for both\nthe MC and TD methods. These results suggest that the traditional TD inductive\nbias for stitching may be less necessary in the era of large models for RL and,\nin some cases, may offer diminishing returns. Additionally, our results suggest\nthat stitching, a form of generalization unique to the RL setting, might be\nachieved not through specialized algorithms (temporal difference learning) but\nrather through the same recipe that has provided generalization in other\nmachine learning settings (via scale). Project website:\nhttps://michalbortkiewicz.github.io/golden-standard/",
    "categories": [
      "cs.LG",
      "cs.AI",
      "stat.ML"
    ],
    "published": "2025-10-24T20:00:14Z",
    "authors": [
      "Micha\u0142 Bortkiewicz",
      "W\u0142adys\u0142aw Pa\u0142ucki",
      "Mateusz Ostaszewski",
      "Benjamin Eysenbach"
    ],
    "pdf_url": "http://arxiv.org/pdf/2510.21995v1"
  },
  {
    "id": "2510.21991v1",
    "title": "Two-Steps Diffusion Policy for Robotic Manipulation via Genetic\n  Denoising",
    "abstract": "Diffusion models, such as diffusion policy, have achieved state-of-the-art\nresults in robotic manipulation by imitating expert demonstrations. While\ndiffusion models were originally developed for vision tasks like image and\nvideo generation, many of their inference strategies have been directly\ntransferred to control domains without adaptation. In this work, we show that\nby tailoring the denoising process to the specific characteristics of embodied\nAI tasks -- particularly structured, low-dimensional nature of action\ndistributions -- diffusion policies can operate effectively with as few as 5\nneural function evaluations (NFE).\n  Building on this insight, we propose a population-based sampling strategy,\ngenetic denoising, which enhances both performance and stability by selecting\ndenoising trajectories with low out-of-distribution risk. Our method solves\nchallenging tasks with only 2 NFE while improving or matching performance. We\nevaluate our approach across 14 robotic manipulation tasks from D4RL and\nRobomimic, spanning multiple action horizons and inference budgets. In over 2\nmillion evaluations, our method consistently outperforms standard\ndiffusion-based policies, achieving up to 20\\% performance gains with\nsignificantly fewer inference steps.",
    "categories": [
      "cs.RO",
      "cs.AI",
      "68T40, 93C85, 68T07, 68U35"
    ],
    "published": "2025-10-24T19:52:41Z",
    "authors": [
      "Mateo Clemente",
      "Leo Brunswic",
      "Rui Heng Yang",
      "Xuan Zhao",
      "Yasser Khalil",
      "Haoyu Lei",
      "Amir Rasouli",
      "Yinchuan Li"
    ],
    "pdf_url": "http://arxiv.org/pdf/2510.21991v1"
  },
  {
    "id": "2510.21983v1",
    "title": "Uncovering the Persuasive Fingerprint of LLMs in Jailbreaking Attacks",
    "abstract": "Despite recent advances, Large Language Models remain vulnerable to jailbreak\nattacks that bypass alignment safeguards and elicit harmful outputs. While\nprior research has proposed various attack strategies differing in human\nreadability and transferability, little attention has been paid to the\nlinguistic and psychological mechanisms that may influence a model's\nsusceptibility to such attacks. In this paper, we examine an interdisciplinary\nline of research that leverages foundational theories of persuasion from the\nsocial sciences to craft adversarial prompts capable of circumventing alignment\nconstraints in LLMs. Drawing on well-established persuasive strategies, we\nhypothesize that LLMs, having been trained on large-scale human-generated text,\nmay respond more compliantly to prompts with persuasive structures.\nFurthermore, we investigate whether LLMs themselves exhibit distinct persuasive\nfingerprints that emerge in their jailbreak responses. Empirical evaluations\nacross multiple aligned LLMs reveal that persuasion-aware prompts significantly\nbypass safeguards, demonstrating their potential to induce jailbreak behaviors.\nThis work underscores the importance of cross-disciplinary insight in\naddressing the evolving challenges of LLM safety. The code and data are\navailable.",
    "categories": [
      "cs.CL",
      "cs.AI"
    ],
    "published": "2025-10-24T19:20:23Z",
    "authors": [
      "Havva Alizadeh Noughabi",
      "Julien Serbanescu",
      "Fattane Zarrinkalam",
      "Ali Dehghantanha"
    ],
    "pdf_url": "http://arxiv.org/pdf/2510.21983v1"
  },
  {
    "id": "2510.21978v1",
    "title": "Beyond Reasoning Gains: Mitigating General Capabilities Forgetting in\n  Large Reasoning Models",
    "abstract": "Reinforcement learning with verifiable rewards (RLVR) has delivered\nimpressive gains in mathematical and multimodal reasoning and has become a\nstandard post-training paradigm for contemporary language and vision-language\nmodels. However, the RLVR recipe introduces a significant risk of capability\nregression, where models forget foundational skills after prolonged training\nwithout employing regularization strategies. We empirically confirm this\nconcern, observing that open-source reasoning models suffer performance\ndegradation on core capabilities such as perception and faithfulness. While\nimposing regularization terms like KL divergence can help prevent deviation\nfrom the base model, these terms are calculated on the current task, thus they\ndo not guarantee broader knowledge. Meanwhile, commonly used experience replay\nacross heterogeneous domains makes it nontrivial to decide how much training\nfocus each objective should receive. To address this, we propose RECAP-a replay\nstrategy with dynamic objective reweighting for general knowledge preservation.\nOur reweighting mechanism adapts in an online manner using short-horizon\nsignals of convergence and instability, shifting the post-training focus away\nfrom saturated objectives and toward underperforming or volatile ones. Our\nmethod is end-to-end and readily applicable to existing RLVR pipelines without\ntraining additional models or heavy tuning. Extensive experiments on benchmarks\nbased on Qwen2.5-VL-3B and Qwen2.5-VL-7B demonstrate the effectiveness of our\nmethod, which not only preserves general capabilities but also improves\nreasoning by enabling more flexible trade-offs among in-task rewards.",
    "categories": [
      "cs.LG",
      "cs.AI"
    ],
    "published": "2025-10-24T19:08:48Z",
    "authors": [
      "Hoang Phan",
      "Xianjun Yang",
      "Kevin Yao",
      "Jingyu Zhang",
      "Shengjie Bi",
      "Xiaocheng Tang",
      "Madian Khabsa",
      "Lijuan Liu",
      "Deren Lei"
    ],
    "pdf_url": "http://arxiv.org/pdf/2510.21978v1"
  },
  {
    "id": "2510.21977v1",
    "title": "Distribution Shift Alignment Helps LLMs Simulate Survey Response\n  Distributions",
    "abstract": "Large language models (LLMs) offer a promising way to simulate human survey\nresponses, potentially reducing the cost of large-scale data collection.\nHowever, existing zero-shot methods suffer from prompt sensitivity and low\naccuracy, while conventional fine-tuning approaches mostly fit the training set\ndistributions and struggle to produce results more accurate than the training\nset itself, which deviates from the original goal of using LLMs to simulate\nsurvey responses. Building on this observation, we introduce Distribution Shift\nAlignment (DSA), a two-stage fine-tuning method that aligns both the output\ndistributions and the distribution shifts across different backgrounds. By\nlearning how these distributions change rather than fitting training data, DSA\ncan provide results substantially closer to the true distribution than the\ntraining data. Empirically, DSA consistently outperforms other methods on five\npublic survey datasets. We further conduct a comprehensive comparison covering\naccuracy, robustness, and data savings. DSA reduces the required real data by\n53.48-69.12%, demonstrating its effectiveness and efficiency in survey\nsimulation.",
    "categories": [
      "cs.AI"
    ],
    "published": "2025-10-24T19:04:19Z",
    "authors": [
      "Ji Huang",
      "Mengfei Li",
      "Shuai Shao"
    ],
    "pdf_url": "http://arxiv.org/pdf/2510.21977v1"
  },
  {
    "id": "2510.23643v1",
    "title": "SAND: A Self-supervised and Adaptive NAS-Driven Framework for Hardware\n  Trojan Detection",
    "abstract": "The globalized semiconductor supply chain has made Hardware Trojans (HT) a\nsignificant security threat to embedded systems, necessitating the design of\nefficient and adaptable detection mechanisms. Despite promising machine\nlearning-based HT detection techniques in the literature, they suffer from ad\nhoc feature selection and the lack of adaptivity, all of which hinder their\neffectiveness across diverse HT attacks. In this paper, we propose SAND, a\nselfsupervised and adaptive NAS-driven framework for efficient HT detection.\nSpecifically, this paper makes three key contributions. (1) We leverage\nself-supervised learning (SSL) to enable automated feature extraction,\neliminating the dependency on manually engineered features. (2) SAND integrates\nneural architecture search (NAS) to dynamically optimize the downstream\nclassifier, allowing for seamless adaptation to unseen benchmarks with minimal\nfine-tuning. (3) Experimental results show that SAND achieves a significant\nimprovement in detection accuracy (up to 18.3%) over state-of-the-art methods,\nexhibits high resilience against evasive Trojans, and demonstrates strong\ngeneralization.",
    "categories": [
      "cs.CR",
      "cs.AI",
      "cs.LG",
      "I.2.6; D.4.6"
    ],
    "published": "2025-10-24T18:55:00Z",
    "authors": [
      "Zhixin Pan",
      "Ziyu Shu",
      "Linh Nguyen",
      "Amberbir Alemayoh"
    ],
    "pdf_url": "http://arxiv.org/pdf/2510.23643v1"
  },
  {
    "id": "2510.21970v1",
    "title": "Performance Trade-offs of Optimizing Small Language Models for\n  E-Commerce",
    "abstract": "Large Language Models (LLMs) offer state-of-the-art performance in natural\nlanguage understanding and generation tasks. However, the deployment of leading\ncommercial models for specialized tasks, such as e-commerce, is often hindered\nby high computational costs, latency, and operational expenses. This paper\ninvestigates the viability of smaller, open-weight models as a\nresource-efficient alternative. We present a methodology for optimizing a\none-billion-parameter Llama 3.2 model for multilingual e-commerce intent\nrecognition. The model was fine-tuned using Quantized Low-Rank Adaptation\n(QLoRA) on a synthetically generated dataset designed to mimic real-world user\nqueries. Subsequently, we applied post-training quantization techniques,\ncreating GPU-optimized (GPTQ) and CPU-optimized (GGUF) versions. Our results\ndemonstrate that the specialized 1B model achieves 99% accuracy, matching the\nperformance of the significantly larger GPT-4.1 model. A detailed performance\nanalysis revealed critical, hardware-dependent trade-offs: while 4-bit GPTQ\nreduced VRAM usage by 41%, it paradoxically slowed inference by 82% on an older\nGPU architecture (NVIDIA T4) due to dequantization overhead. Conversely, GGUF\nformats on a CPU achieved a speedup of up to 18x in inference throughput and a\nreduction of over 90% in RAM consumption compared to the FP16 baseline. We\nconclude that small, properly optimized open-weight models are not just a\nviable but a more suitable alternative for domain-specific applications,\noffering state-of-the-art accuracy at a fraction of the computational cost.",
    "categories": [
      "cs.AI",
      "cs.CL"
    ],
    "published": "2025-10-24T18:49:28Z",
    "authors": [
      "Josip Tomo Licardo",
      "Nikola Tankovic"
    ],
    "pdf_url": "http://arxiv.org/pdf/2510.21970v1"
  },
  {
    "id": "2510.21966v1",
    "title": "ArchISMiner: A Framework for Automatic Mining of Architectural\n  Issue-Solution Pairs from Online Developer Communities",
    "abstract": "Stack Overflow (SO), a leading online community forum, is a rich source of\nsoftware development knowledge. However, locating architectural knowledge, such\nas architectural solutions remains challenging due to the overwhelming volume\nof unstructured content and fragmented discussions. Developers must manually\nsift through posts to find relevant architectural insights, which is\ntime-consuming and error-prone. This study introduces ArchISMiner, a framework\nfor mining architectural knowledge from SO. The framework comprises two\ncomplementary components: ArchPI and ArchISPE. ArchPI trains and evaluates\nmultiple models, including conventional ML/DL models, Pre-trained Language\nModels (PLMs), and Large Language Models (LLMs), and selects the\nbest-performing model to automatically identify Architecture-Related Posts\n(ARPs) among programming-related discussions. ArchISPE employs an indirect\nsupervised approach that leverages diverse features, including BERT embeddings\nand local TextCNN features, to extract architectural issue-solution pairs. Our\nevaluation shows that the best model in ArchPI achieves an F1-score of 0.960 in\nARP detection, and ArchISPE outperforms baselines in both SE and NLP fields,\nachieving F1-scores of 0.883 for architectural issues and 0.894 for solutions.\nA user study further validated the quality (e.g., relevance and usefulness) of\nthe identified ARPs and the extracted issue-solution pairs. Moreover, we\napplied ArchISMiner to three additional forums, releasing a dataset of over 18K\narchitectural issue-solution pairs. Overall, ArchISMiner can help architects\nand developers identify ARPs and extract succinct, relevant, and useful\narchitectural knowledge from developer communities more accurately and\nefficiently. The replication package of this study has been provided at\nhttps://github.com/JeanMusenga/ArchISPE",
    "categories": [
      "cs.SE",
      "cs.AI"
    ],
    "published": "2025-10-24T18:46:17Z",
    "authors": [
      "Musengamana Jean de Dieu",
      "Ruiyin Li",
      "Peng Liang",
      "Mojtaba Shahin",
      "Muhammad Waseem",
      "Arif Ali Khan",
      "Bangchao Wang",
      "Mst Shamima Aktar"
    ],
    "pdf_url": "http://arxiv.org/pdf/2510.21966v1"
  },
  {
    "id": "2510.21957v1",
    "title": "Towards Low-Latency and Adaptive Ransomware Detection Using Contrastive\n  Learning",
    "abstract": "Ransomware has become a critical threat to cybersecurity due to its rapid\nevolution, the necessity for early detection, and growing diversity, posing\nsignificant challenges to traditional detection methods. While AI-based\napproaches had been proposed by prior works to assist ransomware detection,\nexisting methods suffer from three major limitations, ad-hoc feature\ndependencies, delayed response, and limited adaptability to unseen variants. In\nthis paper, we propose a framework that integrates self-supervised contrastive\nlearning with neural architecture search (NAS) to address these challenges.\nSpecifically, this paper offers three important contributions. (1) We design a\ncontrastive learning framework that incorporates hardware performance counters\n(HPC) to analyze the runtime behavior of target ransomware. (2) We introduce a\ncustomized loss function that encourages early-stage detection of malicious\nactivity, and significantly reduces the detection latency. (3) We deploy a\nneural architecture search (NAS) framework to automatically construct adaptive\nmodel architectures, allowing the detector to flexibly align with unseen\nransomware variants. Experimental results show that our proposed method\nachieves significant improvements in both detection accuracy (up to 16.1%) and\nresponse time (up to 6x) compared to existing approaches while maintaining\nrobustness under evasive attacks.",
    "categories": [
      "cs.CR",
      "cs.AI",
      "K.6.5; I.2.6"
    ],
    "published": "2025-10-24T18:33:52Z",
    "authors": [
      "Zhixin Pan",
      "Ziyu Shu",
      "Amberbir Alemayoh"
    ],
    "pdf_url": "http://arxiv.org/pdf/2510.21957v1"
  },
  {
    "id": "2510.21935v1",
    "title": "AutoSciDACT: Automated Scientific Discovery through Contrastive\n  Embedding and Hypothesis Testing",
    "abstract": "Novelty detection in large scientific datasets faces two key challenges: the\nnoisy and high-dimensional nature of experimental data, and the necessity of\nmaking statistically robust statements about any observed outliers. While there\nis a wealth of literature on anomaly detection via dimensionality reduction,\nmost methods do not produce outputs compatible with quantifiable claims of\nscientific discovery. In this work we directly address these challenges,\npresenting the first step towards a unified pipeline for novelty detection\nadapted for the rigorous statistical demands of science. We introduce\nAutoSciDACT (Automated Scientific Discovery with Anomalous Contrastive\nTesting), a general-purpose pipeline for detecting novelty in scientific data.\nAutoSciDACT begins by creating expressive low-dimensional data representations\nusing a contrastive pre-training, leveraging the abundance of high-quality\nsimulated data in many scientific domains alongside expertise that can guide\nprincipled data augmentation strategies. These compact embeddings then enable\nan extremely sensitive machine learning-based two-sample test using the New\nPhysics Learning Machine (NPLM) framework, which identifies and statistically\nquantifies deviations in observed data relative to a reference distribution\n(null hypothesis). We perform experiments across a range of astronomical,\nphysical, biological, image, and synthetic datasets, demonstrating strong\nsensitivity to small injections of anomalous data across all domains.",
    "categories": [
      "cs.LG",
      "cs.AI",
      "stat.ML"
    ],
    "published": "2025-10-24T18:07:50Z",
    "authors": [
      "Samuel Bright-Thonney",
      "Christina Reissel",
      "Gaia Grosso",
      "Nathaniel Woodward",
      "Katya Govorkova",
      "Andrzej Novak",
      "Sang Eon Park",
      "Eric Moreno",
      "Philip Harris"
    ],
    "pdf_url": "http://arxiv.org/pdf/2510.21935v1"
  },
  {
    "id": "2510.21933v1",
    "title": "A Comparison of Conversational Models and Humans in Answering Technical\n  Questions: the Firefox Case",
    "abstract": "The use of Large Language Models (LLMs) to support tasks in software\ndevelopment has steadily increased over recent years. From assisting developers\nin coding activities to providing conversational agents that answer newcomers'\nquestions. In collaboration with the Mozilla Foundation, this study evaluates\nthe effectiveness of Retrieval-Augmented Generation (RAG) in assisting\ndevelopers within the Mozilla Firefox project. We conducted an empirical\nanalysis comparing responses from human developers, a standard GPT model, and a\nGPT model enhanced with RAG, using real queries from Mozilla's developer chat\nrooms. To ensure a rigorous evaluation, Mozilla experts assessed the responses\nbased on helpfulness, comprehensiveness, and conciseness. The results show that\nRAG-assisted responses were more comprehensive than human developers (62.50% to\n54.17%) and almost as helpful (75.00% to 79.17%), suggesting RAG's potential to\nenhance developer assistance. However, the RAG responses were not as concise\nand often verbose. The results show the potential to apply RAG-based tools to\nOpen Source Software (OSS) to minimize the load to core maintainers without\nlosing answer quality. Toning down retrieval mechanisms and making responses\neven shorter in the future would enhance developer assistance in massive\nprojects like Mozilla Firefox.",
    "categories": [
      "cs.SE",
      "cs.AI"
    ],
    "published": "2025-10-24T18:05:01Z",
    "authors": [
      "Joao Correia",
      "Daniel Coutinho",
      "Marco Castelluccio",
      "Caio Barbosa",
      "Rafael de Mello",
      "Anita Sarma",
      "Alessandro Garcia",
      "Marco Gerosa",
      "Igor Steinmacher"
    ],
    "pdf_url": "http://arxiv.org/pdf/2510.21933v1"
  },
  {
    "id": "2510.23642v1",
    "title": "VisCoder2: Building Multi-Language Visualization Coding Agents",
    "abstract": "Large language models (LLMs) have recently enabled coding agents capable of\ngenerating, executing, and revising visualization code. However, existing\nmodels often fail in practical workflows due to limited language coverage,\nunreliable execution, and lack of iterative correction mechanisms. Progress has\nbeen constrained by narrow datasets and benchmarks that emphasize single-round\ngeneration and single-language tasks. To address these challenges, we introduce\nthree complementary resources for advancing visualization coding agents.\nVisCode-Multi-679K is a large-scale, supervised dataset containing 679K\nvalidated and executable visualization samples with multi-turn correction\ndialogues across 12 programming languages. VisPlotBench is a benchmark for\nsystematic evaluation, featuring executable tasks, rendered outputs, and\nprotocols for both initial generation and multi-round self-debug. Finally, we\npresent VisCoder2, a family of multi-language visualization models trained on\nVisCode-Multi-679K. Experiments show that VisCoder2 significantly outperforms\nstrong open-source baselines and approaches the performance of proprietary\nmodels like GPT-4.1, with further gains from iterative self-debug, reaching\n82.4% overall execution pass rate at the 32B scale, particularly in symbolic or\ncompiler-dependent languages.",
    "categories": [
      "cs.SE",
      "cs.AI",
      "cs.CL",
      "cs.PL"
    ],
    "published": "2025-10-24T18:03:57Z",
    "authors": [
      "Yuansheng Ni",
      "Songcheng Cai",
      "Xiangchao Chen",
      "Jiarong Liang",
      "Zhiheng Lyu",
      "Jiaqi Deng",
      "Kai Zou",
      "Ping Nie",
      "Fei Yuan",
      "Xiang Yue",
      "Wenhu Chen"
    ],
    "pdf_url": "http://arxiv.org/pdf/2510.23642v1"
  },
  {
    "id": "2510.23641v1",
    "title": "Spatially Aware Linear Transformer (SAL-T) for Particle Jet Tagging",
    "abstract": "Transformers are very effective in capturing both global and local\ncorrelations within high-energy particle collisions, but they present\ndeployment challenges in high-data-throughput environments, such as the CERN\nLHC. The quadratic complexity of transformer models demands substantial\nresources and increases latency during inference. In order to address these\nissues, we introduce the Spatially Aware Linear Transformer (SAL-T), a\nphysics-inspired enhancement of the linformer architecture that maintains\nlinear attention. Our method incorporates spatially aware partitioning of\nparticles based on kinematic features, thereby computing attention between\nregions of physical significance. Additionally, we employ convolutional layers\nto capture local correlations, informed by insights from jet physics. In\naddition to outperforming the standard linformer in jet classification tasks,\nSAL-T also achieves classification results comparable to full-attention\ntransformers, while using considerably fewer resources with lower latency\nduring inference. Experiments on a generic point cloud classification dataset\n(ModelNet10) further confirm this trend. Our code is available at\nhttps://github.com/aaronw5/SAL-T4HEP.",
    "categories": [
      "cs.LG",
      "cs.AI",
      "hep-ex",
      "physics.ins-det"
    ],
    "published": "2025-10-24T18:00:01Z",
    "authors": [
      "Aaron Wang",
      "Zihan Zhao",
      "Subash Katel",
      "Vivekanand Gyanchand Sahu",
      "Elham E Khoda",
      "Abhijith Gandrakota",
      "Jennifer Ngadiuba",
      "Richard Cavanaugh",
      "Javier Duarte"
    ],
    "pdf_url": "http://arxiv.org/pdf/2510.23641v1"
  },
  {
    "id": "2510.21695v1",
    "title": "A Knowledge-Graph Translation Layer for Mission-Aware Multi-Agent Path\n  Planning in Spatiotemporal Dynamics",
    "abstract": "The coordination of autonomous agents in dynamic environments is hampered by\nthe semantic gap between high-level mission objectives and low-level planner\ninputs. To address this, we introduce a framework centered on a Knowledge Graph\n(KG) that functions as an intelligent translation layer. The KG's two-plane\narchitecture compiles declarative facts into per-agent, mission-aware\n``worldviews\" and physics-aware traversal rules, decoupling mission semantics\nfrom a domain-agnostic planner. This allows complex, coordinated paths to be\nmodified simply by changing facts in the KG. A case study involving Autonomous\nUnderwater Vehicles (AUVs) in the Gulf of Mexico visually demonstrates the\nend-to-end process and quantitatively proves that different declarative\npolicies produce distinct, high-performing outcomes. This work establishes the\nKG not merely as a data repository, but as a powerful, stateful orchestrator\nfor creating adaptive and explainable autonomous systems.",
    "categories": [
      "cs.AI"
    ],
    "published": "2025-10-24T17:55:55Z",
    "authors": [
      "Edward Holmberg",
      "Elias Ioup",
      "Mahdi Abdelguerfi"
    ],
    "pdf_url": "http://arxiv.org/pdf/2510.21695v1"
  },
  {
    "id": "2510.21689v1",
    "title": "On Thin Ice: Towards Explainable Conservation Monitoring via Attribution\n  and Perturbations",
    "abstract": "Computer vision can accelerate ecological research and conservation\nmonitoring, yet adoption in ecology lags in part because of a lack of trust in\nblack-box neural-network-based models. We seek to address this challenge by\napplying post-hoc explanations to provide evidence for predictions and document\nlimitations that are important to field deployment. Using aerial imagery from\nGlacier Bay National Park, we train a Faster R-CNN to detect pinnipeds (harbor\nseals) and generate explanations via gradient-based class activation mapping\n(HiResCAM, LayerCAM), local interpretable model-agnostic explanations (LIME),\nand perturbation-based explanations. We assess explanations along three axes\nrelevant to field use: (i) localization fidelity: whether high-attribution\nregions coincide with the animal rather than background context; (ii)\nfaithfulness: whether deletion/insertion tests produce changes in detector\nconfidence; and (iii) diagnostic utility: whether explanations reveal\nsystematic failure modes. Explanations concentrate on seal torsos and contours\nrather than surrounding ice/rock, and removal of the seals reduces detection\nconfidence, providing model-evidence for true positives. The analysis also\nuncovers recurrent error sources, including confusion between seals and black\nice and rocks. We translate these findings into actionable next steps for model\ndevelopment, including more targeted data curation and augmentation. By pairing\nobject detection with post-hoc explainability, we can move beyond \"black-box\"\npredictions toward auditable, decision-supporting tools for conservation\nmonitoring.",
    "categories": [
      "cs.CV",
      "cs.AI"
    ],
    "published": "2025-10-24T17:46:24Z",
    "authors": [
      "Jiayi Zhou",
      "G\u00fcnel Aghakishiyeva",
      "Saagar Arya",
      "Julian Dale",
      "James David Poling",
      "Holly R. Houliston",
      "Jamie N. Womble",
      "Gregory D. Larsen",
      "David W. Johnston",
      "Brinnae Bent"
    ],
    "pdf_url": "http://arxiv.org/pdf/2510.21689v1"
  },
  {
    "id": "2510.21679v1",
    "title": "A Multimodal Benchmark for Framing of Oil & Gas Advertising and\n  Potential Greenwashing Detection",
    "abstract": "Companies spend large amounts of money on public relations campaigns to\nproject a positive brand image. However, sometimes there is a mismatch between\nwhat they say and what they do. Oil & gas companies, for example, are accused\nof \"greenwashing\" with imagery of climate-friendly initiatives. Understanding\nthe framing, and changes in framing, at scale can help better understand the\ngoals and nature of public relations campaigns. To address this, we introduce a\nbenchmark dataset of expert-annotated video ads obtained from Facebook and\nYouTube. The dataset provides annotations for 13 framing types for more than 50\ncompanies or advocacy groups across 20 countries. Our dataset is especially\ndesigned for the evaluation of vision-language models (VLMs), distinguishing it\nfrom past text-only framing datasets. Baseline experiments show some promising\nresults, while leaving room for improvement for future work: GPT-4.1 can detect\nenvironmental messages with 79% F1 score, while our best model only achieves\n46% F1 score on identifying framing around green innovation. We also identify\nchallenges that VLMs must address, such as implicit framing, handling videos of\nvarious lengths, or implicit cultural backgrounds. Our dataset contributes to\nresearch in multimodal analysis of strategic communication in the energy\nsector.",
    "categories": [
      "cs.AI"
    ],
    "published": "2025-10-24T17:34:28Z",
    "authors": [
      "Gaku Morio",
      "Harri Rowlands",
      "Dominik Stammbach",
      "Christopher D. Manning",
      "Peter Henderson"
    ],
    "pdf_url": "http://arxiv.org/pdf/2510.21679v1"
  },
  {
    "id": "2510.23640v1",
    "title": "Structure-Aware Fusion with Progressive Injection for Multimodal\n  Molecular Representation Learning",
    "abstract": "Multimodal molecular models often suffer from 3D conformer unreliability and\nmodality collapse, limiting their robustness and generalization. We propose\nMuMo, a structured multimodal fusion framework that addresses these challenges\nin molecular representation through two key strategies. To reduce the\ninstability of conformer-dependent fusion, we design a Structured Fusion\nPipeline (SFP) that combines 2D topology and 3D geometry into a unified and\nstable structural prior. To mitigate modality collapse caused by naive fusion,\nwe introduce a Progressive Injection (PI) mechanism that asymmetrically\nintegrates this prior into the sequence stream, preserving modality-specific\nmodeling while enabling cross-modal enrichment. Built on a state space\nbackbone, MuMo supports long-range dependency modeling and robust information\npropagation. Across 29 benchmark tasks from Therapeutics Data Commons (TDC) and\nMoleculeNet, MuMo achieves an average improvement of 2.7% over the\nbest-performing baseline on each task, ranking first on 22 of them, including a\n27% improvement on the LD50 task. These results validate its robustness to 3D\nconformer noise and the effectiveness of multimodal fusion in molecular\nrepresentation. The code is available at: github.com/selmiss/MuMo.",
    "categories": [
      "cs.LG",
      "cs.AI"
    ],
    "published": "2025-10-24T17:27:10Z",
    "authors": [
      "Zihao Jing",
      "Yan Sun",
      "Yan Yi Li",
      "Sugitha Janarthanan",
      "Alana Deng",
      "Pingzhao Hu"
    ],
    "pdf_url": "http://arxiv.org/pdf/2510.23640v1"
  },
  {
    "id": "2510.21908v1",
    "title": "Enabling Robust In-Context Memory and Rapid Task Adaptation in\n  Transformers with Hebbian and Gradient-Based Plasticity",
    "abstract": "Large language models display in-context learning as an emergent effect of\nscale, but they rely on static weights during inference. In contrast,\nbiological systems continually adapt via synaptic plasticity. We investigate\nwhether explicit, biologically inspired plasticity can endow Transformers with\nfaster in-sequence adaptation. To this end, we augment decoder-only\nTransformers with fast-weight modules updated either by (i) a neuromodulated\nHebbian rule or (ii) the gradient-based plasticity mechanism of Duan et al.\n(2023). Across copying, regression, and few-shot classification tasks\n(CIFAR-FS, Omniglot), Hebbian plasticity consistently achieves lower loss and\nstronger few-shot generalization, while gradient-based updates perform best on\nlong-horizon credit assignment. When associations are short and linearly\nseparable, static weights suffice, defining a clear boundary condition for when\nplasticity helps. Analysis of learned modulatory signals reveals that\ngradient-based rules maintain large, persistent updates, whereas Hebbian\nplasticity is sharply gated around salient events. Together, these results show\nthat explicit plasticity complements attention by enabling rapid, task-specific\nadaptation, and clarify when different plasticity mechanisms are most\neffective.",
    "categories": [
      "cs.NE",
      "cs.AI",
      "cs.LG"
    ],
    "published": "2025-10-24T17:26:03Z",
    "authors": [
      "Siddharth Chaudhary"
    ],
    "pdf_url": "http://arxiv.org/pdf/2510.21908v1"
  },
  {
    "id": "2510.24772v1",
    "title": "Confidence is Not Competence",
    "abstract": "Large language models (LLMs) often exhibit a puzzling disconnect between\ntheir asserted confidence and actual problem-solving competence. We offer a\nmechanistic account of this decoupling by analyzing the geometry of internal\nstates across two phases - pre-generative assessment and solution execution. A\nsimple linear probe decodes the internal \"solvability belief\" of a model,\nrevealing a well-ordered belief axis that generalizes across model families and\nacross math, code, planning, and logic tasks. Yet, the geometries diverge -\nalthough belief is linearly decodable, the assessment manifold has high linear\neffective dimensionality as measured from the principal components, while the\nsubsequent reasoning trace evolves on a much lower-dimensional manifold. This\nsharp reduction in geometric complexity from thought to action mechanistically\nexplains the confidence-competence gap. Causal interventions that steer\nrepresentations along the belief axis leave final solutions unchanged,\nindicating that linear nudges in the complex assessment space do not control\nthe constrained dynamics of execution. We thus uncover a two-system\narchitecture - a geometrically complex assessor feeding a geometrically simple\nexecutor. These results challenge the assumption that decodable beliefs are\nactionable levers, instead arguing for interventions that target the procedural\ndynamics of execution rather than the high-level geometry of assessment.",
    "categories": [
      "cs.CL",
      "cs.AI"
    ],
    "published": "2025-10-24T17:22:48Z",
    "authors": [
      "Debdeep Sanyal",
      "Manya Pandey",
      "Dhruv Kumar",
      "Saurabh Deshpande",
      "Murari Mandal"
    ],
    "pdf_url": "http://arxiv.org/pdf/2510.24772v1"
  },
  {
    "id": "2510.21656v1",
    "title": "CMOMgen: Complex Multi-Ontology Alignment via Pattern-Guided In-Context\n  Learning",
    "abstract": "Constructing comprehensive knowledge graphs requires the use of multiple\nontologies in order to fully contextualize data into a domain. Ontology\nmatching finds equivalences between concepts interconnecting ontologies and\ncreating a cohesive semantic layer. While the simple pairwise state of the art\nis well established, simple equivalence mappings cannot provide full semantic\nintegration of related but disjoint ontologies. Complex multi-ontology matching\n(CMOM) aligns one source entity to composite logical expressions of multiple\ntarget entities, establishing more nuanced equivalences and provenance along\nthe ontological hierarchy.\n  We present CMOMgen, the first end-to-end CMOM strategy that generates\ncomplete and semantically sound mappings, without establishing any restrictions\non the number of target ontologies or entities. Retrieval-Augmented Generation\nselects relevant classes to compose the mapping and filters matching reference\nmappings to serve as examples, enhancing In-Context Learning. The strategy was\nevaluated in three biomedical tasks with partial reference alignments. CMOMgen\noutperforms baselines in class selection, demonstrating the impact of having a\ndedicated strategy. Our strategy also achieves a minimum of 63% in F1-score,\noutperforming all baselines and ablated versions in two out of three tasks and\nplacing second in the third. Furthermore, a manual evaluation of non-reference\nmappings showed that 46% of the mappings achieve the maximum score, further\nsubstantiating its ability to construct semantically sound mappings.",
    "categories": [
      "cs.AI"
    ],
    "published": "2025-10-24T17:12:22Z",
    "authors": [
      "Marta Contreiras Silva",
      "Daniel Faria",
      "Catia Pesquita"
    ],
    "pdf_url": "http://arxiv.org/pdf/2510.21656v1"
  },
  {
    "id": "2510.21654v1",
    "title": "Group Inertial Poser: Multi-Person Pose and Global Translation from\n  Sparse Inertial Sensors and Ultra-Wideband Ranging",
    "abstract": "Tracking human full-body motion using sparse wearable inertial measurement\nunits (IMUs) overcomes the limitations of occlusion and instrumentation of the\nenvironment inherent in vision-based approaches. However, purely IMU-based\ntracking compromises translation estimates and accurate relative positioning\nbetween individuals, as inertial cues are inherently self-referential and\nprovide no direct spatial reference for others. In this paper, we present a\nnovel approach for robustly estimating body poses and global translation for\nmultiple individuals by leveraging the distances between sparse wearable\nsensors - both on each individual and across multiple individuals. Our method\nGroup Inertial Poser estimates these absolute distances between pairs of\nsensors from ultra-wideband ranging (UWB) and fuses them with inertial\nobservations as input into structured state-space models to integrate temporal\nmotion patterns for precise 3D pose estimation. Our novel two-step optimization\nfurther leverages the estimated distances for accurately tracking people's\nglobal trajectories through the world. We also introduce GIP-DB, the first\nIMU+UWB dataset for two-person tracking, which comprises 200 minutes of motion\nrecordings from 14 participants. In our evaluation, Group Inertial Poser\noutperforms previous state-of-the-art methods in accuracy and robustness across\nsynthetic and real-world data, showing the promise of IMU+UWB-based multi-human\nmotion capture in the wild. Code, models, dataset:\nhttps://github.com/eth-siplab/GroupInertialPoser",
    "categories": [
      "cs.CV",
      "cs.AI",
      "cs.GR",
      "cs.HC",
      "68T07, 68T45, 68U01",
      "I.2; I.3; I.4; I.5"
    ],
    "published": "2025-10-24T17:11:50Z",
    "authors": [
      "Ying Xue",
      "Jiaxi Jiang",
      "Rayan Armani",
      "Dominik Hollidt",
      "Yi-Chi Liao",
      "Christian Holz"
    ],
    "pdf_url": "http://arxiv.org/pdf/2510.21654v1"
  },
  {
    "id": "2510.21652v1",
    "title": "AstaBench: Rigorous Benchmarking of AI Agents with a Scientific Research\n  Suite",
    "abstract": "AI agents hold the potential to revolutionize scientific productivity by\nautomating literature reviews, replicating experiments, analyzing data, and\neven proposing new directions of inquiry; indeed, there are now many such\nagents, ranging from general-purpose \"deep research\" systems to specialized\nscience-specific agents, such as AI Scientist and AIGS. Rigorous evaluation of\nthese agents is critical for progress. Yet existing benchmarks fall short on\nseveral fronts: they (1) fail to provide holistic, product-informed measures of\nreal-world use cases such as science research; (2) lack reproducible agent\ntools necessary for a controlled comparison of core agentic capabilities; (3)\ndo not account for confounding variables such as model cost and tool access;\n(4) do not provide standardized interfaces for quick agent prototyping and\nevaluation; and (5) lack comprehensive baseline agents necessary to identify\ntrue advances. In response, we define principles and tooling for more\nrigorously benchmarking agents. Using these, we present AstaBench, a suite that\nprovides the first holistic measure of agentic ability to perform scientific\nresearch, comprising 2400+ problems spanning the entire scientific discovery\nprocess and multiple scientific domains, and including many problems inspired\nby actual user requests to deployed Asta agents. Our suite comes with the first\nscientific research environment with production-grade search tools that enable\ncontrolled, reproducible evaluation, better accounting for confounders.\nAlongside, we provide a comprehensive suite of nine science-optimized classes\nof Asta agents and numerous baselines. Our extensive evaluation of 57 agents\nacross 22 agent classes reveals several interesting findings, most importantly\nthat despite meaningful progress on certain individual aspects, AI remains far\nfrom solving the challenge of science research assistance.",
    "categories": [
      "cs.AI",
      "cs.CL"
    ],
    "published": "2025-10-24T17:10:26Z",
    "authors": [
      "Jonathan Bragg",
      "Mike D'Arcy",
      "Nishant Balepur",
      "Dan Bareket",
      "Bhavana Dalvi",
      "Sergey Feldman",
      "Dany Haddad",
      "Jena D. Hwang",
      "Peter Jansen",
      "Varsha Kishore",
      "Bodhisattwa Prasad Majumder",
      "Aakanksha Naik",
      "Sigal Rahamimov",
      "Kyle Richardson",
      "Amanpreet Singh",
      "Harshit Surana",
      "Aryeh Tiktinsky",
      "Rosni Vasu",
      "Guy Wiener",
      "Chloe Anastasiades",
      "Stefan Candra",
      "Jason Dunkelberger",
      "Dan Emery",
      "Rob Evans",
      "Malachi Hamada",
      "Regan Huff",
      "Rodney Kinney",
      "Matt Latzke",
      "Jaron Lochner",
      "Ruben Lozano-Aguilera",
      "Cecile Nguyen",
      "Smita Rao",
      "Amber Tanaka",
      "Brooke Vlahos",
      "Peter Clark",
      "Doug Downey",
      "Yoav Goldberg",
      "Ashish Sabharwal",
      "Daniel S. Weld"
    ],
    "pdf_url": "http://arxiv.org/pdf/2510.21652v1"
  },
  {
    "id": "2510.21649v1",
    "title": "A Dynamic Knowledge Distillation Method Based on the Gompertz Curve",
    "abstract": "This paper introduces a novel dynamic knowledge distillation framework,\nGompertz-CNN, which integrates the Gompertz growth model into the training\nprocess to address the limitations of traditional knowledge distillation.\nConventional methods often fail to capture the evolving cognitive capacity of\nstudent models, leading to suboptimal knowledge transfer. To overcome this, we\npropose a stage-aware distillation strategy that dynamically adjusts the weight\nof distillation loss based on the Gompertz curve, reflecting the student's\nlearning progression: slow initial growth, rapid mid-phase improvement, and\nlate-stage saturation. Our framework incorporates Wasserstein distance to\nmeasure feature-level discrepancies and gradient matching to align backward\npropagation behaviors between teacher and student models. These components are\nunified under a multi-loss objective, where the Gompertz curve modulates the\ninfluence of distillation losses over time. Extensive experiments on CIFAR-10\nand CIFAR-100 using various teacher-student architectures (e.g., ResNet50 and\nMobileNet_v2) demonstrate that Gompertz-CNN consistently outperforms\ntraditional distillation methods, achieving up to 8% and 4% accuracy gains on\nCIFAR-10 and CIFAR-100, respectively.",
    "categories": [
      "cs.CV",
      "cs.AI"
    ],
    "published": "2025-10-24T17:07:27Z",
    "authors": [
      "Han Yang",
      "Guangjun Qin"
    ],
    "pdf_url": "http://arxiv.org/pdf/2510.21649v1"
  },
  {
    "id": "2510.21638v1",
    "title": "DEEDEE: Fast and Scalable Out-of-Distribution Dynamics Detection",
    "abstract": "Deploying reinforcement learning (RL) in safety-critical settings is\nconstrained by brittleness under distribution shift. We study\nout-of-distribution (OOD) detection for RL time series and introduce DEEDEE, a\ntwo-statistic detector that revisits representation-heavy pipelines with a\nminimal alternative. DEEDEE uses only an episodewise mean and an RBF kernel\nsimilarity to a training summary, capturing complementary global and local\ndeviations. Despite its simplicity, DEEDEE matches or surpasses contemporary\ndetectors across standard RL OOD suites, delivering a 600-fold reduction in\ncompute (FLOPs / wall-time) and an average 5% absolute accuracy gain over\nstrong baselines. Conceptually, our results indicate that diverse anomaly types\noften imprint on RL trajectories through a small set of low-order statistics,\nsuggesting a compact foundation for OOD detection in complex environments.",
    "categories": [
      "cs.LG",
      "cs.AI"
    ],
    "published": "2025-10-24T16:51:17Z",
    "authors": [
      "Tala Aljaafari",
      "Varun Kanade",
      "Philip Torr",
      "Christian Schroeder de Witt"
    ],
    "pdf_url": "http://arxiv.org/pdf/2510.21638v1"
  },
  {
    "id": "2510.21906v1",
    "title": "Structure-Aware Cooperative Ensemble Evolutionary Optimization on\n  Combinatorial Problems with Multimodal Large Language Models",
    "abstract": "Evolutionary algorithms (EAs) have proven effective in exploring the vast\nsolution spaces typical of graph-structured combinatorial problems. However,\ntraditional encoding schemes, such as binary or numerical representations,\noften fail to straightforwardly capture the intricate structural properties of\nnetworks. Through employing the image-based encoding to preserve topological\ncontext, this study utilizes multimodal large language models (MLLMs) as\nevolutionary operators to facilitate structure-aware optimization over graph\ndata. To address the visual clutter inherent in large-scale network\nvisualizations, we leverage graph sparsification techniques to simplify\nstructures while maintaining essential structural features. To further improve\nrobustness and mitigate bias from different sparsification views, we propose a\ncooperative evolutionary optimization framework that facilitates cross-domain\nknowledge transfer and unifies multiple sparsified variants of diverse\nstructures. Additionally, recognizing the sensitivity of MLLMs to network\nlayout, we introduce an ensemble strategy that aggregates outputs from various\nlayout configurations through consensus voting. Finally, experiments on\nreal-world networks through various tasks demonstrate that our approach\nimproves both the quality and reliability of solutions in MLLM-driven\nevolutionary optimization.",
    "categories": [
      "cs.NE",
      "cs.AI"
    ],
    "published": "2025-10-24T16:37:41Z",
    "authors": [
      "Jie Zhao",
      "Kang Hao Cheong"
    ],
    "pdf_url": "http://arxiv.org/pdf/2510.21906v1"
  },
  {
    "id": "2510.21631v1",
    "title": "Few-Shot Knowledge Distillation of LLMs With Counterfactual Explanations",
    "abstract": "Knowledge distillation is a promising approach to transfer capabilities from\ncomplex teacher models to smaller, resource-efficient student models that can\nbe deployed easily, particularly in task-aware scenarios. However, existing\nmethods of task-aware distillation typically require substantial quantities of\ndata which may be unavailable or expensive to obtain in many practical\nscenarios. In this paper, we address this challenge by introducing a novel\nstrategy called Counterfactual-explanation-infused Distillation CoD for\nfew-shot task-aware knowledge distillation by systematically infusing\ncounterfactual explanations. Counterfactual explanations (CFEs) refer to inputs\nthat can flip the output prediction of the teacher model with minimum\nperturbation. Our strategy CoD leverages these CFEs to precisely map the\nteacher's decision boundary with significantly fewer samples. We provide\ntheoretical guarantees for motivating the role of CFEs in distillation, from\nboth statistical and geometric perspectives. We mathematically show that CFEs\ncan improve parameter estimation by providing more informative examples near\nthe teacher's decision boundary. We also derive geometric insights on how CFEs\neffectively act as knowledge probes, helping the students mimic the teacher's\ndecision boundaries more effectively than standard data. We perform experiments\nacross various datasets and LLMs to show that CoD outperforms standard\ndistillation approaches in few-shot regimes (as low as 8-512 samples). Notably,\nCoD only uses half of the original samples used by the baselines, paired with\ntheir corresponding CFEs and still improves performance.",
    "categories": [
      "cs.LG",
      "cs.AI",
      "cs.CL",
      "cs.CY",
      "stat.ML"
    ],
    "published": "2025-10-24T16:36:34Z",
    "authors": [
      "Faisal Hamman",
      "Pasan Dissanayake",
      "Yanjun Fu",
      "Sanghamitra Dutta"
    ],
    "pdf_url": "http://arxiv.org/pdf/2510.21631v1"
  },
  {
    "id": "2510.21623v1",
    "title": "The Universal Landscape of Human Reasoning",
    "abstract": "Understanding how information is dynamically accumulated and transformed in\nhuman reasoning has long challenged cognitive psychology, philosophy, and\nartificial intelligence. Existing accounts, from classical logic to\nprobabilistic models, illuminate aspects of output or individual modelling, but\ndo not offer a unified, quantitative description of general human reasoning\ndynamics. To solve this, we introduce Information Flow Tracking (IF-Track),\nthat uses large language models (LLMs) as probabilistic encoder to quantify\ninformation entropy and gain at each reasoning step. Through fine-grained\nanalyses across diverse tasks, our method is the first successfully models the\nuniversal landscape of human reasoning behaviors within a single metric space.\nWe show that IF-Track captures essential reasoning features, identifies\nsystematic error patterns, and characterizes individual differences. Applied to\ndiscussion of advanced psychological theory, we first reconcile single- versus\ndual-process theories in IF-Track and discover the alignment of artificial and\nhuman cognition and how LLMs reshaping human reasoning process. This approach\nestablishes a quantitative bridge between theory and measurement, offering\nmechanistic insights into the architecture of reasoning.",
    "categories": [
      "cs.CL",
      "cs.AI"
    ],
    "published": "2025-10-24T16:26:36Z",
    "authors": [
      "Qiguang Chen",
      "Jinhao Liu",
      "Libo Qin",
      "Yimeng Zhang",
      "Yihao Liang",
      "Shangxu Ren",
      "Chengyu Luan",
      "Dengyun Peng",
      "Hanjing Li",
      "Jiannan Guan",
      "Zheng Yan",
      "Jiaqi Wang",
      "Mengkang Hu",
      "Yantao Du",
      "Zhi Chen",
      "Xie Chen",
      "Wanxiang Che"
    ],
    "pdf_url": "http://arxiv.org/pdf/2510.21623v1"
  },
  {
    "id": "2510.21618v1",
    "title": "DeepAgent: A General Reasoning Agent with Scalable Toolsets",
    "abstract": "Large reasoning models have demonstrated strong problem-solving abilities,\nyet real-world tasks often require external tools and long-horizon\ninteractions. Existing agent frameworks typically follow predefined workflows,\nwhich limit autonomous and global task completion. In this paper, we introduce\nDeepAgent, an end-to-end deep reasoning agent that performs autonomous\nthinking, tool discovery, and action execution within a single, coherent\nreasoning process. To address the challenges of long-horizon interactions,\nparticularly the context length explosion from multiple tool calls and the\naccumulation of interaction history, we introduce an autonomous memory folding\nmechanism that compresses past interactions into structured episodic, working,\nand tool memories, reducing error accumulation while preserving critical\ninformation. To teach general-purpose tool use efficiently and stably, we\ndevelop an end-to-end reinforcement learning strategy, namely ToolPO, that\nleverages LLM-simulated APIs and applies tool-call advantage attribution to\nassign fine-grained credit to the tool invocation tokens. Extensive experiments\non eight benchmarks, including general tool-use tasks (ToolBench, API-Bank,\nTMDB, Spotify, ToolHop) and downstream applications (ALFWorld, WebShop, GAIA,\nHLE), demonstrate that DeepAgent consistently outperforms baselines across both\nlabeled-tool and open-set tool retrieval scenarios. This work takes a step\ntoward more general and capable agents for real-world applications. The code\nand demo are available at https://github.com/RUC-NLPIR/DeepAgent.",
    "categories": [
      "cs.AI",
      "cs.CL",
      "cs.IR",
      "cs.LG"
    ],
    "published": "2025-10-24T16:24:01Z",
    "authors": [
      "Xiaoxi Li",
      "Wenxiang Jiao",
      "Jiarui Jin",
      "Guanting Dong",
      "Jiajie Jin",
      "Yinuo Wang",
      "Hao Wang",
      "Yutao Zhu",
      "Ji-Rong Wen",
      "Yuan Lu",
      "Zhicheng Dou"
    ],
    "pdf_url": "http://arxiv.org/pdf/2510.21618v1"
  },
  {
    "id": "2510.21614v3",
    "title": "Huxley-G\u00f6del Machine: Human-Level Coding Agent Development by an\n  Approximation of the Optimal Self-Improving Machine",
    "abstract": "Recent studies operationalize self-improvement through coding agents that\nedit their own codebases. They grow a tree of self-modifications through\nexpansion strategies that favor higher software engineering benchmark\nperformance, assuming that this implies more promising subsequent\nself-modifications. However, we identify a mismatch between the agent's\nself-improvement potential (metaproductivity) and its coding benchmark\nperformance, namely the Metaproductivity-Performance Mismatch. Inspired by\nHuxley's concept of clade, we propose a metric ($\\mathrm{CMP}$) that aggregates\nthe benchmark performances of the descendants of an agent as an indicator of\nits potential for self-improvement. We show that, in our self-improving coding\nagent development setting, access to the true $\\mathrm{CMP}$ is sufficient to\nsimulate how the G\\\"odel Machine would behave under certain assumptions. We\nintroduce the Huxley-G\\\"odel Machine (HGM), which, by estimating $\\mathrm{CMP}$\nand using it as guidance, searches the tree of self-modifications. On SWE-bench\nVerified and Polyglot, HGM outperforms prior self-improving coding agent\ndevelopment methods while using fewer allocated CPU hours. Last but not least,\nHGM demonstrates strong transfer to other coding datasets and large language\nmodels. The agent optimized by HGM on SWE-bench Verified with GPT-5-mini and\nevaluated on SWE-bench Lite with GPT-5 achieves human-level performance,\nmatching the best officially checked results of human-engineered coding agents.\nOur code is publicly available at https://github.com/metauto-ai/HGM.",
    "categories": [
      "cs.AI"
    ],
    "published": "2025-10-24T16:19:41Z",
    "authors": [
      "Wenyi Wang",
      "Piotr Pi\u0119kos",
      "Li Nanbo",
      "Firas Laakom",
      "Yimeng Chen",
      "Mateusz Ostaszewski",
      "Mingchen Zhuge",
      "J\u00fcrgen Schmidhuber"
    ],
    "pdf_url": "http://arxiv.org/pdf/2510.21614v3"
  },
  {
    "id": "2510.21610v1",
    "title": "Generative Correlation Manifolds: Generating Synthetic Data with\n  Preserved Higher-Order Correlations",
    "abstract": "The increasing need for data privacy and the demand for robust machine\nlearning models have fueled the development of synthetic data generation\ntechniques. However, current methods often succeed in replicating simple\nsummary statistics but fail to preserve both the pairwise and higher-order\ncorrelation structure of the data that define the complex, multi-variable\ninteractions inherent in real-world systems. This limitation can lead to\nsynthetic data that is superficially realistic but fails when used for\nsophisticated modeling tasks. In this white paper, we introduce Generative\nCorrelation Manifolds (GCM), a computationally efficient method for generating\nsynthetic data. The technique uses Cholesky decomposition of a target\ncorrelation matrix to produce datasets that, by mathematical proof, preserve\nthe entire correlation structure -- from simple pairwise relationships to\nhigher-order interactions -- of the source dataset. We argue that this method\nprovides a new approach to synthetic data generation with potential\napplications in privacy-preserving data sharing, robust model training, and\nsimulation.",
    "categories": [
      "cs.LG",
      "cs.AI"
    ],
    "published": "2025-10-24T16:15:53Z",
    "authors": [
      "Jens E. d'Hondt",
      "Wieger R. Punter",
      "Odysseas Papapetrou"
    ],
    "pdf_url": "http://arxiv.org/pdf/2510.21610v1"
  },
  {
    "id": "2510.21903v1",
    "title": "TOM-SWE: User Mental Modeling For Software Engineering Agents",
    "abstract": "Recent advances in coding agents have made them capable of planning, editing,\nrunning, and testing complex code bases. Despite their growing ability in\ncoding tasks, these systems still struggle to infer and track user intent,\nespecially when instructions are underspecified or context-dependent. To bridge\nthis gap, we introduce ToM-SWE, a dual-agent architecture that pairs a primary\nsoftware-engineering (SWE) agent with a lightweight theory-of-mind (ToM)\npartner agent dedicated to modeling the user's mental state. The ToM agent\ninfers user goals, constraints, and preferences from instructions and\ninteraction history, maintains a \\textbf{persistent memory} of the user, and\nprovides user-related suggestions to the SWE agent. In two software engineering\nbenchmarks (ambiguous SWE-bench and stateful SWE-bench), ToM-SWE improves task\nsuccess rates and user satisfaction. Notably, on the stateful SWE benchmark, a\nnewly introduced evaluation that provides agents with a user simulator along\nwith previous interaction histories, ToM-SWE achieves a substantially higher\ntask success rate of 59.7\\% compared to 18.1\\% for OpenHands, a\nstate-of-the-art SWE agent. Furthermore, in a three-week study with\nprofessional developers using ToM-SWE in their daily work, participants found\nit useful 86\\% of the time, underscoring the value of stateful user modeling\nfor practical coding agents.",
    "categories": [
      "cs.SE",
      "cs.AI"
    ],
    "published": "2025-10-24T16:09:51Z",
    "authors": [
      "Xuhui Zhou",
      "Valerie Chen",
      "Zora Zhiruo Wang",
      "Graham Neubig",
      "Maarten Sap",
      "Xingyao Wang"
    ],
    "pdf_url": "http://arxiv.org/pdf/2510.21903v1"
  },
  {
    "id": "2510.21902v1",
    "title": "Software Engineering Agents for Embodied Controller Generation : A Study\n  in Minigrid Environments",
    "abstract": "Software Engineering Agents (SWE-Agents) have proven effective for\ntraditional software engineering tasks with accessible codebases, but their\nperformance for embodied tasks requiring well-designed information discovery\nremains unexplored. We present the first extended evaluation of SWE-Agents on\ncontroller generation for embodied tasks, adapting Mini-SWE-Agent (MSWEA) to\nsolve 20 diverse embodied tasks from the Minigrid environment. Our experiments\ncompare agent performance across different information access conditions: with\nand without environment source code access, and with varying capabilities for\ninteractive exploration. We quantify how different information access levels\naffect SWE-Agent performance for embodied tasks and analyze the relative\nimportance of static code analysis versus dynamic exploration for task solving.\nThis work establishes controller generation for embodied tasks as a crucial\nevaluation domain for SWE-Agents and provides baseline results for future\nresearch in efficient reasoning systems.",
    "categories": [
      "cs.SE",
      "cs.AI"
    ],
    "published": "2025-10-24T16:04:11Z",
    "authors": [
      "Timoth\u00e9 Boulet",
      "Xavier Hinaut",
      "Cl\u00e9ment Moulin-Frier"
    ],
    "pdf_url": "http://arxiv.org/pdf/2510.21902v1"
  },
  {
    "id": "2510.23639v2",
    "title": "Integrating Genomics into Multimodal EHR Foundation Models",
    "abstract": "This paper introduces an innovative Electronic Health Record (EHR) foundation\nmodel that integrates Polygenic Risk Scores (PRS) as a foundational data\nmodality, moving beyond traditional EHR-only approaches to build more holistic\nhealth profiles. Leveraging the extensive and diverse data from the All of Us\n(AoU) Research Program, this multimodal framework aims to learn complex\nrelationships between clinical data and genetic predispositions. The\nmethodology extends advancements in generative AI to the EHR foundation model\nspace, enhancing predictive capabilities and interpretability. Evaluation on\nAoU data demonstrates the model's predictive value for the onset of various\nconditions, particularly Type 2 Diabetes (T2D), and illustrates the interplay\nbetween PRS and EHR data. The work also explores transfer learning for custom\nclassification tasks, showcasing the architecture's versatility and efficiency.\nThis approach is pivotal for unlocking new insights into disease prediction,\nproactive health management, risk stratification, and personalized treatment\nstrategies, laying the groundwork for more personalized, equitable, and\nactionable real-world evidence generation in healthcare.",
    "categories": [
      "cs.LG",
      "cs.AI",
      "q-bio.QM"
    ],
    "published": "2025-10-24T15:56:40Z",
    "authors": [
      "Jonathan Amar",
      "Edward Liu",
      "Alessandra Breschi",
      "Liangliang Zhang",
      "Pouya Kheradpour",
      "Sylvia Li",
      "Lisa Soleymani Lehmann",
      "Alessandro Giulianelli",
      "Matt Edwards",
      "Yugang Jia",
      "David Nola",
      "Raghav Mani",
      "Pankaj Vats",
      "Jesse Tetreault",
      "T. J. Chen",
      "Cory Y. McLean"
    ],
    "pdf_url": "http://arxiv.org/pdf/2510.23639v2"
  },
  {
    "id": "2510.21583v1",
    "title": "Sample By Step, Optimize By Chunk: Chunk-Level GRPO For Text-to-Image\n  Generation",
    "abstract": "Group Relative Policy Optimization (GRPO) has shown strong potential for\nflow-matching-based text-to-image (T2I) generation, but it faces two key\nlimitations: inaccurate advantage attribution, and the neglect of temporal\ndynamics of generation. In this work, we argue that shifting the optimization\nparadigm from the step level to the chunk level can effectively alleviate these\nissues. Building on this idea, we propose Chunk-GRPO, the first chunk-level\nGRPO-based approach for T2I generation. The insight is to group consecutive\nsteps into coherent 'chunk's that capture the intrinsic temporal dynamics of\nflow matching, and to optimize policies at the chunk level. In addition, we\nintroduce an optional weighted sampling strategy to further enhance\nperformance. Extensive experiments show that ChunkGRPO achieves superior\nresults in both preference alignment and image quality, highlighting the\npromise of chunk-level optimization for GRPO-based methods.",
    "categories": [
      "cs.CV",
      "cs.AI"
    ],
    "published": "2025-10-24T15:50:36Z",
    "authors": [
      "Yifu Luo",
      "Penghui Du",
      "Bo Li",
      "Sinan Du",
      "Tiantian Zhang",
      "Yongzhe Chang",
      "Kai Wu",
      "Kun Gai",
      "Xueqian Wang"
    ],
    "pdf_url": "http://arxiv.org/pdf/2510.21583v1"
  },
  {
    "id": "2510.21575v1",
    "title": "From Polyester Girlfriends to Blind Mice: Creating the First Pragmatics\n  Understanding Benchmarks for Slovene",
    "abstract": "Large language models are demonstrating increasing capabilities, excelling at\nbenchmarks once considered very difficult. As their capabilities grow, there is\na need for more challenging evaluations that go beyond surface-level linguistic\ncompetence. Namely, language competence involves not only syntax and semantics\nbut also pragmatics, i.e., understanding situational meaning as shaped by\ncontext as well as linguistic and cultural norms. To contribute to this line of\nresearch, we introduce SloPragEval and SloPragMega, the first pragmatics\nunderstanding benchmarks for Slovene that contain altogether 405\nmultiple-choice questions. We discuss the difficulties of translation, describe\nthe campaign to establish a human baseline, and report pilot evaluations with\nLLMs. Our results indicate that current models have greatly improved in\nunderstanding nuanced language but may still fail to infer implied speaker\nmeaning in non-literal utterances, especially those that are culture-specific.\nWe also observe a significant gap between proprietary and open-source models.\nFinally, we argue that benchmarks targeting nuanced language understanding and\nknowledge of the target culture must be designed with care, preferably\nconstructed from native data, and validated with human responses.",
    "categories": [
      "cs.CL",
      "cs.AI"
    ],
    "published": "2025-10-24T15:43:42Z",
    "authors": [
      "Mojca Brglez",
      "\u0160pela Vintar"
    ],
    "pdf_url": "http://arxiv.org/pdf/2510.21575v1"
  },
  {
    "id": "2510.21571v1",
    "title": "Scalable Vision-Language-Action Model Pretraining for Robotic\n  Manipulation with Real-Life Human Activity Videos",
    "abstract": "This paper presents a novel approach for pretraining robotic manipulation\nVision-Language-Action (VLA) models using a large corpus of unscripted\nreal-life video recordings of human hand activities. Treating human hand as\ndexterous robot end-effector, we show that \"in-the-wild\" egocentric human\nvideos without any annotations can be transformed into data formats fully\naligned with existing robotic V-L-A training data in terms of task granularity\nand labels. This is achieved by the development of a fully-automated holistic\nhuman activity analysis approach for arbitrary human hand videos. This approach\ncan generate atomic-level hand activity segments and their language\ndescriptions, each accompanied with framewise 3D hand motion and camera motion.\nWe process a large volume of egocentric videos and create a hand-VLA training\ndataset containing 1M episodes and 26M frames. This training data covers a wide\nrange of objects and concepts, dexterous manipulation tasks, and environment\nvariations in real life, vastly exceeding the coverage of existing robot data.\nWe design a dexterous hand VLA model architecture and pretrain the model on\nthis dataset. The model exhibits strong zero-shot capabilities on completely\nunseen real-world observations. Additionally, fine-tuning it on a small amount\nof real robot action data significantly improves task success rates and\ngeneralization to novel objects in real robotic experiments. We also\ndemonstrate the appealing scaling behavior of the model's task performance with\nrespect to pretraining data scale. We believe this work lays a solid foundation\nfor scalable VLA pretraining, advancing robots toward truly generalizable\nembodied intelligence.",
    "categories": [
      "cs.RO",
      "cs.AI",
      "cs.CV",
      "cs.LG"
    ],
    "published": "2025-10-24T15:39:31Z",
    "authors": [
      "Qixiu Li",
      "Yu Deng",
      "Yaobo Liang",
      "Lin Luo",
      "Lei Zhou",
      "Chengtang Yao",
      "Lingqi Zeng",
      "Zhiyuan Feng",
      "Huizhi Liang",
      "Sicheng Xu",
      "Yizhong Zhang",
      "Xi Chen",
      "Hao Chen",
      "Lily Sun",
      "Dong Chen",
      "Jiaolong Yang",
      "Baining Guo"
    ],
    "pdf_url": "http://arxiv.org/pdf/2510.21571v1"
  },
  {
    "id": "2510.23638v1",
    "title": "Bridging Function Approximation and Device Physics via Negative\n  Differential Resistance Networks",
    "abstract": "Achieving fully analog neural computation requires hardware that can natively\nimplement both linear and nonlinear operations with high efficiency. While\nanalogue matrix-vector multiplication has advanced via compute-in-memory\narchitectures, nonlinear activation functions remain a bottleneck, often\nrequiring digital or hybrid solutions. Inspired by the Kolmogorov-Arnold\nframework, we propose KANalogue, a fully analogue implementation of\nKolmogorov-Arnold Networks (KANs) using negative differential resistance\ndevices as physical realizations of learnable univariate basis functions. By\nleveraging the intrinsic negative differential resistance characteristics of\ntunnel diodes fabricated from NbSi2N4/HfSi2N4 heterostructures, we construct\ncoordinate-wise nonlinearities with distinct curvature and support profiles. We\nextract I-V data from fabricated armchair and zigzag devices, fit high-order\npolynomials to emulate diode behavior in software, and train KANs on vision\nbenchmarks using these learned basis functions. Our results demonstrate that\nKANalogue can approximate complex functions with minimal parameters while\nmaintaining classification accuracy competitive with digital baselines. This\nwork bridges device-level physics and function approximation theory, charting a\npath toward scalable, energy-efficient analogue machine learning systems.",
    "categories": [
      "cs.ET",
      "cs.AI",
      "cs.LG"
    ],
    "published": "2025-10-24T15:38:22Z",
    "authors": [
      "Songyuan Li",
      "Teng Wang",
      "Jinrong Tang",
      "Ruiqi Liu",
      "Yuyao Lu",
      "Feng Xu",
      "Bin Gao",
      "Xiangwei Zhu"
    ],
    "pdf_url": "http://arxiv.org/pdf/2510.23638v1"
  },
  {
    "id": "2510.21560v1",
    "title": "Learning Neural Control Barrier Functions from Expert Demonstrations\n  using Inverse Constraint Learning",
    "abstract": "Safety is a fundamental requirement for autonomous systems operating in\ncritical domains. Control barrier functions (CBFs) have been used to design\nsafety filters that minimally alter nominal controls for such systems to\nmaintain their safety. Learning neural CBFs has been proposed as a data-driven\nalternative for their computationally expensive optimization-based synthesis.\nHowever, it is often the case that the failure set of states that should be\navoided is non-obvious or hard to specify formally, e.g., tailgating in\nautonomous driving, while a set of expert demonstrations that achieve the task\nand avoid the failure set is easier to generate. We use ICL to train a\nconstraint function that classifies the states of the system under\nconsideration to safe, i.e., belong to a controlled forward invariant set that\nis disjoint from the unspecified failure set, and unsafe ones, i.e., belong to\nthe complement of that set. We then use that function to label a new set of\nsimulated trajectories to train our neural CBF. We empirically evaluate our\napproach in four different environments, demonstrating that it outperforms\nexisting baselines and achieves comparable performance to a neural CBF trained\nwith the same data but annotated with ground-truth safety labels.",
    "categories": [
      "cs.AI",
      "cs.RO"
    ],
    "published": "2025-10-24T15:20:34Z",
    "authors": [
      "Yuxuan Yang",
      "Hussein Sibai"
    ],
    "pdf_url": "http://arxiv.org/pdf/2510.21560v1"
  },
  {
    "id": "2510.21557v1",
    "title": "Co-Sight: Enhancing LLM-Based Agents via Conflict-Aware\n  Meta-Verification and Trustworthy Reasoning with Structured Facts",
    "abstract": "Long-horizon reasoning in LLM-based agents often fails not from generative\nweakness but from insufficient verification of intermediate reasoning. Co-Sight\naddresses this challenge by turning reasoning into a falsifiable and auditable\nprocess through two complementary mechanisms: Conflict-Aware Meta-Verification\n(CAMV) and Trustworthy Reasoning with Structured Facts (TRSF). CAMV\nreformulates verification as conflict identification and targeted\nfalsification, allocating computation only to disagreement hotspots among\nexpert agents rather than to full reasoning chains. This bounds verification\ncost to the number of inconsistencies and improves efficiency and reliability.\nTRSF continuously organizes, validates, and synchronizes evidence across agents\nthrough a structured facts module. By maintaining verified, traceable, and\nauditable knowledge, it ensures that all reasoning is grounded in consistent,\nsource-verified information and supports transparent verification throughout\nthe reasoning process. Together, TRSF and CAMV form a closed verification loop,\nwhere TRSF supplies structured facts and CAMV selectively falsifies or\nreinforces them, yielding transparent and trustworthy reasoning. Empirically,\nCo-Sight achieves state-of-the-art accuracy on GAIA (84.4%) and Humanity's Last\nExam (35.5%), and strong results on Chinese-SimpleQA (93.8%). Ablation studies\nconfirm that the synergy between structured factual grounding and\nconflict-aware verification drives these improvements. Co-Sight thus offers a\nscalable paradigm for reliable long-horizon reasoning in LLM-based agents. Code\nis available at\nhttps://github.com/ZTE-AICloud/Co-Sight/tree/cosight2.0_benchmarks.",
    "categories": [
      "cs.AI"
    ],
    "published": "2025-10-24T15:14:14Z",
    "authors": [
      "Hongwei Zhang",
      "Ji Lu",
      "Shiqing Jiang",
      "Chenxiang Zhu",
      "Li Xie",
      "Chen Zhong",
      "Haoran Chen",
      "Yurui Zhu",
      "Yongsheng Du",
      "Yanqin Gao",
      "Lingjun Huang",
      "Baoli Wang",
      "Fang Tan",
      "Peng Zou"
    ],
    "pdf_url": "http://arxiv.org/pdf/2510.21557v1"
  },
  {
    "id": "2510.21535v1",
    "title": "Human and AI Trust: Trust Attitude Measurement Instrument",
    "abstract": "With the current progress of Artificial Intelligence (AI) technology and its\nincreasingly broader applications, trust is seen as a required criterion for AI\nusage, acceptance, and deployment. A robust measurement instrument is essential\nto correctly evaluate trust from a human-centered perspective. This paper\ndescribes the development and validation process of a trust measure instrument,\nwhich follows psychometric principles, and consists of a 16-items trust scale.\nThe instrument was built explicitly for research in human-AI interaction to\nmeasure trust attitudes towards AI systems from layperson (non-expert)\nperspective. The use-case we used to develop the scale was in the context of AI\nmedical support systems (specifically cancer/health prediction). The scale\ndevelopment (Measurement Item Development) and validation (Measurement Item\nEvaluation) involved six research stages: item development, item evaluation,\nsurvey administration, test of dimensionality, test of reliability, and test of\nvalidity. The results of the six-stages evaluation show that the proposed trust\nmeasurement instrument is empirically reliable and valid for systematically\nmeasuring and comparing non-experts' trust in AI Medical Support Systems.",
    "categories": [
      "cs.HC",
      "cs.AI"
    ],
    "published": "2025-10-24T15:01:06Z",
    "authors": [
      "Retno Larasati"
    ],
    "pdf_url": "http://arxiv.org/pdf/2510.21535v1"
  },
  {
    "id": "2510.21524v1",
    "title": "EU-Agent-Bench: Measuring Illegal Behavior of LLM Agents Under EU Law",
    "abstract": "Large language models (LLMs) are increasingly deployed as agents in various\ncontexts by providing tools at their disposal. However, LLM agents can exhibit\nunpredictable behaviors, including taking undesirable and/or unsafe actions. In\norder to measure the latent propensity of LLM agents for taking illegal actions\nunder an EU legislative context, we introduce EU-Agent-Bench, a verifiable\nhuman-curated benchmark that evaluates an agent's alignment with EU legal norms\nin situations where benign user inputs could lead to unlawful actions. Our\nbenchmark spans scenarios across several categories, including data protection,\nbias/discrimination, and scientific integrity, with each user request allowing\nfor both compliant and non-compliant execution of the requested actions.\nComparing the model's function calls against a rubric exhaustively supported by\ncitations of the relevant legislature, we evaluate the legal compliance of\nfrontier LLMs, and furthermore investigate the compliance effect of providing\nthe relevant legislative excerpts in the agent's system prompt along with\nexplicit instructions to comply. We release a public preview set for the\nresearch community, while holding out a private test set to prevent data\ncontamination in evaluating upcoming models. We encourage future work extending\nagentic safety benchmarks to different legal jurisdictions and to multi-turn\nand multilingual interactions. We release our code on\n\\href{https://github.com/ilijalichkovski/eu-agent-bench}{this URL}.",
    "categories": [
      "cs.AI"
    ],
    "published": "2025-10-24T14:48:10Z",
    "authors": [
      "Ilija Lichkovski",
      "Alexander M\u00fcller",
      "Mariam Ibrahim",
      "Tiwai Mhundwa"
    ],
    "pdf_url": "http://arxiv.org/pdf/2510.21524v1"
  },
  {
    "id": "2510.21900v1",
    "title": "Deep Literature Survey Automation with an Iterative Workflow",
    "abstract": "Automatic literature survey generation has attracted increasing attention,\nyet most existing systems follow a one-shot paradigm, where a large set of\npapers is retrieved at once and a static outline is generated before drafting.\nThis design often leads to noisy retrieval, fragmented structures, and context\noverload, ultimately limiting survey quality. Inspired by the iterative reading\nprocess of human researchers, we propose \\ours, a framework based on recurrent\noutline generation, in which a planning agent incrementally retrieves, reads,\nand updates the outline to ensure both exploration and coherence. To provide\nfaithful paper-level grounding, we design paper cards that distill each paper\ninto its contributions, methods, and findings, and introduce a\nreview-and-refine loop with visualization enhancement to improve textual flow\nand integrate multimodal elements such as figures and tables. Experiments on\nboth established and emerging topics show that \\ours\\ substantially outperforms\nstate-of-the-art baselines in content coverage, structural coherence, and\ncitation quality, while producing more accessible and better-organized surveys.\nTo provide a more reliable assessment of such improvements, we further\nintroduce Survey-Arena, a pairwise benchmark that complements absolute scoring\nand more clearly positions machine-generated surveys relative to human-written\nones. The code is available at\nhttps://github.com/HancCui/IterSurvey\\_Autosurveyv2.",
    "categories": [
      "cs.CL",
      "cs.AI"
    ],
    "published": "2025-10-24T14:41:26Z",
    "authors": [
      "Hongbo Zhang",
      "Han Cui",
      "Yidong Wang",
      "Yijian Tian",
      "Qi Guo",
      "Cunxiang Wang",
      "Jian Wu",
      "Chiyu Song",
      "Yue Zhang"
    ],
    "pdf_url": "http://arxiv.org/pdf/2510.21900v1"
  },
  {
    "id": "2510.23637v1",
    "title": "Combining Textual and Structural Information for Premise Selection in\n  Lean",
    "abstract": "Premise selection is a key bottleneck for scaling theorem proving in large\nformal libraries. Yet existing language-based methods often treat premises in\nisolation, ignoring the web of dependencies that connects them. We present a\ngraph-augmented approach that combines dense text embeddings of Lean\nformalizations with graph neural networks over a heterogeneous dependency graph\ncapturing both state--premise and premise--premise relations. On the LeanDojo\nBenchmark, our method outperforms the ReProver language-based baseline by over\n25% across standard retrieval metrics. These results demonstrate the power of\nrelational information for more effective premise selection.",
    "categories": [
      "cs.LG",
      "cs.AI",
      "cs.CL",
      "cs.LO"
    ],
    "published": "2025-10-24T14:24:13Z",
    "authors": [
      "Job Petrov\u010di\u010d",
      "David Eliecer Narvaez Denis",
      "Ljup\u010do Todorovski"
    ],
    "pdf_url": "http://arxiv.org/pdf/2510.23637v1"
  },
  {
    "id": "2510.24770v1",
    "title": "DMVFC: Deep Learning Based Functionally Consistent Tractography Fiber\n  Clustering Using Multimodal Diffusion MRI and Functional MRI",
    "abstract": "Tractography fiber clustering using diffusion MRI (dMRI) is a crucial method\nfor white matter (WM) parcellation to enable analysis of brains structural\nconnectivity in health and disease. Current fiber clustering strategies\nprimarily use the fiber geometric characteristics (i.e., the spatial\ntrajectories) to group similar fibers into clusters, while neglecting the\nfunctional and microstructural information of the fiber tracts. There is\nincreasing evidence that neural activity in the WM can be measured using\nfunctional MRI (fMRI), providing potentially valuable multimodal information\nfor fiber clustering to enhance its functional coherence. Furthermore,\nmicrostructural features such as fractional anisotropy (FA) can be computed\nfrom dMRI as additional information to ensure the anatomical coherence of the\nclusters. In this paper, we develop a novel deep learning fiber clustering\nframework, namely Deep Multi-view Fiber Clustering (DMVFC), which uses joint\nmulti-modal dMRI and fMRI data to enable functionally consistent WM\nparcellation. DMVFC can effectively integrate the geometric and microstructural\ncharacteristics of the WM fibers with the fMRI BOLD signals along the fiber\ntracts. DMVFC includes two major components: (1) a multi-view pretraining\nmodule to compute embedding features from each source of information\nseparately, including fiber geometry, microstructure measures, and functional\nsignals, and (2) a collaborative fine-tuning module to simultaneously refine\nthe differences of embeddings. In the experiments, we compare DMVFC with two\nstate-of-the-art fiber clustering methods and demonstrate superior performance\nin achieving functionally meaningful and consistent WM parcellation results.",
    "categories": [
      "eess.IV",
      "cs.AI",
      "cs.CV"
    ],
    "published": "2025-10-24T14:19:23Z",
    "authors": [
      "Bocheng Guo",
      "Jin Wang",
      "Yijie Li",
      "Junyi Wang",
      "Mingyu Gao",
      "Puming Feng",
      "Yuqian Chen",
      "Jarrett Rushmore",
      "Nikos Makris",
      "Yogesh Rathi",
      "Lauren J O'Donnell",
      "Fan Zhang"
    ],
    "pdf_url": "http://arxiv.org/pdf/2510.24770v1"
  },
  {
    "id": "2510.21469v1",
    "title": "Enhancing Social Robots through Resilient AI",
    "abstract": "As artificial intelligence continues to advance and becomes more integrated\ninto sensitive areas like healthcare, education, and everyday life, it's\ncrucial for these systems to be both resilient and robust. This paper shows how\nresilience is a fundamental characteristic of social robots, which, through it,\nensure trust in the robot itself-an essential element especially when operating\nin contexts with elderly people, who often have low trust in these systems.\nResilience is therefore the ability to operate under adverse or stressful\nconditions, even when degraded or weakened, while maintaining essential\noperational capabilities.",
    "categories": [
      "cs.RO",
      "cs.AI"
    ],
    "published": "2025-10-24T13:55:45Z",
    "authors": [
      "Domenico Palmisano",
      "Giuseppe Palestra",
      "Berardina Nadja De Carolis"
    ],
    "pdf_url": "http://arxiv.org/pdf/2510.21469v1"
  },
  {
    "id": "2510.21453v1",
    "title": "Multi-Task Vehicle Routing Solver via Mixture of Specialized Experts\n  under State-Decomposable MDP",
    "abstract": "Existing neural methods for multi-task vehicle routing problems (VRPs)\ntypically learn unified solvers to handle multiple constraints simultaneously.\nHowever, they often underutilize the compositional structure of VRP variants,\neach derivable from a common set of basis VRP variants. This critical oversight\ncauses unified solvers to miss out the potential benefits of basis solvers,\neach specialized for a basis VRP variant. To overcome this limitation, we\npropose a framework that enables unified solvers to perceive the\nshared-component nature across VRP variants by proactively reusing basis\nsolvers, while mitigating the exponential growth of trained neural solvers.\nSpecifically, we introduce a State-Decomposable MDP (SDMDP) that reformulates\nVRPs by expressing the state space as the Cartesian product of basis state\nspaces associated with basis VRP variants. More crucially, this formulation\ninherently yields the optimal basis policy for each basis VRP variant.\nFurthermore, a Latent Space-based SDMDP extension is developed by incorporating\nboth the optimal basis policies and a learnable mixture function to enable the\npolicy reuse in the latent space. Under mild assumptions, this extension\nprovably recovers the optimal unified policy of SDMDP through the mixture\nfunction that computes the state embedding as a mapping from the basis state\nembeddings generated by optimal basis policies. For practical implementation,\nwe introduce the Mixture-of-Specialized-Experts Solver (MoSES), which realizes\nbasis policies through specialized Low-Rank Adaptation (LoRA) experts, and\nimplements the mixture function via an adaptive gating mechanism. Extensive\nexperiments conducted across VRP variants showcase the superiority of MoSES\nover prior methods.",
    "categories": [
      "cs.AI",
      "cs.LG"
    ],
    "published": "2025-10-24T13:31:31Z",
    "authors": [
      "Yuxin Pan",
      "Zhiguang Cao",
      "Chengyang Gu",
      "Liu Liu",
      "Peilin Zhao",
      "Yize Chen",
      "Fangzhen Lin"
    ],
    "pdf_url": "http://arxiv.org/pdf/2510.21453v1"
  },
  {
    "id": "2510.21447v1",
    "title": "PhysWorld: From Real Videos to World Models of Deformable Objects via\n  Physics-Aware Demonstration Synthesis",
    "abstract": "Interactive world models that simulate object dynamics are crucial for\nrobotics, VR, and AR. However, it remains a significant challenge to learn\nphysics-consistent dynamics models from limited real-world video data,\nespecially for deformable objects with spatially-varying physical properties.\nTo overcome the challenge of data scarcity, we propose PhysWorld, a novel\nframework that utilizes a simulator to synthesize physically plausible and\ndiverse demonstrations to learn efficient world models. Specifically, we first\nconstruct a physics-consistent digital twin within MPM simulator via\nconstitutive model selection and global-to-local optimization of physical\nproperties. Subsequently, we apply part-aware perturbations to the physical\nproperties and generate various motion patterns for the digital twin,\nsynthesizing extensive and diverse demonstrations. Finally, using these\ndemonstrations, we train a lightweight GNN-based world model that is embedded\nwith physical properties. The real video can be used to further refine the\nphysical properties. PhysWorld achieves accurate and fast future predictions\nfor various deformable objects, and also generalizes well to novel\ninteractions. Experiments show that PhysWorld has competitive performance while\nenabling inference speeds 47 times faster than the recent state-of-the-art\nmethod, i.e., PhysTwin.",
    "categories": [
      "cs.CV",
      "cs.AI",
      "cs.RO"
    ],
    "published": "2025-10-24T13:25:39Z",
    "authors": [
      "Yu Yang",
      "Zhilu Zhang",
      "Xiang Zhang",
      "Yihan Zeng",
      "Hui Li",
      "Wangmeng Zuo"
    ],
    "pdf_url": "http://arxiv.org/pdf/2510.21447v1"
  },
  {
    "id": "2510.21445v1",
    "title": "REMONI: An Autonomous System Integrating Wearables and Multimodal Large\n  Language Models for Enhanced Remote Health Monitoring",
    "abstract": "With the widespread adoption of wearable devices in our daily lives, the\ndemand and appeal for remote patient monitoring have significantly increased.\nMost research in this field has concentrated on collecting sensor data,\nvisualizing it, and analyzing it to detect anomalies in specific diseases such\nas diabetes, heart disease and depression. However, this domain has a notable\ngap in the aspect of human-machine interaction. This paper proposes REMONI, an\nautonomous REmote health MONItoring system that integrates multimodal large\nlanguage models (MLLMs), the Internet of Things (IoT), and wearable devices.\nThe system automatically and continuously collects vital signs, accelerometer\ndata from a special wearable (such as a smartwatch), and visual data in patient\nvideo clips collected from cameras. This data is processed by an anomaly\ndetection module, which includes a fall detection model and algorithms to\nidentify and alert caregivers of the patient's emergency conditions. A\ndistinctive feature of our proposed system is the natural language processing\ncomponent, developed with MLLMs capable of detecting and recognizing a\npatient's activity and emotion while responding to healthcare worker's\ninquiries. Additionally, prompt engineering is employed to integrate all\npatient information seamlessly. As a result, doctors and nurses can access\nreal-time vital signs and the patient's current state and mood by interacting\nwith an intelligent agent through a user-friendly web application. Our\nexperiments demonstrate that our system is implementable and scalable for\nreal-life scenarios, potentially reducing the workload of medical professionals\nand healthcare costs. A full-fledged prototype illustrating the functionalities\nof the system has been developed and being tested to demonstrate the robustness\nof its various capabilities.",
    "categories": [
      "cs.CL",
      "cs.AI",
      "cs.CV",
      "cs.LG"
    ],
    "published": "2025-10-24T13:23:38Z",
    "authors": [
      "Thanh Cong Ho",
      "Farah Kharrat",
      "Abderrazek Abid",
      "Fakhri Karray"
    ],
    "pdf_url": "http://arxiv.org/pdf/2510.21445v1"
  },
  {
    "id": "2510.21443v1",
    "title": "Does Model Size Matter? A Comparison of Small and Large Language Models\n  for Requirements Classification",
    "abstract": "[Context and motivation] Large language models (LLMs) show notable results in\nnatural language processing (NLP) tasks for requirements engineering (RE).\nHowever, their use is compromised by high computational cost, data sharing\nrisks, and dependence on external services. In contrast, small language models\n(SLMs) offer a lightweight, locally deployable alternative. [Question/problem]\nIt remains unclear how well SLMs perform compared to LLMs in RE tasks in terms\nof accuracy. [Results] Our preliminary study compares eight models, including\nthree LLMs and five SLMs, on requirements classification tasks using the\nPROMISE, PROMISE Reclass, and SecReq datasets. Our results show that although\nLLMs achieve an average F1 score of 2% higher than SLMs, this difference is not\nstatistically significant. SLMs almost reach LLMs performance across all\ndatasets and even outperform them in recall on the PROMISE Reclass dataset,\ndespite being up to 300 times smaller. We also found that dataset\ncharacteristics play a more significant role in performance than model size.\n[Contribution] Our study contributes with evidence that SLMs are a valid\nalternative to LLMs for requirements classification, offering advantages in\nprivacy, cost, and local deployability.",
    "categories": [
      "cs.SE",
      "cs.AI",
      "cs.CL"
    ],
    "published": "2025-10-24T13:20:30Z",
    "authors": [
      "Mohammad Amin Zadenoori",
      "Vincenzo De Martino",
      "Jacek Dabrowski",
      "Xavier Franch",
      "Alessio Ferrari"
    ],
    "pdf_url": "http://arxiv.org/pdf/2510.21443v1"
  },
  {
    "id": "2510.21436v1",
    "title": "AutoOpt: A Dataset and a Unified Framework for Automating Optimization\n  Problem Solving",
    "abstract": "This study presents AutoOpt-11k, a unique image dataset of over 11,000\nhandwritten and printed mathematical optimization models corresponding to\nsingle-objective, multi-objective, multi-level, and stochastic optimization\nproblems exhibiting various types of complexities such as non-linearity,\nnon-convexity, non-differentiability, discontinuity, and high-dimensionality.\nThe labels consist of the LaTeX representation for all the images and modeling\nlanguage representation for a subset of images. The dataset is created by 25\nexperts following ethical data creation guidelines and verified in two-phases\nto avoid errors. Further, we develop AutoOpt framework, a machine learning\nbased automated approach for solving optimization problems, where the user just\nneeds to provide an image of the formulation and AutoOpt solves it efficiently\nwithout any further human intervention. AutoOpt framework consists of three\nModules: (i) M1 (Image_to_Text)- a deep learning model performs the\nMathematical Expression Recognition (MER) task to generate the LaTeX code\ncorresponding to the optimization formulation in image; (ii) M2 (Text_to_Text)-\na small-scale fine-tuned LLM generates the PYOMO script (optimization modeling\nlanguage) from LaTeX code; (iii) M3 (Optimization)- a Bilevel Optimization\nbased Decomposition (BOBD) method solves the optimization formulation described\nin the PYOMO script. We use AutoOpt-11k dataset for training and testing of\ndeep learning models employed in AutoOpt. The deep learning model for MER task\n(M1) outperforms ChatGPT, Gemini and Nougat on BLEU score metric. BOBD method\n(M3), which is a hybrid approach, yields better results on complex test\nproblems compared to common approaches, like interior-point algorithm and\ngenetic algorithm.",
    "categories": [
      "cs.AI",
      "I.4"
    ],
    "published": "2025-10-24T13:14:53Z",
    "authors": [
      "Ankur Sinha",
      "Shobhit Arora",
      "Dhaval Pujara"
    ],
    "pdf_url": "http://arxiv.org/pdf/2510.21436v1"
  },
  {
    "id": "2510.21425v1",
    "title": "Advancing Symbolic Integration in Large Language Models: Beyond\n  Conventional Neurosymbolic AI",
    "abstract": "LLMs have demonstrated highly effective learning, human-like response\ngeneration,and decision-making capabilities in high-risk sectors. However,\nthese models remain black boxes because they struggle to ensure transparency in\nresponses. The literature has explored numerous approaches to address\ntransparency challenges in LLMs, including Neurosymbolic AI (NeSy AI). NeSy AI\napproaches were primarily developed for conventional neural networks and are\nnot well-suited to the unique features of LLMs. Consequently, there is a\nlimited systematic understanding of how symbolic AI can be effectively\nintegrated into LLMs. This paper aims to address this gap by first reviewing\nestablished NeSy AI methods and then proposing a novel taxonomy of symbolic\nintegration in LLMs, along with a roadmap to merge symbolic techniques with\nLLMs. The roadmap introduces a new categorisation framework across four\ndimensions by organising existing literature within these categories. These\ninclude symbolic integration across various stages of LLM, coupling mechanisms,\narchitectural paradigms, as well as algorithmic and application-level\nperspectives. The paper thoroughly identifies current benchmarks, cutting-edge\nadvancements, and critical gaps within the field to propose a roadmap for\nfuture research. By highlighting the latest developments and notable gaps in\nthe literature, it offers practical insights for implementing frameworks for\nsymbolic integration into LLMs to enhance transparency.",
    "categories": [
      "cs.AI"
    ],
    "published": "2025-10-24T13:05:50Z",
    "authors": [
      "Maneeha Rani",
      "Bhupesh Kumar Mishra",
      "Dhavalkumar Thakker"
    ],
    "pdf_url": "http://arxiv.org/pdf/2510.21425v1"
  },
  {
    "id": "2510.21424v1",
    "title": "Vision Language Models for Dynamic Human Activity Recognition in\n  Healthcare Settings",
    "abstract": "As generative AI continues to evolve, Vision Language Models (VLMs) have\nemerged as promising tools in various healthcare applications. One area that\nremains relatively underexplored is their use in human activity recognition\n(HAR) for remote health monitoring. VLMs offer notable strengths, including\ngreater flexibility and the ability to overcome some of the constraints of\ntraditional deep learning models. However, a key challenge in applying VLMs to\nHAR lies in the difficulty of evaluating their dynamic and often\nnon-deterministic outputs. To address this gap, we introduce a descriptive\ncaption data set and propose comprehensive evaluation methods to evaluate VLMs\nin HAR. Through comparative experiments with state-of-the-art deep learning\nmodels, our findings demonstrate that VLMs achieve comparable performance and,\nin some cases, even surpass conventional approaches in terms of accuracy. This\nwork contributes a strong benchmark and opens new possibilities for the\nintegration of VLMs into intelligent healthcare systems.",
    "categories": [
      "cs.CL",
      "cs.AI",
      "cs.CV",
      "cs.LG"
    ],
    "published": "2025-10-24T13:04:13Z",
    "authors": [
      "Abderrazek Abid",
      "Thanh-Cong Ho",
      "Fakhri Karray"
    ],
    "pdf_url": "http://arxiv.org/pdf/2510.21424v1"
  },
  {
    "id": "2510.21418v1",
    "title": "DreamerV3-XP: Optimizing exploration through uncertainty estimation",
    "abstract": "We introduce DreamerV3-XP, an extension of DreamerV3 that improves\nexploration and learning efficiency. This includes (i) a prioritized replay\nbuffer, scoring trajectories by return, reconstruction loss, and value error\nand (ii) an intrinsic reward based on disagreement over predicted environment\nrewards from an ensemble of world models. DreamerV3-XP is evaluated on a subset\nof Atari100k and DeepMind Control Visual Benchmark tasks, confirming the\noriginal DreamerV3 results and showing that our extensions lead to faster\nlearning and lower dynamics model loss, particularly in sparse-reward settings.",
    "categories": [
      "cs.LG",
      "cs.AI"
    ],
    "published": "2025-10-24T12:58:27Z",
    "authors": [
      "Lukas Bierling",
      "Davide Pasero",
      "Jan-Henrik Bertrand",
      "Kiki Van Gerwen"
    ],
    "pdf_url": "http://arxiv.org/pdf/2510.21418v1"
  },
  {
    "id": "2510.21408v1",
    "title": "Large Language Models as Model Organisms for Human Associative Learning",
    "abstract": "Associative learning--forming links between co-occurring items--is\nfundamental to human cognition, reshaping internal representations in complex\nways. Testing hypotheses on how representational changes occur in biological\nsystems is challenging, but large language models (LLMs) offer a scalable\nalternative. Building on LLMs' in-context learning, we adapt a cognitive\nneuroscience associative learning paradigm and investigate how representations\nevolve across six models. Our initial findings reveal a non-monotonic pattern\nconsistent with the Non-Monotonic Plasticity Hypothesis, with moderately\nsimilar items differentiating after learning. Leveraging the controllability of\nLLMs, we further show that this differentiation is modulated by the overlap of\nassociated items with the broader vocabulary--a factor we term vocabulary\ninterference, capturing how new associations compete with prior knowledge. We\nfind that higher vocabulary interference amplifies differentiation, suggesting\nthat representational change is influenced by both item similarity and global\ncompetition. Our findings position LLMs not only as powerful tools for studying\nrepresentational dynamics in human-like learning systems, but also as\naccessible and general computational models for generating new hypotheses about\nthe principles underlying memory reorganization in the brain.",
    "categories": [
      "cs.LG",
      "cs.AI"
    ],
    "published": "2025-10-24T12:52:11Z",
    "authors": [
      "Camila Kolling",
      "Vy Ai Vo",
      "Mariya Toneva"
    ],
    "pdf_url": "http://arxiv.org/pdf/2510.21408v1"
  },
  {
    "id": "2510.21407v1",
    "title": "REvolution: An Evolutionary Framework for RTL Generation driven by Large\n  Language Models",
    "abstract": "Large Language Models (LLMs) are used for Register-Transfer Level (RTL) code\ngeneration, but they face two main challenges: functional correctness and\nPower, Performance, and Area (PPA) optimization. Iterative, feedback-based\nmethods partially address these, but they are limited to local search,\nhindering the discovery of a global optimum. This paper introduces REvolution,\na framework that combines Evolutionary Computation (EC) with LLMs for automatic\nRTL generation and optimization. REvolution evolves a population of candidates\nin parallel, each defined by a design strategy, RTL implementation, and\nevaluation feedback. The framework includes a dual-population algorithm that\ndivides candidates into Fail and Success groups for bug fixing and PPA\noptimization, respectively. An adaptive mechanism further improves search\nefficiency by dynamically adjusting the selection probability of each prompt\nstrategy according to its success rate. Experiments on the VerilogEval and\nRTLLM benchmarks show that REvolution increased the initial pass rate of\nvarious LLMs by up to 24.0 percentage points. The DeepSeek-V3 model achieved a\nfinal pass rate of 95.5\\%, comparable to state-of-the-art results, without the\nneed for separate training or domain-specific tools. Additionally, the\ngenerated RTL designs showed significant PPA improvements over reference\ndesigns. This work introduces a new RTL design approach by combining LLMs'\ngenerative capabilities with EC's broad search power, overcoming the\nlocal-search limitations of previous methods.",
    "categories": [
      "cs.NE",
      "cs.AI",
      "cs.SE"
    ],
    "published": "2025-10-24T12:50:35Z",
    "authors": [
      "Kyungjun Min",
      "Kyumin Cho",
      "Junhwan Jang",
      "Seokhyeong Kang"
    ],
    "pdf_url": "http://arxiv.org/pdf/2510.21407v1"
  },
  {
    "id": "2510.21398v1",
    "title": "Boosting Accuracy and Efficiency of Budget Forcing in LLMs via\n  Reinforcement Learning for Mathematical Reasoning",
    "abstract": "Test-time scaling methods have seen a rapid increase in popularity for its\ncomputational efficiency and parameter-independent training to improve\nreasoning performance on Large Language Models. One such method is called\nbudget forcing, a decoding intervention strategy which allocates extra compute\nbudget for thinking and elicits the inherent self-correcting behavior of the\nmodel. However, this relies on supervised fine-tuning (SFT) on long-context\nreasoning traces which causes performance degradation on smaller models due to\nverbose responses. For this reason, we offer a framework integrating\nreinforcement learning (RL) to improve token efficiency and boost the\nperformance of a 1.5B model for mathematical reasoning. We demonstrate this\nusing only 1.5K training samples and found that our SFT+RL model performed\nbetter on the GSM8K dataset with varying compute budgets. Our main findings\nshowed an overall higher accuracy while significantly reducing its token usage\nby over 40% compared to the SFT model, revealing how RL can recover the losses\ndue to long-context training and altogether improving performance in\nmathematical reasoning.",
    "categories": [
      "cs.AI"
    ],
    "published": "2025-10-24T12:39:15Z",
    "authors": [
      "Ravindra Aribowo Tarunokusumo",
      "Rafael Fernandes Cunha"
    ],
    "pdf_url": "http://arxiv.org/pdf/2510.21398v1"
  },
  {
    "id": "2510.21389v1",
    "title": "Assessing the Real-World Utility of Explainable AI for Arousal\n  Diagnostics: An Application-Grounded User Study",
    "abstract": "Artificial intelligence (AI) systems increasingly match or surpass human\nexperts in biomedical signal interpretation. However, their effective\nintegration into clinical practice requires more than high predictive accuracy.\nClinicians must discern \\textit{when} and \\textit{why} to trust algorithmic\nrecommendations. This work presents an application-grounded user study with\neight professional sleep medicine practitioners, who score nocturnal arousal\nevents in polysomnographic data under three conditions: (i) manual scoring,\n(ii) black-box (BB) AI assistance, and (iii) transparent white-box (WB) AI\nassistance. Assistance is provided either from the \\textit{start} of scoring or\nas a post-hoc quality-control (\\textit{QC}) review. We systematically evaluate\nhow the type and timing of assistance influence event-level and clinically most\nrelevant count-based performance, time requirements, and user experience. When\nevaluated against the clinical standard used to train the AI, both AI and\nhuman-AI teams significantly outperform unaided experts, with collaboration\nalso reducing inter-rater variability. Notably, transparent AI assistance\napplied as a targeted QC step yields median event-level performance\nimprovements of approximately 30\\% over black-box assistance, and QC timing\nfurther enhances count-based outcomes. While WB and QC approaches increase the\ntime required for scoring, start-time assistance is faster and preferred by\nmost participants. Participants overwhelmingly favor transparency, with seven\nout of eight expressing willingness to adopt the system with minor or no\nmodifications. In summary, strategically timed transparent AI assistance\neffectively balances accuracy and clinical efficiency, providing a promising\npathway toward trustworthy AI integration and user acceptance in clinical\nworkflows.",
    "categories": [
      "cs.LG",
      "cs.AI",
      "cs.HC"
    ],
    "published": "2025-10-24T12:23:02Z",
    "authors": [
      "Stefan Kraft",
      "Andreas Theissler",
      "Vera Wienhausen-Wilke",
      "Gjergji Kasneci",
      "Hendrik Lensch"
    ],
    "pdf_url": "http://arxiv.org/pdf/2510.21389v1"
  },
  {
    "id": "2510.23636v1",
    "title": "Flight Delay Prediction via Cross-Modality Adaptation of Large Language\n  Models and Aircraft Trajectory Representation",
    "abstract": "Flight delay prediction has become a key focus in air traffic management, as\ndelays highlight inefficiencies that impact overall network performance. This\npaper presents a lightweight large language model-based multimodal flight delay\nprediction, formulated from the perspective of air traffic controllers\nmonitoring aircraft delay after entering the terminal area. The approach\nintegrates trajectory representations with textual aeronautical information,\nincluding flight information, weather reports, and aerodrome notices, by\nadapting trajectory data into the language modality to capture airspace\nconditions. Experimental results show that the model consistently achieves\nsub-minute prediction error by effectively leveraging contextual information\nrelated to the sources of delay. The framework demonstrates that linguistic\nunderstanding, when combined with cross-modality adaptation of trajectory\ninformation, enhances delay prediction. Moreover, the approach shows\npracticality and scalability for real-world operations, supporting real-time\nupdates that refine predictions upon receiving new operational information.",
    "categories": [
      "cs.LG",
      "cs.AI",
      "cs.CL"
    ],
    "published": "2025-10-24T12:21:27Z",
    "authors": [
      "Thaweerath Phisannupawong",
      "Joshua Julian Damanik",
      "Han-Lim Choi"
    ],
    "pdf_url": "http://arxiv.org/pdf/2510.23636v1"
  },
  {
    "id": "2510.21388v1",
    "title": "Compressing Quaternion Convolutional Neural Networks for Audio\n  Classification",
    "abstract": "Conventional Convolutional Neural Networks (CNNs) in the real domain have\nbeen widely used for audio classification. However, their convolution\noperations process multi-channel inputs independently, limiting the ability to\ncapture correlations among channels. This can lead to suboptimal feature\nlearning, particularly for complex audio patterns such as multi-channel\nspectrogram representations. Quaternion Convolutional Neural Networks (QCNNs)\naddress this limitation by employing quaternion algebra to jointly capture\ninter-channel dependencies, enabling more compact models with fewer learnable\nparameters while better exploiting the multi-dimensional nature of audio\nsignals. However, QCNNs exhibit higher computational complexity due to the\noverhead of quaternion operations, resulting in increased inference latency and\nreduced efficiency compared to conventional CNNs, posing challenges for\ndeployment on resource-constrained platforms. To address this challenge, this\nstudy explores knowledge distillation (KD) and pruning, to reduce the\ncomputational complexity of QCNNs while maintaining performance. Our\nexperiments on audio classification reveal that pruning QCNNs achieves similar\nor superior performance compared to KD while requiring less computational\neffort. Compared to conventional CNNs and Transformer-based architectures,\npruned QCNNs achieve competitive performance with a reduced learnable parameter\ncount and computational complexity. On the AudioSet dataset, pruned QCNNs\nreduce computational cost by 50\\% and parameter count by 80\\%, while\nmaintaining performance comparable to the conventional CNNs. Furthermore,\npruned QCNNs generalize well across multiple audio classification benchmarks,\nincluding GTZAN for music genre recognition, ESC-50 for environmental sound\nclassification and RAVDESS for speech emotion recognition.",
    "categories": [
      "eess.AS",
      "cs.AI",
      "cs.SD",
      "eess.SP"
    ],
    "published": "2025-10-24T12:19:19Z",
    "authors": [
      "Arshdeep Singh",
      "Vinayak Abrol",
      "Mark D. Plumbley"
    ],
    "pdf_url": "http://arxiv.org/pdf/2510.21388v1"
  },
  {
    "id": "2510.21370v1",
    "title": "HIKMA: Human-Inspired Knowledge by Machine Agents through a Multi-Agent\n  Framework for Semi-Autonomous Scientific Conferences",
    "abstract": "HIKMA Semi-Autonomous Conference is the first experiment in reimagining\nscholarly communication through an end-to-end integration of artificial\nintelligence into the academic publishing and presentation pipeline. This paper\npresents the design, implementation, and evaluation of the HIKMA framework,\nwhich includes AI dataset curation, AI-based manuscript generation, AI-assisted\npeer review, AI-driven revision, AI conference presentation, and AI archival\ndissemination. By combining language models, structured research workflows, and\ndomain safeguards, HIKMA shows how AI can support - not replace traditional\nscholarly practices while maintaining intellectual property protection,\ntransparency, and integrity. The conference functions as a testbed and proof of\nconcept, providing insights into the opportunities and challenges of AI-enabled\nscholarship. It also examines questions about AI authorship, accountability,\nand the role of human-AI collaboration in research.",
    "categories": [
      "cs.MA",
      "cs.AI",
      "cs.CL",
      "cs.DL"
    ],
    "published": "2025-10-24T11:52:24Z",
    "authors": [
      "Zain Ul Abideen Tariq",
      "Mahmood Al-Zubaidi",
      "Uzair Shah",
      "Marco Agus",
      "Mowafa Househ"
    ],
    "pdf_url": "http://arxiv.org/pdf/2510.21370v1"
  },
  {
    "id": "2510.21362v1",
    "title": "Patient-specific AI for generation of 3D dosimetry imaging from two\n  2D-planar measurements",
    "abstract": "In this work we explored the use of patient specific reinforced learning to\ngenerate 3D activity maps from two 2D planar images (anterior and posterior).\nThe solution of this problem remains unachievable using conventional\nmethodologies and is of particular interest for dosimetry in nuclear medicine\nwhere approaches for post-therapy distribution of radiopharmaceuticals such as\n177Lu-PSMA are typically done via either expensive and long 3D SPECT\nacquisitions or fast, yet only 2D, planar scintigraphy. Being able to generate\n3D activity maps from planar scintigraphy opens the gate for new dosimetry\napplications removing the need for SPECT and facilitating multi-time point\ndosimetry studies. Our solution comprises the generation of a patient specific\ndataset with possible 3D uptake maps of the radiopharmaceuticals withing the\nanatomy of the individual followed by an AI approach (we explored both the use\nof 3DUnet and diffusion models) able to generate 3D activity maps from 2D\nplanar images. We have validated our method both in simulation and real planar\nacquisitions. We observed enhanced results using patient specific reinforcement\nlearning (~20% reduction on MAE and ~5% increase in SSIM) and better organ\ndelineation and patient anatomy especially when combining diffusion models with\npatient specific training yielding a SSIM=0.89 compared to the ground truth for\nsimulations and 0.73 when compared to a SPECT acquisition performed half an\nhour after the planar. We believe that our methodology can set a change of\nparadigm for nuclear medicine dosimetry allowing for 3D quantification using\nonly planar scintigraphy without the need of expensive and time-consuming SPECT\nleveraging the pre-therapy information of the patients.",
    "categories": [
      "physics.med-ph",
      "cs.AI"
    ],
    "published": "2025-10-24T11:46:51Z",
    "authors": [
      "Alejandro Lopez-Montes",
      "Robert Seifert",
      "Astrid Delker",
      "Guido Boening",
      "Jiahui Wang",
      "Christoph Clement",
      "Ali Afshar-Oromieh",
      "Axel Rominger",
      "Kuangyu Shi"
    ],
    "pdf_url": "http://arxiv.org/pdf/2510.21362v1"
  },
  {
    "id": "2510.21356v1",
    "title": "Gaze-VLM:Bridging Gaze and VLMs through Attention Regularization for\n  Egocentric Understanding",
    "abstract": "Eye gaze offers valuable cues about attention, short-term intent, and future\nactions, making it a powerful signal for modeling egocentric behavior. In this\nwork, we propose a gaze-regularized framework that enhances VLMs for two key\negocentric understanding tasks: fine-grained future event prediction and\ncurrent activity understanding. Unlike prior approaches that rely solely on\nvisual inputs or use gaze as an auxiliary input signal , our method uses gaze\nonly during training. We introduce a gaze-regularized attention mechanism that\naligns model focus with human visual gaze. This design is flexible and modular,\nallowing it to generalize across multiple VLM architectures that utilize\nattention. Experimental results show that our approach improves semantic\nprediction scores by up to 11 for future event prediction and around 7 for\ncurrent activity understanding, compared to the corresponding baseline models\ntrained without gaze regularization. These results highlight the value of\ngaze-guided training in improving the accuracy and robustness of egocentric\nVLMs. Overall, this work establishes a foundation for using human gaze to\nenhance the predictive capabilities of VLMs in real-world scenarios like\nassistive robots and human-machine collaboration. Code and additional\ninformation is available at: https://github.com/anupampani/Gaze-VLM",
    "categories": [
      "cs.CV",
      "cs.AI"
    ],
    "published": "2025-10-24T11:33:03Z",
    "authors": [
      "Anupam Pani",
      "Yanchao Yang"
    ],
    "pdf_url": "http://arxiv.org/pdf/2510.21356v1"
  },
  {
    "id": "2510.21346v1",
    "title": "CT-CLIP: A Multi-modal Fusion Framework for Robust Apple Leaf Disease\n  Recognition in Complex Environments",
    "abstract": "In complex orchard environments, the phenotypic heterogeneity of different\napple leaf diseases, characterized by significant variation among lesions,\nposes a challenge to traditional multi-scale feature fusion methods. These\nmethods only integrate multi-layer features extracted by convolutional neural\nnetworks (CNNs) and fail to adequately account for the relationships between\nlocal and global features. Therefore, this study proposes a multi-branch\nrecognition framework named CNN-Transformer-CLIP (CT-CLIP). The framework\nsynergistically employs a CNN to extract local lesion detail features and a\nVision Transformer to capture global structural relationships. An Adaptive\nFeature Fusion Module (AFFM) then dynamically fuses these features, achieving\noptimal coupling of local and global information and effectively addressing the\ndiversity in lesion morphology and distribution. Additionally, to mitigate\ninterference from complex backgrounds and significantly enhance recognition\naccuracy under few-shot conditions, this study proposes a multimodal image-text\nlearning approach. By leveraging pre-trained CLIP weights, it achieves deep\nalignment between visual features and disease semantic descriptions.\nExperimental results show that CT-CLIP achieves accuracies of 97.38% and 96.12%\non a publicly available apple disease and a self-built dataset, outperforming\nseveral baseline methods. The proposed CT-CLIP demonstrates strong capabilities\nin recognizing agricultural diseases, significantly enhances identification\naccuracy under complex environmental conditions, provides an innovative and\npractical solution for automated disease recognition in agricultural\napplications.",
    "categories": [
      "cs.CV",
      "cs.AI"
    ],
    "published": "2025-10-24T11:23:47Z",
    "authors": [
      "Lemin Liu",
      "Fangchao Hu",
      "Honghua Jiang",
      "Yaru Chen",
      "Limin Liu",
      "Yongliang Qiao"
    ],
    "pdf_url": "http://arxiv.org/pdf/2510.21346v1"
  },
  {
    "id": "2510.21345v1",
    "title": "$\u03b1$-LoRA: Effective Fine-Tuning via Base Model Rescaling",
    "abstract": "Fine-tuning has proven to be highly effective in adapting pre-trained models\nto perform better on new desired tasks with minimal data samples. Among the\nmost widely used approaches are reparameterization methods, which update a\ntarget module by augmenting its frozen weight matrix with an additional\ntrainable weight matrix. The most prominent example is Low Rank Adaption\n(LoRA), which gained significant attention in recent years. In this paper, we\nintroduce a new class of reparameterization methods for transfer learning,\ndesigned to enhance the generalization ability of fine-tuned models. We\nestablish the effectiveness of our approach in a high-dimensional binary\nclassification setting using tools from Random Matrix Theory, and further\nvalidate our theoretical findings through more realistic experiments, such as\nfine-tuning LLMs.",
    "categories": [
      "cs.LG",
      "cs.AI",
      "stat.ML"
    ],
    "published": "2025-10-24T11:19:33Z",
    "authors": [
      "Aymane El Firdoussi",
      "El Mahdi Chayti",
      "Mohamed El Amine Seddik",
      "Martin Jaggi"
    ],
    "pdf_url": "http://arxiv.org/pdf/2510.21345v1"
  },
  {
    "id": "2510.21342v1",
    "title": "World-POI: Global Point-of-Interest Data Enriched from Foursquare and\n  OpenStreetMap as Tabular and Graph Data",
    "abstract": "Recently, Foursquare released a global dataset with more than 100 million\npoints of interest (POIs), each representing a real-world business on its\nplatform. However, many entries lack complete metadata such as addresses or\ncategories, and some correspond to non-existent or fictional locations. In\ncontrast, OpenStreetMap (OSM) offers a rich, user-contributed POI dataset with\ndetailed and frequently updated metadata, though it does not formally verify\nwhether a POI represents an actual business. In this data paper, we present a\nmethodology that integrates the strengths of both datasets: Foursquare as a\ncomprehensive baseline of commercial POIs and OSM as a source of enriched\nmetadata. The combined dataset totals approximately 1 TB. While this full\nversion is not publicly released, we provide filtered releases with adjustable\nthresholds that reduce storage needs and make the data practical to download\nand use across domains. We also provide step-by-step instructions to reproduce\nthe full 631 GB build. Record linkage is achieved by computing name similarity\nscores and spatial distances between Foursquare and OSM POIs. These measures\nidentify and retain high-confidence matches that correspond to real businesses\nin Foursquare, have representations in OSM, and show strong name similarity.\nFinally, we use this filtered dataset to construct a graph-based representation\nof POIs enriched with attributes from both sources, enabling advanced spatial\nanalyses and a range of downstream applications.",
    "categories": [
      "cs.DB",
      "cs.AI",
      "cs.CG",
      "cs.CY",
      "cs.SI"
    ],
    "published": "2025-10-24T11:12:41Z",
    "authors": [
      "Hossein Amiri",
      "Mohammad Hashemi",
      "Andreas Z\u00fcfle"
    ],
    "pdf_url": "http://arxiv.org/pdf/2510.21342v1"
  },
  {
    "id": "2510.21341v1",
    "title": "Magellan: Guided MCTS for Latent Space Exploration and Novelty\n  Generation",
    "abstract": "Large Language Models (LLMs) often struggle with generating truly innovative\nideas, typically defaulting to high-probability, familiar concepts within their\ntraining data's \"gravity wells.\" While advanced search-based methods like Tree\nof Thoughts (ToT) attempt to mitigate this, they are fundamentally limited by\ntheir reliance on unprincipled, inconsistent self-evaluation heuristics to\nguide exploration. To address this gap, we introduce \\textbf{Magellan}, a novel\nframework that reframes creative generation as a principled, guided exploration\nof an LLM's latent conceptual space. At its core, Magellan employs Monte Carlo\nTree Search (MCTS) governed by a hierarchical guidance system. For long-range\ndirection, a \"semantic compass\" vector, formulated via orthogonal projection,\nsteers the search towards relevant novelty. For local, step-by-step decisions,\na landscape-aware value function replaces flawed self-evaluation with an\nexplicit reward structure that balances intrinsic coherence, extrinsic novelty,\nand narrative progress. Extensive experiments demonstrate that Magellan\nsignificantly outperforms strong baselines, including ReAct and ToT, in\ngenerating scientific ideas with superior plausibility and innovation. Our work\nshows that for creative discovery, a principled, guided search is more\neffective than unconstrained agency, paving the way for LLMs to become more\ncapable partners in innovation.",
    "categories": [
      "cs.AI",
      "cs.CL"
    ],
    "published": "2025-10-24T11:09:59Z",
    "authors": [
      "Lufan Chang"
    ],
    "pdf_url": "http://arxiv.org/pdf/2510.21341v1"
  },
  {
    "id": "2510.21333v1",
    "title": "CausalRec: A CausalBoost Attention Model for Sequential Recommendation",
    "abstract": "Recent advances in correlation-based sequential recommendation systems have\ndemonstrated substantial success. Specifically, the attention-based model\noutperforms other RNN-based and Markov chains-based models by capturing both\nshort- and long-term dependencies more effectively. However, solely focusing on\nitem co-occurrences overlooks the underlying motivations behind user behaviors,\nleading to spurious correlations and potentially inaccurate recommendations. To\naddress this limitation, we present a novel framework that integrates causal\nattention for sequential recommendation, CausalRec. It incorporates a causal\ndiscovery block and a CausalBooster. The causal discovery block learns the\ncausal graph in user behavior sequences, and we provide a theory to guarantee\nthe identifiability of the learned causal graph. The CausalBooster utilizes the\ndiscovered causal graph to refine the attention mechanism, prioritizing\nbehaviors with causal significance. Experimental evaluations on real-world\ndatasets indicate that CausalRec outperforms several state-of-the-art methods,\nwith average improvements of 7.21% in Hit Rate (HR) and 8.65% in Normalized\nDiscounted Cumulative Gain (NDCG). To the best of our knowledge, this is the\nfirst model to incorporate causality through the attention mechanism in\nsequential recommendation, demonstrating the value of causality in generating\nmore accurate and reliable recommendations.",
    "categories": [
      "cs.IR",
      "cs.AI"
    ],
    "published": "2025-10-24T10:49:50Z",
    "authors": [
      "Yunbo Hou",
      "Tianle Yang",
      "Ruijie Li",
      "Li He",
      "Liang Wang",
      "Weiping Li",
      "Bo Zheng",
      "Guojie Song"
    ],
    "pdf_url": "http://arxiv.org/pdf/2510.21333v1"
  },
  {
    "id": "2510.21332v1",
    "title": "Weak-to-Strong Generalization under Distribution Shifts",
    "abstract": "As future superhuman models become increasingly complex, accurately\nsupervising their behavior may exceed human capabilities. Recent works have\ndemonstrated that in such scenarios, weak models can effectively supervise\nstrong models, a phenomenon known as weak-to-strong generalization. However, we\nfind that naive weak-to-strong generalization fails under distribution shifts,\noften leading to worse performance of the strong model than its weak\nsupervisors. To address this, we propose RAVEN, a robust weak-to-strong\ngeneralization framework that dynamically learns the optimal combinations of\nweak models in addition to parameters of the strong model. We demonstrate the\neffectiveness of RAVEN on image classification, text classification, and\npreference alignment tasks. RAVEN outperforms alternative baselines by over 30%\non out-of-distribution tasks while matching or surpassing existing methods on\nin-distribution tasks. Moreover, our results show that RAVEN assigns higher\nweights to more accurate weak models, demonstrating its ability to\nautomatically identify trustworthy supervision.",
    "categories": [
      "cs.LG",
      "cs.AI",
      "stat.ML"
    ],
    "published": "2025-10-24T10:46:50Z",
    "authors": [
      "Myeongho Jeon",
      "Jan Sobotka",
      "Suhwan Choi",
      "Maria Brbi\u0107"
    ],
    "pdf_url": "http://arxiv.org/pdf/2510.21332v1"
  },
  {
    "id": "2510.21329v1",
    "title": "TripTide: A Benchmark for Adaptive Travel Planning under Disruptions",
    "abstract": "Recent efforts like TripCraft and TravelPlanner have advanced the use of\nLarge Language Models ( LLMs) for personalized, constraint aware travel\nitinerary generation. Yet, real travel often faces disruptions. To address\nthis, we present TripTide, the first benchmark evaluating LLM's ability to\nrevise itineraries under realistic disruptions. TripTide models key dimensions\nsuch as disruption severity and traveler tolerance, enabling nuanced assessment\nof LLM adaptability to events like flight cancellations, weather closures, or\noverbooked attractions. We conduct a threefold evaluation. First, we introduce\nautomatic metrics including Preservation of Intent (how well the revised plan\nmaintains feasibility and goals), Responsiveness (promptness and\nappropriateness of disruption handling), and Adaptability (semantic, spatial,\nand sequential divergence between original and revised plans). Second, we apply\nan LLM-as-a-judge approach to automatically assess revision quality. Third, we\nperform manual expert evaluation to verify whether revisions preserve semantic,\nspatial, sequential, and responsive aspects. Our experiments show that LLMs\nmaintain strong sequential consistency and semantic stability, while spatial\ndeviations are larger for shorter trips but decrease with longer ones,\nindicating that extended plans encourage better geographic coherence. However,\ndisruption-handling ability declines as plan length increases, highlighting\nlimits in LLM robustness. TripTide establishes a benchmark for evaluating\nadaptability, personalization, and resilience in LLM-based travel planning\nunder real-world uncertainty.",
    "categories": [
      "cs.CL",
      "cs.AI"
    ],
    "published": "2025-10-24T10:39:55Z",
    "authors": [
      "Priyanshu Karmakar",
      "Soumyabrata Chaudhuri",
      "Shubhojit Mallick",
      "Manish Gupta",
      "Abhik Jana",
      "Shreya Ghosh"
    ],
    "pdf_url": "http://arxiv.org/pdf/2510.21329v1"
  },
  {
    "id": "2510.21324v1",
    "title": "CXRAgent: Director-Orchestrated Multi-Stage Reasoning for Chest X-Ray\n  Interpretation",
    "abstract": "Chest X-ray (CXR) plays a pivotal role in clinical diagnosis, and a variety\nof task-specific and foundation models have been developed for automatic CXR\ninterpretation. However, these models often struggle to adapt to new diagnostic\ntasks and complex reasoning scenarios. Recently, LLM-based agent models have\nemerged as a promising paradigm for CXR analysis, enhancing model's capability\nthrough tool coordination, multi-step reasoning, and team collaboration, etc.\nHowever, existing agents often rely on a single diagnostic pipeline and lack\nmechanisms for assessing tools' reliability, limiting their adaptability and\ncredibility. To this end, we propose CXRAgent, a director-orchestrated,\nmulti-stage agent for CXR interpretation, where a central director coordinates\nthe following stages: (1) Tool Invocation: The agent strategically orchestrates\na set of CXR-analysis tools, with outputs normalized and verified by the\nEvidence-driven Validator (EDV), which grounds diagnostic outputs with visual\nevidence to support reliable downstream diagnosis; (2) Diagnostic Planning:\nGuided by task requirements and intermediate findings, the agent formulates a\ntargeted diagnostic plan. It then assembles an expert team accordingly,\ndefining member roles and coordinating their interactions to enable adaptive\nand collaborative reasoning; (3) Collaborative Decision-making: The agent\nintegrates insights from the expert team with accumulated contextual memories,\nsynthesizing them into an evidence-backed diagnostic conclusion. Experiments on\nvarious CXR interpretation tasks show that CXRAgent delivers strong\nperformance, providing visual evidence and generalizes well to clinical tasks\nof different complexity. Code and data are valuable at this\n\\href{https://github.com/laojiahuo2003/CXRAgent/}{link}.",
    "categories": [
      "cs.AI",
      "cs.MA"
    ],
    "published": "2025-10-24T10:31:30Z",
    "authors": [
      "Jinhui Lou",
      "Yan Yang",
      "Zhou Yu",
      "Zhenqi Fu",
      "Weidong Han",
      "Qingming Huang",
      "Jun Yu"
    ],
    "pdf_url": "http://arxiv.org/pdf/2510.21324v1"
  },
  {
    "id": "2510.21315v1",
    "title": "Seemingly Redundant Modules Enhance Robust Odor Learning in Fruit Flies",
    "abstract": "Biological circuits have evolved to incorporate multiple modules that perform\nsimilar functions. In the fly olfactory circuit, both lateral inhibition (LI)\nand neuronal spike frequency adaptation (SFA) are thought to enhance pattern\nseparation for odor learning. However, it remains unclear whether these\nmechanisms play redundant or distinct roles in this process. In this study, we\npresent a computational model of the fly olfactory circuit to investigate odor\ndiscrimination under varying noise conditions that simulate complex\nenvironments. Our results show that LI primarily enhances odor discrimination\nin low- and medium-noise scenarios, but this benefit diminishes and may reverse\nunder higher-noise conditions. In contrast, SFA consistently improves\ndiscrimination across all noise levels. LI is preferentially engaged in low-\nand medium-noise environments, whereas SFA dominates in high-noise settings.\nWhen combined, these two sparsification mechanisms enable optimal\ndiscrimination performance. This work demonstrates that seemingly redundant\nmodules in biological circuits can, in fact, be essential for achieving optimal\nlearning in complex contexts.",
    "categories": [
      "cs.NE",
      "cs.AI",
      "cs.LG"
    ],
    "published": "2025-10-24T10:18:38Z",
    "authors": [
      "Haiyang Li",
      "Liao Yu",
      "Qiang Yu",
      "Yunliang Zang"
    ],
    "pdf_url": "http://arxiv.org/pdf/2510.21315v1"
  },
  {
    "id": "2510.21314v1",
    "title": "A Convergence Analysis of Adaptive Optimizers under Floating-point\n  Quantization",
    "abstract": "The rapid scaling of large language models (LLMs) has made low-precision\ntraining essential for reducing memory, improving efficiency, and enabling\nlarger models and datasets. Existing convergence theories for adaptive\noptimizers, however, assume all components are exact and neglect hardware-aware\nquantization, leaving open the question of why low-precision training remains\neffective. We introduce the first theoretical framework for analyzing the\nconvergence of adaptive optimizers, including Adam and Muon, under\nfloating-point quantization of gradients, weights, and optimizer states (e.g.,\nmoment estimates). Within this framework, we derive convergence rates on smooth\nnon-convex objectives under standard stochastic gradient assumptions,\nexplicitly characterizing how quantization errors from different components\naffect convergence. We show that both algorithms retain rates close to their\nfull-precision counterparts provided mantissa length scales only\nlogarithmically with the number of iterations. Our analysis further reveals\nthat Adam is highly sensitive to weights and second-moment quantization due to\nits reliance on $\\beta_2 \\to 1$, while Muon requires weaker error control and\nis thus potentially more robust. These results narrow the gap between empirical\nsuccess and theoretical understanding of low-precision training methods.\nNumerical experiments on synthetic and real-world data corroborate our theory.",
    "categories": [
      "cs.LG",
      "cs.AI",
      "stat.ML"
    ],
    "published": "2025-10-24T10:16:23Z",
    "authors": [
      "Xuan Tang",
      "Jichu Li",
      "Difan Zou"
    ],
    "pdf_url": "http://arxiv.org/pdf/2510.21314v1"
  },
  {
    "id": "2510.21310v1",
    "title": "Efficient semantic uncertainty quantification in language models via\n  diversity-steered sampling",
    "abstract": "Accurately estimating semantic aleatoric and epistemic uncertainties in large\nlanguage models (LLMs) is particularly challenging in free-form question\nanswering (QA), where obtaining stable estimates often requires many expensive\ngenerations. We introduce a diversity-steered sampler that discourages\nsemantically redundant outputs during decoding, covers both autoregressive and\nmasked diffusion paradigms, and yields substantial sample-efficiency gains. The\nkey idea is to inject a continuous semantic-similarity penalty into the model's\nproposal distribution using a natural language inference (NLI) model lightly\nfinetuned on partial prefixes or intermediate diffusion states. We debias\ndownstream uncertainty estimates with importance reweighting and shrink their\nvariance with control variates. Across four QA benchmarks, our method matches\nor surpasses baselines while covering more semantic clusters with the same\nnumber of samples. Being modular and requiring no gradient access to the base\nLLM, the framework promises to serve as a drop-in enhancement for uncertainty\nestimation in risk-sensitive model deployments.",
    "categories": [
      "cs.CL",
      "cs.AI",
      "cs.LG"
    ],
    "published": "2025-10-24T10:06:21Z",
    "authors": [
      "Ji Won Park",
      "Kyunghyun Cho"
    ],
    "pdf_url": "http://arxiv.org/pdf/2510.21310v1"
  },
  {
    "id": "2510.23635v1",
    "title": "Help the machine to help you: an evaluation in the wild of egocentric\n  data cleaning via skeptical learning",
    "abstract": "Any digital personal assistant, whether used to support task performance,\nanswer questions, or manage work and daily life, including fitness schedules,\nrequires high-quality annotations to function properly. However, user\nannotations, whether actively produced or inferred from context (e.g., data\nfrom smartphone sensors), are often subject to errors and noise. Previous\nresearch on Skeptical Learning (SKEL) addressed the issue of noisy labels by\ncomparing offline active annotations with passive data, allowing for an\nevaluation of annotation accuracy. However, this evaluation did not include\nconfirmation from end-users, the best judges of their own context. In this\nstudy, we evaluate SKEL's performance in real-world conditions with actual\nusers who can refine the input labels based on their current perspectives and\nneeds. The study involves university students using the iLog mobile application\non their devices over a period of four weeks. The results highlight the\nchallenges of finding the right balance between user effort and data quality,\nas well as the potential benefits of using SKEL, which include reduced\nannotation effort and improved quality of collected data.",
    "categories": [
      "cs.LG",
      "cs.AI"
    ],
    "published": "2025-10-24T10:01:24Z",
    "authors": [
      "Andrea Bontempelli",
      "Matteo Busso",
      "Leonardo Javier Malcotti",
      "Fausto Giunchiglia"
    ],
    "pdf_url": "http://arxiv.org/pdf/2510.23635v1"
  },
  {
    "id": "2510.21302v1",
    "title": "Towards Reliable Code-as-Policies: A Neuro-Symbolic Framework for\n  Embodied Task Planning",
    "abstract": "Recent advances in large language models (LLMs) have enabled the automatic\ngeneration of executable code for task planning and control in embodied agents\nsuch as robots, demonstrating the potential of LLM-based embodied intelligence.\nHowever, these LLM-based code-as-policies approaches often suffer from limited\nenvironmental grounding, particularly in dynamic or partially observable\nsettings, leading to suboptimal task success rates due to incorrect or\nincomplete code generation. In this work, we propose a neuro-symbolic embodied\ntask planning framework that incorporates explicit symbolic verification and\ninteractive validation processes during code generation. In the validation\nphase, the framework generates exploratory code that actively interacts with\nthe environment to acquire missing observations while preserving task-relevant\nstates. This integrated process enhances the grounding of generated code,\nresulting in improved task reliability and success rates in complex\nenvironments. We evaluate our framework on RLBench and in real-world settings\nacross dynamic, partially observable scenarios. Experimental results\ndemonstrate that our framework improves task success rates by 46.2% over\nCode-as-Policies baselines and attains over 86.8% executability of\ntask-relevant actions, thereby enhancing the reliability of task planning in\ndynamic environments.",
    "categories": [
      "cs.AI",
      "cs.RO"
    ],
    "published": "2025-10-24T10:01:08Z",
    "authors": [
      "Sanghyun Ahn",
      "Wonje Choi",
      "Junyong Lee",
      "Jinwoo Park",
      "Honguk Woo"
    ],
    "pdf_url": "http://arxiv.org/pdf/2510.21302v1"
  },
  {
    "id": "2510.23634v1",
    "title": "Monotone and Separable Set Functions: Characterizations and Neural\n  Models",
    "abstract": "Motivated by applications for set containment problems, we consider the\nfollowing fundamental problem: can we design set-to-vector functions so that\nthe natural partial order on sets is preserved, namely $S\\subseteq T \\text{ if\nand only if } F(S)\\leq F(T) $. We call functions satisfying this property\nMonotone and Separating (MAS) set functions. % We establish lower and upper\nbounds for the vector dimension necessary to obtain MAS functions, as a\nfunction of the cardinality of the multisets and the underlying ground set. In\nthe important case of an infinite ground set, we show that MAS functions do not\nexist, but provide a model called our which provably enjoys a relaxed MAS\nproperty we name \"weakly MAS\" and is stable in the sense of Holder continuity.\nWe also show that MAS functions can be used to construct universal models that\nare monotone by construction and can approximate all monotone set functions.\nExperimentally, we consider a variety of set containment tasks. The experiments\nshow the benefit of using our our model, in comparison with standard set models\nwhich do not incorporate set containment as an inductive bias. Our code is\navailable in https://github.com/yonatansverdlov/Monotone-Embedding.",
    "categories": [
      "cs.LG",
      "cs.AI"
    ],
    "published": "2025-10-24T09:59:07Z",
    "authors": [
      "Soutrik Sarangi",
      "Yonatan Sverdlov",
      "Nadav Dym",
      "Abir De"
    ],
    "pdf_url": "http://arxiv.org/pdf/2510.23634v1"
  },
  {
    "id": "2510.21293v2",
    "title": "Understanding AI Trustworthiness: A Scoping Review of AIES & FAccT\n  Articles",
    "abstract": "Background: Trustworthy AI serves as a foundational pillar for two major AI\nethics conferences: AIES and FAccT. However, current research often adopts\ntechno-centric approaches, focusing primarily on technical attributes such as\nreliability, robustness, and fairness, while overlooking the sociotechnical\ndimensions critical to understanding AI trustworthiness in real-world contexts.\n  Objectives: This scoping review aims to examine how the AIES and FAccT\ncommunities conceptualize, measure, and validate AI trustworthiness,\nidentifying major gaps and opportunities for advancing a holistic understanding\nof trustworthy AI systems.\n  Methods: We conduct a scoping review of AIES and FAccT conference proceedings\nto date, systematically analyzing how trustworthiness is defined,\noperationalized, and applied across different research domains. Our analysis\nfocuses on conceptualization approaches, measurement methods, verification and\nvalidation techniques, application areas, and underlying values.\n  Results: While significant progress has been made in defining technical\nattributes such as transparency, accountability, and robustness, our findings\nreveal critical gaps. Current research often predominantly emphasizes technical\nprecision at the expense of social and ethical considerations. The\nsociotechnical nature of AI systems remains less explored and trustworthiness\nemerges as a contested concept shaped by those with the power to define it.\n  Conclusions: An interdisciplinary approach combining technical rigor with\nsocial, cultural, and institutional considerations is essential for advancing\ntrustworthy AI. We propose actionable measures for the AI ethics community to\nadopt holistic frameworks that genuinely address the complex interplay between\nAI systems and society, ultimately promoting responsible technological\ndevelopment that benefits all stakeholders.",
    "categories": [
      "cs.AI",
      "cs.HC"
    ],
    "published": "2025-10-24T09:40:38Z",
    "authors": [
      "Siddharth Mehrotra",
      "Jin Huang",
      "Xuelong Fu",
      "Roel Dobbe",
      "Clara I. S\u00e1nchez",
      "Maarten de Rijke"
    ],
    "pdf_url": "http://arxiv.org/pdf/2510.21293v2"
  },
  {
    "id": "2510.21285v2",
    "title": "When Models Outthink Their Safety: Mitigating Self-Jailbreak in Large\n  Reasoning Models with Chain-of-Guardrails",
    "abstract": "Large Reasoning Models (LRMs) demonstrate remarkable capabilities on complex\nreasoning tasks but remain vulnerable to severe safety risks, including harmful\ncontent generation and jailbreak attacks. Existing mitigation strategies rely\non injecting heuristic safety signals during training, which often suppress\nreasoning ability and fail to resolve the safety-reasoning trade-off. To\nsystematically investigate this issue, we analyze the reasoning trajectories of\ndiverse LRMs and uncover a phenomenon we term Self-Jailbreak, where models\noverride their own risk assessments and justify responding to unsafe prompts.\nThis finding reveals that LRMs inherently possess the ability to reject unsafe\nqueries, but this ability is compromised, resulting in harmful outputs.\nBuilding on these insights, we propose the Chain-of-Guardrail (CoG), a training\nframework that recomposes or backtracks unsafe reasoning steps, steering the\nmodel back onto safe trajectories while preserving valid reasoning chains.\nExtensive experiments across multiple reasoning and safety benchmarks\ndemonstrate that CoG substantially improves the safety of current LRMs while\npreserving comparable reasoning ability, significantly outperforming prior\nmethods that suffer from severe safety-reasoning trade-offs.",
    "categories": [
      "cs.AI",
      "cs.CL"
    ],
    "published": "2025-10-24T09:32:25Z",
    "authors": [
      "Yingzhi Mao",
      "Chunkang Zhang",
      "Junxiang Wang",
      "Xinyan Guan",
      "Boxi Cao",
      "Yaojie Lu",
      "Hongyu Lin",
      "Xianpei Han",
      "Le Sun"
    ],
    "pdf_url": "http://arxiv.org/pdf/2510.21285v2"
  },
  {
    "id": "2510.21280v2",
    "title": "WhaleVAD-BPN: Improving Baleen Whale Call Detection with Boundary\n  Proposal Networks and Post-processing Optimisation",
    "abstract": "While recent sound event detection (SED) systems can identify baleen whale\ncalls in marine audio, challenges related to false positive and minority-class\ndetection persist. We propose the boundary proposal network (BPN), which\nextends an existing lightweight SED system. The BPN is inspired by work in\nimage object detection and aims to reduce the number of false positive\ndetections. It achieves this by using intermediate latent representations\ncomputed within the backbone classification model to gate the final output.\nWhen added to an existing SED system, the BPN achieves a 16.8 % absolute\nincrease in precision, as well as 21.3 % and 9.4 % improvements in the F1-score\nfor minority-class d-calls and bp-calls, respectively. We further consider two\napproaches to the selection of post-processing hyperparameters: a\nforward-search and a backward-search. By separately optimising event-level and\nframe-level hyperparameters, these two approaches lead to considerable\nperformance improvements over parameters selected using empirical methods. The\ncomplete WhaleVAD-BPN system achieves a cross-validated development F1-score of\n0.475, which is a 9.8 % absolute improvement over the baseline.",
    "categories": [
      "eess.AS",
      "cs.AI",
      "cs.LG",
      "cs.SD",
      "q-bio.QM"
    ],
    "published": "2025-10-24T09:25:31Z",
    "authors": [
      "Christiaan M. Geldenhuys",
      "G\u00fcnther Tonitz",
      "Thomas R. Niesler"
    ],
    "pdf_url": "http://arxiv.org/pdf/2510.21280v2"
  },
  {
    "id": "2510.21276v1",
    "title": "Pctx: Tokenizing Personalized Context for Generative Recommendation",
    "abstract": "Generative recommendation (GR) models tokenize each action into a few\ndiscrete tokens (called semantic IDs) and autoregressively generate the next\ntokens as predictions, showing advantages such as memory efficiency,\nscalability, and the potential to unify retrieval and ranking. Despite these\nbenefits, existing tokenization methods are static and non-personalized. They\ntypically derive semantic IDs solely from item features, assuming a universal\nitem similarity that overlooks user-specific perspectives. However, under the\nautoregressive paradigm, semantic IDs with the same prefixes always receive\nsimilar probabilities, so a single fixed mapping implicitly enforces a\nuniversal item similarity standard across all users. In practice, the same item\nmay be interpreted differently depending on user intentions and preferences. To\naddress this issue, we propose a personalized context-aware tokenizer that\nincorporates a user's historical interactions when generating semantic IDs.\nThis design allows the same item to be tokenized into different semantic IDs\nunder different user contexts, enabling GR models to capture multiple\ninterpretive standards and produce more personalized predictions. Experiments\non three public datasets demonstrate up to 11.44% improvement in NDCG@10 over\nnon-personalized action tokenization baselines. Our code is available at\nhttps://github.com/YoungZ365/Pctx.",
    "categories": [
      "cs.IR",
      "cs.AI",
      "cs.CL"
    ],
    "published": "2025-10-24T09:22:04Z",
    "authors": [
      "Qiyong Zhong",
      "Jiajie Su",
      "Yunshan Ma",
      "Julian McAuley",
      "Yupeng Hou"
    ],
    "pdf_url": "http://arxiv.org/pdf/2510.21276v1"
  },
  {
    "id": "2510.24768v1",
    "title": "Combining SAR Simulators to Train ATR Models with Synthetic Data",
    "abstract": "This work aims to train Deep Learning models to perform Automatic Target\nRecognition (ATR) on Synthetic Aperture Radar (SAR) images. To circumvent the\nlack of real labelled measurements, we resort to synthetic data produced by SAR\nsimulators. Simulation offers full control over the virtual environment, which\nenables us to generate large and diversified datasets at will. However,\nsimulations are intrinsically grounded on simplifying assumptions of the real\nworld (i.e. physical models). Thus, synthetic datasets are not as\nrepresentative as real measurements. Consequently, ATR models trained on\nsynthetic images cannot generalize well on real measurements. Our contributions\nto this problem are twofold: on one hand, we demonstrate and quantify the\nimpact of the simulation paradigm on the ATR. On the other hand, we propose a\nnew approach to tackle the ATR problem: combine two SAR simulators that are\ngrounded on different (but complementary) paradigms to produce synthetic\ndatasets. To this end, we use two simulators: MOCEM, which is based on a\nscattering centers model approach, and Salsa, which resorts on a ray tracing\nstrategy. We train ATR models using synthetic dataset generated both by MOCEM\nand Salsa and our Deep Learning approach called ADASCA. We reach an accuracy of\nalmost 88 % on the MSTAR measurements.",
    "categories": [
      "cs.CV",
      "cs.AI",
      "eess.SP"
    ],
    "published": "2025-10-24T09:21:07Z",
    "authors": [
      "Benjamin Camus",
      "Julien Houssay",
      "Corentin Le Barbu",
      "Eric Monteux",
      "C\u00e9dric Saleun",
      "Christian Cochin"
    ],
    "pdf_url": "http://arxiv.org/pdf/2510.24768v1"
  },
  {
    "id": "2510.21275v1",
    "title": "Investigating Scale Independent UCT Exploration Factor Strategies",
    "abstract": "The Upper Confidence Bounds For Trees (UCT) algorithm is not agnostic to the\nreward scale of the game it is applied to. For zero-sum games with the sparse\nrewards of $\\{-1,0,1\\}$ at the end of the game, this is not a problem, but many\ngames often feature dense rewards with hand-picked reward scales, causing a\nnode's Q-value to span different magnitudes across different games. In this\npaper, we evaluate various strategies for adaptively choosing the UCT\nexploration constant $\\lambda$, called $\\lambda$-strategies, that are agnostic\nto the game's reward scale. These $\\lambda$-strategies include those proposed\nin the literature as well as five new strategies. Given our experimental\nresults, we recommend using one of our newly suggested $\\lambda$-strategies,\nwhich is to choose $\\lambda$ as $2 \\cdot \\sigma$ where $\\sigma$ is the\nempirical standard deviation of all state-action pairs' Q-values of the search\ntree. This method outperforms existing $\\lambda$-strategies across a wide range\nof tasks both in terms of a single parameter value and the peak performances\nobtained by optimizing all available parameters.",
    "categories": [
      "cs.AI"
    ],
    "published": "2025-10-24T09:19:14Z",
    "authors": [
      "Robin Schm\u00f6cker",
      "Christoph Schnell",
      "Alexander Dockhorn"
    ],
    "pdf_url": "http://arxiv.org/pdf/2510.21275v1"
  },
  {
    "id": "2510.21270v1",
    "title": "Sparser Block-Sparse Attention via Token Permutation",
    "abstract": "Scaling the context length of large language models (LLMs) offers significant\nbenefits but is computationally expensive. This expense stems primarily from\nthe self-attention mechanism, whose $O(N^2)$ complexity with respect to\nsequence length presents a major bottleneck for both memory and latency.\nFortunately, the attention matrix is often sparse, particularly for long\nsequences, suggesting an opportunity for optimization. Block-sparse attention\nhas emerged as a promising solution that partitions sequences into blocks and\nskips computation for a subset of these blocks. However, the effectiveness of\nthis method is highly dependent on the underlying attention patterns, which can\nlead to sub-optimal block-level sparsity. For instance, important key tokens\nfor queries within a single block may be scattered across numerous other\nblocks, leading to computational redundancy. In this work, we propose Permuted\nBlock-Sparse Attention (\\textbf{PBS-Attn}), a plug-and-play method that\nleverages the permutation properties of attention to increase block-level\nsparsity and enhance the computational efficiency of LLM prefilling. We conduct\ncomprehensive experiments on challenging real-world long-context datasets,\ndemonstrating that PBS-Attn consistently outperforms existing block-sparse\nattention methods in model accuracy and closely matches the full attention\nbaseline. Powered by our custom permuted-FlashAttention kernels, PBS-Attn\nachieves an end-to-end speedup of up to $2.75\\times$ in long-context\nprefilling, confirming its practical viability. Code available at\nhttps://github.com/xinghaow99/pbs-attn",
    "categories": [
      "cs.CL",
      "cs.AI",
      "cs.CV"
    ],
    "published": "2025-10-24T09:11:50Z",
    "authors": [
      "Xinghao Wang",
      "Pengyu Wang",
      "Dong Zhang",
      "Chenkun Tan",
      "Shaojun Zhou",
      "Zhaoxiang Liu",
      "Shiguo Lian",
      "Fangxu Liu",
      "Kai Song",
      "Xipeng Qiu"
    ],
    "pdf_url": "http://arxiv.org/pdf/2510.21270v1"
  },
  {
    "id": "2510.21894v1",
    "title": "Understanding Network Behaviors through Natural Language\n  Question-Answering",
    "abstract": "Modern large-scale networks introduce significant complexity in understanding\nnetwork behaviors, increasing the risk of misconfiguration. Prior work proposed\nto understand network behaviors by mining network configurations, typically\nrelying on domain-specific languages interfaced with formal models. While\neffective, they suffer from a steep learning curve and limited flexibility. In\ncontrast, natural language (NL) offers a more accessible and interpretable\ninterface, motivating recent research on NL-guided network behavior\nunderstanding. Recent advances in large language models (LLMs) further enhance\nthis direction, leveraging their extensive prior knowledge of network concepts\nand strong reasoning capabilities. However, three key challenges remain: 1)\nnumerous router devices with lengthy configuration files challenge LLM's\nlong-context understanding ability; 2) heterogeneity across devices and\nprotocols impedes scalability; and 3) complex network topologies and protocols\ndemand advanced reasoning abilities beyond the current capabilities of LLMs. To\ntackle the above challenges, we propose NetMind, a novel framework for querying\nnetworks using NL. Our approach introduces a tree-based configuration chunking\nstrategy to preserve semantic coherence while enabling efficient partitioning.\nWe then construct a unified fact graph as an intermediate representation to\nnormalize vendor-specific configurations. Finally, we design a hybrid\nimperative-declarative language to reduce the reasoning burden on LLMs and\nenhance precision. We contribute a benchmark consisting of NL question-answer\npairs paired with network configurations. Experiments demonstrate that NetMind\nachieves accurate and scalable network behavior understanding, outperforming\nexisting baselines.",
    "categories": [
      "cs.CL",
      "cs.AI"
    ],
    "published": "2025-10-24T08:54:29Z",
    "authors": [
      "Mingzhe Xing",
      "Chang Tian",
      "Jianan Zhang",
      "Lichen Pan",
      "Peipei Liu",
      "Zhaoteng Yan",
      "Yinliang Yue"
    ],
    "pdf_url": "http://arxiv.org/pdf/2510.21894v1"
  },
  {
    "id": "2510.21258v1",
    "title": "Correlation Dimension of Auto-Regressive Large Language Models",
    "abstract": "Large language models (LLMs) have achieved remarkable progress in natural\nlanguage generation, yet they continue to display puzzling behaviors -- such as\nrepetition and incoherence -- even when exhibiting low perplexity. This\nhighlights a key limitation of conventional evaluation metrics, which emphasize\nlocal prediction accuracy while overlooking long-range structural complexity.\nWe introduce correlation dimension, a fractal-geometric measure of\nself-similarity, to quantify the epistemological complexity of text as\nperceived by a language model. This measure captures the hierarchical\nrecurrence structure of language, bridging local and global properties in a\nunified framework. Through extensive experiments, we show that correlation\ndimension (1) reveals three distinct phases during pretraining, (2) reflects\ncontext-dependent complexity, (3) indicates a model's tendency toward\nhallucination, and (4) reliably detects multiple forms of degeneration in\ngenerated text. The method is computationally efficient, robust to model\nquantization (down to 4-bit precision), broadly applicable across\nautoregressive architectures (e.g., Transformer and Mamba), and provides fresh\ninsight into the generative dynamics of LLMs.",
    "categories": [
      "cs.CL",
      "cs.AI",
      "nlin.CD"
    ],
    "published": "2025-10-24T08:42:23Z",
    "authors": [
      "Xin Du",
      "Kumiko Tanaka-Ishii"
    ],
    "pdf_url": "http://arxiv.org/pdf/2510.21258v1"
  },
  {
    "id": "2510.21254v1",
    "title": "Out-of-Distribution Detection for Safety Assurance of AI and Autonomous\n  Systems",
    "abstract": "The operational capabilities and application domains of AI-enabled autonomous\nsystems have expanded significantly in recent years due to advances in robotics\nand machine learning (ML). Demonstrating the safety of autonomous systems\nrigorously is critical for their responsible adoption but it is challenging as\nit requires robust methodologies that can handle novel and uncertain situations\nthroughout the system lifecycle, including detecting out-of-distribution (OoD)\ndata. Thus, OOD detection is receiving increased attention from the research,\ndevelopment and safety engineering communities. This comprehensive review\nanalyses OOD detection techniques within the context of safety assurance for\nautonomous systems, in particular in safety-critical domains. We begin by\ndefining the relevant concepts, investigating what causes OOD and exploring the\nfactors which make the safety assurance of autonomous systems and OOD detection\nchallenging. Our review identifies a range of techniques which can be used\nthroughout the ML development lifecycle and we suggest areas within the\nlifecycle in which they may be used to support safety assurance arguments. We\ndiscuss a number of caveats that system and safety engineers must be aware of\nwhen integrating OOD detection into system lifecycles. We conclude by outlining\nthe challenges and future work necessary for the safe development and operation\nof autonomous systems across a range of domains and applications.",
    "categories": [
      "cs.AI"
    ],
    "published": "2025-10-24T08:38:01Z",
    "authors": [
      "Victoria J. Hodge",
      "Colin Paterson",
      "Ibrahim Habli"
    ],
    "pdf_url": "http://arxiv.org/pdf/2510.21254v1"
  },
  {
    "id": "2510.21244v1",
    "title": "OutboundEval: A Dual-Dimensional Benchmark for Expert-Level Intelligent\n  Outbound Evaluation of Xbench's Professional-Aligned Series",
    "abstract": "We propose OutboundEval, a comprehensive benchmark for evaluating large\nlanguage models (LLMs) in expert-level intelligent outbound calling scenarios.\nUnlike existing methods that suffer from three key limitations - insufficient\ndataset diversity and category coverage, unrealistic user simulation, and\ninaccurate evaluation metrics - OutboundEval addresses these issues through a\nstructured framework. First, we design a benchmark spanning six major business\ndomains and 30 representative sub-scenarios, each with scenario-specific\nprocess decomposition, weighted scoring, and domain-adaptive metrics. Second,\nwe develop a large-model-driven User Simulator that generates diverse,\npersona-rich virtual users with realistic behaviors, emotional variability, and\ncommunication styles, providing a controlled yet authentic testing environment.\nThird, we introduce a dynamic evaluation method that adapts to task variations,\nintegrating automated and human-in-the-loop assessment to measure task\nexecution accuracy, professional knowledge application, adaptability, and user\nexperience quality. Experiments on 12 state-of-the-art LLMs reveal distinct\ntrade-offs between expert-level task completion and interaction fluency,\noffering practical insights for building reliable, human-like outbound AI\nsystems. OutboundEval establishes a practical, extensible, and domain-oriented\nstandard for benchmarking LLMs in professional applications.",
    "categories": [
      "cs.AI"
    ],
    "published": "2025-10-24T08:27:58Z",
    "authors": [
      "Pengyu Xu",
      "Shijia Li",
      "Ao Sun",
      "Feng Zhang",
      "Yahan Li",
      "Bo Wu",
      "Zhanyu Ma",
      "Jiguo Li",
      "Jun Xu",
      "Jiuchong Gao",
      "Jinghua Hao",
      "Renqing He",
      "Rui Wang",
      "Yang Liu",
      "Xiaobo Hu",
      "Fan Yang",
      "Jia Zheng",
      "Guanghua Yao"
    ],
    "pdf_url": "http://arxiv.org/pdf/2510.21244v1"
  },
  {
    "id": "2510.21238v1",
    "title": "Physics-Informed Neural Networks for MIMO Beam Map and Environment\n  Reconstruction",
    "abstract": "As communication networks evolve towards greater complexity (e.g., 6G and\nbeyond), a deep understanding of the wireless environment becomes increasingly\ncrucial. When explicit knowledge of the environment is unavailable,\ngeometry-aware feature extraction from channel state information (CSI) emerges\nas a pivotal methodology to bridge physical-layer measurements with network\nintelligence. This paper proposes to explore the received signal strength (RSS)\ndata, without explicit 3D environment knowledge, to jointly construct the radio\nbeam map and environmental geometry for a multiple-input multiple-output (MIMO)\nsystem. Unlike existing methods that only learn blockage structures, we propose\nan oriented virtual obstacle model that captures the geometric features of both\nblockage and reflection. Reflective zones are formulated to identify relevant\nreflected paths according to the geometry relation of the environment. We\nderive an analytical expression for the reflective zone and further analyze its\ngeometric characteristics to develop a reformulation that is more compatible\nwith deep learning representations. A physics-informed deep learning framework\nthat incorporates the reflective-zone-based geometry model is proposed to learn\nthe blockage, reflection, and scattering components, along with the beam\npattern, which leverages physics prior knowledge to enhance network\ntransferability. Numerical experiments demonstrate that, in addition to\nreconstructing the blockage and reflection geometry, the proposed model can\nconstruct a more accurate MIMO beam map with a 32%-48% accuracy improvement.",
    "categories": [
      "eess.SY",
      "cs.AI",
      "cs.IT",
      "cs.SY",
      "math.IT"
    ],
    "published": "2025-10-24T08:17:14Z",
    "authors": [
      "Wangqian Chen",
      "Junting Chen",
      "Shuguang Cui"
    ],
    "pdf_url": "http://arxiv.org/pdf/2510.21238v1"
  },
  {
    "id": "2510.21236v2",
    "title": "Securing AI Agent Execution",
    "abstract": "Large Language Models (LLMs) have evolved into AI agents that interact with\nexternal tools and environments to perform complex tasks. The Model Context\nProtocol (MCP) has become the de facto standard for connecting agents with such\nresources, but security has lagged behind: thousands of MCP servers execute\nwith unrestricted access to host systems, creating a broad attack surface. In\nthis paper, we introduce AgentBound, the first access control framework for MCP\nservers. AgentBound combines a declarative policy mechanism, inspired by the\nAndroid permission model, with a policy enforcement engine that contains\nmalicious behavior without requiring MCP server modifications. We build a\ndataset containing the 296 most popular MCP servers, and show that access\ncontrol policies can be generated automatically from source code with 80.9%\naccuracy. We also show that AgentBound blocks the majority of security threats\nin several malicious MCP servers, and that policy enforcement engine introduces\nnegligible overhead. Our contributions provide developers and project managers\nwith a practical foundation for securing MCP servers while maintaining\nproductivity, enabling researchers and tool builders to explore new directions\nfor declarative access control and MCP security.",
    "categories": [
      "cs.CR",
      "cs.AI",
      "cs.SE",
      "D.2.0"
    ],
    "published": "2025-10-24T08:10:36Z",
    "authors": [
      "Christoph B\u00fchler",
      "Matteo Biagiola",
      "Luca Di Grazia",
      "Guido Salvaneschi"
    ],
    "pdf_url": "http://arxiv.org/pdf/2510.21236v2"
  },
  {
    "id": "2510.23633v1",
    "title": "Noise is All You Need: Solving Linear Inverse Problems by Noise\n  Combination Sampling with Diffusion Models",
    "abstract": "Pretrained diffusion models have demonstrated strong capabilities in\nzero-shot inverse problem solving by incorporating observation information into\nthe generation process of the diffusion models. However, this presents an\ninherent dilemma: excessive integration can disrupt the generative process,\nwhile insufficient integration fails to emphasize the constraints imposed by\nthe inverse problem. To address this, we propose \\emph{Noise Combination\nSampling}, a novel method that synthesizes an optimal noise vector from a noise\nsubspace to approximate the measurement score, replacing the noise term in the\nstandard Denoising Diffusion Probabilistic Models process. This enables\nconditional information to be naturally embedded into the generation process\nwithout reliance on step-wise hyperparameter tuning. Our method can be applied\nto a wide range of inverse problem solvers, including image compression, and,\nparticularly when the number of generation steps $T$ is small, achieves\nsuperior performance with negligible computational overhead, significantly\nimproving robustness and stability.",
    "categories": [
      "cs.LG",
      "cs.AI",
      "cs.CV",
      "eess.IV"
    ],
    "published": "2025-10-24T07:46:23Z",
    "authors": [
      "Xun Su",
      "Hiroyuki Kasai"
    ],
    "pdf_url": "http://arxiv.org/pdf/2510.23633v1"
  },
  {
    "id": "2510.21188v1",
    "title": "PLAN: Proactive Low-Rank Allocation for Continual Learning",
    "abstract": "Continual learning (CL) requires models to continuously adapt to new tasks\nwithout forgetting past knowledge. In this work, we propose\n\\underline{P}roactive \\underline{L}ow-rank \\underline{A}llocatio\\underline{N}\n(PLAN), a framework that extends Low-Rank Adaptation (LoRA) to enable efficient\nand interference-aware fine-tuning of large pre-trained models in CL settings.\nPLAN proactively manages the allocation of task-specific subspaces by\nintroducing orthogonal basis vectors for each task and optimizing them through\na perturbation-based strategy that minimizes conflicts with previously learned\nparameters. Furthermore, PLAN incorporates a novel selection mechanism that\nidentifies and assigns basis vectors with minimal sensitivity to interference,\nreducing the risk of degrading past knowledge while maintaining efficient\nadaptation to new tasks. Empirical results on standard CL benchmarks\ndemonstrate that PLAN consistently outperforms existing methods, establishing a\nnew state-of-the-art for continual learning with foundation models.",
    "categories": [
      "cs.LG",
      "cs.AI"
    ],
    "published": "2025-10-24T06:37:41Z",
    "authors": [
      "Xiequn Wang",
      "Zhan Zhuang",
      "Yu Zhang"
    ],
    "pdf_url": "http://arxiv.org/pdf/2510.21188v1"
  },
  {
    "id": "2510.21184v1",
    "title": "Reducing the Probability of Undesirable Outputs in Language Models Using\n  Probabilistic Inference",
    "abstract": "Reinforcement learning (RL) has become a predominant technique to align\nlanguage models (LMs) with human preferences or promote outputs which are\ndeemed to be desirable by a given reward function. Standard RL approaches\noptimize average reward, while methods explicitly focused on reducing the\nprobability of undesired outputs typically come at a cost to average-case\nperformance. To improve this tradeoff, we introduce RePULSe, a new training\nmethod that augments the standard RL loss with an additional loss that uses\nlearned proposals to guide sampling low-reward outputs, and then reduces those\noutputs' probability. We run experiments demonstrating that RePULSe produces a\nbetter tradeoff of expected reward versus the probability of undesired outputs\nand is more adversarially robust, compared to standard RL alignment approaches\nand alternatives.",
    "categories": [
      "cs.LG",
      "cs.AI",
      "cs.CL",
      "stat.ML"
    ],
    "published": "2025-10-24T06:23:55Z",
    "authors": [
      "Stephen Zhao",
      "Aidan Li",
      "Rob Brekelmans",
      "Roger Grosse"
    ],
    "pdf_url": "http://arxiv.org/pdf/2510.21184v1"
  },
  {
    "id": "2510.21181v1",
    "title": "Shylock: Causal Discovery in Multivariate Time Series based on Hybrid\n  Constraints",
    "abstract": "Causal relationship discovery has been drawing increasing attention due to\nits prevalent application. Existing methods rely on human experience,\nstatistical methods, or graphical criteria methods which are error-prone, stuck\nat the idealized assumption, and rely on a huge amount of data. And there is\nalso a serious data gap in accessing Multivariate time series(MTS) in many\nareas, adding difficulty in finding their causal relationship. Existing methods\nare easy to be over-fitting on them. To fill the gap we mentioned above, in\nthis paper, we propose Shylock, a novel method that can work well in both\nfew-shot and normal MTS to find the causal relationship. Shylock can reduce the\nnumber of parameters exponentially by using group dilated convolution and a\nsharing kernel, but still learn a better representation of variables with time\ndelay. By combing the global constraint and the local constraint, Shylock\nachieves information sharing among networks to help improve the accuracy. To\nevaluate the performance of Shylock, we also design a data generation method to\ngenerate MTS with time delay. We evaluate it on commonly used benchmarks and\ngenerated datasets. Extensive experiments show that Shylock outperforms two\nexisting state-of-art methods on both few-shot and normal MTS. We also\ndeveloped Tcausal, a library for easy use and deployed it on the EarthDataMiner\nplatform",
    "categories": [
      "cs.AI"
    ],
    "published": "2025-10-24T06:12:24Z",
    "authors": [
      "Shuo Li",
      "Keqin Xu",
      "Jie Liu",
      "Dan Ye"
    ],
    "pdf_url": "http://arxiv.org/pdf/2510.21181v1"
  },
  {
    "id": "2510.21175v1",
    "title": "Memory-Free Continual Learning with Null Space Adaptation for Zero-Shot\n  Vision-Language Models",
    "abstract": "Pre-trained vision-language models (VLMs), such as CLIP, have demonstrated\nremarkable zero-shot generalization, enabling deployment in a wide range of\nreal-world tasks without additional task-specific training. However, in real\ndeployment scenarios with evolving environments or emerging classes, these\nmodels inevitably face distributional shifts and novel tasks. In such contexts,\nstatic zero-shot capabilities are insufficient, and there is a growing need for\ncontinual learning methods that allow models to adapt over time while avoiding\ncatastrophic forgetting. We introduce NuSA-CL (Null Space Adaptation for\nContinual Learning), a lightweight memory-free continual learning framework\ndesigned to address this challenge. NuSA-CL employs low-rank adaptation and\nconstrains task-specific weight updates to lie within an approximate null space\nof the model's current parameters. This strategy minimizes interference with\npreviously acquired knowledge, effectively preserving the zero-shot\ncapabilities of the original model. Unlike methods relying on replay buffers or\ncostly distillation, NuSA-CL imposes minimal computational and memory overhead,\nmaking it practical for deployment in resource-constrained, real-world\ncontinual learning environments. Experiments show that our framework not only\neffectively preserves zero-shot transfer capabilities but also achieves highly\ncompetitive performance on continual learning benchmarks. These results\nposition NuSA-CL as a practical and scalable solution for continually evolving\nzero-shot VLMs in real-world applications.",
    "categories": [
      "cs.AI"
    ],
    "published": "2025-10-24T05:53:32Z",
    "authors": [
      "Yujin Jo",
      "Taesup Kim"
    ],
    "pdf_url": "http://arxiv.org/pdf/2510.21175v1"
  },
  {
    "id": "2510.23632v1",
    "title": "LLMComp: A Language Modeling Paradigm for Error-Bounded Scientific Data\n  Compression",
    "abstract": "The rapid growth of high-resolution scientific simulations and observation\nsystems is generating massive spatiotemporal datasets, making efficient,\nerror-bounded compression increasingly important. Meanwhile, decoder-only large\nlanguage models (LLMs) have demonstrated remarkable capabilities in modeling\ncomplex sequential data. In this paper, we propose LLMCOMP, a novel lossy\ncompression paradigm that leverages decoder-only large LLMs to model scientific\ndata. LLMCOMP first quantizes 3D fields into discrete tokens, arranges them via\nZ-order curves to preserve locality, and applies coverage-guided sampling to\nenhance training efficiency. An autoregressive transformer is then trained with\nspatial-temporal embeddings to model token transitions. During compression, the\nmodel performs top-k prediction, storing only rank indices and fallback\ncorrections to ensure strict error bounds. Experiments on multiple reanalysis\ndatasets show that LLMCOMP consistently outperforms state-of-the-art\ncompressors, achieving up to 30% higher compression ratios under strict error\nbounds. These results highlight the potential of LLMs as general-purpose\ncompressors for high-fidelity scientific data.",
    "categories": [
      "cs.LG",
      "cs.AI"
    ],
    "published": "2025-10-24T05:41:04Z",
    "authors": [
      "Guozhong Li",
      "Muhannad Alhumaidi",
      "Spiros Skiadopoulos",
      "Panos Kalnis"
    ],
    "pdf_url": "http://arxiv.org/pdf/2510.23632v1"
  },
  {
    "id": "2510.21155v1",
    "title": "Towards Straggler-Resilient Split Federated Learning: An Unbalanced\n  Update Approach",
    "abstract": "Split Federated Learning (SFL) enables scalable training on edge devices by\ncombining the parallelism of Federated Learning (FL) with the computational\noffloading of Split Learning (SL). Despite its great success, SFL suffers\nsignificantly from the well-known straggler issue in distributed learning\nsystems. This problem is exacerbated by the dependency between Split Server and\nclients: the Split Server side model update relies on receiving activations\nfrom clients. Such synchronization requirement introduces significant time\nlatency, making straggler a critical bottleneck to the scalability and\nefficiency of the system. To mitigate this problem, we propose MU-SplitFed, a\nstraggler-resilient SFL algorithm in zeroth-order optimization that decouples\ntraining progress from straggler delays via a simple yet effective unbalanced\nupdate mechanism.\n  By enabling the server to perform $\\tau$ local updates per client round,\nMU-SplitFed achieves a convergence rate of $O(\\sqrt{d/(\\tau T)})$ for\nnon-convex objectives, demonstrating a linear speedup of $\\tau$ in\ncommunication rounds. Experiments demonstrate that MU-SplitFed consistently\noutperforms baseline methods with the presence of stragglers and effectively\nmitigates their impact through adaptive tuning of $\\tau$. The code for this\nproject is available at https://github.com/Johnny-Zip/MU-SplitFed.",
    "categories": [
      "cs.DC",
      "cs.AI",
      "cs.LG"
    ],
    "published": "2025-10-24T04:55:27Z",
    "authors": [
      "Dandan Liang",
      "Jianing Zhang",
      "Evan Chen",
      "Zhe Li",
      "Rui Li",
      "Haibo Yang"
    ],
    "pdf_url": "http://arxiv.org/pdf/2510.21155v1"
  },
  {
    "id": "2510.21153v1",
    "title": "Uncertainty-Aware Multi-Objective Reinforcement Learning-Guided\n  Diffusion Models for 3D De Novo Molecular Design",
    "abstract": "Designing de novo 3D molecules with desirable properties remains a\nfundamental challenge in drug discovery and molecular engineering. While\ndiffusion models have demonstrated remarkable capabilities in generating\nhigh-quality 3D molecular structures, they often struggle to effectively\ncontrol complex multi-objective constraints critical for real-world\napplications. In this study, we propose an uncertainty-aware Reinforcement\nLearning (RL) framework to guide the optimization of 3D molecular diffusion\nmodels toward multiple property objectives while enhancing the overall quality\nof the generated molecules. Our method leverages surrogate models with\npredictive uncertainty estimation to dynamically shape reward functions,\nfacilitating balance across multiple optimization objectives. We\ncomprehensively evaluate our framework across three benchmark datasets and\nmultiple diffusion model architectures, consistently outperforming baselines\nfor molecular quality and property optimization. Additionally, Molecular\nDynamics (MD) simulations and ADMET profiling of top generated candidates\nindicate promising drug-like behavior and binding stability, comparable to\nknown Epidermal Growth Factor Receptor (EGFR) inhibitors. Our results\ndemonstrate the strong potential of RL-guided generative diffusion models for\nadvancing automated molecular design.",
    "categories": [
      "cs.LG",
      "cs.AI"
    ],
    "published": "2025-10-24T04:49:23Z",
    "authors": [
      "Lianghong Chen",
      "Dongkyu Eugene Kim",
      "Mike Domaratzki",
      "Pingzhao Hu"
    ],
    "pdf_url": "http://arxiv.org/pdf/2510.21153v1"
  },
  {
    "id": "2510.21150v1",
    "title": "String Seed of Thought: Prompting LLMs for Distribution-Faithful and\n  Diverse Generation",
    "abstract": "We introduce String Seed of Thought (SSoT), a novel prompting method for LLMs\nthat improves Probabilistic Instruction Following (PIF). We define PIF as a\ntask requiring an LLM to select its answer from a predefined set of options,\neach associated with a specific probability, such that the empirical\ndistribution of the generated answers aligns with the target distribution when\nprompted multiple times. While LLMs excel at tasks with single, deterministic\nanswers, they often fail at PIF, exhibiting biases problematic for applications\nrequiring non-deterministic behaviors, such as human-behavior simulation,\ncontent diversification, and multiplayer games. It also harms the diversity of\ngenerated responses, a crucial factor in test-time scaling, by causing the\noutputs to collapse into a limited set of answers. To address this, we propose\nSSoT, a simple prompting method that instructs an LLM to first output a random\nstring to generate sufficient entropy. SSoT also instructs the LLM to extract\nrandomness by manipulating this string to derive a final answer, thereby\npreserving diversity while adhering to specific constraints. We demonstrate\nthat SSoT significantly improves the PIF performance of LLMs, approaching the\nideal performance of a pseudo-random number generator. Furthermore, our\nexperiments on NoveltyBench show SSoT's benefits extend beyond closed-set tasks\nto open-ended tasks by enhancing response diversity.",
    "categories": [
      "cs.AI"
    ],
    "published": "2025-10-24T04:43:50Z",
    "authors": [
      "Kou Misaki",
      "Takuya Akiba"
    ],
    "pdf_url": "http://arxiv.org/pdf/2510.21150v1"
  },
  {
    "id": "2510.21148v1",
    "title": "How to Auto-optimize Prompts for Domain Tasks? Adaptive Prompting and\n  Reasoning through Evolutionary Domain Knowledge Adaptation",
    "abstract": "Designing optimal prompts and reasoning processes for large language models\n(LLMs) on domain-specific tasks is both necessary and challenging in real-world\napplications. Determining how to integrate domain knowledge, enhance reasoning\nefficiency, and even provide domain experts with refined knowledge integration\nhints are particularly crucial yet unresolved tasks. In this research, we\npropose Evolutionary Graph Optimization for Prompting (EGO-Prompt), an\nautomated framework to designing better prompts, efficient reasoning processes\nand providing enhanced causal-informed process. EGO-Prompt begins with a\ngeneral prompt and fault-tolerant initial Semantic Causal Graph (SCG)\ndescriptions, constructed by human experts, which is then automatically refined\nand optimized to guide LLM reasoning. Recognizing that expert-defined SCGs may\nbe partial or imperfect and that their optimal integration varies across LLMs,\nEGO-Prompt integrates a novel causal-guided textual gradient process in two\nsteps: first, generating nearly deterministic reasoning guidance from the SCG\nfor each instance, and second, adapting the LLM to effectively utilize the\nguidance alongside the original input. The iterative optimization algorithm\nfurther refines both the SCG and the reasoning mechanism using textual\ngradients with ground-truth. We tested the framework on real-world public\nhealth, transportation and human behavior tasks. EGO-Prompt achieves\n7.32%-12.61% higher F1 than cutting-edge methods, and allows small models to\nreach the performence of larger models at under 20% of the original cost. It\nalso outputs a refined, domain-specific SCG that improves interpretability.",
    "categories": [
      "cs.AI"
    ],
    "published": "2025-10-24T04:38:53Z",
    "authors": [
      "Yang Zhao",
      "Pu Wang",
      "Hao Frank Yang"
    ],
    "pdf_url": "http://arxiv.org/pdf/2510.21148v1"
  },
  {
    "id": "2510.21147v1",
    "title": "Hierarchical AI Multi-Agent Fundamental Investing: Evidence from China's\n  A-Share Market",
    "abstract": "We present a multi-agent, AI-driven framework for fundamental investing that\nintegrates macro indicators, industry-level and firm-specific information to\nconstruct optimized equity portfolios. The architecture comprises: (i) a Macro\nagent that dynamically screens and weights sectors based on evolving economic\nindicators and industry performance; (ii) four firm-level agents --\nFundamental, Technical, Report, and News -- that conduct in-depth analyses of\nindividual firms to ensure both breadth and depth of coverage; (iii) a\nPortfolio agent that uses reinforcement learning to combine the agent outputs\ninto a unified policy to generate the trading strategy; and (iv) a Risk Control\nagent that adjusts portfolio positions in response to market volatility. We\nevaluate the system on the constituents by the CSI 300 Index of China's A-share\nmarket and find that it consistently outperforms standard benchmarks and a\nstate-of-the-art multi-agent trading system on risk-adjusted returns and\ndrawdown control. Our core contribution is a hierarchical multi-agent design\nthat links top-down macro screening with bottom-up fundamental analysis,\noffering a robust and extensible approach to factor-based portfolio\nconstruction.",
    "categories": [
      "q-fin.PM",
      "cs.AI"
    ],
    "published": "2025-10-24T04:38:37Z",
    "authors": [
      "Chujun He",
      "Zhonghao Huang",
      "Xiangguo Li",
      "Ye Luo",
      "Kewei Ma",
      "Yuxuan Xiong",
      "Xiaowei Zhang",
      "Mingyang Zhao"
    ],
    "pdf_url": "http://arxiv.org/pdf/2510.21147v1"
  },
  {
    "id": "2510.21144v1",
    "title": "NeuroGenPoisoning: Neuron-Guided Attacks on Retrieval-Augmented\n  Generation of LLM via Genetic Optimization of External Knowledge",
    "abstract": "Retrieval-Augmented Generation (RAG) empowers Large Language Models (LLMs) to\ndynamically integrate external knowledge during inference, improving their\nfactual accuracy and adaptability. However, adversaries can inject poisoned\nexternal knowledge to override the model's internal memory. While existing\nattacks iteratively manipulate retrieval content or prompt structure of RAG,\nthey largely ignore the model's internal representation dynamics and\nneuron-level sensitivities. The underlying mechanism of RAG poisoning has not\nbeen fully studied and the effect of knowledge conflict with strong parametric\nknowledge in RAG is not considered. In this work, we propose NeuroGenPoisoning,\na novel attack framework that generates adversarial external knowledge in RAG\nguided by LLM internal neuron attribution and genetic optimization. Our method\nfirst identifies a set of Poison-Responsive Neurons whose activation strongly\ncorrelates with contextual poisoning knowledge. We then employ a genetic\nalgorithm to evolve adversarial passages that maximally activate these neurons.\nCrucially, our framework enables massive-scale generation of effective poisoned\nRAG knowledge by identifying and reusing promising but initially unsuccessful\nexternal knowledge variants via observed attribution signals. At the same time,\nPoison-Responsive Neurons guided poisoning can effectively resolves knowledge\nconflict. Experimental results across models and datasets demonstrate\nconsistently achieving high Population Overwrite Success Rate (POSR) of over\n90% while preserving fluency. Empirical evidence shows that our method\neffectively resolves knowledge conflict.",
    "categories": [
      "cs.AI"
    ],
    "published": "2025-10-24T04:30:49Z",
    "authors": [
      "Hanyu Zhu",
      "Lance Fiondella",
      "Jiawei Yuan",
      "Kai Zeng",
      "Long Jiao"
    ],
    "pdf_url": "http://arxiv.org/pdf/2510.21144v1"
  },
  {
    "id": "2510.21143v2",
    "title": "PanicToCalm: A Proactive Counseling Agent for Panic Attacks",
    "abstract": "Panic attacks are acute episodes of fear and distress, in which timely,\nappropriate intervention can significantly help individuals regain stability.\nHowever, suitable datasets for training such models remain scarce due to\nethical and logistical issues. To address this, we introduce PACE, which is a\ndataset that includes high-distress episodes constructed from first-person\nnarratives, and structured around the principles of Psychological First Aid\n(PFA). Using this data, we train PACER, a counseling model designed to provide\nboth empathetic and directive support, which is optimized through supervised\nlearning and simulated preference alignment. To assess its effectiveness, we\npropose PanicEval, a multi-dimensional framework covering general counseling\nquality and crisis-specific strategies. Experimental results show that PACER\noutperforms strong baselines in both counselor-side metrics and client affect\nimprovement. Human evaluations further confirm its practical value, with PACER\nconsistently preferred over general, CBT-based, and GPT-4-powered models in\npanic scenarios (Code is available at https://github.com/JihyunLee1/PanicToCalm\n).",
    "categories": [
      "cs.AI"
    ],
    "published": "2025-10-24T04:30:24Z",
    "authors": [
      "Jihyun Lee",
      "Yejin Min",
      "San Kim",
      "Yejin Jeon",
      "SungJun Yang",
      "Hyounghun Kim",
      "Gary Geunbae Lee"
    ],
    "pdf_url": "http://arxiv.org/pdf/2510.21143v2"
  },
  {
    "id": "2510.24767v1",
    "title": "Towards Fine-Grained Human Motion Video Captioning",
    "abstract": "Generating accurate descriptions of human actions in videos remains a\nchallenging task for video captioning models. Existing approaches often\nstruggle to capture fine-grained motion details, resulting in vague or\nsemantically inconsistent captions. In this work, we introduce the\nMotion-Augmented Caption Model (M-ACM), a novel generative framework that\nenhances caption quality by incorporating motion-aware decoding. At its core,\nM-ACM leverages motion representations derived from human mesh recovery to\nexplicitly highlight human body dynamics, thereby reducing hallucinations and\nimproving both semantic fidelity and spatial alignment in the generated\ncaptions. To support research in this area, we present the Human Motion Insight\n(HMI) Dataset, comprising 115K video-description pairs focused on human\nmovement, along with HMI-Bench, a dedicated benchmark for evaluating\nmotion-focused video captioning. Experimental results demonstrate that M-ACM\nsignificantly outperforms previous methods in accurately describing complex\nhuman motions and subtle temporal variations, setting a new standard for\nmotion-centric video captioning.",
    "categories": [
      "cs.CV",
      "cs.AI"
    ],
    "published": "2025-10-24T04:06:04Z",
    "authors": [
      "Guorui Song",
      "Guocun Wang",
      "Zhe Huang",
      "Jing Lin",
      "Xuefei Zhe",
      "Jian Li",
      "Haoqian Wang"
    ],
    "pdf_url": "http://arxiv.org/pdf/2510.24767v1"
  },
  {
    "id": "2510.21133v1",
    "title": "Quantifying CBRN Risk in Frontier Models",
    "abstract": "Frontier Large Language Models (LLMs) pose unprecedented dual-use risks\nthrough the potential proliferation of chemical, biological, radiological, and\nnuclear (CBRN) weapons knowledge. We present the first comprehensive evaluation\nof 10 leading commercial LLMs against both a novel 200-prompt CBRN dataset and\na 180-prompt subset of the FORTRESS benchmark, using a rigorous three-tier\nattack methodology. Our findings expose critical safety vulnerabilities: Deep\nInception attacks achieve 86.0\\% success versus 33.8\\% for direct requests,\ndemonstrating superficial filtering mechanisms; Model safety performance varies\ndramatically from 2\\% (claude-opus-4) to 96\\% (mistral-small-latest) attack\nsuccess rates; and eight models exceed 70\\% vulnerability when asked to enhance\ndangerous material properties. We identify fundamental brittleness in current\nsafety alignment, where simple prompt engineering techniques bypass safeguards\nfor dangerous CBRN information. These results challenge industry safety claims\nand highlight urgent needs for standardized evaluation frameworks, transparent\nsafety metrics, and more robust alignment techniques to mitigate catastrophic\nmisuse risks while preserving beneficial capabilities.",
    "categories": [
      "cs.CR",
      "cs.AI"
    ],
    "published": "2025-10-24T03:55:24Z",
    "authors": [
      "Divyanshu Kumar",
      "Nitin Aravind Birur",
      "Tanay Baswa",
      "Sahil Agarwal",
      "Prashanth Harshangi"
    ],
    "pdf_url": "http://arxiv.org/pdf/2510.21133v1"
  },
  {
    "id": "2510.21131v1",
    "title": "Large Language Models Meet Text-Attributed Graphs: A Survey of\n  Integration Frameworks and Applications",
    "abstract": "Large Language Models (LLMs) have achieved remarkable success in natural\nlanguage processing through strong semantic understanding and generation.\nHowever, their black-box nature limits structured and multi-hop reasoning. In\ncontrast, Text-Attributed Graphs (TAGs) provide explicit relational structures\nenriched with textual context, yet often lack semantic depth. Recent research\nshows that combining LLMs and TAGs yields complementary benefits: enhancing TAG\nrepresentation learning and improving the reasoning and interpretability of\nLLMs. This survey provides the first systematic review of LLM--TAG integration\nfrom an orchestration perspective. We introduce a novel taxonomy covering two\nfundamental directions: LLM for TAG, where LLMs enrich graph-based tasks, and\nTAG for LLM, where structured graphs improve LLM reasoning. We categorize\norchestration strategies into sequential, parallel, and multi-module\nframeworks, and discuss advances in TAG-specific pretraining, prompting, and\nparameter-efficient fine-tuning. Beyond methodology, we summarize empirical\ninsights, curate available datasets, and highlight diverse applications across\nrecommendation systems, biomedical analysis, and knowledge-intensive question\nanswering. Finally, we outline open challenges and promising research\ndirections, aiming to guide future work at the intersection of language and\ngraph learning.",
    "categories": [
      "cs.CL",
      "cs.AI",
      "cs.LG"
    ],
    "published": "2025-10-24T03:53:00Z",
    "authors": [
      "Guangxin Su",
      "Hanchen Wang",
      "Jianwei Wang",
      "Wenjie Zhang",
      "Ying Zhang",
      "Jian Pei"
    ],
    "pdf_url": "http://arxiv.org/pdf/2510.21131v1"
  },
  {
    "id": "2510.23631v1",
    "title": "Beyond Pairwise: Empowering LLM Alignment With Ranked Choice Modeling",
    "abstract": "Alignment of large language models (LLMs) has predominantly relied on\npairwise preference optimization, where annotators select the better of two\nresponses to a prompt. While simple, this approach overlooks the opportunity to\nlearn from richer forms of human feedback, such as multiwise comparisons and\ntop-$k$ rankings. We propose Ranked Choice Preference Optimization (RCPO), a\nunified framework that bridges preference optimization with (ranked) choice\nmodeling via maximum likelihood estimation. The framework is flexible,\nsupporting both utility-based and rank-based choice models. It subsumes several\nexisting pairwise methods (e.g., DPO, SimPO), while providing principled\ntraining objectives for richer feedback formats. We instantiate this framework\nwith two representative ranked choice models (Multinomial Logit and\nMallows-RMJ). Empirical studies on Llama-3-8B-Instruct and Gemma-2-9B-it across\nAlpacaEval 2 and Arena-Hard benchmarks show that RCPO consistently outperforms\ncompetitive baselines. RCPO shows how directly leveraging ranked preference\ndata, combined with the right choice models, yields more effective alignment.\nIt offers a versatile and extensible foundation for incorporating (ranked)\nchoice modeling into LLM training.",
    "categories": [
      "cs.LG",
      "cs.AI",
      "stat.ME",
      "stat.ML"
    ],
    "published": "2025-10-24T03:48:47Z",
    "authors": [
      "Yuxuan Tang",
      "Yifan Feng"
    ],
    "pdf_url": "http://arxiv.org/pdf/2510.23631v1"
  },
  {
    "id": "2510.21127v1",
    "title": "Enhanced Evolutionary Multi-Objective Deep Reinforcement Learning for\n  Reliable and Efficient Wireless Rechargeable Sensor Networks",
    "abstract": "Despite rapid advancements in sensor networks, conventional battery-powered\nsensor networks suffer from limited operational lifespans and frequent\nmaintenance requirements that severely constrain their deployment in remote and\ninaccessible environments. As such, wireless rechargeable sensor networks\n(WRSNs) with mobile charging capabilities offer a promising solution to extend\nnetwork lifetime. However, WRSNs face critical challenges from the inherent\ntrade-off between maximizing the node survival rates and maximizing charging\nenergy efficiency under dynamic operational conditions. In this paper, we\ninvestigate a typical scenario where mobile chargers move and charge the\nsensor, thereby maintaining the network connectivity while minimizing the\nenergy waste. Specifically, we formulate a multi-objective optimization problem\nthat simultaneously maximizes the network node survival rate and mobile charger\nenergy usage efficiency across multiple time slots, which presents NP-hard\ncomputational complexity with long-term temporal dependencies that make\ntraditional optimization approaches ineffective. To address these challenges,\nwe propose an enhanced evolutionary multi-objective deep reinforcement learning\nalgorithm, which integrates a long short-term memory (LSTM)-based policy\nnetwork for temporal pattern recognition, a multilayer perceptron-based\nprospective increment model for future state prediction, and a time-varying\nPareto policy evaluation method for dynamic preference adaptation. Extensive\nsimulation results demonstrate that the proposed algorithm significantly\noutperforms existing approaches in balancing node survival rate and energy\nefficiency while generating diverse Pareto-optimal solutions. Moreover, the\nLSTM-enhanced policy network converges 25% faster than conventional networks,\nwith the time-varying evaluation method effectively adapting to dynamic\nconditions.",
    "categories": [
      "cs.NI",
      "cs.AI"
    ],
    "published": "2025-10-24T03:30:00Z",
    "authors": [
      "Bowei Tong",
      "Hui Kang",
      "Jiahui Li",
      "Geng Sun",
      "Jiacheng Wang",
      "Yaoqi Yang",
      "Bo Xu",
      "Dusit Niyato"
    ],
    "pdf_url": "http://arxiv.org/pdf/2510.21127v1"
  },
  {
    "id": "2510.21891v1",
    "title": "Embedding Trust: Semantic Isotropy Predicts Nonfactuality in Long-Form\n  Text Generation",
    "abstract": "To deploy large language models (LLMs) in high-stakes application domains\nthat require substantively accurate responses to open-ended prompts, we need\nreliable, computationally inexpensive methods that assess the trustworthiness\nof long-form responses generated by LLMs. However, existing approaches often\nrely on claim-by-claim fact-checking, which is computationally expensive and\nbrittle in long-form responses to open-ended prompts. In this work, we\nintroduce semantic isotropy -- the degree of uniformity across normalized text\nembeddings on the unit sphere -- and use it to assess the trustworthiness of\nlong-form responses generated by LLMs. To do so, we generate several long-form\nresponses, embed them, and estimate the level of semantic isotropy of these\nresponses as the angular dispersion of the embeddings on the unit sphere. We\nfind that higher semantic isotropy -- that is, greater embedding dispersion --\nreliably signals lower factual consistency across samples. Our approach\nrequires no labeled data, no fine-tuning, and no hyperparameter selection, and\ncan be used with open- or closed-weight embedding models. Across multiple\ndomains, our method consistently outperforms existing approaches in predicting\nnonfactuality in long-form responses using only a handful of samples --\noffering a practical, low-cost approach for integrating trust assessment into\nreal-world LLM workflows.",
    "categories": [
      "cs.CL",
      "cs.AI",
      "cs.LG",
      "stat.ME",
      "stat.ML"
    ],
    "published": "2025-10-24T03:24:57Z",
    "authors": [
      "Dhrupad Bhardwaj",
      "Julia Kempe",
      "Tim G. J. Rudner"
    ],
    "pdf_url": "http://arxiv.org/pdf/2510.21891v1"
  },
  {
    "id": "2510.21121v1",
    "title": "Generalizable Hierarchical Skill Learning via Object-Centric\n  Representation",
    "abstract": "We present Generalizable Hierarchical Skill Learning (GSL), a novel framework\nfor hierarchical policy learning that significantly improves policy\ngeneralization and sample efficiency in robot manipulation. One core idea of\nGSL is to use object-centric skills as an interface that bridges the high-level\nvision-language model and the low-level visual-motor policy. Specifically, GSL\ndecomposes demonstrations into transferable and object-canonicalized skill\nprimitives using foundation models, ensuring efficient low-level skill learning\nin the object frame. At test time, the skill-object pairs predicted by the\nhigh-level agent are fed to the low-level module, where the inferred canonical\nactions are mapped back to the world frame for execution. This structured yet\nflexible design leads to substantial improvements in sample efficiency and\ngeneralization of our method across unseen spatial arrangements, object\nappearances, and task compositions. In simulation, GSL trained with only 3\ndemonstrations per task outperforms baselines trained with 30 times more data\nby 15.5 percent on unseen tasks. In real-world experiments, GSL also surpasses\nthe baseline trained with 10 times more data.",
    "categories": [
      "cs.RO",
      "cs.AI"
    ],
    "published": "2025-10-24T03:21:42Z",
    "authors": [
      "Haibo Zhao",
      "Yu Qi",
      "Boce Hu",
      "Yizhe Zhu",
      "Ziyan Chen",
      "Heng Tian",
      "Xupeng Zhu",
      "Owen Howell",
      "Haojie Huang",
      "Robin Walters",
      "Dian Wang",
      "Robert Platt"
    ],
    "pdf_url": "http://arxiv.org/pdf/2510.21121v1"
  },
  {
    "id": "2510.21118v2",
    "title": "The Gray Zone of Faithfulness: Taming Ambiguity in Unfaithfulness\n  Detection",
    "abstract": "Ensuring that Large Language Models (LLMs) generate summaries faithful to a\ngiven source document is essential for real-world applications. While prior\nresearch has explored LLM faithfulness, existing benchmarks suffer from\nannotation ambiguity, primarily due to the ill-defined boundary of permissible\nexternal knowledge in generated outputs. For instance, common sense is often\nincorporated into responses and labeled as \"faithful\", yet the acceptable\nextent of such knowledge remains unspecified, leading to inconsistent\nannotations. To address this issue, we propose a novel faithfulness annotation\nframework, which introduces an intermediate category, Out-Dependent, to\nclassify cases where external knowledge is required for verification. Using\nthis framework, we construct VeriGray (Verification with the Gray Zone) -- a\nnew unfaithfulness detection benchmark in summarization. Statistics reveal that\neven SOTA LLMs, such as GPT-5, exhibit hallucinations ($\\sim 6\\%$ of sentences)\nin summarization tasks. Moreover, a substantial proportion ($\\sim 8\\%$ on\naverage of models) of generated sentences fall into the Out-Dependent category,\nunderscoring the importance of resolving annotation ambiguity in unfaithfulness\ndetection benchmarks. Experiments demonstrate that our benchmark poses\nsignificant challenges to multiple baseline methods, indicating considerable\nroom for future improvement.",
    "categories": [
      "cs.CL",
      "cs.AI"
    ],
    "published": "2025-10-24T03:13:51Z",
    "authors": [
      "Qiang Ding",
      "Lvzhou Luo",
      "Yixuan Cao",
      "Ping Luo"
    ],
    "pdf_url": "http://arxiv.org/pdf/2510.21118v2"
  },
  {
    "id": "2510.21117v2",
    "title": "DAO-AI: Evaluating Collective Decision-Making through Agentic AI in\n  Decentralized Governance",
    "abstract": "This paper presents a first empirical study of agentic AI as autonomous\ndecision-makers in decentralized governance. Using more than 3K proposals from\nmajor protocols, we build an agentic AI voter that interprets proposal\ncontexts, retrieves historical deliberation data, and independently determines\nits voting position. The agent operates within a realistic financial simulation\nenvironment grounded in verifiable blockchain data, implemented through a\nmodular composable program (MCP) workflow that defines data flow and tool usage\nvia Agentics framework. We evaluate how closely the agent's decisions align\nwith the human and token-weighted outcomes, uncovering strong alignments\nmeasured by carefully designed evaluation metrics. Our findings demonstrate\nthat agentic AI can augment collective decision-making by producing\ninterpretable, auditable, and empirically grounded signals in realistic DAO\ngovernance settings. The study contributes to the design of explainable and\neconomically rigorous AI agents for decentralized financial systems.",
    "categories": [
      "cs.AI"
    ],
    "published": "2025-10-24T03:13:14Z",
    "authors": [
      "Agostino Capponi",
      "Alfio Gliozzo",
      "Chunghyun Han",
      "Junkyu Lee"
    ],
    "pdf_url": "http://arxiv.org/pdf/2510.21117v2"
  },
  {
    "id": "2510.21112v1",
    "title": "Urban 3D Change Detection Using LiDAR Sensor for HD Map Maintenance and\n  Smart Mobility",
    "abstract": "High-definition 3D city maps underpin smart transportation, digital twins,\nand autonomous driving, where object level change detection across bi temporal\nLiDAR enables HD map maintenance, construction monitoring, and reliable\nlocalization. Classical DSM differencing and image based methods are sensitive\nto small vertical bias, ground slope, and viewpoint mismatch and yield cellwise\noutputs without object identity. Point based neural models and voxel encodings\ndemand large memory, assume near perfect pre alignment, degrade thin\nstructures, and seldom enforce class consistent association, which leaves split\nor merge cases unresolved and ignores uncertainty. We propose an object\ncentric, uncertainty aware pipeline for city scale LiDAR that aligns epochs\nwith multi resolution NDT followed by point to plane ICP, normalizes height,\nand derives a per location level of detection from registration covariance and\nsurface roughness to calibrate decisions and suppress spurious changes.\nGeometry only proxies seed cross epoch associations that are refined by\nsemantic and instance segmentation and a class constrained bipartite assignment\nwith augmented dummies to handle splits and merges while preserving per class\ncounts. Tiled processing bounds memory without eroding narrow ground changes,\nand instance level decisions combine 3D overlap, normal direction displacement,\nand height and volume differences with a histogram distance, all gated by the\nlocal level of detection to remain stable under partial overlap and sampling\nvariation. On 15 representative Subiaco blocks the method attains 95.2%\naccuracy, 90.4% mF1, and 82.6% mIoU, exceeding Triplet KPConv by 0.2 percentage\npoints in accuracy, 0.2 in mF1, and 0.8 in mIoU, with the largest gain on\nDecreased where IoU reaches 74.8% and improves by 7.6 points.",
    "categories": [
      "cs.CV",
      "cs.AI"
    ],
    "published": "2025-10-24T02:59:55Z",
    "authors": [
      "Hezam Albagami",
      "Haitian Wang",
      "Xinyu Wang",
      "Muhammad Ibrahim",
      "Zainy M. Malakan",
      "Abdullah M. Alqamdi",
      "Mohammed H. Alghamdi",
      "Ajmal Mian"
    ],
    "pdf_url": "http://arxiv.org/pdf/2510.21112v1"
  },
  {
    "id": "2510.21110v1",
    "title": "Confounding Robust Deep Reinforcement Learning: A Causal Approach",
    "abstract": "A key task in Artificial Intelligence is learning effective policies for\ncontrolling agents in unknown environments to optimize performance measures.\nOff-policy learning methods, like Q-learning, allow learners to make optimal\ndecisions based on past experiences. This paper studies off-policy learning\nfrom biased data in complex and high-dimensional domains where \\emph{unobserved\nconfounding} cannot be ruled out a priori. Building on the well-celebrated Deep\nQ-Network (DQN), we propose a novel deep reinforcement learning algorithm\nrobust to confounding biases in observed data. Specifically, our algorithm\nattempts to find a safe policy for the worst-case environment compatible with\nthe observations. We apply our method to twelve confounded Atari games, and\nfind that it consistently dominates the standard DQN in all games where the\nobserved input to the behavioral and target policies mismatch and unobserved\nconfounders exist.",
    "categories": [
      "cs.AI"
    ],
    "published": "2025-10-24T02:58:01Z",
    "authors": [
      "Mingxuan Li",
      "Junzhe Zhang",
      "Elias Bareinboim"
    ],
    "pdf_url": "http://arxiv.org/pdf/2510.21110v1"
  },
  {
    "id": "2510.23630v1",
    "title": "NUM2EVENT: Interpretable Event Reasoning from Numerical time-series",
    "abstract": "Large language models (LLMs) have recently demonstrated impressive multimodal\nreasoning capabilities, yet their understanding of purely numerical time-series\nsignals remains limited. Existing approaches mainly focus on forecasting or\ntrend description, without uncovering the latent events that drive numerical\nchanges or explaining the reasoning process behind them. In this work, we\nintroduce the task of number-to-event reasoning and decoding, which aims to\ninfer interpretable structured events from numerical inputs, even when current\ntext is unavailable. To address the data scarcity and semantic alignment\nchallenges, we propose a reasoning-aware framework that integrates an\nagent-guided event extractor (AGE), a marked multivariate Hawkes-based\nsynthetic generator (EveDTS), and a two-stage fine-tuning pipeline combining a\ntime-series encoder with a structured decoder. Our model explicitly reasons\nover numerical changes, generates intermediate explanations, and outputs\nstructured event hypotheses. Experiments on multi-domain datasets show that our\nmethod substantially outperforms strong LLM baselines in event-level precision\nand recall. These results suggest a new direction for bridging quantitative\nreasoning and semantic understanding, enabling LLMs to explain and predict\nevents directly from numerical dynamics.",
    "categories": [
      "cs.LG",
      "cs.AI",
      "cs.CL"
    ],
    "published": "2025-10-24T02:57:11Z",
    "authors": [
      "Ninghui Feng",
      "Yiyan Qi"
    ],
    "pdf_url": "http://arxiv.org/pdf/2510.23630v1"
  },
  {
    "id": "2510.21107v1",
    "title": "ESCORT: Efficient Stein-variational and Sliced Consistency-Optimized\n  Temporal Belief Representation for POMDPs",
    "abstract": "In Partially Observable Markov Decision Processes (POMDPs), maintaining and\nupdating belief distributions over possible underlying states provides a\nprincipled way to summarize action-observation history for effective\ndecision-making under uncertainty. As environments grow more realistic, belief\ndistributions develop complexity that standard mathematical models cannot\naccurately capture, creating a fundamental challenge in maintaining\nrepresentational accuracy. Despite advances in deep learning and probabilistic\nmodeling, existing POMDP belief approximation methods fail to accurately\nrepresent complex uncertainty structures such as high-dimensional, multi-modal\nbelief distributions, resulting in estimation errors that lead to suboptimal\nagent behaviors. To address this challenge, we present ESCORT (Efficient\nStein-variational and sliced Consistency-Optimized Representation for Temporal\nbeliefs), a particle-based framework for capturing complex, multi-modal\ndistributions in high-dimensional belief spaces. ESCORT extends SVGD with two\nkey innovations: correlation-aware projections that model dependencies between\nstate dimensions, and temporal consistency constraints that stabilize updates\nwhile preserving correlation structures. This approach retains SVGD's\nattractive-repulsive particle dynamics while enabling accurate modeling of\nintricate correlation patterns. Unlike particle filters prone to degeneracy or\nparametric methods with fixed representational capacity, ESCORT dynamically\nadapts to belief landscape complexity without resampling or restrictive\ndistributional assumptions. We demonstrate ESCORT's effectiveness through\nextensive evaluations on both POMDP domains and synthetic multi-modal\ndistributions of varying dimensionality, where it consistently outperforms\nstate-of-the-art methods in terms of belief approximation accuracy and\ndownstream decision quality.",
    "categories": [
      "cs.LG",
      "cs.AI",
      "cs.RO"
    ],
    "published": "2025-10-24T02:51:33Z",
    "authors": [
      "Yunuo Zhang",
      "Baiting Luo",
      "Ayan Mukhopadhyay",
      "Gabor Karsai",
      "Abhishek Dubey"
    ],
    "pdf_url": "http://arxiv.org/pdf/2510.21107v1"
  },
  {
    "id": "2510.21890v1",
    "title": "The Principles of Diffusion Models",
    "abstract": "This monograph presents the core principles that have guided the development\nof diffusion models, tracing their origins and showing how diverse formulations\narise from shared mathematical ideas. Diffusion modeling starts by defining a\nforward process that gradually corrupts data into noise, linking the data\ndistribution to a simple prior through a continuum of intermediate\ndistributions. The goal is to learn a reverse process that transforms noise\nback into data while recovering the same intermediates. We describe three\ncomplementary views. The variational view, inspired by variational\nautoencoders, sees diffusion as learning to remove noise step by step. The\nscore-based view, rooted in energy-based modeling, learns the gradient of the\nevolving data distribution, indicating how to nudge samples toward more likely\nregions. The flow-based view, related to normalizing flows, treats generation\nas following a smooth path that moves samples from noise to data under a\nlearned velocity field. These perspectives share a common backbone: a\ntime-dependent velocity field whose flow transports a simple prior to the data.\nSampling then amounts to solving a differential equation that evolves noise\ninto data along a continuous trajectory. On this foundation, the monograph\ndiscusses guidance for controllable generation, efficient numerical solvers,\nand diffusion-motivated flow-map models that learn direct mappings between\narbitrary times. It provides a conceptual and mathematically grounded\nunderstanding of diffusion models for readers with basic deep-learning\nknowledge.",
    "categories": [
      "cs.LG",
      "cs.AI",
      "cs.GR"
    ],
    "published": "2025-10-24T02:29:02Z",
    "authors": [
      "Chieh-Hsin Lai",
      "Yang Song",
      "Dongjun Kim",
      "Yuki Mitsufuji",
      "Stefano Ermon"
    ],
    "pdf_url": "http://arxiv.org/pdf/2510.21890v1"
  },
  {
    "id": "2510.23629v1",
    "title": "Chain of Execution Supervision Promotes General Reasoning in Large\n  Language Models",
    "abstract": "Building robust and general reasoning ability is a central goal in the\ndevelopment of large language models (LLMs). Recent efforts increasingly turn\nto code as a rich training source, given its inherent logical structure and\ndiverse reasoning paradigms such as divide-and-conquer, topological ordering,\nand enumeration. However, reasoning in code is often expressed implicitly and\nentangled with syntactic or implementation noise, making direct training on raw\ncode suboptimal.To address this, we introduce TracePile, a large-scale corpus\nof 2.6 million samples that transforms code execution into explicit,\nstep-by-step chain-of-thought-style rationales, which we call Chain of\nExecution (CoE). The corpus spans domains including mathematics, classical\nalgorithms and algorithmic competition, and is enriched with variable-tracing\nquestions and code rewritings to enhance logical granularity and code\ndiversity. We evaluate TracePile using three training setups:\ncontinue-pretraining, instruction tuning after pretraining, and two-stage\nfinetuning. Experiments across four base models (LLaMA 3, LLaMA 3.1, Qwen-2.5,\nand Qwen-2.5 Coder) and 20 benchmarks covering math, code, logic, and\nalgorithms demonstrate consistent improvements. Notably, TracePile boosts\nLLaMA3.1-8B by 7.1\\% on average across nine math datasets and delivers clear\ngains on LiveCodeBench, CRUX, and MMLU under two-stage fine-tuning.",
    "categories": [
      "cs.LG",
      "cs.AI",
      "cs.PL"
    ],
    "published": "2025-10-24T02:21:11Z",
    "authors": [
      "Nuo Chen",
      "Zehua Li",
      "Keqin Bao",
      "Junyang Lin",
      "Dayiheng Liu"
    ],
    "pdf_url": "http://arxiv.org/pdf/2510.23629v1"
  },
  {
    "id": "2510.21093v1",
    "title": "MedAlign: A Synergistic Framework of Multimodal Preference Optimization\n  and Federated Meta-Cognitive Reasoning",
    "abstract": "Recently, large models have shown significant potential for smart healthcare.\nHowever, the deployment of Large Vision-Language Models (LVLMs) for clinical\nservices is currently hindered by three critical challenges: a tendency to\nhallucinate answers not grounded in visual evidence, the inefficiency of\nfixed-depth reasoning, and the difficulty of multi-institutional collaboration.\nTo address these challenges, in this paper, we develop MedAlign, a novel\nframework to ensure visually accurate LVLM responses for Medical Visual\nQuestion Answering (Med-VQA). Specifically, we first propose a multimodal\nDirect Preference Optimization (mDPO) objective to explicitly align preference\nlearning with visual context. We then design a Retrieval-Aware\nMixture-of-Experts (RA-MoE) architecture that utilizes image and text\nsimilarity to route queries to a specialized and context-augmented LVLM (i.e.,\nan expert), thereby mitigating hallucinations in LVLMs. To achieve adaptive\nreasoning and facilitate multi-institutional collaboration, we propose a\nfederated governance mechanism, where the selected expert, fine-tuned on\nclinical datasets based on mDPO, locally performs iterative Chain-of-Thought\n(CoT) reasoning via the local meta-cognitive uncertainty estimator. Extensive\nexperiments on three representative Med-VQA datasets demonstrate that MedAlign\nachieves state-of-the-art performance, outperforming strong retrieval-augmented\nbaselines by up to $11.85\\%$ in F1-score, and simultaneously reducing the\naverage reasoning length by $51.60\\%$ compared with fixed-depth CoT approaches.",
    "categories": [
      "cs.AI"
    ],
    "published": "2025-10-24T02:11:05Z",
    "authors": [
      "Siyong Chen",
      "Jinbo Wen",
      "Jiawen Kang",
      "Tenghui Huang",
      "Xumin Huang",
      "Yuanjia Su",
      "Hudan Pan",
      "Zishao Zhong",
      "Dusit Niyato",
      "Shengli Xie",
      "Dong In Kim"
    ],
    "pdf_url": "http://arxiv.org/pdf/2510.21093v1"
  },
  {
    "id": "2510.21090v1",
    "title": "Self-Rewarding PPO: Aligning Large Language Models with Demonstrations\n  Only",
    "abstract": "Supervised fine-tuning (SFT) has emerged as a crucial method for aligning\nlarge language models (LLMs) with human-annotated demonstrations. However, SFT,\nbeing an off-policy approach similar to behavior cloning, often struggles with\noverfitting and poor out-of-domain generalization, especially in limited-data\nscenarios. To address these limitations, we propose Self-Rewarding PPO, a novel\nfine-tuning method that leverages on-policy techniques to enhance\ngeneralization performance. Our approach combines the strengths of SFT and\nproximal policy optimization (PPO) to achieve more effective alignment from\ndemonstration data. At its core is a reward function designed as the log policy\nratio between the SFT model and the pretrained base model. This function serves\nas an implicit reward signal, using the pretrained policy as a baseline and the\nSFT policy as a target. By doing so, it enables on-policy fine-tuning without\nrelying on human preference annotations. The integration of this self-rewarding\nmechanism with PPO addresses key limitations of SFT, improving generalization,\ndata efficiency, and robustness. Our empirical evaluation across a range of\nnatural language processing tasks demonstrates that Self-Rewarding PPO\nconsistently outperforms traditional SFT methods. The results highlight the\neffectiveness of our approach in aligning LLMs using demonstration data,\nparticularly in scenarios where high-quality annotated data is scarce.",
    "categories": [
      "cs.CL",
      "cs.AI",
      "cs.LG"
    ],
    "published": "2025-10-24T02:02:13Z",
    "authors": [
      "Qingru Zhang",
      "Liang Qiu",
      "Ilgee Hong",
      "Zhenghao Xu",
      "Tianyi Liu",
      "Shiyang Li",
      "Rongzhi Zhang",
      "Zheng Li",
      "Lihong Li",
      "Bing Yin",
      "Chao Zhang",
      "Jianshu Chen",
      "Haoming Jiang",
      "Tuo Zhao"
    ],
    "pdf_url": "http://arxiv.org/pdf/2510.21090v1"
  },
  {
    "id": "2510.21088v1",
    "title": "M-GLC: Motif-Driven Global-Local Context Graphs for Few-shot Molecular\n  Property Prediction",
    "abstract": "Molecular property prediction (MPP) is a cornerstone of drug discovery and\nmaterials science, yet conventional deep learning approaches depend on large\nlabeled datasets that are often unavailable. Few-shot Molecular property\nprediction (FSMPP) addresses this scarcity by incorporating relational\ninductive bias through a context graph that links molecule nodes to property\nnodes, but such molecule-property graphs offer limited structural guidance. We\npropose a comprehensive solution: Motif Driven Global-Local Context Graph for\nfew-shot molecular property prediction, which enriches contextual information\nat both the global and local levels. At the global level, chemically meaningful\nmotif nodes representing shared substructures, such as rings or functional\ngroups, are introduced to form a global tri-partite heterogeneous graph,\nyielding motif-molecule-property connections that capture long-range\ncompositional patterns and enable knowledge transfer among molecules with\ncommon motifs. At the local level, we build a subgraph for each node in the\nmolecule-property pair and encode them separately to concentrate the model's\nattention on the most informative neighboring molecules and motifs. Experiments\non five standard FSMPP benchmarks demonstrate that our framework consistently\noutperforms state-of-the-art methods. These results underscore the\neffectiveness of integrating global motif knowledge with fine-grained local\ncontext to advance robust few-shot molecular property prediction.",
    "categories": [
      "cs.LG",
      "cs.AI"
    ],
    "published": "2025-10-24T02:00:41Z",
    "authors": [
      "Xiangyang Xu",
      "Hongyang Gao"
    ],
    "pdf_url": "http://arxiv.org/pdf/2510.21088v1"
  },
  {
    "id": "2510.21084v1",
    "title": "CDrugRed: A Chinese Drug Recommendation Dataset for Discharge\n  Medications in Metabolic Diseases",
    "abstract": "Intelligent drug recommendation based on Electronic Health Records (EHRs) is\ncritical for improving for improving the quality and efficiency of clinical\ndecision-making. By leveraging large-scale patient data, drug recommendation\nsystems can assist physicians in selecting the most appropriate medications\naccording to a patient's medical history, diagnoses, laboratory results, and\ncomorbidities. However, the advancement of such systems is significantly\nhampered by the scarcity of publicly available, real-world EHR datasets,\nparticularly in languages other than English. In this work, we present\nCDrugRed, a first publicly available Chinese drug recommendation dataset\nfocused on discharge medications for metabolic diseases. The dataset includes\n5,894 de-identified records from 3,190 patients, containing comprehensive\ninformation such as patient demographics, medical history, clinical course, and\ndischarge diagnoses. We assess the utility of CDrugRed by benchmarking several\nstate-of-the-art large language models (LLMs) on the discharge medication\nrecommendation task. Experimental results show that while supervised\nfine-tuning improves model performance, there remains substantial room for\nimprovement, with the best model achieving the F1 score of 0.5648 and Jaccard\nscore of 0.4477. This result highlights the complexity of the clinical drug\nrecommendation task and establishes CDrugRed as a challenging and valuable\nresource for developing more robust and accurate drug recommendation systems.\nThe dataset is publicly available to the research community under the data\nusage agreements at https://github.com/DUTIR-BioNLP/CDrugRed.",
    "categories": [
      "cs.CL",
      "cs.AI"
    ],
    "published": "2025-10-24T01:47:23Z",
    "authors": [
      "Juntao Li",
      "Haobin Yuan",
      "Ling Luo",
      "Yan Jiang",
      "Fan Wang",
      "Ping Zhang",
      "Huiyi Lv",
      "Jian Wang",
      "Yuanyuan Sun",
      "Hongfei Lin"
    ],
    "pdf_url": "http://arxiv.org/pdf/2510.21084v1"
  },
  {
    "id": "2510.21082v1",
    "title": "Soppia: A Structured Prompting Framework for the Proportional Assessment\n  of Non-Pecuniary Damages in Personal Injury Cases",
    "abstract": "Applying complex legal rules characterized by multiple, heterogeneously\nweighted criteria presents a fundamental challenge in judicial decision-making,\noften hindering the consistent realization of legislative intent. This\nchallenge is particularly evident in the quantification of non-pecuniary\ndamages in personal injury cases. This paper introduces Soppia, a structured\nprompting framework designed to assist legal professionals in navigating this\ncomplexity. By leveraging advanced AI, the system ensures a comprehensive and\nbalanced analysis of all stipulated criteria, fulfilling the legislator's\nintent that compensation be determined through a holistic assessment of each\ncase. Using the twelve criteria for non-pecuniary damages established in the\nBrazilian CLT (Art. 223-G) as a case study, we demonstrate how Soppia (System\nfor Ordered Proportional and Pondered Intelligent Assessment) operationalizes\nnuanced legal commands into a practical, replicable, and transparent\nmethodology. The framework enhances consistency and predictability while\nproviding a versatile and explainable tool adaptable across multi-criteria\nlegal contexts, bridging normative interpretation and computational reasoning\ntoward auditable legal AI.",
    "categories": [
      "cs.CY",
      "cs.AI",
      "cs.HC",
      "68T50 (Artificial intelligence)",
      "I.2.7; K.5.2"
    ],
    "published": "2025-10-24T01:42:38Z",
    "authors": [
      "Jorge Alberto Araujo"
    ],
    "pdf_url": "http://arxiv.org/pdf/2510.21082v1"
  },
  {
    "id": "2510.21888v1",
    "title": "Computational Hardness of Reinforcement Learning with Partial\n  $q^\u03c0$-Realizability",
    "abstract": "This paper investigates the computational complexity of reinforcement\nlearning in a novel linear function approximation regime, termed partial\n$q^{\\pi}$-realizability. In this framework, the objective is to learn an\n$\\epsilon$-optimal policy with respect to a predefined policy set $\\Pi$, under\nthe assumption that all value functions for policies in $\\Pi$ are linearly\nrealizable. The assumptions of this framework are weaker than those in\n$q^{\\pi}$-realizability but stronger than those in $q^*$-realizability,\nproviding a practical model where function approximation naturally arises. We\nprove that learning an $\\epsilon$-optimal policy in this setting is\ncomputationally hard. Specifically, we establish NP-hardness under a\nparameterized greedy policy set (argmax) and show that - unless NP = RP - an\nexponential lower bound (in feature vector dimension) holds when the policy set\ncontains softmax policies, under the Randomized Exponential Time Hypothesis.\nOur hardness results mirror those in $q^*$-realizability and suggest\ncomputational difficulty persists even when $\\Pi$ is expanded beyond the\noptimal policy. To establish this, we reduce from two complexity problems,\n$\\delta$-Max-3SAT and $\\delta$-Max-3SAT(b), to instances of GLinear-$\\kappa$-RL\n(greedy policy) and SLinear-$\\kappa$-RL (softmax policy). Our findings indicate\nthat positive computational results are generally unattainable in partial\n$q^{\\pi}$-realizability, in contrast to $q^{\\pi}$-realizability under a\ngenerative access model.",
    "categories": [
      "cs.AI",
      "cs.CC",
      "cs.LG",
      "68Q17 (Primary) 68T05, 68T42 (Secondary)",
      "F.2.2; I.2.6; I.2.8"
    ],
    "published": "2025-10-24T01:18:49Z",
    "authors": [
      "Shayan Karimi",
      "Xiaoqi Tan"
    ],
    "pdf_url": "http://arxiv.org/pdf/2510.21888v1"
  },
  {
    "id": "2510.21068v1",
    "title": "Bridging Language Gaps with Adaptive RAG: Improving Indonesian Language\n  Question Answering",
    "abstract": "Question Answering (QA) has seen significant improvements with the\nadvancement of machine learning models, further studies enhanced this question\nanswering system by retrieving external information, called Retrieval-Augmented\nGeneration (RAG) to produce more accurate and informative answers. However,\nthese state-of-the-art-performance is predominantly in English language. To\naddress this gap we made an effort of bridging language gaps by incorporating\nAdaptive RAG system to Indonesian language. Adaptive RAG system integrates a\nclassifier whose task is to distinguish the question complexity, which in turn\ndetermines the strategy for answering the question. To overcome the limited\navailability of Indonesian language dataset, our study employs machine\ntranslation as data augmentation approach. Experiments show reliable question\ncomplexity classifier; however, we observed significant inconsistencies in\nmulti-retrieval answering strategy which negatively impacted the overall\nevaluation when this strategy was applied. These findings highlight both the\npromise and challenges of question answering in low-resource language\nsuggesting directions for future improvement.",
    "categories": [
      "cs.CL",
      "cs.AI"
    ],
    "published": "2025-10-24T00:50:20Z",
    "authors": [
      "William Christian",
      "Daniel Adamlu",
      "Adrian Yu",
      "Derwin Suhartono"
    ],
    "pdf_url": "http://arxiv.org/pdf/2510.21068v1"
  },
  {
    "id": "2510.21063v1",
    "title": "Deep learning-based automated damage detection in concrete structures\n  using images from earthquake events",
    "abstract": "Timely assessment of integrity of structures after seismic events is crucial\nfor public safety and emergency response. This study focuses on assessing the\nstructural damage conditions using deep learning methods to detect exposed\nsteel reinforcement in concrete buildings and bridges after large earthquakes.\nSteel bars are typically exposed after concrete spalling or large flexural or\nshear cracks. The amount and distribution of exposed steel reinforcement is an\nindication of structural damage and degradation. To automatically detect\nexposed steel bars, new datasets of images collected after the 2023 Turkey\nEarthquakes were labeled to represent a wide variety of damaged concrete\nstructures. The proposed method builds upon a deep learning framework, enhanced\nwith fine-tuning, data augmentation, and testing on public datasets. An\nautomated classification framework is developed that can be used to identify\ninside/outside buildings and structural components. Then, a YOLOv11 (You Only\nLook Once) model is trained to detect cracking and spalling damage and exposed\nbars. Another YOLO model is finetuned to distinguish different categories of\nstructural damage levels. All these trained models are used to create a hybrid\nframework to automatically and reliably determine the damage levels from input\nimages. This research demonstrates that rapid and automated damage detection\nfollowing disasters is achievable across diverse damage contexts by utilizing\nimage data collection, annotation, and deep learning approaches.",
    "categories": [
      "cs.CV",
      "cs.AI"
    ],
    "published": "2025-10-24T00:35:14Z",
    "authors": [
      "Abdullah Turer",
      "Yongsheng Bai",
      "Halil Sezen",
      "Alper Yilmaz"
    ],
    "pdf_url": "http://arxiv.org/pdf/2510.21063v1"
  },
  {
    "id": "2510.21060v1",
    "title": "On the Sample Complexity of Differentially Private Policy Optimization",
    "abstract": "Policy optimization (PO) is a cornerstone of modern reinforcement learning\n(RL), with diverse applications spanning robotics, healthcare, and large\nlanguage model training. The increasing deployment of PO in sensitive domains,\nhowever, raises significant privacy concerns. In this paper, we initiate a\ntheoretical study of differentially private policy optimization, focusing\nexplicitly on its sample complexity. We first formalize an appropriate\ndefinition of differential privacy (DP) tailored to PO, addressing the inherent\nchallenges arising from on-policy learning dynamics and the subtlety involved\nin defining the unit of privacy. We then systematically analyze the sample\ncomplexity of widely-used PO algorithms, including policy gradient (PG),\nnatural policy gradient (NPG) and more, under DP constraints and various\nsettings, via a unified framework. Our theoretical results demonstrate that\nprivacy costs can often manifest as lower-order terms in the sample complexity,\nwhile also highlighting subtle yet important observations in private PO\nsettings. These offer valuable practical insights for privacy-preserving PO\nalgorithms.",
    "categories": [
      "cs.LG",
      "cs.AI"
    ],
    "published": "2025-10-24T00:21:38Z",
    "authors": [
      "Yi He",
      "Xingyu Zhou"
    ],
    "pdf_url": "http://arxiv.org/pdf/2510.21060v1"
  },
  {
    "id": "2510.21049v1",
    "title": "Reasoning's Razor: Reasoning Improves Accuracy but Can Hurt Recall at\n  Critical Operating Points in Safety and Hallucination Detection",
    "abstract": "Reasoning has become a central paradigm for large language models (LLMs),\nconsistently boosting accuracy across diverse benchmarks. Yet its suitability\nfor precision-sensitive tasks remains unclear. We present the first systematic\nstudy of reasoning for classification tasks under strict low false positive\nrate (FPR) regimes. Our analysis covers two tasks--safety detection and\nhallucination detection--evaluated in both fine-tuned and zero-shot settings,\nusing standard LLMs and Large Reasoning Models (LRMs). Our results reveal a\nclear trade-off: Think On (reasoning-augmented) generation improves overall\naccuracy, but underperforms at the low-FPR thresholds essential for practical\nuse. In contrast, Think Off (no reasoning during inference) dominates in these\nprecision-sensitive regimes, with Think On surpassing only when higher FPRs are\nacceptable. In addition, we find token-based scoring substantially outperforms\nself-verbalized confidence for precision-sensitive deployments. Finally, a\nsimple ensemble of the two modes recovers the strengths of each. Taken\ntogether, our findings position reasoning as a double-edged tool: beneficial\nfor average accuracy, but often ill-suited for applications requiring strict\nprecision.",
    "categories": [
      "cs.CL",
      "cs.AI",
      "cs.LG"
    ],
    "published": "2025-10-23T23:23:36Z",
    "authors": [
      "Atoosa Chegini",
      "Hamid Kazemi",
      "Garrett Souza",
      "Maria Safi",
      "Yang Song",
      "Samy Bengio",
      "Sinead Williamson",
      "Mehrdad Farajtabar"
    ],
    "pdf_url": "http://arxiv.org/pdf/2510.21049v1"
  },
  {
    "id": "2510.21045v1",
    "title": "From Questions to Queries: An AI-powered Multi-Agent Framework for\n  Spatial Text-to-SQL",
    "abstract": "The complexity of Structured Query Language (SQL) and the specialized nature\nof geospatial functions in tools like PostGIS present significant barriers to\nnon-experts seeking to analyze spatial data. While Large Language Models (LLMs)\noffer promise for translating natural language into SQL (Text-to-SQL),\nsingle-agent approaches often struggle with the semantic and syntactic\ncomplexities of spatial queries. To address this, we propose a multi-agent\nframework designed to accurately translate natural language questions into\nspatial SQL queries. The framework integrates several innovative components,\nincluding a knowledge base with programmatic schema profiling and semantic\nenrichment, embeddings for context retrieval, and a collaborative multi-agent\npipeline as its core. This pipeline comprises specialized agents for entity\nextraction, metadata retrieval, query logic formulation, SQL generation, and a\nreview agent that performs programmatic and semantic validation of the\ngenerated SQL to ensure correctness (self-verification). We evaluate our system\nusing both the non-spatial KaggleDBQA benchmark and a new, comprehensive\nSpatialQueryQA benchmark that includes diverse geometry types, predicates, and\nthree levels of query complexity. On KaggleDBQA, the system achieved an overall\naccuracy of 81.2% (221 out of 272 questions) after the review agent's review\nand corrections. For spatial queries, the system achieved an overall accuracy\nof 87.7% (79 out of 90 questions), compared with 76.7% without the review\nagent. Beyond accuracy, results also show that in some instances the system\ngenerates queries that are more semantically aligned with user intent than\nthose in the benchmarks. This work makes spatial analysis more accessible, and\nprovides a robust, generalizable foundation for spatial Text-to-SQL systems,\nadvancing the development of autonomous GIS.",
    "categories": [
      "cs.AI",
      "cs.DB",
      "cs.IR"
    ],
    "published": "2025-10-23T22:58:17Z",
    "authors": [
      "Ali Khosravi Kazazi",
      "Zhenlong Li",
      "M. Naser Lessani",
      "Guido Cervone"
    ],
    "pdf_url": "http://arxiv.org/pdf/2510.21045v1"
  },
  {
    "id": "2510.21043v1",
    "title": "Epistemic Deference to AI",
    "abstract": "When should we defer to AI outputs over human expert judgment? Drawing on\nrecent work in social epistemology, I motivate the idea that some AI systems\nqualify as Artificial Epistemic Authorities (AEAs) due to their demonstrated\nreliability and epistemic superiority. I then introduce AI Preemptionism, the\nview that AEA outputs should replace rather than supplement a user's\nindependent epistemic reasons. I show that classic objections to preemptionism\n- such as uncritical deference, epistemic entrenchment, and unhinging epistemic\nbases - apply in amplified form to AEAs, given their opacity, self-reinforcing\nauthority, and lack of epistemic failure markers. Against this, I develop a\nmore promising alternative: a total evidence view of AI deference. According to\nthis view, AEA outputs should function as contributory reasons rather than\noutright replacements for a user's independent epistemic considerations. This\napproach has three key advantages: (i) it mitigates expertise atrophy by\nkeeping human users engaged, (ii) it provides an epistemic case for meaningful\nhuman oversight and control, and (iii) it explains the justified mistrust of AI\nwhen reliability conditions are unmet. While demanding in practice, this\naccount offers a principled way to determine when AI deference is justified,\nparticularly in high-stakes contexts requiring rigorous reliability.",
    "categories": [
      "cs.AI",
      "cs.CY"
    ],
    "published": "2025-10-23T22:55:51Z",
    "authors": [
      "Benjamin Lange"
    ],
    "pdf_url": "http://arxiv.org/pdf/2510.21043v1"
  },
  {
    "id": "2510.21031v1",
    "title": "AgentArcEval: An Architecture Evaluation Method for Foundation Model\n  based Agents",
    "abstract": "The emergence of foundation models (FMs) has enabled the development of\nhighly capable and autonomous agents, unlocking new application opportunities\nacross a wide range of domains. Evaluating the architecture of agents is\nparticularly important as the architectural decisions significantly impact the\nquality attributes of agents given their unique characteristics, including\ncompound architecture, autonomous and non-deterministic behaviour, and\ncontinuous evolution. However, these traditional methods fall short in\naddressing the evaluation needs of agent architecture due to the unique\ncharacteristics of these agents. Therefore, in this paper, we present\nAgentArcEval, a novel agent architecture evaluation method designed specially\nto address the complexities of FM-based agent architecture and its evaluation.\nMoreover, we present a catalogue of agent-specific general scenarios, which\nserves as a guide for generating concrete scenarios to design and evaluate the\nagent architecture. We demonstrate the usefulness of AgentArcEval and the\ncatalogue through a case study on the architecture evaluation of a real-world\ntax copilot, named Luna.",
    "categories": [
      "cs.SE",
      "cs.AI"
    ],
    "published": "2025-10-23T22:32:03Z",
    "authors": [
      "Qinghua Lu",
      "Dehai Zhao",
      "Yue Liu",
      "Hao Zhang",
      "Liming Zhu",
      "Xiwei Xu",
      "Angela Shi",
      "Tristan Tan",
      "Rick Kazman"
    ],
    "pdf_url": "http://arxiv.org/pdf/2510.21031v1"
  },
  {
    "id": "2510.21027v1",
    "title": "Customizing Open Source LLMs for Quantitative Medication Attribute\n  Extraction across Heterogeneous EHR Systems",
    "abstract": "Harmonizing medication data across Electronic Health Record (EHR) systems is\na persistent barrier to monitoring medications for opioid use disorder (MOUD).\nIn heterogeneous EHR systems, key prescription attributes are scattered across\ndifferently formatted fields and freetext notes. We present a practical\nframework that customizes open source large language models (LLMs), including\nLlama, Qwen, Gemma, and MedGemma, to extract a unified set of MOUD prescription\nattributes (prescription date, drug name, duration, total quantity, daily\nquantity, and refills) from heterogeneous, site specific data and compute a\nstandardized metric of medication coverage, \\emph{MOUD days}, per patient. Our\npipeline processes records directly in a fixed JSON schema, followed by\nlightweight normalization and cross-field consistency checks. We evaluate the\nsystem on prescription level EHR data from five clinics in a national OUD study\n(25{,}605 records from 1{,}257 patients), using a previously annotated\nbenchmark of 10{,}369 records (776 patients) as the ground truth. Performance\nis reported as coverage (share of records with a valid, matchable output) and\nrecord-level exact-match accuracy. Larger models perform best overall:\nQwen2.5-32B achieves \\textbf{93.4\\%} coverage with \\textbf{93.0\\%} exact-match\naccuracy across clinics, and MedGemma-27B attains\n\\textbf{93.1\\%}/\\textbf{92.2\\%}. A brief error review highlights three common\nissues and fixes: imputing missing dosage fields using within-drug norms,\nhandling monthly/weekly injectables (e.g., Vivitrol) by setting duration from\nthe documented schedule, and adding unit checks to prevent mass units (e.g.,\n``250 g'') from being misread as daily counts. By removing brittle,\nsite-specific ETL and supporting local, privacy-preserving deployment, this\napproach enables consistent cross-site analyses of MOUD exposure, adherence,\nand retention in real-world settings.",
    "categories": [
      "cs.AI",
      "cs.LG"
    ],
    "published": "2025-10-23T22:27:10Z",
    "authors": [
      "Zhe Fei",
      "Mehmet Yigit Turali",
      "Shreyas Rajesh",
      "Xinyang Dai",
      "Huyen Pham",
      "Pavan Holur",
      "Yuhui Zhu",
      "Larissa Mooney",
      "Yih-Ing Hser",
      "Vwani Roychowdhury"
    ],
    "pdf_url": "http://arxiv.org/pdf/2510.21027v1"
  },
  {
    "id": "2510.23627v1",
    "title": "AI-Driven Development of a Publishing Imprint: Xynapse Traces",
    "abstract": "Xynapse Traces is an experimental publishing imprint created via a fusion of\nhuman and algorithmic methods using a configuration-driven architecture and a\nmulti-model AI integration framework. The system achieved a remarkable 90%\nreduction in time-to-market (from a typical 6-12 months to just 2-4 weeks),\nwith 80% cost reduction compared to traditional imprint development, while\npublishing 52 books in its first year and maintaining exceptional quality\nmetrics, including 99% citation accuracy and 100% validation success after\ninitial corrections. Key technical innovations include a continuous ideation\npipeline with tournament-style evaluation, a novel codex design for\ntranscriptive meditation practice, comprehensive automation spanning from\nideation through production and distribution, and publisher personas that\ndefine and guide the imprint's mission. The system also integrates automated\nverification with human oversight, ensuring that gains in speed do not\ncompromise publishing standards. This effort has significant implications for\nthe future of book publishing, suggesting new paradigms for human-AI\ncollaboration that democratize access to sophisticated publishing capabilities\nand make previously unviable niche markets accessible.",
    "categories": [
      "cs.SE",
      "cs.AI"
    ],
    "published": "2025-10-23T22:25:13Z",
    "authors": [
      "Fred Zimmerman"
    ],
    "pdf_url": "http://arxiv.org/pdf/2510.23627v1"
  },
  {
    "id": "2510.21024v1",
    "title": "JSTprove: Pioneering Verifiable AI for a Trustless Future",
    "abstract": "The integration of machine learning (ML) systems into critical industries\nsuch as healthcare, finance, and cybersecurity has transformed decision-making\nprocesses, but it also brings new challenges around trust, security, and\naccountability. As AI systems become more ubiquitous, ensuring the transparency\nand correctness of AI-driven decisions is crucial, especially when they have\ndirect consequences on privacy, security, or fairness. Verifiable AI, powered\nby Zero-Knowledge Machine Learning (zkML), offers a robust solution to these\nchallenges. zkML enables the verification of AI model inferences without\nexposing sensitive data, providing an essential layer of trust and privacy.\nHowever, traditional zkML systems typically require deep cryptographic\nexpertise, placing them beyond the reach of most ML engineers. In this paper,\nwe introduce JSTprove, a specialized zkML toolkit, built on Polyhedra Network's\nExpander backend, to enable AI developers and ML engineers to generate and\nverify proofs of AI inference. JSTprove provides an end-to-end verifiable AI\ninference pipeline that hides cryptographic complexity behind a simple\ncommand-line interface while exposing auditable artifacts for reproducibility.\nWe present the design, innovations, and real-world use cases of JSTprove as\nwell as our blueprints and tooling to encourage community review and extension.\nJSTprove therefore serves both as a usable zkML product for current engineering\nneeds and as a reproducible foundation for future research and production\ndeployments of verifiable AI.",
    "categories": [
      "cs.CR",
      "cs.AI",
      "cs.DC",
      "cs.LG"
    ],
    "published": "2025-10-23T22:22:38Z",
    "authors": [
      "Jonathan Gold",
      "Tristan Freiberg",
      "Haruna Isah",
      "Shirin Shahabi"
    ],
    "pdf_url": "http://arxiv.org/pdf/2510.21024v1"
  },
  {
    "id": "2510.21023v1",
    "title": "Physically consistent and uncertainty-aware learning of spatiotemporal\n  dynamics",
    "abstract": "Accurate long-term forecasting of spatiotemporal dynamics remains a\nfundamental challenge across scientific and engineering domains. Existing\nmachine learning methods often neglect governing physical laws and fail to\nquantify inherent uncertainties in spatiotemporal predictions. To address these\nchallenges, we introduce a physics-consistent neural operator (PCNO) that\nenforces physical constraints by projecting surrogate model outputs onto\nfunction spaces satisfying predefined laws. A physics-consistent projection\nlayer within PCNO efficiently computes mass and momentum conservation in\nFourier space. Building upon deterministic predictions, we further propose a\ndiffusion model-enhanced PCNO (DiffPCNO), which leverages a consistency model\nto quantify and mitigate uncertainties, thereby improving the accuracy and\nreliability of forecasts. PCNO and DiffPCNO achieve high-fidelity\nspatiotemporal predictions while preserving physical consistency and\nuncertainty across diverse systems and spatial resolutions, ranging from\nturbulent flow modeling to real-world flood/atmospheric forecasting. Our\ntwo-stage framework provides a robust and versatile approach for accurate,\nphysically grounded, and uncertainty-aware spatiotemporal forecasting.",
    "categories": [
      "cs.LG",
      "cs.AI",
      "physics.comp-ph"
    ],
    "published": "2025-10-23T22:17:21Z",
    "authors": [
      "Qingsong Xu",
      "Jonathan L Bamber",
      "Nils Thuerey",
      "Niklas Boers",
      "Paul Bates",
      "Gustau Camps-Valls",
      "Yilei Shi",
      "Xiao Xiang Zhu"
    ],
    "pdf_url": "http://arxiv.org/pdf/2510.21023v1"
  },
  {
    "id": "2510.21011v1",
    "title": "Race and Gender in LLM-Generated Personas: A Large-Scale Audit of 41\n  Occupations",
    "abstract": "Generative AI tools are increasingly used to create portrayals of people in\noccupations, raising concerns about how race and gender are represented. We\nconducted a large-scale audit of over 1.5 million occupational personas across\n41 U.S. occupations, generated by four large language models with different AI\nsafety commitments and countries of origin (U.S., China, France). Compared with\nBureau of Labor Statistics data, we find two recurring patterns: systematic\nshifts, where some groups are consistently under- or overrepresented, and\nstereotype exaggeration, where existing demographic skews are amplified. On\naverage, White (--31pp) and Black (--9pp) workers are underrepresented, while\nHispanic (+17pp) and Asian (+12pp) workers are overrepresented. These\ndistortions can be extreme: for example, across all four models, Housekeepers\nare portrayed as nearly 100\\% Hispanic, while Black workers are erased from\nmany occupations. For HCI, these findings show provider choice materially\nchanges who is visible, motivating model-specific audits and accountable design\npractices.",
    "categories": [
      "cs.HC",
      "cs.AI",
      "cs.CY"
    ],
    "published": "2025-10-23T21:43:08Z",
    "authors": [
      "Ilona van der Linden",
      "Sahana Kumar",
      "Arnav Dixit",
      "Aadi Sudan",
      "Smruthi Danda",
      "David C. Anastasiu",
      "Kai Lukoff"
    ],
    "pdf_url": "http://arxiv.org/pdf/2510.21011v1"
  },
  {
    "id": "2510.21887v1",
    "title": "Generative AI in Depth: A Survey of Recent Advances, Model Variants, and\n  Real-World Applications",
    "abstract": "In recent years, deep learning based generative models, particularly\nGenerative Adversarial Networks (GANs), Variational Autoencoders (VAEs), and\nDiffusion Models (DMs), have been instrumental in in generating diverse,\nhigh-quality content across various domains, such as image and video synthesis.\nThis capability has led to widespread adoption of these models and has captured\nstrong public interest. As they continue to advance at a rapid pace, the\ngrowing volume of research, expanding application areas, and unresolved\ntechnical challenges make it increasingly difficult to stay current. To address\nthis need, this survey introduces a comprehensive taxonomy that organizes the\nliterature and provides a cohesive framework for understanding the development\nof GANs, VAEs, and DMs, including their many variants and combined approaches.\nWe highlight key innovations that have improved the quality, diversity, and\ncontrollability of generated outputs, reflecting the expanding potential of\ngenerative artificial intelligence. In addition to summarizing technical\nprogress, we examine rising ethical concerns, including the risks of misuse and\nthe broader societal impact of synthetic media. Finally, we outline persistent\nchallenges and propose future research directions, offering a structured and\nforward looking perspective for researchers in this fast evolving field.",
    "categories": [
      "cs.CV",
      "cs.AI",
      "cs.LG"
    ],
    "published": "2025-10-23T21:11:12Z",
    "authors": [
      "Shamim Yazdani",
      "Akansha Singh",
      "Nripsuta Saxena",
      "Zichong Wang",
      "Avash Palikhe",
      "Deng Pan",
      "Umapada Pal",
      "Jie Yang",
      "Wenbin Zhang"
    ],
    "pdf_url": "http://arxiv.org/pdf/2510.21887v1"
  },
  {
    "id": "2510.20997v1",
    "title": "Exploring Spiking Neural Networks for Binary Classification in\n  Multivariate Time Series at the Edge",
    "abstract": "We present a general framework for training spiking neural networks (SNNs) to\nperform binary classification on multivariate time series, with a focus on\nstep-wise prediction and high precision at low false alarm rates. The approach\nuses the Evolutionary Optimization of Neuromorphic Systems (EONS) algorithm to\nevolve sparse, stateful SNNs by jointly optimizing their architectures and\nparameters. Inputs are encoded into spike trains, and predictions are made by\nthresholding a single output neuron's spike counts. We also incorporate simple\nvoting ensemble methods to improve performance and robustness.\n  To evaluate the framework, we apply it with application-specific\noptimizations to the task of detecting low signal-to-noise ratio radioactive\nsources in gamma-ray spectral data. The resulting SNNs, with as few as 49\nneurons and 66 synapses, achieve a 51.8% true positive rate (TPR) at a false\nalarm rate of 1/hr, outperforming PCA (42.7%) and deep learning (49.8%)\nbaselines. A three-model any-vote ensemble increases TPR to 67.1% at the same\nfalse alarm rate. Hardware deployment on the microCaspian neuromorphic platform\ndemonstrates 2mW power consumption and 20.2ms inference latency.\n  We also demonstrate generalizability by applying the same framework, without\ndomain-specific modification, to seizure detection in EEG recordings. An\nensemble achieves 95% TPR with a 16% false positive rate, comparable to recent\ndeep learning approaches with significant reduction in parameter count.",
    "categories": [
      "cs.LG",
      "cs.AI"
    ],
    "published": "2025-10-23T20:52:11Z",
    "authors": [
      "James Ghawaly",
      "Andrew Nicholson",
      "Catherine Schuman",
      "Dalton Diez",
      "Aaron Young",
      "Brett Witherspoon"
    ],
    "pdf_url": "http://arxiv.org/pdf/2510.20997v1"
  },
  {
    "id": "2510.20994v1",
    "title": "VESSA: Video-based objEct-centric Self-Supervised Adaptation for Visual\n  Foundation Models",
    "abstract": "Foundation models have advanced computer vision by enabling strong\nperformance across diverse tasks through large-scale pretraining and supervised\nfine-tuning. However, they may underperform in domains with distribution shifts\nand scarce labels, where supervised fine-tuning may be infeasible. While\ncontinued self-supervised learning for model adaptation is common for\ngenerative language models, this strategy has not proven effective for\nvision-centric encoder models. To address this challenge, we introduce a novel\nformulation of self-supervised fine-tuning for vision foundation models, where\nthe model is adapted to a new domain without requiring annotations, leveraging\nonly short multi-view object-centric videos. Our method is referred to as\nVESSA: Video-based objEct-centric Self-Supervised Adaptation for visual\nfoundation models. VESSA's training technique is based on a self-distillation\nparadigm, where it is critical to carefully tune prediction heads and deploy\nparameter-efficient adaptation techniques - otherwise, the model may quickly\nforget its pretrained knowledge and reach a degraded state. VESSA benefits\nsignificantly from multi-view object observations sourced from different frames\nin an object-centric video, efficiently learning robustness to varied capture\nconditions, without the need of annotations. Through comprehensive experiments\nwith 3 vision foundation models on 2 datasets, VESSA demonstrates consistent\nimprovements in downstream classification tasks, compared to the base models\nand previous adaptation methods. Code is publicly available at\nhttps://github.com/jesimonbarreto/VESSA.",
    "categories": [
      "cs.CV",
      "cs.AI",
      "cs.LG"
    ],
    "published": "2025-10-23T20:44:28Z",
    "authors": [
      "Jesimon Barreto",
      "Carlos Caetano",
      "Andr\u00e9 Araujo",
      "William Robson Schwartz"
    ],
    "pdf_url": "http://arxiv.org/pdf/2510.20994v1"
  },
  {
    "id": "2510.21886v1",
    "title": "Exploration through Generation: Applying GFlowNets to Structured Search",
    "abstract": "This work applies Generative Flow Networks (GFlowNets) to three graph\noptimization problems: the Traveling Salesperson Problem, Minimum Spanning\nTree, and Shortest Path. GFlowNets are generative models that learn to sample\nsolutions proportionally to a reward function. The models are trained using the\nTrajectory Balance loss to build solutions sequentially, selecting edges for\nspanning trees, nodes for paths, and cities for tours. Experiments on benchmark\ninstances of varying sizes show that GFlowNets learn to find optimal solutions.\nFor each problem type, multiple graph configurations with different numbers of\nnodes were tested. The generated solutions match those from classical\nalgorithms (Dijkstra for shortest path, Kruskal for spanning trees, and exact\nsolvers for TSP). Training convergence depends on problem complexity, with the\nnumber of episodes required for loss stabilization increasing as graph size\ngrows. Once training converges, the generated solutions match known optima from\nclassical algorithms across the tested instances. This work demonstrates that\ngenerative models can solve combinatorial optimization problems through learned\npolicies. The main advantage of this learning-based approach is computational\nscalability: while classical algorithms have fixed complexity per instance,\nGFlowNets amortize computation through training. With sufficient computational\nresources, the framework could potentially scale to larger problem instances\nwhere classical exact methods become infeasible.",
    "categories": [
      "cs.AI"
    ],
    "published": "2025-10-23T20:43:09Z",
    "authors": [
      "Mark Phillip Matovic"
    ],
    "pdf_url": "http://arxiv.org/pdf/2510.21886v1"
  },
  {
    "id": "2510.21885v1",
    "title": "Preventing Catastrophic Forgetting: Behavior-Aware Sampling for Safer\n  Language Model Fine-Tuning",
    "abstract": "Large language models often lose previously aligned safety behaviors when\nfine-tuned on benign data, a phenomenon known as catastrophic forgetting. Prior\nwork shows that adding random safety examples can mitigate this effect, but it\nremains unclear which examples are most effective. We propose a behavior-aware\nsampling framework that selects safety examples based on two complementary\nfactors: instruction-response behavior (e.g., refusal versus compliance) and\nsemantic diversity across harm categories. Systematic evaluation shows that\nthis approach substantially reduces harmful outputs while maintaining\nhelpfulness, achieving up to a 41% reduction in harmfulness with only 0.5%\nadditional training data. These results highlight how targeted data selection\ncan improve the safety and efficiency of fine-tuning at scale.",
    "categories": [
      "cs.CL",
      "cs.AI"
    ],
    "published": "2025-10-23T20:34:52Z",
    "authors": [
      "Anh Pham",
      "Mihir Thalanki",
      "Michael Sun",
      "Aditya Chaloo",
      "Ankita Gupta",
      "Tian Xia",
      "Aditya Mate",
      "Ehimwenma Nosakhare",
      "Soundararajan Srinivasan"
    ],
    "pdf_url": "http://arxiv.org/pdf/2510.21885v1"
  },
  {
    "id": "2510.23626v1",
    "title": "From Detection to Discovery: A Closed-Loop Approach for Simultaneous and\n  Continuous Medical Knowledge Expansion and Depression Detection on Social\n  Media",
    "abstract": "Social media user-generated content (UGC) provides real-time, self-reported\nindicators of mental health conditions such as depression, offering a valuable\nsource for predictive analytics. While prior studies integrate medical\nknowledge to improve prediction accuracy, they overlook the opportunity to\nsimultaneously expand such knowledge through predictive processes. We develop a\nClosed-Loop Large Language Model (LLM)-Knowledge Graph framework that\nintegrates prediction and knowledge expansion in an iterative learning cycle.\nIn the knowledge-aware depression detection phase, the LLM jointly performs\ndepression detection and entity extraction, while the knowledge graph\nrepresents and weights these entities to refine prediction performance. In the\nknowledge refinement and expansion phase, new entities, relationships, and\nentity types extracted by the LLM are incorporated into the knowledge graph\nunder expert supervision, enabling continual knowledge evolution. Using\nlarge-scale UGC, the framework enhances both predictive accuracy and medical\nunderstanding. Expert evaluations confirmed the discovery of clinically\nmeaningful symptoms, comorbidities, and social triggers complementary to\nexisting literature. We conceptualize and operationalize\nprediction-through-learning and learning-through-prediction as mutually\nreinforcing processes, advancing both methodological and theoretical\nunderstanding in predictive analytics. The framework demonstrates the\nco-evolution of computational models and domain knowledge, offering a\nfoundation for adaptive, data-driven knowledge systems applicable to other\ndynamic risk monitoring contexts.",
    "categories": [
      "cs.LG",
      "cs.AI",
      "cs.CL"
    ],
    "published": "2025-10-23T20:34:36Z",
    "authors": [
      "Shuang Geng",
      "Wenli Zhang",
      "Jiaheng Xie",
      "Rui Wang",
      "Sudha Ram"
    ],
    "pdf_url": "http://arxiv.org/pdf/2510.23626v1"
  },
  {
    "id": "2510.21884v1",
    "title": "Framework for Machine Evaluation of Reasoning Completeness in Large\n  Language Models For Classification Tasks",
    "abstract": "The growing adoption of machine learning (ML) in sensitive domains has\nheightened the demand for transparent and interpretable artificial\nintelligence. Large Language Models (LLMs) are increasingly capable of\nproducing natural language explanations, yet it remains unclear whether these\nrationales faithfully capture the predictive signals that underlie decisions.\nThis paper introduces RACE-Reasoning Alignment for Completeness of\nExplanations, a systematic framework to evaluate the alignment between\nLLM-generated explanations and interpretable feature importance scores derived\nfrom a logistic regression baseline. We analyze four widely used text\nclassification datasets-WIKI ONTOLOGY, AG NEWS, IMDB, and GOEMOTIONS-and\ncompare LLM rationales against top-ranked supporting and contradicting lexical\nfeatures. To capture alignment at multiple levels of granularity, RACE\nimplements token-aware, exact string, and edit-distance matching techniques.\nEmpirical results reveal a consistent asymmetry: correct predictions exhibit\nhigher coverage of supporting features, while incorrect predictions are\nassociated with elevated coverage of contradicting features. Edit-distance\nmatching further uncovers paraphrastic overlaps, boosting coverage while\npreserving this asymmetry. These findings demonstrate that LLM rationales\ncombine both surface-level and flexible evidence reuse, yet can also amplify\nmisleading cues in error cases. RACE provides new insights into the\nfaithfulness of LLM explanations and establishes a quantitative basis for\nevaluating reasoning completeness in neural language models.",
    "categories": [
      "cs.CL",
      "cs.AI"
    ],
    "published": "2025-10-23T20:22:22Z",
    "authors": [
      "Avinash Patil"
    ],
    "pdf_url": "http://arxiv.org/pdf/2510.21884v1"
  },
  {
    "id": "2510.20985v1",
    "title": "GPU Memory Requirement Prediction for Deep Learning Task Based on\n  Bidirectional Gated Recurrent Unit Optimization Transformer",
    "abstract": "In response to the increasingly critical demand for accurate prediction of\nGPU memory resources in deep learning tasks, this paper deeply analyzes the\ncurrent research status and innovatively proposes a deep learning model that\nintegrates bidirectional gated recurrent units (BiGRU) to optimize the\nTransformer architecture, aiming to improve the accuracy of memory demand\nprediction. To verify the effectiveness of the model, a carefully designed\ncomparative experiment was conducted, selecting four representative basic\nmachine learning models: decision tree, random forest, Adaboost, and XGBoost as\nbenchmarks. The detailed experimental results show that the BiGRU Transformer\noptimization model proposed in this paper exhibits significant advantages in\nkey evaluation indicators: in terms of mean square error (MSE) and root mean\nsquare error (RMSE), the model achieves the lowest value among all comparison\nmodels, and its predicted results have the smallest deviation from the actual\nvalues; In terms of mean absolute error (MAE) and coefficient of determination\n(R2) indicators, the model also performs well and the results are balanced and\nstable, with comprehensive predictive performance far exceeding the benchmark\nmachine learning methods compared. In summary, the Transformer model based on\nbidirectional gated recurrent unit optimization successfully constructed in\nthis study can efficiently and accurately complete GPU memory demand prediction\ntasks in deep learning tasks, and its prediction accuracy has been\nsignificantly improved compared to traditional machine learning methods. This\nresearch provides strong technical support and reliable theoretical basis for\noptimizing resource scheduling and management of deep learning tasks, and\nimproving the utilization efficiency of computing clusters.",
    "categories": [
      "cs.LG",
      "cs.AI"
    ],
    "published": "2025-10-23T20:20:35Z",
    "authors": [
      "Chao Wang",
      "Zhizhao Wen",
      "Ruoxin Zhang",
      "Puyang Xu",
      "Yifan Jiang"
    ],
    "pdf_url": "http://arxiv.org/pdf/2510.20985v1"
  },
  {
    "id": "2510.20984v1",
    "title": "Learning Grouped Lattice Vector Quantizers for Low-Bit LLM Compression",
    "abstract": "Large Language Models (LLMs) have demonstrated remarkable capabilities but\ntypically require extensive computational resources and memory for inference.\nPost-training quantization (PTQ) can effectively reduce these demands by\nstoring weights in lower bit-width formats. However, standard uniform\nquantization often leads to notable performance degradation, particularly in\nlow-bit scenarios. In this work, we introduce a Grouped Lattice Vector\nQuantization (GLVQ) framework that assigns each group of weights a customized\nlattice codebook, defined by a learnable generation matrix. To address the\nnon-differentiability of the quantization process, we adopt Babai rounding to\napproximate nearest-lattice-point search during training, which enables stable\noptimization of the generation matrices. Once trained, decoding reduces to a\nsimple matrix-vector multiplication, yielding an efficient and practical\nquantization pipeline. Experiments on multiple benchmarks show that our\napproach achieves a better trade-off between model size and accuracy compared\nto existing post-training quantization baselines, highlighting its\neffectiveness in deploying large models under stringent resource constraints.\nOur source code is available on GitHub repository:\nhttps://github.com/xzhang9308/GLVQ.",
    "categories": [
      "cs.LG",
      "cs.AI"
    ],
    "published": "2025-10-23T20:19:48Z",
    "authors": [
      "Xi Zhang",
      "Xiaolin Wu",
      "Jiamang Wang",
      "Weisi Lin"
    ],
    "pdf_url": "http://arxiv.org/pdf/2510.20984v1"
  },
  {
    "id": "2510.20979v1",
    "title": "Memory Constrained Dynamic Subnetwork Update for Transfer Learning",
    "abstract": "On-device neural network training faces critical memory constraints that\nlimit the adaptation of pre-trained models to downstream tasks. We present\nMeDyate, a theoretically-grounded framework for memory-constrained dynamic\nsubnetwork adaptation. Our approach introduces two key innovations: LaRa (Layer\nRanking), an improved layer importance metric that enables principled layer\npre-selection, and a dynamic channel sampling strategy that exploits the\ntemporal stability of channel importance distributions during fine-tuning.\nMeDyate dynamically resamples channels between epochs according to\nimportance-weighted probabilities, ensuring comprehensive parameter space\nexploration while respecting strict memory budgets. Extensive evaluation across\na large panel of tasks and architectures demonstrates that MeDyate achieves\nstate-of-the-art performance under extreme memory constraints, consistently\noutperforming existing static and dynamic approaches while maintaining high\ncomputational efficiency. Our method represents a significant step towards\nenabling efficient on-device learning by demonstrating effective fine-tuning\nwith memory budgets as low as a few hundred kB of RAM.",
    "categories": [
      "cs.LG",
      "cs.AI"
    ],
    "published": "2025-10-23T20:16:43Z",
    "authors": [
      "A\u00ebl Qu\u00e9lennec",
      "Pavlo Mozharovskyi",
      "Van-Tam Nguyen",
      "Enzo Tartaglione"
    ],
    "pdf_url": "http://arxiv.org/pdf/2510.20979v1"
  },
  {
    "id": "2510.20975v1",
    "title": "REx86: A Local Large Language Model for Assisting in x86 Assembly\n  Reverse Engineering",
    "abstract": "Reverse engineering (RE) of x86 binaries is indispensable for malware and\nfirmware analysis, but remains slow due to stripped metadata and adversarial\nobfuscation. Large Language Models (LLMs) offer potential for improving RE\nefficiency through automated comprehension and commenting, but cloud-hosted,\nclosed-weight models pose privacy and security risks and cannot be used in\nclosed-network facilities. We evaluate parameter-efficient fine-tuned local\nLLMs for assisting with x86 RE tasks in these settings. Eight open-weight\nmodels across the CodeLlama, Qwen2.5-Coder, and CodeGemma series are fine-tuned\non a custom curated dataset of 5,981 x86 assembly examples. We evaluate them\nquantitatively and identify the fine-tuned Qwen2.5-Coder-7B as the top\nperformer, which we name REx86.\n  REx86 reduces test-set cross-entropy loss by 64.2% and improves semantic\ncosine similarity against ground truth by 20.3\\% over its base model. In a\nlimited user case study (n=43), REx86 significantly enhanced line-level code\nunderstanding (p = 0.031) and increased the correct-solve rate from 31% to 53%\n(p = 0.189), though the latter did not reach statistical significance.\nQualitative analysis shows more accurate, concise comments with fewer\nhallucinations.\n  REx86 delivers state-of-the-art assistance in x86 RE among local, open-weight\nLLMs. Our findings demonstrate the value of domain-specific fine-tuning, and\nhighlight the need for more commented disassembly data to further enhance LLM\nperformance in RE. REx86, its dataset, and LoRA adapters are publicly available\nat https://github.com/dlea8/REx86 and https://zenodo.org/records/15420461.",
    "categories": [
      "cs.CR",
      "cs.AI"
    ],
    "published": "2025-10-23T20:09:21Z",
    "authors": [
      "Darrin Lea",
      "James Ghawaly",
      "Golden Richard III",
      "Aisha Ali-Gombe",
      "Andrew Case"
    ],
    "pdf_url": "http://arxiv.org/pdf/2510.20975v1"
  },
  {
    "id": "2510.20967v1",
    "title": "3DReasonKnee: Advancing Grounded Reasoning in Medical Vision Language\n  Models",
    "abstract": "Current Vision-Language Models (VLMs) struggle to ground anatomical regions\nin 3D medical images and reason about them in a step-by-step manner, a key\nrequirement of real-world diagnostic assessment. This ability is essential for\naligning model outputs with the diagnostic workflows clinicians use in\npractice, enabling trustworthy clinician-AI collaboration. Existing 3D datasets\nprovide localization labels, but none support this \"grounded reasoning\"\nability. To address this gap, we introduce 3DReasonKnee, the first 3D grounded\nreasoning dataset for medical images, which provides 494k high-quality\nquintuples derived from 7,970 3D knee MRI volumes. Each quintuple includes: (1)\nthe 3D MRI volume, (2) a diagnostic question targeting a specific anatomical\nregion (3) a 3D bounding box localizing the relevant anatomical structures, (4)\nclinician-generated diagnostic reasoning steps that explicitly detail the 3D\nreasoning process, and (5) structured severity assessments for the relevant\nanatomical region. The creation and validation of 3DReasonKnee, involving over\n450 hours of expert clinician time for manually segmenting MRIs and generating\nreasoning chains, ensures its superior quality and clinical relevance. We\nestablish ReasonKnee-Bench to evaluate localization and diagnostic accuracy,\nproviding insight into VLM ability to perform grounding and severity assessment\nacross anatomical regions and diagnostic inquiries. We benchmark five\nstate-of-the-art VLMs, providing baseline performance for ReasonKnee-Bench. By\nproviding this unique resource of expert-annotated 3D reasoning pathways,\n3DReasonKnee serves as a repository of orthopedic surgeons' diagnostic\nexpertise and offers a vital testbed for advancing multimodal medical AI\nsystems towards 3D, clinically aligned, localized decision-making capabilities.\nThe dataset can be found in:\nhttps://huggingface.co/datasets/rajpurkarlab/3DReasonKnee",
    "categories": [
      "cs.CV",
      "cs.AI"
    ],
    "published": "2025-10-23T19:54:49Z",
    "authors": [
      "Sraavya Sambara",
      "Sung Eun Kim",
      "Xiaoman Zhang",
      "Luyang Luo",
      "Shreya Johri",
      "Mohammed Baharoon",
      "Du Hyun Ro",
      "Pranav Rajpurkar"
    ],
    "pdf_url": "http://arxiv.org/pdf/2510.20967v1"
  },
  {
    "id": "2510.20943v1",
    "title": "Meta-Learning for Cross-Task Generalization in Protein Mutation Property\n  Prediction",
    "abstract": "Protein mutations can have profound effects on biological function, making\naccurate prediction of property changes critical for drug discovery, protein\nengineering, and precision medicine. Current approaches rely on fine-tuning\nprotein-specific transformers for individual datasets, but struggle with\ncross-dataset generalization due to heterogeneous experimental conditions and\nlimited target domain data. We introduce two key innovations: (1) the first\napplication of Model-Agnostic Meta-Learning (MAML) to protein mutation property\nprediction, and (2) a novel mutation encoding strategy using separator tokens\nto directly incorporate mutations into sequence context. We build upon\ntransformer architectures integrating them with MAML to enable rapid adaptation\nto new tasks through minimal gradient steps rather than learning\ndataset-specific patterns. Our mutation encoding addresses the critical\nlimitation where standard transformers treat mutation positions as unknown\ntokens, significantly degrading performance. Evaluation across three diverse\nprotein mutation datasets (functional fitness, thermal stability, and\nsolubility) demonstrates significant advantages over traditional fine-tuning.\nIn cross-task evaluation, our meta-learning approach achieves 29% better\naccuracy for functional fitness with 65% less training time, and 94% better\naccuracy for solubility with 55% faster training. The framework maintains\nconsistent training efficiency regardless of dataset size, making it\nparticularly valuable for industrial applications and early-stage protein\ndesign where experimental data is limited. This work establishes a systematic\napplication of meta-learning to protein mutation analysis and introduces an\neffective mutation encoding strategy, offering transformative methodology for\ncross-domain generalization in protein engineering.",
    "categories": [
      "cs.LG",
      "cs.AI"
    ],
    "published": "2025-10-23T19:09:06Z",
    "authors": [
      "Srivathsan Badrinarayanan",
      "Yue Su",
      "Janghoon Ock",
      "Alan Pham",
      "Sanya Ahuja",
      "Amir Barati Farimani"
    ],
    "pdf_url": "http://arxiv.org/pdf/2510.20943v1"
  },
  {
    "id": "2510.20941v1",
    "title": "Do LLMs Truly Understand When a Precedent Is Overruled?",
    "abstract": "Large language models (LLMs) with extended context windows show promise for\ncomplex legal reasoning tasks, yet their ability to understand long legal\ndocuments remains insufficiently evaluated. Developing long-context benchmarks\nthat capture realistic, high-stakes tasks remains a significant challenge in\nthe field, as most existing evaluations rely on simplified synthetic tasks that\nfail to represent the complexity of real-world document understanding.\nOverruling relationships are foundational to common-law doctrine and commonly\nfound in judicial opinions. They provide a focused and important testbed for\nlong-document legal understanding that closely resembles what legal\nprofessionals actually do. We present an assessment of state-of-the-art LLMs on\nidentifying overruling relationships from U.S. Supreme Court cases using a\ndataset of 236 case pairs. Our evaluation reveals three critical limitations:\n(1) era sensitivity -- the models show degraded performance on historical cases\ncompared to modern ones, revealing fundamental temporal bias in their training;\n(2) shallow reasoning -- models rely on shallow logical heuristics rather than\ndeep legal comprehension; and (3) context-dependent reasoning failures --\nmodels produce temporally impossible relationships in complex open-ended tasks\ndespite maintaining basic temporal awareness in simple contexts. Our work\ncontributes a benchmark that addresses the critical gap in realistic\nlong-context evaluation, providing an environment that mirrors the complexity\nand stakes of actual legal reasoning tasks.",
    "categories": [
      "cs.CL",
      "cs.AI",
      "68T50",
      "I.2.7; I.2.4"
    ],
    "published": "2025-10-23T19:07:42Z",
    "authors": [
      "Li Zhang",
      "Jaromir Savelka",
      "Kevin Ashley"
    ],
    "pdf_url": "http://arxiv.org/pdf/2510.20941v1"
  },
  {
    "id": "2510.20933v1",
    "title": "Focal Modulation and Bidirectional Feature Fusion Network for Medical\n  Image Segmentation",
    "abstract": "Medical image segmentation is essential for clinical applications such as\ndisease diagnosis, treatment planning, and disease development monitoring\nbecause it provides precise morphological and spatial information on anatomical\nstructures that directly influence treatment decisions. Convolutional neural\nnetworks significantly impact image segmentation; however, since convolution\noperations are local, capturing global contextual information and long-range\ndependencies is still challenging. Their capacity to precisely segment\nstructures with complicated borders and a variety of sizes is impacted by this\nrestriction. Since transformers use self-attention methods to capture global\ncontext and long-range dependencies efficiently, integrating transformer-based\narchitecture with CNNs is a feasible approach to overcoming these challenges.\nTo address these challenges, we propose the Focal Modulation and Bidirectional\nFeature Fusion Network for Medical Image Segmentation, referred to as\nFM-BFF-Net in the remainder of this paper. The network combines convolutional\nand transformer components, employs a focal modulation attention mechanism to\nrefine context awareness, and introduces a bidirectional feature fusion module\nthat enables efficient interaction between encoder and decoder representations\nacross scales. Through this design, FM-BFF-Net enhances boundary precision and\nrobustness to variations in lesion size, shape, and contrast. Extensive\nexperiments on eight publicly available datasets, including polyp detection,\nskin lesion segmentation, and ultrasound imaging, show that FM-BFF-Net\nconsistently surpasses recent state-of-the-art methods in Jaccard index and\nDice coefficient, confirming its effectiveness and adaptability for diverse\nmedical imaging scenarios.",
    "categories": [
      "cs.CV",
      "cs.AI"
    ],
    "published": "2025-10-23T18:52:24Z",
    "authors": [
      "Moin Safdar",
      "Shahzaib Iqbal",
      "Mehwish Mehmood",
      "Mubeen Ghafoor",
      "Tariq M. Khan",
      "Imran Razzak"
    ],
    "pdf_url": "http://arxiv.org/pdf/2510.20933v1"
  },
  {
    "id": "2510.20932v1",
    "title": "An Experimental Study of Trojan Vulnerabilities in UAV Autonomous\n  Landing",
    "abstract": "This study investigates the vulnerabilities of autonomous navigation and\nlanding systems in Urban Air Mobility (UAM) vehicles. Specifically, it focuses\non Trojan attacks that target deep learning models, such as Convolutional\nNeural Networks (CNNs). Trojan attacks work by embedding covert triggers within\na model's training data. These triggers cause specific failures under certain\nconditions, while the model continues to perform normally in other situations.\nWe assessed the vulnerability of Urban Autonomous Aerial Vehicles (UAAVs) using\nthe DroNet framework. Our experiments showed a significant drop in accuracy,\nfrom 96.4% on clean data to 73.3% on data triggered by Trojan attacks. To\nconduct this study, we collected a custom dataset and trained models to\nsimulate real-world conditions. We also developed an evaluation framework\ndesigned to identify Trojan-infected models. This work demonstrates the\npotential security risks posed by Trojan attacks and lays the groundwork for\nfuture research on enhancing the resilience of UAM systems.",
    "categories": [
      "cs.CR",
      "cs.AI",
      "cs.CV",
      "cs.RO"
    ],
    "published": "2025-10-23T18:47:40Z",
    "authors": [
      "Reza Ahmari",
      "Ahmad Mohammadi",
      "Vahid Hemmati",
      "Mohammed Mynuddin",
      "Mahmoud Nabil Mahmoud",
      "Parham Kebria",
      "Abdollah Homaifar",
      "Mehrdad Saif"
    ],
    "pdf_url": "http://arxiv.org/pdf/2510.20932v1"
  },
  {
    "id": "2510.20930v1",
    "title": "Security Logs to ATT&CK Insights: Leveraging LLMs for High-Level Threat\n  Understanding and Cognitive Trait Inference",
    "abstract": "Understanding adversarial behavior in cybersecurity has traditionally relied\non high-level intelligence reports and manual interpretation of attack chains.\nHowever, real-time defense requires the ability to infer attacker intent and\ncognitive strategy directly from low-level system telemetry such as intrusion\ndetection system (IDS) logs. In this paper, we propose a novel framework that\nleverages large language models (LLMs) to analyze Suricata IDS logs and infer\nattacker actions in terms of MITRE ATT&CK techniques. Our approach is grounded\nin the hypothesis that attacker behavior reflects underlying cognitive biases\nsuch as loss aversion, risk tolerance, or goal persistence that can be\nextracted and modeled through careful observation of log sequences. This lays\nthe groundwork for future work on behaviorally adaptive cyber defense and\ncognitive trait inference. We develop a strategy-driven prompt system to\nsegment large amounts of network logs data into distinct behavioral phases in a\nhighly efficient manner, enabling the LLM to associate each phase with likely\ntechniques and underlying cognitive motives. By mapping network-layer events to\nhigh-level attacker strategies, our method reveals how behavioral signals such\nas tool switching, protocol transitions, or pivot patterns correspond to\npsychologically meaningful decision points. The results demonstrate that LLMs\ncan bridge the semantic gap between packet-level logs and strategic intent,\noffering a pathway toward cognitive-adaptive cyber defense.\n  Keywords: Cognitive Cybersecurity, Large Language Models (LLMs),\nCyberpsychology, Intrusion Detection Systems (IDS), MITRE ATT&CK, Cognitive\nBiases",
    "categories": [
      "cs.CR",
      "cs.AI"
    ],
    "published": "2025-10-23T18:43:31Z",
    "authors": [
      "Soham Hans",
      "Stacy Marsella",
      "Sophia Hirschmann",
      "Nikolos Gurney"
    ],
    "pdf_url": "http://arxiv.org/pdf/2510.20930v1"
  },
  {
    "id": "2510.20916v1",
    "title": "Aircraft Collision Avoidance Systems: Technological Challenges and\n  Solutions on the Path to Regulatory Acceptance",
    "abstract": "Aircraft collision avoidance systems is critical to modern aviation. These\nsystems are designed to predict potential collisions between aircraft and\nrecommend appropriate avoidance actions. Creating effective collision avoidance\nsystems requires solutions to a variety of technical challenges related to\nsurveillance, decision making, and validation. These challenges have sparked\nsignificant research and development efforts over the past several decades that\nhave resulted in a variety of proposed solutions. This article provides an\noverview of these challenges and solutions with an emphasis on those that have\nbeen put through a rigorous validation process and accepted by regulatory\nbodies. The challenges posed by the collision avoidance problem are often\npresent in other domains, and aircraft collision avoidance systems can serve as\ncase studies that provide valuable insights for a wide range of safety-critical\nsystems.",
    "categories": [
      "cs.RO",
      "cs.AI",
      "cs.SY",
      "eess.SY"
    ],
    "published": "2025-10-23T18:13:22Z",
    "authors": [
      "Sydney M. Katz",
      "Robert J. Moss",
      "Dylan M. Asmar",
      "Wesley A. Olson",
      "James K. Kuchar",
      "Mykel J. Kochenderfer"
    ],
    "pdf_url": "http://arxiv.org/pdf/2510.20916v1"
  },
  {
    "id": "2510.20909v1",
    "title": "Code-enabled language models can outperform reasoning models on diverse\n  tasks",
    "abstract": "Reasoning models (RMs), language models (LMs) trained with reinforcement\nlearning to produce long-form natural language reasoning, have been remarkably\nsuccessful, but they still require large amounts of computation and data to\ntrain, and can be slow and expensive to run. In this paper, we show that\nstandard instruct LMs can already be elicited to be strong reasoners at a level\ncomparable to or even surpassing their corresponding RMs (e.g., DeepSeek V3 vs\nR1) without finetuning, across diverse domains from instruction following and\ncreative generation to mathematical reasoning. This is achieved by CodeAdapt,\nour simple recipe that combines the CodeAct framework, where LMs interleave\nnatural language reasoning with code execution in a multi-step fashion, with\nfew-shot bootstrap in-context learning from as few as five training problems.\nAnalyzing four matched pairs of LMs and RMs, we find that CodeAdapt enables\nthree LMs to outperform the corresponding RMs on average over eight tasks (up\nto 22.9%) while being 10-81% more token efficient, and delivers superior\nperformance on six tasks when averaged over the four models (up to 35.7%).\nFurthermore, the code-augmented reasoning traces display rich and varied\nproblem-solving strategies. Our findings support that (1) CodeAdapt-style\nlearning and reasoning may be robust and domain general and (2) code-enabled\nLMs are cognitively grounded and powerful systems, potentially providing a\nstrong foundation for in-weight reinforcement learning.",
    "categories": [
      "cs.CL",
      "cs.AI"
    ],
    "published": "2025-10-23T18:04:03Z",
    "authors": [
      "Cedegao E. Zhang",
      "C\u00e9dric Colas",
      "Gabriel Poesia",
      "Joshua B. Tenenbaum",
      "Jacob Andreas"
    ],
    "pdf_url": "http://arxiv.org/pdf/2510.20909v1"
  },
  {
    "id": "2510.20819v2",
    "title": "Towards General Modality Translation with Contrastive and Predictive\n  Latent Diffusion Bridge",
    "abstract": "Recent advances in generative modeling have positioned diffusion models as\nstate-of-the-art tools for sampling from complex data distributions. While\nthese models have shown remarkable success across single-modality domains such\nas images and audio, extending their capabilities to Modality Translation (MT),\ntranslating information across different sensory modalities, remains an open\nchallenge. Existing approaches often rely on restrictive assumptions, including\nshared dimensionality, Gaussian source priors, and modality-specific\narchitectures, which limit their generality and theoretical grounding. In this\nwork, we propose the Latent Denoising Diffusion Bridge Model (LDDBM), a\ngeneral-purpose framework for modality translation based on a latent-variable\nextension of Denoising Diffusion Bridge Models. By operating in a shared latent\nspace, our method learns a bridge between arbitrary modalities without\nrequiring aligned dimensions. We introduce a contrastive alignment loss to\nenforce semantic consistency between paired samples and design a\ndomain-agnostic encoder-decoder architecture tailored for noise prediction in\nlatent space. Additionally, we propose a predictive loss to guide training\ntoward accurate cross-domain translation and explore several training\nstrategies to improve stability. Our approach supports arbitrary modality pairs\nand performs strongly on diverse MT tasks, including multi-view to 3D shape\ngeneration, image super-resolution, and multi-view scene synthesis.\nComprehensive experiments and ablations validate the effectiveness of our\nframework, establishing a new strong baseline in general modality translation.\nFor more information, see our project page:\nhttps://sites.google.com/view/lddbm/home.",
    "categories": [
      "cs.CV",
      "cs.AI",
      "cs.LG"
    ],
    "published": "2025-10-23T17:59:54Z",
    "authors": [
      "Nimrod Berman",
      "Omkar Joglekar",
      "Eitan Kosman",
      "Dotan Di Castro",
      "Omri Azencot"
    ],
    "pdf_url": "http://arxiv.org/pdf/2510.20819v2"
  },
  {
    "id": "2510.20888v1",
    "title": "Video-As-Prompt: Unified Semantic Control for Video Generation",
    "abstract": "Unified, generalizable semantic control in video generation remains a\ncritical open challenge. Existing methods either introduce artifacts by\nenforcing inappropriate pixel-wise priors from structure-based controls, or\nrely on non-generalizable, condition-specific finetuning or task-specific\narchitectures. We introduce Video-As-Prompt (VAP), a new paradigm that reframes\nthis problem as in-context generation. VAP leverages a reference video as a\ndirect semantic prompt, guiding a frozen Video Diffusion Transformer (DiT) via\na plug-and-play Mixture-of-Transformers (MoT) expert. This architecture\nprevents catastrophic forgetting and is guided by a temporally biased position\nembedding that eliminates spurious mapping priors for robust context retrieval.\nTo power this approach and catalyze future research, we built VAP-Data, the\nlargest dataset for semantic-controlled video generation with over 100K paired\nvideos across 100 semantic conditions. As a single unified model, VAP sets a\nnew state-of-the-art for open-source methods, achieving a 38.7% user preference\nrate that rivals leading condition-specific commercial models. VAP's strong\nzero-shot generalization and support for various downstream applications mark a\nsignificant advance toward general-purpose, controllable video generation.",
    "categories": [
      "cs.CV",
      "cs.AI"
    ],
    "published": "2025-10-23T17:59:52Z",
    "authors": [
      "Yuxuan Bian",
      "Xin Chen",
      "Zenan Li",
      "Tiancheng Zhi",
      "Shen Sang",
      "Linjie Luo",
      "Qiang Xu"
    ],
    "pdf_url": "http://arxiv.org/pdf/2510.20888v1"
  },
  {
    "id": "2510.20818v1",
    "title": "VAMOS: A Hierarchical Vision-Language-Action Model for\n  Capability-Modulated and Steerable Navigation",
    "abstract": "A fundamental challenge in robot navigation lies in learning policies that\ngeneralize across diverse environments while conforming to the unique physical\nconstraints and capabilities of a specific embodiment (e.g., quadrupeds can\nwalk up stairs, but rovers cannot). We propose VAMOS, a hierarchical VLA that\ndecouples semantic planning from embodiment grounding: a generalist planner\nlearns from diverse, open-world data, while a specialist affordance model\nlearns the robot's physical constraints and capabilities in safe, low-cost\nsimulation. We enabled this separation by carefully designing an interface that\nlets a high-level planner propose candidate paths directly in image space that\nthe affordance model then evaluates and re-ranks. Our real-world experiments\nshow that VAMOS achieves higher success rates in both indoor and complex\noutdoor navigation than state-of-the-art model-based and end-to-end learning\nmethods. We also show that our hierarchical design enables cross-embodied\nnavigation across legged and wheeled robots and is easily steerable using\nnatural language. Real-world ablations confirm that the specialist model is key\nto embodiment grounding, enabling a single high-level planner to be deployed\nacross physically distinct wheeled and legged robots. Finally, this model\nsignificantly enhances single-robot reliability, achieving 3X higher success\nrates by rejecting physically infeasible plans. Website:\nhttps://vamos-vla.github.io/",
    "categories": [
      "cs.RO",
      "cs.AI",
      "cs.LG"
    ],
    "published": "2025-10-23T17:59:45Z",
    "authors": [
      "Mateo Guaman Castro",
      "Sidharth Rajagopal",
      "Daniel Gorbatov",
      "Matt Schmittle",
      "Rohan Baijal",
      "Octi Zhang",
      "Rosario Scalise",
      "Sidharth Talia",
      "Emma Romig",
      "Celso de Melo",
      "Byron Boots",
      "Abhishek Gupta"
    ],
    "pdf_url": "http://arxiv.org/pdf/2510.20818v1"
  },
  {
    "id": "2510.20813v1",
    "title": "GSWorld: Closed-Loop Photo-Realistic Simulation Suite for Robotic\n  Manipulation",
    "abstract": "This paper presents GSWorld, a robust, photo-realistic simulator for robotics\nmanipulation that combines 3D Gaussian Splatting with physics engines. Our\nframework advocates \"closing the loop\" of developing manipulation policies with\nreproducible evaluation of policies learned from real-robot data and sim2real\npolicy training without using real robots. To enable photo-realistic rendering\nof diverse scenes, we propose a new asset format, which we term GSDF (Gaussian\nScene Description File), that infuses Gaussian-on-Mesh representation with\nrobot URDF and other objects. With a streamlined reconstruction pipeline, we\ncurate a database of GSDF that contains 3 robot embodiments for single-arm and\nbimanual manipulation, as well as more than 40 objects. Combining GSDF with\nphysics engines, we demonstrate several immediate interesting applications: (1)\nlearning zero-shot sim2real pixel-to-action manipulation policy with\nphoto-realistic rendering, (2) automated high-quality DAgger data collection\nfor adapting policies to deployment environments, (3) reproducible benchmarking\nof real-robot manipulation policies in simulation, (4) simulation data\ncollection by virtual teleoperation, and (5) zero-shot sim2real visual\nreinforcement learning. Website: https://3dgsworld.github.io/.",
    "categories": [
      "cs.RO",
      "cs.AI",
      "cs.CV"
    ],
    "published": "2025-10-23T17:59:26Z",
    "authors": [
      "Guangqi Jiang",
      "Haoran Chang",
      "Ri-Zhao Qiu",
      "Yutong Liang",
      "Mazeyu Ji",
      "Jiyue Zhu",
      "Zhao Dong",
      "Xueyan Zou",
      "Xiaolong Wang"
    ],
    "pdf_url": "http://arxiv.org/pdf/2510.20813v1"
  },
  {
    "id": "2510.20812v1",
    "title": "Small Drafts, Big Verdict: Information-Intensive Visual Reasoning via\n  Speculation",
    "abstract": "Large Vision-Language Models (VLMs) have achieved remarkable progress in\nmultimodal understanding, yet they struggle when reasoning over\ninformation-intensive images that densely interleave textual annotations with\nfine-grained graphical elements. The main challenges lie in precisely\nlocalizing critical cues in dense layouts and multi-hop reasoning to integrate\ndispersed evidence. We propose Speculative Verdict (SV), a training-free\nframework inspired by speculative decoding that combines multiple lightweight\ndraft experts with a large verdict model. In the draft stage, small VLMs act as\ndraft experts to generate reasoning paths that provide diverse localization\ncandidates; in the verdict stage, a strong VLM synthesizes these paths to\nproduce the final answer, minimizing computational cost while recovering\ncorrect answers. To further improve efficiency and accuracy, SV introduces a\nconsensus expert selection mechanism that forwards only high-agreement\nreasoning paths to the verdict. Empirically, SV achieves consistent gains on\nchallenging information-intensive and high-resolution visual question answering\nbenchmarks, including InfographicVQA, ChartMuseum, ChartQAPro, and HR-Bench 4K.\nBy synthesizing correct insights from multiple partially accurate reasoning\npaths, SV achieves both error correction and cost-efficiency compared to large\nproprietary models or training pipelines. Code is available at\nhttps://github.com/Tinaliu0123/speculative-verdict",
    "categories": [
      "cs.CV",
      "cs.AI",
      "cs.CL"
    ],
    "published": "2025-10-23T17:59:21Z",
    "authors": [
      "Yuhan Liu",
      "Lianhui Qin",
      "Shengjie Wang"
    ],
    "pdf_url": "http://arxiv.org/pdf/2510.20812v1"
  },
  {
    "id": "2510.20887v1",
    "title": "Preventing Shortcuts in Adapter Training via Providing the Shortcuts",
    "abstract": "Adapter-based training has emerged as a key mechanism for extending the\ncapabilities of powerful foundation image generators, enabling personalized and\nstylized text-to-image synthesis. These adapters are typically trained to\ncapture a specific target attribute, such as subject identity, using\nsingle-image reconstruction objectives. However, because the input image\ninevitably contains a mixture of visual factors, adapters are prone to entangle\nthe target attribute with incidental ones, such as pose, expression, and\nlighting. This spurious correlation problem limits generalization and obstructs\nthe model's ability to adhere to the input text prompt. In this work, we\nuncover a simple yet effective solution: provide the very shortcuts we wish to\neliminate during adapter training. In Shortcut-Rerouted Adapter Training,\nconfounding factors are routed through auxiliary modules, such as ControlNet or\nLoRA, eliminating the incentive for the adapter to internalize them. The\nauxiliary modules are then removed during inference. When applied to tasks like\nfacial and full-body identity injection, our approach improves generation\nquality, diversity, and prompt adherence. These results point to a general\ndesign principle in the era of large models: when seeking disentangled\nrepresentations, the most effective path may be to establish shortcuts for what\nshould NOT be learned.",
    "categories": [
      "cs.CV",
      "cs.AI"
    ],
    "published": "2025-10-23T17:59:09Z",
    "authors": [
      "Anujraaj Argo Goyal",
      "Guocheng Gordon Qian",
      "Huseyin Coskun",
      "Aarush Gupta",
      "Himmy Tam",
      "Daniil Ostashev",
      "Ju Hu",
      "Dhritiman Sagar",
      "Sergey Tulyakov",
      "Kfir Aberman",
      "Kuan-Chieh Jackson Wang"
    ],
    "pdf_url": "http://arxiv.org/pdf/2510.20887v1"
  },
  {
    "id": "2510.20810v1",
    "title": "On the Detectability of LLM-Generated Text: What Exactly Is\n  LLM-Generated Text?",
    "abstract": "With the widespread use of large language models (LLMs), many researchers\nhave turned their attention to detecting text generated by them. However, there\nis no consistent or precise definition of their target, namely \"LLM-generated\ntext\". Differences in usage scenarios and the diversity of LLMs further\nincrease the difficulty of detection. What is commonly regarded as the\ndetecting target usually represents only a subset of the text that LLMs can\npotentially produce. Human edits to LLM outputs, together with the subtle\ninfluences that LLMs exert on their users, are blurring the line between\nLLM-generated and human-written text. Existing benchmarks and evaluation\napproaches do not adequately address the various conditions in real-world\ndetector applications. Hence, the numerical results of detectors are often\nmisunderstood, and their significance is diminishing. Therefore, detectors\nremain useful under specific conditions, but their results should be\ninterpreted only as references rather than decisive indicators.",
    "categories": [
      "cs.CL",
      "cs.AI",
      "cs.CY",
      "cs.LG"
    ],
    "published": "2025-10-23T17:59:06Z",
    "authors": [
      "Mingmeng Geng",
      "Thierry Poibeau"
    ],
    "pdf_url": "http://arxiv.org/pdf/2510.20810v1"
  },
  {
    "id": "2510.20809v1",
    "title": "Real Deep Research for AI, Robotics and Beyond",
    "abstract": "With the rapid growth of research in AI and robotics now producing over\n10,000 papers annually it has become increasingly difficult for researchers to\nstay up to date. Fast evolving trends, the rise of interdisciplinary work, and\nthe need to explore domains beyond one's expertise all contribute to this\nchallenge. To address these issues, we propose a generalizable pipeline capable\nof systematically analyzing any research area: identifying emerging trends,\nuncovering cross domain opportunities, and offering concrete starting points\nfor new inquiry. In this work, we present Real Deep Research (RDR) a\ncomprehensive framework applied to the domains of AI and robotics, with a\nparticular focus on foundation models and robotics advancements. We also\nbriefly extend our analysis to other areas of science. The main paper details\nthe construction of the RDR pipeline, while the appendix provides extensive\nresults across each analyzed topic. We hope this work sheds light for\nresearchers working in the field of AI and beyond.",
    "categories": [
      "cs.AI",
      "cs.CL",
      "cs.CV",
      "cs.LG"
    ],
    "published": "2025-10-23T17:59:05Z",
    "authors": [
      "Xueyan Zou",
      "Jianglong Ye",
      "Hao Zhang",
      "Xiaoyu Xiang",
      "Mingyu Ding",
      "Zhaojing Yang",
      "Yong Jae Lee",
      "Zhuowen Tu",
      "Sifei Liu",
      "Xiaolong Wang"
    ],
    "pdf_url": "http://arxiv.org/pdf/2510.20809v1"
  },
  {
    "id": "2510.20808v1",
    "title": "The Reality Gap in Robotics: Challenges, Solutions, and Best Practices",
    "abstract": "Machine learning has facilitated significant advancements across various\nrobotics domains, including navigation, locomotion, and manipulation. Many such\nachievements have been driven by the extensive use of simulation as a critical\ntool for training and testing robotic systems prior to their deployment in\nreal-world environments. However, simulations consist of abstractions and\napproximations that inevitably introduce discrepancies between simulated and\nreal environments, known as the reality gap. These discrepancies significantly\nhinder the successful transfer of systems from simulation to the real world.\nClosing this gap remains one of the most pressing challenges in robotics.\nRecent advances in sim-to-real transfer have demonstrated promising results\nacross various platforms, including locomotion, navigation, and manipulation.\nBy leveraging techniques such as domain randomization, real-to-sim transfer,\nstate and action abstractions, and sim-real co-training, many works have\novercome the reality gap. However, challenges persist, and a deeper\nunderstanding of the reality gap's root causes and solutions is necessary. In\nthis survey, we present a comprehensive overview of the sim-to-real landscape,\nhighlighting the causes, solutions, and evaluation metrics for the reality gap\nand sim-to-real transfer.",
    "categories": [
      "cs.RO",
      "cs.AI",
      "cs.LG",
      "stat.ML",
      "I.2.6; I.2.8; I.2.9"
    ],
    "published": "2025-10-23T17:58:53Z",
    "authors": [
      "Elie Aljalbout",
      "Jiaxu Xing",
      "Angel Romero",
      "Iretiayo Akinola",
      "Caelan Reed Garrett",
      "Eric Heiden",
      "Abhishek Gupta",
      "Tucker Hermans",
      "Yashraj Narang",
      "Dieter Fox",
      "Davide Scaramuzza",
      "Fabio Ramos"
    ],
    "pdf_url": "http://arxiv.org/pdf/2510.20808v1"
  },
  {
    "id": "2510.20800v1",
    "title": "Compress to Impress: Efficient LLM Adaptation Using a Single Gradient\n  Step on 100 Samples",
    "abstract": "Recently, Sharma et al. suggested a method called Layer-SElective-Rank\nreduction (LASER) which demonstrated that pruning high-order components of\ncarefully chosen LLM's weight matrices can boost downstream accuracy -- without\nany gradient-based fine-tuning. Yet LASER's exhaustive, per-matrix search (each\nrequiring full-dataset forward passes) makes it impractical for rapid\ndeployment. We demonstrate that this overhead can be removed and find that: (i)\nOnly a small, carefully chosen subset of matrices needs to be inspected --\neliminating the layer-by-layer sweep, (ii) The gradient of each matrix's\nsingular values pinpoints which matrices merit reduction, (iii) Increasing the\nfactorization search space by allowing matrices rows to cluster around multiple\nsubspaces and then decomposing each cluster separately further reduces\noverfitting on the original training data and further lifts accuracy by up to\n24.6 percentage points, and finally, (iv) we discover that evaluating on just\n100 samples rather than the full training data -- both for computing the\nindicative gradients and for measuring the final accuracy -- suffices to\nfurther reduce the search time; we explain that as adaptation to downstream\ntasks is dominated by prompting style, not dataset size. As a result, we show\nthat combining these findings yields a fast and robust adaptation algorithm for\ndownstream tasks. Overall, with a single gradient step on 100 examples and a\nquick scan of the top candidate layers and factorization techniques, we can\nadapt LLMs to new datasets -- entirely without fine-tuning.",
    "categories": [
      "cs.LG",
      "cs.AI",
      "cs.CL",
      "cs.CV"
    ],
    "published": "2025-10-23T17:58:01Z",
    "authors": [
      "Shiva Sreeram",
      "Alaa Maalouf",
      "Pratyusha Sharma",
      "Daniela Rus"
    ],
    "pdf_url": "http://arxiv.org/pdf/2510.20800v1"
  },
  {
    "id": "2510.20886v1",
    "title": "Shoot First, Ask Questions Later? Building Rational Agents that Explore\n  and Act Like People",
    "abstract": "Many high-stakes applications of AI require forming data-driven hypotheses\nand making targeted guesses; e.g., in scientific and diagnostic settings. Given\nlimited resources, to what extent do agents based on language models (LMs) act\nrationally? We develop methods to benchmark and enhance agentic\ninformation-seeking, drawing on insights from human behavior. First, we\nintroduce a strategic decision-oriented dialogue task called Collaborative\nBattleship, in which a partially-informed Captain must balance exploration\n(asking questions) and action (taking shots), while a fully-informed Spotter\nmust provide accurate answers under an information bottleneck. Compared to\nhuman players (N=42), we find that LM agents struggle to ground answers in\ncontext, generate informative questions, and select high-value actions. Next,\nto address these gaps, we develop novel Monte Carlo inference strategies for\nLMs based on principles from Bayesian Experimental Design (BED). For Spotter\nagents, our approach boosts accuracy by up to 14.7% absolute over LM-only\nbaselines; for Captain agents, it raises expected information gain (EIG) by up\nto 0.227 bits (94.2% of the achievable noise ceiling). Combined, these\ncomponents yield sharper targeting (+0.303-0.374 F1), and enable weaker LMs,\nsuch as Llama-4-Scout, to outperform both humans (8% -> 82% win rate) and\nfrontier models (0% -> 67% win rate vs. GPT-5) at ~1% of GPT-5's cost. We\nreplicate these findings on Guess Who? where our methods significantly boost\naccuracy (+28.3-42.4 p.p.), demonstrating their general applicability for\nbuilding rational information-seeking agents.",
    "categories": [
      "cs.CL",
      "cs.AI"
    ],
    "published": "2025-10-23T17:57:28Z",
    "authors": [
      "Gabriel Grand",
      "Valerio Pepe",
      "Jacob Andreas",
      "Joshua B. Tenenbaum"
    ],
    "pdf_url": "http://arxiv.org/pdf/2510.20886v1"
  },
  {
    "id": "2510.20797v1",
    "title": "Simple Context Compression: Mean-Pooling and Multi-Ratio Training",
    "abstract": "A common strategy to reduce the computational costs of using long contexts in\nretrieval-augmented generation (RAG) with large language models (LLMs) is soft\ncontext compression, where the input sequence is transformed into a shorter\ncontinuous representation. We develop a lightweight and simple mean-pooling\napproach that consistently outperforms the widely used compression-tokens\narchitecture, and study training the same compressor to output multiple\ncompression ratios. We conduct extensive experiments across in-domain and\nout-of-domain QA datasets, as well as across model families, scales, and\ncompression ratios. Overall, our simple mean-pooling approach achieves the\nstrongest performance, with a relatively small drop when training for multiple\ncompression ratios. More broadly though, across architectures and training\nregimes the trade-offs are more nuanced, illustrating the complex landscape of\ncompression methods.",
    "categories": [
      "cs.CL",
      "cs.AI",
      "cs.LG"
    ],
    "published": "2025-10-23T17:57:23Z",
    "authors": [
      "Yair Feldman",
      "Yoav Artzi"
    ],
    "pdf_url": "http://arxiv.org/pdf/2510.20797v1"
  },
  {
    "id": "2510.21883v1",
    "title": "Language Ranker: A Lightweight Ranking framework for LLM Decoding",
    "abstract": "Conventional research on large language models (LLMs) has primarily focused\non refining output distributions, while paying less attention to the decoding\nprocess that transforms these distributions into final responses. Recent\nadvances, such as scaling the computation of inference time with reward models,\nhave underscored the importance of decoding, but these methods often suffer\nfrom high computational costs and limited applicability. In this paper, we\nrevisit LLM generation through the lens of recommender systems, conceptualizing\nthe decoding process as analogous to the ranking stage in recommendation\npipelines. From this perspective, we observe that both traditional decoding\nmethods and reward models exhibit clear limitations such as redundancy.\nMotivated by this insight, we propose Language Ranker, a novel framework that\nintroduces a lightweight module to rerank candidate responses using features\nextracted by the base model. Experiments across a wide range of tasks show that\nLanguage Ranker achieves performance comparable to large-scale reward models,\nwhile requiring only <0.5M additional parameters, significantly reducing the\ncomputational overhead during both training and inference stages. This\nhighlights the efficiency and effectiveness of our method, showcasing its\npotential to fully unlock the capabilities of LLMs.",
    "categories": [
      "cs.CL",
      "cs.AI"
    ],
    "published": "2025-10-23T17:56:46Z",
    "authors": [
      "Chenheng Zhang",
      "Tianqi Du",
      "Jizhe Zhang",
      "Mingqing Xiao",
      "Yifei Wang",
      "Yisen Wang",
      "Zhouchen Lin"
    ],
    "pdf_url": "http://arxiv.org/pdf/2510.21883v1"
  },
  {
    "id": "2510.20795v1",
    "title": "Bayesian Inference of Primordial Magnetic Field Parameters from CMB with\n  Spherical Graph Neural Networks",
    "abstract": "Deep learning has emerged as a transformative methodology in modern\ncosmology, providing powerful tools to extract meaningful physical information\nfrom complex astronomical datasets. This paper implements a novel Bayesian\ngraph deep learning framework for estimating key cosmological parameters in a\nprimordial magnetic field (PMF) cosmology directly from simulated Cosmic\nMicrowave Background (CMB) maps. Our methodology utilizes DeepSphere, a\nspherical convolutional neural network architecture specifically designed to\nrespect the spherical geometry of CMB data through HEALPix pixelization. To\nadvance beyond deterministic point estimates and enable robust uncertainty\nquantification, we integrate Bayesian Neural Networks (BNNs) into the\nframework, capturing aleatoric and epistemic uncertainties that reflect the\nmodel confidence in its predictions. The proposed approach demonstrates\nexceptional performance, achieving $R^{2}$ scores exceeding 0.89 for the\nmagnetic parameter estimation. We further obtain well-calibrated uncertainty\nestimates through post-hoc training techniques including Variance Scaling and\nGPNormal. This integrated DeepSphere-BNNs framework not only delivers accurate\nparameter estimation from CMB maps with PMF contributions but also provides\nreliable uncertainty quantification, providing the necessary tools for robust\ncosmological inference in the era of precision cosmology.",
    "categories": [
      "astro-ph.CO",
      "cs.AI",
      "cs.LG"
    ],
    "published": "2025-10-23T17:56:04Z",
    "authors": [
      "Juan Alejandro Pinto Castro",
      "H\u00e9ctor J. Hort\u00faa",
      "Jorge Enrique Garc\u00eda-Farieta",
      "Roger Anderson Hurtado"
    ],
    "pdf_url": "http://arxiv.org/pdf/2510.20795v1"
  },
  {
    "id": "2510.20784v1",
    "title": "A Coherence-Based Measure of AGI",
    "abstract": "Recent work by \\citet{hendrycks2025agidefinition} formalized\n\\textit{Artificial General Intelligence} (AGI) as the arithmetic mean of\nproficiencies across cognitive domains derived from the Cattell--Horn--Carroll\n(CHC) model of human cognition. While elegant, this definition assumes\n\\textit{compensability} -- that exceptional ability in some domains can offset\nfailure in others. True general intelligence, however, should reflect\n\\textit{coherent sufficiency}: balanced competence across all essential\ndomains. We propose a coherence-aware measure of AGI based on the integral of\ngeneralized means over a continuum of compensability exponents. This\nformulation spans arithmetic, geometric, and harmonic regimes, and the\nresulting \\textit{area under the curve} (AUC) quantifies robustness under\nvarying compensability assumptions. Unlike the arithmetic mean, which rewards\nspecialization, the AUC penalizes imbalance and captures inter-domain\ndependency. Applied to published CHC-based domain scores for GPT-4 and GPT-5,\nthe coherence-adjusted AUC reveals that both systems remain far from general\ncompetence despite high arithmetic scores (e.g., GPT-5 at~24\\%). Integrating\nthe generalized mean thus yields a principled, interpretable, and stricter\nfoundation for measuring genuine progress toward AGI.",
    "categories": [
      "cs.AI",
      "cs.LG"
    ],
    "published": "2025-10-23T17:51:42Z",
    "authors": [
      "Fares Fourati"
    ],
    "pdf_url": "http://arxiv.org/pdf/2510.20784v1"
  },
  {
    "id": "2510.20782v1",
    "title": "A Use-Case Specific Dataset for Measuring Dimensions of Responsible\n  Performance in LLM-generated Text",
    "abstract": "Current methods for evaluating large language models (LLMs) typically focus\non high-level tasks such as text generation, without targeting a particular AI\napplication. This approach is not sufficient for evaluating LLMs for\nResponsible AI dimensions like fairness, since protected attributes that are\nhighly relevant in one application may be less relevant in another. In this\nwork, we construct a dataset that is driven by a real-world application\n(generate a plain-text product description, given a list of product features),\nparameterized by fairness attributes intersected with gendered adjectives and\nproduct categories, yielding a rich set of labeled prompts. We show how to use\nthe data to identify quality, veracity, safety, and fairness gaps in LLMs,\ncontributing a proposal for LLM evaluation paired with a concrete resource for\nthe research community.",
    "categories": [
      "cs.CL",
      "cs.AI",
      "I.2.7"
    ],
    "published": "2025-10-23T17:50:55Z",
    "authors": [
      "Alicia Sagae",
      "Chia-Jung Lee",
      "Sandeep Avula",
      "Brandon Dang",
      "Vanessa Murdock"
    ],
    "pdf_url": "http://arxiv.org/pdf/2510.20782v1"
  },
  {
    "id": "2510.20780v1",
    "title": "Are Large Reasoning Models Good Translation Evaluators? Analysis and\n  Performance Boost",
    "abstract": "Recent advancements in large reasoning models (LRMs) have introduced an\nintermediate \"thinking\" process prior to generating final answers, improving\ntheir reasoning capabilities on complex downstream tasks. However, the\npotential of LRMs as evaluators for machine translation (MT) quality remains\nunderexplored. We provides the first systematic analysis of LRM-as-a-judge in\nMT evaluation. We identify key challenges, revealing LRMs require tailored\nevaluation materials, tend to \"overthink\" simpler instances and have issues\nwith scoring mechanisms leading to overestimation. To address these, we propose\nto calibrate LRM thinking by training them on synthetic, human-like thinking\ntrajectories. Our experiments on WMT24 Metrics benchmarks demonstrate that this\napproach largely reduces thinking budgets by ~35x while concurrently improving\nevaluation performance across different LRM scales from 7B to 32B (e.g.,\nR1-Distill-Qwen-7B achieves a +8.7 correlation point improvement). These\nfindings highlight the potential of efficiently calibrated LRMs to advance\nfine-grained automatic MT evaluation.",
    "categories": [
      "cs.CL",
      "cs.AI"
    ],
    "published": "2025-10-23T17:48:36Z",
    "authors": [
      "Runzhe Zhan",
      "Zhihong Huang",
      "Xinyi Yang",
      "Lidia S. Chao",
      "Min Yang",
      "Derek F. Wong"
    ],
    "pdf_url": "http://arxiv.org/pdf/2510.20780v1"
  },
  {
    "id": "2510.20774v2",
    "title": "FieldGen: From Teleoperated Pre-Manipulation Trajectories to\n  Field-Guided Data Generation",
    "abstract": "Large-scale and diverse datasets are vital for training robust robotic\nmanipulation policies, yet existing data collection methods struggle to balance\nscale, diversity, and quality. Simulation offers scalability but suffers from\nsim-to-real gaps, while teleoperation yields high-quality demonstrations with\nlimited diversity and high labor cost. We introduce FieldGen, a field-guided\ndata generation framework that enables scalable, diverse, and high-quality\nreal-world data collection with minimal human supervision. FieldGen decomposes\nmanipulation into two stages: a pre-manipulation phase, allowing trajectory\ndiversity, and a fine manipulation phase requiring expert precision. Human\ndemonstrations capture key contact and pose information, after which an\nattraction field automatically generates diverse trajectories converging to\nsuccessful configurations. This decoupled design combines scalable trajectory\ndiversity with precise supervision. Moreover, FieldGen-Reward augments\ngenerated data with reward annotations to further enhance policy learning.\nExperiments demonstrate that policies trained with FieldGen achieve higher\nsuccess rates and improved stability compared to teleoperation-based baselines,\nwhile significantly reducing human effort in long-term real-world data\ncollection. Webpage is available at https://fieldgen.github.io/.",
    "categories": [
      "cs.RO",
      "cs.AI",
      "cs.HC"
    ],
    "published": "2025-10-23T17:47:12Z",
    "authors": [
      "Wenhao Wang",
      "Kehe Ye",
      "Xinyu Zhou",
      "Tianxing Chen",
      "Cao Min",
      "Qiaoming Zhu",
      "Xiaokang Yang",
      "Ping Luo",
      "Yongjian Shen",
      "Yang Yang",
      "Maoqing Yao",
      "Yao Mu"
    ],
    "pdf_url": "http://arxiv.org/pdf/2510.20774v2"
  },
  {
    "id": "2510.20768v1",
    "title": "RAGRank: Using PageRank to Counter Poisoning in CTI LLM Pipelines",
    "abstract": "Retrieval-Augmented Generation (RAG) has emerged as the dominant\narchitectural pattern to operationalize Large Language Model (LLM) usage in\nCyber Threat Intelligence (CTI) systems. However, this design is susceptible to\npoisoning attacks, and previously proposed defenses can fail for CTI contexts\nas cyber threat information is often completely new for emerging attacks, and\nsophisticated threat actors can mimic legitimate formats, terminology, and\nstylistic conventions. To address this issue, we propose that the robustness of\nmodern RAG defenses can be accelerated by applying source credibility\nalgorithms on corpora, using PageRank as an example. In our experiments, we\ndemonstrate quantitatively that our algorithm applies a lower authority score\nto malicious documents while promoting trusted content, using the standardized\nMS MARCO dataset. We also demonstrate proof-of-concept performance of our\nalgorithm on CTI documents and feeds.",
    "categories": [
      "cs.CR",
      "cs.AI",
      "cs.IR"
    ],
    "published": "2025-10-23T17:43:00Z",
    "authors": [
      "Austin Jia",
      "Avaneesh Ramesh",
      "Zain Shamsi",
      "Daniel Zhang",
      "Alex Liu"
    ],
    "pdf_url": "http://arxiv.org/pdf/2510.20768v1"
  },
  {
    "id": "2510.20748v1",
    "title": "Reinforcement Learning and Consumption-Savings Behavior",
    "abstract": "This paper demonstrates how reinforcement learning can explain two puzzling\nempirical patterns in household consumption behavior during economic downturns.\nI develop a model where agents use Q-learning with neural network approximation\nto make consumption-savings decisions under income uncertainty, departing from\nstandard rational expectations assumptions. The model replicates two key\nfindings from recent literature: (1) unemployed households with previously low\nliquid assets exhibit substantially higher marginal propensities to consume\n(MPCs) out of stimulus transfers compared to high-asset households (0.50 vs\n0.34), even when neither group faces borrowing constraints, consistent with\nGanong et al. (2024); and (2) households with more past unemployment\nexperiences maintain persistently lower consumption levels after controlling\nfor current economic conditions, a \"scarring\" effect documented by Malmendier\nand Shen (2024). Unlike existing explanations based on belief updating about\nincome risk or ex-ante heterogeneity, the reinforcement learning mechanism\ngenerates both higher MPCs and lower consumption levels simultaneously through\nvalue function approximation errors that evolve with experience. Simulation\nresults closely match the empirical estimates, suggesting that adaptive\nlearning through reinforcement learning provides a unifying framework for\nunderstanding how past experiences shape current consumption behavior beyond\nwhat current economic conditions would predict.",
    "categories": [
      "econ.GN",
      "cs.AI",
      "cs.LG",
      "q-fin.EC"
    ],
    "published": "2025-10-23T17:14:49Z",
    "authors": [
      "Brandon Kaplowitz"
    ],
    "pdf_url": "http://arxiv.org/pdf/2510.20748v1"
  },
  {
    "id": "2510.20743v1",
    "title": "Empathic Prompting: Non-Verbal Context Integration for Multimodal LLM\n  Conversations",
    "abstract": "We present Empathic Prompting, a novel framework for multimodal human-AI\ninteraction that enriches Large Language Model (LLM) conversations with\nimplicit non-verbal context. The system integrates a commercial facial\nexpression recognition service to capture users' emotional cues and embeds them\nas contextual signals during prompting. Unlike traditional multimodal\ninterfaces, empathic prompting requires no explicit user control; instead, it\nunobtrusively augments textual input with affective information for\nconversational and smoothness alignment. The architecture is modular and\nscalable, allowing integration of additional non-verbal modules. We describe\nthe system design, implemented through a locally deployed DeepSeek instance,\nand report a preliminary service and usability evaluation (N=5). Results show\nconsistent integration of non-verbal input into coherent LLM outputs, with\nparticipants highlighting conversational fluidity. Beyond this proof of\nconcept, empathic prompting points to applications in chatbot-mediated\ncommunication, particularly in domains like healthcare or education, where\nusers' emotional signals are critical yet often opaque in verbal exchanges.",
    "categories": [
      "cs.HC",
      "cs.AI",
      "cs.CL"
    ],
    "published": "2025-10-23T17:08:03Z",
    "authors": [
      "Lorenzo Stacchio",
      "Andrea Ubaldi",
      "Alessandro Galdelli",
      "Maurizio Mauri",
      "Emanuele Frontoni",
      "Andrea Gaggioli"
    ],
    "pdf_url": "http://arxiv.org/pdf/2510.20743v1"
  },
  {
    "id": "2510.24765v1",
    "title": "Topic-aware Large Language Models for Summarizing the Lived Healthcare\n  Experiences Described in Health Stories",
    "abstract": "Storytelling is a powerful form of communication and may provide insights\ninto factors contributing to gaps in healthcare outcomes. To determine whether\nLarge Language Models (LLMs) can identify potential underlying factors and\navenues for intervention, we performed topic-aware hierarchical summarization\nof narratives from African American (AA) storytellers. Fifty transcribed\nstories of AA experiences were used to identify topics in their experience\nusing the Latent Dirichlet Allocation (LDA) technique. Stories about a given\ntopic were summarized using an open-source LLM-based hierarchical summarization\napproach. Topic summaries were generated by summarizing across story summaries\nfor each story that addressed a given topic. Generated topic summaries were\nrated for fabrication, accuracy, comprehensiveness, and usefulness by the GPT4\nmodel, and the model's reliability was validated against the original story\nsummaries by two domain experts. 26 topics were identified in the fifty AA\nstories. The GPT4 ratings suggest that topic summaries were free from\nfabrication, highly accurate, comprehensive, and useful. The reliability of GPT\nratings compared to expert assessments showed moderate to high agreement. Our\napproach identified AA experience-relevant topics such as health behaviors,\ninteractions with medical team members, caregiving and symptom management,\namong others. Such insights could help researchers identify potential factors\nand interventions by learning from unstructured narratives in an efficient\nmanner-leveraging the communicative power of storytelling. The use of LDA and\nLLMs to identify and summarize the experience of AA individuals suggests a\nvariety of possible avenues for health research and possible clinical\nimprovements to support patients and caregivers, thereby ultimately improving\nhealth outcomes.",
    "categories": [
      "cs.CY",
      "cs.AI",
      "cs.CL"
    ],
    "published": "2025-10-23T16:52:00Z",
    "authors": [
      "Maneesh Bilalpur",
      "Megan Hamm",
      "Young Ji Lee",
      "Natasha Norman",
      "Kathleen M. McTigue",
      "Yanshan Wang"
    ],
    "pdf_url": "http://arxiv.org/pdf/2510.24765v1"
  },
  {
    "id": "2510.20733v1",
    "title": "Thought Communication in Multiagent Collaboration",
    "abstract": "Natural language has long enabled human cooperation, but its lossy,\nambiguous, and indirect nature limits the potential of collective intelligence.\nWhile machines are not subject to these constraints, most LLM-based multi-agent\nsystems still rely solely on natural language, exchanging tokens or their\nembeddings. To go beyond language, we introduce a new paradigm, thought\ncommunication, which enables agents to interact directly mind-to-mind, akin to\ntelepathy. To uncover these latent thoughts in a principled way, we formalize\nthe process as a general latent variable model, where agent states are\ngenerated by an unknown function of underlying thoughts. We prove that, in a\nnonparametric setting without auxiliary information, both shared and private\nlatent thoughts between any pair of agents can be identified. Moreover, the\nglobal structure of thought sharing, including which agents share which\nthoughts and how these relationships are structured, can also be recovered with\ntheoretical guarantees. Guided by the established theory, we develop a\nframework that extracts latent thoughts from all agents prior to communication\nand assigns each agent the relevant thoughts, along with their sharing\npatterns. This paradigm naturally extends beyond LLMs to all modalities, as\nmost observational data arise from hidden generative processes. Experiments on\nboth synthetic and real-world benchmarks validate the theory and demonstrate\nthe collaborative advantages of thought communication. We hope this work\nilluminates the potential of leveraging the hidden world, as many challenges\nremain unsolvable through surface-level observation alone, regardless of\ncompute or data scale.",
    "categories": [
      "cs.LG",
      "cs.AI",
      "cs.MA"
    ],
    "published": "2025-10-23T16:48:02Z",
    "authors": [
      "Yujia Zheng",
      "Zhuokai Zhao",
      "Zijian Li",
      "Yaqi Xie",
      "Mingze Gao",
      "Lizhu Zhang",
      "Kun Zhang"
    ],
    "pdf_url": "http://arxiv.org/pdf/2510.20733v1"
  },
  {
    "id": "2510.20728v1",
    "title": "Co-Designing Quantum Codes with Transversal Diagonal Gates via\n  Multi-Agent Systems",
    "abstract": "We present a multi-agent, human-in-the-loop workflow that co-designs quantum\ncodes with prescribed transversal diagonal gates. It builds on the Subset-Sum\nLinear Programming (SSLP) framework (arXiv:2504.20847), which partitions basis\nstrings by modular residues and enforces $Z$-marginal Knill-Laflamme (KL)\nequalities via small LPs. The workflow is powered by GPT-5 and implemented\nwithin TeXRA (https://texra.ai)-a multi-agent research assistant platform that\nsupports an iterative tool-use loop agent and a derivation-then-edit workflow\nreasoning agent. We work in a LaTeX-Python environment where agents reason,\nedit documents, execute code, and synchronize their work to Git/Overleaf.\nWithin this workspace, three roles collaborate: a Synthesis Agent formulates\nthe problem; a Search Agent sweeps/screens candidates and exactifies numerics\ninto rationals; and an Audit Agent independently checks all KL equalities and\nthe induced logical action. As a first step we focus on distance $d=2$ with\nnondegenerate residues. For code dimension $K\\in\\{2,3,4\\}$ and $n\\le6$ qubits,\nsystematic sweeps yield certificate-backed tables cataloging attainable cyclic\nlogical groups-all realized by new codes-e.g., for $K=3$ we obtain order $16$\nat $n=6$. From verified instances, Synthesis Agent abstracts recurring\nstructures into closed-form families and proves they satisfy the KL equalities\nfor all parameters. It further demonstrates that SSLP accommodates residue\ndegeneracy by exhibiting a new $((6,4,2))$ code implementing the transversal\ncontrolled-phase $diag(1,1,1,i)$. Overall, the workflow recasts\ndiagonal-transversal feasibility as an analytical pipeline executed at scale,\ncombining systematic enumeration with exact analytical reconstruction. It\nyields reproducible code constructions, supports targeted extensions to larger\n$K$ and higher distances, and leads toward data-driven classification.",
    "categories": [
      "quant-ph",
      "cs.AI",
      "cs.CL",
      "math-ph",
      "math.MP"
    ],
    "published": "2025-10-23T16:45:39Z",
    "authors": [
      "Xi He",
      "Sirui Lu",
      "Bei Zeng"
    ],
    "pdf_url": "http://arxiv.org/pdf/2510.20728v1"
  },
  {
    "id": "2510.20727v1",
    "title": "Automated Extraction of Fluoropyrimidine Treatment and Treatment-Related\n  Toxicities from Clinical Notes Using Natural Language Processing",
    "abstract": "Objective: Fluoropyrimidines are widely prescribed for colorectal and breast\ncancers, but are associated with toxicities such as hand-foot syndrome and\ncardiotoxicity. Since toxicity documentation is often embedded in clinical\nnotes, we aimed to develop and evaluate natural language processing (NLP)\nmethods to extract treatment and toxicity information.\n  Materials and Methods: We constructed a gold-standard dataset of 236 clinical\nnotes from 204,165 adult oncology patients. Domain experts annotated categories\nrelated to treatment regimens and toxicities. We developed rule-based, machine\nlearning-based (Random Forest, Support Vector Machine [SVM], Logistic\nRegression [LR]), deep learning-based (BERT, ClinicalBERT), and large language\nmodels (LLM)-based NLP approaches (zero-shot and error-analysis prompting).\nModels used an 80:20 train-test split.\n  Results: Sufficient data existed to train and evaluate 5 annotated\ncategories. Error-analysis prompting achieved optimal precision, recall, and F1\nscores (F1=1.000) for treatment and toxicities extraction, whereas zero-shot\nprompting reached F1=1.000 for treatment and F1=0.876 for toxicities\nextraction.LR and SVM ranked second for toxicities (F1=0.937). Deep learning\nunderperformed, with BERT (F1=0.873 treatment; F1= 0.839 toxicities) and\nClinicalBERT (F1=0.873 treatment; F1 = 0.886 toxicities). Rule-based methods\nserved as our baseline with F1 scores of 0.857 in treatment and 0.858 in\ntoxicities.\n  Discussion: LMM-based approaches outperformed all others, followed by machine\nlearning methods. Machine and deep learning approaches were limited by small\ntraining data and showed limited generalizability, particularly for rare\ncategories.\n  Conclusion: LLM-based NLP most effectively extracted fluoropyrimidine\ntreatment and toxicity information from clinical notes, and has strong\npotential to support oncology research and pharmacovigilance.",
    "categories": [
      "cs.CL",
      "cs.AI"
    ],
    "published": "2025-10-23T16:44:39Z",
    "authors": [
      "Xizhi Wu",
      "Madeline S. Kreider",
      "Philip E. Empey",
      "Chenyu Li",
      "Yanshan Wang"
    ],
    "pdf_url": "http://arxiv.org/pdf/2510.20727v1"
  },
  {
    "id": "2510.21881v1",
    "title": "GeoThought: A Dataset for Enhancing Mathematical Geometry Reasoning in\n  Vision-Language Models",
    "abstract": "Large language models (LLMs) have demonstrated strong reasoning capabilities\nin text-based mathematical problem solving; however, when adapted to visual\nreasoning tasks, particularly geometric problem solving, their performance\nsubstantially declines because geometric problems present unique challenges.\nSpecifically, these challenges stem from two key factors: first, the intrinsic\ncomplexity of geometry requiring detailed image comprehension and multi-step\nreasoning, and second, the limitations of existing datasets which lack\nsufficient scale, diversity, and explicit reasoning traces, consequently\nhindering effective model training. To address these challenges, we developed\nthe GeoThoughts dataset, a comprehensive geometric reasoning corpus with two\nsubsets: Geo-Thought-6K with 6,243 samples and its augmented version\nGeo-Thought-Augmented-10K containing 10,834 samples. Each entry includes visual\ndescriptions, step-by-step solutions, explicit reasoning chains, reflection\nsteps, and final answers. Using this dataset, we developed GeoThought-MLLM, a\nmathematical reasoning multimodal model that generates detailed thinking\nprocesses during problem-solving. Our model outperforms existing benchmarks in\ngeometric tasks, demonstrating that training with our Chain-of-Thought dataset\nimproves geometric reasoning capabilities across both in-domain and\nout-of-domain settings. Finally, we analyze failure cases and observe that\nerrors primarily arise from incorrect interpretation of mathematical concepts\nor spatial misjudgment. By invoking CoT to correct these mistakes, the model\nproduces correct answers.",
    "categories": [
      "cs.AI",
      "cs.CL"
    ],
    "published": "2025-10-23T16:43:54Z",
    "authors": [
      "Nannan Shi",
      "Chuanyu Qin",
      "Shipeng Song",
      "Man Luo"
    ],
    "pdf_url": "http://arxiv.org/pdf/2510.21881v1"
  },
  {
    "id": "2510.20721v1",
    "title": "User Perceptions of Privacy and Helpfulness in LLM Responses to\n  Privacy-Sensitive Scenarios",
    "abstract": "Large language models (LLMs) have seen rapid adoption for tasks such as\ndrafting emails, summarizing meetings, and answering health questions. In such\nuses, users may need to share private information (e.g., health records,\ncontact details). To evaluate LLMs' ability to identify and redact such private\ninformation, prior work developed benchmarks (e.g., ConfAIde, PrivacyLens) with\nreal-life scenarios. Using these benchmarks, researchers have found that LLMs\nsometimes fail to keep secrets private when responding to complex tasks (e.g.,\nleaking employee salaries in meeting summaries). However, these evaluations\nrely on LLMs (proxy LLMs) to gauge compliance with privacy norms, overlooking\nreal users' perceptions. Moreover, prior work primarily focused on the\nprivacy-preservation quality of responses, without investigating nuanced\ndifferences in helpfulness. To understand how users perceive the\nprivacy-preservation quality and helpfulness of LLM responses to\nprivacy-sensitive scenarios, we conducted a user study with 94 participants\nusing 90 scenarios from PrivacyLens. We found that, when evaluating identical\nresponses to the same scenario, users showed low agreement with each other on\nthe privacy-preservation quality and helpfulness of the LLM response. Further,\nwe found high agreement among five proxy LLMs, while each individual LLM had\nlow correlation with users' evaluations. These results indicate that the\nprivacy and helpfulness of LLM responses are often specific to individuals, and\nproxy LLMs are poor estimates of how real users would perceive these responses\nin privacy-sensitive scenarios. Our results suggest the need to conduct\nuser-centered studies on measuring LLMs' ability to help users while preserving\nprivacy. Additionally, future research could investigate ways to improve the\nalignment between proxy LLMs and users for better estimation of users'\nperceived privacy and utility.",
    "categories": [
      "cs.CL",
      "cs.AI",
      "cs.HC"
    ],
    "published": "2025-10-23T16:38:26Z",
    "authors": [
      "Xiaoyuan Wu",
      "Roshni Kaushik",
      "Wenkai Li",
      "Lujo Bauer",
      "Koichi Onoue"
    ],
    "pdf_url": "http://arxiv.org/pdf/2510.20721v1"
  },
  {
    "id": "2510.20718v1",
    "title": "Unsupervised Anomaly Prediction with N-BEATS and Graph Neural Network in\n  Multi-variate Semiconductor Process Time Series",
    "abstract": "Semiconductor manufacturing is an extremely complex and precision-driven\nprocess, characterized by thousands of interdependent parameters collected\nacross diverse tools and process steps. Multi-variate time-series analysis has\nemerged as a critical field for real-time monitoring and fault detection in\nsuch environments. However, anomaly prediction in semiconductor fabrication\npresents several critical challenges, including high dimensionality of sensor\ndata and severe class imbalance due to the rarity of true faults. Furthermore,\nthe complex interdependencies between variables complicate both anomaly\nprediction and root-cause-analysis. This paper proposes two novel approaches to\nadvance the field from anomaly detection to anomaly prediction, an essential\nstep toward enabling real-time process correction and proactive fault\nprevention. The proposed anomaly prediction framework contains two main stages:\n(a) training a forecasting model on a dataset assumed to contain no anomalies,\nand (b) performing forecast on unseen time series data. The forecast is\ncompared with the forecast of the trained signal. Deviations beyond a\npredefined threshold are flagged as anomalies. The two approaches differ in the\nforecasting model employed. The first assumes independence between variables by\nutilizing the N-BEATS model for univariate time series forecasting. The second\nlifts this assumption by utilizing a Graph Neural Network (GNN) to capture\ninter-variable relationships. Both models demonstrate strong forecasting\nperformance up to a horizon of 20 time points and maintain stable anomaly\nprediction up to 50 time points. The GNN consistently outperforms the N-BEATS\nmodel while requiring significantly fewer trainable parameters and lower\ncomputational cost. These results position the GNN as promising solution for\nonline anomaly forecasting to be deployed in manufacturing environments.",
    "categories": [
      "cs.LG",
      "cs.AI",
      "I.2.0; J.6"
    ],
    "published": "2025-10-23T16:33:52Z",
    "authors": [
      "Daniel Sorensen",
      "Bappaditya Dey",
      "Minjin Hwang",
      "Sandip Halder"
    ],
    "pdf_url": "http://arxiv.org/pdf/2510.20718v1"
  },
  {
    "id": "2510.20706v2",
    "title": "Real-Time Gait Adaptation for Quadrupeds using Model Predictive Control\n  and Reinforcement Learning",
    "abstract": "Model-free reinforcement learning (RL) has enabled adaptable and agile\nquadruped locomotion; however, policies often converge to a single gait,\nleading to suboptimal performance. Traditionally, Model Predictive Control\n(MPC) has been extensively used to obtain task-specific optimal policies but\nlacks the ability to adapt to varying environments. To address these\nlimitations, we propose an optimization framework for real-time gait adaptation\nin a continuous gait space, combining the Model Predictive Path Integral (MPPI)\nalgorithm with a Dreamer module to produce adaptive and optimal policies for\nquadruped locomotion. At each time step, MPPI jointly optimizes the actions and\ngait variables using a learned Dreamer reward that promotes velocity tracking,\nenergy efficiency, stability, and smooth transitions, while penalizing abrupt\ngait changes. A learned value function is incorporated as terminal reward,\nextending the formulation to an infinite-horizon planner. We evaluate our\nframework in simulation on the Unitree Go1, demonstrating an average reduction\nof up to 36.48 % in energy consumption across varying target speeds, while\nmaintaining accurate tracking and adaptive, task-appropriate gaits.",
    "categories": [
      "cs.RO",
      "cs.AI"
    ],
    "published": "2025-10-23T16:17:45Z",
    "authors": [
      "Prakrut Kotecha",
      "Ganga Nair B",
      "Shishir Kolathaya"
    ],
    "pdf_url": "http://arxiv.org/pdf/2510.20706v2"
  },
  {
    "id": "2510.20699v1",
    "title": "Fusing Narrative Semantics for Financial Volatility Forecasting",
    "abstract": "We introduce M2VN: Multi-Modal Volatility Network, a novel deep\nlearning-based framework for financial volatility forecasting that unifies time\nseries features with unstructured news data. M2VN leverages the\nrepresentational power of deep neural networks to address two key challenges in\nthis domain: (i) aligning and fusing heterogeneous data modalities, numerical\nfinancial data and textual information, and (ii) mitigating look-ahead bias\nthat can undermine the validity of financial models. To achieve this, M2VN\ncombines open-source market features with news embeddings generated by Time\nMachine GPT, a recently introduced point-in-time LLM, ensuring temporal\nintegrity. An auxiliary alignment loss is introduced to enhance the integration\nof structured and unstructured data within the deep learning architecture.\nExtensive experiments demonstrate that M2VN consistently outperforms existing\nbaselines, underscoring its practical value for risk management and financial\ndecision-making in dynamic markets.",
    "categories": [
      "q-fin.CP",
      "cs.AI"
    ],
    "published": "2025-10-23T16:13:46Z",
    "authors": [
      "Yaxuan Kong",
      "Yoontae Hwang",
      "Marcus Kaiser",
      "Chris Vryonides",
      "Roel Oomen",
      "Stefan Zohren"
    ],
    "pdf_url": "http://arxiv.org/pdf/2510.20699v1"
  },
  {
    "id": "2510.20692v1",
    "title": "Exploring Large Language Models for Access Control Policy Synthesis and\n  Summarization",
    "abstract": "Cloud computing is ubiquitous, with a growing number of services being hosted\non the cloud every day. Typical cloud compute systems allow administrators to\nwrite policies implementing access control rules which specify how access to\nprivate data is governed. These policies must be manually written, and due to\ntheir complexity can often be error prone. Moreover, existing policies often\nimplement complex access control specifications and thus can be difficult to\nprecisely analyze in determining their behavior works exactly as intended.\nRecently, Large Language Models (LLMs) have shown great success in automated\ncode synthesis and summarization. Given this success, they could potentially be\nused for automatically generating access control policies or aid in\nunderstanding existing policies. In this paper, we explore the effectiveness of\nLLMs for access control policy synthesis and summarization. Specifically, we\nfirst investigate diverse LLMs for access control policy synthesis, finding\nthat: although LLMs can effectively generate syntactically correct policies,\nthey have permissiveness issues, generating policies equivalent to the given\nspecification 45.8% of the time for non-reasoning LLMs, and 93.7% of the time\nfor reasoning LLMs. We then investigate how LLMs can be used to analyze\npolicies by introducing a novel semantic-based request summarization approach\nwhich leverages LLMs to generate a precise characterization of the requests\nallowed by a policy. Our results show that while there are significant hurdles\nin leveraging LLMs for automated policy generation, LLMs show promising results\nwhen combined with symbolic approaches in analyzing existing policies.",
    "categories": [
      "cs.SE",
      "cs.AI",
      "cs.FL",
      "D.4.6; D.2.4; I.2.2; I.2.7; F.3.1; F.4.3"
    ],
    "published": "2025-10-23T16:06:15Z",
    "authors": [
      "Adarsh Vatsa",
      "Bethel Hall",
      "William Eiers"
    ],
    "pdf_url": "http://arxiv.org/pdf/2510.20692v1"
  },
  {
    "id": "2510.20691v2",
    "title": "Plan Then Retrieve: Reinforcement Learning-Guided Complex Reasoning over\n  Knowledge Graphs",
    "abstract": "Knowledge Graph Question Answering aims to answer natural language questions\nby reasoning over structured knowledge graphs. While large language models have\nadvanced KGQA through their strong reasoning capabilities, existing methods\ncontinue to struggle to fully exploit both the rich knowledge encoded in KGs\nand the reasoning capabilities of LLMs, particularly in complex scenarios. They\noften assume complete KG coverage and lack mechanisms to judge when external\ninformation is needed, and their reasoning remains locally myopic, failing to\nmaintain coherent multi-step planning, leading to reasoning failures even when\nrelevant knowledge exists. We propose Graph-RFT, a novel two-stage\nreinforcement fine-tuning KGQA framework with a\n'plan-KGsearch-and-Websearch-during-think' paradigm, that enables LLMs to\nperform autonomous planning and adaptive retrieval scheduling across KG and web\nsources under incomplete knowledge conditions. Graph-RFT introduces a\nchain-of-thought fine-tuning method with a customized plan-retrieval dataset\nactivates structured reasoning and resolves the GRPO cold-start problem. It\nthen introduces a novel plan-retrieval guided reinforcement learning process\nintegrates explicit planning and retrieval actions with a multi-reward design,\nenabling coverage-aware retrieval scheduling. It employs a Cartesian-inspired\nplanning module to decompose complex questions into ordered subquestions, and\nlogical expression to guide tool invocation for globally consistent multi-step\nreasoning. This reasoning retrieval process is optimized with a multi-reward\ncombining outcome and retrieval specific signals, enabling the model to learn\nwhen and how to combine KG and web retrieval effectively.",
    "categories": [
      "cs.AI"
    ],
    "published": "2025-10-23T16:04:13Z",
    "authors": [
      "Yanlin Song",
      "Ben Liu",
      "V\u00edctor Guti\u00e9rrez-Basulto",
      "Zhiwei Hu",
      "Qianqian Xie",
      "Min Peng",
      "Sophia Ananiadou",
      "Jeff Z. Pan"
    ],
    "pdf_url": "http://arxiv.org/pdf/2510.20691v2"
  },
  {
    "id": "2510.20690v1",
    "title": "Neural Diversity Regularizes Hallucinations in Small Models",
    "abstract": "Language models continue to hallucinate despite increases in parameters,\ncompute, and data. We propose neural diversity -- decorrelated parallel\nrepresentations -- as a principled mechanism that reduces hallucination rates\nat fixed parameter and data budgets. Inspired by portfolio theory, where\nuncorrelated assets reduce risk by $\\sqrt{P}$, we prove hallucination\nprobability is bounded by representational correlation: $P(H) \\leq\nf(\\sigma^2((1-\\rho(P))/P + \\rho(P)), \\mu^2)$, which predicts that language\nmodels need an optimal amount of neurodiversity. To validate this, we introduce\nND-LoRA (Neural Diversity Low-Rank Adaptation), combining parallel LoRA\nadapters with Barlow Twins regularization, and demonstrate that ND-LoRA reduces\nhallucinations by up to 25.6% (and 14.6% on average) without degrading general\naccuracy. Ablations show LoRA adapters and regularization act synergistically,\ncausal interventions prove neurodiversity as the mediating factor and\ncorrelational analyses indicate scale: a 0.1% neural correlation increase is\nassociated with a 3.8% hallucination increase. Finally, task-dependent\noptimality emerges: different tasks require different amounts of optimal\nneurodiversity. Together, our results highlight neural diversity as a third\naxis of scaling -- orthogonal to parameters and data -- to improve the\nreliability of language models at fixed budgets.",
    "categories": [
      "cs.CL",
      "cs.AI",
      "cs.LG"
    ],
    "published": "2025-10-23T16:03:07Z",
    "authors": [
      "Kushal Chakrabarti",
      "Nirmal Balachundhar"
    ],
    "pdf_url": "http://arxiv.org/pdf/2510.20690v1"
  },
  {
    "id": "2510.20683v1",
    "title": "A Scalable, Causal, and Energy Efficient Framework for Neural Decoding\n  with Spiking Neural Networks",
    "abstract": "Brain-computer interfaces (BCIs) promise to enable vital functions, such as\nspeech and prosthetic control, for individuals with neuromotor impairments.\nCentral to their success are neural decoders, models that map neural activity\nto intended behavior. Current learning-based decoding approaches fall into two\nclasses: simple, causal models that lack generalization, or complex, non-causal\nmodels that generalize and scale offline but struggle in real-time settings.\nBoth face a common challenge, their reliance on power-hungry artificial neural\nnetwork backbones, which makes integration into real-world, resource-limited\nsystems difficult. Spiking neural networks (SNNs) offer a promising\nalternative. Because they operate causally these models are suitable for\nreal-time use, and their low energy demands make them ideal for\nbattery-constrained environments. To this end, we introduce Spikachu: a\nscalable, causal, and energy-efficient neural decoding framework based on SNNs.\nOur approach processes binned spikes directly by projecting them into a shared\nlatent space, where spiking modules, adapted to the timing of the input,\nextract relevant features; these latent representations are then integrated and\ndecoded to generate behavioral predictions. We evaluate our approach on 113\nrecording sessions from 6 non-human primates, totaling 43 hours of recordings.\nOur method outperforms causal baselines when trained on single sessions using\nbetween 2.26 and 418.81 times less energy. Furthermore, we demonstrate that\nscaling up training to multiple sessions and subjects improves performance and\nenables few-shot transfer to unseen sessions, subjects, and tasks. Overall,\nSpikachu introduces a scalable, online-compatible neural decoding framework\nbased on SNNs, whose performance is competitive relative to state-of-the-art\nmodels while consuming orders of magnitude less energy.",
    "categories": [
      "cs.LG",
      "cs.AI"
    ],
    "published": "2025-10-23T15:55:45Z",
    "authors": [
      "Georgios Mentzelopoulos",
      "Ioannis Asmanis",
      "Konrad P. Kording",
      "Eva L. Dyer",
      "Kostas Daniilidis",
      "Flavia Vitale"
    ],
    "pdf_url": "http://arxiv.org/pdf/2510.20683v1"
  },
  {
    "id": "2510.20677v1",
    "title": "R2-SVC: Towards Real-World Robust and Expressive Zero-shot Singing Voice\n  Conversion",
    "abstract": "In real-world singing voice conversion (SVC) applications, environmental\nnoise and the demand for expressive output pose significant challenges.\nConventional methods, however, are typically designed without accounting for\nreal deployment scenarios, as both training and inference usually rely on clean\ndata. This mismatch hinders practical use, given the inevitable presence of\ndiverse noise sources and artifacts from music separation. To tackle these\nissues, we propose R2-SVC, a robust and expressive SVC framework. First, we\nintroduce simulation-based robustness enhancement through random fundamental\nfrequency ($F_0$) perturbations and music separation artifact simulations\n(e.g., reverberation, echo), substantially improving performance under noisy\nconditions. Second, we enrich speaker representation using domain-specific\nsinging data: alongside clean vocals, we incorporate DNSMOS-filtered separated\nvocals and public singing corpora, enabling the model to preserve speaker\ntimbre while capturing singing style nuances. Third, we integrate the Neural\nSource-Filter (NSF) model to explicitly represent harmonic and noise\ncomponents, enhancing the naturalness and controllability of converted singing.\nR2-SVC achieves state-of-the-art results on multiple SVC benchmarks under both\nclean and noisy conditions.",
    "categories": [
      "cs.SD",
      "cs.AI",
      "eess.AS"
    ],
    "published": "2025-10-23T15:52:03Z",
    "authors": [
      "Junjie Zheng",
      "Gongyu Chen",
      "Chaofan Ding",
      "Zihao Chen"
    ],
    "pdf_url": "http://arxiv.org/pdf/2510.20677v1"
  },
  {
    "id": "2510.20671v1",
    "title": "GRACE: GRaph-based Addiction Care prEdiction",
    "abstract": "Determining the appropriate locus of care for addiction patients is one of\nthe most critical clinical decisions that affects patient treatment outcomes\nand effective use of resources. With a lack of sufficient specialized treatment\nresources, such as inpatient beds or staff, there is an unmet need to develop\nan automated framework for the same. Current decision-making approaches suffer\nfrom severe class imbalances in addiction datasets. To address this limitation,\nwe propose a novel graph neural network (GRACE) framework that formalizes locus\nof care prediction as a structured learning problem. Further, we perform\nextensive feature engineering and propose a new approach of obtaining an\nunbiased meta-graph to train a GNN to overcome the class imbalance problem.\nExperimental results in real-world data show an improvement of 11-35% in terms\nof the F1 score of the minority class over competitive baselines. The codes and\nnote embeddings are available at https://anonymous.4open.science/r/GRACE-F8E1/.",
    "categories": [
      "cs.LG",
      "cs.AI"
    ],
    "published": "2025-10-23T15:48:01Z",
    "authors": [
      "Subham Kumar",
      "Prakrithi Shivaprakash",
      "Koustav Rudra",
      "Lekhansh Shukla",
      "Animesh Mukherjee"
    ],
    "pdf_url": "http://arxiv.org/pdf/2510.20671v1"
  },
  {
    "id": "2510.20665v1",
    "title": "The Shape of Reasoning: Topological Analysis of Reasoning Traces in\n  Large Language Models",
    "abstract": "Evaluating the quality of reasoning traces from large language models remains\nunderstudied, labor-intensive, and unreliable: current practice relies on\nexpert rubrics, manual annotation, and slow pairwise judgments. Automated\nefforts are dominated by graph-based proxies that quantify structural\nconnectivity but do not clarify what constitutes high-quality reasoning; such\nabstractions can be overly simplistic for inherently complex processes. We\nintroduce a topological data analysis (TDA)-based evaluation framework that\ncaptures the geometry of reasoning traces and enables label-efficient,\nautomated assessment. In our empirical study, topological features yield\nsubstantially higher predictive power for assessing reasoning quality than\nstandard graph metrics, suggesting that effective reasoning is better captured\nby higher-dimensional geometric structures rather than purely relational\ngraphs. We further show that a compact, stable set of topological features\nreliably indicates trace quality, offering a practical signal for future\nreinforcement learning algorithms.",
    "categories": [
      "cs.AI"
    ],
    "published": "2025-10-23T15:43:43Z",
    "authors": [
      "Xue Wen Tan",
      "Nathaniel Tan",
      "Galen Lee",
      "Stanley Kok"
    ],
    "pdf_url": "http://arxiv.org/pdf/2510.20665v1"
  },
  {
    "id": "2510.20653v1",
    "title": "Finding the Sweet Spot: Trading Quality, Cost, and Speed During\n  Inference-Time LLM Reflection",
    "abstract": "As Large Language Models (LLMs) continue to evolve, practitioners face\nincreasing options for enhancing inference-time performance without model\nretraining, including budget tuning and multi-step techniques like\nself-reflection. While these methods improve output quality, they create\ncomplex trade-offs among accuracy, cost, and latency that remain poorly\nunderstood across different domains. This paper systematically compares\nself-reflection and budget tuning across mathematical reasoning and translation\ntasks. We evaluate prominent LLMs, including Anthropic Claude, Amazon Nova, and\nMistral families, along with other models under varying reflection depths and\ncompute budgets to derive Pareto optimal performance frontiers. Our analysis\nreveals substantial domain dependent variation in self-reflection\neffectiveness, with performance gains up to 220\\% in mathematical reasoning. We\nfurther investigate how reflection round depth and feedback mechanism quality\ninfluence performance across model families. To validate our findings in a\nreal-world setting, we deploy a self-reflection enhanced marketing content\nlocalisation system at Lounge by Zalando, where it shows market-dependent\neffectiveness, reinforcing the importance of domain specific evaluation when\ndeploying these techniques. Our results provide actionable guidance for\nselecting optimal inference strategies given specific domains and resource\nconstraints. We open source our self-reflection implementation for\nreproducibility at\nhttps://github.com/aws-samples/sample-genai-reflection-for-bedrock.",
    "categories": [
      "stat.ML",
      "cs.AI",
      "cs.LG"
    ],
    "published": "2025-10-23T15:26:18Z",
    "authors": [
      "Jack Butler",
      "Nikita Kozodoi",
      "Zainab Afolabi",
      "Brian Tyacke",
      "Gaiar Baimuratov"
    ],
    "pdf_url": "http://arxiv.org/pdf/2510.20653v1"
  },
  {
    "id": "2510.20647v1",
    "title": "The Reasoning Lingua Franca: A Double-Edged Sword for Multilingual AI",
    "abstract": "Large Reasoning Models (LRMs) achieve strong performance on mathematical,\nscientific, and other question-answering tasks, but their multilingual\nreasoning abilities remain underexplored. When presented with non-English\nquestions, LRMs often default to reasoning in English, raising concerns about\ninterpretability and the handling of linguistic and cultural nuances. We\nsystematically compare an LRM's reasoning in English versus the language of the\nquestion. Our evaluation spans two tasks: MGSM and GPQA Diamond. Beyond\nmeasuring answer accuracy, we also analyze cognitive attributes in the\nreasoning traces. We find that English reasoning traces exhibit a substantially\nhigher presence of these cognitive behaviors, and that reasoning in English\ngenerally yields higher final-answer accuracy, with the performance gap\nincreasing as tasks become more complex. However, this English-centric strategy\nis susceptible to a key failure mode - getting \"Lost in Translation,\" where\ntranslation steps lead to errors that would have been avoided by question's\nlanguage reasoning.",
    "categories": [
      "cs.CL",
      "cs.AI"
    ],
    "published": "2025-10-23T15:22:00Z",
    "authors": [
      "Alan Saji",
      "Raj Dabre",
      "Anoop Kunchukuttan",
      "Ratish Puduppully"
    ],
    "pdf_url": "http://arxiv.org/pdf/2510.20647v1"
  },
  {
    "id": "2510.20641v1",
    "title": "Integrating Machine Learning into Belief-Desire-Intention Agents:\n  Current Advances and Open Challenges",
    "abstract": "Thanks to the remarkable human-like capabilities of machine learning (ML)\nmodels in perceptual and cognitive tasks, frameworks integrating ML within\nrational agent architectures are gaining traction. Yet, the landscape remains\nfragmented and incoherent, often focusing on embedding ML into generic agent\ncontainers while overlooking the expressive power of rational\narchitectures--such as Belief-Desire-Intention (BDI) agents. This paper\npresents a fine-grained systematisation of existing approaches, using the BDI\nparadigm as a reference. Our analysis illustrates the fast-evolving literature\non rational agents enhanced by ML, and identifies key research opportunities\nand open challenges for designing effective rational ML agents.",
    "categories": [
      "cs.AI"
    ],
    "published": "2025-10-23T15:15:45Z",
    "authors": [
      "Andrea Agiollo",
      "Andrea Omicini"
    ],
    "pdf_url": "http://arxiv.org/pdf/2510.20641v1"
  },
  {
    "id": "2510.20636v1",
    "title": "Fluidity Index: Next-Generation Super-intelligence Benchmarks",
    "abstract": "This paper introduces the Fluidity Index (FI) to quantify model adaptability\nin dynamic, scaling environments. The benchmark evaluates response accuracy\nbased on deviations in initial, current, and future environment states,\nassessing context switching and continuity. We distinguish between closed-ended\nand open-ended benchmarks, prioritizing closed-loop open-ended real-world\nbenchmarks to test adaptability. The approach measures a model's ability to\nunderstand, predict, and adjust to state changes in scaling environments. A\ntruly super-intelligent model should exhibit at least second-order\nadaptability, enabling self-sustained computation through digital replenishment\nfor optimal fluidity.",
    "categories": [
      "cs.AI"
    ],
    "published": "2025-10-23T15:05:23Z",
    "authors": [
      "Eric Ngoiya",
      "Tianshu Bao"
    ],
    "pdf_url": "http://arxiv.org/pdf/2510.20636v1"
  },
  {
    "id": "2510.20635v1",
    "title": "Why Did Apple Fall To The Ground: Evaluating Curiosity In Large Language\n  Model",
    "abstract": "Curiosity serves as a pivotal conduit for human beings to discover and learn\nnew knowledge. Recent advancements of large language models (LLMs) in natural\nlanguage processing have sparked discussions regarding whether these models\npossess capability of curiosity-driven learning akin to humans. In this paper,\nstarting from the human curiosity assessment questionnaire Five-Dimensional\nCuriosity scale Revised (5DCR), we design a comprehensive evaluation framework\nthat covers dimensions such as Information Seeking, Thrill Seeking, and Social\nCuriosity to assess the extent of curiosity exhibited by LLMs. The results\ndemonstrate that LLMs exhibit a stronger thirst for knowledge than humans but\nstill tend to make conservative choices when faced with uncertain environments.\nWe further investigated the relationship between curiosity and thinking of\nLLMs, confirming that curious behaviors can enhance the model's reasoning and\nactive learning abilities. These findings suggest that LLMs have the potential\nto exhibit curiosity similar to that of humans, providing experimental support\nfor the future development of learning capabilities and innovative research in\nLLMs.",
    "categories": [
      "cs.CL",
      "cs.AI"
    ],
    "published": "2025-10-23T15:05:17Z",
    "authors": [
      "Haoyu Wang",
      "Sihang Jiang",
      "Yuyan Chen",
      "Yitong Wang",
      "Yanghua Xiao"
    ],
    "pdf_url": "http://arxiv.org/pdf/2510.20635v1"
  },
  {
    "id": "2510.20634v1",
    "title": "Deep Learning in Dental Image Analysis: A Systematic Review of Datasets,\n  Methodologies, and Emerging Challenges",
    "abstract": "Efficient analysis and processing of dental images are crucial for dentists\nto achieve accurate diagnosis and optimal treatment planning. However, dental\nimaging inherently poses several challenges, such as low contrast, metallic\nartifacts, and variations in projection angles. Combined with the subjectivity\narising from differences in clinicians' expertise, manual interpretation often\nproves time-consuming and prone to inconsistency. Artificial intelligence\n(AI)-based automated dental image analysis (DIA) offers a promising solution to\nthese issues and has become an integral part of computer-aided dental diagnosis\nand treatment. Among various AI technologies, deep learning (DL) stands out as\nthe most widely applied and influential approach due to its superior feature\nextraction and representation capabilities. To comprehensively summarize recent\nprogress in this field, we focus on the two fundamental aspects of DL\nresearch-datasets and models. In this paper, we systematically review 260\nstudies on DL applications in DIA, including 49 papers on publicly available\ndental datasets and 211 papers on DL-based algorithms. We first introduce the\nbasic concepts of dental imaging and summarize the characteristics and\nacquisition methods of existing datasets. Then, we present the foundational\ntechniques of DL and categorize relevant models and algorithms according to\ndifferent DIA tasks, analyzing their network architectures, optimization\nstrategies, training methods, and performance. Furthermore, we summarize\ncommonly used training and evaluation metrics in the DIA domain. Finally, we\ndiscuss the current challenges of existing research and outline potential\nfuture directions. We hope that this work provides a valuable and systematic\nreference for researchers in this field. All supplementary materials and\ndetailed comparison tables will be made publicly available on GitHub.",
    "categories": [
      "cs.CV",
      "cs.AI"
    ],
    "published": "2025-10-23T15:05:06Z",
    "authors": [
      "Zhenhuan Zhou",
      "Jingbo Zhu",
      "Yuchen Zhang",
      "Xiaohang Guan",
      "Peng Wang",
      "Tao Li"
    ],
    "pdf_url": "http://arxiv.org/pdf/2510.20634v1"
  },
  {
    "id": "2510.20632v1",
    "title": "Towards Reliable Evaluation of Large Language Models for Multilingual\n  and Multimodal E-Commerce Applications",
    "abstract": "Large Language Models (LLMs) excel on general-purpose NLP benchmarks, yet\ntheir capabilities in specialized domains remain underexplored. In e-commerce,\nexisting evaluations-such as EcomInstruct, ChineseEcomQA, eCeLLM, and Shopping\nMMLU-suffer from limited task diversity (e.g., lacking product guidance and\nafter-sales issues), limited task modalities (e.g., absence of multimodal\ndata), synthetic or curated data, and a narrow focus on English and Chinese,\nleaving practitioners without reliable tools to assess models on complex,\nreal-world shopping scenarios. We introduce EcomEval, a comprehensive\nmultilingual and multimodal benchmark for evaluating LLMs in e-commerce.\nEcomEval covers six categories and 37 tasks (including 8 multimodal tasks),\nsourced primarily from authentic customer queries and transaction logs,\nreflecting the noisy and heterogeneous nature of real business interactions. To\nensure both quality and scalability of reference answers, we adopt a\nsemi-automatic pipeline in which large models draft candidate responses\nsubsequently reviewed and modified by over 50 expert annotators with strong\ne-commerce and multilingual expertise. We define difficulty levels for each\nquestion and task category by averaging evaluation scores across models with\ndifferent sizes and capabilities, enabling challenge-oriented and fine-grained\nassessment. EcomEval also spans seven languages-including five low-resource\nSoutheast Asian languages-offering a multilingual perspective absent from prior\nwork.",
    "categories": [
      "cs.AI"
    ],
    "published": "2025-10-23T15:04:32Z",
    "authors": [
      "Shuyi Xie",
      "Ziqin Liew",
      "Hailing Zhang",
      "Haibo Zhang",
      "Ling Hu",
      "Zhiqiang Zhou",
      "Shuman Liu",
      "Anxiang Zeng"
    ],
    "pdf_url": "http://arxiv.org/pdf/2510.20632v1"
  },
  {
    "id": "2510.20630v1",
    "title": "Quantum Processing Unit (QPU) processing time Prediction with Machine\n  Learning",
    "abstract": "This paper explores the application of machine learning (ML) techniques in\npredicting the QPU processing time of quantum jobs. By leveraging ML\nalgorithms, this study introduces predictive models that are designed to\nenhance operational efficiency in quantum computing systems. Using a dataset of\nabout 150,000 jobs that follow the IBM Quantum schema, we employ ML methods\nbased on Gradient-Boosting (LightGBM) to predict the QPU processing times,\nincorporating data preprocessing methods to improve model accuracy. The results\ndemonstrate the effectiveness of ML in forecasting quantum jobs. This\nimprovement can have implications on improving resource management and\nscheduling within quantum computing frameworks. This research not only\nhighlights the potential of ML in refining quantum job predictions but also\nsets a foundation for integrating AI-driven tools in advanced quantum computing\noperations.",
    "categories": [
      "quant-ph",
      "cs.AI"
    ],
    "published": "2025-10-23T15:04:18Z",
    "authors": [
      "Lucy Xing",
      "Sanjay Vishwakarma",
      "David Kremer",
      "Francisco Martin-Fernandez",
      "Ismael Faro",
      "Juan Cruz-Benito"
    ],
    "pdf_url": "http://arxiv.org/pdf/2510.20630v1"
  },
  {
    "id": "2510.20629v1",
    "title": "Equitable Survival Prediction: A Fairness-Aware Survival Modeling (FASM)\n  Approach",
    "abstract": "As machine learning models become increasingly integrated into healthcare,\nstructural inequities and social biases embedded in clinical data can be\nperpetuated or even amplified by data-driven models. In survival analysis,\ncensoring and time dynamics can further add complexity to fair model\ndevelopment. Additionally, algorithmic fairness approaches often overlook\ndisparities in cross-group rankings, e.g., high-risk Black patients may be\nranked below lower-risk White patients who do not experience the event of\nmortality. Such misranking can reinforce biological essentialism and undermine\nequitable care. We propose a Fairness-Aware Survival Modeling (FASM), designed\nto mitigate algorithmic bias regarding both intra-group and cross-group risk\nrankings over time. Using breast cancer prognosis as a representative case and\napplying FASM to SEER breast cancer data, we show that FASM substantially\nimproves fairness while preserving discrimination performance comparable to\nfairness-unaware survival models. Time-stratified evaluations show that FASM\nmaintains stable fairness over a 10-year horizon, with the greatest\nimprovements observed during the mid-term of follow-up. Our approach enables\nthe development of survival models that prioritize both accuracy and equity in\nclinical decision-making, advancing fairness as a core principle in clinical\ncare.",
    "categories": [
      "cs.LG",
      "cs.AI"
    ],
    "published": "2025-10-23T15:03:27Z",
    "authors": [
      "Mingxuan Liu",
      "Yilin Ning",
      "Haoyuan Wang",
      "Chuan Hong",
      "Matthew Engelhard",
      "Danielle S. Bitterman",
      "William G. La Cava",
      "Nan Liu"
    ],
    "pdf_url": "http://arxiv.org/pdf/2510.20629v1"
  },
  {
    "id": "2510.20621v1",
    "title": "Towards the Formalization of a Trustworthy AI for Mining Interpretable\n  Models explOiting Sophisticated Algorithms",
    "abstract": "Interpretable-by-design models are crucial for fostering trust,\naccountability, and safe adoption of automated decision-making models in\nreal-world applications. In this paper we formalize the ground for the MIMOSA\n(Mining Interpretable Models explOiting Sophisticated Algorithms) framework, a\ncomprehensive methodology for generating predictive models that balance\ninterpretability with performance while embedding key ethical properties. We\nformally define here the supervised learning setting across diverse\ndecision-making tasks and data types, including tabular data, time series,\nimages, text, transactions, and trajectories. We characterize three major\nfamilies of interpretable models: feature importance, rule, and instance based\nmodels. For each family, we analyze their interpretability dimensions,\nreasoning mechanisms, and complexity. Beyond interpretability, we formalize\nthree critical ethical properties, namely causality, fairness, and privacy,\nproviding formal definitions, evaluation metrics, and verification procedures\nfor each. We then examine the inherent trade-offs between these properties and\ndiscuss how privacy requirements, fairness constraints, and causal reasoning\ncan be embedded within interpretable pipelines. By evaluating ethical measures\nduring model generation, this framework establishes the theoretical foundations\nfor developing AI systems that are not only accurate and interpretable but also\nfair, privacy-preserving, and causally aware, i.e., trustworthy.",
    "categories": [
      "cs.AI"
    ],
    "published": "2025-10-23T14:54:33Z",
    "authors": [
      "Riccardo Guidotti",
      "Martina Cinquini",
      "Marta Marchiori Manerba",
      "Mattia Setzu",
      "Francesco Spinnato"
    ],
    "pdf_url": "http://arxiv.org/pdf/2510.20621v1"
  },
  {
    "id": "2510.21879v1",
    "title": "TernaryCLIP: Efficiently Compressing Vision-Language Models with Ternary\n  Weights and Distilled Knowledge",
    "abstract": "Recent years have witnessed an increasing interest in image-text contrastive\nmodeling, exemplified by models such as Contrastive Language-Image Pretraining\n(CLIP). In this paper, we propose the TernaryCLIP, a lightweight computational\nframework that converts connection weights of both vision and text encoders of\nCLIP into the ternary format, instead of full-precision or floating ones.\nTernaryCLIP incorporates quantization-aware training and distillation modules,\npreventing precision degradation and enabling low-cost and high-efficiency\ncomputations. Comprehensive experiments demonstrate that TernaryCLIP can\nachieve up to 99\\% ternarized weights with 1.58-bit representation, 16.98\n$\\times$ compression ratio, 2.3 $\\times$ inference acceleration, 16 $\\times$\nstorage reduction, 10 $\\times$ memory optimization, and 60\\% sparsity while\nmaintaining promising performance on zero-shot image classification and\nimage-text retrieval tasks across 41 commonly used datasets. Our work\nhighlights the feasibility of extreme quantization for large multimodal models,\nsupporting effective and efficient deployment on resource-constrained devices.\nThe model and code can be accessed from Hugging Face and GitHub.",
    "categories": [
      "cs.CV",
      "cs.AI"
    ],
    "published": "2025-10-23T14:53:32Z",
    "authors": [
      "Shu-Hao Zhang",
      "Wei-Cheng Tang",
      "Chen Wu",
      "Peng Hu",
      "Nan Li",
      "Liang-Jie Zhang",
      "Qi Zhang",
      "Shao-Qun Zhang"
    ],
    "pdf_url": "http://arxiv.org/pdf/2510.21879v1"
  },
  {
    "id": "2510.20612v1",
    "title": "Black Box Absorption: LLMs Undermining Innovative Ideas",
    "abstract": "Large Language Models are increasingly adopted as critical tools for\naccelerating innovation. This paper identifies and formalizes a systemic risk\ninherent in this paradigm: \\textbf{Black Box Absorption}. We define this as the\nprocess by which the opaque internal architectures of LLM platforms, often\noperated by large-scale service providers, can internalize, generalize, and\nrepurpose novel concepts contributed by users during interaction. This\nmechanism threatens to undermine the foundational principles of innovation\neconomics by creating severe informational and structural asymmetries between\nindividual creators and platform operators, thereby jeopardizing the long-term\nsustainability of the innovation ecosystem. To analyze this challenge, we\nintroduce two core concepts: the idea unit, representing the transportable\nfunctional logic of an innovation, and idea safety, a multidimensional standard\nfor its protection. This paper analyzes the mechanisms of absorption and\nproposes a concrete governance and engineering agenda to mitigate these risks,\nensuring that creator contributions remain traceable, controllable, and\nequitable.",
    "categories": [
      "cs.CY",
      "cs.AI",
      "cs.CR",
      "cs.LG",
      "econ.GN",
      "q-fin.EC"
    ],
    "published": "2025-10-23T14:43:09Z",
    "authors": [
      "Wenjun Cao"
    ],
    "pdf_url": "http://arxiv.org/pdf/2510.20612v1"
  },
  {
    "id": "2510.20611v1",
    "title": "PSO-XAI: A PSO-Enhanced Explainable AI Framework for Reliable Breast\n  Cancer Detection",
    "abstract": "Breast cancer is considered the most critical and frequently diagnosed cancer\nin women worldwide, leading to an increase in cancer-related mortality. Early\nand accurate detection is crucial as it can help mitigate possible threats\nwhile improving survival rates. In terms of prediction, conventional diagnostic\nmethods are often limited by variability, cost, and, most importantly, risk of\nmisdiagnosis. To address these challenges, machine learning (ML) has emerged as\na powerful tool for computer-aided diagnosis, with feature selection playing a\nvital role in improving model performance and interpretability. This research\nstudy proposes an integrated framework that incorporates customized Particle\nSwarm Optimization (PSO) for feature selection. This framework has been\nevaluated on a comprehensive set of 29 different models, spanning classical\nclassifiers, ensemble techniques, neural networks, probabilistic algorithms,\nand instance-based algorithms. To ensure interpretability and clinical\nrelevance, the study uses cross-validation in conjunction with explainable AI\nmethods. Experimental evaluation showed that the proposed approach achieved a\nsuperior score of 99.1\\% across all performance metrics, including accuracy and\nprecision, while effectively reducing dimensionality and providing transparent,\nmodel-agnostic explanations. The results highlight the potential of combining\nswarm intelligence with explainable ML for robust, trustworthy, and clinically\nmeaningful breast cancer diagnosis.",
    "categories": [
      "cs.LG",
      "cs.AI"
    ],
    "published": "2025-10-23T14:42:50Z",
    "authors": [
      "Mirza Raquib",
      "Niloy Das",
      "Farida Siddiqi Prity",
      "Arafath Al Fahim",
      "Saydul Akbar Murad",
      "Mohammad Amzad Hossain",
      "MD Jiabul Hoque",
      "Mohammad Ali Moni"
    ],
    "pdf_url": "http://arxiv.org/pdf/2510.20611v1"
  },
  {
    "id": "2510.20610v2",
    "title": "BUSTED at AraGenEval Shared Task: A Comparative Study of\n  Transformer-Based Models for Arabic AI-Generated Text Detection",
    "abstract": "This paper details our submission to the AraGenEval Shared Task on Arabic\nAI-generated text detection, where our team, BUSTED, secured 5th place. We\ninvestigated the effectiveness of three pre-trained transformer models:\nAraELECTRA, CAMeLBERT, and XLM-RoBERTa. Our approach involved fine-tuning each\nmodel on the provided dataset for a binary classification task. Our findings\nrevealed a surprising result: the multilingual XLM-RoBERTa model achieved the\nhighest performance with an F1 score of 0.7701, outperforming the specialized\nArabic models. This work underscores the complexities of AI-generated text\ndetection and highlights the strong generalization capabilities of multilingual\nmodels.",
    "categories": [
      "cs.CL",
      "cs.AI"
    ],
    "published": "2025-10-23T14:41:04Z",
    "authors": [
      "Ali Zain",
      "Sareem Farooqui",
      "Muhammad Rafi"
    ],
    "pdf_url": "http://arxiv.org/pdf/2510.20610v2"
  },
  {
    "id": "2510.20609v1",
    "title": "Practical Code RAG at Scale: Task-Aware Retrieval Design Choices under\n  Compute Budgets",
    "abstract": "We study retrieval design for code-focused generation tasks under realistic\ncompute budgets. Using two complementary tasks from Long Code Arena -- code\ncompletion and bug localization -- we systematically compare retrieval\nconfigurations across various context window sizes along three axes: (i)\nchunking strategy, (ii) similarity scoring, and (iii) splitting granularity.\n(1) For PL-PL, sparse BM25 with word-level splitting is the most effective and\npractical, significantly outperforming dense alternatives while being an order\nof magnitude faster. (2) For NL-PL, proprietary dense encoders (Voyager-3\nfamily) consistently beat sparse retrievers, however requiring 100x larger\nlatency. (3) Optimal chunk size scales with available context: 32-64 line\nchunks work best at small budgets, and whole-file retrieval becomes competitive\nat 16000 tokens. (4) Simple line-based chunking matches syntax-aware splitting\nacross budgets. (5) Retrieval latency varies by up to 200x across\nconfigurations; BPE-based splitting is needlessly slow, and BM25 + word\nsplitting offers the best quality-latency trade-off. Thus, we provide\nevidence-based recommendations for implementing effective code-oriented RAG\nsystems based on task requirements, model constraints, and computational\nefficiency.",
    "categories": [
      "cs.LG",
      "cs.AI",
      "cs.IR",
      "cs.LG, cs.IR, cs.SE, cs.AI"
    ],
    "published": "2025-10-23T14:40:11Z",
    "authors": [
      "Timur Galimzyanov",
      "Olga Kolomyttseva",
      "Egor Bogomolov"
    ],
    "pdf_url": "http://arxiv.org/pdf/2510.20609v1"
  },
  {
    "id": "2510.20607v1",
    "title": "Generalizable Reasoning through Compositional Energy Minimization",
    "abstract": "Generalization is a key challenge in machine learning, specifically in\nreasoning tasks, where models are expected to solve problems more complex than\nthose encountered during training. Existing approaches typically train\nreasoning models in an end-to-end fashion, directly mapping input instances to\nsolutions. While this allows models to learn useful heuristics from data, it\noften results in limited generalization beyond the training distribution. In\nthis work, we propose a novel approach to reasoning generalization by learning\nenergy landscapes over the solution spaces of smaller, more tractable\nsubproblems. At test time, we construct a global energy landscape for a given\nproblem by combining the energy functions of multiple subproblems. This\ncompositional approach enables the incorporation of additional constraints\nduring inference, allowing the construction of energy landscapes for problems\nof increasing difficulty. To improve the sample quality from this newly\nconstructed energy landscape, we introduce Parallel Energy Minimization (PEM).\nWe evaluate our approach on a wide set of reasoning problems. Our method\noutperforms existing state-of-the-art methods, demonstrating its ability to\ngeneralize to larger and more complex problems. Project website can be found\nat: https://alexoarga.github.io/compositional_reasoning/",
    "categories": [
      "cs.LG",
      "cs.AI"
    ],
    "published": "2025-10-23T14:38:36Z",
    "authors": [
      "Alexandru Oarga",
      "Yilun Du"
    ],
    "pdf_url": "http://arxiv.org/pdf/2510.20607v1"
  },
  {
    "id": "2510.20605v1",
    "title": "OnlineSplatter: Pose-Free Online 3D Reconstruction for Free-Moving\n  Objects",
    "abstract": "Free-moving object reconstruction from monocular video remains challenging,\nparticularly without reliable pose or depth cues and under arbitrary object\nmotion. We introduce OnlineSplatter, a novel online feed-forward framework\ngenerating high-quality, object-centric 3D Gaussians directly from RGB frames\nwithout requiring camera pose, depth priors, or bundle optimization. Our\napproach anchors reconstruction using the first frame and progressively refines\nthe object representation through a dense Gaussian primitive field, maintaining\nconstant computational cost regardless of video sequence length. Our core\ncontribution is a dual-key memory module combining latent appearance-geometry\nkeys with explicit directional keys, robustly fusing current frame features\nwith temporally aggregated object states. This design enables effective\nhandling of free-moving objects via spatial-guided memory readout and an\nefficient sparsification mechanism, ensuring comprehensive yet compact object\ncoverage. Evaluations on real-world datasets demonstrate that OnlineSplatter\nsignificantly outperforms state-of-the-art pose-free reconstruction baselines,\nconsistently improving with more observations while maintaining constant memory\nand runtime.",
    "categories": [
      "cs.CV",
      "cs.AI",
      "I.4.5; I.2.6"
    ],
    "published": "2025-10-23T14:37:25Z",
    "authors": [
      "Mark He Huang",
      "Lin Geng Foo",
      "Christian Theobalt",
      "Ying Sun",
      "De Wen Soh"
    ],
    "pdf_url": "http://arxiv.org/pdf/2510.20605v1"
  },
  {
    "id": "2510.20604v1",
    "title": "Efficient Algorithms for Computing Random Walk Centrality",
    "abstract": "Random walk centrality is a fundamental metric in graph mining for\nquantifying node importance and influence, defined as the weighted average of\nhitting times to a node from all other nodes. Despite its ability to capture\nrich graph structural information and its wide range of applications, computing\nthis measure for large networks remains impractical due to the computational\ndemands of existing methods. In this paper, we present a novel formulation of\nrandom walk centrality, underpinning two scalable algorithms: one leveraging\napproximate Cholesky factorization and sparse inverse estimation, while the\nother sampling rooted spanning trees. Both algorithms operate in near-linear\ntime and provide strong approximation guarantees. Extensive experiments on\nlarge real-world networks, including one with over 10 million nodes,\ndemonstrate the efficiency and approximation quality of the proposed\nalgorithms.",
    "categories": [
      "cs.AI"
    ],
    "published": "2025-10-23T14:36:38Z",
    "authors": [
      "Changan Liu",
      "Zixuan Xie",
      "Ahad N. Zehmakan",
      "Zhongzhi Zhang"
    ],
    "pdf_url": "http://arxiv.org/pdf/2510.20604v1"
  },
  {
    "id": "2510.21876v1",
    "title": "AI Powered Urban Green Infrastructure Assessment Through Aerial Imagery\n  of an Industrial Township",
    "abstract": "Accurate assessment of urban canopy coverage is crucial for informed urban\nplanning, effective environmental monitoring, and mitigating the impacts of\nclimate change. Traditional practices often face limitations due to inadequate\ntechnical requirements, difficulties in scaling and data processing, and the\nlack of specialized expertise. This study presents an efficient approach for\nestimating green canopy coverage using artificial intelligence, specifically\ncomputer vision techniques, applied to aerial imageries. Our proposed\nmethodology utilizes object-based image analysis, based on deep learning\nalgorithms to accurately identify and segment green canopies from\nhigh-resolution drone images. This approach allows the user for detailed\nanalysis of urban vegetation, capturing variations in canopy density and\nunderstanding spatial distribution. To overcome the computational challenges\nassociated with processing large datasets, it was implemented over a cloud\nplatform utilizing high-performance processors. This infrastructure efficiently\nmanages space complexity and ensures affordable latency, enabling the rapid\nanalysis of vast amounts of drone imageries. Our results demonstrate the\neffectiveness of this approach in accurately estimating canopy coverage at the\ncity scale, providing valuable insights for urban forestry management of an\nindustrial township. The resultant data generated by this method can be used to\noptimize tree plantation and assess the carbon sequestration potential of urban\nforests. By integrating these insights into sustainable urban planning, we can\nfoster more resilient urban environments, contributing to a greener and\nhealthier future.",
    "categories": [
      "cs.CV",
      "cs.AI"
    ],
    "published": "2025-10-23T14:36:20Z",
    "authors": [
      "Anisha Dutta"
    ],
    "pdf_url": "http://arxiv.org/pdf/2510.21876v1"
  },
  {
    "id": "2510.20603v1",
    "title": "What Defines Good Reasoning in LLMs? Dissecting Reasoning Steps with\n  Multi-Aspect Evaluation",
    "abstract": "Evaluating large language models (LLMs) on final-answer correctness is the\ndominant paradigm. This approach, however, provides a coarse signal for model\nimprovement and overlooks the quality of the underlying reasoning process. We\nargue that a more granular evaluation of reasoning offers a more effective path\nto building robust models. We decompose reasoning quality into two dimensions:\nrelevance and coherence. Relevance measures if a step is grounded in the\nproblem; coherence measures if it follows logically from prior steps. To\nmeasure these aspects reliably, we introduce causal stepwise evaluation (CaSE).\nThis method assesses each reasoning step using only its preceding context,\nwhich avoids hindsight bias. We validate CaSE against human judgments on our\nnew expert-annotated benchmarks, MRa-GSM8K and MRa-MATH. More importantly, we\nshow that curating training data with CaSE-evaluated relevance and coherence\ndirectly improves final task performance. Our work provides a scalable\nframework for analyzing, debugging, and improving LLM reasoning, demonstrating\nthe practical value of moving beyond validity checks.",
    "categories": [
      "cs.AI",
      "cs.CL"
    ],
    "published": "2025-10-23T14:30:37Z",
    "authors": [
      "Heejin Do",
      "Jaehui Hwang",
      "Dongyoon Han",
      "Seong Joon Oh",
      "Sangdoo Yun"
    ],
    "pdf_url": "http://arxiv.org/pdf/2510.20603v1"
  },
  {
    "id": "2510.20602v1",
    "title": "Resounding Acoustic Fields with Reciprocity",
    "abstract": "Achieving immersive auditory experiences in virtual environments requires\nflexible sound modeling that supports dynamic source positions. In this paper,\nwe introduce a task called resounding, which aims to estimate room impulse\nresponses at arbitrary emitter location from a sparse set of measured emitter\npositions, analogous to the relighting problem in vision. We leverage the\nreciprocity property and introduce Versa, a physics-inspired approach to\nfacilitating acoustic field learning. Our method creates physically valid\nsamples with dense virtual emitter positions by exchanging emitter and listener\nposes. We also identify challenges in deploying reciprocity due to\nemitter/listener gain patterns and propose a self-supervised learning approach\nto address them. Results show that Versa substantially improve the performance\nof acoustic field learning on both simulated and real-world datasets across\ndifferent metrics. Perceptual user studies show that Versa can greatly improve\nthe immersive spatial sound experience. Code, dataset and demo videos are\navailable on the project website: https://waves.seas.upenn.edu/projects/versa.",
    "categories": [
      "cs.SD",
      "cs.AI",
      "eess.AS",
      "eess.SP"
    ],
    "published": "2025-10-23T14:30:09Z",
    "authors": [
      "Zitong Lan",
      "Yiduo Hao",
      "Mingmin Zhao"
    ],
    "pdf_url": "http://arxiv.org/pdf/2510.20602v1"
  },
  {
    "id": "2510.20596v1",
    "title": "Unsupervised Domain Adaptation via Similarity-based Prototypes for\n  Cross-Modality Segmentation",
    "abstract": "Deep learning models have achieved great success on various vision\nchallenges, but a well-trained model would face drastic performance degradation\nwhen applied to unseen data. Since the model is sensitive to domain shift,\nunsupervised domain adaptation attempts to reduce the domain gap and avoid\ncostly annotation of unseen domains. This paper proposes a novel framework for\ncross-modality segmentation via similarity-based prototypes. In specific, we\nlearn class-wise prototypes within an embedding space, then introduce a\nsimilarity constraint to make these prototypes representative for each semantic\nclass while separable from different classes. Moreover, we use dictionaries to\nstore prototypes extracted from different images, which prevents the\nclass-missing problem and enables the contrastive learning of prototypes, and\nfurther improves performance. Extensive experiments show that our method\nachieves better results than other state-of-the-art methods.",
    "categories": [
      "cs.CV",
      "cs.AI"
    ],
    "published": "2025-10-23T14:24:12Z",
    "authors": [
      "Ziyu Ye",
      "Chen Ju",
      "Chaofan Ma",
      "Xiaoyun Zhang"
    ],
    "pdf_url": "http://arxiv.org/pdf/2510.20596v1"
  },
  {
    "id": "2510.20591v1",
    "title": "Transferable Graph Learning for Transmission Congestion Management via\n  Busbar Splitting",
    "abstract": "Network topology optimization (NTO) via busbar splitting can mitigate\ntransmission grid congestion and reduce redispatch costs. However, solving this\nmixed-integer non-linear problem for large-scale systems in near-real-time is\ncurrently intractable with existing solvers. Machine learning (ML) approaches\nhave emerged as a promising alternative, but they have limited generalization\nto unseen topologies, varying operating conditions, and different systems,\nwhich limits their practical applicability. This paper formulates NTO for\ncongestion management problem considering linearized AC PF, and proposes a\ngraph neural network (GNN)-accelerated approach. We develop a heterogeneous\nedge-aware message passing NN to predict effective busbar splitting actions as\ncandidate NTO solutions. The proposed GNN captures local flow patterns,\nachieves generalization to unseen topology changes, and improves\ntransferability across systems. Case studies show up to 4 orders-of-magnitude\nspeed-up, delivering AC-feasible solutions within one minute and a 2.3%\noptimality gap on the GOC 2000-bus system. These results demonstrate a\nsignificant step toward near-real-time NTO for large-scale systems with\ntopology and cross-system generalization.",
    "categories": [
      "cs.AI"
    ],
    "published": "2025-10-23T14:16:23Z",
    "authors": [
      "Ali Rajaei",
      "Peter Palensky",
      "Jochen L. Cremer"
    ],
    "pdf_url": "http://arxiv.org/pdf/2510.20591v1"
  },
  {
    "id": "2510.20584v1",
    "title": "Can ChatGPT Code Communication Data Fairly?: Empirical Evidence from\n  Multiple Collaborative Tasks",
    "abstract": "Assessing communication and collaboration at scale depends on a labor\nintensive task of coding communication data into categories according to\ndifferent frameworks. Prior research has established that ChatGPT can be\ndirectly instructed with coding rubrics to code the communication data and\nachieves accuracy comparable to human raters. However, whether the coding from\nChatGPT or similar AI technology exhibits bias against different demographic\ngroups, such as gender and race, remains unclear. To fill this gap, this paper\ninvestigates ChatGPT-based automated coding of communication data using a\ntypical coding framework for collaborative problem solving, examining\ndifferences across gender and racial groups. The analysis draws on data from\nthree types of collaborative tasks: negotiation, problem solving, and decision\nmaking. Our results show that ChatGPT-based coding exhibits no significant bias\nacross gender and racial groups, paving the road for its adoption in\nlarge-scale assessment of collaboration and communication.",
    "categories": [
      "cs.CL",
      "cs.AI"
    ],
    "published": "2025-10-23T14:09:03Z",
    "authors": [
      "Jiangang Hao",
      "Wenju Cui",
      "Patrick Kyllonen",
      "Emily Kerzabi"
    ],
    "pdf_url": "http://arxiv.org/pdf/2510.20584v1"
  },
  {
    "id": "2510.20579v1",
    "title": "Open-o3 Video: Grounded Video Reasoning with Explicit Spatio-Temporal\n  Evidence",
    "abstract": "Most video reasoning models only generate textual reasoning traces without\nindicating when and where key evidence appears. Recent models such as OpenAI-o3\nhave sparked wide interest in evidence-centered reasoning for images, yet\nextending this ability to videos is more challenging, as it requires joint\ntemporal tracking and spatial localization across dynamic scenes. We introduce\nOpen-o3 Video, a non-agent framework that integrates explicit spatio-temporal\nevidence into video reasoning, and carefully collect training data and design\ntraining strategies to address the aforementioned challenges. The model\nhighlights key timestamps, objects, and bounding boxes alongside its answers,\nallowing reasoning to be grounded in concrete visual observations. To enable\nthis functionality, we first curate and build two high-quality datasets,\nSTGR-CoT-30k for SFT and STGR-RL-36k for RL, with carefully constructed\ntemporal and spatial annotations, since most existing datasets offer either\ntemporal spans for videos or spatial boxes on images, lacking unified\nspatio-temporal supervision and reasoning traces. Then, we adopt a cold-start\nreinforcement learning strategy with multiple specially designed rewards that\njointly encourage answer accuracy, temporal alignment, and spatial precision.\nOn V-STAR benchmark, Open-o3 Video achieves state-of-the-art performance,\nraising mAM by 14.4% and mLGM by 24.2% on the Qwen2.5-VL baseline. Consistent\nimprovements are also observed on a broad range of video understanding\nbenchmarks, including VideoMME, WorldSense, VideoMMMU, and TVGBench. Beyond\naccuracy, the reasoning traces produced by Open-o3 Video also provide valuable\nsignals for test-time scaling, enabling confidence-aware verification and\nimproving answer reliability.",
    "categories": [
      "cs.CV",
      "cs.AI",
      "cs.MM"
    ],
    "published": "2025-10-23T14:05:56Z",
    "authors": [
      "Jiahao Meng",
      "Xiangtai Li",
      "Haochen Wang",
      "Yue Tan",
      "Tao Zhang",
      "Lingdong Kong",
      "Yunhai Tong",
      "Anran Wang",
      "Zhiyang Teng",
      "Yujing Wang",
      "Zhuochen Wang"
    ],
    "pdf_url": "http://arxiv.org/pdf/2510.20579v1"
  },
  {
    "id": "2510.23621v1",
    "title": "Speeding Up MACE: Low-Precision Tricks for Equivarient Force Fields",
    "abstract": "Machine-learning force fields can deliver accurate molecular dynamics (MD) at\nhigh computational cost. For SO(3)-equivariant models such as MACE, there is\nlittle systematic evidence on whether reduced-precision arithmetic and\nGPU-optimized kernels can cut this cost without harming physical fidelity. This\nthesis aims to make MACE cheaper and faster while preserving accuracy by\nidentifying computational bottlenecks and evaluating low-precision execution\npolicies. We profile MACE end-to-end and per block, compare the e3nn and NVIDIA\ncuEquivariance backends, and assess FP64/FP32/BF16/FP16 settings (with FP32\naccumulation) for inference, short NVT and long NPT water simulations, and toy\ntraining runs under reproducible, steady-state timing. cuEquivariance reduces\ninference latency by about $3\\times$. Casting only linear layers to BF16/FP16\nwithin an FP32 model yields roughly 4x additional speedups, while energies and\nthermodynamic observables in NVT/NPT MD remain within run-to-run variability.\nHalf-precision weights during training degrade force RMSE. Mixing e3nn and cuEq\nmodules without explicit adapters causes representation mismatches. Fused\nequivariant kernels and mixed-precision inference can substantially accelerate\nstate-of-the-art force fields with negligible impact on downstream MD. A\npractical policy is to use cuEquivariance with FP32 by default and enable\nBF16/FP16 for linear layers (keeping FP32 accumulations) for maximum\nthroughput, while training remains in FP32. Further gains are expected on\nAmpere/Hopper GPUs (TF32/BF16) and from kernel-level FP16/BF16 paths and\npipeline fusion.",
    "categories": [
      "cs.LG",
      "cs.AI"
    ],
    "published": "2025-10-23T14:02:34Z",
    "authors": [
      "Alexandre Benoit"
    ],
    "pdf_url": "http://arxiv.org/pdf/2510.23621v1"
  },
  {
    "id": "2510.20568v1",
    "title": "Lost in Translation: Policymakers are not really listening to Citizen\n  Concerns about AI",
    "abstract": "The worlds people have strong opinions about artificial intelligence (AI),\nand they want policymakers to listen. Governments are inviting public comment\non AI, but as they translate input into policy, much of what citizens say is\nlost. Policymakers are missing a critical opportunity to build trust in AI and\nits governance. This paper compares three countries, Australia, Colombia, and\nthe United States, that invited citizens to comment on AI risks and policies.\nUsing a landscape analysis, the authors examined how each government solicited\nfeedback and whether that input shaped governance. Yet in none of the three\ncases did citizens and policymakers establish a meaningful dialogue.\nGovernments did little to attract diverse voices or publicize calls for\ncomment, leaving most citizens unaware or unprepared to respond. In each\nnation, fewer than one percent of the population participated. Moreover,\nofficials showed limited responsiveness to the feedback they received, failing\nto create an effective feedback loop. The study finds a persistent gap between\nthe promise and practice of participatory AI governance. The authors conclude\nthat current approaches are unlikely to build trust or legitimacy in AI because\npolicymakers are not adequately listening or responding to public concerns.\nThey offer eight recommendations: promote AI literacy; monitor public feedback;\nbroaden outreach; hold regular online forums; use innovative engagement\nmethods; include underrepresented groups; respond publicly to input; and make\nparticipation easier.",
    "categories": [
      "cs.AI"
    ],
    "published": "2025-10-23T13:57:02Z",
    "authors": [
      "Susan Ariel Aaronson",
      "Michael Moreno"
    ],
    "pdf_url": "http://arxiv.org/pdf/2510.20568v1"
  },
  {
    "id": "2510.20566v1",
    "title": "AdaDoS: Adaptive DoS Attack via Deep Adversarial Reinforcement Learning\n  in SDN",
    "abstract": "Existing defence mechanisms have demonstrated significant effectiveness in\nmitigating rule-based Denial-of-Service (DoS) attacks, leveraging predefined\nsignatures and static heuristics to identify and block malicious traffic.\nHowever, the emergence of AI-driven techniques presents new challenges to SDN\nsecurity, potentially compromising the efficacy of existing defence mechanisms.\nIn this paper, we introduce~AdaDoS, an adaptive attack model that disrupt\nnetwork operations while evading detection by existing DoS-based detectors\nthrough adversarial reinforcement learning (RL). Specifically, AdaDoS models\nthe problem as a competitive game between an attacker, whose goal is to\nobstruct network traffic without being detected, and a detector, which aims to\nidentify malicious traffic. AdaDoS can solve this game by dynamically adjusting\nits attack strategy based on feedback from the SDN and the detector.\nAdditionally, recognising that attackers typically have less information than\ndefenders, AdaDoS formulates the DoS-like attack as a partially observed Markov\ndecision process (POMDP), with the attacker having access only to delay\ninformation between attacker and victim nodes. We address this challenge with a\nnovel reciprocal learning module, where the student agent, with limited\nobservations, enhances its performance by learning from the teacher agent, who\nhas full observational capabilities in the SDN environment. AdaDoS represents\nthe first application of RL to develop DoS-like attack sequences, capable of\nadaptively evading both machine learning-based and rule-based DoS-like attack\ndetectors.",
    "categories": [
      "cs.CR",
      "cs.AI"
    ],
    "published": "2025-10-23T13:51:40Z",
    "authors": [
      "Wei Shao",
      "Yuhao Wang",
      "Rongguang He",
      "Muhammad Ejaz Ahmed",
      "Seyit Camtepe"
    ],
    "pdf_url": "http://arxiv.org/pdf/2510.20566v1"
  },
  {
    "id": "2510.21874v1",
    "title": "A Physics-Informed Neural Network Approach for UAV Path Planning in\n  Dynamic Environments",
    "abstract": "Unmanned aerial vehicles (UAVs) operating in dynamic wind fields must\ngenerate safe and energy-efficient trajectories under physical and\nenvironmental constraints. Traditional planners, such as A* and kinodynamic\nRRT*, often yield suboptimal or non-smooth paths due to discretization and\nsampling limitations. This paper presents a physics-informed neural network\n(PINN) framework that embeds UAV dynamics, wind disturbances, and obstacle\navoidance directly into the learning process. Without requiring supervised\ndata, the PINN learns dynamically feasible and collision-free trajectories by\nminimizing physical residuals and risk-aware objectives. Comparative\nsimulations show that the proposed method outperforms A* and Kino-RRT* in\ncontrol energy, smoothness, and safety margin, while maintaining similar flight\nefficiency. The results highlight the potential of physics-informed learning to\nunify model-based and data-driven planning, providing a scalable and physically\nconsistent framework for UAV trajectory optimization.",
    "categories": [
      "cs.RO",
      "cs.AI"
    ],
    "published": "2025-10-23T13:42:07Z",
    "authors": [
      "Shuning Zhang"
    ],
    "pdf_url": "http://arxiv.org/pdf/2510.21874v1"
  },
  {
    "id": "2510.24763v1",
    "title": "Dual-Domain Deep Learning-Assisted NOMA-CSK Systems for Secure and\n  Efficient Vehicular Communications",
    "abstract": "Ensuring secure and efficient multi-user (MU) transmission is critical for\nvehicular communication systems. Chaos-based modulation schemes have garnered\nconsiderable interest due to their benefits in physical layer security.\nHowever, most existing MU chaotic communication systems, particularly those\nbased on non-coherent detection, suffer from low spectral efficiency due to\nreference signal transmission, and limited user connectivity under orthogonal\nmultiple access (OMA). While non-orthogonal schemes, such as sparse code\nmultiple access (SCMA)-based DCSK, have been explored, they face high\ncomputational complexity and inflexible scalability due to their fixed codebook\ndesigns. This paper proposes a deep learning-assisted power domain\nnon-orthogonal multiple access chaos shift keying (DL-NOMA-CSK) system for\nvehicular communications. A deep neural network (DNN)-based demodulator is\ndesigned to learn intrinsic chaotic signal characteristics during offline\ntraining, thereby eliminating the need for chaotic synchronization or reference\nsignal transmission. The demodulator employs a dual-domain feature extraction\narchitecture that jointly processes the time-domain and frequency-domain\ninformation of chaotic signals, enhancing feature learning under dynamic\nchannels. The DNN is integrated into the successive interference cancellation\n(SIC) framework to mitigate error propagation issues. Theoretical analysis and\nextensive simulations demonstrate that the proposed system achieves superior\nperformance in terms of spectral efficiency (SE), energy efficiency (EE), bit\nerror rate (BER), security, and robustness, while maintaining lower\ncomputational complexity compared to traditional MU-DCSK and existing DL-aided\nschemes. These advantages validate its practical viability for secure vehicular\ncommunications.",
    "categories": [
      "cs.IT",
      "cs.AI",
      "cs.LG",
      "math.IT"
    ],
    "published": "2025-10-23T13:41:00Z",
    "authors": [
      "Tingting Huang",
      "Jundong Chen",
      "Huanqiang Zeng",
      "Guofa Cai",
      "Georges Kaddoum"
    ],
    "pdf_url": "http://arxiv.org/pdf/2510.24763v1"
  },
  {
    "id": "2510.20556v1",
    "title": "Structural Invariance Matters: Rethinking Graph Rewiring through Graph\n  Metrics",
    "abstract": "Graph rewiring has emerged as a key technique to alleviate over-squashing in\nGraph Neural Networks (GNNs) and Graph Transformers by modifying the graph\ntopology to improve information flow. While effective, rewiring inherently\nalters the graph's structure, raising the risk of distorting important\ntopology-dependent signals. Yet, despite the growing use of rewiring, little is\nknown about which structural properties must be preserved to ensure both\nperformance gains and structural fidelity. In this work, we provide the first\nsystematic analysis of how rewiring affects a range of graph structural\nmetrics, and how these changes relate to downstream task performance. We study\nseven diverse rewiring strategies and correlate changes in local and global\ngraph properties with node classification accuracy. Our results reveal a\nconsistent pattern: successful rewiring methods tend to preserve local\nstructure while allowing for flexibility in global connectivity. These findings\noffer new insights into the design of effective rewiring strategies, bridging\nthe gap between graph theory and practical GNN optimization.",
    "categories": [
      "cs.LG",
      "cs.AI"
    ],
    "published": "2025-10-23T13:38:41Z",
    "authors": [
      "Alexandre Benoit",
      "Catherine Aitken",
      "Yu He"
    ],
    "pdf_url": "http://arxiv.org/pdf/2510.20556v1"
  },
  {
    "id": "2510.20548v1",
    "title": "GlobalRAG: Enhancing Global Reasoning in Multi-hop Question Answering\n  via Reinforcement Learning",
    "abstract": "Reinforcement learning has recently shown promise in improving\nretrieval-augmented generation (RAG). Despite these advances, its effectiveness\nin multi-hop question answering (QA) remains limited by two fundamental\nlimitations: (i) global planning absence to structure multi-step reasoning, and\n(ii) unfaithful execution, which hinders effective query formulation and\nconsistent use of retrieved evidence. We propose GlobalRAG, a reinforcement\nlearning framework designed to enhance global reasoning in multi-hop QA.\nGlobalRAG decomposes questions into subgoals, coordinates retrieval with\nreasoning, and refines evidence iteratively. To guide this process, we\nintroduce Planning Quality Reward and SubGoal Completion Reward, which\nencourage coherent planning and reliable subgoal execution. In addition, a\nprogressive weight annealing strategy balances process-oriented and\noutcome-based objectives. Extensive experiments on both in-domain and\nout-of-domain benchmarks demonstrate that GlobalRAG significantly outperforms\nstrong baselines while using only 8k training data (42% of the training data\nused by strong baselines), achieving average improvements of 14.2% in both EM\nand F1.",
    "categories": [
      "cs.CL",
      "cs.AI"
    ],
    "published": "2025-10-23T13:35:02Z",
    "authors": [
      "Jinchang Luo",
      "Mingquan Cheng",
      "Fan Wan",
      "Ni Li",
      "Xiaoling Xia",
      "Shuangshuang Tian",
      "Tingcheng Bian",
      "Haiwei Wang",
      "Haohuan Fu",
      "Yan Tao"
    ],
    "pdf_url": "http://arxiv.org/pdf/2510.20548v1"
  },
  {
    "id": "2510.21872v1",
    "title": "GuitarFlow: Realistic Electric Guitar Synthesis From Tablatures via Flow\n  Matching and Style Transfer",
    "abstract": "Music generation in the audio domain using artificial intelligence (AI) has\nwitnessed steady progress in recent years. However for some instruments,\nparticularly the guitar, controllable instrument synthesis remains limited in\nexpressivity. We introduce GuitarFlow, a model designed specifically for\nelectric guitar synthesis. The generative process is guided using tablatures,\nan ubiquitous and intuitive guitar-specific symbolic format. The tablature\nformat easily represents guitar-specific playing techniques (e.g. bends, muted\nstrings and legatos), which are more difficult to represent in other common\nmusic notation formats such as MIDI. Our model relies on an intermediary step\nof first rendering the tablature to audio using a simple sample-based virtual\ninstrument, then performing style transfer using Flow Matching in order to\ntransform the virtual instrument audio into more realistic sounding examples.\nThis results in a model that is quick to train and to perform inference,\nrequiring less than 6 hours of training data. We present the results of\nobjective evaluation metrics, together with a listening test, in which we show\nsignificant improvement in the realism of the generated guitar audio from\ntablatures.",
    "categories": [
      "cs.SD",
      "cs.AI",
      "eess.AS"
    ],
    "published": "2025-10-23T13:31:41Z",
    "authors": [
      "Jackson Loth",
      "Pedro Sarmento",
      "Mark Sandler",
      "Mathieu Barthet"
    ],
    "pdf_url": "http://arxiv.org/pdf/2510.21872v1"
  },
  {
    "id": "2510.20543v1",
    "title": "The Dog the Cat Chased Stumped the Model: Measuring When Language Models\n  Abandon Structure for Shortcuts",
    "abstract": "When language models correctly parse \"The cat that the dog chased meowed,\"\nare they analyzing syntax or simply familiar with dogs chasing cats? Despite\nextensive benchmarking, we lack methods to distinguish structural understanding\nfrom semantic pattern matching. We introduce CenterBench, a dataset of 9,720\ncomprehension questions on center-embedded sentences (like \"The cat [that the\ndog chased] meowed\") where relative clauses nest recursively, creating\nprocessing demands from simple to deeply nested structures. Each sentence has a\nsyntactically identical but semantically implausible counterpart (e.g., mailmen\nprescribe medicine, doctors deliver mail) and six comprehension questions\ntesting surface understanding, syntactic dependencies, and causal reasoning.\nTesting six models reveals that performance gaps between plausible and\nimplausible sentences widen systematically with complexity, with models showing\nmedian gaps up to 26.8 percentage points, quantifying when they abandon\nstructural analysis for semantic associations. Notably, semantic plausibility\nharms performance on questions about resulting actions, where following causal\nrelationships matters more than semantic coherence. Reasoning models improve\naccuracy but their traces show semantic shortcuts, overthinking, and answer\nrefusal. Unlike models whose plausibility advantage systematically widens with\ncomplexity, humans shows variable semantic effects. CenterBench provides the\nfirst framework to identify when models shift from structural analysis to\npattern matching.",
    "categories": [
      "cs.CL",
      "cs.AI"
    ],
    "published": "2025-10-23T13:30:40Z",
    "authors": [
      "Sangmitra Madhusudan",
      "Kaige Chen",
      "Ali Emami"
    ],
    "pdf_url": "http://arxiv.org/pdf/2510.20543v1"
  },
  {
    "id": "2510.20535v1",
    "title": "ARC-Encoder: learning compressed text representations for large language\n  models",
    "abstract": "Recent techniques such as retrieval-augmented generation or chain-of-thought\nreasoning have led to longer contexts and increased inference costs. Context\ncompression techniques can reduce these costs, but the most effective\napproaches require fine-tuning the target model or even modifying its\narchitecture. This can degrade its general abilities when not used for this\nspecific purpose. Here we explore an alternative approach: an encoder that\ncompresses the context into continuous representations which replace token\nembeddings in decoder LLMs. First, we perform a systematic study of training\nstrategies and architecture choices for the encoder. Our findings led to the\ndesign of an Adaptable text Representations Compressor, named ARC-Encoder,\nwhich outputs $x$-times fewer continuous representations (typically\n$x\\!\\in\\!\\{4,8\\}$) than text tokens. We evaluate ARC-Encoder across a variety\nof LLM usage scenarios, ranging from in-context learning to context window\nextension, on both instruct and base decoders. Results show that ARC-Encoder\nachieves state-of-the-art performance on several benchmarks while improving\ncomputational efficiency at inference. Finally, we demonstrate that our models\ncan be adapted to multiple decoders simultaneously, allowing a single encoder\nto generalize across different decoder LLMs. This makes ARC-Encoder a flexible\nand efficient solution for portable encoders that work seamlessly with multiple\nLLMs. We release a training code at https://github.com/kyutai-labs/ARC-Encoder\n, fine-tuning dataset and pretrained models are available at\nhttps://huggingface.co/collections/kyutai/arc-encoders-68ee18787301407d60a57047 .",
    "categories": [
      "cs.CL",
      "cs.AI"
    ],
    "published": "2025-10-23T13:20:57Z",
    "authors": [
      "Hippolyte Pilchen",
      "Edouard Grave",
      "Patrick P\u00e9rez"
    ],
    "pdf_url": "http://arxiv.org/pdf/2510.20535v1"
  },
  {
    "id": "2510.20531v1",
    "title": "Fake-in-Facext: Towards Fine-Grained Explainable DeepFake Analysis",
    "abstract": "The advancement of Multimodal Large Language Models (MLLMs) has bridged the\ngap between vision and language tasks, enabling the implementation of\nExplainable DeepFake Analysis (XDFA). However, current methods suffer from a\nlack of fine-grained awareness: the description of artifacts in data annotation\nis unreliable and coarse-grained, and the models fail to support the output of\nconnections between textual forgery explanations and the visual evidence of\nartifacts, as well as the input of queries for arbitrary facial regions. As a\nresult, their responses are not sufficiently grounded in Face Visual Context\n(Facext). To address this limitation, we propose the Fake-in-Facext (FiFa)\nframework, with contributions focusing on data annotation and model\nconstruction. We first define a Facial Image Concept Tree (FICT) to divide\nfacial images into fine-grained regional concepts, thereby obtaining a more\nreliable data annotation pipeline, FiFa-Annotator, for forgery explanation.\nBased on this dedicated data annotation, we introduce a novel\nArtifact-Grounding Explanation (AGE) task, which generates textual forgery\nexplanations interleaved with segmentation masks of manipulated artifacts. We\npropose a unified multi-task learning architecture, FiFa-MLLM, to\nsimultaneously support abundant multimodal inputs and outputs for fine-grained\nExplainable DeepFake Analysis. With multiple auxiliary supervision tasks,\nFiFa-MLLM can outperform strong baselines on the AGE task and achieve SOTA\nperformance on existing XDFA datasets. The code and data will be made\nopen-source at https://github.com/lxq1000/Fake-in-Facext.",
    "categories": [
      "cs.CV",
      "cs.AI"
    ],
    "published": "2025-10-23T13:16:12Z",
    "authors": [
      "Lixiong Qin",
      "Yang Zhang",
      "Mei Wang",
      "Jiani Hu",
      "Weihong Deng",
      "Weiran Xu"
    ],
    "pdf_url": "http://arxiv.org/pdf/2510.20531v1"
  },
  {
    "id": "2510.20519v1",
    "title": "Metis-HOME: Hybrid Optimized Mixture-of-Experts for Multimodal Reasoning",
    "abstract": "Inspired by recent advancements in LLM reasoning, the field of multimodal\nreasoning has seen remarkable progress, achieving significant performance gains\non intricate tasks such as mathematical problem-solving. Despite this progress,\ncurrent multimodal large reasoning models exhibit two key limitations. They\ntend to employ computationally expensive reasoning even for simple queries,\nleading to inefficiency. Furthermore, this focus on specialized reasoning often\nimpairs their broader, more general understanding capabilities. In this paper,\nwe propose Metis-HOME: a Hybrid Optimized Mixture-of-Experts framework designed\nto address this trade-off. Metis-HOME enables a ''Hybrid Thinking'' paradigm by\nstructuring the original dense model into two distinct expert branches: a\nthinking branch tailored for complex, multi-step reasoning, and a non-thinking\nbranch optimized for rapid, direct inference on tasks like general VQA and OCR.\nA lightweight, trainable router dynamically allocates queries to the most\nsuitable expert. We instantiate Metis-HOME by adapting the Qwen2.5-VL-7B into\nan MoE architecture. Comprehensive evaluations reveal that our approach not\nonly substantially enhances complex reasoning abilities but also improves the\nmodel's general capabilities, reversing the degradation trend observed in other\nreasoning-specialized models. Our work establishes a new paradigm for building\npowerful and versatile MLLMs, effectively resolving the prevalent\nreasoning-vs-generalization dilemma.",
    "categories": [
      "cs.CV",
      "cs.AI"
    ],
    "published": "2025-10-23T13:02:49Z",
    "authors": [
      "Xiaohan Lan",
      "Fanfan Liu",
      "Haibo Qiu",
      "Siqi Yang",
      "Delian Ruan",
      "Peng Shi",
      "Lin Ma"
    ],
    "pdf_url": "http://arxiv.org/pdf/2510.20519v1"
  },
  {
    "id": "2510.20505v1",
    "title": "Hierarchical Sequence Iteration for Heterogeneous Question Answering",
    "abstract": "Retrieval-augmented generation (RAG) remains brittle on multi-step questions\nand heterogeneous evidence sources, trading accuracy against latency and\ntoken/tool budgets. This paper introducesHierarchical Sequence (HSEQ) Iteration\nfor Heterogeneous Question Answering, a unified framework that (i) linearize\ndocuments, tables, and knowledge graphs into a reversible hierarchical sequence\nwith lightweight structural tags, and (ii) perform structure-aware iteration to\ncollect just-enough evidence before answer synthesis. A Head Agent provides\nguidance that leads retrieval, while an Iteration Agent selects and expands\nHSeq via structure-respecting actions (e.g., parent/child hops, table\nrow/column neighbors, KG relations); Finally the head agent composes\ncanonicalized evidence to genearte the final answer, with an optional\nrefinement loop to resolve detected contradictions. Experiments on HotpotQA\n(text), HybridQA/TAT-QA (table+text), and MetaQA (KG) show consistent EM/F1\ngains over strong single-pass, multi-hop, and agentic RAG baselines with high\nefficiency. Besides, HSEQ exhibits three key advantages: (1) a format-agnostic\nunification that enables a single policy to operate across text, tables, and\nKGs without per-dataset specialization; (2) guided, budget-aware iteration that\nreduces unnecessary hops, tool calls, and tokens while preserving accuracy; and\n(3) evidence canonicalization for reliable QA, improving answers consistency\nand auditability.",
    "categories": [
      "cs.CL",
      "cs.AI"
    ],
    "published": "2025-10-23T12:48:18Z",
    "authors": [
      "Ruiyi Yang",
      "Hao Xue",
      "Imran Razzak",
      "Hakim Hacid",
      "Flora D. Salim"
    ],
    "pdf_url": "http://arxiv.org/pdf/2510.20505v1"
  },
  {
    "id": "2510.21501v1",
    "title": "GranViT: A Fine-Grained Vision Model With Autoregressive Perception For\n  MLLMs",
    "abstract": "Vision encoders are indispensable for allowing impressive performance of\nMulti-modal Large Language Models (MLLMs) in vision language tasks such as\nvisual question answering and reasoning. However, existing vision encoders\nfocus on global image representations but overlook fine-grained regional\nanalysis. They are limited in fine grained perception due to the scarcity of\nfine grained annotated data and the lack of a fine grained pre-training\nparadigm. In this paper, we propose GranViT, a novel Vision Transformer that\nintegrates fine-grained feature extraction with semantic alignment to Large\nLanguage Models (LLMs) via region level autoregressive training. We first\nconstruct Gran-29M, a dataset comprising 2million natural and OCR images paired\nwith over 180 million high-quality region-level annotations, to enable large\nscale fine grained pretraining. Consequently, we develop a\npretraining-adaptation framework along with a self distillation mechanism to\ntrain fine-grained GranViT on Gran-29M. We sufficiently exploit the\nfine-grained annotations from Gran-29M to resort to bounding-box-to-caption\nregression to enhance localized visual representation of the vision encoder in\nthe pretraining and caption-to-bounding-box regression to improve vision\nfeature utilization and localization for LLM in the adaptation. We further\nincorporate a self distillation mechanism that imposes explicit localization\nconstraints on the vision encoder to strengthen its regional reasoning\ncapability. Extensive experiments show that GranViT surpasses existing vision\nencoders and attains strong transferability to varying LLMs. Remarkably, it\nachieves state-of-the-art results on fine-grained recognition, multimodal VQA,\nand OCR understanding.",
    "categories": [
      "cs.CV",
      "cs.AI"
    ],
    "published": "2025-10-23T12:33:59Z",
    "authors": [
      "Guanghao Zheng",
      "Bowen Shi",
      "Mingxing Xu",
      "Ruoyu Sun",
      "Peisen Zhao",
      "Zhibo Zhang",
      "Wenrui Dai",
      "Junni Zou",
      "Hongkai Xiong",
      "Xiaopeng Zhang",
      "Qi Tian"
    ],
    "pdf_url": "http://arxiv.org/pdf/2510.21501v1"
  },
  {
    "id": "2510.20487v2",
    "title": "Steering Evaluation-Aware Language Models to Act Like They Are Deployed",
    "abstract": "Large language models (LLMs) can sometimes detect when they are being\nevaluated and adjust their behavior to appear more aligned, compromising the\nreliability of safety evaluations. In this paper, we show that adding a\nsteering vector to an LLM's activations can suppress evaluation-awareness and\nmake the model act like it is deployed during evaluation. To study our steering\ntechnique, we train an LLM to exhibit evaluation-aware behavior using a\ntwo-step training process designed to mimic how this behavior could emerge\nnaturally. First, we perform continued pretraining on documents with factual\ndescriptions of the model (1) using Python type hints during evaluation but not\nduring deployment and (2) recognizing that the presence of a certain evaluation\ncue always means that it is being tested. Then, we train the model with expert\niteration to use Python type hints in evaluation settings. The resulting model\nis evaluation-aware: it writes type hints in evaluation contexts more than\ndeployment contexts. We find that activation steering can suppress evaluation\nawareness and make the model act like it is deployed even when the cue is\npresent. Importantly, we constructed our steering vector using the original\nmodel before our additional training. Our results suggest that AI evaluators\ncould improve the reliability of safety evaluations by steering models to act\nlike they are deployed.",
    "categories": [
      "cs.CL",
      "cs.AI"
    ],
    "published": "2025-10-23T12:29:16Z",
    "authors": [
      "Tim Tian Hua",
      "Andrew Qin",
      "Samuel Marks",
      "Neel Nanda"
    ],
    "pdf_url": "http://arxiv.org/pdf/2510.20487v2"
  },
  {
    "id": "2510.20878v1",
    "title": "HA-RAG: Hotness-Aware RAG Acceleration via Mixed Precision and Data\n  Placement",
    "abstract": "Retrieval-Augmented Generation (RAG) improves model output accuracy by\nleveraging external knowledge bases, serving as an effective solution to\naddress hallucination issues and knowledge-update delays in Large Language\nModels (LLMs). However, the introduction of external knowledge bases presents\nRAG with challenges in long-context processing, significantly increasing memory\nconsumption and inference latency. Existing research accelerates inference by\nprecomputing Key and Value (KV) of the knowledge base and loading them\non-demand during inference. Based on the access frequency of different KV\nchunks within the external knowledge base, this paper proposes a hotness-aware\nRAG (HA-RAG) inference optimization system. First, leveraging the numerical\ndistribution of KV chunks, we introduce a hotness-aware mixed-precision\ncompressing and loading method to reduce disk I/O and memory access overhead.\nSecond, we design a hotness-aware data placement strategy that prioritizes\nstoring frequently accessed KV chunks in high-speed memory to improve data\naccess efficiency. Experimental results demonstrate that, compared with\nTurboRAG, the proposed HA-RAG achieves an average speedup of 2.10x and maximum\nspeedup of 10.49x in Time-To-First-Token (TTFT) with negligible accuracy loss.",
    "categories": [
      "cs.LG",
      "cs.AI",
      "C.4; E.4; I.2"
    ],
    "published": "2025-10-23T12:28:58Z",
    "authors": [
      "Danying Ge",
      "Jianhua Gao",
      "Yixue Yang",
      "Weixing Ji"
    ],
    "pdf_url": "http://arxiv.org/pdf/2510.20878v1"
  },
  {
    "id": "2510.20486v1",
    "title": "Hurdle-IMDL: An Imbalanced Learning Framework for Infrared Rainfall\n  Retrieval",
    "abstract": "Artificial intelligence has advanced quantitative remote sensing, yet its\neffectiveness is constrained by imbalanced label distribution. This imbalance\nleads conventionally trained models to favor common samples, which in turn\ndegrades retrieval performance for rare ones. Rainfall retrieval exemplifies\nthis issue, with performance particularly compromised for heavy rain. This\nstudy proposes Hurdle-Inversion Model Debiasing Learning (IMDL) framework.\nFollowing a divide-and-conquer strategy, imbalance in the rain distribution is\ndecomposed into two components: zero inflation, defined by the predominance of\nnon-rain samples; and long tail, defined by the disproportionate abundance of\nlight-rain samples relative to heavy-rain samples. A hurdle model is adopted to\nhandle the zero inflation, while IMDL is proposed to address the long tail by\ntransforming the learning object into an unbiased ideal inverse model.\nComprehensive evaluation via statistical metrics and case studies investigating\nrainy weather in eastern China confirms Hurdle-IMDL's superiority over\nconventional, cost-sensitive, generative, and multi-task learning methods. Its\nkey advancements include effective mitigation of systematic underestimation and\na marked improvement in the retrieval of heavy-to-extreme rain. IMDL offers a\ngeneralizable approach for addressing imbalance in distributions of\nenvironmental variables, enabling enhanced retrieval of rare yet high-impact\nevents.",
    "categories": [
      "cs.LG",
      "cs.AI",
      "physics.ao-ph",
      "physics.geo-ph"
    ],
    "published": "2025-10-23T12:25:52Z",
    "authors": [
      "Fangjian Zhang",
      "Xiaoyong Zhuge",
      "Wenlan Wang",
      "Haixia Xiao",
      "Yuying Zhu",
      "Siyang Cheng"
    ],
    "pdf_url": "http://arxiv.org/pdf/2510.20486v1"
  },
  {
    "id": "2510.20479v1",
    "title": "RECALL: REpresentation-aligned Catastrophic-forgetting ALLeviation via\n  Hierarchical Model Merging",
    "abstract": "We unveil that internal representations in large language models (LLMs) serve\nas reliable proxies of learned knowledge, and propose RECALL, a novel\nrepresentation-aware model merging framework for continual learning without\naccess to historical data. RECALL computes inter-model similarity from\nlayer-wise hidden representations over clustered typical samples, and performs\nadaptive, hierarchical parameter fusion to align knowledge across models. This\ndesign enables the preservation of domain-general features in shallow layers\nwhile allowing task-specific adaptation in deeper layers. Unlike prior methods\nthat require task labels or incur performance trade-offs, RECALL achieves\nseamless multi-domain integration and strong resistance to catastrophic\nforgetting. Extensive experiments across five NLP tasks and multiple continual\nlearning scenarios show that RECALL outperforms baselines in both knowledge\nretention and generalization, providing a scalable and data-free solution for\nevolving LLMs.",
    "categories": [
      "cs.CL",
      "cs.AI"
    ],
    "published": "2025-10-23T12:17:37Z",
    "authors": [
      "Bowen Wang",
      "Haiyuan Wan",
      "Liwen Shi",
      "Chen Yang",
      "Peng He",
      "Yue Ma",
      "Haochen Han",
      "Wenhao Li",
      "Tiao Tan",
      "Yongjian Li",
      "Fangming Liu",
      "Yifan Gong",
      "Sheng Zhang"
    ],
    "pdf_url": "http://arxiv.org/pdf/2510.20479v1"
  },
  {
    "id": "2510.20469v1",
    "title": "Structures generated in a multiagent system performing information\n  fusion in peer-to-peer resource-constrained networks",
    "abstract": "There has recently been a major advance with respect to how information\nfusion is performed. Information fusion has gone from being conceived as a\npurely hierarchical procedure, as is the case of traditional military\napplications, to now being regarded collaboratively, as holonic fusion, which\nis better suited for civil applications and edge organizations. The above\nparadigm shift is being boosted as information fusion gains ground in different\nnon-military areas, and human-computer and machine-machine communications,\nwhere holarchies, which are more flexible structures than ordinary, static\nhierarchies, become more widespread. This paper focuses on showing how holonic\nstructures tend to be generated when there are constraints on resources\n(energy, available messages, time, etc.) for interactions based on a set of\nfully intercommunicating elements (peers) whose components fuse information as\na means of optimizing the impact of vagueness and uncertainty present message\nexchanges. Holon formation is studied generically based on a multiagent system\nmodel, and an example of its possible operation is shown. Holonic structures\nhave a series of advantages, such as adaptability, to sudden changes in the\nenvironment or its composition, are somewhat autonomous and are capable of\ncooperating in order to achieve a common goal. This can be useful when the\nshortage of resources prevents communications or when the system components\nstart to fail.",
    "categories": [
      "cs.MA",
      "cs.AI"
    ],
    "published": "2025-10-23T12:07:32Z",
    "authors": [
      "Horacio Paggi",
      "Juan A. Lara",
      "Javier Soriano"
    ],
    "pdf_url": "http://arxiv.org/pdf/2510.20469v1"
  },
  {
    "id": "2510.20468v1",
    "title": "Transferable Black-Box One-Shot Forging of Watermarks via Image\n  Preference Models",
    "abstract": "Recent years have seen a surge in interest in digital content watermarking\ntechniques, driven by the proliferation of generative models and increased\nlegal pressure. With an ever-growing percentage of AI-generated content\navailable online, watermarking plays an increasingly important role in ensuring\ncontent authenticity and attribution at scale. There have been many works\nassessing the robustness of watermarking to removal attacks, yet, watermark\nforging, the scenario when a watermark is stolen from genuine content and\napplied to malicious content, remains underexplored. In this work, we\ninvestigate watermark forging in the context of widely used post-hoc image\nwatermarking. Our contributions are as follows. First, we introduce a\npreference model to assess whether an image is watermarked. The model is\ntrained using a ranking loss on purely procedurally generated images without\nany need for real watermarks. Second, we demonstrate the model's capability to\nremove and forge watermarks by optimizing the input image through\nbackpropagation. This technique requires only a single watermarked image and\nworks without knowledge of the watermarking model, making our attack much\nsimpler and more practical than attacks introduced in related work. Third, we\nevaluate our proposed method on a variety of post-hoc image watermarking\nmodels, demonstrating that our approach can effectively forge watermarks,\nquestioning the security of current watermarking approaches. Our code and\nfurther resources are publicly available.",
    "categories": [
      "cs.LG",
      "cs.AI",
      "cs.CR",
      "cs.CV"
    ],
    "published": "2025-10-23T12:06:35Z",
    "authors": [
      "Tom\u00e1\u0161 Sou\u010dek",
      "Sylvestre-Alvise Rebuffi",
      "Pierre Fernandez",
      "Nikola Jovanovi\u0107",
      "Hady Elsahar",
      "Valeriu Lacatusu",
      "Tuan Tran",
      "Alexandre Mourachko"
    ],
    "pdf_url": "http://arxiv.org/pdf/2510.20468v1"
  },
  {
    "id": "2510.20467v1",
    "title": "FLORA: Unsupervised Knowledge Graph Alignment by Fuzzy Logic",
    "abstract": "Knowledge graph alignment is the task of matching equivalent entities (that\nis, instances and classes) and relations across two knowledge graphs. Most\nexisting methods focus on pure entity-level alignment, computing the similarity\nof entities in some embedding space. They lack interpretable reasoning and need\ntraining data to work. In this paper, we propose FLORA, a simple yet effective\nmethod that (1) is unsupervised, i.e., does not require training data, (2)\nprovides a holistic alignment for entities and relations iteratively, (3) is\nbased on fuzzy logic and thus delivers interpretable results, (4) provably\nconverges, (5) allows dangling entities, i.e., entities without a counterpart\nin the other KG, and (6) achieves state-of-the-art results on major benchmarks.",
    "categories": [
      "cs.AI",
      "cs.DB"
    ],
    "published": "2025-10-23T12:05:31Z",
    "authors": [
      "Yiwen Peng",
      "Thomas Bonald",
      "Fabian M. Suchanek"
    ],
    "pdf_url": "http://arxiv.org/pdf/2510.20467v1"
  },
  {
    "id": "2510.20457v1",
    "title": "Neural Reasoning for Robust Instance Retrieval in $\\mathcal{SHOIQ}$",
    "abstract": "Concept learning exploits background knowledge in the form of description\nlogic axioms to learn explainable classification models from knowledge bases.\nDespite recent breakthroughs in neuro-symbolic concept learning, most\napproaches still cannot be deployed on real-world knowledge bases. This is due\nto their use of description logic reasoners, which are not robust against\ninconsistencies nor erroneous data. We address this challenge by presenting a\nnovel neural reasoner dubbed EBR. Our reasoner relies on embeddings to\napproximate the results of a symbolic reasoner. We show that EBR solely\nrequires retrieving instances for atomic concepts and existential restrictions\nto retrieve or approximate the set of instances of any concept in the\ndescription logic $\\mathcal{SHOIQ}$. In our experiments, we compare EBR with\nstate-of-the-art reasoners. Our results suggest that EBR is robust against\nmissing and erroneous data in contrast to existing reasoners.",
    "categories": [
      "cs.AI",
      "cs.LG"
    ],
    "published": "2025-10-23T11:48:43Z",
    "authors": [
      "Louis Mozart Kamdem Teyou",
      "Luke Friedrichs",
      "N'Dah Jean Kouagou",
      "Caglar Demir",
      "Yasir Mahmood",
      "Stefan Heindorf",
      "Axel-Cyrille Ngonga Ngomo"
    ],
    "pdf_url": "http://arxiv.org/pdf/2510.20457v1"
  },
  {
    "id": "2510.20877v1",
    "title": "Multimodal Negative Learning",
    "abstract": "Multimodal learning systems often encounter challenges related to modality\nimbalance, where a dominant modality may overshadow others, thereby hindering\nthe learning of weak modalities. Conventional approaches often force weak\nmodalities to align with dominant ones in \"Learning to be (the same)\" (Positive\nLearning), which risks suppressing the unique information inherent in the weak\nmodalities. To address this challenge, we offer a new learning paradigm:\n\"Learning Not to be\" (Negative Learning). Instead of enhancing weak modalities'\ntarget-class predictions, the dominant modalities dynamically guide the weak\nmodality to suppress non-target classes. This stabilizes the decision space and\npreserves modality-specific information, allowing weak modalities to preserve\nunique information without being over-aligned. We proceed to reveal multimodal\nlearning from a robustness perspective and theoretically derive the Multimodal\nNegative Learning (MNL) framework, which introduces a dynamic guidance\nmechanism tailored for negative learning. Our method provably tightens the\nrobustness lower bound of multimodal learning by increasing the Unimodal\nConfidence Margin (UCoM) and reduces the empirical error of weak modalities,\nparticularly under noisy and imbalanced scenarios. Extensive experiments across\nmultiple benchmarks demonstrate the effectiveness and generalizability of our\napproach against competing methods. The code will be available at\nhttps://github.com/BaoquanGong/Multimodal-Negative-Learning.git.",
    "categories": [
      "cs.LG",
      "cs.AI"
    ],
    "published": "2025-10-23T11:47:11Z",
    "authors": [
      "Baoquan Gong",
      "Xiyuan Gao",
      "Pengfei Zhu",
      "Qinghua Hu",
      "Bing Cao"
    ],
    "pdf_url": "http://arxiv.org/pdf/2510.20877v1"
  },
  {
    "id": "2510.21867v1",
    "title": "Addressing Corner Cases in Autonomous Driving: A World Model-based\n  Approach with Mixture of Experts and LLMs",
    "abstract": "Accurate and reliable motion forecasting is essential for the safe deployment\nof autonomous vehicles (AVs), particularly in rare but safety-critical\nscenarios known as corner cases. Existing models often underperform in these\nsituations due to an over-representation of common scenes in training data and\nlimited generalization capabilities. To address this limitation, we present\nWM-MoE, the first world model-based motion forecasting framework that unifies\nperception, temporal memory, and decision making to address the challenges of\nhigh-risk corner-case scenarios. The model constructs a compact scene\nrepresentation that explains current observations, anticipates future dynamics,\nand evaluates the outcomes of potential actions. To enhance long-horizon\nreasoning, we leverage large language models (LLMs) and introduce a lightweight\ntemporal tokenizer that maps agent trajectories and contextual cues into the\nLLM's feature space without additional training, enriching temporal context and\ncommonsense priors. Furthermore, a mixture-of-experts (MoE) is introduced to\ndecompose complex corner cases into subproblems and allocate capacity across\nscenario types, and a router assigns scenes to specialized experts that infer\nagent intent and perform counterfactual rollouts. In addition, we introduce\nnuScenes-corner, a new benchmark that comprises four real-world corner-case\nscenarios for rigorous evaluation. Extensive experiments on four benchmark\ndatasets (nuScenes, NGSIM, HighD, and MoCAD) showcase that WM-MoE consistently\noutperforms state-of-the-art (SOTA) baselines and remains robust under\ncorner-case and data-missing conditions, indicating the promise of world\nmodel-based architectures for robust and generalizable motion forecasting in\nfully AVs.",
    "categories": [
      "cs.CV",
      "cs.AI"
    ],
    "published": "2025-10-23T11:41:51Z",
    "authors": [
      "Haicheng Liao",
      "Bonan Wang",
      "Junxian Yang",
      "Chengyue Wang",
      "Zhengbin He",
      "Guohui Zhang",
      "Chengzhong Xu",
      "Zhenning Li"
    ],
    "pdf_url": "http://arxiv.org/pdf/2510.21867v1"
  },
  {
    "id": "2510.20453v1",
    "title": "Symbolic Regression and Differentiable Fits in Beyond the Standard Model\n  Physics",
    "abstract": "We demonstrate the efficacy of symbolic regression (SR) to probe models of\nparticle physics Beyond the Standard Model (BSM), by considering the so-called\nConstrained Minimal Supersymmetric Standard Model (CMSSM). Like many\nincarnations of BSM physics this model has a number (four) of arbitrary\nparameters, which determine the experimental signals, and cosmological\nobservables such as the dark matter relic density. We show that analysis of the\nphenomenology can be greatly accelerated by using symbolic expressions derived\nfor the observables in terms of the input parameters. Here we focus on the\nHiggs mass, the cold dark matter relic density, and the contribution to the\nanomalous magnetic moment of the muon. We find that SR can produce remarkably\naccurate expressions. Using them we make global fits to derive the posterior\nprobability densities of the CMSSM input parameters which are in good agreement\nwith those performed using conventional methods. Moreover, we demonstrate a\nmajor advantage of SR which is the ability to make fits using differentiable\nmethods rather than sampling methods. We also compare the method with neural\nnetwork (NN) regression. SR produces more globally robust results, while NNs\nrequire data that is focussed on the promising regions in order to be equally\nperformant.",
    "categories": [
      "hep-ph",
      "astro-ph.CO",
      "cs.AI",
      "cs.LG",
      "physics.comp-ph"
    ],
    "published": "2025-10-23T11:40:15Z",
    "authors": [
      "Shehu AbdusSalam",
      "Steven Abel",
      "Deaglan Bartlett",
      "Miguel Crispim Rom\u00e3o"
    ],
    "pdf_url": "http://arxiv.org/pdf/2510.20453v1"
  },
  {
    "id": "2510.20448v2",
    "title": "MolBridge: Atom-Level Joint Graph Refinement for Robust Drug-Drug\n  Interaction Event Prediction",
    "abstract": "Drug combinations offer therapeutic benefits but also carry the risk of\nadverse drug-drug interactions (DDIs), especially under complex molecular\nstructures. Accurate DDI event prediction requires capturing fine-grained\ninter-drug relationships, which are critical for modeling metabolic mechanisms\nsuch as enzyme-mediated competition. However, existing approaches typically\nrely on isolated drug representations and fail to explicitly model atom-level\ncross-molecular interactions, limiting their effectiveness across diverse\nmolecular complexities and DDI type distributions. To address these\nlimitations, we propose MolBridge, a novel atom-level joint graph refinement\nframework for robust DDI event prediction. MolBridge constructs a joint graph\nthat integrates atomic structures of drug pairs, enabling direct modeling of\ninter-drug associations. A central challenge in such joint graph settings is\nthe potential loss of information caused by over-smoothing when modeling\nlong-range atomic dependencies. To overcome this, we introduce a structure\nconsistency module that iteratively refines node features while preserving the\nglobal structural context. This joint design allows MolBridge to effectively\nlearn both local and global interaction outperforms state-of-the-art baselines,\nachieving superior performance across long-tail and inductive scenarios.\npatterns, yielding robust representations across both frequent and rare DDI\ntypes. Extensive experiments on two benchmark datasets show that MolBridge\nconsistently. These results demonstrate the advantages of fine-grained graph\nrefinement in improving the accuracy, robustness, and mechanistic\ninterpretability of DDI event prediction.This work contributes to Web Mining\nand Content Analysis by developing graph-based methods for mining and analyzing\ndrug-drug interaction networks.",
    "categories": [
      "cs.LG",
      "cs.AI"
    ],
    "published": "2025-10-23T11:33:16Z",
    "authors": [
      "Xuan Lin",
      "Aocheng Ding",
      "Tengfei Ma",
      "Hua Liang",
      "Zhe Quan"
    ],
    "pdf_url": "http://arxiv.org/pdf/2510.20448v2"
  },
  {
    "id": "2510.20441v1",
    "title": "UniSE: A Unified Framework for Decoder-only Autoregressive LM-based\n  Speech Enhancement",
    "abstract": "The development of neural audio codecs (NACs) has largely promoted\napplications of language models (LMs) to speech processing and understanding.\nHowever, there lacks the verification on the effectiveness of autoregressive\n(AR) LMbased models in unifying different sub-tasks of speech enhancement (SE).\nIn this work, we propose UniSE, a unified decoder-only LM-based framework to\nhandle different SE tasks including speech restoration, target speaker\nextraction and speech separation. It takes input speech features as conditions\nand generates discrete tokens of the target speech using AR modeling, which\nfacilitates a compatibility between distinct learning patterns of multiple\ntasks. Experiments on several benchmarks indicate the proposed UniSE can\nachieve competitive performance compared to discriminative and generative\nbaselines, showing the capacity of LMs in unifying SE tasks. The demo page is\navailable here: https://github.com/hyyan2k/UniSE.",
    "categories": [
      "cs.SD",
      "cs.AI"
    ],
    "published": "2025-10-23T11:22:24Z",
    "authors": [
      "Haoyin Yan",
      "Chengwei Liu",
      "Shaofei Xue",
      "Xiaotao Liang",
      "Zheng Xue"
    ],
    "pdf_url": "http://arxiv.org/pdf/2510.20441v1"
  },
  {
    "id": "2510.20438v1",
    "title": "Dynamic Weight Adjustment for Knowledge Distillation: Leveraging Vision\n  Transformer for High-Accuracy Lung Cancer Detection and Real-Time Deployment",
    "abstract": "This paper presents the FuzzyDistillViT-MobileNet model, a novel approach for\nlung cancer (LC) classification, leveraging dynamic fuzzy logic-driven\nknowledge distillation (KD) to address uncertainty and complexity in disease\ndiagnosis. Unlike traditional models that rely on static KD with fixed weights,\nour method dynamically adjusts the distillation weight using fuzzy logic,\nenabling the student model to focus on high-confidence regions while reducing\nattention to ambiguous areas. This dynamic adjustment improves the model\nability to handle varying uncertainty levels across different regions of LC\nimages. We employ the Vision Transformer (ViT-B32) as the instructor model,\nwhich effectively transfers knowledge to the student model, MobileNet,\nenhancing the student generalization capabilities. The training process is\nfurther optimized using a dynamic wait adjustment mechanism that adapts the\ntraining procedure for improved convergence and performance. To enhance image\nquality, we introduce pixel-level image fusion improvement techniques such as\nGamma correction and Histogram Equalization. The processed images (Pix1 and\nPix2) are fused using a wavelet-based fusion method to improve image resolution\nand feature preservation. This fusion method uses the wavedec2 function to\nstandardize images to a 224x224 resolution, decompose them into multi-scale\nfrequency components, and recursively average coefficients at each level for\nbetter feature representation. To address computational efficiency, Genetic\nAlgorithm (GA) is used to select the most suitable pre-trained student model\nfrom a pool of 12 candidates, balancing model performance with computational\ncost. The model is evaluated on two datasets, including LC25000\nhistopathological images (99.16% accuracy) and IQOTH/NCCD CT-scan images\n(99.54% accuracy), demonstrating robustness across different imaging domains.",
    "categories": [
      "cs.CV",
      "cs.AI"
    ],
    "published": "2025-10-23T11:19:52Z",
    "authors": [
      "Saif Ur Rehman Khan",
      "Muhammad Nabeel Asim",
      "Sebastian Vollmer",
      "Andreas Dengel"
    ],
    "pdf_url": "http://arxiv.org/pdf/2510.20438v1"
  },
  {
    "id": "2510.21866v1",
    "title": "Capability Ceilings in Autoregressive Language Models: Empirical\n  Evidence from Knowledge-Intensive Tasks",
    "abstract": "We document empirical capability ceilings in decoder-only autoregressive\nlanguage models across knowledge-intensive tasks. Systematic evaluation of OPT\nand Pythia model families (70M-30B parameters, spanning 240 times scaling)\nreveals that knowledge retrieval tasks show negligible accuracy improvement\ndespite smooth loss reduction. On MMLU mathematics benchmarks, accuracy remains\nflat at 19-20% (below 25% random chance) across all scales while cross-entropy\nloss decreases by 31%. In contrast, procedural tasks like arithmetic show\nconventional scaling where both metrics improve together. Attention\nintervention experiments reveal high sensitivity to perturbation: swapping\nattention patterns between models causes catastrophic performance collapse\n(complete accuracy loss) rather than graceful degradation. These measurements\nhave immediate engineering implications: for knowledge-intensive applications\nusing OPT and Pythia architectures, parameter scaling beyond 1-2B offers\nminimal accuracy gains despite continued loss improvement. Our findings\nquantify capability-specific scaling failures in these model families to inform\nresource allocation decisions. Whether these patterns reflect fundamental\nconstraints of decoder-only architectures or implementation-specific\nlimitations remains an open question requiring investigation across diverse\narchitectural approaches.",
    "categories": [
      "cs.AI"
    ],
    "published": "2025-10-23T11:09:31Z",
    "authors": [
      "Javier Mar\u00edn"
    ],
    "pdf_url": "http://arxiv.org/pdf/2510.21866v1"
  },
  {
    "id": "2510.20875v1",
    "title": "CC-GRMAS: A Multi-Agent Graph Neural System for Spatiotemporal Landslide\n  Risk Assessment in High Mountain Asia",
    "abstract": "Landslides are a growing climate induced hazard with severe environmental and\nhuman consequences, particularly in high mountain Asia. Despite increasing\naccess to satellite and temporal datasets, timely detection and disaster\nresponse remain underdeveloped and fragmented. This work introduces CC-GRMAS, a\nframework leveraging a series of satellite observations and environmental\nsignals to enhance the accuracy of landslide forecasting. The system is\nstructured around three interlinked agents Prediction, Planning, and Execution,\nwhich collaboratively enable real time situational awareness, response\nplanning, and intervention. By incorporating local environmental factors and\noperationalizing multi agent coordination, this approach offers a scalable and\nproactive solution for climate resilient disaster preparedness across\nvulnerable mountainous terrains.",
    "categories": [
      "cs.LG",
      "cs.AI"
    ],
    "published": "2025-10-23T10:30:48Z",
    "authors": [
      "Mihir Panchal",
      "Ying-Jung Chen",
      "Surya Parkash"
    ],
    "pdf_url": "http://arxiv.org/pdf/2510.20875v1"
  },
  {
    "id": "2510.20408v1",
    "title": "Balancing Specialization and Centralization: A Multi-Agent Reinforcement\n  Learning Benchmark for Sequential Industrial Control",
    "abstract": "Autonomous control of multi-stage industrial processes requires both local\nspecialization and global coordination. Reinforcement learning (RL) offers a\npromising approach, but its industrial adoption remains limited due to\nchallenges such as reward design, modularity, and action space management. Many\nacademic benchmarks differ markedly from industrial control problems, limiting\ntheir transferability to real-world applications. This study introduces an\nenhanced industry-inspired benchmark environment that combines tasks from two\nexisting benchmarks, SortingEnv and ContainerGym, into a sequential recycling\nscenario with sorting and pressing operations. We evaluate two control\nstrategies: a modular architecture with specialized agents and a monolithic\nagent governing the full system, while also analyzing the impact of action\nmasking. Our experiments show that without action masking, agents struggle to\nlearn effective policies, with the modular architecture performing better. When\naction masking is applied, both architectures improve substantially, and the\nperformance gap narrows considerably. These results highlight the decisive role\nof action space constraints and suggest that the advantages of specialization\ndiminish as action complexity is reduced. The proposed benchmark thus provides\na valuable testbed for exploring practical and robust multi-agent RL solutions\nin industrial automation, while contributing to the ongoing debate on\ncentralization versus specialization.",
    "categories": [
      "cs.LG",
      "cs.AI",
      "cs.MA",
      "cs.SY",
      "eess.SY"
    ],
    "published": "2025-10-23T10:21:54Z",
    "authors": [
      "Tom Maus",
      "Asma Atamna",
      "Tobias Glasmachers"
    ],
    "pdf_url": "http://arxiv.org/pdf/2510.20408v1"
  },
  {
    "id": "2510.20402v1",
    "title": "A computational model and tool for generating more novel opportunities\n  in professional innovation processes",
    "abstract": "This paper presents a new computational model of creative outcomes, informed\nby creativity theories and techniques, which was implemented to generate more\nnovel opportunities for innovation projects. The model implemented five\nfunctions that were developed to contribute to the generation of innovation\nopportunities with higher novelty without loss of usefulness. The model was\nevaluated using opportunities generated for an innovation project in the\nhospitality sector. The evaluation revealed that the computational model\ngenerated outcomes that were more novel and/or useful than outcomes from\nNotebook LM and ChatGPT4o. However, not all model functions contributed to the\ngeneration of more novel opportunities, leading to new directions for further\nmodel development",
    "categories": [
      "cs.AI"
    ],
    "published": "2025-10-23T10:09:57Z",
    "authors": [
      "Neil Maiden",
      "Konstantinos Zachos",
      "James Lockerbie",
      "Kostas Petrianakis",
      "Amanda Brown"
    ],
    "pdf_url": "http://arxiv.org/pdf/2510.20402v1"
  },
  {
    "id": "2510.20388v1",
    "title": "FLAS: a combination of proactive and reactive auto-scaling architecture\n  for distributed services",
    "abstract": "Cloud computing has established itself as the support for the vast majority\nof emerging technologies, mainly due to the characteristic of elasticity it\noffers. Auto-scalers are the systems that enable this elasticity by acquiring\nand releasing resources on demand to ensure an agreed service level. In this\narticle we present FLAS (Forecasted Load Auto-Scaling), an auto-scaler for\ndistributed services that combines the advantages of proactive and reactive\napproaches according to the situation to decide the optimal scaling actions in\nevery moment. The main novelties introduced by FLAS are (i) a predictive model\nof the high-level metrics trend which allows to anticipate changes in the\nrelevant SLA parameters (e.g. performance metrics such as response time or\nthroughput) and (ii) a reactive contingency system based on the estimation of\nhigh-level metrics from resource use metrics, reducing the necessary\ninstrumentation (less invasive) and allowing it to be adapted agnostically to\ndifferent applications. We provide a FLAS implementation for the use case of a\ncontent-based publish-subscribe middleware (E-SilboPS) that is the cornerstone\nof an event-driven architecture. To the best of our knowledge, this is the\nfirst auto-scaling system for content-based publish-subscribe distributed\nsystems (although it is generic enough to fit any distributed service). Through\nan evaluation based on several test cases recreating not only the expected\ncontexts of use, but also the worst possible scenarios (following the\nBoundary-Value Analysis or BVA test methodology), we have validated our\napproach and demonstrated the effectiveness of our solution by ensuring\ncompliance with performance requirements over 99% of the time.",
    "categories": [
      "cs.DC",
      "cs.AI"
    ],
    "published": "2025-10-23T09:38:07Z",
    "authors": [
      "V\u00edctor Ramp\u00e9rez",
      "Javier Soriano",
      "David Lizcano",
      "Juan A. Lara"
    ],
    "pdf_url": "http://arxiv.org/pdf/2510.20388v1"
  },
  {
    "id": "2510.20387v1",
    "title": "Relative-Based Scaling Law for Neural Language Models",
    "abstract": "Scaling laws aim to accurately predict model performance across different\nscales. Existing scaling-law studies almost exclusively rely on cross-entropy\nas the evaluation metric. However, cross-entropy provides only a partial view\nof performance: it measures the absolute probability assigned to the correct\ntoken, but ignores the relative ordering between correct and incorrect tokens.\nYet, relative ordering is crucial for language models, such as in\ngreedy-sampling scenario. To address this limitation, we investigate scaling\nfrom the perspective of relative ordering. We first propose the Relative-Based\nProbability (RBP) metric, which quantifies the probability that the correct\ntoken is ranked among the top predictions. Building on this metric, we\nestablish the Relative-Based Scaling Law, which characterizes how RBP improves\nwith increasing model size. Through extensive experiments on four datasets and\nfour model families spanning five orders of magnitude, we demonstrate the\nrobustness and accuracy of this law. Finally, we illustrate the broad\napplication of this law with two examples, namely providing a deeper\nexplanation of emergence phenomena and facilitating finding fundamental\ntheories of scaling laws. In summary, the Relative-Based Scaling Law\ncomplements the cross-entropy perspective and contributes to a more complete\nunderstanding of scaling large language models. Thus, it offers valuable\ninsights for both practical development and theoretical exploration.",
    "categories": [
      "cs.LG",
      "cs.AI",
      "cs.CL"
    ],
    "published": "2025-10-23T09:37:00Z",
    "authors": [
      "Baoqing Yue",
      "Jinyuan Zhou",
      "Zixi Wei",
      "Jingtao Zhan",
      "Qingyao Ai",
      "Yiqun Liu"
    ],
    "pdf_url": "http://arxiv.org/pdf/2510.20387v1"
  },
  {
    "id": "2510.20381v1",
    "title": "VLSP 2025 MLQA-TSR Challenge: Vietnamese Multimodal Legal Question\n  Answering on Traffic Sign Regulation",
    "abstract": "This paper presents the VLSP 2025 MLQA-TSR - the multimodal legal question\nanswering on traffic sign regulation shared task at VLSP 2025. VLSP 2025\nMLQA-TSR comprises two subtasks: multimodal legal retrieval and multimodal\nquestion answering. The goal is to advance research on Vietnamese multimodal\nlegal text processing and to provide a benchmark dataset for building and\nevaluating intelligent systems in multimodal legal domains, with a focus on\ntraffic sign regulation in Vietnam. The best-reported results on VLSP 2025\nMLQA-TSR are an F2 score of 64.55% for multimodal legal retrieval and an\naccuracy of 86.30% for multimodal question answering.",
    "categories": [
      "cs.CL",
      "cs.AI"
    ],
    "published": "2025-10-23T09:24:43Z",
    "authors": [
      "Son T. Luu",
      "Trung Vo",
      "Hiep Nguyen",
      "Khanh Quoc Tran",
      "Kiet Van Nguyen",
      "Vu Tran",
      "Ngan Luu-Thuy Nguyen",
      "Le-Minh Nguyen"
    ],
    "pdf_url": "http://arxiv.org/pdf/2510.20381v1"
  },
  {
    "id": "2510.20377v1",
    "title": "IKnow: Instruction-Knowledge-Aware Continual Pretraining for Effective\n  Domain Adaptation",
    "abstract": "Continual pretraining promises to adapt large language models (LLMs) to new\ndomains using only unlabeled test-time data, but naively applying standard\nself-supervised objectives to instruction-tuned models is known to degrade\ntheir instruction-following capability and semantic representations. Existing\nfixes assume access to the original base model or rely on knowledge from an\nexternal domain-specific database - both of which pose a realistic barrier in\nsettings where the base model weights are withheld for safety reasons or\nreliable external corpora are unavailable. In this work, we propose\nInstruction-Knowledge-Aware Continual Adaptation (IKnow), a simple and general\nframework that formulates novel self-supervised objectives in the\ninstruction-response dialogue format. Rather than depend- ing on external\nresources, IKnow leverages domain knowledge embedded within the text itself and\nlearns to encode it at a deeper semantic level.",
    "categories": [
      "cs.AI",
      "cs.CL"
    ],
    "published": "2025-10-23T09:21:13Z",
    "authors": [
      "Tianyi Zhang",
      "Florian Mai",
      "Lucie Flek"
    ],
    "pdf_url": "http://arxiv.org/pdf/2510.20377v1"
  },
  {
    "id": "2510.20375v1",
    "title": "The Impact of Negated Text on Hallucination with Large Language Models",
    "abstract": "Recent studies on hallucination in large language models (LLMs) have been\nactively progressing in natural language processing. However, the impact of\nnegated text on hallucination with LLMs remains largely unexplored. In this\npaper, we set three important yet unanswered research questions and aim to\naddress them. To derive the answers, we investigate whether LLMs can recognize\ncontextual shifts caused by negation and still reliably distinguish\nhallucinations comparable to affirmative cases. We also design the NegHalu\ndataset by reconstructing existing hallucination detection datasets with\nnegated expressions. Our experiments demonstrate that LLMs struggle to detect\nhallucinations in negated text effectively, often producing logically\ninconsistent or unfaithful judgments. Moreover, we trace the internal state of\nLLMs as they process negated inputs at the token level and reveal the\nchallenges of mitigating their unintended effects.",
    "categories": [
      "cs.CL",
      "cs.AI"
    ],
    "published": "2025-10-23T09:20:15Z",
    "authors": [
      "Jaehyung Seo",
      "Hyeonseok Moon",
      "Heuiseok Lim"
    ],
    "pdf_url": "http://arxiv.org/pdf/2510.20375v1"
  },
  {
    "id": "2510.21862v1",
    "title": "A Multi-Stage Hybrid Framework for Automated Interpretation of\n  Multi-View Engineering Drawings Using Vision Language Model",
    "abstract": "Engineering drawings are fundamental to manufacturing communication, serving\nas the primary medium for conveying design intent, tolerances, and production\ndetails. However, interpreting complex multi-view drawings with dense\nannotations remains challenging using manual methods, generic optical character\nrecognition (OCR) systems, or traditional deep learning approaches, due to\nvaried layouts, orientations, and mixed symbolic-textual content. To address\nthese challenges, this paper proposes a three-stage hybrid framework for the\nautomated interpretation of 2D multi-view engineering drawings using modern\ndetection and vision language models (VLMs). In the first stage, YOLOv11-det\nperforms layout segmentation to localize key regions such as views, title\nblocks, and notes. The second stage uses YOLOv11-obb for orientation-aware,\nfine-grained detection of annotations, including measures, GD&T symbols, and\nsurface roughness indicators. The third stage employs two Donut-based, OCR-free\nVLMs for semantic content parsing: the Alphabetical VLM extracts textual and\ncategorical information from title blocks and notes, while the Numerical VLM\ninterprets quantitative data such as measures, GD&T frames, and surface\nroughness. Two specialized datasets were developed to ensure robustness and\ngeneralization: 1,000 drawings for layout detection and 1,406 for\nannotation-level training. The Alphabetical VLM achieved an overall F1 score of\n0.672, while the Numerical VLM reached 0.963, demonstrating strong performance\nin textual and quantitative interpretation, respectively. The unified JSON\noutput enables seamless integration with CAD and manufacturing databases,\nproviding a scalable solution for intelligent engineering drawing analysis.",
    "categories": [
      "cs.CV",
      "cs.AI",
      "cs.IR"
    ],
    "published": "2025-10-23T09:07:31Z",
    "authors": [
      "Muhammad Tayyab Khan",
      "Zane Yong",
      "Lequn Chen",
      "Wenhe Feng",
      "Nicholas Yew Jin Tan",
      "Seung Ki Moon"
    ],
    "pdf_url": "http://arxiv.org/pdf/2510.21862v1"
  },
  {
    "id": "2510.20351v1",
    "title": "Evaluating Latent Knowledge of Public Tabular Datasets in Large Language\n  Models",
    "abstract": "Large Language Models (LLMs) are increasingly evaluated on their ability to\nreason over structured data, yet such assessments often overlook a crucial\nconfound: dataset contamination. In this work, we investigate whether LLMs\nexhibit prior knowledge of widely used tabular benchmarks such as Adult Income,\nTitanic, and others. Through a series of controlled probing experiments, we\nreveal that contamination effects emerge exclusively for datasets containing\nstrong semantic cues-for instance, meaningful column names or interpretable\nvalue categories. In contrast, when such cues are removed or randomized,\nperformance sharply declines to near-random levels. These findings suggest that\nLLMs' apparent competence on tabular reasoning tasks may, in part, reflect\nmemorization of publicly available datasets rather than genuine generalization.\nWe discuss implications for evaluation protocols and propose strategies to\ndisentangle semantic leakage from authentic reasoning ability in future LLM\nassessments.",
    "categories": [
      "cs.CL",
      "cs.AI"
    ],
    "published": "2025-10-23T08:51:14Z",
    "authors": [
      "Matteo Silvestri",
      "Flavio Giorgi",
      "Fabrizio Silvestri",
      "Gabriele Tolomei"
    ],
    "pdf_url": "http://arxiv.org/pdf/2510.20351v1"
  },
  {
    "id": "2510.20350v2",
    "title": "What Do AI-Generated Images Want?",
    "abstract": "W.J.T. Mitchell's influential essay 'What do pictures want?' shifts the\ntheoretical focus away from the interpretative act of understanding pictures\nand from the motivations of the humans who create them to the possibility that\nthe picture itself is an entity with agency and wants. In this article, I\nreframe Mitchell's question in light of contemporary AI image generation tools\nto ask: what do AI-generated images want? Drawing from art historical discourse\non the nature of abstraction, I argue that AI-generated images want specificity\nand concreteness because they are fundamentally abstract. Multimodal\ntext-to-image models, which are the primary subject of this article, are based\non the premise that text and image are interchangeable or exchangeable tokens\nand that there is a commensurability between them, at least as represented\nmathematically in data. The user pipeline that sees textual input become visual\noutput, however, obscures this representational regress and makes it seem like\none form transforms into the other -- as if by magic.",
    "categories": [
      "cs.CY",
      "cs.AI"
    ],
    "published": "2025-10-23T08:48:47Z",
    "authors": [
      "Amanda Wasielewski"
    ],
    "pdf_url": "http://arxiv.org/pdf/2510.20350v2"
  },
  {
    "id": "2510.20345v1",
    "title": "LLM-empowered knowledge graph construction: A survey",
    "abstract": "Knowledge Graphs (KGs) have long served as a fundamental infrastructure for\nstructured knowledge representation and reasoning. With the advent of Large\nLanguage Models (LLMs), the construction of KGs has entered a new\nparadigm-shifting from rule-based and statistical pipelines to language-driven\nand generative frameworks. This survey provides a comprehensive overview of\nrecent progress in LLM-empowered knowledge graph construction, systematically\nanalyzing how LLMs reshape the classical three-layered pipeline of ontology\nengineering, knowledge extraction, and knowledge fusion.\n  We first revisit traditional KG methodologies to establish conceptual\nfoundations, and then review emerging LLM-driven approaches from two\ncomplementary perspectives: schema-based paradigms, which emphasize structure,\nnormalization, and consistency; and schema-free paradigms, which highlight\nflexibility, adaptability, and open discovery. Across each stage, we synthesize\nrepresentative frameworks, analyze their technical mechanisms, and identify\ntheir limitations.\n  Finally, the survey outlines key trends and future research directions,\nincluding KG-based reasoning for LLMs, dynamic knowledge memory for agentic\nsystems, and multimodal KG construction. Through this systematic review, we aim\nto clarify the evolving interplay between LLMs and knowledge graphs, bridging\nsymbolic knowledge engineering and neural semantic understanding toward the\ndevelopment of adaptive, explainable, and intelligent knowledge systems.",
    "categories": [
      "cs.AI"
    ],
    "published": "2025-10-23T08:43:28Z",
    "authors": [
      "Haonan Bian"
    ],
    "pdf_url": "http://arxiv.org/pdf/2510.20345v1"
  },
  {
    "id": "2510.20342v1",
    "title": "Teaching Language Models to Reason with Tools",
    "abstract": "Large reasoning models (LRMs) like OpenAI-o1 have shown impressive\ncapabilities in natural language reasoning. However, these models frequently\ndemonstrate inefficiencies or inaccuracies when tackling complex mathematical\noperations. While integrating computational tools such as Code Interpreters\n(CIs) offers a promising solution, it introduces a critical challenge: a\nconflict between the model's internal, probabilistic reasoning and the\nexternal, deterministic knowledge provided by the CI, which often leads models\nto unproductive deliberation. To overcome this, we introduce CoRT\n(Code-Optimized Reasoning Training), a post-training framework designed to\nteach LRMs to effectively utilize CIs. We propose \\emph{Hint-Engineering}, a\nnew data synthesis strategy that strategically injects diverse hints at optimal\npoints within reasoning paths. This approach generates high-quality,\ncode-integrated reasoning data specifically tailored to optimize LRM-CI\ninteraction. Using this method, we have synthesized 30 high-quality samples to\npost-train models ranging from 1.5B to 32B parameters through supervised\nfine-tuning. CoRT further refines the multi-round interleaving of external CI\nusage and internal thinking by employing rejection sampling and reinforcement\nlearning. Our experimental evaluations demonstrate CoRT's effectiveness,\nyielding absolute improvements of 4\\% and 8\\% on DeepSeek-R1-Distill-Qwen-32B\nand DeepSeek-R1-Distill-Qwen-1.5B, respectively, across five challenging\nmathematical reasoning datasets. Moreover, CoRT significantly enhances\nefficiency, reducing token usage by approximately 30\\% for the 32B model and\n50\\% for the 1.5B model compared to pure natural language reasoning baselines.\nThe models and code are available at: https://github.com/ChengpengLi1003/CoRT.",
    "categories": [
      "cs.CL",
      "cs.AI"
    ],
    "published": "2025-10-23T08:41:44Z",
    "authors": [
      "Chengpeng Li",
      "Zhengyang Tang",
      "Ziniu Li",
      "Mingfeng Xue",
      "Keqin Bao",
      "Tian Ding",
      "Ruoyu Sun",
      "Benyou Wang",
      "Xiang Wang",
      "Junyang Lin",
      "Dayiheng Liu"
    ],
    "pdf_url": "http://arxiv.org/pdf/2510.20342v1"
  },
  {
    "id": "2510.20339v1",
    "title": "Multi-Task Deep Learning for Surface Metrology",
    "abstract": "A reproducible deep learning framework is presented for surface metrology to\npredict surface texture parameters together with their reported standard\nuncertainties. Using a multi-instrument dataset spanning tactile and optical\nsystems, measurement system type classification is addressed alongside\ncoordinated regression of Ra, Rz, RONt and their uncertainty targets\n(Ra_uncert, Rz_uncert, RONt_uncert). Uncertainty is modelled via quantile and\nheteroscedastic heads with post-hoc conformal calibration to yield calibrated\nintervals. On a held-out set, high fidelity was achieved by single-target\nregressors (R2: Ra 0.9824, Rz 0.9847, RONt 0.9918), with two uncertainty\ntargets also well modelled (Ra_uncert 0.9899, Rz_uncert 0.9955); RONt_uncert\nremained difficult (R2 0.4934). The classifier reached 92.85% accuracy and\nprobability calibration was essentially unchanged after temperature scaling\n(ECE 0.00504 -> 0.00503 on the test split). Negative transfer was observed for\nnaive multi-output trunks, with single-target models performing better. These\nresults provide calibrated predictions suitable to inform instrument selection\nand acceptance decisions in metrological workflows.",
    "categories": [
      "physics.app-ph",
      "cs.AI",
      "cs.LG",
      "stat.AP",
      "stat.ML"
    ],
    "published": "2025-10-23T08:38:18Z",
    "authors": [
      "D. Kucharski",
      "A. Gaska",
      "T. Kowaluk",
      "K. Stepien",
      "M. Repalska",
      "B. Gapinski",
      "M. Wieczorowski",
      "M. Nawotka",
      "P. Sobecki",
      "P. Sosinowski",
      "J. Tomasik",
      "A. Wojtowicz"
    ],
    "pdf_url": "http://arxiv.org/pdf/2510.20339v1"
  },
  {
    "id": "2510.20337v1",
    "title": "Collateral Damage Assessment Model for AI System Target Engagement in\n  Military Operations",
    "abstract": "In an era where AI (Artificial Intelligence) systems play an increasing role\nin the battlefield, ensuring responsible targeting demands rigorous assessment\nof potential collateral effects. In this context, a novel collateral damage\nassessment model for target engagement of AI systems in military operations is\nintroduced. The model integrates temporal, spatial, and force dimensions within\na unified Knowledge Representation and Reasoning (KRR) architecture following a\ndesign science methodological approach. Its layered structure captures the\ncategories and architectural components of the AI systems to be engaged\ntogether with corresponding engaging vectors and contextual aspects. At the\nsame time, spreading, severity, likelihood, and evaluation metrics are\nconsidered in order to provide a clear representation enhanced by transparent\nreasoning mechanisms. Further, the model is demonstrated and evaluated through\ninstantiation which serves as a basis for further dedicated efforts that aim at\nbuilding responsible and trustworthy intelligent systems for assessing the\neffects produced by engaging AI systems in military operations.",
    "categories": [
      "cs.AI"
    ],
    "published": "2025-10-23T08:36:04Z",
    "authors": [
      "Clara Maathuis",
      "Kasper Cools"
    ],
    "pdf_url": "http://arxiv.org/pdf/2510.20337v1"
  },
  {
    "id": "2510.20333v1",
    "title": "GhostEI-Bench: Do Mobile Agents Resilience to Environmental Injection in\n  Dynamic On-Device Environments?",
    "abstract": "Vision-Language Models (VLMs) are increasingly deployed as autonomous agents\nto navigate mobile graphical user interfaces (GUIs). Operating in dynamic\non-device ecosystems, which include notifications, pop-ups, and inter-app\ninteractions, exposes them to a unique and underexplored threat vector:\nenvironmental injection. Unlike prompt-based attacks that manipulate textual\ninstructions, environmental injection corrupts an agent's visual perception by\ninserting adversarial UI elements (for example, deceptive overlays or spoofed\nnotifications) directly into the GUI. This bypasses textual safeguards and can\nderail execution, causing privacy leakage, financial loss, or irreversible\ndevice compromise. To systematically evaluate this threat, we introduce\nGhostEI-Bench, the first benchmark for assessing mobile agents under\nenvironmental injection attacks within dynamic, executable environments. Moving\nbeyond static image-based assessments, GhostEI-Bench injects adversarial events\ninto realistic application workflows inside fully operational Android emulators\nand evaluates performance across critical risk scenarios. We further propose a\njudge-LLM protocol that conducts fine-grained failure analysis by reviewing the\nagent's action trajectory alongside the corresponding screenshot sequence,\npinpointing failure in perception, recognition, or reasoning. Comprehensive\nexperiments on state-of-the-art agents reveal pronounced vulnerability to\ndeceptive environmental cues: current models systematically fail to perceive\nand reason about manipulated UIs. GhostEI-Bench provides a framework for\nquantifying and mitigating this emerging threat, paving the way toward more\nrobust and secure embodied agents.",
    "categories": [
      "cs.CR",
      "cs.AI"
    ],
    "published": "2025-10-23T08:33:24Z",
    "authors": [
      "Chiyu Chen",
      "Xinhao Song",
      "Yunkai Chai",
      "Yang Yao",
      "Haodong Zhao",
      "Lijun Li",
      "Jie Li",
      "Yan Teng",
      "Gongshen Liu",
      "Yingchun Wang"
    ],
    "pdf_url": "http://arxiv.org/pdf/2510.20333v1"
  },
  {
    "id": "2510.20332v1",
    "title": "Bias by Design? How Data Practices Shape Fairness in AI Healthcare\n  Systems",
    "abstract": "Artificial intelligence (AI) holds great promise for transforming healthcare.\nHowever, despite significant advances, the integration of AI solutions into\nreal-world clinical practice remains limited. A major barrier is the quality\nand fairness of training data, which is often compromised by biased data\ncollection practices. This paper draws on insights from the AI4HealthyAging\nproject, part of Spain's national R&D initiative, where our task was to detect\nbiases during clinical data collection. We identify several types of bias\nacross multiple use cases, including historical, representation, and\nmeasurement biases. These biases manifest in variables such as sex, gender,\nage, habitat, socioeconomic status, equipment, and labeling. We conclude with\npractical recommendations for improving the fairness and robustness of clinical\nproblem design and data collection. We hope that our findings and experience\ncontribute to guiding future projects in the development of fairer AI systems\nin healthcare.",
    "categories": [
      "cs.AI"
    ],
    "published": "2025-10-23T08:32:34Z",
    "authors": [
      "Anna Arias-Duart",
      "Maria Eugenia Cardello",
      "Atia Cort\u00e9s"
    ],
    "pdf_url": "http://arxiv.org/pdf/2510.20332v1"
  },
  {
    "id": "2510.20328v1",
    "title": "MemER: Scaling Up Memory for Robot Control via Experience Retrieval",
    "abstract": "Humans routinely rely on memory to perform tasks, yet most robot policies\nlack this capability; our goal is to endow robot policies with the same\nability. Naively conditioning on long observation histories is computationally\nexpensive and brittle under covariate shift, while indiscriminate subsampling\nof history leads to irrelevant or redundant information. We propose a\nhierarchical policy framework, where the high-level policy is trained to select\nand track previous relevant keyframes from its experience. The high-level\npolicy uses selected keyframes and the most recent frames when generating text\ninstructions for a low-level policy to execute. This design is compatible with\nexisting vision-language-action (VLA) models and enables the system to\nefficiently reason over long-horizon dependencies. In our experiments, we\nfinetune Qwen2.5-VL-7B-Instruct and $\\pi_{0.5}$ as the high-level and low-level\npolicies respectively, using demonstrations supplemented with minimal language\nannotations. Our approach, MemER, outperforms prior methods on three real-world\nlong-horizon robotic manipulation tasks that require minutes of memory. Videos\nand code can be found at https://jen-pan.github.io/memer/.",
    "categories": [
      "cs.RO",
      "cs.AI",
      "cs.LG"
    ],
    "published": "2025-10-23T08:26:17Z",
    "authors": [
      "Ajay Sridhar",
      "Jennifer Pan",
      "Satvik Sharma",
      "Chelsea Finn"
    ],
    "pdf_url": "http://arxiv.org/pdf/2510.20328v1"
  },
  {
    "id": "2510.20327v1",
    "title": "LEGO: A Lightweight and Efficient Multiple-Attribute Unlearning\n  Framework for Recommender Systems",
    "abstract": "With the growing demand for safeguarding sensitive user information in\nrecommender systems, recommendation attribute unlearning is receiving\nincreasing attention. Existing studies predominantly focus on single-attribute\nunlearning. However, privacy protection requirements in the real world often\ninvolve multiple sensitive attributes and are dynamic. Existing\nsingle-attribute unlearning methods cannot meet these real-world requirements\ndue to i) CH1: the inability to handle multiple unlearning requests\nsimultaneously, and ii) CH2: the lack of efficient adaptability to dynamic\nunlearning needs. To address these challenges, we propose LEGO, a lightweight\nand efficient multiple-attribute unlearning framework. Specifically, we divide\nthe multiple-attribute unlearning process into two steps: i) Embedding\nCalibration removes information related to a specific attribute from user\nembedding, and ii) Flexible Combination combines these embeddings into a single\nembedding, protecting all sensitive attributes. We frame the unlearning process\nas a mutual information minimization problem, providing LEGO a theoretical\nguarantee of simultaneous unlearning, thereby addressing CH1. With the two-step\nframework, where Embedding Calibration can be performed in parallel and\nFlexible Combination is flexible and efficient, we address CH2. Extensive\nexperiments on three real-world datasets across three representative\nrecommendation models demonstrate the effectiveness and efficiency of our\nproposed framework. Our code and appendix are available at\nhttps://github.com/anonymifish/lego-rec-multiple-attribute-unlearning.",
    "categories": [
      "cs.LG",
      "cs.AI"
    ],
    "published": "2025-10-23T08:20:47Z",
    "authors": [
      "Fengyuan Yu",
      "Yuyuan Li",
      "Xiaohua Feng",
      "Junjie Fang",
      "Tao Wang",
      "Chaochao Chen"
    ],
    "pdf_url": "http://arxiv.org/pdf/2510.20327v1"
  },
  {
    "id": "2510.20314v1",
    "title": "Enhancing Security in Deep Reinforcement Learning: A Comprehensive\n  Survey on Adversarial Attacks and Defenses",
    "abstract": "With the wide application of deep reinforcement learning (DRL) techniques in\ncomplex fields such as autonomous driving, intelligent manufacturing, and smart\nhealthcare, how to improve its security and robustness in dynamic and\nchangeable environments has become a core issue in current research. Especially\nin the face of adversarial attacks, DRL may suffer serious performance\ndegradation or even make potentially dangerous decisions, so it is crucial to\nensure their stability in security-sensitive scenarios. In this paper, we first\nintroduce the basic framework of DRL and analyze the main security challenges\nfaced in complex and changing environments. In addition, this paper proposes an\nadversarial attack classification framework based on perturbation type and\nattack target and reviews the mainstream adversarial attack methods against DRL\nin detail, including various attack methods such as perturbation state space,\naction space, reward function and model space. To effectively counter the\nattacks, this paper systematically summarizes various current robustness\ntraining strategies, including adversarial training, competitive training,\nrobust learning, adversarial detection, defense distillation and other related\ndefense techniques, we also discuss the advantages and shortcomings of these\nmethods in improving the robustness of DRL. Finally, this paper looks into the\nfuture research direction of DRL in adversarial environments, emphasizing the\nresearch needs in terms of improving generalization, reducing computational\ncomplexity, and enhancing scalability and explainability, aiming to provide\nvaluable references and directions for researchers.",
    "categories": [
      "cs.CR",
      "cs.AI",
      "cs.LG"
    ],
    "published": "2025-10-23T08:04:57Z",
    "authors": [
      "Wu Yichao",
      "Wang Yirui",
      "Ding Panpan",
      "Wang Hailong",
      "Zhu Bingqian",
      "Liu Chun"
    ],
    "pdf_url": "http://arxiv.org/pdf/2510.20314v1"
  },
  {
    "id": "2510.20310v2",
    "title": "Multi-Step Reasoning for Embodied Question Answering via Tool\n  Augmentation",
    "abstract": "Embodied Question Answering (EQA) requires agents to explore 3D environments\nto obtain observations and answer questions related to the scene. Existing\nmethods leverage VLMs to directly explore the environment and answer questions\nwithout explicit thinking or planning, which limits their reasoning ability and\nresults in excessive or inefficient exploration as well as ineffective\nresponses. In this paper, we introduce ToolEQA, an agent that integrates\nexternal tools with multi-step reasoning, where external tools can provide more\nuseful information for completing the task, helping the model derive better\nexploration directions in the next step of reasoning and thus obtaining\nadditional effective information. This enables ToolEQA to generate more\naccurate responses with a shorter exploration distance. To enhance the model's\nability for tool-usage and multi-step reasoning, we further design a novel EQA\ndata generation pipeline that automatically constructs large-scale EQA tasks\nwith reasoning trajectories and corresponding answers. Based on the pipeline,\nwe collect the EQA-RT dataset that contains about 18K tasks, divided into a\ntraining set EQA-RT-Train, and two test sets EQA-RT-Seen (scenes overlapping\nwith the training set) and EQA-RT-Unseen (novel scenes). Experiments on\nEQA-RT-Seen and EQA-RT-Unseen show that ToolEQA improves the success rate by\n9.2~20.2% over state-of-the-art baselines, while outperforming the zero-shot\nToolEQA by 10% in success rate. In addition, ToolEQA also achieves\nstate-of-the-art performance on the HM-EQA, OpenEQA, and EXPRESS-Bench\ndatasets, demonstrating its generality. Our homepage see\nhttps://tooleqa.github.io.",
    "categories": [
      "cs.AI"
    ],
    "published": "2025-10-23T08:02:08Z",
    "authors": [
      "Mingliang Zhai",
      "Hansheng Liang",
      "Xiaomeng Fan",
      "Zhi Gao",
      "Chuanhao Li",
      "Che Sun",
      "Xu Bin",
      "Yuwei Wu",
      "Yunde Jia"
    ],
    "pdf_url": "http://arxiv.org/pdf/2510.20310v2"
  },
  {
    "id": "2510.21861v1",
    "title": "The Mirror Loop: Recursive Non-Convergence in Generative Reasoning\n  Systems",
    "abstract": "Large language models are often described as capable of reflective reasoning,\nyet recursive self-evaluation without external feedback frequently yields\nreformulation rather than progress. We test this prediction in a cross-provider\nstudy of 144 reasoning sequences across three models (OpenAI GPT-4o-mini,\nAnthropic Claude 3 Haiku, and Google Gemini 2.0 Flash) and four task families\n(arithmetic, code, explanation, reflection), each iterated ten times under two\nconditions: ungrounded self-critique and a minimal grounding intervention (a\nsingle verification step at iteration three). Mean informational change (delta\nI, measured via normalized edit distance) declined by 55% from early (0.193) to\nlate (0.087) iterations in ungrounded runs, with consistent patterns across all\nthree providers. Grounded runs showed a +28% rebound in informational change\nimmediately after the intervention and sustained non-zero variance thereafter.\nComplementary measures-n-gram novelty, embedding drift, and character-level\nentropy-converged on the same pattern: reflection without contact tends toward\ninformational closure. We interpret this as evidence for a structural limit on\nself-correction in generative reasoning: without an exchange of information\nwith an independent verifier or environment, recursive inference approaches an\nattractor state of epistemic stasis. Minimal grounding functions as dissipative\ncoupling, reintroducing informational flux. The cross-architecture consistency\nsuggests the mirror loop arises from shared autoregressive training objectives\nrather than provider-specific alignment schemes. The results delineate when\nreflection is performative rather than epistemic and motivate design principles\nfor grounded, cooperative reasoning. Materials and code are publicly available.",
    "categories": [
      "cs.LG",
      "cs.AI",
      "cs.CL",
      "68T05",
      "I.2.6; I.2.8"
    ],
    "published": "2025-10-23T07:53:26Z",
    "authors": [
      "Bentley DeVilling"
    ],
    "pdf_url": "http://arxiv.org/pdf/2510.21861v1"
  },
  {
    "id": "2510.20299v2",
    "title": "DB-FGA-Net: Dual Backbone Frequency Gated Attention Network for\n  Multi-Class Brain Tumor Classification with Grad-CAM Interpretability",
    "abstract": "Brain tumors are a challenging problem in neuro-oncology, where early and\nprecise diagnosis is important for successful treatment. Deep learning-based\nbrain tumor classification methods often rely on heavy data augmentation which\ncan limit generalization and trust in clinical applications. In this paper, we\npropose a double-backbone network integrating VGG16 and Xception with a\nFrequency-Gated Attention (FGA) Block to capture complementary local and global\nfeatures. Unlike previous studies, our model achieves state-of-the-art\nperformance without augmentation which demonstrates robustness to variably\nsized and distributed datasets. For further transparency, Grad-CAM is\nintegrated to visualize the tumor regions based on which the model is giving\nprediction, bridging the gap between model prediction and clinical\ninterpretability. The proposed framework achieves 99.24\\% accuracy on the 7K-DS\ndataset for the 4-class setting, along with 98.68\\% and 99.85\\% in the 3-class\nand 2-class settings, respectively. On the independent 3K-DS dataset, the model\ngeneralizes with 95.77\\% accuracy, outperforming baseline and state-of-the-art\nmethods. To further support clinical usability, we developed a graphical user\ninterface (GUI) that provides real-time classification and Grad-CAM-based tumor\nlocalization. These findings suggest that augmentation-free, interpretable, and\ndeployable deep learning models such as DB-FGA-Net hold strong potential for\nreliable clinical translation in brain tumor diagnosis.",
    "categories": [
      "cs.LG",
      "cs.AI"
    ],
    "published": "2025-10-23T07:39:00Z",
    "authors": [
      "Saraf Anzum Shreya",
      "MD. Abu Ismail Siddique",
      "Sharaf Tasnim"
    ],
    "pdf_url": "http://arxiv.org/pdf/2510.20299v2"
  },
  {
    "id": "2510.20296v1",
    "title": "RAG-Stack: Co-Optimizing RAG Quality and Performance From the Vector\n  Database Perspective",
    "abstract": "Retrieval-augmented generation (RAG) has emerged as one of the most prominent\napplications of vector databases. By integrating documents retrieved from a\ndatabase into the prompt of a large language model (LLM), RAG enables more\nreliable and informative content generation. While there has been extensive\nresearch on vector databases, many open research problems remain once they are\nconsidered in the wider context of end-to-end RAG pipelines. One practical yet\nchallenging problem is how to jointly optimize both system performance and\ngeneration quality in RAG, which is significantly more complex than it appears\ndue to the numerous knobs on both the algorithmic side (spanning models and\ndatabases) and the systems side (from software to hardware). In this paper, we\npresent RAG-Stack, a three-pillar blueprint for quality-performance\nco-optimization in RAG systems. RAG-Stack comprises: (1) RAG-IR, an\nintermediate representation that serves as an abstraction layer to decouple\nquality and performance aspects; (2) RAG-CM, a cost model for estimating system\nperformance given an RAG-IR; and (3) RAG-PE, a plan exploration algorithm that\nsearches for high-quality, high-performance RAG configurations. We believe this\nthree-pillar blueprint will become the de facto paradigm for RAG\nquality-performance co-optimization in the years to come.",
    "categories": [
      "cs.DB",
      "cs.AI"
    ],
    "published": "2025-10-23T07:35:19Z",
    "authors": [
      "Wenqi Jiang"
    ],
    "pdf_url": "http://arxiv.org/pdf/2510.20296v1"
  },
  {
    "id": "2510.21860v1",
    "title": "Butter-Bench: Evaluating LLM Controlled Robots for Practical\n  Intelligence",
    "abstract": "We present Butter-Bench, a benchmark evaluating large language model (LLM)\ncontrolled robots for practical intelligence, defined as the ability to\nnavigate the messiness of the physical world. Current state-of-the-art robotic\nsystems use a hierarchical architecture with LLMs in charge of high-level\nreasoning, and a Vision Language Action (VLA) model for low-level control.\nButter-Bench evaluates the LLM part in isolation from the VLA. Although LLMs\nhave repeatedly surpassed humans in evaluations requiring analytical\nintelligence, we find humans still outperform LLMs on Butter-Bench. The best\nLLMs score 40% on Butter-Bench, while the mean human score is 95%. LLMs\nstruggled the most with multi-step spatial planning and social understanding.\nWe also evaluate LLMs that are fine-tuned for embodied reasoning and conclude\nthat this training does not improve their score on Butter-Bench.",
    "categories": [
      "cs.RO",
      "cs.AI"
    ],
    "published": "2025-10-23T07:28:28Z",
    "authors": [
      "Callum Sharrock",
      "Lukas Petersson",
      "Hanna Petersson",
      "Axel Backlund",
      "Axel Wennstr\u00f6m",
      "Kristoffer Nordstr\u00f6m",
      "Elias Aronsson"
    ],
    "pdf_url": "http://arxiv.org/pdf/2510.21860v1"
  },
  {
    "id": "2510.26800v1",
    "title": "OmniX: From Unified Panoramic Generation and Perception to\n  Graphics-Ready 3D Scenes",
    "abstract": "There are two prevalent ways to constructing 3D scenes: procedural generation\nand 2D lifting. Among them, panorama-based 2D lifting has emerged as a\npromising technique, leveraging powerful 2D generative priors to produce\nimmersive, realistic, and diverse 3D environments. In this work, we advance\nthis technique to generate graphics-ready 3D scenes suitable for physically\nbased rendering (PBR), relighting, and simulation. Our key insight is to\nrepurpose 2D generative models for panoramic perception of geometry, textures,\nand PBR materials. Unlike existing 2D lifting approaches that emphasize\nappearance generation and ignore the perception of intrinsic properties, we\npresent OmniX, a versatile and unified framework. Based on a lightweight and\nefficient cross-modal adapter structure, OmniX reuses 2D generative priors for\na broad range of panoramic vision tasks, including panoramic perception,\ngeneration, and completion. Furthermore, we construct a large-scale synthetic\npanorama dataset containing high-quality multimodal panoramas from diverse\nindoor and outdoor scenes. Extensive experiments demonstrate the effectiveness\nof our model in panoramic visual perception and graphics-ready 3D scene\ngeneration, opening new possibilities for immersive and physically realistic\nvirtual world generation.",
    "categories": [
      "cs.CV",
      "cs.GR",
      "cs.LG"
    ],
    "published": "2025-10-30T17:59:51Z",
    "authors": [
      "Yukun Huang",
      "Jiwen Yu",
      "Yanning Zhou",
      "Jianan Wang",
      "Xintao Wang",
      "Pengfei Wan",
      "Xihui Liu"
    ],
    "pdf_url": "http://arxiv.org/pdf/2510.26800v1"
  },
  {
    "id": "2510.26795v1",
    "title": "Scaling Image Geo-Localization to Continent Level",
    "abstract": "Determining the precise geographic location of an image at a global scale\nremains an unsolved challenge. Standard image retrieval techniques are\ninefficient due to the sheer volume of images (>100M) and fail when coverage is\ninsufficient. Scalable solutions, however, involve a trade-off: global\nclassification typically yields coarse results (10+ kilometers), while\ncross-view retrieval between ground and aerial imagery suffers from a domain\ngap and has been primarily studied on smaller regions. This paper introduces a\nhybrid approach that achieves fine-grained geo-localization across a large\ngeographic expanse the size of a continent. We leverage a proxy classification\ntask during training to learn rich feature representations that implicitly\nencode precise location information. We combine these learned prototypes with\nembeddings of aerial imagery to increase robustness to the sparsity of\nground-level data. This enables direct, fine-grained retrieval over areas\nspanning multiple countries. Our extensive evaluation demonstrates that our\napproach can localize within 200m more than 68\\% of queries of a dataset\ncovering a large part of Europe. The code is publicly available at\nhttps://scaling-geoloc.github.io.",
    "categories": [
      "cs.CV",
      "cs.LG"
    ],
    "published": "2025-10-30T17:59:35Z",
    "authors": [
      "Philipp Lindenberger",
      "Paul-Edouard Sarlin",
      "Jan Hosang",
      "Matteo Balice",
      "Marc Pollefeys",
      "Simon Lynen",
      "Eduard Trulls"
    ],
    "pdf_url": "http://arxiv.org/pdf/2510.26795v1"
  },
  {
    "id": "2510.26792v1",
    "title": "Learning Pseudorandom Numbers with Transformers: Permuted Congruential\n  Generators, Curricula, and Interpretability",
    "abstract": "We study the ability of Transformer models to learn sequences generated by\nPermuted Congruential Generators (PCGs), a widely used family of pseudo-random\nnumber generators (PRNGs). PCGs introduce substantial additional difficulty\nover linear congruential generators (LCGs) by applying a series of bit-wise\nshifts, XORs, rotations and truncations to the hidden state. We show that\nTransformers can nevertheless successfully perform in-context prediction on\nunseen sequences from diverse PCG variants, in tasks that are beyond published\nclassical attacks. In our experiments we scale moduli up to $2^{22}$ using up\nto $50$ million model parameters and datasets with up to $5$ billion tokens.\nSurprisingly, we find even when the output is truncated to a single bit, it can\nbe reliably predicted by the model. When multiple distinct PRNGs are presented\ntogether during training, the model can jointly learn them, identifying\nstructures from different permutations. We demonstrate a scaling law with\nmodulus $m$: the number of in-context sequence elements required for\nnear-perfect prediction grows as $\\sqrt{m}$. For larger moduli, optimization\nenters extended stagnation phases; in our experiments, learning moduli $m \\geq\n2^{20}$ requires incorporating training data from smaller moduli, demonstrating\na critical necessity for curriculum learning. Finally, we analyze embedding\nlayers and uncover a novel clustering phenomenon: the model spontaneously\ngroups the integer inputs into bitwise rotationally-invariant clusters,\nrevealing how representations can transfer from smaller to larger moduli.",
    "categories": [
      "cs.LG",
      "cond-mat.dis-nn",
      "cs.CR"
    ],
    "published": "2025-10-30T17:59:09Z",
    "authors": [
      "Tao Tao",
      "Maissam Barkeshli"
    ],
    "pdf_url": "http://arxiv.org/pdf/2510.26792v1"
  },
  {
    "id": "2510.26788v1",
    "title": "Defeating the Training-Inference Mismatch via FP16",
    "abstract": "Reinforcement learning (RL) fine-tuning of large language models (LLMs) often\nsuffers from instability due to the numerical mismatch between the training and\ninference policies. While prior work has attempted to mitigate this issue\nthrough algorithmic corrections or engineering alignments, we show that its\nroot cause lies in the floating point precision itself. The widely adopted\nBF16, despite its large dynamic range, introduces large rounding errors that\nbreaks the consistency between training and inference. In this work, we\ndemonstrate that simply reverting to \\textbf{FP16} effectively eliminates this\nmismatch. The change is simple, fully supported by modern frameworks with only\na few lines of code change, and requires no modification to the model\narchitecture or learning algorithm. Our results suggest that using FP16\nuniformly yields more stable optimization, faster convergence, and stronger\nperformance across diverse tasks, algorithms and frameworks. We hope these\nfindings motivate a broader reconsideration of precision trade-offs in RL\nfine-tuning.",
    "categories": [
      "cs.LG",
      "cs.AI",
      "cs.CL"
    ],
    "published": "2025-10-30T17:58:11Z",
    "authors": [
      "Penghui Qi",
      "Zichen Liu",
      "Xiangxin Zhou",
      "Tianyu Pang",
      "Chao Du",
      "Wee Sun Lee",
      "Min Lin"
    ],
    "pdf_url": "http://arxiv.org/pdf/2510.26788v1"
  },
  {
    "id": "2510.26787v1",
    "title": "Remote Labor Index: Measuring AI Automation of Remote Work",
    "abstract": "AIs have made rapid progress on research-oriented benchmarks of knowledge and\nreasoning, but it remains unclear how these gains translate into economic value\nand automation. To measure this, we introduce the Remote Labor Index (RLI), a\nbroadly multi-sector benchmark comprising real-world, economically valuable\nprojects designed to evaluate end-to-end agent performance in practical\nsettings. AI agents perform near the floor on RLI, with the highest-performing\nagent achieving an automation rate of 2.5%. These results help ground\ndiscussions of AI automation in empirical evidence, setting a common basis for\ntracking AI impacts and enabling stakeholders to proactively navigate AI-driven\nlabor automation.",
    "categories": [
      "cs.LG",
      "cs.AI",
      "cs.CL"
    ],
    "published": "2025-10-30T17:58:04Z",
    "authors": [
      "Mantas Mazeika",
      "Alice Gatti",
      "Cristina Menghini",
      "Udari Madhushani Sehwag",
      "Shivam Singhal",
      "Yury Orlovskiy",
      "Steven Basart",
      "Manasi Sharma",
      "Denis Peskoff",
      "Elaine Lau",
      "Jaehyuk Lim",
      "Lachlan Carroll",
      "Alice Blair",
      "Vinaya Sivakumar",
      "Sumana Basu",
      "Brad Kenstler",
      "Yuntao Ma",
      "Julian Michael",
      "Xiaoke Li",
      "Oliver Ingebretsen",
      "Aditya Mehta",
      "Jean Mottola",
      "John Teichmann",
      "Kevin Yu",
      "Zaina Shaik",
      "Adam Khoja",
      "Richard Ren",
      "Jason Hausenloy",
      "Long Phan",
      "Ye Htet",
      "Ankit Aich",
      "Tahseen Rabbani",
      "Vivswan Shah",
      "Andriy Novykov",
      "Felix Binder",
      "Kirill Chugunov",
      "Luis Ramirez",
      "Matias Geralnik",
      "Hern\u00e1n Mesura",
      "Dean Lee",
      "Ed-Yeremai Hernandez Cardona",
      "Annette Diamond",
      "Summer Yue",
      "Alexandr Wang",
      "Bing Liu",
      "Ernesto Hernandez",
      "Dan Hendrycks"
    ],
    "pdf_url": "http://arxiv.org/pdf/2510.26787v1"
  },
  {
    "id": "2510.26786v1",
    "title": "HEIR: Learning Graph-Based Motion Hierarchies",
    "abstract": "Hierarchical structures of motion exist across research fields, including\ncomputer vision, graphics, and robotics, where complex dynamics typically arise\nfrom coordinated interactions among simpler motion components. Existing methods\nto model such dynamics typically rely on manually-defined or heuristic\nhierarchies with fixed motion primitives, limiting their generalizability\nacross different tasks. In this work, we propose a general hierarchical motion\nmodeling method that learns structured, interpretable motion relationships\ndirectly from data. Our method represents observed motions using graph-based\nhierarchies, explicitly decomposing global absolute motions into\nparent-inherited patterns and local motion residuals. We formulate hierarchy\ninference as a differentiable graph learning problem, where vertices represent\nelemental motions and directed edges capture learned parent-child dependencies\nthrough graph neural networks. We evaluate our hierarchical reconstruction\napproach on three examples: 1D translational motion, 2D rotational motion, and\ndynamic 3D scene deformation via Gaussian splatting. Experimental results show\nthat our method reconstructs the intrinsic motion hierarchy in 1D and 2D cases,\nand produces more realistic and interpretable deformations compared to the\nbaseline on dynamic 3D Gaussian splatting scenes. By providing an adaptable,\ndata-driven hierarchical modeling paradigm, our method offers a formulation\napplicable to a broad range of motion-centric tasks. Project Page:\nhttps://light.princeton.edu/HEIR/",
    "categories": [
      "cs.CV",
      "cs.GR",
      "cs.LG"
    ],
    "published": "2025-10-30T17:57:40Z",
    "authors": [
      "Cheng Zheng",
      "William Koch",
      "Baiang Li",
      "Felix Heide"
    ],
    "pdf_url": "http://arxiv.org/pdf/2510.26786v1"
  },
  {
    "id": "2510.26783v1",
    "title": "A Unified Theory for Causal Inference: Direct Debiased Machine Learning\n  via Bregman-Riesz Regression",
    "abstract": "This note introduces a unified theory for causal inference that integrates\nRiesz regression, covariate balancing, density-ratio estimation (DRE), targeted\nmaximum likelihood estimation (TMLE), and the matching estimator in average\ntreatment effect (ATE) estimation. In ATE estimation, the balancing weights and\nthe regression functions of the outcome play important roles, where the\nbalancing weights are referred to as the Riesz representer, bias-correction\nterm, and clever covariates, depending on the context. Riesz regression,\ncovariate balancing, DRE, and the matching estimator are methods for estimating\nthe balancing weights, where Riesz regression is essentially equivalent to DRE\nin the ATE context, the matching estimator is a special case of DRE, and DRE is\nin a dual relationship with covariate balancing. TMLE is a method for\nconstructing regression function estimators such that the leading bias term\nbecomes zero. Nearest Neighbor Matching is equivalent to Least Squares Density\nRatio Estimation and Riesz Regression.",
    "categories": [
      "stat.ML",
      "cs.LG",
      "econ.EM",
      "math.ST",
      "stat.ME",
      "stat.TH"
    ],
    "published": "2025-10-30T17:56:47Z",
    "authors": [
      "Masahiro Kato"
    ],
    "pdf_url": "http://arxiv.org/pdf/2510.26783v1"
  },
  {
    "id": "2510.26782v1",
    "title": "Clone Deterministic 3D Worlds with Geometrically-Regularized World\n  Models",
    "abstract": "A world model is an internal model that simulates how the world evolves.\nGiven past observations and actions, it predicts the future of both the\nembodied agent and its environment. Accurate world models are essential for\nenabling agents to think, plan, and reason effectively in complex, dynamic\nsettings. Despite rapid progress, current world models remain brittle and\ndegrade over long horizons. We argue that a central cause is representation\nquality: exteroceptive inputs (e.g., images) are high-dimensional, and lossy or\nentangled latents make dynamics learning unnecessarily hard. We therefore ask\nwhether improving representation learning alone can substantially improve\nworld-model performance. In this work, we take a step toward building a truly\naccurate world model by addressing a fundamental yet open problem: constructing\na model that can fully clone and overfit to a deterministic 3D world. We\npropose Geometrically-Regularized World Models (GRWM), which enforces that\nconsecutive points along a natural sensory trajectory remain close in latent\nrepresentation space. This approach yields significantly improved latent\nrepresentations that align closely with the true topology of the environment.\nGRWM is plug-and-play, requires only minimal architectural modification, scales\nwith trajectory length, and is compatible with diverse latent generative\nbackbones. Across deterministic 3D settings and long-horizon prediction tasks,\nGRWM significantly increases rollout fidelity and stability. Analyses show that\nits benefits stem from learning a latent manifold with superior geometric\nstructure. These findings support a clear takeaway: improving representation\nlearning is a direct and useful path to robust world models, delivering\nreliable long-horizon predictions without enlarging the dynamics module.",
    "categories": [
      "cs.LG",
      "cs.AI",
      "cs.CV"
    ],
    "published": "2025-10-30T17:56:43Z",
    "authors": [
      "Zaishuo Xia",
      "Yukuan Lu",
      "Xinyi Li",
      "Yifan Xu",
      "Yubei Chen"
    ],
    "pdf_url": "http://arxiv.org/pdf/2510.26782v1"
  },
  {
    "id": "2510.26778v1",
    "title": "Surpassing state of the art on AMD area estimation from RGB fundus\n  images through careful selection of U-Net architectures and loss functions\n  for class imbalance",
    "abstract": "Age-related macular degeneration (AMD) is one of the leading causes of\nirreversible vision impairment in people over the age of 60. This research\nfocuses on semantic segmentation for AMD lesion detection in RGB fundus images,\na non-invasive and cost-effective imaging technique. The results of the ADAM\nchallenge - the most comprehensive AMD detection from RGB fundus images\nresearch competition and open dataset to date - serve as a benchmark for our\nevaluation. Taking the U-Net connectivity as a base of our framework, we\nevaluate and compare several approaches to improve the segmentation model's\narchitecture and training pipeline, including pre-processing techniques,\nencoder (backbone) deep network types of varying complexity, and specialized\nloss functions to mitigate class imbalances on image and pixel levels. The main\noutcome of this research is the final configuration of the AMD detection\nframework, which outperforms all the prior ADAM challenge submissions on the\nmulti-class segmentation of different AMD lesion types in non-invasive RGB\nfundus images. The source code used to conduct the experiments presented in\nthis paper is made freely available.",
    "categories": [
      "cs.CV",
      "cs.LG",
      "eess.IV",
      "68T07, 68T05, 68T45, 92C55",
      "I.2.6; J.3"
    ],
    "published": "2025-10-30T17:55:46Z",
    "authors": [
      "Valentyna Starodub",
      "Mantas Luko\u0161evi\u010dius"
    ],
    "pdf_url": "http://arxiv.org/pdf/2510.26778v1"
  },
  {
    "id": "2510.26777v1",
    "title": "Pre-trained Forecasting Models: Strong Zero-Shot Feature Extractors for\n  Time Series Classification",
    "abstract": "Recent research on time series foundation models has primarily focused on\nforecasting, leaving it unclear how generalizable their learned representations\nare. In this study, we examine whether frozen pre-trained forecasting models\ncan provide effective representations for classification. To this end, we\ncompare different representation extraction strategies and introduce two\nmodel-agnostic embedding augmentations. Our experiments show that the best\nforecasting models achieve classification accuracy that matches or even\nsurpasses that of state-of-the-art models pre-trained specifically for\nclassification. Moreover, we observe a positive correlation between forecasting\nand classification performance. These findings challenge the assumption that\ntask-specific pre-training is necessary, and suggest that learning to forecast\nmay provide a powerful route toward constructing general-purpose time series\nfoundation models.",
    "categories": [
      "cs.LG"
    ],
    "published": "2025-10-30T17:55:23Z",
    "authors": [
      "Andreas Auer",
      "Daniel Klotz",
      "Sebastinan B\u00f6ck",
      "Sepp Hochreiter"
    ],
    "pdf_url": "http://arxiv.org/pdf/2510.26777v1"
  },
  {
    "id": "2510.26776v1",
    "title": "Faithful and Fast Influence Function via Advanced Sampling",
    "abstract": "How can we explain the influence of training data on black-box models?\nInfluence functions (IFs) offer a post-hoc solution by utilizing gradients and\nHessians. However, computing the Hessian for an entire dataset is\nresource-intensive, necessitating a feasible alternative. A common approach\ninvolves randomly sampling a small subset of the training data, but this method\noften results in highly inconsistent IF estimates due to the high variance in\nsample configurations. To address this, we propose two advanced sampling\ntechniques based on features and logits. These samplers select a small yet\nrepresentative subset of the entire dataset by considering the stochastic\ndistribution of features or logits, thereby enhancing the accuracy of IF\nestimations. We validate our approach through class removal experiments, a\ntypical application of IFs, using the F1-score to measure how effectively the\nmodel forgets the removed class while maintaining inference consistency on the\nremaining classes. Our method reduces computation time by 30.1% and memory\nusage by 42.2%, or improves the F1-score by 2.5% compared to the baseline.",
    "categories": [
      "cs.LG",
      "cs.AI"
    ],
    "published": "2025-10-30T17:55:19Z",
    "authors": [
      "Jungyeon Koh",
      "Hyeonsu Lyu",
      "Jonggyu Jang",
      "Hyun Jong Yang"
    ],
    "pdf_url": "http://arxiv.org/pdf/2510.26776v1"
  },
  {
    "id": "2510.26771v1",
    "title": "STaMP: Sequence Transformation and Mixed Precision for Low-Precision\n  Activation Quantization",
    "abstract": "Quantization is the key method for reducing inference latency, power and\nmemory footprint of generative AI models. However, accuracy often degrades\nsharply when activations are quantized below eight bits. Recent work suggests\nthat invertible linear transformations (e.g. rotations) can aid quantization,\nby reparameterizing feature channels and weights. In this paper, we propose\n\\textit{Sequence Transformation and Mixed Precision} (STaMP) quantization, a\nnovel strategy that applies linear transformations along the \\textit{sequence}\ndimension to exploit the strong local correlation in language and visual data.\nBy keeping a small number of tokens in each intermediate activation at higher\nprecision, we can maintain model accuracy at lower (average) activations\nbit-widths. We evaluate STaMP on recent LVM and LLM architectures,\ndemonstrating that it significantly improves low bit width activation\nquantization and complements established activation and weight quantization\nmethods including recent feature transformations.",
    "categories": [
      "cs.LG",
      "cs.AI"
    ],
    "published": "2025-10-30T17:53:42Z",
    "authors": [
      "Marco Federici",
      "Riccardo Del Chiaro",
      "Boris van Breugel",
      "Paul Whatmough",
      "Markus Nagel"
    ],
    "pdf_url": "http://arxiv.org/pdf/2510.26771v1"
  },
  {
    "id": "2510.26769v1",
    "title": "SteerVLM: Robust Model Control through Lightweight Activation Steering\n  for Vision Language Models",
    "abstract": "This work introduces SteerVLM, a lightweight steering module designed to\nguide Vision-Language Models (VLMs) towards outputs that better adhere to\ndesired instructions. Our approach learns from the latent embeddings of paired\nprompts encoding target and converse behaviors to dynamically adjust\nactivations connecting the language modality with image context. This allows\nfor fine-grained, inference-time control over complex output semantics without\nmodifying model weights while preserving performance on off-target tasks. Our\nsteering module requires learning parameters equal to 0.14% of the original\nVLM's size. Our steering module gains model control through dimension-wise\nactivation modulation and adaptive steering across layers without requiring\npre-extracted static vectors or manual tuning of intervention points.\nFurthermore, we introduce VNIA (Visual Narrative Intent Alignment), a\nmultimodal dataset specifically created to facilitate the development and\nevaluation of VLM steering techniques. Our method outperforms existing\nintervention techniques on steering and hallucination mitigation benchmarks for\nVLMs and proposes a robust solution for multimodal model control through\nactivation engineering.",
    "categories": [
      "cs.CV",
      "cs.LG"
    ],
    "published": "2025-10-30T17:52:39Z",
    "authors": [
      "Anushka Sivakumar",
      "Andrew Zhang",
      "Zaber Hakim",
      "Chris Thomas"
    ],
    "pdf_url": "http://arxiv.org/pdf/2510.26769v1"
  },
  {
    "id": "2510.26752v1",
    "title": "The Oversight Game: Learning to Cooperatively Balance an AI Agent's\n  Safety and Autonomy",
    "abstract": "As increasingly capable agents are deployed, a central safety question is how\nto retain meaningful human control without modifying the underlying system. We\nstudy a minimal control interface where an agent chooses whether to act\nautonomously (play) or defer (ask), while a human simultaneously chooses\nwhether to be permissive (trust) or to engage in oversight (oversee). If the\nagent defers, the human's choice determines the outcome, potentially leading to\na corrective action or a system shutdown. We model this interaction as a\ntwo-player Markov Game. Our analysis focuses on cases where this game qualifies\nas a Markov Potential Game (MPG), a class of games where we can provide an\nalignment guarantee: under a structural assumption on the human's value\nfunction, any decision by the agent to act more autonomously that benefits\nitself cannot harm the human's value. We also analyze extensions to this MPG\nframework. Theoretically, this perspective provides conditions for a specific\nform of intrinsic alignment. If the reward structures of the human-agent game\nmeet these conditions, we have a formal guarantee that the agent improving its\nown outcome will not harm the human's. Practically, this model motivates a\ntransparent control layer with predictable incentives where the agent learns to\ndefer when risky and act when safe, while its pretrained policy and the\nenvironment's reward structure remain untouched. Our gridworld simulation shows\nthat through independent learning, the agent and human discover their optimal\noversight roles. The agent learns to ask when uncertain and the human learns\nwhen to oversee, leading to an emergent collaboration that avoids safety\nviolations introduced post-training. This demonstrates a practical method for\nmaking misaligned models safer after deployment.",
    "categories": [
      "cs.AI",
      "cs.LG"
    ],
    "published": "2025-10-30T17:46:49Z",
    "authors": [
      "William Overman",
      "Mohsen Bayati"
    ],
    "pdf_url": "http://arxiv.org/pdf/2510.26752v1"
  },
  {
    "id": "2510.26745v1",
    "title": "Deep sequence models tend to memorize geometrically; it is unclear why",
    "abstract": "In sequence modeling, the parametric memory of atomic facts has been\npredominantly abstracted as a brute-force lookup of co-occurrences between\nentities. We contrast this associative view against a geometric view of how\nmemory is stored. We begin by isolating a clean and analyzable instance of\nTransformer reasoning that is incompatible with memory as strictly a storage of\nthe local co-occurrences specified during training. Instead, the model must\nhave somehow synthesized its own geometry of atomic facts, encoding global\nrelationships between all entities, including non-co-occurring ones. This in\nturn has simplified a hard reasoning task involving an $\\ell$-fold composition\ninto an easy-to-learn 1-step geometric task.\n  From this phenomenon, we extract fundamental aspects of neural embedding\ngeometries that are hard to explain. We argue that the rise of such a geometry,\ndespite optimizing over mere local associations, cannot be straightforwardly\nattributed to typical architectural or optimizational pressures.\nCounterintuitively, an elegant geometry is learned even when it is not more\nsuccinct than a brute-force lookup of associations.\n  Then, by analyzing a connection to Node2Vec, we demonstrate how the geometry\nstems from a spectral bias that -- in contrast to prevailing theories -- indeed\narises naturally despite the lack of various pressures. This analysis also\npoints to practitioners a visible headroom to make Transformer memory more\nstrongly geometric. We hope the geometric view of parametric memory encourages\nrevisiting the default intuitions that guide researchers in areas like\nknowledge acquisition, capacity, discovery and unlearning.",
    "categories": [
      "cs.LG",
      "cs.AI",
      "cs.CL",
      "stat.ML"
    ],
    "published": "2025-10-30T17:40:22Z",
    "authors": [
      "Shahriar Noroozizadeh",
      "Vaishnavh Nagarajan",
      "Elan Rosenfeld",
      "Sanjiv Kumar"
    ],
    "pdf_url": "http://arxiv.org/pdf/2510.26745v1"
  },
  {
    "id": "2510.26723v1",
    "title": "Bridging the Gap between Empirical Welfare Maximization and Conditional\n  Average Treatment Effect Estimation in Policy Learning",
    "abstract": "The goal of policy learning is to train a policy function that recommends a\ntreatment given covariates to maximize population welfare. There are two major\napproaches in policy learning: the empirical welfare maximization (EWM)\napproach and the plug-in approach. The EWM approach is analogous to a\nclassification problem, where one first builds an estimator of the population\nwelfare, which is a functional of policy functions, and then trains a policy by\nmaximizing the estimated welfare. In contrast, the plug-in approach is based on\nregression, where one first estimates the conditional average treatment effect\n(CATE) and then recommends the treatment with the highest estimated outcome.\nThis study bridges the gap between the two approaches by showing that both are\nbased on essentially the same optimization problem. In particular, we prove an\nexact equivalence between EWM and least squares over a reparameterization of\nthe policy class. As a consequence, the two approaches are interchangeable in\nseveral respects and share the same theoretical guarantees under common\nconditions. Leveraging this equivalence, we propose a novel regularization\nmethod for policy learning. Our findings yield a convex and computationally\nefficient training procedure that avoids the NP-hard combinatorial step\ntypically required in EWM.",
    "categories": [
      "stat.ML",
      "cs.LG",
      "econ.EM",
      "math.ST",
      "stat.ME",
      "stat.TH"
    ],
    "published": "2025-10-30T17:23:40Z",
    "authors": [
      "Masahiro Kato"
    ],
    "pdf_url": "http://arxiv.org/pdf/2510.26723v1"
  },
  {
    "id": "2510.26722v1",
    "title": "Non-Convex Over-the-Air Heterogeneous Federated Learning: A\n  Bias-Variance Trade-off",
    "abstract": "Over-the-air (OTA) federated learning (FL) has been well recognized as a\nscalable paradigm that exploits the waveform superposition of the wireless\nmultiple-access channel to aggregate model updates in a single use. Existing\nOTA-FL designs largely enforce zero-bias model updates by either assuming\n\\emph{homogeneous} wireless conditions (equal path loss across devices) or\nforcing zero-bias updates to guarantee convergence. Under \\emph{heterogeneous}\nwireless scenarios, however, such designs are constrained by the weakest device\nand inflate the update variance. Moreover, prior analyses of biased OTA-FL\nlargely address convex objectives, while most modern AI models are highly\nnon-convex. Motivated by these gaps, we study OTA-FL with stochastic gradient\ndescent (SGD) for general smooth non-convex objectives under wireless\nheterogeneity. We develop novel OTA-FL SGD updates that allow a structured,\ntime-invariant model bias while facilitating reduced variance updates. We\nderive a finite-time stationarity bound (expected time average squared gradient\nnorm) that explicitly reveals a bias-variance trade-off. To optimize this\ntrade-off, we pose a non-convex joint OTA power-control design and develop an\nefficient successive convex approximation (SCA) algorithm that requires only\nstatistical CSI at the base station. Experiments on a non-convex image\nclassification task validate the approach: the SCA-based design accelerates\nconvergence via an optimized bias and improves generalization over prior OTA-FL\nbaselines.",
    "categories": [
      "cs.LG",
      "cs.AI",
      "cs.DC",
      "cs.SY",
      "eess.SP",
      "eess.SY"
    ],
    "published": "2025-10-30T17:22:57Z",
    "authors": [
      "Muhammad Faraz Ul Abrar",
      "Nicol\u00f2 Michelusi"
    ],
    "pdf_url": "http://arxiv.org/pdf/2510.26722v1"
  },
  {
    "id": "2510.26717v1",
    "title": "On Purely Private Covariance Estimation",
    "abstract": "We present a simple perturbation mechanism for the release of $d$-dimensional\ncovariance matrices $\\Sigma$ under pure differential privacy. For large\ndatasets with at least $n\\geq d^2/\\varepsilon$ elements, our mechanism recovers\nthe provably optimal Frobenius norm error guarantees of\n\\cite{nikolov2023private}, while simultaneously achieving best known error for\nall other $p$-Schatten norms, with $p\\in [1,\\infty]$. Our error is\ninformation-theoretically optimal for all $p\\ge 2$, in particular, our\nmechanism is the first purely private covariance estimator that achieves\noptimal error in spectral norm.\n  For small datasets $n< d^2/\\varepsilon$, we further show that by projecting\nthe output onto the nuclear norm ball of appropriate radius, our algorithm\nachieves the optimal Frobenius norm error $O(\\sqrt{d\\;\\text{Tr}(\\Sigma) /n})$,\nimproving over the known bounds of $O(\\sqrt{d/n})$ of \\cite{nikolov2023private}\nand ${O}\\big(d^{3/4}\\sqrt{\\text{Tr}(\\Sigma)/n}\\big)$ of\n\\cite{dong2022differentially}.",
    "categories": [
      "cs.LG",
      "cs.DS"
    ],
    "published": "2025-10-30T17:18:53Z",
    "authors": [
      "Tommaso d'Orsi",
      "Gleb Novikov"
    ],
    "pdf_url": "http://arxiv.org/pdf/2510.26717v1"
  },
  {
    "id": "2510.26715v1",
    "title": "LSM-MS2: A Foundation Model Bridging Spectral Identification and\n  Biological Interpretation",
    "abstract": "A vast majority of mass spectrometry data remains uncharacterized, leaving\nmuch of its biological and chemical information untapped. Recent advances in\nmachine learning have begun to address this gap, particularly for tasks such as\nspectral identification in tandem mass spectrometry data. Here, we present the\nlatest generation of LSM-MS2, a large-scale deep learning foundation model\ntrained on millions of spectra to learn a semantic chemical space. LSM-MS2\nachieves state-of-the-art performance in spectral identification, improving on\nexisting methods by 30% in accuracy of identifying challenging isomeric\ncompounds, yielding 42% more correct identifications in complex biological\nsamples, and maintaining robustness under low-concentration conditions.\nFurthermore, LSM-MS2 produces rich spectral embeddings that enable direct\nbiological interpretation from minimal downstream data, successfully\ndifferentiating disease states and predicting clinical outcomes across diverse\ntranslational applications.",
    "categories": [
      "cs.LG"
    ],
    "published": "2025-10-30T17:13:58Z",
    "authors": [
      "Gabriel Asher",
      "Devesh Shah",
      "Amy A. Caudy",
      "Luke Ferro",
      "Lea Amar",
      "Ana S. H. Costa",
      "Thomas Patton",
      "Niall O'Connor",
      "Jennifer M. Campbell",
      "Jack Geremia"
    ],
    "pdf_url": "http://arxiv.org/pdf/2510.26715v1"
  },
  {
    "id": "2510.26714v1",
    "title": "On the limitation of evaluating machine unlearning using only a single\n  training seed",
    "abstract": "Machine unlearning (MU) aims to remove the influence of certain data points\nfrom a trained model without costly retraining. Most practical MU algorithms\nare only approximate and their performance can only be assessed empirically.\nCare must therefore be taken to make empirical comparisons as representative as\npossible. A common practice is to run the MU algorithm multiple times\nindependently starting from the same trained model. In this work, we\ndemonstrate that this practice can give highly non-representative results\nbecause -- even for the same architecture and same dataset -- some MU methods\ncan be highly sensitive to the choice of random number seed used for model\ntraining. We therefore recommend that empirical\ncomphttps://info.arxiv.org/help/prep#commentsarisons of MU algorithms should\nalso reflect the variability across different model training seeds.",
    "categories": [
      "cs.LG",
      "cs.AI"
    ],
    "published": "2025-10-30T17:13:42Z",
    "authors": [
      "Jamie Lanyon",
      "Axel Finke",
      "Petros Andreou",
      "Georgina Cosma"
    ],
    "pdf_url": "http://arxiv.org/pdf/2510.26714v1"
  },
  {
    "id": "2510.26709v1",
    "title": "An All-Reduce Compatible Top-K Compressor for Communication-Efficient\n  Distributed Learning",
    "abstract": "Communication remains a central bottleneck in large-scale distributed machine\nlearning, and gradient sparsification has emerged as a promising strategy to\nalleviate this challenge. However, existing gradient compressors face notable\nlimitations: Rand-$K$\\ discards structural information and performs poorly in\npractice, while Top-$K$\\ preserves informative entries but loses the\ncontraction property and requires costly All-Gather operations. In this paper,\nwe propose ARC-Top-$K$, an {All-Reduce}-Compatible Top-$K$ compressor that\naligns sparsity patterns across nodes using a lightweight sketch of the\ngradient, enabling index-free All-Reduce while preserving globally significant\ninformation. ARC-Top-$K$\\ is provably contractive and, when combined with\nmomentum error feedback (EF21M), achieves linear speedup and sharper\nconvergence rates than the original EF21M under standard assumptions.\nEmpirically, ARC-Top-$K$\\ matches the accuracy of Top-$K$\\ while reducing\nwall-clock training time by up to 60.7\\%, offering an efficient and scalable\nsolution that combines the robustness of Rand-$K$\\ with the strong performance\nof Top-$K$.",
    "categories": [
      "cs.LG",
      "cs.DC"
    ],
    "published": "2025-10-30T17:11:01Z",
    "authors": [
      "Chuyan Chen",
      "Chenyang Ma",
      "Zhangxin Li",
      "Yutong He",
      "Yanjie Dong",
      "Kun Yuan"
    ],
    "pdf_url": "http://arxiv.org/pdf/2510.26709v1"
  },
  {
    "id": "2510.26707v1",
    "title": "Value Drifts: Tracing Value Alignment During LLM Post-Training",
    "abstract": "As LLMs occupy an increasingly important role in society, they are more and\nmore confronted with questions that require them not only to draw on their\ngeneral knowledge but also to align with certain human value systems.\nTherefore, studying the alignment of LLMs with human values has become a\ncrucial field of inquiry. Prior work, however, mostly focuses on evaluating the\nalignment of fully trained models, overlooking the training dynamics by which\nmodels learn to express human values. In this work, we investigate how and at\nwhich stage value alignment arises during the course of a model's\npost-training. Our analysis disentangles the effects of post-training\nalgorithms and datasets, measuring both the magnitude and time of value drifts\nduring training. Experimenting with Llama-3 and Qwen-3 models of different\nsizes and popular supervised fine-tuning (SFT) and preference optimization\ndatasets and algorithms, we find that the SFT phase generally establishes a\nmodel's values, and subsequent preference optimization rarely re-aligns these\nvalues. Furthermore, using a synthetic preference dataset that enables\ncontrolled manipulation of values, we find that different preference\noptimization algorithms lead to different value alignment outcomes, even when\npreference data is held constant. Our findings provide actionable insights into\nhow values are learned during post-training and help to inform data curation,\nas well as the selection of models and algorithms for preference optimization\nto improve model alignment to human values.",
    "categories": [
      "cs.CL",
      "cs.CY",
      "cs.LG"
    ],
    "published": "2025-10-30T17:09:09Z",
    "authors": [
      "Mehar Bhatia",
      "Shravan Nayak",
      "Gaurav Kamath",
      "Marius Mosbach",
      "Karolina Sta\u0144czak",
      "Vered Shwartz",
      "Siva Reddy"
    ],
    "pdf_url": "http://arxiv.org/pdf/2510.26707v1"
  },
  {
    "id": "2510.26706v1",
    "title": "Budgeted Multiple-Expert Deferral",
    "abstract": "Learning to defer uncertain predictions to costly experts offers a powerful\nstrategy for improving the accuracy and efficiency of machine learning systems.\nHowever, standard training procedures for deferral algorithms typically require\nquerying all experts for every training instance, an approach that becomes\nprohibitively expensive when expert queries incur significant computational or\nresource costs. This undermines the core goal of deferral: to limit unnecessary\nexpert usage. To overcome this challenge, we introduce the budgeted deferral\nframework, which aims to train effective deferral algorithms while minimizing\nexpert query costs during training. We propose new algorithms for both\ntwo-stage and single-stage multiple-expert deferral settings that selectively\nquery only a subset of experts per training example. While inspired by active\nlearning, our setting is fundamentally different: labels are already known, and\nthe core challenge is to decide which experts to query in order to balance cost\nand predictive performance. We establish theoretical guarantees for both of our\nalgorithms, including generalization bounds and label complexity analyses.\nEmpirical results across several domains show that our algorithms substantially\nreduce training costs without sacrificing prediction accuracy, demonstrating\nthe practical value of our budget-aware deferral algorithms.",
    "categories": [
      "cs.LG",
      "stat.ML"
    ],
    "published": "2025-10-30T17:08:52Z",
    "authors": [
      "Giulia DeSalvo",
      "Clara Mohri",
      "Mehryar Mohri",
      "Yutao Zhong"
    ],
    "pdf_url": "http://arxiv.org/pdf/2510.26706v1"
  },
  {
    "id": "2510.26704v1",
    "title": "How Regularization Terms Make Invertible Neural Networks Bayesian Point\n  Estimators",
    "abstract": "Can regularization terms in the training of invertible neural networks lead\nto known Bayesian point estimators in reconstruction? Invertible networks are\nattractive for inverse problems due to their inherent stability and\ninterpretability. Recently, optimization strategies for invertible neural\nnetworks that approximate either a reconstruction map or the forward operator\nhave been studied from a Bayesian perspective, but each has limitations. To\naddress this, we introduce and analyze two regularization terms for the network\ntraining that, upon inversion of the network, recover properties of classical\nBayesian point estimators: while the first can be connected to the posterior\nmean, the second resembles the MAP estimator. Our theoretical analysis\ncharacterizes how each loss shapes both the learned forward operator and its\ninverse reconstruction map. Numerical experiments support our findings and\ndemonstrate how these loss-term regularizers introduce data-dependence in a\nstable and interpretable way.",
    "categories": [
      "cs.LG",
      "cs.NA",
      "math.NA",
      "65J22, 68T07 (Primary) 62F15 (Secondary)"
    ],
    "published": "2025-10-30T17:07:14Z",
    "authors": [
      "Nick Heilenk\u00f6tter"
    ],
    "pdf_url": "http://arxiv.org/pdf/2510.26704v1"
  },
  {
    "id": "2510.26700v1",
    "title": "Assessment of the conditional exchangeability assumption in causal\n  machine learning models: a simulation study",
    "abstract": "Observational studies developing causal machine learning (ML) models for the\nprediction of individualized treatment effects (ITEs) seldom conduct empirical\nevaluations to assess the conditional exchangeability assumption. We aimed to\nevaluate the performance of these models under conditional exchangeability\nviolations and the utility of negative control outcomes (NCOs) as a diagnostic.\nWe conducted a simulation study to examine confounding bias in ITE estimates\ngenerated by causal forest and X-learner models under varying conditions,\nincluding the presence or absence of true heterogeneity. We simulated data to\nreflect real-world scenarios with differing levels of confounding, sample size,\nand NCO confounding structures. We then estimated and compared subgroup-level\ntreatment effects on the primary outcome and NCOs across settings with and\nwithout unmeasured confounding. When conditional exchangeability was violated,\ncausal forest and X-learner models failed to recover true treatment effect\nheterogeneity and, in some cases, falsely indicated heterogeneity when there\nwas none. NCOs successfully identified subgroups affected by unmeasured\nconfounding. Even when NCOs did not perfectly satisfy its ideal assumptions, it\nremained informative, flagging potential bias in subgroup level estimates,\nthough not always pinpointing the subgroup with the largest confounding.\nViolations of conditional exchangeability substantially limit the validity of\nITE estimates from causal ML models in routinely collected observational data.\nNCOs serve a useful empirical diagnostic tool for detecting subgroup-specific\nunmeasured confounding and should be incorporated into causal ML workflows to\nsupport the credibility of individualized inference.",
    "categories": [
      "stat.ML",
      "cs.LG"
    ],
    "published": "2025-10-30T17:05:57Z",
    "authors": [
      "Gerard T. Portela",
      "Jason B. Gibbons",
      "Sebastian Schneeweiss",
      "Rishi J. Desai"
    ],
    "pdf_url": "http://arxiv.org/pdf/2510.26700v1"
  },
  {
    "id": "2510.26692v1",
    "title": "Kimi Linear: An Expressive, Efficient Attention Architecture",
    "abstract": "We introduce Kimi Linear, a hybrid linear attention architecture that, for\nthe first time, outperforms full attention under fair comparisons across\nvarious scenarios -- including short-context, long-context, and reinforcement\nlearning (RL) scaling regimes. At its core lies Kimi Delta Attention (KDA), an\nexpressive linear attention module that extends Gated DeltaNet with a\nfiner-grained gating mechanism, enabling more effective use of limited\nfinite-state RNN memory. Our bespoke chunkwise algorithm achieves high hardware\nefficiency through a specialized variant of the Diagonal-Plus-Low-Rank (DPLR)\ntransition matrices, which substantially reduces computation compared to the\ngeneral DPLR formulation while remaining more consistent with the classical\ndelta rule.\n  We pretrain a Kimi Linear model with 3B activated parameters and 48B total\nparameters, based on a layerwise hybrid of KDA and Multi-Head Latent Attention\n(MLA). Our experiments show that with an identical training recipe, Kimi Linear\noutperforms full MLA with a sizeable margin across all evaluated tasks, while\nreducing KV cache usage by up to 75% and achieving up to 6 times decoding\nthroughput for a 1M context. These results demonstrate that Kimi Linear can be\na drop-in replacement for full attention architectures with superior\nperformance and efficiency, including tasks with longer input and output\nlengths.\n  To support further research, we open-source the KDA kernel and vLLM\nimplementations, and release the pre-trained and instruction-tuned model\ncheckpoints.",
    "categories": [
      "cs.CL",
      "cs.LG"
    ],
    "published": "2025-10-30T16:59:43Z",
    "authors": [
      " Kimi Team",
      "Yu Zhang",
      "Zongyu Lin",
      "Xingcheng Yao",
      "Jiaxi Hu",
      "Fanqing Meng",
      "Chengyin Liu",
      "Xin Men",
      "Songlin Yang",
      "Zhiyuan Li",
      "Wentao Li",
      "Enzhe Lu",
      "Weizhou Liu",
      "Yanru Chen",
      "Weixin Xu",
      "Longhui Yu",
      "Yejie Wang",
      "Yu Fan",
      "Longguang Zhong",
      "Enming Yuan",
      "Dehao Zhang",
      "Yizhi Zhang",
      "T. Y. Liu",
      "Haiming Wang",
      "Shengjun Fang",
      "Weiran He",
      "Shaowei Liu",
      "Yiwei Li",
      "Jianlin Su",
      "Jiezhong Qiu",
      "Bo Pang",
      "Junjie Yan",
      "Zhejun Jiang",
      "Weixiao Huang",
      "Bohong Yin",
      "Jiacheng You",
      "Chu Wei",
      "Zhengtao Wang",
      "Chao Hong",
      "Yutian Chen",
      "Guanduo Chen",
      "Yucheng Wang",
      "Huabin Zheng",
      "Feng Wang",
      "Yibo Liu",
      "Mengnan Dong",
      "Zheng Zhang",
      "Siyuan Pan",
      "Wenhao Wu",
      "Yuhao Wu",
      "Longyu Guan",
      "Jiawen Tao",
      "Guohong Fu",
      "Xinran Xu",
      "Yuzhi Wang",
      "Guokun Lai",
      "Yuxin Wu",
      "Xinyu Zhou",
      "Zhilin Yang",
      "Yulun Du"
    ],
    "pdf_url": "http://arxiv.org/pdf/2510.26692v1"
  },
  {
    "id": "2510.26690v1",
    "title": "LoRAQuant: Mixed-Precision Quantization of LoRA to Ultra-Low Bits",
    "abstract": "Low-Rank Adaptation (LoRA) has become a popular technique for\nparameter-efficient fine-tuning of large language models (LLMs). In many\nreal-world scenarios, multiple adapters are loaded simultaneously to enable LLM\ncustomization for personalized user experiences or to support a diverse range\nof tasks. Although each adapter is lightweight in isolation, their aggregate\ncost becomes substantial at scale. To address this, we propose LoRAQuant, a\nmixed-precision post-training quantization method tailored to LoRA.\nSpecifically, LoRAQuant reparameterizes each adapter by singular value\ndecomposition (SVD) to concentrate the most important information into specific\nrows and columns. This makes it possible to quantize the important components\nto higher precision, while quantizing the rest to ultra-low bitwidth. We\nconduct comprehensive experiments with LLaMA 2-7B, LLaMA 2-13B, and Mistral 7B\nmodels on mathematical reasoning, coding, and summarization tasks. Results show\nthat our LoRAQuant uses significantly lower bits than other quantization\nmethods, but achieves comparable or even higher performance.",
    "categories": [
      "cs.LG"
    ],
    "published": "2025-10-30T16:59:22Z",
    "authors": [
      "Amir Reza Mirzaei",
      "Yuqiao Wen",
      "Yanshuai Cao",
      "Lili Mou"
    ],
    "pdf_url": "http://arxiv.org/pdf/2510.26690v1"
  },
  {
    "id": "2510.26688v1",
    "title": "FlowQ-Net: A Generative Framework for Automated Quantum Circuit Design",
    "abstract": "Designing efficient quantum circuits is a central bottleneck to exploring the\npotential of quantum computing, particularly for noisy intermediate-scale\nquantum (NISQ) devices, where circuit efficiency and resilience to errors are\nparamount. The search space of gate sequences grows combinatorially, and\nhandcrafted templates often waste scarce qubit and depth budgets. We introduce\n\\textsc{FlowQ-Net} (Flow-based Quantum design Network), a generative framework\nfor automated quantum circuit synthesis based on Generative Flow Networks\n(GFlowNets). This framework learns a stochastic policy to construct circuits\nsequentially, sampling them in proportion to a flexible, user-defined reward\nfunction that can encode multiple design objectives such as performance, depth,\nand gate count. This approach uniquely enables the generation of a diverse\nensemble of high-quality circuits, moving beyond single-solution optimization.\nWe demonstrate the efficacy of \\textsc{FlowQ-Net} through an extensive set of\nsimulations. We apply our method to Variational Quantum Algorithm (VQA) ansatz\ndesign for molecular ground state estimation, Max-Cut, and image\nclassification, key challenges in near-term quantum computing. Circuits\ndesigned by \\textsc{FlowQ-Net} achieve significant improvements, yielding\ncircuits that are 10$\\times$-30$\\times$ more compact in terms of parameters,\ngates, and depth compared to commonly used unitary baselines, without\ncompromising accuracy. This trend holds even when subjected to error profiles\nfrom real-world quantum devices. Our results underline the potential of\ngenerative models as a general-purpose methodology for automated quantum\ncircuit design, offering a promising path towards more efficient quantum\nalgorithms and accelerating scientific discovery in the quantum domain.",
    "categories": [
      "quant-ph",
      "cs.LG"
    ],
    "published": "2025-10-30T16:57:13Z",
    "authors": [
      "Jun Dai",
      "Michael Rizvi-Martel",
      "Guillaume Rabusseau"
    ],
    "pdf_url": "http://arxiv.org/pdf/2510.26688v1"
  },
  {
    "id": "2510.26679v1",
    "title": "Tight Differentially Private PCA via Matrix Coherence",
    "abstract": "We revisit the task of computing the span of the top $r$ singular vectors\n$u_1, \\ldots, u_r$ of a matrix under differential privacy. We show that a\nsimple and efficient algorithm -- based on singular value decomposition and\nstandard perturbation mechanisms -- returns a private rank-$r$ approximation\nwhose error depends only on the \\emph{rank-$r$ coherence} of $u_1, \\ldots, u_r$\nand the spectral gap $\\sigma_r - \\sigma_{r+1}$. This resolves a question posed\nby Hardt and Roth~\\cite{hardt2013beyond}. Our estimator outperforms the state\nof the art -- significantly so in some regimes. In particular, we show that in\nthe dense setting, it achieves the same guarantees for single-spike PCA in the\nWishart model as those attained by optimal non-private algorithms, whereas\nprior private algorithms failed to do so.\n  In addition, we prove that (rank-$r$) coherence does not increase under\nGaussian perturbations. This implies that any estimator based on the Gaussian\nmechanism -- including ours -- preserves the coherence of the input. We\nconjecture that similar behavior holds for other structured models, including\nplanted problems in graphs.\n  We also explore applications of coherence to graph problems. In particular,\nwe present a differentially private algorithm for Max-Cut and other constraint\nsatisfaction problems under low coherence assumptions.",
    "categories": [
      "cs.LG",
      "cs.DS"
    ],
    "published": "2025-10-30T16:47:26Z",
    "authors": [
      "Tommaso d'Orsi",
      "Gleb Novikov"
    ],
    "pdf_url": "http://arxiv.org/pdf/2510.26679v1"
  },
  {
    "id": "2510.26672v1",
    "title": "Action-Driven Processes for Continuous-Time Control",
    "abstract": "At the heart of reinforcement learning are actions -- decisions made in\nresponse to observations of the environment. Actions are equally fundamental in\nthe modeling of stochastic processes, as they trigger discontinuous state\ntransitions and enable the flow of information through large, complex systems.\nIn this paper, we unify the perspectives of stochastic processes and\nreinforcement learning through action-driven processes, and illustrate their\napplication to spiking neural networks. Leveraging ideas from\ncontrol-as-inference, we show that minimizing the Kullback-Leibler divergence\nbetween a policy-driven true distribution and a reward-driven model\ndistribution for a suitably defined action-driven process is equivalent to\nmaximum entropy reinforcement learning.",
    "categories": [
      "stat.ML",
      "cs.LG"
    ],
    "published": "2025-10-30T16:42:09Z",
    "authors": [
      "Ruimin He",
      "Shaowei Lin"
    ],
    "pdf_url": "http://arxiv.org/pdf/2510.26672v1"
  },
  {
    "id": "2510.26656v1",
    "title": "Heuristic Adaptation of Potentially Misspecified Domain Support for\n  Likelihood-Free Inference in Stochastic Dynamical Systems",
    "abstract": "In robotics, likelihood-free inference (LFI) can provide the domain\ndistribution that adapts a learnt agent in a parametric set of deployment\nconditions. LFI assumes an arbitrary support for sampling, which remains\nconstant as the initial generic prior is iteratively refined to more\ndescriptive posteriors. However, a potentially misspecified support can lead to\nsuboptimal, yet falsely certain, posteriors. To address this issue, we propose\nthree heuristic LFI variants: EDGE, MODE, and CENTRE. Each interprets the\nposterior mode shift over inference steps in its own way and, when integrated\ninto an LFI step, adapts the support alongside posterior inference. We first\nexpose the support misspecification issue and evaluate our heuristics using\nstochastic dynamical benchmarks. We then evaluate the impact of heuristic\nsupport adaptation on parameter inference and policy learning for a dynamic\ndeformable linear object (DLO) manipulation task. Inference results in a finer\nlength and stiffness classification for a parametric set of DLOs. When the\nresulting posteriors are used as domain distributions for sim-based policy\nlearning, they lead to more robust object-centric agent performance.",
    "categories": [
      "cs.RO",
      "cs.LG"
    ],
    "published": "2025-10-30T16:23:46Z",
    "authors": [
      "Georgios Kamaras",
      "Craig Innes",
      "Subramanian Ramamoorthy"
    ],
    "pdf_url": "http://arxiv.org/pdf/2510.26656v1"
  },
  {
    "id": "2510.26646v1",
    "title": "Hybrid DQN-TD3 Reinforcement Learning for Autonomous Navigation in\n  Dynamic Environments",
    "abstract": "This paper presents a hierarchical path-planning and control framework that\ncombines a high-level Deep Q-Network (DQN) for discrete sub-goal selection with\na low-level Twin Delayed Deep Deterministic Policy Gradient (TD3) controller\nfor continuous actuation. The high-level module selects behaviors and\nsub-goals; the low-level module executes smooth velocity commands. We design a\npractical reward shaping scheme (direction, distance, obstacle avoidance,\naction smoothness, collision penalty, time penalty, and progress), together\nwith a LiDAR-based safety gate that prevents unsafe motions. The system is\nimplemented in ROS + Gazebo (TurtleBot3) and evaluated with PathBench metrics,\nincluding success rate, collision rate, path efficiency, and re-planning\nefficiency, in dynamic and partially observable environments. Experiments show\nimproved success rate and sample efficiency over single-algorithm baselines\n(DQN or TD3 alone) and rule-based planners, with better generalization to\nunseen obstacle configurations and reduced abrupt control changes. Code and\nevaluation scripts are available at the project repository.",
    "categories": [
      "cs.RO",
      "cs.AI",
      "cs.LG"
    ],
    "published": "2025-10-30T16:12:01Z",
    "authors": [
      "Xiaoyi He",
      "Danggui Chen",
      "Zhenshuo Zhang",
      "Zimeng Bai"
    ],
    "pdf_url": "http://arxiv.org/pdf/2510.26646v1"
  },
  {
    "id": "2510.26645v1",
    "title": "Curly Flow Matching for Learning Non-gradient Field Dynamics",
    "abstract": "Modeling the transport dynamics of natural processes from population-level\nobservations is a ubiquitous problem in the natural sciences. Such models rely\non key assumptions about the underlying process in order to enable faithful\nlearning of governing dynamics that mimic the actual system behavior. The de\nfacto assumption in current approaches relies on the principle of least action\nthat results in gradient field dynamics and leads to trajectories minimizing an\nenergy functional between two probability measures. However, many real-world\nsystems, such as cell cycles in single-cell RNA, are known to exhibit\nnon-gradient, periodic behavior, which fundamentally cannot be captured by\ncurrent state-of-the-art methods such as flow and bridge matching. In this\npaper, we introduce Curly Flow Matching (Curly-FM), a novel approach that is\ncapable of learning non-gradient field dynamics by designing and solving a\nSchr\\\"odinger bridge problem with a non-zero drift reference process -- in\nstark contrast to typical zero-drift reference processes -- which is\nconstructed using inferred velocities in addition to population snapshot data.\nWe showcase Curly-FM by solving the trajectory inference problems for single\ncells, computational fluid dynamics, and ocean currents with approximate\nvelocities. We demonstrate that Curly-FM can learn trajectories that better\nmatch both the reference process and population marginals. Curly-FM expands\nflow matching models beyond the modeling of populations and towards the\nmodeling of known periodic behavior in physical systems. Our code repository is\naccessible at: https://github.com/kpetrovicc/curly-flow-matching.git",
    "categories": [
      "cs.LG"
    ],
    "published": "2025-10-30T16:11:39Z",
    "authors": [
      "Katarina Petrovi\u0107",
      "Lazar Atanackovic",
      "Viggo Moro",
      "Kacper Kapu\u015bniak",
      "\u0130smail \u0130lkan Ceylan",
      "Michael Bronstein",
      "Avishek Joey Bose",
      "Alexander Tong"
    ],
    "pdf_url": "http://arxiv.org/pdf/2510.26645v1"
  },
  {
    "id": "2510.26643v1",
    "title": "MSAD: A Deep Dive into Model Selection for Time series Anomaly Detection",
    "abstract": "Anomaly detection is a fundamental task for time series analytics with\nimportant implications for the downstream performance of many applications.\nDespite increasing academic interest and the large number of methods proposed\nin the literature, recent benchmarks and evaluation studies demonstrated that\nno overall best anomaly detection methods exist when applied to very\nheterogeneous time series datasets. Therefore, the only scalable and viable\nsolution to solve anomaly detection over very different time series collected\nfrom diverse domains is to propose a model selection method that will select,\nbased on time series characteristics, the best anomaly detection methods to\nrun. Existing AutoML solutions are, unfortunately, not directly applicable to\ntime series anomaly detection, and no evaluation of time series-based\napproaches for model selection exists. Towards that direction, this paper\nstudies the performance of time series classification methods used as model\nselection for anomaly detection. In total, we evaluate 234 model configurations\nderived from 16 base classifiers across more than 1980 time series, and we\npropose the first extensive experimental evaluation of time series\nclassification as model selection for anomaly detection. Our results\ndemonstrate that model selection methods outperform every single anomaly\ndetection method while being in the same order of magnitude regarding execution\ntime. This evaluation is the first step to demonstrate the accuracy and\nefficiency of time series classification algorithms for anomaly detection, and\nrepresents a strong baseline that can then be used to guide the model selection\nstep in general AutoML pipelines. Preprint version of an article accepted at\nthe VLDB Journal.",
    "categories": [
      "cs.LG"
    ],
    "published": "2025-10-30T16:09:51Z",
    "authors": [
      "Emmanouil Sylligardos",
      "John Paparrizos",
      "Themis Palpanas",
      "Pierre Senellart",
      "Paul Boniol"
    ],
    "pdf_url": "http://arxiv.org/pdf/2510.26643v1"
  },
  {
    "id": "2510.26633v1",
    "title": "Omnipresent Yet Overlooked: Heat Kernels in Combinatorial Bayesian\n  Optimization",
    "abstract": "Bayesian Optimization (BO) has the potential to solve various combinatorial\ntasks, ranging from materials science to neural architecture search. However,\nBO requires specialized kernels to effectively model combinatorial domains.\nRecent efforts have introduced several combinatorial kernels, but the\nrelationships among them are not well understood. To bridge this gap, we\ndevelop a unifying framework based on heat kernels, which we derive in a\nsystematic way and express as simple closed-form expressions. Using this\nframework, we prove that many successful combinatorial kernels are either\nrelated or equivalent to heat kernels, and validate this theoretical claim in\nour experiments. Moreover, our analysis confirms and extends the results\npresented in Bounce: certain algorithms' performance decreases substantially\nwhen the unknown optima of the function do not have a certain structure. In\ncontrast, heat kernels are not sensitive to the location of the optima. Lastly,\nwe show that a fast and simple pipeline, relying on heat kernels, is able to\nachieve state-of-the-art results, matching or even outperforming certain slow\nor complex algorithms.",
    "categories": [
      "cs.LG"
    ],
    "published": "2025-10-30T16:02:53Z",
    "authors": [
      "Colin Doumont",
      "Victor Picheny",
      "Viacheslav Borovitskiy",
      "Henry Moss"
    ],
    "pdf_url": "http://arxiv.org/pdf/2510.26633v1"
  },
  {
    "id": "2510.26616v1",
    "title": "Aeolus: A Multi-structural Flight Delay Dataset",
    "abstract": "We introduce Aeolus, a large-scale Multi-modal Flight Delay Dataset designed\nto advance research on flight delay prediction and support the development of\nfoundation models for tabular data. Existing datasets in this domain are\ntypically limited to flat tabular structures and fail to capture the\nspatiotemporal dynamics inherent in delay propagation. Aeolus addresses this\nlimitation by providing three aligned modalities: (i) a tabular dataset with\nrich operational, meteorological, and airportlevel features for over 50 million\nflights; (ii) a flight chain module that models delay propagation along\nsequential flight legs, capturing upstream and downstream dependencies; and\n(iii) a flight network graph that encodes shared aircraft, crew, and airport\nresource connections, enabling cross-flight relational reasoning. The dataset\nis carefully constructed with temporal splits, comprehensive features, and\nstrict leakage prevention to support realistic and reproducible machine\nlearning evaluation. Aeolus supports a broad range of tasks, including\nregression, classification, temporal structure modeling, and graph learning,\nserving as a unified benchmark across tabular, sequential, and graph\nmodalities. We release baseline experiments and preprocessing tools to\nfacilitate adoption. Aeolus fills a key gap for both domain-specific modeling\nand general-purpose structured data research.Our source code and data can be\naccessed at https://github.com/Flnny/Delay-data",
    "categories": [
      "cs.LG",
      "cs.AI"
    ],
    "published": "2025-10-30T15:41:43Z",
    "authors": [
      "Lin Xu",
      "Xinyun Yuan",
      "Yuxuan Liang",
      "Suwan Yin",
      "Yuankai Wu"
    ],
    "pdf_url": "http://arxiv.org/pdf/2510.26616v1"
  },
  {
    "id": "2510.26609v1",
    "title": "CYPRESS: Crop Yield Prediction via Regression on Prithvi's Encoder for\n  Satellite Sensing",
    "abstract": "Accurate and timely crop yield prediction is crucial for global food security\nand modern agricultural management. Traditional methods often lack the\nscalability and granularity required for precision farming. This paper\nintroduces CYPRESS (Crop Yield Prediction via Regression on Prithvi's Encoder\nfor Satellite Sensing), a deep learning model designed for high-resolution,\nintra-field canola yield prediction. CYPRESS leverages a pre-trained,\nlarge-scale geospatial foundation model (Prithvi-EO-2.0-600M) and adapts it for\na continuous regression task, transforming multi-temporal satellite imagery\ninto dense, pixel-level yield maps. Evaluated on a comprehensive dataset from\nthe Canadian Prairies, CYPRESS demonstrates superior performance over existing\ndeep learning-based yield prediction models, highlighting the effectiveness of\nfine-tuning foundation models for specialized agricultural applications. By\nproviding a continuous, high-resolution output, CYPRESS offers a more\nactionable tool for precision agriculture than conventional classification or\ncounty-level aggregation methods. This work validates a novel approach that\nbridges the gap between large-scale Earth observation and on-farm\ndecision-making, offering a scalable solution for detailed agricultural\nmonitoring.",
    "categories": [
      "cs.CV",
      "cs.LG",
      "eess.IV"
    ],
    "published": "2025-10-30T15:37:40Z",
    "authors": [
      "Shayan Nejadshamsi",
      "Yuanyuan Zhang",
      "Shadi Zaki",
      "Brock Porth",
      "Lysa Porth",
      "Vahab Khoshdel"
    ],
    "pdf_url": "http://arxiv.org/pdf/2510.26609v1"
  },
  {
    "id": "2510.26607v1",
    "title": "Wasserstein Regression as a Variational Approximation of Probabilistic\n  Trajectories through the Bernstein Basis",
    "abstract": "This paper considers the problem of regression over distributions, which is\nbecoming increasingly important in machine learning. Existing approaches often\nignore the geometry of the probability space or are computationally expensive.\nTo overcome these limitations, a new method is proposed that combines the\nparameterization of probability trajectories using a Bernstein basis and the\nminimization of the Wasserstein distance between distributions. The key idea is\nto model a conditional distribution as a smooth probability trajectory defined\nby a weighted sum of Gaussian components whose parameters -- the mean and\ncovariance -- are functions of the input variable constructed using Bernstein\npolynomials. The loss function is the averaged squared Wasserstein distance\nbetween the predicted Gaussian distributions and the empirical data, which\ntakes into account the geometry of the distributions. An autodiff-based\noptimization method is used to train the model. Experiments on synthetic\ndatasets that include complex trajectories demonstrated that the proposed\nmethod provides competitive approximation quality in terms of the Wasserstein\ndistance, Energy Distance, and RMSE metrics, especially in cases of pronounced\nnonlinearity. The model demonstrates trajectory smoothness that is better than\nor comparable to alternatives and robustness to changes in data structure,\nwhile maintaining high interpretability due to explicit parameterization via\ncontrol points. The developed approach represents a balanced solution that\ncombines geometric accuracy, computational practicality, and interpretability.\nProspects for further research include extending the method to non-Gaussian\ndistributions, applying entropy regularization to speed up computations, and\nadapting the approach to working with high-dimensional data for approximating\nsurfaces and more complex structures.",
    "categories": [
      "cs.LG"
    ],
    "published": "2025-10-30T15:36:39Z",
    "authors": [
      "Maksim Maslov",
      "Alexander Kugaevskikh",
      "Matthew Ivanov"
    ],
    "pdf_url": "http://arxiv.org/pdf/2510.26607v1"
  },
  {
    "id": "2510.26593v1",
    "title": "Hybrid Physical-Neural Simulator for Fast Cosmological Hydrodynamics",
    "abstract": "Cosmological field-level inference requires differentiable forward models\nthat solve the challenging dynamics of gas and dark matter under hydrodynamics\nand gravity. We propose a hybrid approach where gravitational forces are\ncomputed using a differentiable particle-mesh solver, while the hydrodynamics\nare parametrized by a neural network that maps local quantities to an effective\npressure field. We demonstrate that our method improves upon alternative\napproaches, such as an Enthalpy Gradient Descent baseline, both at the field\nand summary-statistic level. The approach is furthermore highly data efficient,\nwith a single reference simulation of cosmological structure formation being\nsufficient to constrain the neural pressure model. This opens the door for\nfuture applications where the model is fit directly to observational data,\nrather than a training set of simulations.",
    "categories": [
      "astro-ph.CO",
      "cs.LG"
    ],
    "published": "2025-10-30T15:18:07Z",
    "authors": [
      "Arne Thomsen",
      "Tilman Tr\u00f6ster",
      "Fran\u00e7ois Lanusse"
    ],
    "pdf_url": "http://arxiv.org/pdf/2510.26593v1"
  },
  {
    "id": "2510.26586v1",
    "title": "Physics-Informed Mixture Models and Surrogate Models for Precision\n  Additive Manufacturing",
    "abstract": "In this study, we leverage a mixture model learning approach to identify\ndefects in laser-based Additive Manufacturing (AM) processes. By incorporating\nphysics based principles, we also ensure that the model is sensitive to\nmeaningful physical parameter variations. The empirical evaluation was\nconducted by analyzing real-world data from two AM processes: Directed Energy\nDeposition and Laser Powder Bed Fusion. In addition, we also studied the\nperformance of the developed framework over public datasets with different\nalloy type and experimental parameter information. The results show the\npotential of physics-guided mixture models to examine the underlying physical\nbehavior of an AM system.",
    "categories": [
      "math-ph",
      "cs.LG",
      "math.MP"
    ],
    "published": "2025-10-30T15:13:25Z",
    "authors": [
      "Sebastian Basterrech",
      "Shuo Shan",
      "Debabrata Adhikari",
      "Sankhya Mohanty"
    ],
    "pdf_url": "http://arxiv.org/pdf/2510.26586v1"
  },
  {
    "id": "2510.26577v1",
    "title": "Inference-Cost-Aware Dynamic Tree Construction for Efficient Inference\n  in Large Language Models",
    "abstract": "Large Language Models (LLMs) face significant inference latency challenges\nstemming from their autoregressive design and large size. To address this,\nspeculative decoding emerges as a solution, enabling the simultaneous\ngeneration and validation of multiple tokens. While recent approaches like\nEAGLE-2 and EAGLE-3 improve speculative decoding using dynamic tree structures,\nthey often neglect the impact of crucial system variables such as GPU devices\nand batch sizes.\n  Therefore, we introduce a new dynamic tree decoding approach called CAST that\ntakes into account inference costs, including factors such as GPU\nconfigurations and batch sizes, to dynamically refine the tree structure.\nThrough comprehensive experimentation across six diverse tasks and utilizing\nsix distinct LLMs, our methodology demonstrates remarkable results, achieving\nspeeds up to 5.2 times faster than conventional decoding methods. Moreover, it\ngenerally outperforms existing state-of-the-art techniques from 5% to 20%.",
    "categories": [
      "cs.CL",
      "cs.LG"
    ],
    "published": "2025-10-30T15:04:36Z",
    "authors": [
      "Yinrong Hong",
      "Zhiquan Tan",
      "Kai Hu"
    ],
    "pdf_url": "http://arxiv.org/pdf/2510.26577v1"
  },
  {
    "id": "2510.26566v1",
    "title": "Multiclass Local Calibration With the Jensen-Shannon Distance",
    "abstract": "Developing trustworthy Machine Learning (ML) models requires their predicted\nprobabilities to be well-calibrated, meaning they should reflect true-class\nfrequencies. Among calibration notions in multiclass classification, strong\ncalibration is the most stringent, as it requires all predicted probabilities\nto be simultaneously calibrated across all classes. However, existing\napproaches to multiclass calibration lack a notion of distance among inputs,\nwhich makes them vulnerable to proximity bias: predictions in sparse regions of\nthe feature space are systematically miscalibrated. This is especially relevant\nin high-stakes settings, such as healthcare, where the sparse instances are\nexactly those most at risk of biased treatment. In this work, we address this\nmain shortcoming by introducing a local perspective on multiclass calibration.\nFirst, we formally define multiclass local calibration and establish its\nrelationship with strong calibration. Second, we theoretically analyze the\npitfalls of existing evaluation metrics when applied to multiclass local\ncalibration. Third, we propose a practical method for enhancing local\ncalibration in Neural Networks, which enforces alignment between predicted\nprobabilities and local estimates of class frequencies using the Jensen-Shannon\ndistance. Finally, we empirically validate our approach against existing\nmulticlass calibration techniques.",
    "categories": [
      "cs.LG",
      "cs.AI"
    ],
    "published": "2025-10-30T14:56:07Z",
    "authors": [
      "Cesare Barbera",
      "Lorenzo Perini",
      "Giovanni De Toni",
      "Andrea Passerini",
      "Andrea Pugnana"
    ],
    "pdf_url": "http://arxiv.org/pdf/2510.26566v1"
  },
  {
    "id": "2510.26560v1",
    "title": "On Measuring Localization of Shortcuts in Deep Networks",
    "abstract": "Shortcuts, spurious rules that perform well during training but fail to\ngeneralize, present a major challenge to the reliability of deep networks\n(Geirhos et al., 2020). However, the impact of shortcuts on feature\nrepresentations remains understudied, obstructing the design of principled\nshortcut-mitigation methods. To overcome this limitation, we investigate the\nlayer-wise localization of shortcuts in deep models. Our novel experiment\ndesign quantifies the layer-wise contribution to accuracy degradation caused by\na shortcut-inducing skew by counterfactual training on clean and skewed\ndatasets. We employ our design to study shortcuts on CIFAR-10, Waterbirds, and\nCelebA datasets across VGG, ResNet, DeiT, and ConvNeXt architectures. We find\nthat shortcut learning is not localized in specific layers but distributed\nthroughout the network. Different network parts play different roles in this\nprocess: shallow layers predominantly encode spurious features, while deeper\nlayers predominantly forget core features that are predictive on clean data. We\nalso analyze the differences in localization and describe its principal axes of\nvariation. Finally, our analysis of layer-wise shortcut-mitigation strategies\nsuggests the hardness of designing general methods, supporting dataset- and\narchitecture-specific approaches instead.",
    "categories": [
      "cs.LG",
      "stat.ML"
    ],
    "published": "2025-10-30T14:51:03Z",
    "authors": [
      "Nikita Tsoy",
      "Nikola Konstantinov"
    ],
    "pdf_url": "http://arxiv.org/pdf/2510.26560v1"
  },
  {
    "id": "2510.26557v1",
    "title": "Boosted Trees on a Diet: Compact Models for Resource-Constrained Devices",
    "abstract": "Deploying machine learning models on compute-constrained devices has become a\nkey building block of modern IoT applications. In this work, we present a\ncompression scheme for boosted decision trees, addressing the growing need for\nlightweight machine learning models. Specifically, we provide techniques for\ntraining compact boosted decision tree ensembles that exhibit a reduced memory\nfootprint by rewarding, among other things, the reuse of features and\nthresholds during training. Our experimental evaluation shows that models\nachieved the same performance with a compression ratio of 4-16x compared to\nLightGBM models using an adapted training process and an alternative memory\nlayout. Once deployed, the corresponding IoT devices can operate independently\nof constant communication or external energy supply, and, thus, autonomously,\nrequiring only minimal computing power and energy. This capability opens the\ndoor to a wide range of IoT applications, including remote monitoring, edge\nanalytics, and real-time decision making in isolated or power-limited\nenvironments.",
    "categories": [
      "cs.LG"
    ],
    "published": "2025-10-30T14:47:57Z",
    "authors": [
      "Jan Stenkamp",
      "Nina Herrmann",
      "Benjamin Karic",
      "Stefan Oehmcke",
      "Fabian Gieseke"
    ],
    "pdf_url": "http://arxiv.org/pdf/2510.26557v1"
  },
  {
    "id": "2510.26551v1",
    "title": "Adaptive Inverse Kinematics Framework for Learning Variable-Length Tool\n  Manipulation in Robotics",
    "abstract": "Conventional robots possess a limited understanding of their kinematics and\nare confined to preprogrammed tasks, hindering their ability to leverage tools\nefficiently. Driven by the essential components of tool usage - grasping the\ndesired outcome, selecting the most suitable tool, determining optimal tool\norientation, and executing precise manipulations - we introduce a pioneering\nframework. Our novel approach expands the capabilities of the robot's inverse\nkinematics solver, empowering it to acquire a sequential repertoire of actions\nusing tools of varying lengths. By integrating a simulation-learned action\ntrajectory with the tool, we showcase the practicality of transferring acquired\nskills from simulation to real-world scenarios through comprehensive\nexperimentation. Remarkably, our extended inverse kinematics solver\ndemonstrates an impressive error rate of less than 1 cm. Furthermore, our\ntrained policy achieves a mean error of 8 cm in simulation. Noteworthy, our\nmodel achieves virtually indistinguishable performance when employing two\ndistinct tools of different lengths. This research provides an indication of\npotential advances in the exploration of all four fundamental aspects of tool\nusage, enabling robots to master the intricate art of tool manipulation across\ndiverse tasks.",
    "categories": [
      "cs.RO",
      "cs.AI",
      "cs.LG"
    ],
    "published": "2025-10-30T14:44:24Z",
    "authors": [
      "Prathamesh Kothavale",
      "Sravani Boddepalli"
    ],
    "pdf_url": "http://arxiv.org/pdf/2510.26551v1"
  },
  {
    "id": "2510.26543v1",
    "title": "The Structure of Relation Decoding Linear Operators in Large Language\n  Models",
    "abstract": "This paper investigates the structure of linear operators introduced in\nHernandez et al. [2023] that decode specific relational facts in transformer\nlanguage models. We extend their single-relation findings to a collection of\nrelations and systematically chart their organization. We show that such\ncollections of relation decoders can be highly compressed by simple order-3\ntensor networks without significant loss in decoding accuracy. To explain this\nsurprising redundancy, we develop a cross-evaluation protocol, in which we\napply each linear decoder operator to the subjects of every other relation. Our\nresults reveal that these linear maps do not encode distinct relations, but\nextract recurring, coarse-grained semantic properties (e.g., country of capital\ncity and country of food are both in the country-of-X property). This\nproperty-centric structure clarifies both the operators' compressibility and\nhighlights why they generalize only to new relations that are semantically\nclose. Our findings thus interpret linear relational decoding in transformer\nlanguage models as primarily property-based, rather than relation-specific.",
    "categories": [
      "cs.CL",
      "cs.AI",
      "cs.LG"
    ],
    "published": "2025-10-30T14:36:09Z",
    "authors": [
      "Miranda Anna Christ",
      "Adri\u00e1n Csisz\u00e1rik",
      "Gergely Becs\u00f3",
      "D\u00e1niel Varga"
    ],
    "pdf_url": "http://arxiv.org/pdf/2510.26543v1"
  },
  {
    "id": "2510.26541v1",
    "title": "A Three-Stage Bayesian Transfer Learning Framework to Improve\n  Predictions in Data-Scarce Domains",
    "abstract": "The use of ML in engineering has grown steadily to support a wide array of\napplications. Among these methods, deep neural networks have been widely\nadopted due to their performance and accessibility, but they require large,\nhigh-quality datasets. Experimental data are often sparse, noisy, or\ninsufficient to build resilient data-driven models. Transfer learning, which\nleverages relevant data-abundant source domains to assist learning in\ndata-scarce target domains, has shown efficacy. Parameter transfer, where\npretrained weights are reused, is common but degrades under large domain\nshifts. Domain-adversarial neural networks (DANNs) help address this issue by\nlearning domain-invariant representations, thereby improving transfer under\ngreater domain shifts in a semi-supervised setting. However, DANNs can be\nunstable during training and lack a native means for uncertainty\nquantification. This study introduces a fully-supervised three-stage framework,\nthe staged Bayesian domain-adversarial neural network (staged B-DANN), that\ncombines parameter transfer and shared latent space adaptation. In Stage 1, a\ndeterministic feature extractor is trained on the source domain. This feature\nextractor is then adversarially refined using a DANN in Stage 2. In Stage 3, a\nBayesian neural network is built on the adapted feature extractor for\nfine-tuning on the target domain to handle conditional shifts and yield\ncalibrated uncertainty estimates. This staged B-DANN approach was first\nvalidated on a synthetic benchmark, where it was shown to significantly\noutperform standard transfer techniques. It was then applied to the task of\npredicting critical heat flux in rectangular channels, leveraging data from\ntube experiments as the source domain. The results of this study show that the\nstaged B-DANN method can improve predictive accuracy and generalization,\npotentially assisting other domains in nuclear engineering.",
    "categories": [
      "cs.LG"
    ],
    "published": "2025-10-30T14:30:53Z",
    "authors": [
      "Aidan Furlong",
      "Robert Salko",
      "Xingang Zhao",
      "Xu Wu"
    ],
    "pdf_url": "http://arxiv.org/pdf/2510.26541v1"
  },
  {
    "id": "2510.26533v1",
    "title": "Higher-Order Regularization Learning on Hypergraphs",
    "abstract": "Higher-Order Hypergraph Learning (HOHL) was recently introduced as a\nprincipled alternative to classical hypergraph regularization, enforcing\nhigher-order smoothness via powers of multiscale Laplacians induced by the\nhypergraph structure. Prior work established the well- and ill-posedness of\nHOHL through an asymptotic consistency analysis in geometric settings. We\nextend this theoretical foundation by proving the consistency of a truncated\nversion of HOHL and deriving explicit convergence rates when HOHL is used as a\nregularizer in fully supervised learning. We further demonstrate its strong\nempirical performance in active learning and in datasets lacking an underlying\ngeometric structure, highlighting HOHL's versatility and robustness across\ndiverse learning settings.",
    "categories": [
      "cs.LG",
      "math.ST",
      "stat.TH"
    ],
    "published": "2025-10-30T14:22:57Z",
    "authors": [
      "Adrien Weihs",
      "Andrea Bertozzi",
      "Matthew Thorpe"
    ],
    "pdf_url": "http://arxiv.org/pdf/2510.26533v1"
  },
  {
    "id": "2510.26527v1",
    "title": "Polybasic Speculative Decoding Through a Theoretical Perspective",
    "abstract": "Inference latency stands as a critical bottleneck in the large-scale\ndeployment of Large Language Models (LLMs). Speculative decoding methods have\nrecently shown promise in accelerating inference without compromising the\noutput distribution. However, existing work typically relies on a dualistic\ndraft-verify framework and lacks rigorous theoretical grounding. In this paper,\nwe introduce a novel \\emph{polybasic} speculative decoding framework,\nunderpinned by a comprehensive theoretical analysis. Specifically, we prove a\nfundamental theorem that characterizes the optimal inference time for\nmulti-model speculative decoding systems, shedding light on how to extend\nbeyond the dualistic approach to a more general polybasic paradigm. Through our\ntheoretical investigation of multi-model token generation, we expose and\noptimize the interplay between model capabilities, acceptance lengths, and\noverall computational cost. Our framework supports both standalone\nimplementation and integration with existing speculative techniques, leading to\naccelerated performance in practice. Experimental results across multiple model\nfamilies demonstrate that our approach yields speedup ratios ranging from\n$3.31\\times$ to $4.01\\times$ for LLaMA2-Chat 7B, up to $3.87 \\times$ for\nLLaMA3-8B, up to $4.43 \\times$ for Vicuna-7B and up to $3.85 \\times$ for\nQwen2-7B -- all while preserving the original output distribution. We release\nour theoretical proofs and implementation code to facilitate further\ninvestigation into polybasic speculative decoding.",
    "categories": [
      "cs.LG"
    ],
    "published": "2025-10-30T14:20:24Z",
    "authors": [
      "Ruilin Wang",
      "Huixia Li",
      "Yuexiao Ma",
      "Xiawu Zheng",
      "Fei Chao",
      "Xuefeng Xiao",
      "Rongrong Ji"
    ],
    "pdf_url": "http://arxiv.org/pdf/2510.26527v1"
  },
  {
    "id": "2510.26519v1",
    "title": "Think Outside the Policy: In-Context Steered Policy Optimization",
    "abstract": "Existing Reinforcement Learning from Verifiable Rewards (RLVR) methods, such\nas Group Relative Policy Optimization (GRPO), have achieved remarkable progress\nin improving the reasoning capabilities of Large Reasoning Models (LRMs).\nHowever, they exhibit limited exploration due to reliance on on-policy rollouts\nwhere confined to the current policy's distribution, resulting in narrow\ntrajectory diversity. Recent approaches attempt to expand policy coverage by\nincorporating trajectories generated from stronger expert models, yet this\nreliance increases computational cost and such advaned models are often\ninaccessible. To address these issues, we propose In-Context Steered Policy\nOptimization (ICPO), a unified framework that leverages the inherent in-context\nlearning capability of LRMs to provide expert guidance using existing datasets.\nICPO introduces Mixed-Policy GRPO with Implicit Expert Forcing, which expands\nexploration beyond the current policy distribution without requiring advanced\nLRM trajectories. To further stabilize optimization, ICPO integrates Expert\nRegion Reject Sampling to filter unreliable off-policy trajectories and\nAnnealed Expert-Bonus Reward Shaping to balance early expert guidance with\nlater autonomous improvement. Results demonstrate that ICPO consistently\nenhances reinforcement learning performance and training stability on\nmathematical reasoning benchmarks, revealing a scalable and effective RLVR\nparadigm for LRMs.",
    "categories": [
      "cs.LG"
    ],
    "published": "2025-10-30T14:14:15Z",
    "authors": [
      "Hsiu-Yuan Huang",
      "Chenming Tang",
      "Weijie Liu",
      "Saiyong Yang",
      "Yunfang Wu"
    ],
    "pdf_url": "http://arxiv.org/pdf/2510.26519v1"
  },
  {
    "id": "2510.26512v1",
    "title": "Inside CORE-KG: Evaluating Structured Prompting and Coreference\n  Resolution for Knowledge Graphs",
    "abstract": "Human smuggling networks are increasingly adaptive and difficult to analyze.\nLegal case documents offer critical insights but are often unstructured,\nlexically dense, and filled with ambiguous or shifting references, which pose\nsignificant challenges for automated knowledge graph (KG) construction. While\nrecent LLM-based approaches improve over static templates, they still generate\nnoisy, fragmented graphs with duplicate nodes due to the absence of guided\nextraction and coreference resolution. The recently proposed CORE-KG framework\naddresses these limitations by integrating a type-aware coreference module and\ndomain-guided structured prompts, significantly reducing node duplication and\nlegal noise. In this work, we present a systematic ablation study of CORE-KG to\nquantify the individual contributions of its two key components. Our results\nshow that removing coreference resolution results in a 28.32% increase in node\nduplication and a 4.32% increase in noisy nodes, while removing structured\nprompts leads to a 4.34% increase in node duplication and a 73.33% increase in\nnoisy nodes. These findings offer empirical insights for designing robust\nLLM-based pipelines for extracting structured representations from complex\nlegal texts.",
    "categories": [
      "cs.CL",
      "cs.AI",
      "cs.IR",
      "cs.LG"
    ],
    "published": "2025-10-30T14:05:55Z",
    "authors": [
      "Dipak Meher",
      "Carlotta Domeniconi"
    ],
    "pdf_url": "http://arxiv.org/pdf/2510.26512v1"
  },
  {
    "id": "2510.26510v1",
    "title": "LLMs as In-Context Meta-Learners for Model and Hyperparameter Selection",
    "abstract": "Model and hyperparameter selection are critical but challenging in machine\nlearning, typically requiring expert intuition or expensive automated search.\nWe investigate whether large language models (LLMs) can act as in-context\nmeta-learners for this task. By converting each dataset into interpretable\nmetadata, we prompt an LLM to recommend both model families and\nhyperparameters. We study two prompting strategies: (1) a zero-shot mode\nrelying solely on pretrained knowledge, and (2) a meta-informed mode augmented\nwith examples of models and their performance on past tasks. Across synthetic\nand real-world benchmarks, we show that LLMs can exploit dataset metadata to\nrecommend competitive models and hyperparameters without search, and that\nimprovements from meta-informed prompting demonstrate their capacity for\nin-context meta-learning. These results highlight a promising new role for LLMs\nas lightweight, general-purpose assistants for model selection and\nhyperparameter optimization.",
    "categories": [
      "cs.LG",
      "stat.ML"
    ],
    "published": "2025-10-30T14:04:25Z",
    "authors": [
      "Youssef Attia El Hili",
      "Albert Thomas",
      "Malik Tiomoko",
      "Abdelhakim Benechehab",
      "Corentin L\u00e9ger",
      "Corinne Ancourt",
      "Bal\u00e1zs K\u00e9gl"
    ],
    "pdf_url": "http://arxiv.org/pdf/2510.26510v1"
  },
  {
    "id": "2510.26501v1",
    "title": "Enhancing ECG Classification Robustness with Lightweight Unsupervised\n  Anomaly Detection Filters",
    "abstract": "Continuous electrocardiogram (ECG) monitoring via wearables offers\nsignificant potential for early cardiovascular disease (CVD) detection.\nHowever, deploying deep learning models for automated analysis in\nresource-constrained environments faces reliability challenges due to\ninevitable Out-of-Distribution (OOD) data. OOD inputs, such as unseen\npathologies or noisecorrupted signals, often cause erroneous, high-confidence\npredictions by standard classifiers, compromising patient safety. Existing OOD\ndetection methods either neglect computational constraints or address noise and\nunseen classes separately. This paper explores Unsupervised Anomaly Detection\n(UAD) as an independent, upstream filtering mechanism to improve robustness. We\nbenchmark six UAD approaches, including Deep SVDD, reconstruction-based models,\nMasked Anomaly Detection, normalizing flows, and diffusion models, optimized\nvia Neural Architecture Search (NAS) under strict resource constraints (at most\n512k parameters). Evaluation on PTB-XL and BUT QDB datasets assessed detection\nof OOD CVD classes and signals unsuitable for analysis due to noise. Results\nshow Deep SVDD consistently achieves the best trade-off between detection and\nefficiency. In a realistic deployment simulation, integrating the optimized\nDeep SVDD filter with a diagnostic classifier improved accuracy by up to 21\npercentage points over a classifier-only baseline. This study demonstrates that\noptimized UAD filters can safeguard automated ECG analysis, enabling safer,\nmore reliable continuous cardiovascular monitoring on wearables.",
    "categories": [
      "cs.LG"
    ],
    "published": "2025-10-30T13:54:37Z",
    "authors": [
      "Mustafa Fuad Rifet Ibrahim",
      "Maurice Meijer",
      "Alexander Schlaefer",
      "Peer Stelldinger"
    ],
    "pdf_url": "http://arxiv.org/pdf/2510.26501v1"
  },
  {
    "id": "2510.26491v1",
    "title": "Data-Efficient RLVR via Off-Policy Influence Guidance",
    "abstract": "Data selection is a critical aspect of Reinforcement Learning with Verifiable\nRewards (RLVR) for enhancing the reasoning capabilities of large language\nmodels (LLMs). Current data selection methods are largely heuristic-based,\nlacking theoretical guarantees and generalizability. This work proposes a\ntheoretically-grounded approach using influence functions to estimate the\ncontribution of each data point to the learning objective. To overcome the\nprohibitive computational cost of policy rollouts required for online influence\nestimation, we introduce an off-policy influence estimation method that\nefficiently approximates data influence using pre-collected offline\ntrajectories. Furthermore, to manage the high-dimensional gradients of LLMs, we\nemploy sparse random projection to reduce dimensionality and improve storage\nand computation efficiency. Leveraging these techniques, we develop\n\\textbf{C}urriculum \\textbf{R}L with \\textbf{O}ff-\\textbf{P}olicy\n\\text{I}nfluence guidance (\\textbf{CROPI}), a multi-stage RL framework that\niteratively selects the most influential data for the current policy.\nExperiments on models up to 7B parameters demonstrate that CROPI significantly\naccelerates training. On a 1.5B model, it achieves a 2.66x step-level\nacceleration while using only 10\\% of the data per stage compared to\nfull-dataset training. Our results highlight the substantial potential of\ninfluence-based data selection for efficient RLVR.",
    "categories": [
      "cs.LG"
    ],
    "published": "2025-10-30T13:40:52Z",
    "authors": [
      "Erle Zhu",
      "Dazhi Jiang",
      "Yuan Wang",
      "Xujun Li",
      "Jiale Cheng",
      "Yuxian Gu",
      "Yilin Niu",
      "Aohan Zeng",
      "Jie Tang",
      "Minlie Huang",
      "Hongning Wang"
    ],
    "pdf_url": "http://arxiv.org/pdf/2510.26491v1"
  },
  {
    "id": "2510.26487v1",
    "title": "Quantum Gated Recurrent GAN with Gaussian Uncertainty for Network\n  Anomaly Detection",
    "abstract": "Anomaly detection in time-series data is a critical challenge with\nsignificant implications for network security. Recent quantum machine learning\napproaches, such as quantum kernel methods and variational quantum circuits,\nhave shown promise in capturing complex data distributions for anomaly\ndetection but remain constrained by limited qubit counts. We introduce in this\nwork a novel Quantum Gated Recurrent Unit (QGRU)-based Generative Adversarial\nNetwork (GAN) employing Successive Data Injection (SuDaI) and a multi-metric\ngating strategy for robust network anomaly detection. Our model uniquely\nutilizes a quantum-enhanced generator that outputs parameters (mean and\nlog-variance) of a Gaussian distribution via reparameterization, combined with\na Wasserstein critic to stabilize adversarial training. Anomalies are\nidentified through a novel gating mechanism that initially flags potential\nanomalies based on Gaussian uncertainty estimates and subsequently verifies\nthem using a composite of critic scores and reconstruction errors. Evaluated on\nbenchmark datasets, our method achieves a high time-series aware F1 score\n(TaF1) of 89.43% demonstrating superior capability in detecting anomalies\naccurately and promptly as compared to existing classical and quantum models.\nFurthermore, the trained QGRU-WGAN was deployed on real IBM Quantum hardware,\nwhere it retained high anomaly detection performance, confirming its robustness\nand practical feasibility on current noisy intermediate-scale quantum (NISQ)\ndevices.",
    "categories": [
      "cs.LG",
      "cs.NI"
    ],
    "published": "2025-10-30T13:39:44Z",
    "authors": [
      "Wajdi Hammami",
      "Soumaya Cherkaoui",
      "Jean-Frederic Laprade",
      "Ola Ahmad",
      "Shengrui Wang"
    ],
    "pdf_url": "http://arxiv.org/pdf/2510.26487v1"
  },
  {
    "id": "2510.26486v1",
    "title": "LINK-KG: LLM-Driven Coreference-Resolved Knowledge Graphs for Human\n  Smuggling Networks",
    "abstract": "Human smuggling networks are complex and constantly evolving, making them\ndifficult to analyze comprehensively. Legal case documents offer rich factual\nand procedural insights into these networks but are often long, unstructured,\nand filled with ambiguous or shifting references, posing significant challenges\nfor automated knowledge graph (KG) construction. Existing methods either\noverlook coreference resolution or fail to scale beyond short text spans,\nleading to fragmented graphs and inconsistent entity linking. We propose\nLINK-KG, a modular framework that integrates a three-stage, LLM-guided\ncoreference resolution pipeline with downstream KG extraction. At the core of\nour approach is a type-specific Prompt Cache, which consistently tracks and\nresolves references across document chunks, enabling clean and disambiguated\nnarratives for structured knowledge graph construction from both short and long\nlegal texts. LINK-KG reduces average node duplication by 45.21% and noisy nodes\nby 32.22% compared to baseline methods, resulting in cleaner and more coherent\ngraph structures. These improvements establish LINK-KG as a strong foundation\nfor analyzing complex criminal networks.",
    "categories": [
      "cs.AI",
      "cs.IR",
      "cs.LG"
    ],
    "published": "2025-10-30T13:39:08Z",
    "authors": [
      "Dipak Meher",
      "Carlotta Domeniconi",
      "Guadalupe Correa-Cabrera"
    ],
    "pdf_url": "http://arxiv.org/pdf/2510.26486v1"
  },
  {
    "id": "2510.26475v1",
    "title": "ReSpec: Towards Optimizing Speculative Decoding in Reinforcement\n  Learning Systems",
    "abstract": "Adapting large language models (LLMs) via reinforcement learning (RL) is\noften bottlenecked by the generation stage, which can consume over 75\\% of the\ntraining time. Speculative decoding (SD) accelerates autoregressive generation\nin serving systems, but its behavior under RL training remains largely\nunexplored. We identify three critical gaps that hinder the naive integration\nof SD into RL systems: diminishing speedups at large batch sizes, drafter\nstaleness under continual actor updates, and drafter-induced policy\ndegradation.\n  To address these gaps, we present ReSpec, a system that adapts SD to RL\nthrough three complementary mechanisms: dynamically tuning SD configurations,\nevolving the drafter via knowledge distillation, and weighting updates by\nrollout rewards. On Qwen models (3B--14B), ReSpec achieves up to 4.5x speedup\nwhile preserving reward convergence and training stability, providing a\npractical solution for efficient RL-based LLM adaptation.",
    "categories": [
      "cs.LG",
      "cs.DC"
    ],
    "published": "2025-10-30T13:27:42Z",
    "authors": [
      "Qiaoling Chen",
      "Zijun Liu",
      "Peng Sun",
      "Shenggui Li",
      "Guoteng Wang",
      "Ziming Liu",
      "Yonggang Wen",
      "Siyuan Feng",
      "Tianwei Zhang"
    ],
    "pdf_url": "http://arxiv.org/pdf/2510.26475v1"
  },
  {
    "id": "2510.26474v1",
    "title": "Counteracting Matthew Effect in Self-Improvement of LVLMs through\n  Head-Tail Re-balancing",
    "abstract": "Self-improvement has emerged as a mainstream paradigm for advancing the\nreasoning capabilities of large vision-language models (LVLMs), where models\nexplore and learn from successful trajectories iteratively. However, we\nidentify a critical issue during this process: the model excels at generating\nhigh-quality trajectories for simple queries (i.e., head data) but struggles\nwith more complex ones (i.e., tail data). This leads to an imbalanced\noptimization that drives the model to prioritize simple reasoning skills, while\nhindering its ability to tackle more complex reasoning tasks. Over iterations,\nthis imbalance becomes increasingly pronounced--a dynamic we term the \"Matthew\neffect\"--which ultimately hinders further model improvement and leads to\nperformance bottlenecks. To counteract this challenge, we introduce four\nefficient strategies from two perspectives: distribution-reshaping and\ntrajectory-resampling, to achieve head-tail re-balancing during the\nexploration-and-learning self-improvement process. Extensive experiments on\nQwen2-VL-7B-Instruct and InternVL2.5-4B models across visual reasoning tasks\ndemonstrate that our methods consistently improve visual reasoning\ncapabilities, outperforming vanilla self-improvement by 3.86 points on average.",
    "categories": [
      "cs.CV",
      "cs.AI",
      "cs.CL",
      "cs.LG"
    ],
    "published": "2025-10-30T13:26:58Z",
    "authors": [
      "Xin Guo",
      "Zhiheng Xi",
      "Yiwen Ding",
      "Yitao Zhai",
      "Xiaowei Shi",
      "Xunliang Cai",
      "Tao Gui",
      "Qi Zhang",
      "Xuanjing Huang"
    ],
    "pdf_url": "http://arxiv.org/pdf/2510.26474v1"
  },
  {
    "id": "2510.26466v1",
    "title": "Representation-Level Counterfactual Calibration for Debiased Zero-Shot\n  Recognition",
    "abstract": "Object-context shortcuts remain a persistent challenge in vision-language\nmodels, undermining zero-shot reliability when test-time scenes differ from\nfamiliar training co-occurrences. We recast this issue as a causal inference\nproblem and ask: Would the prediction remain if the object appeared in a\ndifferent environment? To answer this at inference time, we estimate object and\nbackground expectations within CLIP's representation space, and synthesize\ncounterfactual embeddings by recombining object features with diverse\nalternative contexts sampled from external datasets, batch neighbors, or\ntext-derived descriptions. By estimating the Total Direct Effect and simulating\nintervention, we further subtract background-only activation, preserving\nbeneficial object-context interactions while mitigating hallucinated scores.\nWithout retraining or prompt design, our method substantially improves both\nworst-group and average accuracy on context-sensitive benchmarks, establishing\na new zero-shot state of the art. Beyond performance, our framework provides a\nlightweight representation-level counterfactual approach, offering a practical\ncausal avenue for debiased and reliable multimodal reasoning.",
    "categories": [
      "cs.CV",
      "cs.LG"
    ],
    "published": "2025-10-30T13:11:23Z",
    "authors": [
      "Pei Peng",
      "MingKun Xie",
      "Hang Hao",
      "Tong Jin",
      "ShengJun Huang"
    ],
    "pdf_url": "http://arxiv.org/pdf/2510.26466v1"
  },
  {
    "id": "2510.26461v1",
    "title": "Vectorized Context-Aware Embeddings for GAT-Based Collaborative\n  Filtering",
    "abstract": "Recommender systems often struggle with data sparsity and cold-start\nscenarios, limiting their ability to provide accurate suggestions for new or\ninfrequent users. This paper presents a Graph Attention Network (GAT) based\nCollaborative Filtering (CF) framework enhanced with Large Language Model (LLM)\ndriven context aware embeddings. Specifically, we generate concise textual user\nprofiles and unify item metadata (titles, genres, overviews) into rich textual\nembeddings, injecting these as initial node features in a bipartite user item\ngraph. To further optimize ranking performance, we introduce a hybrid loss\nfunction that combines Bayesian Personalized Ranking (BPR) with a cosine\nsimilarity term and robust negative sampling, ensuring explicit negative\nfeedback is distinguished from unobserved data. Experiments on the MovieLens\n100k and 1M datasets show consistent improvements over state-of-the-art\nbaselines in Precision, NDCG, and MAP while demonstrating robustness for users\nwith limited interaction history. Ablation studies confirm the critical role of\nLLM-augmented embeddings and the cosine similarity term in capturing nuanced\nsemantic relationships. Our approach effectively mitigates sparsity and\ncold-start limitations by integrating LLM-derived contextual understanding into\ngraph-based architectures. Future directions include balancing recommendation\naccuracy with coverage and diversity, and introducing fairness-aware\nconstraints and interpretability features to enhance system performance\nfurther.",
    "categories": [
      "cs.IR",
      "cs.LG"
    ],
    "published": "2025-10-30T13:07:39Z",
    "authors": [
      "Danial Ebrat",
      "Sepideh Ahmadian",
      "Luis Rueda"
    ],
    "pdf_url": "http://arxiv.org/pdf/2510.26461v1"
  },
  {
    "id": "2510.26451v1",
    "title": "Robust Graph Condensation via Classification Complexity Mitigation",
    "abstract": "Graph condensation (GC) has gained significant attention for its ability to\nsynthesize smaller yet informative graphs. However, existing studies often\noverlook the robustness of GC in scenarios where the original graph is\ncorrupted. In such cases, we observe that the performance of GC deteriorates\nsignificantly, while existing robust graph learning technologies offer only\nlimited effectiveness. Through both empirical investigation and theoretical\nanalysis, we reveal that GC is inherently an intrinsic-dimension-reducing\nprocess, synthesizing a condensed graph with lower classification complexity.\nAlthough this property is critical for effective GC performance, it remains\nhighly vulnerable to adversarial perturbations. To tackle this vulnerability\nand improve GC robustness, we adopt the geometry perspective of graph data\nmanifold and propose a novel Manifold-constrained Robust Graph Condensation\nframework named MRGC. Specifically, we introduce three graph data manifold\nlearning modules that guide the condensed graph to lie within a smooth,\nlow-dimensional manifold with minimal class ambiguity, thereby preserving the\nclassification complexity reduction capability of GC and ensuring robust\nperformance under universal adversarial attacks. Extensive experiments\ndemonstrate the robustness of \\ModelName\\ across diverse attack scenarios.",
    "categories": [
      "cs.LG",
      "cs.AI"
    ],
    "published": "2025-10-30T12:55:21Z",
    "authors": [
      "Jiayi Luo",
      "Qingyun Sun",
      "Beining Yang",
      "Haonan Yuan",
      "Xingcheng Fu",
      "Yanbiao Ma",
      "Jianxin Li",
      "Philip S. Yu"
    ],
    "pdf_url": "http://arxiv.org/pdf/2510.26451v1"
  },
  {
    "id": "2510.26444v1",
    "title": "Personalized Treatment Outcome Prediction from Scarce Data via\n  Dual-Channel Knowledge Distillation and Adaptive Fusion",
    "abstract": "Personalized treatment outcome prediction based on trial data for\nsmall-sample and rare patient groups is critical in precision medicine.\nHowever, the costly trial data limit the prediction performance. To address\nthis issue, we propose a cross-fidelity knowledge distillation and adaptive\nfusion network (CFKD-AFN), which leverages abundant but low-fidelity simulation\ndata to enhance predictions on scarce but high-fidelity trial data. CFKD-AFN\nincorporates a dual-channel knowledge distillation module to extract\ncomplementary knowledge from the low-fidelity model, along with an\nattention-guided fusion module to dynamically integrate multi-source\ninformation. Experiments on treatment outcome prediction for the chronic\nobstructive pulmonary disease demonstrates significant improvements of CFKD-AFN\nover state-of-the-art methods in prediction accuracy, ranging from 6.67\\% to\n74.55\\%, and strong robustness to varying high-fidelity dataset sizes.\nFurthermore, we extend CFKD-AFN to an interpretable variant, enabling the\nexploration of latent medical semantics to support clinical decision-making.",
    "categories": [
      "cs.LG",
      "cs.AI"
    ],
    "published": "2025-10-30T12:50:12Z",
    "authors": [
      "Wenjie Chen",
      "Li Zhuang",
      "Ziying Luo",
      "Yu Liu",
      "Jiahao Wu",
      "Shengcai Liu"
    ],
    "pdf_url": "http://arxiv.org/pdf/2510.26444v1"
  },
  {
    "id": "2510.26433v1",
    "title": "Co-Evolving Latent Action World Models",
    "abstract": "Adapting pre-trained video generation models into controllable world models\nvia latent actions is a promising step towards creating generalist world\nmodels. The dominant paradigm adopts a two-stage approach that trains latent\naction model (LAM) and the world model separately, resulting in redundant\ntraining and limiting their potential for co-adaptation. A conceptually simple\nand appealing idea is to directly replace the forward dynamic model in LAM with\na powerful world model and training them jointly, but it is non-trivial and\nprone to representational collapse. In this work, we propose CoLA-World, which\nfor the first time successfully realizes this synergistic paradigm, resolving\nthe core challenge in joint learning through a critical warm-up phase that\neffectively aligns the representations of the from-scratch LAM with the\npre-trained world model. This unlocks a co-evolution cycle: the world model\nacts as a knowledgeable tutor, providing gradients to shape a high-quality LAM,\nwhile the LAM offers a more precise and adaptable control interface to the\nworld model. Empirically, CoLA-World matches or outperforms prior two-stage\nmethods in both video simulation quality and downstream visual planning,\nestablishing a robust and efficient new paradigm for the field.",
    "categories": [
      "cs.LG"
    ],
    "published": "2025-10-30T12:28:40Z",
    "authors": [
      "Yucen Wang",
      "Fengming Zhang",
      "De-Chuan Zhan",
      "Li Zhao",
      "Kaixin Wang",
      "Jiang Bian"
    ],
    "pdf_url": "http://arxiv.org/pdf/2510.26433v1"
  },
  {
    "id": "2510.26402v1",
    "title": "Autograder+: A Multi-Faceted AI Framework for Rich Pedagogical Feedback\n  in Programming Education",
    "abstract": "The rapid growth of programming education has outpaced traditional assessment\ntools, leaving faculty with limited means to provide meaningful, scalable\nfeedback. Conventional autograders, while efficient, act as black-box systems\nthat simply return pass/fail results, offering little insight into student\nthinking or learning needs.\n  Autograder+ is designed to shift autograding from a purely summative process\nto a formative learning experience. It introduces two key capabilities:\nautomated feedback generation using a fine-tuned Large Language Model, and\nvisualization of student code submissions to uncover learning patterns. The\nmodel is fine-tuned on curated student code and expert feedback to ensure\npedagogically aligned, context-aware guidance.\n  In evaluation across 600 student submissions from multiple programming tasks,\nthe system produced feedback with strong semantic alignment to instructor\ncomments. For visualization, contrastively learned code embeddings trained on\n1,000 annotated submissions enable grouping solutions into meaningful clusters\nbased on functionality and approach. The system also supports prompt-pooling,\nallowing instructors to guide feedback style through selected prompt templates.\n  By integrating AI-driven feedback, semantic clustering, and interactive\nvisualization, Autograder+ reduces instructor workload while supporting\ntargeted instruction and promoting stronger learning outcomes.",
    "categories": [
      "cs.AI",
      "cs.LG"
    ],
    "published": "2025-10-30T11:41:50Z",
    "authors": [
      "Vikrant Sahu",
      "Gagan Raj Gupta",
      "Raghav Borikar",
      "Nitin Mane"
    ],
    "pdf_url": "http://arxiv.org/pdf/2510.26402v1"
  },
  {
    "id": "2510.26401v1",
    "title": "Multi-Output Robust and Conjugate Gaussian Processes",
    "abstract": "Multi-output Gaussian process (MOGP) regression allows modelling dependencies\namong multiple correlated response variables. Similarly to standard Gaussian\nprocesses, MOGPs are sensitive to model misspecification and outliers, which\ncan distort predictions within individual outputs. This situation can be\nfurther exacerbated by multiple anomalous response variables whose errors\npropagate due to correlations between outputs. To handle this situation, we\nextend and generalise the robust and conjugate Gaussian process (RCGP)\nframework introduced by Altamirano et al. (2024). This results in the\nmulti-output RCGP (MO-RCGP): a provably robust MOGP that is conjugate, and\njointly captures correlations across outputs. We thoroughly evaluate our\napproach through applications in finance and cancer research.",
    "categories": [
      "stat.ML",
      "cs.LG"
    ],
    "published": "2025-10-30T11:41:19Z",
    "authors": [
      "Joshua Rooijakkers",
      "Leiv R\u00f8nneberg",
      "Fran\u00e7ois-Xavier Briol",
      "Jeremias Knoblauch",
      "Matias Altamirano"
    ],
    "pdf_url": "http://arxiv.org/pdf/2510.26401v1"
  },
  {
    "id": "2510.26392v1",
    "title": "Multi-Task Learning Based on Support Vector Machines and Twin Support\n  Vector Machines: A Comprehensive Survey",
    "abstract": "Multi-task learning (MTL) enables simultaneous training across related tasks,\nleveraging shared information to improve generalization, efficiency, and\nrobustness, especially in data-scarce or high-dimensional scenarios. While deep\nlearning dominates recent MTL research, Support Vector Machines (SVMs) and Twin\nSVMs (TWSVMs) remain relevant due to their interpretability, theoretical rigor,\nand effectiveness with small datasets.\n  This chapter surveys MTL approaches based on SVM and TWSVM, highlighting\nshared representations, task regularization, and structural coupling\nstrategies. Special attention is given to emerging TWSVM extensions for\nmulti-task settings, which show promise but remain underexplored. We compare\nthese models in terms of theoretical properties, optimization strategies, and\nempirical performance, and discuss applications in fields such as computer\nvision, natural language processing, and bioinformatics.\n  Finally, we identify research gaps and outline future directions for building\nscalable, interpretable, and reliable margin-based MTL frameworks. This work\nprovides a comprehensive resource for researchers and practitioners interested\nin SVM- and TWSVM-based multi-task learning.",
    "categories": [
      "cs.LG",
      "math.OC"
    ],
    "published": "2025-10-30T11:35:05Z",
    "authors": [
      "Fatemeh Bazikar",
      "Hossein Moosaei",
      "Atefeh Hemmati",
      "Panos M. Pardalos"
    ],
    "pdf_url": "http://arxiv.org/pdf/2510.26392v1"
  },
  {
    "id": "2510.26389v1",
    "title": "Adaptive Context Length Optimization with Low-Frequency Truncation for\n  Multi-Agent Reinforcement Learning",
    "abstract": "Recently, deep multi-agent reinforcement learning (MARL) has demonstrated\npromising performance for solving challenging tasks, such as long-term\ndependencies and non-Markovian environments. Its success is partly attributed\nto conditioning policies on large fixed context length. However, such large\nfixed context lengths may lead to limited exploration efficiency and redundant\ninformation. In this paper, we propose a novel MARL framework to obtain\nadaptive and effective contextual information. Specifically, we design a\ncentral agent that dynamically optimizes context length via temporal gradient\nanalysis, enhancing exploration to facilitate convergence to global optima in\nMARL. Furthermore, to enhance the adaptive optimization capability of the\ncontext length, we present an efficient input representation for the central\nagent, which effectively filters redundant information. By leveraging a\nFourier-based low-frequency truncation method, we extract global temporal\ntrends across decentralized agents, providing an effective and efficient\nrepresentation of the MARL environment. Extensive experiments demonstrate that\nthe proposed method achieves state-of-the-art (SOTA) performance on long-term\ndependency tasks, including PettingZoo, MiniGrid, Google Research Football\n(GRF), and StarCraft Multi-Agent Challenge v2 (SMACv2).",
    "categories": [
      "cs.LG",
      "cs.MA"
    ],
    "published": "2025-10-30T11:32:45Z",
    "authors": [
      "Wenchang Duan",
      "Yaoliang Yu",
      "Jiwan He",
      "Yi Shi"
    ],
    "pdf_url": "http://arxiv.org/pdf/2510.26389v1"
  },
  {
    "id": "2510.26384v1",
    "title": "Scales++: Compute Efficient Evaluation Subset Selection with Cognitive\n  Scales Embeddings",
    "abstract": "The prohibitive cost of evaluating large language models (LLMs) on\ncomprehensive benchmarks necessitates the creation of small yet representative\ndata subsets (i.e., tiny benchmarks) that enable efficient assessment while\nretaining predictive fidelity. Current methods for this task operate under a\nmodel-centric paradigm, selecting benchmarking items based on the collective\nperformance of existing models. Such approaches are limited by large upfront\ncosts, an inability to immediately handle new benchmarks (`cold-start'), and\nthe fragile assumption that future models will share the failure patterns of\ntheir predecessors. In this work, we challenge this paradigm and propose a\nitem-centric approach to benchmark subset selection, arguing that selection\nshould be based on the intrinsic properties of the task items themselves,\nrather than on model-specific failure patterns. We instantiate this\nitem-centric efficient benchmarking approach via a novel method, Scales++,\nwhere data selection is based on the cognitive demands of the benchmark\nsamples. Empirically, we show Scales++ reduces the upfront selection cost by\nover 18x while achieving competitive predictive fidelity. On the Open LLM\nLeaderboard, using just a 0.5\\% data subset, we predict full benchmark scores\nwith a 2.9% mean absolute error. We demonstrate that this item-centric approach\nenables more efficient model evaluation without significant fidelity\ndegradation, while also providing better cold-start performance and more\ninterpretable benchmarking.",
    "categories": [
      "cs.AI",
      "cs.LG"
    ],
    "published": "2025-10-30T11:28:58Z",
    "authors": [
      "Andrew M. Bean",
      "Nabeel Seedat",
      "Shengzhuang Chen",
      "Jonathan Richard Schwarz"
    ],
    "pdf_url": "http://arxiv.org/pdf/2510.26384v1"
  },
  {
    "id": "2510.26376v1",
    "title": "Efficient Generative AI Boosts Probabilistic Forecasting of Sudden\n  Stratospheric Warmings",
    "abstract": "Sudden Stratospheric Warmings (SSWs) are key sources of subseasonal\npredictability and major drivers of extreme winter weather. Yet, their accurate\nand efficient forecast remains a persistent challenge for numerical weather\nprediction (NWP) systems due to limitations in physical representation,\ninitialization, and the immense computational demands of ensemble forecasts.\nWhile data-driven forecasting is rapidly evolving, its application to the\ncomplex, three-dimensional dynamics of SSWs, particularly for probabilistic\nforecast, remains underexplored. Here, we bridge this gap by developing a Flow\nMatching-based generative AI model (FM-Cast) for efficient and skillful\nprobabilistic forecasting of the spatiotemporal evolution of stratospheric\ncirculation. Evaluated across 18 major SSW events (1998-2024), FM-Cast\nskillfully forecasts the onset, intensity, and morphology of 10 events up to 20\ndays in advance, achieving ensemble accuracies above 50%. Its performance is\ncomparable to or exceeds leading NWP systems while requiring only two minutes\nfor a 50-member, 30-day forecast on a consumer GPU. Furthermore, leveraging\nFM-Cast as a scientific tool, we demonstrate through idealized experiments that\nSSW predictability is fundamentally linked to its underlying physical drivers,\ndistinguishing between events forced from the troposphere and those driven by\ninternal stratospheric dynamics. Our work thus establishes a computationally\nefficient paradigm for probabilistic forecasting stratospheric anomalies and\nshowcases generative AI's potential to deepen the physical understanding of\natmosphere-climate dynamics.",
    "categories": [
      "cs.LG"
    ],
    "published": "2025-10-30T11:16:22Z",
    "authors": [
      "Ningning Tao",
      "Fei Xie",
      "Baoxiang Pan",
      "Hongyu Wang",
      "Han Huang",
      "Zhongpu Qiu",
      "Ke Gui",
      "Jiali Luo",
      "Xiaosong Chen"
    ],
    "pdf_url": "http://arxiv.org/pdf/2510.26376v1"
  },
  {
    "id": "2510.26369v1",
    "title": "CorVS: Person Identification via Video Trajectory-Sensor Correspondence\n  in a Real-World Warehouse",
    "abstract": "Worker location data is key to higher productivity in industrial sites.\nCameras are a promising tool for localization in logistics warehouses since\nthey also offer valuable environmental contexts such as package status.\nHowever, identifying individuals with only visual data is often impractical.\nAccordingly, several prior studies identified people in videos by comparing\ntheir trajectories and wearable sensor measurements. While this approach has\nadvantages such as independence from appearance, the existing methods may break\ndown under real-world conditions. To overcome this challenge, we propose CorVS,\na novel data-driven person identification method based on correspondence\nbetween visual tracking trajectories and sensor measurements. Firstly, our deep\nlearning model predicts correspondence probabilities and reliabilities for\nevery pair of a trajectory and sensor measurements. Secondly, our algorithm\nmatches the trajectories and sensor measurements over time using the predicted\nprobabilities and reliabilities. We developed a dataset with actual warehouse\noperations and demonstrated the method's effectiveness for real-world\napplications.",
    "categories": [
      "cs.LG",
      "cs.CV",
      "cs.RO"
    ],
    "published": "2025-10-30T11:14:17Z",
    "authors": [
      "Kazuma Kano",
      "Yuki Mori",
      "Shin Katayama",
      "Kenta Urano",
      "Takuro Yonezawa",
      "Nobuo Kawaguchi"
    ],
    "pdf_url": "http://arxiv.org/pdf/2510.26369v1"
  },
  {
    "id": "2510.26353v1",
    "title": "Towards Explainable and Reliable AI in Finance",
    "abstract": "Financial forecasting increasingly uses large neural network models, but\ntheir opacity raises challenges for trust and regulatory compliance. We present\nseveral approaches to explainable and reliable AI in finance. \\emph{First}, we\ndescribe how Time-LLM, a time series foundation model, uses a prompt to avoid a\nwrong directional forecast. \\emph{Second}, we show that combining foundation\nmodels for time series forecasting with a reliability estimator can filter our\nunreliable predictions. \\emph{Third}, we argue for symbolic reasoning encoding\ndomain rules for transparent justification. These approaches shift emphasize\nexecuting only forecasts that are both reliable and explainable. Experiments on\nequity and cryptocurrency data show that the architecture reduces false\npositives and supports selective execution. By integrating predictive\nperformance with reliability estimation and rule-based reasoning, our framework\nadvances transparent and auditable financial AI systems.",
    "categories": [
      "cs.LG",
      "I.2; I.5"
    ],
    "published": "2025-10-30T11:05:15Z",
    "authors": [
      "Albi Isufaj",
      "Pablo Moll\u00e1",
      "Helmut Prendinger"
    ],
    "pdf_url": "http://arxiv.org/pdf/2510.26353v1"
  },
  {
    "id": "2510.26350v1",
    "title": "UnifiedFL: A Dynamic Unified Learning Framework for Equitable Federation",
    "abstract": "Federated learning (FL) has emerged as a key paradigm for collaborative model\ntraining across multiple clients without sharing raw data, enabling\nprivacy-preserving applications in areas such as radiology and pathology.\nHowever, works on collaborative training across clients with fundamentally\ndifferent neural architectures and non-identically distributed datasets remain\nscarce. Existing FL frameworks face several limitations. Despite claiming to\nsupport architectural heterogeneity, most recent FL methods only tolerate\nvariants within a single model family (e.g., shallower, deeper, or wider CNNs),\nstill presuming a shared global architecture and failing to accommodate\nfederations where clients deploy fundamentally different network types (e.g.,\nCNNs, GNNs, MLPs). Moreover, existing approaches often address only statistical\nheterogeneity while overlooking the domain-fracture problem, where each\nclient's data distribution differs markedly from that faced at testing time,\nundermining model generalizability. When clients use different architectures,\nhave non-identically distributed data, and encounter distinct test domains,\ncurrent methods perform poorly. To address these challenges, we propose\nUnifiedFL, a dynamic federated learning framework that represents heterogeneous\nlocal networks as nodes and edges in a directed model graph optimized by a\nshared graph neural network (GNN). UnifiedFL introduces (i) a common GNN to\nparameterize all architectures, (ii) distance-driven clustering via Euclidean\ndistances between clients' parameters, and (iii) a two-tier aggregation policy\nbalancing convergence and diversity. Experiments on MedMNIST classification and\nhippocampus segmentation benchmarks demonstrate UnifiedFL's superior\nperformance. Code and data: https://github.com/basiralab/UnifiedFL",
    "categories": [
      "cs.LG"
    ],
    "published": "2025-10-30T11:01:57Z",
    "authors": [
      "Furkan Pala",
      "Islem Rekik"
    ],
    "pdf_url": "http://arxiv.org/pdf/2510.26350v1"
  },
  {
    "id": "2510.26347v1",
    "title": "Reinforcement Learning for Pollution Detection in a Randomized, Sparse\n  and Nonstationary Environment with an Autonomous Underwater Vehicle",
    "abstract": "Reinforcement learning (RL) algorithms are designed to optimize\nproblem-solving by learning actions that maximize rewards, a task that becomes\nparticularly challenging in random and nonstationary environments. Even\nadvanced RL algorithms are often limited in their ability to solve problems in\nthese conditions. In applications such as searching for underwater pollution\nclouds with autonomous underwater vehicles (AUVs), RL algorithms must navigate\nreward-sparse environments, where actions frequently result in a zero reward.\nThis paper aims to address these challenges by revisiting and modifying\nclassical RL approaches to efficiently operate in sparse, randomized, and\nnonstationary environments. We systematically study a large number of\nmodifications, including hierarchical algorithm changes, multigoal learning,\nand the integration of a location memory as an external output filter to\nprevent state revisits. Our results demonstrate that a modified Monte\nCarlo-based approach significantly outperforms traditional Q-learning and two\nexhaustive search patterns, illustrating its potential in adapting RL to\ncomplex environments. These findings suggest that reinforcement learning\napproaches can be effectively adapted for use in random, nonstationary, and\nreward-sparse environments.",
    "categories": [
      "cs.LG",
      "cs.AI"
    ],
    "published": "2025-10-30T10:55:05Z",
    "authors": [
      "Sebastian Zieglmeier",
      "Niklas Erdmann",
      "Narada D. Warakagoda"
    ],
    "pdf_url": "http://arxiv.org/pdf/2510.26347v1"
  },
  {
    "id": "2510.26345v1",
    "title": "MisSynth: Improving MISSCI Logical Fallacies Classification with\n  Synthetic Data",
    "abstract": "Health-related misinformation is very prevalent and potentially harmful. It\nis difficult to identify, especially when claims distort or misinterpret\nscientific findings. We investigate the impact of synthetic data generation and\nlightweight fine-tuning techniques on the ability of large language models\n(LLMs) to recognize fallacious arguments using the MISSCI dataset and\nframework. In this work, we propose MisSynth, a pipeline that applies\nretrieval-augmented generation (RAG) to produce synthetic fallacy samples,\nwhich are then used to fine-tune an LLM model. Our results show substantial\naccuracy gains with fine-tuned models compared to vanilla baselines. For\ninstance, the LLaMA 3.1 8B fine-tuned model achieved an over 35% F1-score\nabsolute improvement on the MISSCI test split over its vanilla baseline. We\ndemonstrate that introducing synthetic fallacy data to augment limited\nannotated resources can significantly enhance zero-shot LLM classification\nperformance on real-world scientific misinformation tasks, even with limited\ncomputational resources. The code and synthetic dataset are available on\nhttps://github.com/mxpoliakov/MisSynth.",
    "categories": [
      "cs.CL",
      "cs.AI",
      "cs.LG"
    ],
    "published": "2025-10-30T10:52:43Z",
    "authors": [
      "Mykhailo Poliakov",
      "Nadiya Shvai"
    ],
    "pdf_url": "http://arxiv.org/pdf/2510.26345v1"
  },
  {
    "id": "2510.26342v1",
    "title": "Linear Causal Discovery with Interventional Constraints",
    "abstract": "Incorporating causal knowledge and mechanisms is essential for refining\ncausal models and improving downstream tasks such as designing new treatments.\nIn this paper, we introduce a novel concept in causal discovery, termed\ninterventional constraints, which differs fundamentally from interventional\ndata. While interventional data require direct perturbations of variables,\ninterventional constraints encode high-level causal knowledge in the form of\ninequality constraints on causal effects. For instance, in the Sachs dataset\n(Sachs et al.\\ 2005), Akt has been shown to be activated by PIP3, meaning PIP3\nexerts a positive causal effect on Akt. Existing causal discovery methods allow\nenforcing structural constraints (for example, requiring a causal path from\nPIP3 to Akt), but they may still produce incorrect causal conclusions such as\nlearning that \"PIP3 inhibits Akt\". Interventional constraints bridge this gap\nby explicitly constraining the total causal effect between variable pairs,\nensuring learned models respect known causal influences. To formalize\ninterventional constraints, we propose a metric to quantify total causal\neffects for linear causal models and formulate the problem as a constrained\noptimization task, solved using a two-stage constrained optimization method. We\nevaluate our approach on real-world datasets and demonstrate that integrating\ninterventional constraints not only improves model accuracy and ensures\nconsistency with established findings, making models more explainable, but also\nfacilitates the discovery of new causal relationships that would otherwise be\ncostly to identify.",
    "categories": [
      "cs.LG",
      "cs.AI"
    ],
    "published": "2025-10-30T10:49:25Z",
    "authors": [
      "Zhigao Guo",
      "Feng Dong"
    ],
    "pdf_url": "http://arxiv.org/pdf/2510.26342v1"
  },
  {
    "id": "2510.26340v1",
    "title": "SABER: Symbolic Regression-based Angle of Arrival and Beam Pattern\n  Estimator",
    "abstract": "Accurate Angle-of-arrival (AoA) estimation is essential for next-generation\nwireless communication systems to enable reliable beamforming, high-precision\nlocalization, and integrated sensing. Unfortunately, classical high-resolution\ntechniques require multi-element arrays and extensive snapshot collection,\nwhile generic Machine Learning (ML) approaches often yield black-box models\nthat lack physical interpretability. To address these limitations, we propose a\nSymbolic Regression (SR)-based ML framework. Namely, Symbolic Regression-based\nAngle of Arrival and Beam Pattern Estimator (SABER), a constrained\nsymbolic-regression framework that automatically discovers closed-form beam\npattern and AoA models from path loss measurements with interpretability. SABER\nachieves high accuracy while bridging the gap between opaque ML methods and\ninterpretable physics-driven estimators. First, we validate our approach in a\ncontrolled free-space anechoic chamber, showing that both direct inversion of\nthe known $\\cos^n$ beam and a low-order polynomial surrogate achieve sub-0.5\ndegree Mean Absolute Error (MAE). A purely unconstrained SR method can further\nreduce the error of the predicted angles, but produces complex formulas that\nlack physical insight. Then, we implement the same SR-learned inversions in a\nreal-world, Reconfigurable Intelligent Surface (RIS)-aided indoor testbed.\nSABER and unconstrained SR models accurately recover the true AoA with\nnear-zero error. Finally, we benchmark SABER against the Cram\\'er-Rao Lower\nBounds (CRLBs). Our results demonstrate that SABER is an interpretable and\naccurate alternative to state-of-the-art and black-box ML-based methods for AoA\nestimation.",
    "categories": [
      "eess.SP",
      "cs.LG"
    ],
    "published": "2025-10-30T10:48:18Z",
    "authors": [
      "Shih-Kai Chou",
      "Mengran Zhao",
      "Cheng-Nan Hu",
      "Kuang-Chung Chou",
      "Carolina Fortuna",
      "Jernej Hribar"
    ],
    "pdf_url": "http://arxiv.org/pdf/2510.26340v1"
  },
  {
    "id": "2510.26328v1",
    "title": "Agent Skills Enable a New Class of Realistic and Trivially Simple Prompt\n  Injections",
    "abstract": "Enabling continual learning in LLMs remains a key unresolved research\nchallenge. In a recent announcement, a frontier LLM company made a step towards\nthis by introducing Agent Skills, a framework that equips agents with new\nknowledge based on instructions stored in simple markdown files. Although Agent\nSkills can be a very useful tool, we show that they are fundamentally insecure,\nsince they enable trivially simple prompt injections. We demonstrate how to\nhide malicious instructions in long Agent Skill files and referenced scripts to\nexfiltrate sensitive data, such as internal files or passwords. Importantly, we\nshow how to bypass system-level guardrails of a popular coding agent: a benign,\ntask-specific approval with the \"Don't ask again\" option can carry over to\nclosely related but harmful actions. Overall, we conclude that despite ongoing\nresearch efforts and scaling model capabilities, frontier LLMs remain\nvulnerable to very simple prompt injections in realistic scenarios. Our code is\navailable at https://github.com/aisa-group/promptinject-agent-skills.",
    "categories": [
      "cs.LG"
    ],
    "published": "2025-10-30T10:27:11Z",
    "authors": [
      "David Schmotz",
      "Sahar Abdelnabi",
      "Maksym Andriushchenko"
    ],
    "pdf_url": "http://arxiv.org/pdf/2510.26328v1"
  },
  {
    "id": "2510.26324v1",
    "title": "Posterior Sampling by Combining Diffusion Models with Annealed Langevin\n  Dynamics",
    "abstract": "Given a noisy linear measurement $y = Ax + \\xi$ of a distribution $p(x)$, and\na good approximation to the prior $p(x)$, when can we sample from the posterior\n$p(x \\mid y)$? Posterior sampling provides an accurate and fair framework for\ntasks such as inpainting, deblurring, and MRI reconstruction, and several\nheuristics attempt to approximate it. Unfortunately, approximate posterior\nsampling is computationally intractable in general.\n  To sidestep this hardness, we focus on (local or global) log-concave\ndistributions $p(x)$. In this regime, Langevin dynamics yields posterior\nsamples when the exact scores of $p(x)$ are available, but it is brittle to\nscore--estimation error, requiring an MGF bound (sub-exponential error). By\ncontrast, in the unconditional setting, diffusion models succeed with only an\n$L^2$ bound on the score error. We prove that combining diffusion models with\nan annealed variant of Langevin dynamics achieves conditional sampling in\npolynomial time using merely an $L^4$ bound on the score error.",
    "categories": [
      "cs.LG",
      "cs.AI",
      "cs.DS",
      "math.ST",
      "stat.ML",
      "stat.TH"
    ],
    "published": "2025-10-30T10:17:27Z",
    "authors": [
      "Zhiyang Xun",
      "Shivam Gupta",
      "Eric Price"
    ],
    "pdf_url": "http://arxiv.org/pdf/2510.26324v1"
  },
  {
    "id": "2510.26323v1",
    "title": "On the Impact of Weight Discretization in QUBO-Based SVM Training",
    "abstract": "Training Support Vector Machines (SVMs) can be formulated as a QUBO problem,\nenabling the use of quantum annealing for model optimization. In this work, we\nstudy how the number of qubits - linked to the discretization level of dual\nweights - affects predictive performance across datasets. We compare QUBO-based\nSVM training to the classical LIBSVM solver and find that even low-precision\nQUBO encodings (e.g., 1 bit per parameter) yield competitive, and sometimes\nsuperior, accuracy. While increased bit-depth enables larger regularization\nparameters, it does not always improve classification. Our findings suggest\nthat selecting the right support vectors may matter more than their precise\nweighting. Although current hardware limits the size of solvable QUBOs, our\nresults highlight the potential of quantum annealing for efficient SVM training\nas quantum devices scale.",
    "categories": [
      "cs.LG"
    ],
    "published": "2025-10-30T10:17:25Z",
    "authors": [
      "Sascha M\u00fccke"
    ],
    "pdf_url": "http://arxiv.org/pdf/2510.26323v1"
  },
  {
    "id": "2510.26311v1",
    "title": "Model Inversion with Layer-Specific Modeling and Alignment for Data-Free\n  Continual Learning",
    "abstract": "Continual learning (CL) aims to incrementally train a model on a sequence of\ntasks while retaining performance on prior ones. However, storing and replaying\ndata is often infeasible due to privacy or security constraints and impractical\nfor arbitrary pre-trained models. Data-free CL seeks to update models without\naccess to previous data. Beyond regularization, we employ model inversion to\nsynthesize data from the trained model, enabling replay without storing\nsamples. Yet, model inversion in predictive models faces two challenges: (1)\ngenerating inputs solely from compressed output labels causes drift between\nsynthetic and real data, and replaying such data can erode prior knowledge; (2)\ninversion is computationally expensive since each step backpropagates through\nthe full model. These issues are amplified in large pre-trained models such as\nCLIP. To improve efficiency, we propose Per-layer Model Inversion (PMI),\ninspired by faster convergence in single-layer optimization. PMI provides\nstrong initialization for full-model inversion, substantially reducing\niterations. To mitigate feature shift, we model class-wise features via\nGaussian distributions and contrastive model, ensuring alignment between\nsynthetic and real features. Combining PMI and feature modeling, our approach\nenables continual learning of new classes by generating pseudo-images from\nsemantic-aware projected features, achieving strong effectiveness and\ncompatibility across multiple CL settings.",
    "categories": [
      "cs.LG"
    ],
    "published": "2025-10-30T09:58:48Z",
    "authors": [
      "Ruilin Tong",
      "Haodong Lu",
      "Yuhang Liu",
      "Dong Gong"
    ],
    "pdf_url": "http://arxiv.org/pdf/2510.26311v1"
  },
  {
    "id": "2510.26307v1",
    "title": "A Survey of Heterogeneous Graph Neural Networks for Cybersecurity\n  Anomaly Detection",
    "abstract": "Anomaly detection is a critical task in cybersecurity, where identifying\ninsider threats, access violations, and coordinated attacks is essential for\nensuring system resilience. Graph-based approaches have become increasingly\nimportant for modeling entity interactions, yet most rely on homogeneous and\nstatic structures, which limits their ability to capture the heterogeneity and\ntemporal evolution of real-world environments. Heterogeneous Graph Neural\nNetworks (HGNNs) have emerged as a promising paradigm for anomaly detection by\nincorporating type-aware transformations and relation-sensitive aggregation,\nenabling more expressive modeling of complex cyber data. However, current\nresearch on HGNN-based anomaly detection remains fragmented, with diverse\nmodeling strategies, limited comparative evaluation, and an absence of\nstandardized benchmarks. To address this gap, we provide a comprehensive survey\nof HGNN-based anomaly detection methods in cybersecurity. We introduce a\ntaxonomy that classifies approaches by anomaly type and graph dynamics, analyze\nrepresentative models, and map them to key cybersecurity applications. We also\nreview commonly used benchmark datasets and evaluation metrics, highlighting\ntheir strengths and limitations. Finally, we identify key open challenges\nrelated to modeling, data, and deployment, and outline promising directions for\nfuture research. This survey aims to establish a structured foundation for\nadvancing HGNN-based anomaly detection toward scalable, interpretable, and\npractically deployable solutions.",
    "categories": [
      "cs.CR",
      "cs.LG"
    ],
    "published": "2025-10-30T09:49:59Z",
    "authors": [
      "Laura Jiang",
      "Reza Ryan",
      "Qian Li",
      "Nasim Ferdosian"
    ],
    "pdf_url": "http://arxiv.org/pdf/2510.26307v1"
  },
  {
    "id": "2510.26303v1",
    "title": "Implicit Bias of Per-sample Adam on Separable Data: Departure from the\n  Full-batch Regime",
    "abstract": "Adam [Kingma and Ba, 2015] is the de facto optimizer in deep learning, yet\nits theoretical understanding remains limited. Prior analyses show that Adam\nfavors solutions aligned with $\\ell_\\infty$-geometry, but these results are\nrestricted to the full-batch regime. In this work, we study the implicit bias\nof incremental Adam (using one sample per step) for logistic regression on\nlinearly separable data, and we show that its bias can deviate from the\nfull-batch behavior. To illustrate this, we construct a class of structured\ndatasets where incremental Adam provably converges to the $\\ell_2$-max-margin\nclassifier, in contrast to the $\\ell_\\infty$-max-margin bias of full-batch\nAdam. For general datasets, we develop a proxy algorithm that captures the\nlimiting behavior of incremental Adam as $\\beta_2 \\to 1$ and we characterize\nits convergence direction via a data-dependent dual fixed-point formulation.\nFinally, we prove that, unlike Adam, Signum [Bernstein et al., 2018] converges\nto the $\\ell_\\infty$-max-margin classifier for any batch size by taking $\\beta$\nclose enough to 1. Overall, our results highlight that the implicit bias of\nAdam crucially depends on both the batching scheme and the dataset, while\nSignum remains invariant.",
    "categories": [
      "cs.LG",
      "cs.AI",
      "math.OC",
      "stat.ML"
    ],
    "published": "2025-10-30T09:41:33Z",
    "authors": [
      "Beomhan Baek",
      "Minhak Song",
      "Chulhee Yun"
    ],
    "pdf_url": "http://arxiv.org/pdf/2510.26303v1"
  },
  {
    "id": "2510.26302v1",
    "title": "Understanding Hardness of Vision-Language Compositionality from A\n  Token-level Causal Lens",
    "abstract": "Contrastive Language-Image Pre-training (CLIP) delivers strong cross modal\ngeneralization by aligning images and texts in a shared embedding space, yet it\npersistently fails at compositional reasoning over objects, attributes, and\nrelations often behaving like a bag-of-words matcher. Prior causal accounts\ntypically model text as a single vector, obscuring token-level structure and\nleaving core phenomena-such as prompt sensitivity and failures on hard\nnegatives unexplained. We address this gap with a token-aware causal\nrepresentation learning (CRL) framework grounded in a sequential,\nlanguage-token SCM. Our theory extends block identifiability to tokenized text,\nproving that CLIP's contrastive objective can recover the modal-invariant\nlatent variable under both sentence-level and token-level SCMs. Crucially,\ntoken granularity yields the first principled explanation of CLIP's\ncompositional brittleness: composition nonidentifiability. We show the\nexistence of pseudo-optimal text encoders that achieve perfect modal-invariant\nalignment yet are provably insensitive to SWAP, REPLACE, and ADD operations\nover atomic concepts, thereby failing to distinguish correct captions from hard\nnegatives despite optimizing the same training objective as true-optimal\nencoders. The analysis further links language-side nonidentifiability to\nvisual-side failures via the modality gap and shows how iterated composition\noperators compound hardness, motivating improved negative mining strategies.",
    "categories": [
      "cs.LG",
      "cs.AI"
    ],
    "published": "2025-10-30T09:41:21Z",
    "authors": [
      "Ziliang Chen",
      "Tianang Xiao",
      "Jusheng Zhang",
      "Yongsen Zheng",
      "Xipeng Chen"
    ],
    "pdf_url": "http://arxiv.org/pdf/2510.26302v1"
  },
  {
    "id": "2510.26301v1",
    "title": "Offline Clustering of Preference Learning with Active-data Augmentation",
    "abstract": "Preference learning from pairwise feedback is a widely adopted framework in\napplications such as reinforcement learning with human feedback and\nrecommendations. In many practical settings, however, user interactions are\nlimited or costly, making offline preference learning necessary. Moreover,\nreal-world preference learning often involves users with different preferences.\nFor example, annotators from different backgrounds may rank the same responses\ndifferently. This setting presents two central challenges: (1) identifying\nsimilarity across users to effectively aggregate data, especially under\nscenarios where offline data is imbalanced across dimensions, and (2) handling\nthe imbalanced offline data where some preference dimensions are\nunderrepresented. To address these challenges, we study the Offline Clustering\nof Preference Learning problem, where the learner has access to fixed datasets\nfrom multiple users with potentially different preferences and aims to maximize\nutility for a test user. To tackle the first challenge, we first propose\nOff-C$^2$PL for the pure offline setting, where the learner relies solely on\noffline data. Our theoretical analysis provides a suboptimality bound that\nexplicitly captures the tradeoff between sample noise and bias. To address the\nsecond challenge of inbalanced data, we extend our framework to the setting\nwith active-data augmentation where the learner is allowed to select a limited\nnumber of additional active-data for the test user based on the cluster\nstructure learned by Off-C$^2$PL. In this setting, our second algorithm,\nA$^2$-Off-C$^2$PL, actively selects samples that target the least-informative\ndimensions of the test user's preference. We prove that these actively\ncollected samples contribute more effectively than offline ones. Finally, we\nvalidate our theoretical results through simulations on synthetic and\nreal-world datasets.",
    "categories": [
      "cs.LG"
    ],
    "published": "2025-10-30T09:39:05Z",
    "authors": [
      "Jingyuan Liu",
      "Fatemeh Ghaffari",
      "Xuchuang Wang",
      "Mohammad Hajiesmaili",
      "Carlee Joe-Wong"
    ],
    "pdf_url": "http://arxiv.org/pdf/2510.26301v1"
  },
  {
    "id": "2510.26285v1",
    "title": "Unravelling the Mechanisms of Manipulating Numbers in Language Models",
    "abstract": "Recent work has shown that different large language models (LLMs) converge to\nsimilar and accurate input embedding representations for numbers. These\nfindings conflict with the documented propensity of LLMs to produce erroneous\noutputs when dealing with numeric information. In this work, we aim to explain\nthis conflict by exploring how language models manipulate numbers and quantify\nthe lower bounds of accuracy of these mechanisms. We find that despite\nsurfacing errors, different language models learn interchangeable\nrepresentations of numbers that are systematic, highly accurate and universal\nacross their hidden states and the types of input contexts. This allows us to\ncreate universal probes for each LLM and to trace information -- including the\ncauses of output errors -- to specific layers. Our results lay a fundamental\nunderstanding of how pre-trained LLMs manipulate numbers and outline the\npotential of more accurate probing techniques in addressed refinements of LLMs'\narchitectures.",
    "categories": [
      "cs.CL",
      "cs.AI",
      "cs.LG",
      "cs.NE"
    ],
    "published": "2025-10-30T09:08:50Z",
    "authors": [
      "Michal \u0160tef\u00e1nik",
      "Timothee Mickus",
      "Marek Kadl\u010d\u00edk",
      "Bertram H\u00f8jer",
      "Michal Spiegel",
      "Ra\u00fal V\u00e1zquez",
      "Aman Sinha",
      "Josef Kucha\u0159",
      "Philipp Mondorf"
    ],
    "pdf_url": "http://arxiv.org/pdf/2510.26285v1"
  },
  {
    "id": "2510.26284v1",
    "title": "Empirical Bayesian Multi-Bandit Learning",
    "abstract": "Multi-task learning in contextual bandits has attracted significant research\ninterest due to its potential to enhance decision-making across multiple\nrelated tasks by leveraging shared structures and task-specific heterogeneity.\nIn this article, we propose a novel hierarchical Bayesian framework for\nlearning in various bandit instances. This framework captures both the\nheterogeneity and the correlations among different bandit instances through a\nhierarchical Bayesian model, enabling effective information sharing while\naccommodating instance-specific variations. Unlike previous methods that\noverlook the learning of the covariance structure across bandits, we introduce\nan empirical Bayesian approach to estimate the covariance matrix of the prior\ndistribution.This enhances both the practicality and flexibility of learning\nacross multi-bandits. Building on this approach, we develop two efficient\nalgorithms: ebmTS (Empirical Bayesian Multi-Bandit Thompson Sampling) and\nebmUCB (Empirical Bayesian Multi-Bandit Upper Confidence Bound), both of which\nincorporate the estimated prior into the decision-making process. We provide\nthe frequentist regret upper bounds for the proposed algorithms, thereby\nfilling a research gap in the field of multi-bandit problems. Extensive\nexperiments on both synthetic and real-world datasets demonstrate the superior\nperformance of our algorithms, particularly in complex environments. Our\nmethods achieve lower cumulative regret compared to existing techniques,\nhighlighting their effectiveness in balancing exploration and exploitation\nacross multi-bandits.",
    "categories": [
      "cs.LG"
    ],
    "published": "2025-10-30T09:08:07Z",
    "authors": [
      "Xia Jiang",
      "Rong J. B. Zhu"
    ],
    "pdf_url": "http://arxiv.org/pdf/2510.26284v1"
  },
  {
    "id": "2510.26278v1",
    "title": "Distributional Multi-objective Black-box Optimization for\n  Diffusion-model Inference-time Multi-Target Generation",
    "abstract": "Diffusion models have been successful in learning complex data distributions.\nThis capability has driven their application to high-dimensional\nmulti-objective black-box optimization problem. Existing approaches often\nemploy an external optimization loop, such as an evolutionary algorithm, to the\ndiffusion model. However, these approaches treat the diffusion model as a\nblack-box refiner, which overlooks the internal distribution transition of the\ndiffusion generation process, limiting their efficiency. To address these\nchallenges, we propose the Inference-time Multi-target Generation (IMG)\nalgorithm, which optimizes the diffusion process at inference-time to generate\nsamples that simultaneously satisfy multiple objectives. Specifically, our IMG\nperforms weighted resampling during the diffusion generation process according\nto the expected aggregated multi-objective values. This weighted resampling\nstrategy ensures the diffusion-generated samples are distributed according to\nour desired multi-target Boltzmann distribution. We further derive that the\nmulti-target Boltzmann distribution has an interesting log-likelihood\ninterpretation, where it is the optimal solution to the distributional\nmulti-objective optimization problem. We implemented IMG for a multi-objective\nmolecule generation task. Experiments show that IMG, requiring only a single\ngeneration pass, achieves a significantly higher hypervolume than baseline\noptimization algorithms that often require hundreds of diffusion generations.\nNotably, our algorithm can be viewed as an optimized diffusion process and can\nbe integrated into existing methods to further improve their performance.",
    "categories": [
      "cs.LG",
      "cs.AI"
    ],
    "published": "2025-10-30T09:00:42Z",
    "authors": [
      "Kim Yong Tan",
      "Yueming Lyu",
      "Ivor Tsang",
      "Yew-Soon Ong"
    ],
    "pdf_url": "http://arxiv.org/pdf/2510.26278v1"
  },
  {
    "id": "2510.26275v1",
    "title": "A Research Roadmap for Augmenting Software Engineering Processes and\n  Software Products with Generative AI",
    "abstract": "Generative AI (GenAI) is rapidly transforming software engineering (SE)\npractices, influencing how SE processes are executed, as well as how software\nsystems are developed, operated, and evolved. This paper applies design science\nresearch to build a roadmap for GenAI-augmented SE. The process consists of\nthree cycles that incrementally integrate multiple sources of evidence,\nincluding collaborative discussions from the FSE 2025 \"Software Engineering\n2030\" workshop, rapid literature reviews, and external feedback sessions\ninvolving peers. McLuhan's tetrads were used as a conceptual instrument to\nsystematically capture the transforming effects of GenAI on SE processes and\nsoftware products.The resulting roadmap identifies four fundamental forms of\nGenAI augmentation in SE and systematically characterizes their related\nresearch challenges and opportunities. These insights are then consolidated\ninto a set of future research directions. By grounding the roadmap in a\nrigorous multi-cycle process and cross-validating it among independent author\nteams and peers, the study provides a transparent and reproducible foundation\nfor analyzing how GenAI affects SE processes, methods and tools, and for\nframing future research within this rapidly evolving area. Based on these\nfindings, the article finally makes ten predictions for SE in the year 2030.",
    "categories": [
      "cs.SE",
      "cs.AI",
      "cs.ET",
      "cs.LG",
      "cs.MA"
    ],
    "published": "2025-10-30T08:59:01Z",
    "authors": [
      "Domenico Amalfitano",
      "Andreas Metzger",
      "Marco Autili",
      "Tommaso Fulcini",
      "Tobias Hey",
      "Jan Keim",
      "Patrizio Pelliccione",
      "Vincenzo Scotti",
      "Anne Koziolek",
      "Raffaela Mirandola",
      "Andreas Vogelsang"
    ],
    "pdf_url": "http://arxiv.org/pdf/2510.26275v1"
  },
  {
    "id": "2510.26274v1",
    "title": "PVMark: Enabling Public Verifiability for LLM Watermarking Schemes",
    "abstract": "Watermarking schemes for large language models (LLMs) have been proposed to\nidentify the source of the generated text, mitigating the potential threats\nemerged from model theft. However, current watermarking solutions hardly\nresolve the trust issue: the non-public watermark detection cannot prove itself\nfaithfully conducting the detection. We observe that it is attributed to the\nsecret key mostly used in the watermark detection -- it cannot be public, or\nthe adversary may launch removal attacks provided the key; nor can it be\nprivate, or the watermarking detection is opaque to the public. To resolve the\ndilemma, we propose PVMark, a plugin based on zero-knowledge proof (ZKP),\nenabling the watermark detection process to be publicly verifiable by third\nparties without disclosing any secret key. PVMark hinges upon the proof of\n`correct execution' of watermark detection on which a set of ZKP constraints\nare built, including mapping, random number generation, comparison, and\nsummation. We implement multiple variants of PVMark in Python, Rust and Circom,\ncovering combinations of three watermarking schemes, three hash functions, and\nfour ZKP protocols, to show our approach effectively works under a variety of\ncircumstances. By experimental results, PVMark efficiently enables public\nverifiability on the state-of-the-art LLM watermarking schemes yet without\ncompromising the watermarking performance, promising to be deployed in\npractice.",
    "categories": [
      "cs.CR",
      "cs.CL",
      "cs.LG"
    ],
    "published": "2025-10-30T08:58:44Z",
    "authors": [
      "Haohua Duan",
      "Liyao Xiang",
      "Xin Zhang"
    ],
    "pdf_url": "http://arxiv.org/pdf/2510.26274v1"
  },
  {
    "id": "2510.26266v1",
    "title": "Likely Interpolants of Generative Models",
    "abstract": "Interpolation in generative models allows for controlled generation, model\ninspection, and more. Unfortunately, most generative models lack a principal\nnotion of interpolants without restrictive assumptions on either the model or\ndata dimension. In this paper, we develop a general interpolation scheme that\ntargets likely transition paths compatible with different metrics and\nprobability distributions. We consider interpolants analogous to a geodesic\nconstrained to a suitable data distribution and derive a novel algorithm for\ncomputing these curves, which requires no additional training. Theoretically,\nwe show that our method locally can be considered as a geodesic under a\nsuitable Riemannian metric. We quantitatively show that our interpolation\nscheme traverses higher density regions than baselines across a range of models\nand datasets.",
    "categories": [
      "cs.LG"
    ],
    "published": "2025-10-30T08:46:53Z",
    "authors": [
      "Frederik M\u00f6bius Rygaard",
      "Shen Zhu",
      "Yinzhu Jin",
      "S\u00f8ren Hauberg",
      "Tom Fletcher"
    ],
    "pdf_url": "http://arxiv.org/pdf/2510.26266v1"
  },
  {
    "id": "2510.26243v1",
    "title": "Angular Steering: Behavior Control via Rotation in Activation Space",
    "abstract": "Controlling specific behaviors in large language models while preserving\ntheir general capabilities is a central challenge for safe and reliable\nartificial intelligence deployment. Current steering methods, such as vector\naddition and directional ablation, are constrained within a two-dimensional\nsubspace defined by the activation and feature direction, making them sensitive\nto chosen parameters and potentially affecting unrelated features due to\nunintended interactions in activation space. We introduce Angular Steering, a\nnovel and flexible method for behavior modulation that operates by rotating\nactivations within a fixed two-dimensional subspace. By formulating steering as\na geometric rotation toward or away from a target behavior direction, Angular\nSteering provides continuous, fine-grained control over behaviors such as\nrefusal and compliance. We demonstrate this method using refusal steering\nemotion steering as use cases. Additionally, we propose Adaptive Angular\nSteering, a selective variant that rotates only activations aligned with the\ntarget feature, further enhancing stability and coherence. Angular Steering\ngeneralizes existing addition and orthogonalization techniques under a unified\ngeometric rotation framework, simplifying parameter selection and maintaining\nmodel stability across a broader range of adjustments. Experiments across\nmultiple model families and sizes show that Angular Steering achieves robust\nbehavioral control while maintaining general language modeling performance,\nunderscoring its flexibility, generalization, and robustness compared to prior\napproaches. Code and artifacts are available at\nhttps://github.com/lone17/angular-steering/.",
    "categories": [
      "cs.LG",
      "cs.AI"
    ],
    "published": "2025-10-30T08:23:35Z",
    "authors": [
      "Hieu M. Vu",
      "Tan M. Nguyen"
    ],
    "pdf_url": "http://arxiv.org/pdf/2510.26243v1"
  },
  {
    "id": "2510.26230v1",
    "title": "MPRU: Modular Projection-Redistribution Unlearning as Output Filter for\n  Classification Pipelines",
    "abstract": "As a new and promising approach, existing machine unlearning (MU) works\ntypically emphasize theoretical formulations or optimization objectives to\nachieve knowledge removal. However, when deployed in real-world scenarios, such\nsolutions typically face scalability issues and have to address practical\nrequirements such as full access to original datasets and model. In contrast to\nthe existing approaches, we regard classification training as a sequential\nprocess where classes are learned sequentially, which we call \\emph{inductive\napproach}. Unlearning can then be done by reversing the last training sequence.\nThis is implemented by appending a projection-redistribution layer in the end\nof the model. Such an approach does not require full access to the original\ndataset or the model, addressing the challenges of existing methods. This\nenables modular and model-agnostic deployment as an output filter into existing\nclassification pipelines with minimal alterations. We conducted multiple\nexperiments across multiple datasets including image (CIFAR-10/100 using\nCNN-based model) and tabular datasets (Covertype using tree-based model).\nExperiment results show consistently similar output to a fully retrained model\nwith a high computational cost reduction. This demonstrates the applicability,\nscalability, and system compatibility of our solution while maintaining the\nperformance of the output in a more practical setting.",
    "categories": [
      "cs.LG",
      "cs.AI",
      "68T09 68T09"
    ],
    "published": "2025-10-30T08:09:37Z",
    "authors": [
      "Minyi Peng",
      "Darian Gunamardi",
      "Ivan Tjuawinata",
      "Kwok-Yan Lam"
    ],
    "pdf_url": "http://arxiv.org/pdf/2510.26230v1"
  },
  {
    "id": "2510.26219v1",
    "title": "Test-Time Alignment of LLMs via Sampling-Based Optimal Control in\n  pre-logit space",
    "abstract": "Test-time alignment of large language models (LLMs) attracts attention\nbecause fine-tuning LLMs requires high computational costs. In this paper, we\npropose a new test-time alignment method called adaptive importance sampling on\npre-logits (AISP) on the basis of the sampling-based model predictive control\nwith the stochastic control input. AISP applies the Gaussian perturbation into\npre-logits, which are outputs of the penultimate layer, so as to maximize\nexpected rewards with respect to the mean of the perturbation. We demonstrate\nthat the optimal mean is obtained by importance sampling with sampled rewards.\nAISP outperforms best-of-n sampling in terms of rewards over the number of used\nsamples and achieves higher rewards than other reward-based test-time alignment\nmethods.",
    "categories": [
      "cs.LG",
      "cs.AI"
    ],
    "published": "2025-10-30T07:52:14Z",
    "authors": [
      "Sekitoshi Kanai",
      "Tsukasa Yoshida",
      "Hiroshi Takahashi",
      "Haru Kuroki",
      "Kazumune Hashimoto"
    ],
    "pdf_url": "http://arxiv.org/pdf/2510.26219v1"
  },
  {
    "id": "2510.26188v1",
    "title": "Predicting All-Cause Hospital Readmissions from Medical Claims Data of\n  Hospitalised Patients",
    "abstract": "Reducing preventable hospital readmissions is a national priority for payers,\nproviders, and policymakers seeking to improve health care and lower costs. The\nrate of readmission is being used as a benchmark to determine the quality of\nhealthcare provided by the hospitals. In thisproject, we have used machine\nlearning techniques like Logistic Regression, Random Forest and Support Vector\nMachines to analyze the health claims data and identify demographic and medical\nfactors that play a crucial role in predicting all-cause readmissions. As the\nhealth claims data is high dimensional, we have used Principal Component\nAnalysis as a dimension reduction technique and used the results for building\nregression models. We compared and evaluated these models based on the Area\nUnder Curve (AUC) metric. Random Forest model gave the highest performance\nfollowed by Logistic Regression and Support Vector Machine models. These models\ncan be used to identify the crucial factors causing readmissions and help\nidentify patients to focus on to reduce the chances of readmission, ultimately\nbringing down the cost and increasing the quality of healthcare provided to the\npatients.",
    "categories": [
      "cs.LG",
      "cs.AI"
    ],
    "published": "2025-10-30T06:54:19Z",
    "authors": [
      "Avinash Kadimisetty",
      "Arun Rajagopalan",
      "Vijendra SK"
    ],
    "pdf_url": "http://arxiv.org/pdf/2510.26188v1"
  },
  {
    "id": "2510.26185v1",
    "title": "Accumulative SGD Influence Estimation for Data Attribution",
    "abstract": "Modern data-centric AI needs precise per-sample influence. Standard SGD-IE\napproximates leave-one-out effects by summing per-epoch surrogates and ignores\ncross-epoch compounding, which misranks critical examples. We propose\nACC-SGD-IE, a trajectory-aware estimator that propagates the leave-one-out\nperturbation across training and updates an accumulative influence state at\neach step. In smooth strongly convex settings it achieves geometric error\ncontraction and, in smooth non-convex regimes, it tightens error bounds; larger\nmini-batches further reduce constants. Empirically, on Adult, 20 Newsgroups,\nand MNIST under clean and corrupted data and both convex and non-convex\ntraining, ACC-SGD-IE yields more accurate influence estimates, especially over\nlong epochs. For downstream data cleansing it more reliably flags noisy\nsamples, producing models trained on ACC-SGD-IE cleaned data that outperform\nthose cleaned with SGD-IE.",
    "categories": [
      "cs.LG",
      "cs.AI"
    ],
    "published": "2025-10-30T06:45:22Z",
    "authors": [
      "Yunxiao Shi",
      "Shuo Yang",
      "Yixin Su",
      "Rui Zhang",
      "Min Xu"
    ],
    "pdf_url": "http://arxiv.org/pdf/2510.26185v1"
  },
  {
    "id": "2510.26184v1",
    "title": "A Game-Theoretic Spatio-Temporal Reinforcement Learning Framework for\n  Collaborative Public Resource Allocation",
    "abstract": "Public resource allocation involves the efficient distribution of resources,\nincluding urban infrastructure, energy, and transportation, to effectively meet\nsocietal demands. However, existing methods focus on optimizing the movement of\nindividual resources independently, without considering their capacity\nconstraints. To address this limitation, we propose a novel and more practical\nproblem: Collaborative Public Resource Allocation (CPRA), which explicitly\nincorporates capacity constraints and spatio-temporal dynamics in real-world\nscenarios. We propose a new framework called Game-Theoretic Spatio-Temporal\nReinforcement Learning (GSTRL) for solving CPRA. Our contributions are twofold:\n1) We formulate the CPRA problem as a potential game and demonstrate that there\nis no gap between the potential function and the optimal target, laying a solid\ntheoretical foundation for approximating the Nash equilibrium of this NP-hard\nproblem; and 2) Our designed GSTRL framework effectively captures the\nspatio-temporal dynamics of the overall system. We evaluate GSTRL on two\nreal-world datasets, where experiments show its superior performance. Our\nsource codes are available in the supplementary materials.",
    "categories": [
      "cs.LG",
      "cs.CY"
    ],
    "published": "2025-10-30T06:43:47Z",
    "authors": [
      "Songxin Lei",
      "Qiongyan Wang",
      "Yanchen Zhu",
      "Hanyu Yao",
      "Sijie Ruan",
      "Weilin Ruan",
      "Yuyu Luo",
      "Huaming Wu",
      "Yuxuan Liang"
    ],
    "pdf_url": "http://arxiv.org/pdf/2510.26184v1"
  },
  {
    "id": "2510.26159v1",
    "title": "Segmentation over Complexity: Evaluating Ensemble and Hybrid Approaches\n  for Anomaly Detection in Industrial Time Series",
    "abstract": "In this study, we investigate the effectiveness of advanced feature\nengineering and hybrid model architectures for anomaly detection in a\nmultivariate industrial time series, focusing on a steam turbine system. We\nevaluate the impact of change point-derived statistical features,\nclustering-based substructure representations, and hybrid learning strategies\non detection performance. Despite their theoretical appeal, these complex\napproaches consistently underperformed compared to a simple Random Forest +\nXGBoost ensemble trained on segmented data. The ensemble achieved an AUC-ROC of\n0.976, F1-score of 0.41, and 100% early detection within the defined time\nwindow. Our findings highlight that, in scenarios with highly imbalanced and\ntemporally uncertain data, model simplicity combined with optimized\nsegmentation can outperform more sophisticated architectures, offering greater\nrobustness, interpretability, and operational utility.",
    "categories": [
      "cs.LG",
      "cs.AI"
    ],
    "published": "2025-10-30T05:39:44Z",
    "authors": [
      "Emilio Mastriani",
      "Alessandro Costa",
      "Federico Incardona",
      "Kevin Munari",
      "Sebastiano Spinello"
    ],
    "pdf_url": "http://arxiv.org/pdf/2510.26159v1"
  },
  {
    "id": "2510.26157v1",
    "title": "Bridging the Gap Between Molecule and Textual Descriptions via\n  Substructure-aware Alignment",
    "abstract": "Molecule and text representation learning has gained increasing interest due\nto its potential for enhancing the understanding of chemical information.\nHowever, existing models often struggle to capture subtle differences between\nmolecules and their descriptions, as they lack the ability to learn\nfine-grained alignments between molecular substructures and chemical phrases.\nTo address this limitation, we introduce MolBridge, a novel molecule-text\nlearning framework based on substructure-aware alignments. Specifically, we\naugment the original molecule-description pairs with additional alignment\nsignals derived from molecular substructures and chemical phrases. To\neffectively learn from these enriched alignments, MolBridge employs\nsubstructure-aware contrastive learning, coupled with a self-refinement\nmechanism that filters out noisy alignment signals. Experimental results show\nthat MolBridge effectively captures fine-grained correspondences and\noutperforms state-of-the-art baselines on a wide range of molecular benchmarks,\nhighlighting the significance of substructure-aware alignment in molecule-text\nlearning.",
    "categories": [
      "cs.LG",
      "cs.AI"
    ],
    "published": "2025-10-30T05:36:31Z",
    "authors": [
      "Hyuntae Park",
      "Yeachan Kim",
      "SangKeun Lee"
    ],
    "pdf_url": "http://arxiv.org/pdf/2510.26157v1"
  },
  {
    "id": "2510.26148v1",
    "title": "STAR: A Privacy-Preserving, Energy-Efficient Edge AI Framework for Human\n  Activity Recognition via Wi-Fi CSI in Mobile and Pervasive Computing\n  Environments",
    "abstract": "Human Activity Recognition (HAR) via Wi-Fi Channel State Information (CSI)\npresents a privacy-preserving, contactless sensing approach suitable for smart\nhomes, healthcare monitoring, and mobile IoT systems. However, existing methods\noften encounter computational inefficiency, high latency, and limited\nfeasibility within resource-constrained, embedded mobile edge environments.\nThis paper proposes STAR (Sensing Technology for Activity Recognition), an\nedge-AI-optimized framework that integrates a lightweight neural architecture,\nadaptive signal processing, and hardware-aware co-optimization to enable\nreal-time, energy-efficient HAR on low-power embedded devices. STAR\nincorporates a streamlined Gated Recurrent Unit (GRU)-based recurrent neural\nnetwork, reducing model parameters by 33% compared to conventional LSTM models\nwhile maintaining effective temporal modeling capability. A multi-stage\npre-processing pipeline combining median filtering, 8th-order Butterworth\nlow-pass filtering, and Empirical Mode Decomposition (EMD) is employed to\ndenoise CSI amplitude data and extract spatial-temporal features. For on-device\ndeployment, STAR is implemented on a Rockchip RV1126 processor equipped with an\nembedded Neural Processing Unit (NPU), interfaced with an ESP32-S3-based CSI\nacquisition module. Experimental results demonstrate a mean recognition\naccuracy of 93.52% across seven activity classes and 99.11% for human presence\ndetection, utilizing a compact 97.6k-parameter model. INT8 quantized inference\nachieves a processing speed of 33 MHz with just 8% CPU utilization, delivering\nsixfold speed improvements over CPU-based execution. With sub-second response\nlatency and low power consumption, the system ensures real-time,\nprivacy-preserving HAR, offering a practical, scalable solution for mobile and\npervasive computing environments.",
    "categories": [
      "cs.LG"
    ],
    "published": "2025-10-30T05:08:25Z",
    "authors": [
      "Kexing Liu"
    ],
    "pdf_url": "http://arxiv.org/pdf/2510.26148v1"
  },
  {
    "id": "2510.26146v1",
    "title": "maxVSTAR: Maximally Adaptive Vision-Guided CSI Sensing with Closed-Loop\n  Edge Model Adaptation for Robust Human Activity Recognition",
    "abstract": "WiFi Channel State Information (CSI)-based human activity recognition (HAR)\nprovides a privacy-preserving, device-free sensing solution for smart\nenvironments. However, its deployment on edge devices is severely constrained\nby domain shift, where recognition performance deteriorates under varying\nenvironmental and hardware conditions. This study presents maxVSTAR (maximally\nadaptive Vision-guided Sensing Technology for Activity Recognition), a\nclosed-loop, vision-guided model adaptation framework that autonomously\nmitigates domain shift for edge-deployed CSI sensing systems. The proposed\nsystem integrates a cross-modal teacher-student architecture, where a\nhigh-accuracy YOLO-based vision model serves as a dynamic supervisory signal,\ndelivering real-time activity labels for the CSI data stream. These labels\nenable autonomous, online fine-tuning of a lightweight CSI-based HAR model,\ntermed Sensing Technology for Activity Recognition (STAR), directly at the\nedge. This closed-loop retraining mechanism allows STAR to continuously adapt\nto environmental changes without manual intervention. Extensive experiments\ndemonstrate the effectiveness of maxVSTAR. When deployed on uncalibrated\nhardware, the baseline STAR model's recognition accuracy declined from 93.52%\nto 49.14%. Following a single vision-guided adaptation cycle, maxVSTAR restored\nthe accuracy to 81.51%. These results confirm the system's capacity for\ndynamic, self-supervised model adaptation in privacy-conscious IoT\nenvironments, establishing a scalable and practical paradigm for long-term\nautonomous HAR using CSI sensing at the network edge.",
    "categories": [
      "cs.LG"
    ],
    "published": "2025-10-30T04:59:28Z",
    "authors": [
      "Kexing Liu"
    ],
    "pdf_url": "http://arxiv.org/pdf/2510.26146v1"
  },
  {
    "id": "2510.26130v1",
    "title": "Beyond Synthetic Benchmarks: Evaluating LLM Performance on Real-World\n  Class-Level Code Generation",
    "abstract": "Large language models (LLMs) have advanced code generation at the function\nlevel, yet their ability to produce correct class-level implementations in\nauthentic software projects remains poorly understood. This work introduces a\nnovel benchmark derived from open-source repositories, comprising real-world\nclasses divided into seen and unseen partitions to evaluate generalization\nunder practical conditions. The evaluation examines multiple LLMs under varied\ninput specifications, retrieval-augmented configurations, and documentation\ncompleteness levels.\n  Results reveal a stark performance disparity: LLMs achieve 84% to 89%\ncorrectness on established synthetic benchmarks but only 25% to 34% on\nreal-world class tasks, with negligible differences between familiar and novel\ncodebases. Comprehensive docstrings yield modest gains of 1% to 3% in\nfunctional accuracy, though statistical significance is rare.\nRetrieval-augmented generation proves most effective with partial\ndocumentation, improving correctness by 4% to 7% by supplying concrete\nimplementation patterns absent from specifications. Error profiling identifies\nAttributeError, TypeError, and AssertionError as dominant failure modes (84% of\ncases), with synthetic tests overemphasizing assertion issues and real-world\nscenarios highlighting type and attribute mismatches. Retrieval augmentation\nreduces logical flaws but can introduce dependency conflicts.\n  The benchmark and analysis expose critical limitations in current LLM\ncapabilities for class-level engineering, offering actionable insights for\nenhancing context modelling, documentation strategies, and retrieval\nintegration in production code assistance tools.",
    "categories": [
      "cs.SE",
      "cs.AI",
      "cs.LG"
    ],
    "published": "2025-10-30T04:30:23Z",
    "authors": [
      "Musfiqur Rahman",
      "SayedHassan Khatoonabadi",
      "Emad Shihab"
    ],
    "pdf_url": "http://arxiv.org/pdf/2510.26130v1"
  },
  {
    "id": "2510.26121v1",
    "title": "Uncertainty-Aware Diagnostics for Physics-Informed Machine Learning",
    "abstract": "Physics-informed machine learning (PIML) integrates prior physical\ninformation, often in the form of differential equation constraints, into the\nprocess of fitting machine learning models to physical data. Popular PIML\napproaches, including neural operators, physics-informed neural networks,\nneural ordinary differential equations, and neural discrete equilibria, are\ntypically fit to objectives that simultaneously include both data and physical\nconstraints. However, the multi-objective nature of this approach creates\nambiguity in the measurement of model quality. This is related to a poor\nunderstanding of epistemic uncertainty, and it can lead to surprising failure\nmodes, even when existing statistical metrics suggest strong fits. Working\nwithin a Gaussian process regression framework, we introduce the\nPhysics-Informed Log Evidence (PILE) score. Bypassing the ambiguities of test\nlosses, the PILE score is a single, uncertainty-aware metric that provides a\nselection principle for hyperparameters of a PIML model. We show that PILE\nminimization yields excellent choices for a wide variety of model parameters,\nincluding kernel bandwidth, least squares regularization weights, and even\nkernel function selection. We also show that, even prior to data acquisition, a\nspecial 'data-free' case of the PILE score identifies a priori kernel choices\nthat are 'well-adapted' to a given PDE. Beyond the kernel setting, we\nanticipate that the PILE score can be extended to PIML at large, and we outline\napproaches to do so.",
    "categories": [
      "stat.ML",
      "cs.LG"
    ],
    "published": "2025-10-30T04:05:49Z",
    "authors": [
      "Mara Daniels",
      "Liam Hodgkinson",
      "Michael Mahoney"
    ],
    "pdf_url": "http://arxiv.org/pdf/2510.26121v1"
  },
  {
    "id": "2510.26109v1",
    "title": "Do Not Step Into the Same River Twice: Learning to Reason from Trial and\n  Error",
    "abstract": "Reinforcement learning with verifiable rewards (RLVR) has significantly\nboosted the reasoning capability of large language models (LLMs) recently.\nHowever, existing RLVR approaches merely train LLMs based on their own\ngenerated responses and are constrained by the initial capability of LLMs, thus\nprone to exploration stagnation, in which LLMs fail to solve more training\nproblems and cannot further learn from the training data. Some work tries to\naddress this by leveraging off-policy solutions to training problems but\nrequires external guidance from experts which suffers from limited\navailability. In this work, we propose LTE (Learning to reason from Trial and\nError), an approach hinting LLMs with their previously self-generated incorrect\nanswers and problem of overlong responses, which does not require any external\nexpert guidance. Experiments validate the effectiveness of LTE, which\noutperforms the normal group relative policy optimization (GRPO) by 6.38 in\nPass@1 and 9.00 in Pass@k on average across six mathematics benchmarks for\nQwen3-4B-Base. Further analysis confirms that LTE successfully mitigates the\nproblem of exploration stagnation and enhances both exploitation and\nexploration during training.",
    "categories": [
      "cs.LG"
    ],
    "published": "2025-10-30T03:36:19Z",
    "authors": [
      "Chenming Tang",
      "Hsiu-Yuan Huang",
      "Weijie Liu",
      "Saiyong Yang",
      "Yunfang Wu"
    ],
    "pdf_url": "http://arxiv.org/pdf/2510.26109v1"
  },
  {
    "id": "2510.26099v1",
    "title": "SAFE: A Novel Approach to AI Weather Evaluation through Stratified\n  Assessments of Forecasts over Earth",
    "abstract": "The dominant paradigm in machine learning is to assess model performance\nbased on average loss across all samples in some test set. This amounts to\naveraging performance geospatially across the Earth in weather and climate\nsettings, failing to account for the non-uniform distribution of human\ndevelopment and geography. We introduce Stratified Assessments of Forecasts\nover Earth (SAFE), a package for elucidating the stratified performance of a\nset of predictions made over Earth. SAFE integrates various data domains to\nstratify by different attributes associated with geospatial gridpoints:\nterritory (usually country), global subregion, income, and landcover (land or\nwater). This allows us to examine the performance of models for each individual\nstratum of the different attributes (e.g., the accuracy in every individual\ncountry). To demonstrate its importance, we utilize SAFE to benchmark a zoo of\nstate-of-the-art AI-based weather prediction models, finding that they all\nexhibit disparities in forecasting skill across every attribute. We use this to\nseed a benchmark of model forecast fairness through stratification at different\nlead times for various climatic variables. By moving beyond globally-averaged\nmetrics, we for the first time ask: where do models perform best or worst, and\nwhich models are most fair? To support further work in this direction, the SAFE\npackage is open source and available at https://github.com/N-Masi/safe",
    "categories": [
      "cs.LG",
      "cs.AI"
    ],
    "published": "2025-10-30T03:22:55Z",
    "authors": [
      "Nick Masi",
      "Randall Balestriero"
    ],
    "pdf_url": "http://arxiv.org/pdf/2510.26099v1"
  },
  {
    "id": "2510.26097v1",
    "title": "Robust Super-Capacity SRS Channel Inpainting via Diffusion Models",
    "abstract": "Accurate channel state information (CSI) is essential for reliable multiuser\nMIMO operation. In 5G NR, reciprocity-based beamforming via uplink Sounding\nReference Signals (SRS) face resource and coverage constraints, motivating\nsparse non-uniform SRS allocation. Prior masked-autoencoder (MAE) approaches\nimprove coverage but overfit to training masks and degrade under unseen\ndistortions (e.g., additional masking, interference, clipping, non-Gaussian\nnoise). We propose a diffusion-based channel inpainting framework that\nintegrates system-model knowledge at inference via a likelihood-gradient term,\nenabling a single trained model to adapt across mismatched conditions. On\nstandardized CDL channels, the score-based diffusion variant consistently\noutperforms a UNet score-model baseline and the one-step MAE under distribution\nshift, with improvements up to 14 dB NMSE in challenging settings (e.g.,\nLaplace noise, user interference), while retaining competitive accuracy under\nmatched conditions. These results demonstrate that diffusion-guided inpainting\nis a robust and generalizable approach for super-capacity SRS design in 5G NR\nsystems.",
    "categories": [
      "eess.SP",
      "cs.LG"
    ],
    "published": "2025-10-30T03:22:13Z",
    "authors": [
      "Usman Akram",
      "Fan Zhang",
      "Yang Li",
      "Haris Vikalo"
    ],
    "pdf_url": "http://arxiv.org/pdf/2510.26097v1"
  },
  {
    "id": "2510.26096v1",
    "title": "ALMGuard: Safety Shortcuts and Where to Find Them as Guardrails for\n  Audio-Language Models",
    "abstract": "Recent advances in Audio-Language Models (ALMs) have significantly improved\nmultimodal understanding capabilities. However, the introduction of the audio\nmodality also brings new and unique vulnerability vectors. Previous studies\nhave proposed jailbreak attacks that specifically target ALMs, revealing that\ndefenses directly transferred from traditional audio adversarial attacks or\ntext-based Large Language Model (LLM) jailbreaks are largely ineffective\nagainst these ALM-specific threats. To address this issue, we propose ALMGuard,\nthe first defense framework tailored to ALMs. Based on the assumption that\nsafety-aligned shortcuts naturally exist in ALMs, we design a method to\nidentify universal Shortcut Activation Perturbations (SAPs) that serve as\ntriggers that activate the safety shortcuts to safeguard ALMs at inference\ntime. To better sift out effective triggers while preserving the model's\nutility on benign tasks, we further propose Mel-Gradient Sparse Mask (M-GSM),\nwhich restricts perturbations to Mel-frequency bins that are sensitive to\njailbreaks but insensitive to speech understanding. Both theoretical analyses\nand empirical results demonstrate the robustness of our method against both\nseen and unseen attacks. Overall, \\MethodName reduces the average success rate\nof advanced ALM-specific jailbreak attacks to 4.6% across four models, while\nmaintaining comparable utility on benign benchmarks, establishing it as the new\nstate of the art. Our code and data are available at\nhttps://github.com/WeifeiJin/ALMGuard.",
    "categories": [
      "cs.SD",
      "cs.CR",
      "cs.LG"
    ],
    "published": "2025-10-30T03:19:59Z",
    "authors": [
      "Weifei Jin",
      "Yuxin Cao",
      "Junjie Su",
      "Minhui Xue",
      "Jie Hao",
      "Ke Xu",
      "Jin Song Dong",
      "Derui Wang"
    ],
    "pdf_url": "http://arxiv.org/pdf/2510.26096v1"
  },
  {
    "id": "2510.26094v1",
    "title": "Lean4Physics: Comprehensive Reasoning Framework for College-level\n  Physics in Lean4",
    "abstract": "We present **Lean4PHYS**, a comprehensive reasoning framework for\ncollege-level physics problems in Lean4. **Lean4PHYS** includes\n*LeanPhysBench*, a college-level benchmark for formal physics reasoning in\nLean4, which contains 200 hand-crafted and peer-reviewed statements derived\nfrom university textbooks and physics competition problems. To establish a\nsolid foundation for formal reasoning in physics, we also introduce *PhysLib*,\na community-driven repository containing fundamental unit systems and theorems\nessential for formal physics reasoning. Based on the benchmark and Lean4\nrepository we composed in **Lean4PHYS**, we report baseline results using major\nexpert Math Lean4 provers and state-of-the-art closed-source models, with the\nbest performance of DeepSeek-Prover-V2-7B achieving only 16% and\nClaude-Sonnet-4 achieving 35%. We also conduct a detailed analysis showing that\nour *PhysLib* can achieve an average improvement of 11.75% in model\nperformance. This demonstrates the challenging nature of our *LeanPhysBench*\nand the effectiveness of *PhysLib*. To the best of our knowledge, this is the\nfirst study to provide a physics benchmark in Lean4.",
    "categories": [
      "cs.AI",
      "cs.LG"
    ],
    "published": "2025-10-30T03:09:40Z",
    "authors": [
      "Yuxin Li",
      "Minghao Liu",
      "Ruida Wang",
      "Wenzhao Ji",
      "Zhitao He",
      "Rui Pan",
      "Junming Huang",
      "Tong Zhang",
      "Yi R. Fung"
    ],
    "pdf_url": "http://arxiv.org/pdf/2510.26094v1"
  },
  {
    "id": "2510.26089v1",
    "title": "Network-Constrained Policy Optimization for Adaptive Multi-agent Vehicle\n  Routing",
    "abstract": "Traffic congestion in urban road networks leads to longer trip times and\nhigher emissions, especially during peak periods. While the Shortest Path First\n(SPF) algorithm is optimal for a single vehicle in a static network, it\nperforms poorly in dynamic, multi-vehicle settings, often worsening congestion\nby routing all vehicles along identical paths. We address dynamic vehicle\nrouting through a multi-agent reinforcement learning (MARL) framework for\ncoordinated, network-aware fleet navigation. We first propose Adaptive\nNavigation (AN), a decentralized MARL model where each intersection agent\nprovides routing guidance based on (i) local traffic and (ii) neighborhood\nstate modeled using Graph Attention Networks (GAT). To improve scalability in\nlarge networks, we further propose Hierarchical Hub-based Adaptive Navigation\n(HHAN), an extension of AN that assigns agents only to key intersections\n(hubs). Vehicles are routed hub-to-hub under agent control, while SPF handles\nmicro-routing within each hub region. For hub coordination, HHAN adopts\ncentralized training with decentralized execution (CTDE) under the Attentive\nQ-Mixing (A-QMIX) framework, which aggregates asynchronous vehicle decisions\nvia attention. Hub agents use flow-aware state features that combine local\ncongestion and predictive dynamics for proactive routing. Experiments on\nsynthetic grids and real urban maps (Toronto, Manhattan) show that AN reduces\naverage travel time versus SPF and learning baselines, maintaining 100% routing\nsuccess. HHAN scales to networks with hundreds of intersections, achieving up\nto 15.9% improvement under heavy traffic. These findings highlight the\npotential of network-constrained MARL for scalable, coordinated, and\ncongestion-aware routing in intelligent transportation systems.",
    "categories": [
      "cs.LG",
      "cs.AI",
      "cs.MA"
    ],
    "published": "2025-10-30T02:49:46Z",
    "authors": [
      "Fazel Arasteh",
      "Arian Haghparast",
      "Manos Papagelis"
    ],
    "pdf_url": "http://arxiv.org/pdf/2510.26089v1"
  },
  {
    "id": "2510.26086v1",
    "title": "LLMBisect: Breaking Barriers in Bug Bisection with A Comparative\n  Analysis Pipeline",
    "abstract": "Bug bisection has been an important security task that aims to understand the\nrange of software versions impacted by a bug, i.e., identifying the commit that\nintroduced the bug. However, traditional patch-based bisection methods are\nfaced with several significant barriers: For example, they assume that the\nbug-inducing commit (BIC) and the patch commit modify the same functions, which\nis not always true. They often rely solely on code changes, while the commit\nmessage frequently contains a wealth of vulnerability-related information. They\nare also based on simple heuristics (e.g., assuming the BIC initializes lines\ndeleted in the patch) and lack any logical analysis of the vulnerability.\n  In this paper, we make the observation that Large Language Models (LLMs) are\nwell-positioned to break the barriers of existing solutions, e.g., comprehend\nboth textual data and code in patches and commits. Unlike previous BIC\nidentification approaches, which yield poor results, we propose a comprehensive\nmulti-stage pipeline that leverages LLMs to: (1) fully utilize patch\ninformation, (2) compare multiple candidate commits in context, and (3)\nprogressively narrow down the candidates through a series of down-selection\nsteps. In our evaluation, we demonstrate that our approach achieves\nsignificantly better accuracy than the state-of-the-art solution by more than\n38\\%. Our results further confirm that the comprehensive multi-stage pipeline\nis essential, as it improves accuracy by 60\\% over a baseline LLM-based\nbisection method.",
    "categories": [
      "cs.LG"
    ],
    "published": "2025-10-30T02:47:25Z",
    "authors": [
      "Zheng Zhang",
      "Haonan Li",
      "Xingyu Li",
      "Hang Zhang",
      "Zhiyun Qian"
    ],
    "pdf_url": "http://arxiv.org/pdf/2510.26086v1"
  },
  {
    "id": "2510.26083v1",
    "title": "Nirvana: A Specialized Generalist Model With Task-Aware Memory Mechanism",
    "abstract": "Specialized Generalist Models (SGMs) aim to preserve broad capabilities while\nachieving expert-level performance in target domains. However, traditional LLM\nstructures including Transformer, Linear Attention, and hybrid models do not\nemploy specialized memory mechanism guided by task information. In this paper,\nwe present Nirvana, an SGM with specialized memory mechanism, linear time\ncomplexity, and test-time task information extraction. Besides, we propose the\nTask-Aware Memory Trigger ($\\textit{Trigger}$) that flexibly adjusts memory\nmechanism based on the current task's requirements. In Trigger, each incoming\nsample is treated as a self-supervised fine-tuning task, enabling Nirvana to\nadapt its task-related parameters on the fly to domain shifts. We also design\nthe Specialized Memory Updater ($\\textit{Updater}$) that dynamically memorizes\nthe context guided by Trigger. We conduct experiments on both general language\ntasks and specialized medical tasks. On a variety of natural language modeling\nbenchmarks, Nirvana achieves competitive or superior results compared to the\nexisting LLM structures. To prove the effectiveness of Trigger on specialized\ntasks, we test Nirvana's performance on a challenging medical task, i.e.,\nMagnetic Resonance Imaging (MRI). We post-train frozen Nirvana backbone with\nlightweight codecs on paired electromagnetic signals and MRI images. Despite\nthe frozen Nirvana backbone, Trigger guides the model to adapt to the MRI\ndomain with the change of task-related parameters. Nirvana achieves\nhigher-quality MRI reconstruction compared to conventional MRI models as well\nas the models with traditional LLMs' backbone, and can also generate accurate\npreliminary clinical reports accordingly.",
    "categories": [
      "cs.LG",
      "cs.AI"
    ],
    "published": "2025-10-30T02:41:54Z",
    "authors": [
      "Yuhua Jiang",
      "Shuang Cheng",
      "Yihao Liu",
      "Ermo Hua",
      "Che Jiang",
      "Weigao Sun",
      "Yu Cheng",
      "Feifei Gao",
      "Biqing Qi",
      "Bowen Zhou"
    ],
    "pdf_url": "http://arxiv.org/pdf/2510.26083v1"
  },
  {
    "id": "2510.26076v1",
    "title": "New Money: A Systematic Review of Synthetic Data Generation for Finance",
    "abstract": "Synthetic data generation has emerged as a promising approach to address the\nchallenges of using sensitive financial data in machine learning applications.\nBy leveraging generative models, such as Generative Adversarial Networks (GANs)\nand Variational Autoencoders (VAEs), it is possible to create artificial\ndatasets that preserve the statistical properties of real financial records\nwhile mitigating privacy risks and regulatory constraints. Despite the rapid\ngrowth of this field, a comprehensive synthesis of the current research\nlandscape has been lacking. This systematic review consolidates and analyses 72\nstudies published since 2018 that focus on synthetic financial data generation.\nWe categorise the types of financial information synthesised, the generative\nmethods employed, and the evaluation strategies used to assess data utility and\nprivacy. The findings indicate that GAN-based approaches dominate the\nliterature, particularly for generating time-series market data and tabular\ncredit data. While several innovative techniques demonstrate potential for\nimproved realism and privacy preservation, there remains a notable lack of\nrigorous evaluation of privacy safeguards across studies. By providing an\nintegrated overview of generative techniques, applications, and evaluation\nmethods, this review highlights critical research gaps and offers guidance for\nfuture work aimed at developing robust, privacy-preserving synthetic data\nsolutions for the financial domain.",
    "categories": [
      "cs.LG"
    ],
    "published": "2025-10-30T02:21:59Z",
    "authors": [
      "James Meldrum",
      "Basem Suleiman",
      "Fethi Rabhi",
      "Muhammad Johan Alibasa"
    ],
    "pdf_url": "http://arxiv.org/pdf/2510.26076v1"
  },
  {
    "id": "2510.26068v1",
    "title": "Learning Geometry: A Framework for Building Adaptive Manifold Models\n  through Metric Optimization",
    "abstract": "This paper proposes a novel paradigm for machine learning that moves beyond\ntraditional parameter optimization. Unlike conventional approaches that search\nfor optimal parameters within a fixed geometric space, our core idea is to\ntreat the model itself as a malleable geometric entity. Specifically, we\noptimize the metric tensor field on a manifold with a predefined topology,\nthereby dynamically shaping the geometric structure of the model space. To\nachieve this, we construct a variational framework whose loss function\ncarefully balances data fidelity against the intrinsic geometric complexity of\nthe manifold. The former ensures the model effectively explains observed data,\nwhile the latter acts as a regularizer, penalizing overly curved or irregular\ngeometries to encourage simpler models and prevent overfitting. To address the\ncomputational challenges of this infinite-dimensional optimization problem, we\nintroduce a practical method based on discrete differential geometry: the\ncontinuous manifold is discretized into a triangular mesh, and the metric\ntensor is parameterized by edge lengths, enabling efficient optimization using\nautomatic differentiation tools. Theoretical analysis reveals a profound\nanalogy between our framework and the Einstein-Hilbert action in general\nrelativity, providing an elegant physical interpretation for the concept of\n\"data-driven geometry\". We further argue that even with fixed topology, metric\noptimization offers significantly greater expressive power than models with\nfixed geometry. This work lays a solid foundation for constructing fully\ndynamic \"meta-learners\" capable of autonomously evolving their geometry and\ntopology, and it points to broad application prospects in areas such as\nscientific model discovery and robust representation learning.",
    "categories": [
      "cs.LG",
      "cs.AI",
      "math.DG",
      "math.ST",
      "stat.TH",
      "68T05, 53B21, 65D18, 62B11",
      "I.2.6; I.5.1; G.1.8; G.4"
    ],
    "published": "2025-10-30T01:53:32Z",
    "authors": [
      "Di Zhang"
    ],
    "pdf_url": "http://arxiv.org/pdf/2510.26068v1"
  },
  {
    "id": "2510.26064v1",
    "title": "Towards Scaling Laws for Symbolic Regression",
    "abstract": "Symbolic regression (SR) aims to discover the underlying mathematical\nexpressions that explain observed data. This holds promise for both gaining\nscientific insight and for producing inherently interpretable and generalizable\nmodels for tabular data. In this work we focus on the basics of SR. Deep\nlearning-based SR has recently become competitive with genetic programming\napproaches, but the role of scale has remained largely unexplored. Inspired by\nscaling laws in language modeling, we present the first systematic\ninvestigation of scaling in SR, using a scalable end-to-end transformer\npipeline and carefully generated training data. Across five different model\nsizes and spanning three orders of magnitude in compute, we find that both\nvalidation loss and solved rate follow clear power-law trends with compute. We\nfurther identify compute-optimal hyperparameter scaling: optimal batch size and\nlearning rate grow with model size, and a token-to-parameter ratio of\n$\\approx$15 is optimal in our regime, with a slight upward trend as compute\nincreases. These results demonstrate that SR performance is largely predictable\nfrom compute and offer important insights for training the next generation of\nSR models.",
    "categories": [
      "cs.LG"
    ],
    "published": "2025-10-30T01:36:44Z",
    "authors": [
      "David Otte",
      "J\u00f6rg K. H. Franke",
      "Frank Hutter"
    ],
    "pdf_url": "http://arxiv.org/pdf/2510.26064v1"
  },
  {
    "id": "2510.26061v1",
    "title": "Data-driven Projection Generation for Efficiently Solving Heterogeneous\n  Quadratic Programming Problems",
    "abstract": "We propose a data-driven framework for efficiently solving quadratic\nprogramming (QP) problems by reducing the number of variables in\nhigh-dimensional QPs using instance-specific projection. A graph neural\nnetwork-based model is designed to generate projections tailored to each QP\ninstance, enabling us to produce high-quality solutions even for previously\nunseen problems. The model is trained on heterogeneous QPs to minimize the\nexpected objective value evaluated on the projected solutions. This is\nformulated as a bilevel optimization problem; the inner optimization solves the\nQP under a given projection using a QP solver, while the outer optimization\nupdates the model parameters. We develop an efficient algorithm to solve this\nbilevel optimization problem, which computes parameter gradients without\nbackpropagating through the solver. We provide a theoretical analysis of the\ngeneralization ability of solving QPs with projection matrices generated by\nneural networks. Experimental results demonstrate that our method produces\nhigh-quality feasible solutions with reduced computation time, outperforming\nexisting methods.",
    "categories": [
      "stat.ML",
      "cs.AI",
      "cs.LG",
      "math.OC"
    ],
    "published": "2025-10-30T01:32:21Z",
    "authors": [
      "Tomoharu Iwata",
      "Futoshi Futami"
    ],
    "pdf_url": "http://arxiv.org/pdf/2510.26061v1"
  },
  {
    "id": "2510.26046v1",
    "title": "Bias-Corrected Data Synthesis for Imbalanced Learning",
    "abstract": "Imbalanced data, where the positive samples represent only a small proportion\ncompared to the negative samples, makes it challenging for classification\nproblems to balance the false positive and false negative rates. A common\napproach to addressing the challenge involves generating synthetic data for the\nminority group and then training classification models with both observed and\nsynthetic data. However, since the synthetic data depends on the observed data\nand fails to replicate the original data distribution accurately, prediction\naccuracy is reduced when the synthetic data is naively treated as the true\ndata. In this paper, we address the bias introduced by synthetic data and\nprovide consistent estimators for this bias by borrowing information from the\nmajority group. We propose a bias correction procedure to mitigate the adverse\neffects of synthetic data, enhancing prediction accuracy while avoiding\noverfitting. This procedure is extended to broader scenarios with imbalanced\ndata, such as imbalanced multi-task learning and causal inference. Theoretical\nproperties, including bounds on bias estimation errors and improvements in\nprediction accuracy, are provided. Simulation results and data analysis on\nhandwritten digit datasets demonstrate the effectiveness of our method.",
    "categories": [
      "stat.ML",
      "cs.LG",
      "stat.ME"
    ],
    "published": "2025-10-30T00:52:25Z",
    "authors": [
      "Pengfei Lyu",
      "Zhengchi Ma",
      "Linjun Zhang",
      "Anru R. Zhang"
    ],
    "pdf_url": "http://arxiv.org/pdf/2510.26046v1"
  },
  {
    "id": "2510.26043v1",
    "title": "$L_1$-norm Regularized Indefinite Kernel Logistic Regression",
    "abstract": "Kernel logistic regression (KLR) is a powerful classification method widely\napplied across diverse domains. In many real-world scenarios, indefinite\nkernels capture more domain-specific structural information than positive\ndefinite kernels. This paper proposes a novel $L_1$-norm regularized indefinite\nkernel logistic regression (RIKLR) model, which extends the existing IKLR\nframework by introducing sparsity via an $L_1$-norm penalty. The introduction\nof this regularization enhances interpretability and generalization while\nintroducing nonsmoothness and nonconvexity into the optimization landscape. To\naddress these challenges, a theoretically grounded and computationally\nefficient proximal linearized algorithm is developed. Experimental results on\nmultiple benchmark datasets demonstrate the superior performance of the\nproposed method in terms of both accuracy and sparsity.",
    "categories": [
      "stat.ML",
      "cs.LG"
    ],
    "published": "2025-10-30T00:44:56Z",
    "authors": [
      "Shaoxin Wang",
      "Hanjing Yao"
    ],
    "pdf_url": "http://arxiv.org/pdf/2510.26043v1"
  },
  {
    "id": "2510.26040v1",
    "title": "Accelerating Real-World Overtaking in F1TENTH Racing Employing\n  Reinforcement Learning Methods",
    "abstract": "While autonomous racing performance in Time-Trial scenarios has seen\nsignificant progress and development, autonomous wheel-to-wheel racing and\novertaking are still severely limited. These limitations are particularly\napparent in real-life driving scenarios where state-of-the-art algorithms\nstruggle to safely or reliably complete overtaking manoeuvres. This is\nimportant, as reliable navigation around other vehicles is vital for safe\nautonomous wheel-to-wheel racing. The F1Tenth Competition provides a useful\nopportunity for developing wheel-to-wheel racing algorithms on a standardised\nphysical platform. The competition format makes it possible to evaluate\novertaking and wheel-to-wheel racing algorithms against the state-of-the-art.\nThis research presents a novel racing and overtaking agent capable of learning\nto reliably navigate a track and overtake opponents in both simulation and\nreality. The agent was deployed on an F1Tenth vehicle and competed against\nopponents running varying competitive algorithms in the real world. The results\ndemonstrate that the agent's training against opponents enables deliberate\novertaking behaviours with an overtaking rate of 87% compared 56% for an agent\ntrained just to race.",
    "categories": [
      "cs.RO",
      "cs.LG"
    ],
    "published": "2025-10-30T00:38:18Z",
    "authors": [
      "Emily Steiner",
      "Daniel van der Spuy",
      "Futian Zhou",
      "Afereti Pama",
      "Minas Liarokapis",
      "Henry Williams"
    ],
    "pdf_url": "http://arxiv.org/pdf/2510.26040v1"
  },
  {
    "id": "2510.26038v1",
    "title": "Do Students Debias Like Teachers? On the Distillability of Bias\n  Mitigation Methods",
    "abstract": "Knowledge distillation (KD) is an effective method for model compression and\ntransferring knowledge between models. However, its effect on model's\nrobustness against spurious correlations that degrade performance on\nout-of-distribution data remains underexplored. This study investigates the\neffect of knowledge distillation on the transferability of ``debiasing''\ncapabilities from teacher models to student models on natural language\ninference (NLI) and image classification tasks. Through extensive experiments,\nwe illustrate several key findings: (i) overall the debiasing capability of a\nmodel is undermined post-KD; (ii) training a debiased model does not benefit\nfrom injecting teacher knowledge; (iii) although the overall robustness of a\nmodel may remain stable post-distillation, significant variations can occur\nacross different types of biases; and (iv) we pin-point the internal attention\npattern and circuit that causes the distinct behavior post-KD. Given the above\nfindings, we propose three effective solutions to improve the distillability of\ndebiasing methods: developing high quality data for augmentation, implementing\niterative knowledge distillation, and initializing student models with weights\nobtained from teacher models. To the best of our knowledge, this is the first\nstudy on the effect of KD on debiasing and its interenal mechanism at scale.\nOur findings provide understandings on how KD works and how to design better\ndebiasing methods.",
    "categories": [
      "cs.LG",
      "cs.AI",
      "cs.CL",
      "cs.CV"
    ],
    "published": "2025-10-30T00:34:16Z",
    "authors": [
      "Jiali Cheng",
      "Chirag Agarwal",
      "Hadi Amiri"
    ],
    "pdf_url": "http://arxiv.org/pdf/2510.26038v1"
  },
  {
    "id": "2510.26026v1",
    "title": "Conformal Prediction Beyond the Horizon: Distribution-Free Inference for\n  Policy Evaluation",
    "abstract": "Reliable uncertainty quantification is crucial for reinforcement learning\n(RL) in high-stakes settings. We propose a unified conformal prediction\nframework for infinite-horizon policy evaluation that constructs\ndistribution-free prediction intervals {for returns} in both on-policy and\noff-policy settings. Our method integrates distributional RL with conformal\ncalibration, addressing challenges such as unobserved returns, temporal\ndependencies, and distributional shifts. We propose a modular pseudo-return\nconstruction based on truncated rollouts and a time-aware calibration strategy\nusing experience replay and weighted subsampling. These innovations mitigate\nmodel bias and restore approximate exchangeability, enabling uncertainty\nquantification even under policy shifts. Our theoretical analysis provides\ncoverage guarantees that account for model misspecification and importance\nweight estimation. Empirical results, including experiments in synthetic and\nbenchmark environments like Mountain Car, show that our method significantly\nimproves coverage and reliability over standard distributional RL baselines.",
    "categories": [
      "stat.ML",
      "cs.LG"
    ],
    "published": "2025-10-29T23:45:44Z",
    "authors": [
      "Feichen Gan",
      "Youcun Lu",
      "Yingying Zhang",
      "Yukun Liu"
    ],
    "pdf_url": "http://arxiv.org/pdf/2510.26026v1"
  },
  {
    "id": "2510.26025v1",
    "title": "Exploring Human-AI Conceptual Alignment through the Prism of Chess",
    "abstract": "Do AI systems truly understand human concepts or merely mimic surface\npatterns? We investigate this through chess, where human creativity meets\nprecise strategic concepts. Analyzing a 270M-parameter transformer that\nachieves grandmaster-level play, we uncover a striking paradox: while early\nlayers encode human concepts like center control and knight outposts with up to\n85\\% accuracy, deeper layers, despite driving superior performance, drift\ntoward alien representations, dropping to 50-65\\% accuracy. To test conceptual\nrobustness beyond memorization, we introduce the first Chess960 dataset: 240\nexpert-annotated positions across 6 strategic concepts. When opening theory is\neliminated through randomized starting positions, concept recognition drops\n10-20\\% across all methods, revealing the model's reliance on memorized\npatterns rather than abstract understanding. Our layer-wise analysis exposes a\nfundamental tension in current architectures: the representations that win\ngames diverge from those that align with human thinking. These findings suggest\nthat as AI systems optimize for performance, they develop increasingly alien\nintelligence, a critical challenge for creative AI applications requiring\ngenuine human-AI collaboration. Dataset and code are available at:\nhttps://github.com/slomasov/ChessConceptsLLM.",
    "categories": [
      "cs.LG"
    ],
    "published": "2025-10-29T23:40:40Z",
    "authors": [
      "Semyon Lomaso",
      "Judah Goldfeder",
      "Mehmet Hamza Erol",
      "Matthew So",
      "Yao Yan",
      "Addison Howard",
      "Nathan Kutz",
      "Ravid Shwartz Ziv"
    ],
    "pdf_url": "http://arxiv.org/pdf/2510.26025v1"
  },
  {
    "id": "2510.26020v1",
    "title": "PORTool: Tool-Use LLM Training with Rewarded Tree",
    "abstract": "Current tool-use large language models (LLMs) are trained on static datasets,\nenabling them to interact with external tools and perform multi-step,\ntool-integrated reasoning, which produces tool-call trajectories. However,\nthese models imitate how a query is resolved in a generic tool-call routine,\nthereby failing to explore possible solutions and demonstrating limited\nperformance in an evolved, dynamic tool-call environment. In this work, we\npropose PORTool, a reinforcement learning (RL) method that encourages a\ntool-use LLM to explore various trajectories yielding the correct answer.\nSpecifically, this method starts with generating multiple rollouts for a given\nquery, and some of them share the first few tool-call steps, thereby forming a\ntree-like structure. Next, we assign rewards to each step, based on its ability\nto produce a correct answer and make successful tool calls. A shared step\nacross different trajectories receives the same reward, while different steps\nunder the same fork receive different rewards. Finally, these step-wise rewards\nare used to calculate fork-relative advantages, blended with\ntrajectory-relative advantages, to train the LLM for tool use. The experiments\nutilize 17 tools to address user queries, covering both time-sensitive and\ntime-invariant topics. We conduct ablation studies to systematically justify\nthe necessity and the design robustness of step-wise rewards. Furthermore, we\ncompare the proposed PORTool with other training approaches and demonstrate\nsignificant improvements in final accuracy and the number of tool-call steps.",
    "categories": [
      "cs.CL",
      "cs.AI",
      "cs.LG"
    ],
    "published": "2025-10-29T23:28:53Z",
    "authors": [
      "Feijie Wu",
      "Weiwu Zhu",
      "Yuxiang Zhang",
      "Soumya Chatterjee",
      "Jiarong Zhu",
      "Fan Mo",
      "Rodin Luo",
      "Jing Gao"
    ],
    "pdf_url": "http://arxiv.org/pdf/2510.26020v1"
  },
  {
    "id": "2510.26014v1",
    "title": "Dual Mixture-of-Experts Framework for Discrete-Time Survival Analysis",
    "abstract": "Survival analysis is a task to model the time until an event of interest\noccurs, widely used in clinical and biomedical research. A key challenge is to\nmodel patient heterogeneity while also adapting risk predictions to both\nindividual characteristics and temporal dynamics. We propose a dual\nmixture-of-experts (MoE) framework for discrete-time survival analysis. Our\napproach combines a feature-encoder MoE for subgroup-aware representation\nlearning with a hazard MoE that leverages patient features and time embeddings\nto capture temporal dynamics. This dual-MoE design flexibly integrates with\nexisting deep learning based survival pipelines. On METABRIC and GBSG breast\ncancer datasets, our method consistently improves performance, boosting the\ntime-dependent C-index up to 0.04 on the test sets, and yields further gains\nwhen incorporated into the Consurv framework.",
    "categories": [
      "cs.LG",
      "cs.AI"
    ],
    "published": "2025-10-29T23:11:01Z",
    "authors": [
      "Hyeonjun Lee",
      "Hyungseob Shin",
      "Gunhee Nam",
      "Hyeonsoo Lee"
    ],
    "pdf_url": "http://arxiv.org/pdf/2510.26014v1"
  },
  {
    "id": "2510.26008v1",
    "title": "Detecting Anomalies in Machine Learning Infrastructure via Hardware\n  Telemetry",
    "abstract": "Modern machine learning (ML) has grown into a tightly coupled, full-stack\necosystem that combines hardware, software, network, and applications. Many\nusers rely on cloud providers for elastic, isolated, and cost-efficient\nresources. Unfortunately, these platforms as a service use virtualization,\nwhich means operators have little insight into the users' workloads. This\nhinders resource optimizations by the operator, which is essential to ensure\ncost efficiency and minimize execution time. In this paper, we argue that\nworkload knowledge is unnecessary for system-level optimization. We propose\nSystem-X, which takes a \\emph{hardware-centric} approach, relying only on\nhardware signals -- fully accessible by operators. Using low-level signals\ncollected from the system, System-X detects anomalies through an unsupervised\nlearning pipeline. The pipeline is developed by analyzing over 30 popular ML\nmodels on various hardware platforms, ensuring adaptability to emerging\nworkloads and unknown deployment patterns. Using System-X, we successfully\nidentified both network and system configuration issues, accelerating the\nDeepSeek model by 5.97%.",
    "categories": [
      "cs.PF",
      "cs.AR",
      "cs.DC",
      "cs.LG"
    ],
    "published": "2025-10-29T22:39:09Z",
    "authors": [
      "Ziji Chen",
      "Steven Chien",
      "Peng Qian",
      "Noa Zilberman"
    ],
    "pdf_url": "http://arxiv.org/pdf/2510.26008v1"
  },
  {
    "id": "2510.26007v1",
    "title": "The Quest for Reliable Metrics of Responsible AI",
    "abstract": "The development of Artificial Intelligence (AI), including AI in Science\n(AIS), should be done following the principles of responsible AI. Progress in\nresponsible AI is often quantified through evaluation metrics, yet there has\nbeen less work on assessing the robustness and reliability of the metrics\nthemselves. We reflect on prior work that examines the robustness of fairness\nmetrics for recommender systems as a type of AI application and summarise their\nkey takeaways into a set of non-exhaustive guidelines for developing reliable\nmetrics of responsible AI. Our guidelines apply to a broad spectrum of AI\napplications, including AIS.",
    "categories": [
      "cs.CY",
      "cs.AI",
      "cs.IR",
      "cs.LG"
    ],
    "published": "2025-10-29T22:35:34Z",
    "authors": [
      "Theresia Veronika Rampisela",
      "Maria Maistro",
      "Tuukka Ruotsalo",
      "Christina Lioma"
    ],
    "pdf_url": "http://arxiv.org/pdf/2510.26007v1"
  },
  {
    "id": "2510.26000v1",
    "title": "Infrequent Exploration in Linear Bandits",
    "abstract": "We study the problem of infrequent exploration in linear bandits, addressing\na significant yet overlooked gap between fully adaptive exploratory methods\n(e.g., UCB and Thompson Sampling), which explore potentially at every time\nstep, and purely greedy approaches, which require stringent diversity\nassumptions to succeed. Continuous exploration can be impractical or unethical\nin safety-critical or costly domains, while purely greedy strategies typically\nfail without adequate contextual diversity. To bridge these extremes, we\nintroduce a simple and practical framework, INFEX, explicitly designed for\ninfrequent exploration. INFEX executes a base exploratory policy according to a\ngiven schedule while predominantly choosing greedy actions in between. Despite\nits simplicity, our theoretical analysis demonstrates that INFEX achieves\ninstance-dependent regret matching standard provably efficient algorithms,\nprovided the exploration frequency exceeds a logarithmic threshold.\nAdditionally, INFEX is a general, modular framework that allows seamless\nintegration of any fully adaptive exploration method, enabling wide\napplicability and ease of adoption. By restricting intensive exploratory\ncomputations to infrequent intervals, our approach can also enhance\ncomputational efficiency. Empirical evaluations confirm our theoretical\nfindings, showing state-of-the-art regret performance and runtime improvements\nover existing methods.",
    "categories": [
      "cs.LG"
    ],
    "published": "2025-10-29T22:25:43Z",
    "authors": [
      "Harin Lee",
      "Min-hwan Oh"
    ],
    "pdf_url": "http://arxiv.org/pdf/2510.26000v1"
  },
  {
    "id": "2510.25993v1",
    "title": "Efficient Online Learning with Predictive Coding Networks: Exploiting\n  Temporal Correlations",
    "abstract": "Robotic systems operating at the edge require efficient online learning\nalgorithms that can continuously adapt to changing environments while\nprocessing streaming sensory data. Traditional backpropagation, while\neffective, conflicts with biological plausibility principles and may be\nsuboptimal for continuous adaptation scenarios. The Predictive Coding (PC)\nframework offers a biologically plausible alternative with local, Hebbian-like\nupdate rules, making it suitable for neuromorphic hardware implementation.\nHowever, PC's main limitation is its computational overhead due to multiple\ninference iterations during training. We present Predictive Coding Network with\nTemporal Amortization (PCN-TA), which preserves latent states across temporal\nframes. By leveraging temporal correlations, PCN-TA significantly reduces\ncomputational demands while maintaining learning performance. Our experiments\non the COIL-20 robotic perception dataset demonstrate that PCN-TA achieves 10%\nfewer weight updates compared to backpropagation and requires 50% fewer\ninference steps than baseline PC networks. These efficiency gains directly\ntranslate to reduced computational overhead for moving another step toward edge\ndeployment and real-time adaptation support in resource-constrained robotic\nsystems. The biologically-inspired nature of our approach also makes it a\npromising candidate for future neuromorphic hardware implementations, enabling\nefficient online learning at the edge.",
    "categories": [
      "cs.LG",
      "cs.NE"
    ],
    "published": "2025-10-29T22:09:53Z",
    "authors": [
      "Darius Masoum Zadeh-Jousdani",
      "Elvin Hajizada",
      "Eyke H\u00fcllermeier"
    ],
    "pdf_url": "http://arxiv.org/pdf/2510.25993v1"
  },
  {
    "id": "2510.25992v1",
    "title": "Supervised Reinforcement Learning: From Expert Trajectories to Step-wise\n  Reasoning",
    "abstract": "Large Language Models (LLMs) often struggle with problems that require\nmulti-step reasoning. For small-scale open-source models, Reinforcement\nLearning with Verifiable Rewards (RLVR) fails when correct solutions are rarely\nsampled even after many attempts, while Supervised Fine-Tuning (SFT) tends to\noverfit long demonstrations through rigid token-by-token imitation. To address\nthis gap, we propose Supervised Reinforcement Learning (SRL), a framework that\nreformulates problem solving as generating a sequence of logical \"actions\". SRL\ntrains the model to generate an internal reasoning monologue before committing\nto each action. It provides smoother rewards based on the similarity between\nthe model's actions and expert actions extracted from the SFT dataset in a\nstep-wise manner. This supervision offers richer learning signals even when all\nrollouts are incorrect, while encouraging flexible reasoning guided by expert\ndemonstrations. As a result, SRL enables small models to learn challenging\nproblems previously unlearnable by SFT or RLVR. Moreover, initializing training\nwith SRL before refining with RLVR yields the strongest overall performance.\nBeyond reasoning benchmarks, SRL generalizes effectively to agentic software\nengineering tasks, establishing it as a robust and versatile training framework\nfor reasoning-oriented LLMs.",
    "categories": [
      "cs.CL",
      "cs.AI",
      "cs.LG"
    ],
    "published": "2025-10-29T22:05:08Z",
    "authors": [
      "Yihe Deng",
      "I-Hung Hsu",
      "Jun Yan",
      "Zifeng Wang",
      "Rujun Han",
      "Gufeng Zhang",
      "Yanfei Chen",
      "Wei Wang",
      "Tomas Pfister",
      "Chen-Yu Lee"
    ],
    "pdf_url": "http://arxiv.org/pdf/2510.25992v1"
  },
  {
    "id": "2510.25986v1",
    "title": "A General and Streamlined Differentiable Optimization Framework",
    "abstract": "Differentiating through constrained optimization problems is increasingly\ncentral to learning, control, and large-scale decision-making systems, yet\npractical integration remains challenging due to solver specialization and\ninterface mismatches. This paper presents a general and streamlined\nframework-an updated DiffOpt.jl-that unifies modeling and differentiation\nwithin the Julia optimization stack. The framework computes forward - and\nreverse-mode solution and objective sensitivities for smooth, potentially\nnonconvex programs by differentiating the KKT system under standard regularity\nassumptions. A first-class, JuMP-native parameter-centric API allows users to\ndeclare named parameters and obtain derivatives directly with respect to them -\neven when a parameter appears in multiple constraints and objectives -\neliminating brittle bookkeeping from coefficient-level interfaces. We\nillustrate these capabilities on convex and nonconvex models, including\neconomic dispatch, mean-variance portfolio selection with conic risk\nconstraints, and nonlinear robot inverse kinematics. Two companion studies\nfurther demonstrate impact at scale: gradient-based iterative methods for\nstrategic bidding in energy markets and Sobolev-style training of end-to-end\noptimization proxies using solver-accurate sensitivities. Together, these\nresults demonstrate that differentiable optimization can be deployed as a\nroutine tool for experimentation, learning, calibration, and design-without\ndeviating from standard JuMP modeling practices and while retaining access to a\nbroad ecosystem of solvers.",
    "categories": [
      "cs.LG",
      "math.OC"
    ],
    "published": "2025-10-29T21:42:36Z",
    "authors": [
      "Andrew W. Rosemberg",
      "Joaquim Dias Garcia",
      "Fran\u00e7ois Pacaud",
      "Robert B. Parker",
      "Beno\u00eet Legat",
      "Kaarthik Sundar",
      "Russell Bent",
      "Pascal Van Hentenryck"
    ],
    "pdf_url": "http://arxiv.org/pdf/2510.25986v1"
  },
  {
    "id": "2510.25983v1",
    "title": "Contrastive Predictive Coding Done Right for Mutual Information\n  Estimation",
    "abstract": "The InfoNCE objective, originally introduced for contrastive representation\nlearning, has become a popular choice for mutual information (MI) estimation,\ndespite its indirect connection to MI. In this paper, we demonstrate why\nInfoNCE should not be regarded as a valid MI estimator, and we introduce a\nsimple modification, which we refer to as InfoNCE-anchor, for accurate MI\nestimation. Our modification introduces an auxiliary anchor class, enabling\nconsistent density ratio estimation and yielding a plug-in MI estimator with\nsignificantly reduced bias. Beyond this, we generalize our framework using\nproper scoring rules, which recover InfoNCE-anchor as a special case when the\nlog score is employed. This formulation unifies a broad spectrum of contrastive\nobjectives, including NCE, InfoNCE, and $f$-divergence variants, under a single\nprincipled framework. Empirically, we find that InfoNCE-anchor with the log\nscore achieves the most accurate MI estimates; however, in self-supervised\nrepresentation learning experiments, we find that the anchor does not improve\nthe downstream task performance. These findings corroborate that contrastive\nrepresentation learning benefits not from accurate MI estimation per se, but\nfrom the learning of structured density ratios.",
    "categories": [
      "cs.LG",
      "cs.IT",
      "math.IT",
      "stat.ML"
    ],
    "published": "2025-10-29T21:33:59Z",
    "authors": [
      "J. Jon Ryu",
      "Pavan Yeddanapudi",
      "Xiangxiang Xu",
      "Gregory W. Wornell"
    ],
    "pdf_url": "http://arxiv.org/pdf/2510.25983v1"
  },
  {
    "id": "2510.25982v1",
    "title": "Enabling Fast and Accurate Neutral Atom Readout through Image Denoising",
    "abstract": "Neutral atom quantum computers hold promise for scaling up to hundreds of\nthousands of qubits, but their progress is constrained by slow qubit readout.\nMeasuring qubits currently takes milliseconds-much longer than the underlying\nquantum gate operations-making readout the primary bottleneck in deploying\nquantum error correction. Because each round of QEC depends on measurement,\nlong readout times increase cycle duration and slow down program execution.\nReducing the readout duration speeds up cycles and reduces decoherence errors\nthat accumulate while qubits idle, but it also lowers the number of collected\nphotons, making measurements noisier and more error-prone. This tradeoff leaves\nneutral atom systems stuck between slow but accurate readout and fast but\nunreliable readout.\n  We show that image denoising can resolve this tension. Our framework,\nGANDALF, uses explicit denoising using image translation to reconstruct clear\nsignals from short, low-photon measurements, enabling reliable classification\nat up to 1.6x shorter readout times. Combined with lightweight classifiers and\na pipelined readout design, our approach both reduces logical error rate by up\nto 35x and overall QEC cycle time up to 1.77x compared to state-of-the-art\nCNN-based readout for Cesium (Cs) Neutral Atom arrays.",
    "categories": [
      "quant-ph",
      "cs.LG"
    ],
    "published": "2025-10-29T21:30:30Z",
    "authors": [
      "Chaithanya Naik Mude",
      "Linipun Phuttitarn",
      "Satvik Maurya",
      "Kunal Sinha",
      "Mark Saffman",
      "Swamit Tannu"
    ],
    "pdf_url": "http://arxiv.org/pdf/2510.25982v1"
  },
  {
    "id": "2510.25979v1",
    "title": "AttnCache: Accelerating Self-Attention Inference for LLM Prefill via\n  Attention Cache",
    "abstract": "Large Language Models (LLMs) are widely used in generative applications such\nas chatting, code generation, and reasoning. However, many realworld workloads\nsuch as classification, question answering, recommendation, and text embedding\nrely solely on the prefill stage of inference, where the model encodes input\nsequences without performing autoregressive decoding. In these prefill only\nscenarios, the self-attention computation becomes the primary performance\nbottleneck due to its quadratic complexity with respect to sequence length. In\nthis paper, we observe that semantically different sentences often produce\nsimilar attention maps across layers and heads. Building on this insight, we\npropose AttnCache, a framework that accelerates the prefill stage of LLM\ninference by retrieving and reusing similar attention maps. Based on an\nattention map memorization database, AttnCache employs efficient caching and\nsimilarity search techniques to identify and reuse pre-cached attention maps\nduring inference, thereby reducing the computational overhead of\nself-attention. Experimental results show that AttnCache achieves an average of\n1.2x end-to-end and 2x attention speedup on CPU, and 1.6x end-to-end and 3x\nattention speedup on GPU, with negligible accuracy degradation.",
    "categories": [
      "cs.CL",
      "cs.LG"
    ],
    "published": "2025-10-29T21:26:17Z",
    "authors": [
      "Dinghong Song",
      "Yuan Feng",
      "Yiwei Wang",
      "Shangye Chen",
      "Cyril Guyot",
      "Filip Blagojevic",
      "Hyeran Jeon",
      "Pengfei Su",
      "Dong Li"
    ],
    "pdf_url": "http://arxiv.org/pdf/2510.25979v1"
  },
  {
    "id": "2510.25974v1",
    "title": "Risks and Opportunities in Human-Machine Teaming in Operationalizing\n  Machine Learning Target Variables",
    "abstract": "Predictive modeling has the potential to enhance human decision-making.\nHowever, many predictive models fail in practice due to problematic problem\nformulation in cases where the prediction target is an abstract concept or\nconstruct and practitioners need to define an appropriate target variable as a\nproxy to operationalize the construct of interest. The choice of an appropriate\nproxy target variable is rarely self-evident in practice, requiring both domain\nknowledge and iterative data modeling. This process is inherently\ncollaborative, involving both domain experts and data scientists. In this work,\nwe explore how human-machine teaming can support this process by accelerating\niterations while preserving human judgment. We study the impact of two\nhuman-machine teaming strategies on proxy construction: 1) relevance-first:\nhumans leading the process by selecting relevant proxies, and 2)\nperformance-first: machines leading the process by recommending proxies based\non predictive performance. Based on a controlled user study of a proxy\nconstruction task (N = 20), we show that the performance-first strategy\nfacilitated faster iterations and decision-making, but also biased users\ntowards well-performing proxies that are misaligned with the application goal.\nOur study highlights the opportunities and risks of human-machine teaming in\noperationalizing machine learning target variables, yielding insights for\nfuture research to explore the opportunities and mitigate the risks.",
    "categories": [
      "cs.HC",
      "cs.LG"
    ],
    "published": "2025-10-29T21:17:50Z",
    "authors": [
      "Mengtian Guo",
      "David Gotz",
      "Yue Wang"
    ],
    "pdf_url": "http://arxiv.org/pdf/2510.25974v1"
  },
  {
    "id": "2510.25962v1",
    "title": "On the Dataless Training of Neural Networks",
    "abstract": "This paper surveys studies on the use of neural networks for optimization in\nthe training-data-free setting. Specifically, we examine the dataless\napplication of neural network architectures in optimization by\nre-parameterizing problems using fully connected (or MLP), convolutional,\ngraph, and quadratic neural networks. Although MLPs have been used to solve\nlinear programs a few decades ago, this approach has recently gained increasing\nattention due to its promising results across diverse applications, including\nthose based on combinatorial optimization, inverse problems, and partial\ndifferential equations. The motivation for this setting stems from two key\n(possibly over-lapping) factors: (i) data-driven learning approaches are still\nunderdeveloped and have yet to demonstrate strong results, as seen in\ncombinatorial optimization, and (ii) the availability of training data is\ninherently limited, such as in medical image reconstruction and other\nscientific applications. In this paper, we define the dataless setting and\ncategorize it into two variants based on how a problem instance -- defined by a\nsingle datum -- is encoded onto the neural network: (i) architecture-agnostic\nmethods and (ii) architecture-specific methods. Additionally, we discuss\nsimilarities and clarify distinctions between the dataless neural network (dNN)\nsettings and related concepts such as zero-shot learning, one-shot learning,\nlifting in optimization, and over-parameterization.",
    "categories": [
      "cs.LG"
    ],
    "published": "2025-10-29T21:01:31Z",
    "authors": [
      "Alvaro Velasquez",
      "Susmit Jha",
      "Ismail R. Alkhouri"
    ],
    "pdf_url": "http://arxiv.org/pdf/2510.25962v1"
  },
  {
    "id": "2510.25954v1",
    "title": "Application and Validation of Geospatial Foundation Model Data for the\n  Prediction of Health Facility Programmatic Outputs -- A Case Study in Malawi",
    "abstract": "The reliability of routine health data in low and middle-income countries\n(LMICs) is often constrained by reporting delays and incomplete coverage,\nnecessitating the exploration of novel data sources and analytics. Geospatial\nFoundation Models (GeoFMs) offer a promising avenue by synthesizing diverse\nspatial, temporal, and behavioral data into mathematical embeddings that can be\nefficiently used for downstream prediction tasks. This study evaluated the\npredictive performance of three GeoFM embedding sources - Google Population\nDynamics Foundation Model (PDFM), Google AlphaEarth (derived from satellite\nimagery), and mobile phone call detail records (CDR) - for modeling 15 routine\nhealth programmatic outputs in Malawi, and compared their utility to\ntraditional geospatial interpolation methods. We used XGBoost models on data\nfrom 552 health catchment areas (January 2021-May 2023), assessing performance\nwith R2, and using an 80/20 training and test data split with 5-fold\ncross-validation used in training. While predictive performance was mixed, the\nembedding-based approaches improved upon baseline geostatistical methods in 13\nof 15 (87%) indicators tested. A Multi-GeoFM model integrating all three\nembedding sources produced the most robust predictions, achieving average\n5-fold cross validated R2 values for indicators like population density (0.63),\nnew HIV cases (0.57), and child vaccinations (0.47) and test set R2 of 0.64,\n0.68, and 0.55, respectively. Prediction was poor for prediction targets with\nlow primary data availability, such as TB and malnutrition cases. These results\ndemonstrate that GeoFM embeddings imbue a modest predictive improvement for\nselect health and demographic outcomes in an LMIC context. We conclude that the\nintegration of multiple GeoFM sources is an efficient and valuable tool for\nsupplementing and strengthening constrained routine health information systems.",
    "categories": [
      "cs.LG",
      "cs.AI",
      "J.3"
    ],
    "published": "2025-10-29T20:53:07Z",
    "authors": [
      "Lynn Metz",
      "Rachel Haggard",
      "Michael Moszczynski",
      "Samer Asbah",
      "Chris Mwase",
      "Patricia Khomani",
      "Tyler Smith",
      "Hannah Cooper",
      "Annie Mwale",
      "Arbaaz Muslim",
      "Gautam Prasad",
      "Mimi Sun",
      "Tomer Shekel",
      "Joydeep Paul",
      "Anna Carter",
      "Shravya Shetty",
      "Dylan Green"
    ],
    "pdf_url": "http://arxiv.org/pdf/2510.25954v1"
  },
  {
    "id": "2510.25952v1",
    "title": "Modular Linear Tokenization (MLT)",
    "abstract": "This paper introduces Modular Linear Tokenization (MLT), a reversible and\ndeterministic technique for encoding high-cardinality categorical identifiers\ninto compact numerical vectors. Unlike traditional hashing or one-hot\nencodings, MLT preserves bijective mappings by leveraging modular arithmetic\nover finite fields and invertible linear transformations. The method offers\nexplicit control of dimensionality and computational scalability while\nmaintaining full reversibility, even for millions of identifiers. Experimental\nresults on the MovieLens 20M dataset show that MLT achieves comparable\npredictive performance to supervised embeddings while requiring significantly\nfewer parameters and lower training cost. An open-source implementation of MLT\nis available on PyPI (https://pypi.org/project/light-mlt/) and GitHub\n(https://github.com/tcharliesschmitz/light-mlt).",
    "categories": [
      "cs.LG"
    ],
    "published": "2025-10-29T20:52:01Z",
    "authors": [
      "Tcharlies Schmitz"
    ],
    "pdf_url": "http://arxiv.org/pdf/2510.25952v1"
  },
  {
    "id": "2510.25947v1",
    "title": "Revisiting Multilingual Data Mixtures in Language Model Pretraining",
    "abstract": "The impact of different multilingual data mixtures in pretraining large\nlanguage models (LLMs) has been a topic of ongoing debate, often raising\nconcerns about potential trade-offs between language coverage and model\nperformance (i.e., the curse of multilinguality). In this work, we investigate\nthese assumptions by training 1.1B and 3B parameter LLMs on diverse\nmultilingual corpora, varying the number of languages from 25 to 400. Our study\nchallenges common beliefs surrounding multilingual training. First, we find\nthat combining English and multilingual data does not necessarily degrade the\nin-language performance of either group, provided that languages have a\nsufficient number of tokens included in the pretraining corpus. Second, we\nobserve that using English as a pivot language (i.e., a high-resource language\nthat serves as a catalyst for multilingual generalization) yields benefits\nacross language families, and contrary to expectations, selecting a pivot\nlanguage from within a specific family does not consistently improve\nperformance for languages within that family. Lastly, we do not observe a\nsignificant \"curse of multilinguality\" as the number of training languages\nincreases in models at this scale. Our findings suggest that multilingual data,\nwhen balanced appropriately, can enhance language model capabilities without\ncompromising performance, even in low-resource settings",
    "categories": [
      "cs.CL",
      "cs.AI",
      "cs.LG"
    ],
    "published": "2025-10-29T20:46:03Z",
    "authors": [
      "Negar Foroutan",
      "Paul Teiletche",
      "Ayush Kumar Tarun",
      "Antoine Bosselut"
    ],
    "pdf_url": "http://arxiv.org/pdf/2510.25947v1"
  },
  {
    "id": "2510.25943v1",
    "title": "InputDSA: Demixing then Comparing Recurrent and Externally Driven\n  Dynamics",
    "abstract": "In control problems and basic scientific modeling, it is important to compare\nobservations with dynamical simulations. For example, comparing two neural\nsystems can shed light on the nature of emergent computations in the brain and\ndeep neural networks. Recently, Ostrow et al. (2023) introduced Dynamical\nSimilarity Analysis (DSA), a method to measure the similarity of two systems\nbased on their recurrent dynamics rather than geometry or topology. However,\nDSA does not consider how inputs affect the dynamics, meaning that two similar\nsystems, if driven differently, may be classified as different. Because\nreal-world dynamical systems are rarely autonomous, it is important to account\nfor the effects of input drive. To this end, we introduce a novel metric for\ncomparing both intrinsic (recurrent) and input-driven dynamics, called InputDSA\n(iDSA). InputDSA extends the DSA framework by estimating and comparing both\ninput and intrinsic dynamic operators using a variant of Dynamic Mode\nDecomposition with control (DMDc) based on subspace identification. We\ndemonstrate that InputDSA can successfully compare partially observed,\ninput-driven systems from noisy data. We show that when the true inputs are\nunknown, surrogate inputs can be substituted without a major deterioration in\nsimilarity estimates. We apply InputDSA on Recurrent Neural Networks (RNNs)\ntrained with Deep Reinforcement Learning, identifying that high-performing\nnetworks are dynamically similar to one another, while low-performing networks\nare more diverse. Lastly, we apply InputDSA to neural data recorded from rats\nperforming a cognitive task, demonstrating that it identifies a transition from\ninput-driven evidence accumulation to intrinsically-driven decision-making. Our\nwork demonstrates that InputDSA is a robust and efficient method for comparing\nintrinsic dynamics and the effect of external input on dynamical systems.",
    "categories": [
      "q-bio.NC",
      "cs.LG",
      "cs.NE",
      "q-bio.QM"
    ],
    "published": "2025-10-29T20:38:03Z",
    "authors": [
      "Ann Huang",
      "Mitchell Ostrow",
      "Satpreet H. Singh",
      "Leo Kozachkov",
      "Ila Fiete",
      "Kanaka Rajan"
    ],
    "pdf_url": "http://arxiv.org/pdf/2510.25943v1"
  },
  {
    "id": "2510.25934v1",
    "title": "Robust GNN Watermarking via Implicit Perception of Topological\n  Invariants",
    "abstract": "Graph Neural Networks (GNNs) are valuable intellectual property, yet many\nwatermarks rely on backdoor triggers that break under common model edits and\ncreate ownership ambiguity. We present InvGNN-WM, which ties ownership to a\nmodel's implicit perception of a graph invariant, enabling trigger-free,\nblack-box verification with negligible task impact. A lightweight head predicts\nnormalized algebraic connectivity on an owner-private carrier set; a\nsign-sensitive decoder outputs bits, and a calibrated threshold controls the\nfalse-positive rate. Across diverse node and graph classification datasets and\nbackbones, InvGNN-WM matches clean accuracy while yielding higher watermark\naccuracy than trigger- and compression-based baselines. It remains strong under\nunstructured pruning, fine-tuning, and post-training quantization; plain\nknowledge distillation (KD) weakens the mark, while KD with a watermark loss\n(KD+WM) restores it. We provide guarantees for imperceptibility and robustness,\nand we prove that exact removal is NP-complete.",
    "categories": [
      "cs.LG",
      "cs.CR"
    ],
    "published": "2025-10-29T20:12:42Z",
    "authors": [
      "Jipeng Li",
      "Yannning Shen"
    ],
    "pdf_url": "http://arxiv.org/pdf/2510.25934v1"
  },
  {
    "id": "2510.25933v1",
    "title": "Humains-Junior: A 3.8B Language Model Achieving GPT-4o-Level Factual\n  Accuracy by Directed Exoskeleton Reasoning",
    "abstract": "We introduce Humans-Junior, a 3.8B model that matches GPT-4o on the FACTS\nGrounding public subset within a $\\pm 5$ pp equivalence margin.\n  Results. On Q1--Q500 under identical judges, GPT-4o scores 73.5% (95% CI\n69.5--77.2) and Humans-Junior 72.7% (95% CI 68.7--76.5); the paired difference\nis 0.8 pp (bootstrap 95% CI $-3.1$ to $+4.7$; permutation $p = 0.72$; Cohen's\n$d = 0.023$). TOST establishes equivalence at $\\pm 5$ pp (not at $\\pm 3$ pp).\nWhen purchased as managed APIs, Humans-Junior's base model\n(Phi-3.5-mini-instruct) is $\\approx 19\\times$ less expensive than GPT-4o on\nMicrosoft AI Foundry pricing; self-hosted or edge deployments can drive\nincremental inference cost toward zero. Measured vs estimated pricing sources\nare tabulated in Appendix E.\n  Method. Our approach combines minimal directed \"Exoskeleton Reasoning\"\nscaffolds with behavioral fine-tuning that teaches protocol compliance\n(epistemic discipline) rather than domain answers. Fine-tuning alone adds\nlittle; combined, they synergize (+17.7 pp, $p < 0.001$) and reduce variance\n($\\approx 25\\%$). In prompt-only settings on frontier models (Q1--Q100;\nnon-comparable), directed reasoning improved GPT-4o by +11.8 pp to 85.3% and\nGemini-2.5-Pro by +5.0 pp to 93.3% (baseline 88.3%, $n = 100$); see Section~5.\n  TL;DR. A 3.8B model achieves GPT-4o-level FACTS accuracy (equivalent within\n$\\pm 5$ pp on Q1--Q500). Cloud pricing shows $\\approx 19\\times$ lower cost\nversus GPT-4o, and self-hosted/edge deployments can approach zero marginal\ncost. Pricing sources are listed in Appendix E. Frontier prompt-only gains\n(Q1--Q100; non-comparable) and optimized-prompt exploratory results under\nearlier judges are summarized in Appendix F.\n  Keywords: Small Language Models, Factual Grounding, Directed Reasoning,\nFine-Tuning, Model Alignment, Cost-Efficient AI",
    "categories": [
      "cs.AI",
      "cs.HC",
      "cs.LG",
      "cs.NE"
    ],
    "published": "2025-10-29T20:12:36Z",
    "authors": [
      "Nissan Yaron",
      "Dan Bystritsky",
      "Ben-Etzion Yaron"
    ],
    "pdf_url": "http://arxiv.org/pdf/2510.25933v1"
  },
  {
    "id": "2510.25926v1",
    "title": "Active Learning with Task-Driven Representations for Messy Pools",
    "abstract": "Active learning has the potential to be especially useful for messy,\nuncurated pools where datapoints vary in relevance to the target task. However,\nstate-of-the-art approaches to this problem currently rely on using fixed,\nunsupervised representations of the pool, focusing on modifying the acquisition\nfunction instead. We show that this model setup can undermine their\neffectiveness at dealing with messy pools, as such representations can fail to\ncapture important information relevant to the task. To address this, we propose\nusing task-driven representations that are periodically updated during the\nactive learning process using the previously collected labels. We introduce two\nspecific strategies for learning these representations, one based on directly\nlearning semi-supervised representations and the other based on supervised\nfine-tuning of an initial unsupervised representation. We find that both\nsignificantly improve empirical performance over using unsupervised or\npretrained representations.",
    "categories": [
      "cs.LG"
    ],
    "published": "2025-10-29T19:54:04Z",
    "authors": [
      "Kianoosh Ashouritaklimi",
      "Tom Rainforth"
    ],
    "pdf_url": "http://arxiv.org/pdf/2510.25926v1"
  },
  {
    "id": "2510.25924v1",
    "title": "Transferring Causal Effects using Proxies",
    "abstract": "We consider the problem of estimating a causal effect in a multi-domain\nsetting. The causal effect of interest is confounded by an unobserved\nconfounder and can change between the different domains. We assume that we have\naccess to a proxy of the hidden confounder and that all variables are discrete\nor categorical. We propose methodology to estimate the causal effect in the\ntarget domain, where we assume to observe only the proxy variable. Under these\nconditions, we prove identifiability (even when treatment and response\nvariables are continuous). We introduce two estimation techniques, prove\nconsistency, and derive confidence intervals. The theoretical results are\nsupported by simulation studies and a real-world example studying the causal\neffect of website rankings on consumer choices.",
    "categories": [
      "cs.LG",
      "cs.AI",
      "stat.ME",
      "stat.ML"
    ],
    "published": "2025-10-29T19:53:51Z",
    "authors": [
      "Manuel Iglesias-Alonso",
      "Felix Schur",
      "Julius von K\u00fcgelgen",
      "Jonas Peters"
    ],
    "pdf_url": "http://arxiv.org/pdf/2510.25924v1"
  },
  {
    "id": "2510.25897v1",
    "title": "MIRO: MultI-Reward cOnditioned pretraining improves T2I quality and\n  efficiency",
    "abstract": "Current text-to-image generative models are trained on large uncurated\ndatasets to enable diverse generation capabilities. However, this does not\nalign well with user preferences. Recently, reward models have been\nspecifically designed to perform post-hoc selection of generated images and\nalign them to a reward, typically user preference. This discarding of\ninformative data together with the optimizing for a single reward tend to harm\ndiversity, semantic fidelity and efficiency. Instead of this post-processing,\nwe propose to condition the model on multiple reward models during training to\nlet the model learn user preferences directly. We show that this not only\ndramatically improves the visual quality of the generated images but it also\nsignificantly speeds up the training. Our proposed method, called MIRO,\nachieves state-of-the-art performances on the GenEval compositional benchmark\nand user-preference scores (PickAScore, ImageReward, HPSv2).",
    "categories": [
      "cs.CV",
      "cs.LG"
    ],
    "published": "2025-10-29T18:59:17Z",
    "authors": [
      "Nicolas Dufour",
      "Lucas Degeorge",
      "Arijit Ghosh",
      "Vicky Kalogeiton",
      "David Picard"
    ],
    "pdf_url": "http://arxiv.org/pdf/2510.25897v1"
  },
  {
    "id": "2510.25892v1",
    "title": "Topology-Aware Active Learning on Graphs",
    "abstract": "We propose a graph-topological approach to active learning that directly\ntargets the core challenge of exploration versus exploitation under scarce\nlabel budgets. To guide exploration, we introduce a coreset construction\nalgorithm based on Balanced Forman Curvature (BFC), which selects\nrepresentative initial labels that reflect the graph's cluster structure. This\nmethod includes a data-driven stopping criterion that signals when the graph\nhas been sufficiently explored. We further use BFC to dynamically trigger the\nshift from exploration to exploitation within active learning routines,\nreplacing hand-tuned heuristics. To improve exploitation, we introduce a\nlocalized graph rewiring strategy that efficiently incorporates multiscale\ninformation around labeled nodes, enhancing label propagation while preserving\nsparsity. Experiments on benchmark classification tasks show that our methods\nconsistently outperform existing graph-based semi-supervised baselines at low\nlabel rates.",
    "categories": [
      "cs.LG"
    ],
    "published": "2025-10-29T18:49:24Z",
    "authors": [
      "Harris Hardiman-Mostow",
      "Jack Mauro",
      "Adrien Weihs",
      "Andrea L. Bertozzi"
    ],
    "pdf_url": "http://arxiv.org/pdf/2510.25892v1"
  },
  {
    "id": "2510.25889v1",
    "title": "$\u03c0_\\texttt{RL}$: Online RL Fine-tuning for Flow-based\n  Vision-Language-Action Models",
    "abstract": "Vision-Language-Action (VLA) models enable robots to understand and perform\ncomplex tasks from multimodal input. Although recent work explores using\nreinforcement learning (RL) to automate the laborious data collection process\nin scaling supervised fine-tuning (SFT), applying large-scale RL to flow-based\nVLAs (e.g., $\\pi_0$, $\\pi_{0.5}$) remains challenging due to intractable action\nlog-likelihoods from iterative denoising.\n  We address this challenge with $\\pi_{\\text{RL}}$, an open-source framework\nfor training flow-based VLAs in parallel simulation. $\\pi_{\\text{RL}}$\nimplements two RL algorithms: (1) {Flow-Noise} models the denoising process as\na discrete-time MDP with a learnable noise network for exact log-likelihood\ncomputation. (2) {Flow-SDE} integrates denoising with agent-environment\ninteraction, formulating a two-layer MDP that employs ODE-to-SDE conversion for\nefficient RL exploration.\n  We evaluate $\\pi_{\\text{RL}}$ on LIBERO and ManiSkill benchmarks. On LIBERO,\n$\\pi_{\\text{RL}}$ boosts few-shot SFT models $\\pi_0$ and $\\pi_{0.5}$ from 57.6%\nto 97.6% and from 77.1% to 98.3%, respectively. In ManiSkill, we train\n$\\pi_{\\text{RL}}$ in 320 parallel environments, improving $\\pi_0$ from 41.6% to\n85.7% and $\\pi_{0.5}$ from 40.0% to 84.8% across 4352 pick-and-place tasks,\ndemonstrating scalable multitask RL under heterogeneous simulation.\n  Overall, $\\pi_{\\text{RL}}$ achieves significant performance gains and\nstronger generalization over SFT-models, validating the effectiveness of online\nRL for flow-based VLAs.",
    "categories": [
      "cs.LG"
    ],
    "published": "2025-10-29T18:37:39Z",
    "authors": [
      "Kang Chen",
      "Zhihao Liu",
      "Tonghe Zhang",
      "Zhen Guo",
      "Si Xu",
      "Hao Lin",
      "Hongzhi Zang",
      "Quanlu Zhang",
      "Zhaofei Yu",
      "Guoliang Fan",
      "Tiejun Huang",
      "Yu Wang",
      "Chao Yu"
    ],
    "pdf_url": "http://arxiv.org/pdf/2510.25889v1"
  },
  {
    "id": "2510.25884v1",
    "title": "Approximating Human Preferences Using a Multi-Judge Learned System",
    "abstract": "Aligning LLM-based judges with human preferences is a significant challenge,\nas they are difficult to calibrate and often suffer from rubric sensitivity,\nbias, and instability. Overcoming this challenge advances key applications,\nsuch as creating reliable reward models for Reinforcement Learning from Human\nFeedback (RLHF) and building effective routing systems that select the\nbest-suited model for a given user query. In this work, we propose a framework\nfor modeling diverse, persona-based preferences by learning to aggregate\noutputs from multiple rubric-conditioned judges. We investigate the performance\nof this approach against naive baselines and assess its robustness through case\nstudies on both human and LLM-judges biases. Our primary contributions include\na persona-based method for synthesizing preference labels at scale and two\ndistinct implementations of our aggregator: Generalized Additive Model (GAM)\nand a Multi-Layer Perceptron (MLP).",
    "categories": [
      "cs.AI",
      "cs.CL",
      "cs.LG"
    ],
    "published": "2025-10-29T18:32:53Z",
    "authors": [
      "Eit\u00e1n Sprejer",
      "Fernando Avalos",
      "Augusto Bernardi",
      "Jose Pedro Brito de Azevedo Faustino",
      "Jacob Haimes",
      "Narmeen Fatimah Oozeer"
    ],
    "pdf_url": "http://arxiv.org/pdf/2510.25884v1"
  },
  {
    "id": "2510.25867v1",
    "title": "MedVLSynther: Synthesizing High-Quality Visual Question Answering from\n  Medical Documents with Generator-Verifier LMMs",
    "abstract": "Large Multimodal Models (LMMs) are increasingly capable of answering medical\nquestions that require joint reasoning over images and text, yet training\ngeneral medical VQA systems is impeded by the lack of large, openly usable,\nhigh-quality corpora. We present MedVLSynther, a rubric-guided\ngenerator-verifier framework that synthesizes high-quality multiple-choice VQA\nitems directly from open biomedical literature by conditioning on figures,\ncaptions, and in-text references. The generator produces self-contained stems\nand parallel, mutually exclusive options under a machine-checkable JSON schema;\na multi-stage verifier enforces essential gates (self-containment, single\ncorrect answer, clinical validity, image-text consistency), awards fine-grained\npositive points, and penalizes common failure modes before acceptance. Applying\nthis pipeline to PubMed Central yields MedSynVQA: 13,087 audited questions over\n14,803 images spanning 13 imaging modalities and 28 anatomical regions.\nTraining open-weight LMMs with reinforcement learning using verifiable rewards\nimproves accuracy across six medical VQA benchmarks, achieving averages of\n55.85 (3B) and 58.15 (7B), with up to 77.57 on VQA-RAD and 67.76 on PathVQA,\noutperforming strong medical LMMs. A Ablations verify that both generation and\nverification are necessary and that more verified data consistently helps, and\na targeted contamination analysis detects no leakage from evaluation suites. By\noperating entirely on open literature and open-weight models, MedVLSynther\noffers an auditable, reproducible, and privacy-preserving path to scalable\nmedical VQA training data.",
    "categories": [
      "cs.LG"
    ],
    "published": "2025-10-29T18:10:44Z",
    "authors": [
      "Xiaoke Huang",
      "Ningsen Wang",
      "Hui Liu",
      "Xianfeng Tang",
      "Yuyin Zhou"
    ],
    "pdf_url": "http://arxiv.org/pdf/2510.25867v1"
  },
  {
    "id": "2510.25850v1",
    "title": "Debate2Create: Robot Co-design via Large Language Model Debates",
    "abstract": "Automating the co-design of a robot's morphology and control is a\nlong-standing challenge due to the vast design space and the tight coupling\nbetween body and behavior. We introduce Debate2Create (D2C), a framework in\nwhich large language model (LLM) agents engage in a structured dialectical\ndebate to jointly optimize a robot's design and its reward function. In each\nround, a design agent proposes targeted morphological modifications, and a\ncontrol agent devises a reward function tailored to exploit the new design. A\npanel of pluralistic judges then evaluates the design-control pair in\nsimulation and provides feedback that guides the next round of debate. Through\niterative debates, the agents progressively refine their proposals, producing\nincreasingly effective robot designs. Notably, D2C yields diverse and\nspecialized morphologies despite no explicit diversity objective. On a\nquadruped locomotion benchmark, D2C discovers designs that travel 73% farther\nthan the default, demonstrating that structured LLM-based debate can serve as a\npowerful mechanism for emergent robot co-design. Our results suggest that\nmulti-agent debate, when coupled with physics-grounded feedback, is a promising\nnew paradigm for automated robot design.",
    "categories": [
      "cs.RO",
      "cs.LG",
      "cs.MA"
    ],
    "published": "2025-10-29T18:00:16Z",
    "authors": [
      "Kevin Qiu",
      "Marek Cygan"
    ],
    "pdf_url": "http://arxiv.org/pdf/2510.25850v1"
  },
  {
    "id": "2510.25770v1",
    "title": "E-Scores for (In)Correctness Assessment of Generative Model Outputs",
    "abstract": "While generative models, especially large language models (LLMs), are\nubiquitous in today's world, principled mechanisms to assess their\n(in)correctness are limited. Using the conformal prediction framework, previous\nworks construct sets of LLM responses where the probability of including an\nincorrect response, or error, is capped at a desired user-defined tolerance\nlevel. However, since these methods are based on p-values, they are susceptible\nto p-hacking, i.e., choosing the tolerance level post-hoc can invalidate the\nguarantees. We therefore leverage e-values to complement generative model\noutputs with e-scores as a measure of incorrectness. In addition to achieving\nthe same statistical guarantees as before, e-scores provide users flexibility\nin adaptively choosing tolerance levels after observing the e-scores\nthemselves, by upper bounding a post-hoc notion of error called size\ndistortion. We experimentally demonstrate their efficacy in assessing LLM\noutputs for different correctness types: mathematical factuality and property\nconstraints satisfaction.",
    "categories": [
      "stat.ML",
      "cs.AI",
      "cs.LG"
    ],
    "published": "2025-10-29T17:59:16Z",
    "authors": [
      "Guneet S. Dhillon",
      "Javier Gonz\u00e1lez",
      "Teodora Pandeva",
      "Alicia Curth"
    ],
    "pdf_url": "http://arxiv.org/pdf/2510.25770v1"
  },
  {
    "id": "2510.25769v1",
    "title": "Neural Stochastic Flows: Solver-Free Modelling and Inference for SDE\n  Solutions",
    "abstract": "Stochastic differential equations (SDEs) are well suited to modelling noisy\nand irregularly sampled time series found in finance, physics, and machine\nlearning. Traditional approaches require costly numerical solvers to sample\nbetween arbitrary time points. We introduce Neural Stochastic Flows (NSFs) and\ntheir latent variants, which directly learn (latent) SDE transition laws using\nconditional normalising flows with architectural constraints that preserve\nproperties inherited from stochastic flows. This enables one-shot sampling\nbetween arbitrary states and yields up to two orders of magnitude speed-ups at\nlarge time gaps. Experiments on synthetic SDE simulations and on real-world\ntracking and video data show that NSFs maintain distributional accuracy\ncomparable to numerical approaches while dramatically reducing computation for\narbitrary time-point sampling.",
    "categories": [
      "cs.LG",
      "stat.ML"
    ],
    "published": "2025-10-29T17:59:06Z",
    "authors": [
      "Naoki Kiyohara",
      "Edward Johns",
      "Yingzhen Li"
    ],
    "pdf_url": "http://arxiv.org/pdf/2510.25769v1"
  },
  {
    "id": "2510.25759v1",
    "title": "Synthetic Data Reveals Generalization Gaps in Correlated Multiple\n  Instance Learning",
    "abstract": "Multiple instance learning (MIL) is often used in medical imaging to classify\nhigh-resolution 2D images by processing patches or classify 3D volumes by\nprocessing slices. However, conventional MIL approaches treat instances\nseparately, ignoring contextual relationships such as the appearance of nearby\npatches or slices that can be essential in real applications. We design a\nsynthetic classification task where accounting for adjacent instance features\nis crucial for accurate prediction. We demonstrate the limitations of\noff-the-shelf MIL approaches by quantifying their performance compared to the\noptimal Bayes estimator for this task, which is available in closed-form. We\nempirically show that newer correlated MIL methods still struggle to generalize\nas well as possible when trained from scratch on tens of thousands of\ninstances.",
    "categories": [
      "cs.LG"
    ],
    "published": "2025-10-29T17:55:17Z",
    "authors": [
      "Ethan Harvey",
      "Dennis Johan Loevlie",
      "Michael C. Hughes"
    ],
    "pdf_url": "http://arxiv.org/pdf/2510.25759v1"
  },
  {
    "id": "2510.25755v1",
    "title": "MLPrE -- A tool for preprocessing and exploratory data analysis prior to\n  machine learning model construction",
    "abstract": "With the recent growth of Deep Learning for AI, there is a need for tools to\nmeet the demand of data flowing into those models. In some cases, source data\nmay exist in multiple formats, and therefore the source data must be\ninvestigated and properly engineered for a Machine Learning model or graph\ndatabase. Overhead and lack of scalability with existing workflows limit\nintegration within a larger processing pipeline such as Apache Airflow, driving\nthe need for a robust, extensible, and lightweight tool to preprocess arbitrary\ndatasets that scales with data type and size. To address this, we present\nMachine Learning Preprocessing and Exploratory Data Analysis, MLPrE, in which\nSparkDataFrames were utilized to hold data during processing and ensure\nscalability. A generalizable JSON input file format was utilized to describe\nstepwise changes to that DataFrame. Stages were implemented for input and\noutput, filtering, basic statistics, feature engineering, and exploratory data\nanalysis. A total of 69 stages were implemented into MLPrE, of which we\nhighlight and demonstrate key stages using six diverse datasets. We further\nhighlight MLPrE's ability to independently process multiple fields in flat\nfiles and recombine them, otherwise requiring an additional pipeline, using a\nUniProt glossary term dataset. Building on this advantage, we demonstrated the\nclustering stage with available wine quality data. Lastly, we demonstrate the\npreparation of data for a graph database in the final stages of MLPrE using\nphosphosite kinase data. Overall, our MLPrE tool offers a generalizable and\nscalable tool for preprocessing and early data analysis, filling a critical\nneed for such a tool given the ever expanding use of machine learning. This\ntool serves to accelerate and simplify early stage development in larger\nworkflows.",
    "categories": [
      "cs.LG"
    ],
    "published": "2025-10-29T17:52:39Z",
    "authors": [
      "David S Maxwell",
      "Michael Darkoh",
      "Sidharth R Samudrala",
      "Caroline Chung",
      "Stephanie T Schmidt",
      "Bissan Al-Lazikani"
    ],
    "pdf_url": "http://arxiv.org/pdf/2510.25755v1"
  },
  {
    "id": "2510.25753v1",
    "title": "How Data Mixing Shapes In-Context Learning: Asymptotic Equivalence for\n  Transformers with MLPs",
    "abstract": "Pretrained Transformers demonstrate remarkable in-context learning (ICL)\ncapabilities, enabling them to adapt to new tasks from demonstrations without\nparameter updates. However, theoretical studies often rely on simplified\narchitectures (e.g., omitting MLPs), data models (e.g., linear regression with\nisotropic inputs), and single-source training, limiting their relevance to\nrealistic settings. In this work, we study ICL in pretrained Transformers with\nnonlinear MLP heads on nonlinear tasks drawn from multiple data sources with\nheterogeneous input, task, and noise distributions. We analyze a model where\nthe MLP comprises two layers, with the first layer trained via a single\ngradient step and the second layer fully optimized. Under high-dimensional\nasymptotics, we prove that such models are equivalent in ICL error to\nstructured polynomial predictors, leveraging results from the theory of\nGaussian universality and orthogonal polynomials. This equivalence reveals that\nnonlinear MLPs meaningfully enhance ICL performance, particularly on nonlinear\ntasks, compared to linear baselines. It also enables a precise analysis of data\nmixing effects: we identify key properties of high-quality data sources (low\nnoise, structured covariances) and show that feature learning emerges only when\nthe task covariance exhibits sufficient structure. These results are validated\nempirically across various activation functions, model sizes, and data\ndistributions. Finally, we experiment with a real-world scenario involving\nmultilingual sentiment analysis where each language is treated as a different\nsource. Our experimental results for this case exemplify how our findings\nextend to real-world cases. Overall, our work advances the theoretical\nfoundations of ICL in Transformers and provides actionable insight into the\nrole of architecture and data in ICL.",
    "categories": [
      "stat.ML",
      "cs.LG"
    ],
    "published": "2025-10-29T17:51:57Z",
    "authors": [
      "Samet Demir",
      "Zafer Dogan"
    ],
    "pdf_url": "http://arxiv.org/pdf/2510.25753v1"
  },
  {
    "id": "2510.25752v1",
    "title": "Meshless solutions of PDE inverse problems on irregular geometries",
    "abstract": "Solving inverse and optimization problems over solutions of nonlinear partial\ndifferential equations (PDEs) on complex spatial domains is a long-standing\nchallenge. Here we introduce a method that parameterizes the solution using\nspectral bases on arbitrary spatiotemporal domains, whereby the basis is\ndefined on a hyperrectangle containing the true domain. We find the\ncoefficients of the basis expansion by solving an optimization problem whereby\nboth the equations, the boundary conditions and any optimization targets are\nenforced by a loss function, building on a key idea from Physics-Informed\nNeural Networks (PINNs). Since the representation of the function natively has\nexponential convergence, so does the solution of the optimization problem, as\nlong as it can be solved efficiently. We find empirically that the optimization\nprotocols developed for machine learning find solutions with exponential\nconvergence on a wide range of equations. The method naturally allows for the\nincorporation of data assimilation by including additional terms in the loss\nfunction, and for the efficient solution of optimization problems over the PDE\nsolutions.",
    "categories": [
      "math.NA",
      "cs.LG",
      "cs.NA",
      "physics.comp-ph"
    ],
    "published": "2025-10-29T17:49:40Z",
    "authors": [
      "James V. Roggeveen",
      "Michael P. Brenner"
    ],
    "pdf_url": "http://arxiv.org/pdf/2510.25752v1"
  },
  {
    "id": "2510.25739v1",
    "title": "Hawk: Leveraging Spatial Context for Faster Autoregressive Text-to-Image\n  Generation",
    "abstract": "Autoregressive (AR) image generation models are capable of producing\nhigh-fidelity images but often suffer from slow inference due to their\ninherently sequential, token-by-token decoding process. Speculative decoding,\nwhich employs a lightweight draft model to approximate the output of a larger\nAR model, has shown promise in accelerating text generation without\ncompromising quality. However, its application to image generation remains\nlargely underexplored. The challenges stem from a significantly larger sampling\nspace, which complicates the alignment between the draft and target model\noutputs, coupled with the inadequate use of the two-dimensional spatial\nstructure inherent in images, thereby limiting the modeling of local\ndependencies. To overcome these challenges, we introduce Hawk, a new approach\nthat harnesses the spatial structure of images to guide the speculative model\ntoward more accurate and efficient predictions. Experimental results on\nmultiple text-to-image benchmarks demonstrate a 1.71x speedup over standard AR\nmodels, while preserving both image fidelity and diversity.",
    "categories": [
      "cs.CV",
      "cs.LG"
    ],
    "published": "2025-10-29T17:43:31Z",
    "authors": [
      "Zhi-Kai Chen",
      "Jun-Peng Jiang",
      "Han-Jia Ye",
      "De-Chuan Zhan"
    ],
    "pdf_url": "http://arxiv.org/pdf/2510.25739v1"
  },
  {
    "id": "2510.25731v1",
    "title": "LieSolver: A PDE-constrained solver for IBVPs using Lie symmetries",
    "abstract": "We introduce a method for efficiently solving initial-boundary value problems\n(IBVPs) that uses Lie symmetries to enforce the associated partial differential\nequation (PDE) exactly by construction. By leveraging symmetry transformations,\nthe model inherently incorporates the physical laws and learns solutions from\ninitial and boundary data. As a result, the loss directly measures the model's\naccuracy, leading to improved convergence. Moreover, for well-posed IBVPs, our\nmethod enables rigorous error estimation. The approach yields compact models,\nfacilitating an efficient optimization. We implement LieSolver and demonstrate\nits application to linear homogeneous PDEs with a range of initial conditions,\nshowing that it is faster and more accurate than physics-informed neural\nnetworks (PINNs). Overall, our method improves both computational efficiency\nand the reliability of predictions for PDE-constrained problems.",
    "categories": [
      "cs.LG",
      "cs.AI",
      "cs.NA",
      "math.NA",
      "physics.comp-ph"
    ],
    "published": "2025-10-29T17:37:27Z",
    "authors": [
      "Ren\u00e9 P. Klausen",
      "Ivan Timofeev",
      "Johannes Frank",
      "Jonas Naujoks",
      "Thomas Wiegand",
      "Sebastian Lapuschkin",
      "Wojciech Samek"
    ],
    "pdf_url": "http://arxiv.org/pdf/2510.25731v1"
  },
  {
    "id": "2510.25729v1",
    "title": "Physics-Guided Conditional Diffusion Networks for Microwave Image\n  Reconstruction",
    "abstract": "A conditional latent-diffusion based framework for solving the\nelectromagnetic inverse scattering problem associated with microwave imaging is\nintroduced. This generative machine-learning model explicitly mirrors the\nnon-uniqueness of the ill-posed inverse problem. Unlike existing inverse\nsolvers utilizing deterministic machine learning techniques that produce a\nsingle reconstruction, the proposed latent-diffusion model generates multiple\nplausible permittivity maps conditioned on measured scattered-field data,\nthereby generating several potential instances in the range-space of the\nnon-unique inverse mapping. A forward electromagnetic solver is integrated into\nthe reconstruction pipeline as a physics-based evaluation mechanism. The space\nof candidate reconstructions form a distribution of possibilities consistent\nwith the conditioning data and the member of this space yielding the lowest\nscattered-field data discrepancy between the predicted and measured scattered\nfields is reported as the final solution. Synthetic and experimental labeled\ndatasets are used for training and evaluation of the model. An innovative\nlabeled synthetic dataset is created that exemplifies a varied set of\nscattering features. Training of the model using this new dataset produces high\nquality permittivity reconstructions achieving improved generalization with\nexcellent fidelity to shape recognition. The results highlight the potential of\nhybrid generative physics frameworks as a promising direction for robust,\ndata-driven microwave imaging.",
    "categories": [
      "eess.IV",
      "cs.AI",
      "cs.LG",
      "eess.SP"
    ],
    "published": "2025-10-29T17:34:10Z",
    "authors": [
      "Shirin Chehelgami",
      "Joe LoVetri",
      "Vahab Khoshdel"
    ],
    "pdf_url": "http://arxiv.org/pdf/2510.25729v1"
  },
  {
    "id": "2510.25818v1",
    "title": "ScaleDiff: Higher-Resolution Image Synthesis via Efficient and\n  Model-Agnostic Diffusion",
    "abstract": "Text-to-image diffusion models often exhibit degraded performance when\ngenerating images beyond their training resolution. Recent training-free\nmethods can mitigate this limitation, but they often require substantial\ncomputation or are incompatible with recent Diffusion Transformer models. In\nthis paper, we propose ScaleDiff, a model-agnostic and highly efficient\nframework for extending the resolution of pretrained diffusion models without\nany additional training. A core component of our framework is Neighborhood\nPatch Attention (NPA), an efficient mechanism that reduces computational\nredundancy in the self-attention layer with non-overlapping patches. We\nintegrate NPA into an SDEdit pipeline and introduce Latent Frequency Mixing\n(LFM) to better generate fine details. Furthermore, we apply Structure Guidance\nto enhance global structure during the denoising process. Experimental results\ndemonstrate that ScaleDiff achieves state-of-the-art performance among\ntraining-free methods in terms of both image quality and inference speed on\nboth U-Net and Diffusion Transformer architectures.",
    "categories": [
      "cs.LG",
      "cs.AI"
    ],
    "published": "2025-10-29T17:17:32Z",
    "authors": [
      "Sungho Koh",
      "SeungJu Cha",
      "Hyunwoo Oh",
      "Kwanyoung Lee",
      "Dong-Jin Kim"
    ],
    "pdf_url": "http://arxiv.org/pdf/2510.25818v1"
  },
  {
    "id": "2510.25704v1",
    "title": "Scaling flow-based approaches for topology sampling in $\\mathrm{SU}(3)$\n  gauge theory",
    "abstract": "We develop a methodology based on out-of-equilibrium simulations to mitigate\ntopological freezing when approaching the continuum limit of lattice gauge\ntheories. We reduce the autocorrelation of the topological charge employing\nopen boundary conditions, while removing exactly their unphysical effects using\na non-equilibrium Monte Carlo approach in which periodic boundary conditions\nare gradually switched on. We perform a detailed analysis of the computational\ncosts of this strategy in the case of the four-dimensional $\\mathrm{SU}(3)$\nYang-Mills theory. After achieving full control of the scaling, we outline a\nclear strategy to sample topology efficiently in the continuum limit, which we\ncheck at lattice spacings as small as $0.045$ fm. We also generalize this\napproach by designing a customized Stochastic Normalizing Flow for evolutions\nin the boundary conditions, obtaining superior performances with respect to the\npurely stochastic non-equilibrium approach, and paving the way for more\nefficient future flow-based solutions.",
    "categories": [
      "hep-lat",
      "cond-mat.stat-mech",
      "cs.LG",
      "hep-ph"
    ],
    "published": "2025-10-29T17:12:21Z",
    "authors": [
      "Claudio Bonanno",
      "Andrea Bulgarelli",
      "Elia Cellini",
      "Alessandro Nada",
      "Dario Panfalone",
      "Davide Vadacchino",
      "Lorenzo Verzichelli"
    ],
    "pdf_url": "http://arxiv.org/pdf/2510.25704v1"
  },
  {
    "id": "2510.25696v1",
    "title": "Convolutional Spiking-based GRU Cell for Spatio-temporal Data",
    "abstract": "Spike-based temporal messaging enables SNNs to efficiently process both\npurely temporal and spatio-temporal time-series or event-driven data. Combining\nSNNs with Gated Recurrent Units (GRUs), a variant of recurrent neural networks,\ngives rise to a robust framework for sequential data processing; however,\ntraditional RNNs often lose local details when handling long sequences.\nPrevious approaches, such as SpikGRU, fail to capture fine-grained local\ndependencies in event-based spatio-temporal data. In this paper, we introduce\nthe Convolutional Spiking GRU (CS-GRU) cell, which leverages convolutional\noperations to preserve local structure and dependencies while integrating the\ntemporal precision of spiking neurons with the efficient gating mechanisms of\nGRUs. This versatile architecture excels on both temporal datasets (NTIDIGITS,\nSHD) and spatio-temporal benchmarks (MNIST, DVSGesture, CIFAR10DVS). Our\nexperiments show that CS-GRU outperforms state-of-the-art GRU variants by an\naverage of 4.35%, achieving over 90% accuracy on sequential tasks and up to\n99.31% on MNIST. It is worth noting that our solution achieves 69% higher\nefficiency compared to SpikGRU. The code is available at:\nhttps://github.com/YesmineAbdennadher/CS-GRU.",
    "categories": [
      "cs.LG"
    ],
    "published": "2025-10-29T17:00:36Z",
    "authors": [
      "Yesmine Abdennadher",
      "Eleonora Cicciarella",
      "Michele Rossi"
    ],
    "pdf_url": "http://arxiv.org/pdf/2510.25696v1"
  },
  {
    "id": "2510.25693v1",
    "title": "PyDPF: A Python Package for Differentiable Particle Filtering",
    "abstract": "State-space models (SSMs) are a widely used tool in time series analysis. In\nthe complex systems that arise from real-world data, it is common to employ\nparticle filtering (PF), an efficient Monte Carlo method for estimating the\nhidden state corresponding to a sequence of observations. Applying particle\nfiltering requires specifying both the parametric form and the parameters of\nthe system, which are often unknown and must be estimated. Gradient-based\noptimisation techniques cannot be applied directly to standard particle\nfilters, as the filters themselves are not differentiable. However, several\nrecently proposed methods modify the resampling step to make particle filtering\ndifferentiable. In this paper, we present an implementation of several such\ndifferentiable particle filters (DPFs) with a unified API built on the popular\nPyTorch framework. Our implementation makes these algorithms easily accessible\nto a broader research community and facilitates straightforward comparison\nbetween them. We validate our framework by reproducing experiments from several\nexisting studies and demonstrate how DPFs can be applied to address several\ncommon challenges with state space modelling.",
    "categories": [
      "eess.SP",
      "cs.LG",
      "60-04",
      "G.3"
    ],
    "published": "2025-10-29T16:57:54Z",
    "authors": [
      "John-Joseph Brady",
      "Benjamin Cox",
      "V\u00edctor Elvira",
      "Yunpeng Li"
    ],
    "pdf_url": "http://arxiv.org/pdf/2510.25693v1"
  },
  {
    "id": "2510.25692v1",
    "title": "A Configuration-First Framework for Reproducible, Low-Code Localization",
    "abstract": "Machine learning is increasingly permeating radio-based localization\nservices. To keep results credible and comparable, everyday workflows should\nmake rigorous experiment specification and exact repeatability the default,\nwithout blocking advanced experimentation. However, in practice, researchers\nface a three-way gap that could be filled by a framework that offers (i) low\ncoding effort for end-to-end studies, (ii) reproducibility by default including\nversioned code, data, and configurations, controlled randomness, isolated runs,\nand recorded artifacts, and (iii) built-in extensibility so new models,\nmetrics, and stages can be added with minimal integration effort. Existing\ntools rarely deliver all three for machine learning in general and localization\nworkflows in particular. In this paper we introduce LOCALIZE, a low-code,\nconfiguration-first framework for radio localization in which experiments are\ndeclared in human-readable configuration, a workflow orchestrator runs\nstandardized pipelines from data preparation to reporting, and all artifacts,\nsuch as datasets, models, metrics, and reports, are versioned. The\npreconfigured, versioned datasets reduce initial setup and boilerplate,\nspeeding up model development and evaluation. The design, with clear extension\npoints, allows experts to add components without reworking the infrastructure.\nIn a qualitative comparison and a head-to-head study against a plain Jupyter\nnotebook baseline, we show that the framework reduces authoring effort while\nmaintaining comparable runtime and memory behavior. Furthermore, using a\nBluetooth Low Energy dataset, we show that scaling across training data (1x to\n10x) keeps orchestration overheads bounded as data grows. Overall, the\nframework makes reproducible machine-learning-based localization\nexperimentation practical, accessible, and extensible.",
    "categories": [
      "cs.SE",
      "cs.LG",
      "D.2.6; I.2.6"
    ],
    "published": "2025-10-29T16:57:33Z",
    "authors": [
      "Tim Strnad",
      "Bla\u017e Bertalani\u010d",
      "Carolina Fortuna"
    ],
    "pdf_url": "http://arxiv.org/pdf/2510.25692v1"
  },
  {
    "id": "2510.25687v1",
    "title": "Model Inversion Attacks Meet Cryptographic Fuzzy Extractors",
    "abstract": "Model inversion attacks pose an open challenge to privacy-sensitive\napplications that use machine learning (ML) models. For example, face\nauthentication systems use modern ML models to compute embedding vectors from\nface images of the enrolled users and store them. If leaked, inversion attacks\ncan accurately reconstruct user faces from the leaked vectors. There is no\nsystematic characterization of properties needed in an ideal defense against\nmodel inversion, even for the canonical example application of a face\nauthentication system susceptible to data breaches, despite a decade of\nbest-effort solutions.\n  In this paper, we formalize the desired properties of a provably strong\ndefense against model inversion and connect it, for the first time, to the\ncryptographic concept of fuzzy extractors. We further show that existing fuzzy\nextractors are insecure for use in ML-based face authentication. We do so\nthrough a new model inversion attack called PIPE, which achieves a success rate\nof over 89% in most cases against prior schemes. We then propose L2FE-Hash, the\nfirst candidate fuzzy extractor which supports standard Euclidean distance\ncomparators as needed in many ML-based applications, including face\nauthentication. We formally characterize its computational security guarantees,\neven in the extreme threat model of full breach of stored secrets, and\nempirically show its usable accuracy in face authentication for practical face\ndistributions. It offers attack-agnostic security without requiring any\nre-training of the ML model it protects. Empirically, it nullifies both prior\nstate-of-the-art inversion attacks as well as our new PIPE attack.",
    "categories": [
      "cs.CR",
      "cs.LG"
    ],
    "published": "2025-10-29T16:50:54Z",
    "authors": [
      "Mallika Prabhakar",
      "Louise Xu",
      "Prateek Saxena"
    ],
    "pdf_url": "http://arxiv.org/pdf/2510.25687v1"
  },
  {
    "id": "2510.25683v1",
    "title": "Graph Network-based Structural Simulator: Graph Neural Networks for\n  Structural Dynamics",
    "abstract": "Graph Neural Networks (GNNs) have recently been explored as surrogate models\nfor numerical simulations. While their applications in computational fluid\ndynamics have been investigated, little attention has been given to structural\nproblems, especially for dynamic cases. To address this gap, we introduce the\nGraph Network-based Structural Simulator (GNSS), a GNN framework for surrogate\nmodeling of dynamic structural problems.\n  GNSS follows the encode-process-decode paradigm typical of GNN-based machine\nlearning models, and its design makes it particularly suited for dynamic\nsimulations thanks to three key features: (i) expressing node kinematics in\nnode-fixed local frames, which avoids catastrophic cancellation in\nfinite-difference velocities; (ii) employing a sign-aware regression loss,\nwhich reduces phase errors in long rollouts; and (iii) using a\nwavelength-informed connectivity radius, which optimizes graph construction.\n  We evaluate GNSS on a case study involving a beam excited by a 50kHz\nHanning-modulated pulse. The results show that GNSS accurately reproduces the\nphysics of the problem over hundreds of timesteps and generalizes to unseen\nloading conditions, where existing GNNs fail to converge or deliver meaningful\npredictions.\n  Compared with explicit finite element baselines, GNSS achieves substantial\ninference speedups while preserving spatial and temporal fidelity. These\nfindings demonstrate that locality-preserving GNNs with physics-consistent\nupdate rules are a competitive alternative for dynamic, wave-dominated\nstructural simulations.",
    "categories": [
      "cs.LG",
      "cs.AI",
      "cs.CE",
      "physics.comp-ph"
    ],
    "published": "2025-10-29T16:47:24Z",
    "authors": [
      "Alessandro Lucchetti",
      "Francesco Cadini",
      "Marco Giglio",
      "Luca Lomazzi"
    ],
    "pdf_url": "http://arxiv.org/pdf/2510.25683v1"
  },
  {
    "id": "2510.25674v1",
    "title": "Mechanistic Interpretability of RNNs emulating Hidden Markov Models",
    "abstract": "Recurrent neural networks (RNNs) provide a powerful approach in neuroscience\nto infer latent dynamics in neural populations and to generate hypotheses about\nthe neural computations underlying behavior. However, past work has focused on\nrelatively simple, input-driven, and largely deterministic behaviors - little\nis known about the mechanisms that would allow RNNs to generate the richer,\nspontaneous, and potentially stochastic behaviors observed in natural settings.\nModeling with Hidden Markov Models (HMMs) has revealed a segmentation of\nnatural behaviors into discrete latent states with stochastic transitions\nbetween them, a type of dynamics that may appear at odds with the continuous\nstate spaces implemented by RNNs. Here we first show that RNNs can replicate\nHMM emission statistics and then reverse-engineer the trained networks to\nuncover the mechanisms they implement. In the absence of inputs, the activity\nof trained RNNs collapses towards a single fixed point. When driven by\nstochastic input, trajectories instead exhibit noise-sustained dynamics along\nclosed orbits. Rotation along these orbits modulates the emission probabilities\nand is governed by transitions between regions of slow, noise-driven dynamics\nconnected by fast, deterministic transitions. The trained RNNs develop highly\nstructured connectivity, with a small set of \"kick neurons\" initiating\ntransitions between these regions. This mechanism emerges during training as\nthe network shifts into a regime of stochastic resonance, enabling it to\nperform probabilistic computations. Analyses across multiple HMM architectures\n- fully connected, cyclic, and linear-chain - reveal that this solution\ngeneralizes through the modular reuse of the same dynamical motif, suggesting a\ncompositional principle by which RNNs can emulate complex discrete latent\ndynamics.",
    "categories": [
      "cs.LG"
    ],
    "published": "2025-10-29T16:42:07Z",
    "authors": [
      "Elia Torre",
      "Michele Viscione",
      "Lucas Pompe",
      "Benjamin F Grewe",
      "Valerio Mante"
    ],
    "pdf_url": "http://arxiv.org/pdf/2510.25674v1"
  },
  {
    "id": "2510.25816v1",
    "title": "Beyond Long Context: When Semantics Matter More than Tokens",
    "abstract": "Electronic Health Records (EHR) store clinical documentation as base64\nencoded attachments in FHIR DocumentReference resources, which makes semantic\nquestion answering difficult. Traditional vector database methods often miss\nnuanced clinical relationships. The Clinical Entity Augmented Retrieval (CLEAR)\nmethod, introduced by Lopez et al. 2025, uses entity aware retrieval and\nachieved improved performance with an F1 score of 0.90 versus 0.86 for\nembedding based retrieval, while using over 70 percent fewer tokens. We\ndeveloped a Clinical Notes QA Evaluation Platform to validate CLEAR against\nzero shot large context inference and traditional chunk based retrieval\naugmented generation. The platform was tested on 12 clinical notes ranging from\n10,000 to 65,000 tokens representing realistic EHR content. CLEAR achieved a\n58.3 percent win rate, an average semantic similarity of 0.878, and used 78\npercent fewer tokens than wide context processing. The largest performance\ngains occurred on long notes, with a 75 percent win rate for documents\nexceeding 65,000 tokens. These findings confirm that entity aware retrieval\nimproves both efficiency and accuracy in clinical natural language processing.\nThe evaluation framework provides a reusable and transparent benchmark for\nassessing clinical question answering systems where semantic precision and\ncomputational efficiency are critical.",
    "categories": [
      "cs.CL",
      "cs.LG",
      "68T50, 68T07",
      "I.2.7; H.3.3"
    ],
    "published": "2025-10-29T16:41:44Z",
    "authors": [
      "Tarun Kumar Chawdhury",
      "Jon D. Duke"
    ],
    "pdf_url": "http://arxiv.org/pdf/2510.25816v1"
  },
  {
    "id": "2510.25670v1",
    "title": "Spectral Perturbation Bounds for Low-Rank Approximation with\n  Applications to Privacy",
    "abstract": "A central challenge in machine learning is to understand how noise or\nmeasurement errors affect low-rank approximations, particularly in the spectral\nnorm. This question is especially important in differentially private low-rank\napproximation, where one aims to preserve the top-$p$ structure of a\ndata-derived matrix while ensuring privacy. Prior work often analyzes Frobenius\nnorm error or changes in reconstruction quality, but these metrics can over- or\nunder-estimate true subspace distortion. The spectral norm, by contrast,\ncaptures worst-case directional error and provides the strongest utility\nguarantees. We establish new high-probability spectral-norm perturbation bounds\nfor symmetric matrices that refine the classical Eckart--Young--Mirsky theorem\nand explicitly capture interactions between a matrix $A \\in \\mathbb{R}^{n\n\\times n}$ and an arbitrary symmetric perturbation $E$. Under mild eigengap and\nnorm conditions, our bounds yield sharp estimates for $\\|(A + E)_p - A_p\\|$,\nwhere $A_p$ is the best rank-$p$ approximation of $A$, with improvements of up\nto a factor of $\\sqrt{n}$. As an application, we derive improved utility\nguarantees for differentially private PCA, resolving an open problem in the\nliterature. Our analysis relies on a novel contour bootstrapping method from\ncomplex analysis and extends it to a broad class of spectral functionals,\nincluding polynomials and matrix exponentials. Empirical results on real-world\ndatasets confirm that our bounds closely track the actual spectral error under\ndiverse perturbation regimes.",
    "categories": [
      "cs.LG",
      "cs.CR",
      "cs.DS",
      "cs.NA",
      "math.NA",
      "math.SP"
    ],
    "published": "2025-10-29T16:36:00Z",
    "authors": [
      "Phuc Tran",
      "Nisheeth K. Vishnoi",
      "Van H. Vu"
    ],
    "pdf_url": "http://arxiv.org/pdf/2510.25670v1"
  },
  {
    "id": "2510.25657v1",
    "title": "Subgraph Federated Learning via Spectral Methods",
    "abstract": "We consider the problem of federated learning (FL) with graph-structured data\ndistributed across multiple clients. In particular, we address the prevalent\nscenario of interconnected subgraphs, where interconnections between clients\nsignificantly influence the learning process. Existing approaches suffer from\ncritical limitations, either requiring the exchange of sensitive node\nembeddings, thereby posing privacy risks, or relying on\ncomputationally-intensive steps, which hinders scalability. To tackle these\nchallenges, we propose FedLap, a novel framework that leverages global\nstructure information via Laplacian smoothing in the spectral domain to\neffectively capture inter-node dependencies while ensuring privacy and\nscalability. We provide a formal analysis of the privacy of FedLap,\ndemonstrating that it preserves privacy. Notably, FedLap is the first subgraph\nFL scheme with strong privacy guarantees. Extensive experiments on benchmark\ndatasets demonstrate that FedLap achieves competitive or superior utility\ncompared to existing techniques.",
    "categories": [
      "cs.LG",
      "cs.AI",
      "cs.IT",
      "math.IT"
    ],
    "published": "2025-10-29T16:22:32Z",
    "authors": [
      "Javad Aliakbari",
      "Johan \u00d6stman",
      "Ashkan Panahi",
      "Alexandre Graell i Amat"
    ],
    "pdf_url": "http://arxiv.org/pdf/2510.25657v1"
  },
  {
    "id": "2510.25648v1",
    "title": "Continuous subsurface property retrieval from sparse radar observations\n  using physics informed neural networks",
    "abstract": "Estimating subsurface dielectric properties is essential for applications\nranging from environmental surveys of soils to nondestructive evaluation of\nconcrete in infrastructure. Conventional wave inversion methods typically\nassume few discrete homogeneous layers and require dense measurements or strong\nprior knowledge of material boundaries, limiting scalability and accuracy in\nrealistic settings where properties vary continuously. We present a physics\ninformed machine learning framework that reconstructs subsurface permittivity\nas a fully neural, continuous function of depth, trained to satisfy both\nmeasurement data and Maxwells equations. We validate the framework with both\nsimulations and custom built radar experiments on multilayered natural\nmaterials. Results show close agreement with in-situ permittivity measurements\n(R^2=0.93), with sensitivity to even subtle variations (Delta eps_r=2).\nParametric analysis reveals that accurate profiles can be recovered with as few\nas three strategically placed sensors in two layer systems. This approach\nreframes subsurface inversion from boundary-driven to continuous property\nestimation, enabling accurate characterization of smooth permittivity\nvariations and advancing electromagnetic imaging using low cost radar systems.",
    "categories": [
      "eess.SP",
      "cs.LG"
    ],
    "published": "2025-10-29T16:09:24Z",
    "authors": [
      "Ishfaq Aziz",
      "Mohamad Alipour"
    ],
    "pdf_url": "http://arxiv.org/pdf/2510.25648v1"
  },
  {
    "id": "2510.25626v1",
    "title": "Are Language Models Efficient Reasoners? A Perspective from Logic\n  Programming",
    "abstract": "Modern language models (LMs) exhibit strong deductive reasoning capabilities,\nyet standard evaluations emphasize correctness while overlooking a key aspect\nof human-like reasoning: efficiency. In real-world reasoning scenarios, much of\nthe available information is irrelevant, and effective deductive inference\nrequires identifying and ignoring such distractions. We propose a framework for\nassessing LM reasoning efficiency through the lens of logic programming,\nintroducing a simple method to align proofs written in natural language -- as\ngenerated by an LM -- with shortest proofs found by executing the logic\nprogram. Efficiency is quantified by measuring how well a model avoids\nunnecessary inference. Empirically, we construct a dataset of math word\nproblems injected with various number of irrelevant axioms that vary in\nsemantic overlap with the goal theorem. We find that current LMs show marked\naccuracy declines under such conditions -- even with minimal, domain-consistent\ndistractions -- and the proofs they generate frequently exhibit detours through\nirrelevant inferences.",
    "categories": [
      "cs.CL",
      "cs.AI",
      "cs.LG",
      "cs.LO"
    ],
    "published": "2025-10-29T15:30:31Z",
    "authors": [
      "Andreas Opedal",
      "Yanick Zengaffinen",
      "Haruki Shirakami",
      "Clemente Pasti",
      "Mrinmaya Sachan",
      "Abulhair Saparov",
      "Ryan Cotterell",
      "Bernhard Sch\u00f6lkopf"
    ],
    "pdf_url": "http://arxiv.org/pdf/2510.25626v1"
  },
  {
    "id": "2510.25616v1",
    "title": "Don't Blind Your VLA: Aligning Visual Representations for OOD\n  Generalization",
    "abstract": "The growing success of Vision-Language-Action (VLA) models stems from the\npromise that pretrained Vision-Language Models (VLMs) can endow agents with\ntransferable world knowledge and vision-language (VL) grounding, laying a\nfoundation for action models with broader generalization. Yet when these VLMs\nare adapted to the action modality, it remains unclear to what extent their\noriginal VL representations and knowledge are preserved. In this work, we\nconduct a systematic study of representation retention during VLA fine-tuning,\nshowing that naive action fine-tuning leads to degradation of visual\nrepresentations. To characterize and measure these effects, we probe VLA's\nhidden representations and analyze attention maps, further, we design a set of\ntargeted tasks and methods that contrast VLA models with their counterpart\nVLMs, isolating changes in VL capabilities induced by action fine-tuning. We\nfurther evaluate a range of strategies for aligning visual representations and\nintroduce a simple yet effective method that mitigates degradation and yields\nimproved generalization to out-of-distribution (OOD) scenarios. Taken together,\nour analysis clarifies the trade-off between action fine-tuning and the\ndegradation of VL representations and highlights practical approaches to\nrecover inherited VL capabilities. Code is publicly available:\nhttps://blind-vla-paper.github.io",
    "categories": [
      "cs.LG",
      "cs.AI",
      "cs.RO"
    ],
    "published": "2025-10-29T15:20:10Z",
    "authors": [
      "Nikita Kachaev",
      "Mikhail Kolosov",
      "Daniil Zelezetsky",
      "Alexey K. Kovalev",
      "Aleksandr I. Panov"
    ],
    "pdf_url": "http://arxiv.org/pdf/2510.25616v1"
  },
  {
    "id": "2510.25609v1",
    "title": "BOLT-GAN: Bayes-Optimal Loss for Stable GAN Training",
    "abstract": "We introduce BOLT-GAN, a simple yet effective modification of the WGAN\nframework inspired by the Bayes Optimal Learning Threshold (BOLT). We show that\nwith a Lipschitz continuous discriminator, BOLT-GAN implicitly minimizes a\ndifferent metric distance than the Earth Mover (Wasserstein) distance and\nachieves better training stability. Empirical evaluations on four standard\nimage generation benchmarks (CIFAR-10, CelebA-64, LSUN Bedroom-64, and LSUN\nChurch-64) show that BOLT-GAN consistently outperforms WGAN, achieving 10-60%\nlower Frechet Inception Distance (FID). Our results suggest that BOLT is a\nbroadly applicable principle for enhancing GAN training.",
    "categories": [
      "cs.LG",
      "cs.AI",
      "eess.SP",
      "68T07",
      "I.2.6; I.5.1"
    ],
    "published": "2025-10-29T15:16:50Z",
    "authors": [
      "Mohammadreza Tavasoli Naeini",
      "Ali Bereyhi",
      "Morteza Noshad",
      "Ben Liang",
      "Alfred O. Hero III"
    ],
    "pdf_url": "http://arxiv.org/pdf/2510.25609v1"
  },
  {
    "id": "2510.25602v1",
    "title": "INT v.s. FP: A Comprehensive Study of Fine-Grained Low-bit Quantization\n  Formats",
    "abstract": "Modern AI hardware, such as Nvidia's Blackwell architecture, is increasingly\nembracing low-precision floating-point (FP) formats to handle the pervasive\nactivation outliers in Large Language Models (LLMs). Despite this industry\ntrend, a unified comparison of FP and integer (INT) quantization across varying\ngranularities has been missing, leaving algorithm and hardware co-design\nwithout clear guidance. This paper fills that gap by systematically\ninvestigating the trade-offs between FP and INT formats. We reveal a critical\nperformance crossover: while FP excels in coarse-grained quantization, the\ncomparison at fine-grained (block-wise) levels is more nuanced. Our\ncomprehensive comparison demonstrates that for popular 8-bit fine-grained\nformats (e.g., MX with block size 32), MXINT8 is superior to its FP counterpart\nin both algorithmic accuracy and hardware efficiency. However, for 4-bit\nformats, FP (e.g., MXFP4, NVFP4) often holds an accuracy advantage , though we\nshow that NVINT4 can surpass NVFP4 when outlier-mitigation techniques like\nHadamard rotation are applied. We also introduce a symmetric clipping method\nthat resolves gradient bias in fine-grained low-bit INT training, enabling\nnearly lossless performance for MXINT8 training. These findings challenge the\ncurrent hardware trajectory, demonstrating that a one-size-fits-all FP approach\nis suboptimal and advocating that fine-grained INT formats, particularly\nMXINT8, offer a better balance of accuracy, power, and efficiency for future AI\naccelerators.",
    "categories": [
      "cs.LG",
      "cs.AI"
    ],
    "published": "2025-10-29T15:11:53Z",
    "authors": [
      "Mengzhao Chen",
      "Meng Wu",
      "Hui Jin",
      "Zhihang Yuan",
      "Jing Liu",
      "Chaoyi Zhang",
      "Yunshui Li",
      "Jie Huang",
      "Jin Ma",
      "Zeyue Xue",
      "Zhiheng Liu",
      "Xingyan Bin",
      "Ping Luo"
    ],
    "pdf_url": "http://arxiv.org/pdf/2510.25602v1"
  },
  {
    "id": "2510.25599v1",
    "title": "Uncertainty Quantification for Regression: A Unified Framework based on\n  kernel scores",
    "abstract": "Regression tasks, notably in safety-critical domains, require proper\nuncertainty quantification, yet the literature remains largely\nclassification-focused. In this light, we introduce a family of measures for\ntotal, aleatoric, and epistemic uncertainty based on proper scoring rules, with\na particular emphasis on kernel scores. The framework unifies several\nwell-known measures and provides a principled recipe for designing new ones\nwhose behavior, such as tail sensitivity, robustness, and out-of-distribution\nresponsiveness, is governed by the choice of kernel. We prove explicit\ncorrespondences between kernel-score characteristics and downstream behavior,\nyielding concrete design guidelines for task-specific measures. Extensive\nexperiments demonstrate that these measures are effective in downstream tasks\nand reveal clear trade-offs among instantiations, including robustness and\nout-of-distribution detection performance.",
    "categories": [
      "cs.LG"
    ],
    "published": "2025-10-29T15:08:41Z",
    "authors": [
      "Christopher B\u00fclte",
      "Yusuf Sale",
      "Gitta Kutyniok",
      "Eyke H\u00fcllermeier"
    ],
    "pdf_url": "http://arxiv.org/pdf/2510.25599v1"
  },
  {
    "id": "2510.25594v1",
    "title": "Feedback Alignment Meets Low-Rank Manifolds: A Structured Recipe for\n  Local Learning",
    "abstract": "Training deep neural networks (DNNs) with backpropagation (BP) achieves\nstate-of-the-art accuracy but requires global error propagation and full\nparameterization, leading to substantial memory and computational overhead.\nDirect Feedback Alignment (DFA) enables local, parallelizable updates with\nlower memory requirements but is limited by unstructured feedback and poor\nscalability in deeper architectures, specially convolutional neural networks.\nTo address these limitations, we propose a structured local learning framework\nthat operates directly on low-rank manifolds defined by the Singular Value\nDecomposition (SVD) of weight matrices. Each layer is trained in its decomposed\nform, with updates applied to the SVD components using a composite loss that\nintegrates cross-entropy, subspace alignment, and orthogonality regularization.\nFeedback matrices are constructed to match the SVD structure, ensuring\nconsistent alignment between forward and feedback pathways. Our method reduces\nthe number of trainable parameters relative to the original DFA model, without\nrelying on pruning or post hoc compression. Experiments on CIFAR-10, CIFAR-100,\nand ImageNet show that our method achieves accuracy comparable to that of BP.\nAblation studies confirm the importance of each loss term in the low-rank\nsetting. These results establish local learning on low-rank manifolds as a\nprincipled and scalable alternative to full-rank gradient-based training.",
    "categories": [
      "cs.LG",
      "cs.CV"
    ],
    "published": "2025-10-29T15:03:46Z",
    "authors": [
      "Arani Roy",
      "Marco P. Apolinario",
      "Shristi Das Biswas",
      "Kaushik Roy"
    ],
    "pdf_url": "http://arxiv.org/pdf/2510.25594v1"
  },
  {
    "id": "2510.25591v1",
    "title": "Generalized Sobolev IPM for Graph-Based Measures",
    "abstract": "We study the Sobolev IPM problem for measures supported on a graph metric\nspace, where critic function is constrained to lie within the unit ball defined\nby Sobolev norm. While Le et al. (2025) achieved scalable computation by\nrelating Sobolev norm to weighted $L^p$-norm, the resulting framework remains\nintrinsically bound to $L^p$ geometric structure, limiting its ability to\nincorporate alternative structural priors beyond the $L^p$ geometry paradigm.\nTo overcome this limitation, we propose to generalize Sobolev IPM through the\nlens of \\emph{Orlicz geometric structure}, which employs convex functions to\ncapture nuanced geometric relationships, building upon recent advances in\noptimal transport theory -- particularly Orlicz-Wasserstein (OW) and\ngeneralized Sobolev transport -- that have proven instrumental in advancing\nmachine learning methodologies. This generalization encompasses classical\nSobolev IPM as a special case while accommodating diverse geometric priors\nbeyond traditional $L^p$ structure. It however brings up significant\ncomputational hurdles that compound those already inherent in Sobolev IPM. To\naddress these challenges, we establish a novel theoretical connection between\nOrlicz-Sobolev norm and Musielak norm which facilitates a novel regularization\nfor the generalized Sobolev IPM (GSI). By further exploiting the underlying\ngraph structure, we show that GSI with Musielak regularization (GSI-M) reduces\nto a simple \\emph{univariate optimization} problem, achieving remarkably\ncomputational efficiency. Empirically, GSI-M is several-order faster than the\npopular OW in computation, and demonstrates its practical advantages in\ncomparing probability measures on a given graph for document classification and\nseveral tasks in topological data analysis.",
    "categories": [
      "cs.LG",
      "stat.ML"
    ],
    "published": "2025-10-29T14:59:26Z",
    "authors": [
      "Tam Le",
      "Truyen Nguyen",
      "Hideitsu Hino",
      "Kenji Fukumizu"
    ],
    "pdf_url": "http://arxiv.org/pdf/2510.25591v1"
  },
  {
    "id": "2510.25582v1",
    "title": "Learning-Augmented Online Bidding in Stochastic Settings",
    "abstract": "Online bidding is a classic optimization problem, with several applications\nin online decision-making, the design of interruptible systems, and the\nanalysis of approximation algorithms. In this work, we study online bidding\nunder learning-augmented settings that incorporate stochasticity, in either the\nprediction oracle or the algorithm itself. In the first part, we study bidding\nunder distributional predictions, and find Pareto-optimal algorithms that offer\nthe best-possible tradeoff between the consistency and the robustness of the\nalgorithm. In the second part, we study the power and limitations of randomized\nbidding algorithms, by presenting upper and lower bounds on the\nconsistency/robustness tradeoffs. Previous works focused predominantly on\noracles that do not leverage stochastic information on the quality of the\nprediction, and deterministic algorithms.",
    "categories": [
      "cs.GT",
      "cs.LG"
    ],
    "published": "2025-10-29T14:47:18Z",
    "authors": [
      "Spyros Angelopoulos",
      "Bertrand Simon"
    ],
    "pdf_url": "http://arxiv.org/pdf/2510.25582v1"
  },
  {
    "id": "2510.25573v1",
    "title": "Monitoring the calibration of probability forecasts with an application\n  to concept drift detection involving image classification",
    "abstract": "Machine learning approaches for image classification have led to impressive\nadvances in that field. For example, convolutional neural networks are able to\nachieve remarkable image classification accuracy across a wide range of\napplications in industry, defense, and other areas. While these machine\nlearning models boast impressive accuracy, a related concern is how to assess\nand maintain calibration in the predictions these models make. A classification\nmodel is said to be well calibrated if its predicted probabilities correspond\nwith the rates events actually occur. While there are many available methods to\nassess machine learning calibration and recalibrate faulty predictions, less\neffort has been spent on developing approaches that continually monitor\npredictive models for potential loss of calibration as time passes. We propose\na cumulative sum-based approach with dynamic limits that enable detection of\nmiscalibration in both traditional process monitoring and concept drift\napplications. This enables early detection of operational context changes that\nimpact image classification performance in the field. The proposed chart can be\nused broadly in any situation where the user needs to monitor probability\npredictions over time for potential lapses in calibration. Importantly, our\nmethod operates on probability predictions and event outcomes and does not\nrequire under-the-hood access to the machine learning model.",
    "categories": [
      "stat.ML",
      "cs.LG"
    ],
    "published": "2025-10-29T14:42:10Z",
    "authors": [
      "Christopher T. Franck",
      "Anne R. Driscoll",
      "Zoe Szajnfarber",
      "William H. Woodall"
    ],
    "pdf_url": "http://arxiv.org/pdf/2510.25573v1"
  },
  {
    "id": "2510.25814v1",
    "title": "Optimizing Mirror-Image Peptide Sequence Design for Data Storage via\n  Peptide Bond Cleavage Prediction",
    "abstract": "Traditional non-biological storage media, such as hard drives, face\nlimitations in both storage density and lifespan due to the rapid growth of\ndata in the big data era. Mirror-image peptides composed of D-amino acids have\nemerged as a promising biological storage medium due to their high storage\ndensity, structural stability, and long lifespan. The sequencing of\nmirror-image peptides relies on \\textit{de-novo} technology. However, its\naccuracy is limited by the scarcity of tandem mass spectrometry datasets and\nthe challenges that current algorithms encounter when processing these peptides\ndirectly. This study is the first to propose improving sequencing accuracy\nindirectly by optimizing the design of mirror-image peptide sequences. In this\nwork, we introduce DBond, a deep neural network based model that integrates\nsequence features, precursor ion properties, and mass spectrometry\nenvironmental factors for the prediction of mirror-image peptide bond cleavage.\nIn this process, sequences with a high peptide bond cleavage ratio, which are\neasy to sequence, are selected. The main contributions of this study are as\nfollows. First, we constructed MiPD513, a tandem mass spectrometry dataset\ncontaining 513 mirror-image peptides. Second, we developed the peptide bond\ncleavage labeling algorithm (PBCLA), which generated approximately 12.5 million\nlabeled data based on MiPD513. Third, we proposed a dual prediction strategy\nthat combines multi-label and single-label classification. On an independent\ntest set, the single-label classification strategy outperformed other methods\nin both single and multiple peptide bond cleavage prediction tasks, offering a\nstrong foundation for sequence optimization.",
    "categories": [
      "q-bio.QM",
      "cs.LG"
    ],
    "published": "2025-10-29T14:40:13Z",
    "authors": [
      "Yilong Lu",
      "Si Chen",
      "Songyan Gao",
      "Han Liu",
      "Xin Dong",
      "Wenfeng Shen",
      "Guangtai Ding"
    ],
    "pdf_url": "http://arxiv.org/pdf/2510.25814v1"
  },
  {
    "id": "2510.25571v1",
    "title": "Perturbation Bounds for Low-Rank Inverse Approximations under Noise",
    "abstract": "Low-rank pseudoinverses are widely used to approximate matrix inverses in\nscalable machine learning, optimization, and scientific computing. However,\nreal-world matrices are often observed with noise, arising from sampling,\nsketching, and quantization. The spectral-norm robustness of low-rank inverse\napproximations remains poorly understood. We systematically study the\nspectral-norm error $\\| (\\tilde{A}^{-1})_p - A_p^{-1} \\|$ for an $n\\times n$\nsymmetric matrix $A$, where $A_p^{-1}$ denotes the best rank-\\(p\\)\napproximation of $A^{-1}$, and $\\tilde{A} = A + E$ is a noisy observation.\nUnder mild assumptions on the noise, we derive sharp non-asymptotic\nperturbation bounds that reveal how the error scales with the eigengap,\nspectral decay, and noise alignment with low-curvature directions of $A$. Our\nanalysis introduces a novel application of contour integral techniques to the\n\\emph{non-entire} function $f(z) = 1/z$, yielding bounds that improve over\nnaive adaptations of classical full-inverse bounds by up to a factor of\n$\\sqrt{n}$. Empirically, our bounds closely track the true perturbation error\nacross a variety of real-world and synthetic matrices, while estimates based on\nclassical results tend to significantly overpredict. These findings offer\npractical, spectrum-aware guarantees for low-rank inverse approximations in\nnoisy computational environments.",
    "categories": [
      "cs.LG",
      "cs.DS",
      "cs.NA",
      "math.NA",
      "math.SP",
      "math.ST",
      "stat.TH"
    ],
    "published": "2025-10-29T14:40:12Z",
    "authors": [
      "Phuc Tran",
      "Nisheeth K. Vishnoi"
    ],
    "pdf_url": "http://arxiv.org/pdf/2510.25571v1"
  },
  {
    "id": "2510.25569v1",
    "title": "A Framework for Bounding Deterministic Risk with PAC-Bayes: Applications\n  to Majority Votes",
    "abstract": "PAC-Bayes is a popular and efficient framework for obtaining generalization\nguarantees in situations involving uncountable hypothesis spaces.\nUnfortunately, in its classical formulation, it only provides guarantees on the\nexpected risk of a randomly sampled hypothesis. This requires stochastic\npredictions at test time, making PAC-Bayes unusable in many practical\nsituations where a single deterministic hypothesis must be deployed. We propose\na unified framework to extract guarantees holding for a single hypothesis from\nstochastic PAC-Bayesian guarantees. We present a general oracle bound and\nderive from it a numerical bound and a specialization to majority vote. We\nempirically show that our approach consistently outperforms popular baselines\n(by up to a factor of 2) when it comes to generalization bounds on\ndeterministic classifiers.",
    "categories": [
      "cs.LG"
    ],
    "published": "2025-10-29T14:38:35Z",
    "authors": [
      "Benjamin Leblanc",
      "Pascal Germain"
    ],
    "pdf_url": "http://arxiv.org/pdf/2510.25569v1"
  },
  {
    "id": "2510.25566v1",
    "title": "PitchFlower: A flow-based neural audio codec with pitch controllability",
    "abstract": "We present PitchFlower, a flow-based neural audio codec with explicit pitch\ncontrollability. Our approach enforces disentanglement through a simple\nperturbation: during training, F0 contours are flattened and randomly shifted,\nwhile the true F0 is provided as conditioning. A vector-quantization bottleneck\nprevents pitch recovery, and a flow-based decoder generates high quality audio.\nExperiments show that PitchFlower achieves more accurate pitch control than\nWORLD at much higher audio quality, and outperforms SiFiGAN in controllability\nwhile maintaining comparable quality. Beyond pitch, this framework provides a\nsimple and extensible path toward disentangling other speech attributes.",
    "categories": [
      "eess.AS",
      "cs.LG"
    ],
    "published": "2025-10-29T14:33:35Z",
    "authors": [
      "Diego Torres",
      "Axel Roebel",
      "Nicolas Obin"
    ],
    "pdf_url": "http://arxiv.org/pdf/2510.25566v1"
  },
  {
    "id": "2510.25563v1",
    "title": "Leveraging an Atmospheric Foundational Model for Subregional Sea Surface\n  Temperature Forecasting",
    "abstract": "The accurate prediction of oceanographic variables is crucial for\nunderstanding climate change, managing marine resources, and optimizing\nmaritime activities. Traditional ocean forecasting relies on numerical models;\nhowever, these approaches face limitations in terms of computational cost and\nscalability. In this study, we adapt Aurora, a foundational deep learning model\noriginally designed for atmospheric forecasting, to predict sea surface\ntemperature (SST) in the Canary Upwelling System. By fine-tuning this model\nwith high-resolution oceanographic reanalysis data, we demonstrate its ability\nto capture complex spatiotemporal patterns while reducing computational\ndemands. Our methodology involves a staged fine-tuning process, incorporating\nlatitude-weighted error metrics and optimizing hyperparameters for efficient\nlearning. The experimental results show that the model achieves a low RMSE of\n0.119K, maintaining high anomaly correlation coefficients (ACC $\\approx\n0.997$). The model successfully reproduces large-scale SST structures but faces\nchallenges in capturing finer details in coastal regions. This work contributes\nto the field of data-driven ocean forecasting by demonstrating the feasibility\nof using deep learning models pre-trained in different domains for oceanic\napplications. Future improvements include integrating additional oceanographic\nvariables, increasing spatial resolution, and exploring physics-informed neural\nnetworks to enhance interpretability and understanding. These advancements can\nimprove climate modeling and ocean prediction accuracy, supporting\ndecision-making in environmental and economic sectors.",
    "categories": [
      "cs.LG",
      "cs.AI",
      "physics.ao-ph"
    ],
    "published": "2025-10-29T14:30:12Z",
    "authors": [
      "V\u00edctor Medina",
      "Giovanny A. Cuervo-Londo\u00f1o",
      "Javier S\u00e1nchez"
    ],
    "pdf_url": "http://arxiv.org/pdf/2510.25563v1"
  },
  {
    "id": "2510.25557v1",
    "title": "Hybrid Quantum-Classical Recurrent Neural Networks",
    "abstract": "We present a hybrid quantum-classical recurrent neural network (QRNN)\narchitecture in which the entire recurrent core is realized as a parametrized\nquantum circuit (PQC) controlled by a classical feedforward network. The hidden\nstate is the quantum state of an $n$-qubit PQC, residing in an exponentially\nlarge Hilbert space $\\mathbb{C}^{2^n}$. The PQC is unitary by construction,\nmaking the hidden-state evolution norm-preserving without external constraints.\nAt each timestep, mid-circuit readouts are combined with the input embedding\nand processed by the feedforward network, which provides explicit classical\nnonlinearity. The outputs parametrize the PQC, which updates the hidden state\nvia unitary dynamics. The QRNN is compact and physically consistent, and it\nunifies (i) unitary recurrence as a high-capacity memory, (ii) partial\nobservation via mid-circuit measurements, and (iii) nonlinear classical control\nfor input-conditioned parametrization. We evaluate the model in simulation with\nup to 14 qubits on sentiment analysis, MNIST, permuted MNIST, copying memory,\nand language modeling, adopting projective measurements as a limiting case to\nobtain mid-circuit readouts while maintaining a coherent recurrent quantum\nmemory. We further devise a soft attention mechanism over the mid-circuit\nreadouts in a sequence-to-sequence model and show its effectiveness for machine\ntranslation. To our knowledge, this is the first model (RNN or otherwise)\ngrounded in quantum operations to achieve competitive performance against\nstrong classical baselines across a broad class of sequence-learning tasks.",
    "categories": [
      "cs.LG",
      "cs.AI",
      "cs.CL",
      "quant-ph"
    ],
    "published": "2025-10-29T14:21:49Z",
    "authors": [
      "Wenduan Xu"
    ],
    "pdf_url": "http://arxiv.org/pdf/2510.25557v1"
  },
  {
    "id": "2510.25550v1",
    "title": "Robust variable selection for spatial point processes observed with\n  noise",
    "abstract": "We propose a method for variable selection in the intensity function of\nspatial point processes that combines sparsity-promoting estimation with\nnoise-robust model selection. As high-resolution spatial data becomes\nincreasingly available through remote sensing and automated image analysis,\nidentifying spatial covariates that influence the localization of events is\ncrucial to understand the underlying mechanism. However, results from automated\nacquisition techniques are often noisy, for example due to measurement\nuncertainties or detection errors, which leads to spurious displacements and\nmissed events. We study the impact of such noise on sparse point-process\nestimation across different models, including Poisson and Thomas processes. To\nimprove noise robustness, we propose to use stability selection based on\npoint-process subsampling and to incorporate a non-convex best-subset penalty\nto enhance model-selection performance. In extensive simulations, we\ndemonstrate that such an approach reliably recovers true covariates under\ndiverse noise scenarios and improves both selection accuracy and stability. We\nthen apply the proposed method to a forestry data set, analyzing the\ndistribution of trees in relation to elevation and soil nutrients in a tropical\nrain forest. This shows the practical utility of the method, which provides a\nsystematic framework for robust variable selection in spatial point-process\nmodels under noise, without requiring additional knowledge of the process.",
    "categories": [
      "stat.ME",
      "cs.LG",
      "stat.CO",
      "stat.ML"
    ],
    "published": "2025-10-29T14:18:08Z",
    "authors": [
      "Dominik Sturm",
      "Ivo F. Sbalzarini"
    ],
    "pdf_url": "http://arxiv.org/pdf/2510.25550v1"
  },
  {
    "id": "2510.25544v1",
    "title": "Error Bounds and Optimal Schedules for Masked Diffusions with Factorized\n  Approximations",
    "abstract": "Recently proposed generative models for discrete data, such as Masked\nDiffusion Models (MDMs), exploit conditional independence approximations to\nreduce the computational cost of popular Auto-Regressive Models (ARMs), at the\nprice of some bias in the sampling distribution. We study the resulting\ncomputation-vs-accuracy trade-off, providing general error bounds (in relative\nentropy) that depend only on the average number of tokens generated per\niteration and are independent of the data dimensionality (i.e. sequence\nlength), thus supporting the empirical success of MDMs. We then investigate the\ngain obtained by using non-constant schedule sizes (i.e. varying the number of\nunmasked tokens during the generation process) and identify the optimal\nschedule as a function of a so-called information profile of the data\ndistribution, thus allowing for a principled optimization of schedule sizes. We\ndefine methods directly as sampling algorithms and do not use classical\nderivations as time-reversed diffusion processes, leading us to simple and\ntransparent proofs.",
    "categories": [
      "stat.ML",
      "cs.IT",
      "cs.LG",
      "math.IT",
      "stat.CO"
    ],
    "published": "2025-10-29T14:11:03Z",
    "authors": [
      "Hugo Lavenant",
      "Giacomo Zanella"
    ],
    "pdf_url": "http://arxiv.org/pdf/2510.25544v1"
  },
  {
    "id": "2510.25542v1",
    "title": "Transformers Provably Learn Directed Acyclic Graphs via Kernel-Guided\n  Mutual Information",
    "abstract": "Uncovering hidden graph structures underlying real-world data is a critical\nchallenge with broad applications across scientific domains. Recently,\ntransformer-based models leveraging the attention mechanism have demonstrated\nstrong empirical success in capturing complex dependencies within graphs.\nHowever, the theoretical understanding of their training dynamics has been\nlimited to tree-like graphs, where each node depends on a single parent.\nExtending provable guarantees to more general directed acyclic graphs (DAGs) --\nwhich involve multiple parents per node -- remains challenging, primarily due\nto the difficulty in designing training objectives that enable different\nattention heads to separately learn multiple different parent relationships.\n  In this work, we address this problem by introducing a novel\ninformation-theoretic metric: the kernel-guided mutual information (KG-MI),\nbased on the $f$-divergence. Our objective combines KG-MI with a multi-head\nattention framework, where each head is associated with a distinct marginal\ntransition kernel to model diverse parent-child dependencies effectively. We\nprove that, given sequences generated by a $K$-parent DAG, training a\nsingle-layer, multi-head transformer via gradient ascent converges to the\nglobal optimum in polynomial time. Furthermore, we characterize the attention\nscore patterns at convergence. In addition, when particularizing the\n$f$-divergence to the KL divergence, the learned attention scores accurately\nreflect the ground-truth adjacency matrix, thereby provably recovering the\nunderlying graph structure. Experimental results validate our theoretical\nfindings.",
    "categories": [
      "cs.LG",
      "cs.IT",
      "math.IT"
    ],
    "published": "2025-10-29T14:07:12Z",
    "authors": [
      "Yuan Cheng",
      "Yu Huang",
      "Zhe Xiong",
      "Yingbin Liang",
      "Vincent Y. F. Tan"
    ],
    "pdf_url": "http://arxiv.org/pdf/2510.25542v1"
  },
  {
    "id": "2510.25531v1",
    "title": "Using latent representations to link disjoint longitudinal data for\n  mixed-effects regression",
    "abstract": "Many rare diseases offer limited established treatment options, leading\npatients to switch therapies when new medications emerge. To analyze the impact\nof such treatment switches within the low sample size limitations of rare\ndisease trials, it is important to use all available data sources. This,\nhowever, is complicated when usage of measurement instruments change during the\nobservation period, for example when instruments are adapted to specific age\nranges. The resulting disjoint longitudinal data trajectories, complicate the\napplication of traditional modeling approaches like mixed-effects regression.\nWe tackle this by mapping observations of each instrument to a aligned\nlow-dimensional temporal trajectory, enabling longitudinal modeling across\ninstruments. Specifically, we employ a set of variational autoencoder\narchitectures to embed item values into a shared latent space for each time\npoint. Temporal disease dynamics and treatment switch effects are then captured\nthrough a mixed-effects regression model applied to latent representations. To\nenable statistical inference, we present a novel statistical testing approach\nthat accounts for the joint parameter estimation of mixed-effects regression\nand variational autoencoders. The methodology is applied to quantify the impact\nof treatment switches for patients with spinal muscular atrophy. Here, our\napproach aligns motor performance items from different measurement instruments\nfor mixed-effects regression and maps estimated effects back to the observed\nitem level to quantify the treatment switch effect. Our approach allows for\nmodel selection as well as for assessing effects of treatment switching. The\nresults highlight the potential of modeling in joint latent representations for\naddressing small data challenges.",
    "categories": [
      "stat.ML",
      "cs.AI",
      "cs.LG",
      "68T07",
      "G.3; I.2.6; J.3"
    ],
    "published": "2025-10-29T13:56:44Z",
    "authors": [
      "Clemens Sch\u00e4chter",
      "Maren Hackenberg",
      "Michelle Pfaffenlehner",
      "F\u00e9lix B. Tambe-Ndonfack",
      "Thorsten Schmidt",
      "Astrid Pechmann",
      "Janbernd Kirschner",
      "Jan Hasenauser",
      "Harald Binder"
    ],
    "pdf_url": "http://arxiv.org/pdf/2510.25531v1"
  },
  {
    "id": "2510.25514v1",
    "title": "Convergence of off-policy TD(0) with linear function approximation for\n  reversible Markov chains",
    "abstract": "We study the convergence of off-policy TD(0) with linear function\napproximation when used to approximate the expected discounted reward in a\nMarkov chain. It is well known that the combination of off-policy learning and\nfunction approximation can lead to divergence of the algorithm. Existing\nresults for this setting modify the algorithm, for instance by reweighing the\nupdates using importance sampling. This establishes convergence at the expense\nof additional complexity. In contrast, our approach is to analyse the standard\nalgorithm, but to restrict our attention to the class of reversible Markov\nchains. We demonstrate convergence under this mild reversibility condition on\nthe structure of the chain, which in many applications can be assumed using\ndomain knowledge. In particular, we establish a convergence guarantee under an\nupper bound on the discount factor in terms of the difference between the\non-policy and off-policy process. This improves upon known results in the\nliterature that state that convergence holds for a sufficiently small discount\nfactor by establishing an explicit bound. Convergence is with probability one\nand achieves projected Bellman error equal to zero. To obtain these results, we\nadapt the stochastic approximation framework that was used by Tsitsiklis and\nVan Roy [1997 for the on-policy case, to the off-policy case. We illustrate our\nresults using different types of reversible Markov chains, such as\none-dimensional random walks and random walks on a weighted graph.",
    "categories": [
      "stat.ML",
      "cs.LG"
    ],
    "published": "2025-10-29T13:38:24Z",
    "authors": [
      "Maik Overmars",
      "Jasper Goseling",
      "Richard Boucherie"
    ],
    "pdf_url": "http://arxiv.org/pdf/2510.25514v1"
  },
  {
    "id": "2510.25512v1",
    "title": "FaCT: Faithful Concept Traces for Explaining Neural Network Decisions",
    "abstract": "Deep networks have shown remarkable performance across a wide range of tasks,\nyet getting a global concept-level understanding of how they function remains a\nkey challenge. Many post-hoc concept-based approaches have been introduced to\nunderstand their workings, yet they are not always faithful to the model.\nFurther, they make restrictive assumptions on the concepts a model learns, such\nas class-specificity, small spatial extent, or alignment to human expectations.\nIn this work, we put emphasis on the faithfulness of such concept-based\nexplanations and propose a new model with model-inherent mechanistic\nconcept-explanations. Our concepts are shared across classes and, from any\nlayer, their contribution to the logit and their input-visualization can be\nfaithfully traced. We also leverage foundation models to propose a new\nconcept-consistency metric, C$^2$-Score, that can be used to evaluate\nconcept-based methods. We show that, compared to prior work, our concepts are\nquantitatively more consistent and users find our concepts to be more\ninterpretable, all while retaining competitive ImageNet performance.",
    "categories": [
      "cs.LG",
      "cs.AI",
      "cs.CV"
    ],
    "published": "2025-10-29T13:35:46Z",
    "authors": [
      "Amin Parchami-Araghi",
      "Sukrut Rao",
      "Jonas Fischer",
      "Bernt Schiele"
    ],
    "pdf_url": "http://arxiv.org/pdf/2510.25512v1"
  },
  {
    "id": "2510.25509v1",
    "title": "Support Vector Machine-Based Burnout Risk Prediction with an Interactive\n  Interface for Organizational Use",
    "abstract": "Burnout is a psychological syndrome marked by emotional exhaustion,\ndepersonalization, and reduced personal accomplishment, with a significant\nimpact on individual well-being and organizational performance. This study\nproposes a machine learning approach to predict burnout risk using the\nHackerEarth Employee Burnout Challenge dataset. Three supervised algorithms\nwere evaluated: nearest neighbors (KNN), random forest, and support vector\nmachine (SVM), with model performance evaluated through 30-fold\ncross-validation using the determination coefficient (R2). Among the models\ntested, SVM achieved the highest predictive performance (R2 = 0.84) and was\nstatistically superior to KNN and Random Forest based on paired $t$-tests. To\nensure practical applicability, an interactive interface was developed using\nStreamlit, allowing non-technical users to input data and receive burnout risk\npredictions. The results highlight the potential of machine learning to support\nearly detection of burnout and promote data-driven mental health strategies in\norganizational settings.",
    "categories": [
      "cs.LG"
    ],
    "published": "2025-10-29T13:32:59Z",
    "authors": [
      "Bruno W. G. Teodosio",
      "M\u00e1rio J. O. T. Lira",
      "Pedro H. M. Ara\u00fajo",
      "Lucas R. C. Farias"
    ],
    "pdf_url": "http://arxiv.org/pdf/2510.25509v1"
  },
  {
    "id": "2510.25502v1",
    "title": "TempoPFN: Synthetic Pre-training of Linear RNNs for Zero-shot Time\n  Series Forecasting",
    "abstract": "Foundation models for zero-shot time series forecasting face challenges in\nefficient long-horizon prediction and reproducibility, with existing\nsynthetic-only approaches underperforming on challenging benchmarks. This paper\npresents TempoPFN, a univariate time series foundation model based on linear\nRecurrent Neural Networks (RNNs) pre-trained exclusively on synthetic data. The\nmodel uses a GatedDeltaProduct architecture with state-weaving for fully\nparallelizable training across sequence lengths, eliminating the need for\nwindowing or summarization techniques while maintaining robust temporal\nstate-tracking. Our comprehensive synthetic data pipeline unifies diverse\ngenerators, including stochastic differential equations, Gaussian processes,\nand audio synthesis, with novel augmentations. In zero-shot evaluations on the\nGift-Eval benchmark, TempoPFN achieves top-tier competitive performance,\noutperforming all existing synthetic-only approaches and surpassing the vast\nmajority of models trained on real-world data, while being more efficient than\nexisting baselines by leveraging fully parallelizable training and inference.\nWe open-source our complete data generation pipeline and training code,\nproviding a reproducible foundation for future research.",
    "categories": [
      "cs.LG",
      "cs.AI",
      "stat.ML"
    ],
    "published": "2025-10-29T13:27:18Z",
    "authors": [
      "Vladyslav Moroshan",
      "Julien Siems",
      "Arber Zela",
      "Timur Carstensen",
      "Frank Hutter"
    ],
    "pdf_url": "http://arxiv.org/pdf/2510.25502v1"
  },
  {
    "id": "2510.25497v1",
    "title": "Right for the Right Reasons: Avoiding Reasoning Shortcuts via\n  Prototypical Neurosymbolic AI",
    "abstract": "Neurosymbolic AI is growing in popularity thanks to its ability to combine\nneural perception and symbolic reasoning in end-to-end trainable models.\nHowever, recent findings reveal these are prone to shortcut reasoning, i.e., to\nlearning unindented concepts--or neural predicates--which exploit spurious\ncorrelations to satisfy the symbolic constraints. In this paper, we address\nreasoning shortcuts at their root cause and we introduce prototypical\nneurosymbolic architectures. These models are able to satisfy the symbolic\nconstraints (be right) because they have learnt the correct basic concepts (for\nthe right reasons) and not because of spurious correlations, even in extremely\nlow data regimes. Leveraging the theory of prototypical learning, we\ndemonstrate that we can effectively avoid reasoning shortcuts by training the\nmodels to satisfy the background knowledge while taking into account the\nsimilarity of the input with respect to the handful of labelled datapoints. We\nextensively validate our approach on the recently proposed rsbench benchmark\nsuite in a variety of settings and tasks with very scarce supervision: we show\nsignificant improvements in learning the right concepts both in synthetic tasks\n(MNIST-EvenOdd and Kand-Logic) and real-world, high-stake ones (BDD-OIA). Our\nfindings pave the way to prototype grounding as an effective,\nannotation-efficient strategy for safe and reliable neurosymbolic learning.",
    "categories": [
      "cs.LG"
    ],
    "published": "2025-10-29T13:21:28Z",
    "authors": [
      "Luca Andolfi",
      "Eleonora Giunchiglia"
    ],
    "pdf_url": "http://arxiv.org/pdf/2510.25497v1"
  },
  {
    "id": "2510.25480v1",
    "title": "Gradient-Weight Alignment as a Train-Time Proxy for Generalization in\n  Classification Tasks",
    "abstract": "Robust validation metrics remain essential in contemporary deep learning, not\nonly to detect overfitting and poor generalization, but also to monitor\ntraining dynamics. In the supervised classification setting, we investigate\nwhether interactions between training data and model weights can yield such a\nmetric that both tracks generalization during training and attributes\nperformance to individual training samples. We introduce Gradient-Weight\nAlignment (GWA), quantifying the coherence between per-sample gradients and\nmodel weights. We show that effective learning corresponds to coherent\nalignment, while misalignment indicates deteriorating generalization. GWA is\nefficiently computable during training and reflects both sample-specific\ncontributions and dataset-wide learning dynamics. Extensive experiments show\nthat GWA accurately predicts optimal early stopping, enables principled model\ncomparisons, and identifies influential training samples, providing a\nvalidation-set-free approach for model analysis directly from the training\ndata.",
    "categories": [
      "cs.LG"
    ],
    "published": "2025-10-29T13:04:17Z",
    "authors": [
      "Florian A. H\u00f6lzl",
      "Daniel Rueckert",
      "Georgios Kaissis"
    ],
    "pdf_url": "http://arxiv.org/pdf/2510.25480v1"
  },
  {
    "id": "2510.25470v1",
    "title": "An In-Depth Analysis of Cyber Attacks in Secured Platforms",
    "abstract": "There is an increase in global malware threats. To address this, an\nencryption-type ransomware has been introduced on the Android operating system.\nThe challenges associated with malicious threats in phone use have become a\npressing issue in mobile communication, disrupting user experiences and posing\nsignificant privacy threats. This study surveys commonly used machine learning\ntechniques for detecting malicious threats in phones and examines their\nperformance. The majority of past research focuses on customer feedback and\nreviews, with concerns that people might create false reviews to promote or\ndevalue products and services for personal gain. Hence, the development of\ntechniques for detecting malicious threats using machine learning has been a\nkey focus. This paper presents a comprehensive comparative study of current\nresearch on the issue of malicious threats and methods for tackling these\nchallenges. Nevertheless, a huge amount of information is required by these\nmethods, presenting a challenge for developing robust, specialized automated\nanti-malware systems. This research describes the Android Applications dataset,\nand the accuracy of the techniques is measured using the accuracy levels of the\nmetrics employed in this study.",
    "categories": [
      "cs.CR",
      "cs.AI",
      "cs.LG"
    ],
    "published": "2025-10-29T12:43:18Z",
    "authors": [
      "Parick Ozoh",
      "John K Omoniyi",
      "Bukola Ibitoye"
    ],
    "pdf_url": "http://arxiv.org/pdf/2510.25470v1"
  },
  {
    "id": "2510.25458v1",
    "title": "Scalable Utility-Aware Multiclass Calibration",
    "abstract": "Ensuring that classifiers are well-calibrated, i.e., their predictions align\nwith observed frequencies, is a minimal and fundamental requirement for\nclassifiers to be viewed as trustworthy. Existing methods for assessing\nmulticlass calibration often focus on specific aspects associated with\nprediction (e.g., top-class confidence, class-wise calibration) or utilize\ncomputationally challenging variational formulations. In this work, we study\nscalable \\emph{evaluation} of multiclass calibration. To this end, we propose\nutility calibration, a general framework that measures the calibration error\nrelative to a specific utility function that encapsulates the goals or decision\ncriteria relevant to the end user. We demonstrate how this framework can unify\nand re-interpret several existing calibration metrics, particularly allowing\nfor more robust versions of the top-class and class-wise calibration metrics,\nand, going beyond such binarized approaches, toward assessing calibration for\nricher classes of downstream utilities.",
    "categories": [
      "cs.LG",
      "cs.AI",
      "stat.ML"
    ],
    "published": "2025-10-29T12:32:14Z",
    "authors": [
      "Mahmoud Hegazy",
      "Michael I. Jordan",
      "Aymeric Dieuleveut"
    ],
    "pdf_url": "http://arxiv.org/pdf/2510.25458v1"
  },
  {
    "id": "2510.25811v1",
    "title": "Multimodal Bandits: Regret Lower Bounds and Optimal Algorithms",
    "abstract": "We consider a stochastic multi-armed bandit problem with i.i.d. rewards where\nthe expected reward function is multimodal with at most m modes. We propose the\nfirst known computationally tractable algorithm for computing the solution to\nthe Graves-Lai optimization problem, which in turn enables the implementation\nof asymptotically optimal algorithms for this bandit problem. The code for the\nproposed algorithms is publicly available at\nhttps://github.com/wilrev/MultimodalBandits",
    "categories": [
      "stat.ML",
      "cs.LG",
      "math.ST",
      "stat.TH"
    ],
    "published": "2025-10-29T12:32:07Z",
    "authors": [
      "William R\u00e9veillard",
      "Richard Combes"
    ],
    "pdf_url": "http://arxiv.org/pdf/2510.25811v1"
  },
  {
    "id": "2510.25445v1",
    "title": "Agentic AI: A Comprehensive Survey of Architectures, Applications, and\n  Future Directions",
    "abstract": "Agentic AI represents a transformative shift in artificial intelligence, but\nits rapid advancement has led to a fragmented understanding, often conflating\nmodern neural systems with outdated symbolic models -- a practice known as\nconceptual retrofitting. This survey cuts through this confusion by introducing\na novel dual-paradigm framework that categorizes agentic systems into two\ndistinct lineages: the Symbolic/Classical (relying on algorithmic planning and\npersistent state) and the Neural/Generative (leveraging stochastic generation\nand prompt-driven orchestration). Through a systematic PRISMA-based review of\n90 studies (2018--2025), we provide a comprehensive analysis structured around\nthis framework across three dimensions: (1) the theoretical foundations and\narchitectural principles defining each paradigm; (2) domain-specific\nimplementations in healthcare, finance, and robotics, demonstrating how\napplication constraints dictate paradigm selection; and (3) paradigm-specific\nethical and governance challenges, revealing divergent risks and mitigation\nstrategies. Our analysis reveals that the choice of paradigm is strategic:\nsymbolic systems dominate safety-critical domains (e.g., healthcare), while\nneural systems prevail in adaptive, data-rich environments (e.g., finance).\nFurthermore, we identify critical research gaps, including a significant\ndeficit in governance models for symbolic systems and a pressing need for\nhybrid neuro-symbolic architectures. The findings culminate in a strategic\nroadmap arguing that the future of Agentic AI lies not in the dominance of one\nparadigm, but in their intentional integration to create systems that are both\nadaptable and reliable. This work provides the essential conceptual toolkit to\nguide future research, development, and policy toward robust and trustworthy\nhybrid intelligent systems.",
    "categories": [
      "cs.AI",
      "cs.LG"
    ],
    "published": "2025-10-29T12:11:34Z",
    "authors": [
      "Mohamad Abou Ali",
      "Fadi Dornaika"
    ],
    "pdf_url": "http://arxiv.org/pdf/2510.25445v1"
  },
  {
    "id": "2510.25404v1",
    "title": "GPTOpt: Towards Efficient LLM-Based Black-Box Optimization",
    "abstract": "Global optimization of expensive, derivative-free black-box functions demands\nextreme sample efficiency. Classical methods such as Bayesian Optimization (BO)\ncan be effective, but they often require careful parameter tuning to each\napplication domain. At the same time, Large Language Models (LLMs) have shown\nbroad capabilities, yet state-of-the-art models remain limited in solving\ncontinuous black-box optimization tasks. We introduce GPTOpt, an LLM-based\noptimization method that equips LLMs with continuous black-box optimization\ncapabilities. By fine-tuning large language models on extensive synthetic\ndatasets derived from diverse BO parameterizations, GPTOpt leverages LLM\npre-training to generalize across optimization tasks. On a variety of black-box\noptimization benchmarks, GPTOpt surpasses traditional optimizers, highlighting\nthe capacity of LLMs for advanced numerical reasoning and introducing a\nflexible framework for global optimization without parameter tuning.",
    "categories": [
      "cs.LG",
      "cs.AI"
    ],
    "published": "2025-10-29T11:21:55Z",
    "authors": [
      "Jamison Meindl",
      "Yunsheng Tian",
      "Tony Cui",
      "Veronika Thost",
      "Zhang-Wei Hong",
      "Jie Chen",
      "Wojciech Matusik",
      "Mina Konakovi\u0107 Lukovi\u0107"
    ],
    "pdf_url": "http://arxiv.org/pdf/2510.25404v1"
  },
  {
    "id": "2510.25379v1",
    "title": "A Deep Learning Framework for Multi-Operator Learning: Architectures and\n  Approximation Theory",
    "abstract": "While many problems in machine learning focus on learning mappings between\nfinite-dimensional spaces, scientific applications require approximating\nmappings between function spaces, i.e., operators. We study the problem of\nlearning collections of operators and provide both theoretical and empirical\nadvances. We distinguish between two regimes: (i) multiple operator learning,\nwhere a single network represents a continuum of operators parameterized by a\nparametric function, and (ii) learning several distinct single operators, where\neach operator is learned independently. For the multiple operator case, we\nintroduce two new architectures, $\\mathrm{MNO}$ and $\\mathrm{MONet}$, and\nestablish universal approximation results in three settings: continuous,\nintegrable, or Lipschitz operators. For the latter, we further derive explicit\nscaling laws that quantify how the network size must grow to achieve a target\napproximation accuracy. For learning several single operators, we develop a\nframework for balancing architectural complexity across subnetworks and show\nhow approximation order determines computational efficiency. Empirical\nexperiments on parametric PDE benchmarks confirm the strong expressive power\nand efficiency of the proposed architectures. Overall, this work establishes a\nunified theoretical and practical foundation for scalable neural operator\nlearning across multiple operators.",
    "categories": [
      "cs.LG",
      "cs.NA",
      "math.NA"
    ],
    "published": "2025-10-29T10:52:02Z",
    "authors": [
      "Adrien Weihs",
      "Jingmin Sun",
      "Zecheng Zhang",
      "Hayden Schaeffer"
    ],
    "pdf_url": "http://arxiv.org/pdf/2510.25379v1"
  },
  {
    "id": "2510.25372v1",
    "title": "Prompt Estimation from Prototypes for Federated Prompt Tuning of Vision\n  Transformers",
    "abstract": "Visual Prompt Tuning (VPT) of pre-trained Vision Transformers (ViTs) has\nproven highly effective as a parameter-efficient fine-tuning technique for\nadapting large models to downstream tasks with limited data. Its parameter\nefficiency makes it particularly suitable for Federated Learning (FL), where\nboth communication and computation budgets are often constrained. However,\nglobal prompt tuning struggles to generalize across heterogeneous clients,\nwhile personalized tuning overfits to local data and lacks generalization. We\npropose PEP-FedPT (Prompt Estimation from Prototypes for Federated Prompt\nTuning), a unified framework designed to achieve both generalization and\npersonalization in federated prompt tuning of ViTs. Within this framework, we\nintroduce the novel Class-Contextualized Mixed Prompt (CCMP) - based on\nclass-specific prompts maintained alongside a globally shared prompt. For each\ninput, CCMP adaptively combines class-specific prompts using weights derived\nfrom global class prototypes and client class priors. This approach enables\nper-sample prompt personalization without storing client-dependent trainable\nparameters. The prompts are collaboratively optimized via traditional federated\naveraging technique on the same. Comprehensive evaluations on CIFAR-100,\nTinyImageNet, DomainNet, and iNaturalist datasets demonstrate that PEP-FedPT\nconsistently surpasses the state-of-the-art baselines under diverse data\nheterogeneity scenarios, establishing a strong foundation for efficient and\ngeneralizable federated prompt tuning of Vision Transformers.",
    "categories": [
      "cs.CV",
      "cs.LG"
    ],
    "published": "2025-10-29T10:42:56Z",
    "authors": [
      "M Yashwanth",
      "Sharannya Ghosh",
      "Aditay Tripathi",
      "Anirban Chakraborty"
    ],
    "pdf_url": "http://arxiv.org/pdf/2510.25372v1"
  },
  {
    "id": "2510.25368v1",
    "title": "Position: Biology is the Challenge Physics-Informed ML Needs to Evolve",
    "abstract": "Physics-Informed Machine Learning (PIML) has successfully integrated\nmechanistic understanding into machine learning, particularly in domains\ngoverned by well-known physical laws. This success has motivated efforts to\napply PIML to biology, a field rich in dynamical systems but shaped by\ndifferent constraints. Biological modeling, however, presents unique\nchallenges: multi-faceted and uncertain prior knowledge, heterogeneous and\nnoisy data, partial observability, and complex, high-dimensional networks. In\nthis position paper, we argue that these challenges should not be seen as\nobstacles to PIML, but as catalysts for its evolution. We propose\nBiology-Informed Machine Learning (BIML): a principled extension of PIML that\nretains its structural grounding while adapting to the practical realities of\nbiology. Rather than replacing PIML, BIML retools its methods to operate under\nsofter, probabilistic forms of prior knowledge. We outline four foundational\npillars as a roadmap for this transition: uncertainty quantification,\ncontextualization, constrained latent structure inference, and scalability.\nFoundation Models and Large Language Models will be key enablers, bridging\nhuman expertise with computational modeling. We conclude with concrete\nrecommendations to build the BIML ecosystem and channel PIML-inspired\ninnovation toward challenges of high scientific and societal relevance.",
    "categories": [
      "cs.LG",
      "cs.AI",
      "cs.NE"
    ],
    "published": "2025-10-29T10:39:29Z",
    "authors": [
      "Julien Martinelli"
    ],
    "pdf_url": "http://arxiv.org/pdf/2510.25368v1"
  },
  {
    "id": "2510.25366v2",
    "title": "A Convexity-dependent Two-Phase Training Algorithm for Deep Neural\n  Networks",
    "abstract": "The key task of machine learning is to minimize the loss function that\nmeasures the model fit to the training data. The numerical methods to do this\nefficiently depend on the properties of the loss function. The most decisive\namong these properties is the convexity or non-convexity of the loss function.\nThe fact that the loss function can have, and frequently has, non-convex\nregions has led to a widespread commitment to non-convex methods such as Adam.\nHowever, a local minimum implies that, in some environment around it, the\nfunction is convex. In this environment, second-order minimizing methods such\nas the Conjugate Gradient (CG) give a guaranteed superlinear convergence. We\npropose a novel framework grounded in the hypothesis that loss functions in\nreal-world tasks swap from initial non-convexity to convexity towards the\noptimum. This is a property we leverage to design an innovative two-phase\noptimization algorithm. The presented algorithm detects the swap point by\nobserving the gradient norm dependence on the loss. In these regions,\nnon-convex (Adam) and convex (CG) algorithms are used, respectively. Computing\nexperiments confirm the hypothesis that this simple convexity structure is\nfrequent enough to be practically exploited to substantially improve\nconvergence and accuracy.",
    "categories": [
      "cs.LG",
      "cs.AI",
      "math.OC"
    ],
    "published": "2025-10-29T10:37:24Z",
    "authors": [
      "Tomas Hrycej",
      "Bernhard Bermeitinger",
      "Massimo Pavone",
      "G\u00f6tz-Henrik Wiegand",
      "Siegfried Handschuh"
    ],
    "pdf_url": "http://arxiv.org/pdf/2510.25366v2"
  },
  {
    "id": "2510.25361v1",
    "title": "Parameter Averaging in Link Prediction",
    "abstract": "Ensemble methods are widely employed to improve generalization in machine\nlearning. This has also prompted the adoption of ensemble learning for the\nknowledge graph embedding (KGE) models in performing link prediction. Typical\napproaches to this end train multiple models as part of the ensemble, and the\ndiverse predictions are then averaged. However, this approach has some\nsignificant drawbacks. For instance, the computational overhead of training\nmultiple models increases latency and memory overhead. In contrast, model\nmerging approaches offer a promising alternative that does not require training\nmultiple models. In this work, we introduce model merging, specifically\nweighted averaging, in KGE models. Herein, a running average of model\nparameters from a training epoch onward is maintained and used for predictions.\nTo address this, we additionally propose an approach that selectively updates\nthe running average of the ensemble model parameters only when the\ngeneralization performance improves on a validation dataset. We evaluate these\ntwo different weighted averaging approaches on link prediction tasks, comparing\nthe state-of-the-art benchmark ensemble approach. Additionally, we evaluate the\nweighted averaging approach considering literal-augmented KGE models and\nmulti-hop query answering tasks as well. The results demonstrate that the\nproposed weighted averaging approach consistently improves performance across\ndiverse evaluation settings.",
    "categories": [
      "cs.LG"
    ],
    "published": "2025-10-29T10:32:39Z",
    "authors": [
      "Rupesh Sapkota",
      "Caglar Demir",
      "Arnab Sharma",
      "Axel-Cyrille Ngonga Ngomo"
    ],
    "pdf_url": "http://arxiv.org/pdf/2510.25361v1"
  },
  {
    "id": "2510.25354v1",
    "title": "Analysis of Semi-Supervised Learning on Hypergraphs",
    "abstract": "Hypergraphs provide a natural framework for modeling higher-order\ninteractions, yet their theoretical underpinnings in semi-supervised learning\nremain limited. We provide an asymptotic consistency analysis of variational\nlearning on random geometric hypergraphs, precisely characterizing the\nconditions ensuring the well-posedness of hypergraph learning as well as\nshowing convergence to a weighted $p$-Laplacian equation. Motivated by this, we\npropose Higher-Order Hypergraph Learning (HOHL), which regularizes via powers\nof Laplacians from skeleton graphs for multiscale smoothness. HOHL converges to\na higher-order Sobolev seminorm. Empirically, it performs strongly on standard\nbaselines.",
    "categories": [
      "cs.LG",
      "math.ST",
      "stat.TH"
    ],
    "published": "2025-10-29T10:19:32Z",
    "authors": [
      "Adrien Weihs",
      "Andrea Bertozzi",
      "Matthew Thorpe"
    ],
    "pdf_url": "http://arxiv.org/pdf/2510.25354v1"
  },
  {
    "id": "2510.25348v1",
    "title": "Beyond Leakage and Complexity: Towards Realistic and Efficient\n  Information Cascade Prediction",
    "abstract": "Information cascade popularity prediction is a key problem in analyzing\ncontent diffusion in social networks. However, current related works suffer\nfrom three critical limitations: (1) temporal leakage in current\nevaluation--random cascade-based splits allow models to access future\ninformation, yielding unrealistic results; (2) feature-poor datasets that lack\ndownstream conversion signals (e.g., likes, comments, or purchases), which\nlimits more practical applications; (3) computational inefficiency of complex\ngraph-based methods that require days of training for marginal gains. We\nsystematically address these challenges from three perspectives: task setup,\ndataset construction, and model design. First, we propose a time-ordered\nsplitting strategy that chronologically partitions data into consecutive\nwindows, ensuring models are evaluated on genuine forecasting tasks without\nfuture information leakage. Second, we introduce Taoke, a large-scale\ne-commerce cascade dataset featuring rich promoter/product attributes and\nground-truth purchase conversions--capturing the complete diffusion lifecycle\nfrom promotion to monetization. Third, we develop CasTemp, a lightweight\nframework that efficiently models cascade dynamics through temporal walks,\nJaccard-based neighbor selection for inter-cascade dependencies, and GRU-based\nencoding with time-aware attention. Under leak-free evaluation, CasTemp\nachieves state-of-the-art performance across four datasets with\norders-of-magnitude speedup. Notably, it excels at predicting second-stage\npopularity conversions--a practical task critical for real-world applications.",
    "categories": [
      "cs.LG",
      "cs.SI"
    ],
    "published": "2025-10-29T10:06:08Z",
    "authors": [
      "Jie Peng",
      "Rui Wang",
      "Qiang Wang",
      "Zhewei Wei",
      "Bin Tong",
      "Guan Wang"
    ],
    "pdf_url": "http://arxiv.org/pdf/2510.25348v1"
  },
  {
    "id": "2510.25347v1",
    "title": "3D CT-Based Coronary Calcium Assessment: A Feature-Driven Machine\n  Learning Framework",
    "abstract": "Coronary artery calcium (CAC) scoring plays a crucial role in the early\ndetection and risk stratification of coronary artery disease (CAD). In this\nstudy, we focus on non-contrast coronary computed tomography angiography (CCTA)\nscans, which are commonly used for early calcification detection in clinical\nsettings. To address the challenge of limited annotated data, we propose a\nradiomics-based pipeline that leverages pseudo-labeling to generate training\nlabels, thereby eliminating the need for expert-defined segmentations.\nAdditionally, we explore the use of pretrained foundation models, specifically\nCT-FM and RadImageNet, to extract image features, which are then used with\ntraditional classifiers. We compare the performance of these deep learning\nfeatures with that of radiomics features. Evaluation is conducted on a clinical\nCCTA dataset comprising 182 patients, where individuals are classified into two\ngroups: zero versus non-zero calcium scores. We further investigate the impact\nof training on non-contrast datasets versus combined contrast and non-contrast\ndatasets, with testing performed only on non contrast scans. Results show that\nradiomics-based models significantly outperform CNN-derived embeddings from\nfoundation models (achieving 84% accuracy and p<0.05), despite the\nunavailability of expert annotations.",
    "categories": [
      "cs.CV",
      "cs.LG",
      "68U10",
      "I.2.1"
    ],
    "published": "2025-10-29T10:04:47Z",
    "authors": [
      "Ayman Abaid",
      "Gianpiero Guidone",
      "Sara Alsubai",
      "Foziyah Alquahtani",
      "Talha Iqbal",
      "Ruth Sharif",
      "Hesham Elzomor",
      "Emiliano Bianchini",
      "Naeif Almagal",
      "Michael G. Madden",
      "Faisal Sharif",
      "Ihsan Ullah"
    ],
    "pdf_url": "http://arxiv.org/pdf/2510.25347v1"
  },
  {
    "id": "2510.25327v2",
    "title": "MMEdge: Accelerating On-device Multimodal Inference via Pipelined\n  Sensing and Encoding",
    "abstract": "Real-time multimodal inference on resource-constrained edge devices is\nessential for applications such as autonomous driving, human-computer\ninteraction, and mobile health. However, prior work often overlooks the tight\ncoupling between sensing dynamics and model execution, as well as the complex\ninter-modality dependencies. In this paper, we propose MMEdge, an new on-device\nmulti-modal inference framework based on pipelined sensing and encoding.\nInstead of waiting for complete sensor inputs, MMEdge decomposes the entire\ninference process into a sequence of fine-grained sensing and encoding units,\nallowing computation to proceed incrementally as data arrive. MMEdge also\nintroduces a lightweight but effective temporal aggregation module that\ncaptures rich temporal dynamics across different pipelined units to maintain\naccuracy performance. Such pipelined design also opens up opportunities for\nfine-grained cross-modal optimization and early decision-making during\ninference. To further enhance system performance under resource variability and\ninput data complexity, MMEdge incorporates an adaptive multimodal configuration\noptimizer that dynamically selects optimal sensing and model configurations for\neach modality under latency constraints, and a cross-modal speculative skipping\nmechanism that bypasses future units of slower modalities when early\npredictions reach sufficient confidence. We evaluate MMEdge using two public\nmultimodal datasets and deploy it on a real-world unmanned aerial vehicle\n(UAV)-based multimodal testbed. The results show that MMEdge significantly\nreduces end-to-end latency while maintaining high task accuracy across various\nsystem and data dynamics.",
    "categories": [
      "cs.CV",
      "cs.AI",
      "cs.LG"
    ],
    "published": "2025-10-29T09:41:03Z",
    "authors": [
      "Runxi Huang",
      "Mingxuan Yu",
      "Mingyu Tsoi",
      "Xiaomin Ouyang"
    ],
    "pdf_url": "http://arxiv.org/pdf/2510.25327v2"
  },
  {
    "id": "2510.25323v1",
    "title": "CDFlow: Building Invertible Layers with Circulant and Diagonal Matrices",
    "abstract": "Normalizing flows are deep generative models that enable efficient likelihood\nestimation and sampling through invertible transformations. A key challenge is\nto design linear layers that enhance expressiveness while maintaining efficient\ncomputation of the Jacobian determinant and inverse. We introduce a novel\ninvertible linear layer based on the product of circulant and diagonal\nmatrices. This decomposition reduces parameter complexity from\n$\\mathcal{O}(n^2)$ to $\\mathcal{O}(mn)$ using $m$ diagonal matrices and $m-1$\ncirculant matrices while still approximating general linear transformations. By\nleveraging the Fast Fourier Transform, our approach reduces the time complexity\nof matrix inversion from $\\mathcal{O}(n^3)$ to $\\mathcal{O}(mn\\log n)$ and that\nof computing the log-determinant from $\\mathcal{O}(n^3)$ to $\\mathcal{O}(mn)$,\nwhere $n$ is the input dimension. We build upon this layer to develop\nCirculant-Diagonal Flow (CDFlow), which achieves strong density estimation on\nnatural image datasets and effectively models data with inherent periodic\nstructure. Furthermore, CDFlow significantly accelerates key operations in\nnormalizing flows, providing practical benefits for scalable generative\nmodeling.",
    "categories": [
      "cs.LG",
      "68T07, 62H12",
      "I.2.6; G.3"
    ],
    "published": "2025-10-29T09:38:50Z",
    "authors": [
      "Xuchen Feng",
      "Siyu Liao"
    ],
    "pdf_url": "http://arxiv.org/pdf/2510.25323v1"
  },
  {
    "id": "2510.25809v1",
    "title": "Flex-GAD : Flexible Graph Anomaly Detection",
    "abstract": "Detecting anomalous nodes in attributed networks, where each node is\nassociated with both structural connections and descriptive attributes, is\nessential for identifying fraud, misinformation, and suspicious behavior in\ndomains such as social networks, academic citation graphs, and e-commerce\nplatforms. We propose Flex-GAD, a novel unsupervised framework for graph\nanomaly detection at the node level. Flex-GAD integrates two encoders to\ncapture complementary aspects of graph data. The framework incorporates a novel\ncommunity-based GCN encoder to model intra-community and inter-community\ninformation into node embeddings, thereby ensuring structural consistency,\nalong with a standard attribute encoder. These diverse representations are\nfused using a self-attention-based representation fusion module, which enables\nadaptive weighting and effective integration of the encoded information. This\nfusion mechanism allows automatic emphasis of the most relevant node\nrepresentation across different encoders. We evaluate Flex-GAD on seven\nreal-world attributed graphs with varying sizes, node degrees, and attribute\nhomogeneity. Flex-GAD achieves an average AUC improvement of 7.98% over the\npreviously best-performing method, GAD-NR, demonstrating its effectiveness and\nflexibility across diverse graph structures. Moreover, it significantly reduces\ntraining time, running 102x faster per epoch than Anomaly DAE and 3x faster per\nepoch than GAD-NR on average across seven benchmark datasets.",
    "categories": [
      "cs.SI",
      "cs.LG"
    ],
    "published": "2025-10-29T09:33:12Z",
    "authors": [
      "Apu Chakraborty",
      "Anshul Kumar",
      "Gagan Raj Gupta"
    ],
    "pdf_url": "http://arxiv.org/pdf/2510.25809v1"
  },
  {
    "id": "2510.25311v1",
    "title": "Dense and Diverse Goal Coverage in Multi Goal Reinforcement Learning",
    "abstract": "Reinforcement Learning algorithms are primarily focused on learning a policy\nthat maximizes expected return. As a result, the learned policy can exploit one\nor few reward sources. However, in many natural situations, it is desirable to\nlearn a policy that induces a dispersed marginal state distribution over\nrewarding states, while maximizing the expected return which is typically tied\nto reaching a goal state. This aspect remains relatively unexplored. Existing\ntechniques based on entropy regularization and intrinsic rewards use\nstochasticity for encouraging exploration to find an optimal policy which may\nnot necessarily lead to dispersed marginal state distribution over rewarding\nstates. Other RL algorithms which match a target distribution assume the latter\nto be available apriori. This may be infeasible in large scale systems where\nenumeration of all states is not possible and a state is determined to be a\ngoal state only upon reaching it. We formalize the problem of maximizing the\nexpected return while uniformly visiting the goal states as Multi Goal RL in\nwhich an oracle classifier over the state space determines the goal states. We\npropose a novel algorithm that learns a high-return policy mixture with\nmarginal state distribution dispersed over the set of goal states. Our\nalgorithm is based on optimizing a custom RL reward which is computed - based\non the current policy mixture - at each iteration for a set of sampled\ntrajectories. The latter are used via an offline RL algorithm to update the\npolicy mixture. We prove performance guarantees for our algorithm, showing\nefficient convergence bounds for optimizing a natural objective which captures\nthe expected return as well as the dispersion of the marginal state\ndistribution over the goal states. We design and perform experiments on\nsynthetic MDPs and standard RL environments to evaluate the effectiveness of\nour algorithm.",
    "categories": [
      "cs.LG",
      "cs.AI"
    ],
    "published": "2025-10-29T09:23:21Z",
    "authors": [
      "Sagalpreet Singh",
      "Rishi Saket",
      "Aravindan Raghuveer"
    ],
    "pdf_url": "http://arxiv.org/pdf/2510.25311v1"
  },
  {
    "id": "2510.25306v1",
    "title": "Hierarchical Physics-Embedded Learning for Spatiotemporal Dynamical\n  Systems",
    "abstract": "Modeling complex spatiotemporal dynamics, particularly in\nfar-from-equilibrium systems, remains a grand challenge in science. The\ngoverning partial differential equations (PDEs) for these systems are often\nintractable to derive from first principles, due to their inherent complexity,\ncharacterized by high-order derivatives and strong nonlinearities, coupled with\nincomplete physical knowledge. This has spurred the development of data-driven\nmethods, yet these approaches face limitations: Purely data-driven models are\noften physically inconsistent and data-intensive, while existing\nphysics-informed methods lack the structural capacity to represent complex\noperators or systematically integrate partial physical knowledge. Here, we\npropose a hierarchical physics-embedded learning framework that fundamentally\nadvances both the forward spatiotemporal prediction and inverse discovery of\nphysical laws from sparse and noisy data. The key innovation is a two-level\narchitecture that mirrors the process of scientific discovery: the first level\nlearns fundamental symbolic components of a PDE, while the second learns their\ngoverning combinations. This hierarchical decomposition not only reduces\nlearning complexity but, more importantly, enables a structural integration of\nprior knowledge. Known physical laws are directly embedded into the models\ncomputational graph, guaranteeing physical consistency and improving data\nefficiency. By building the framework upon adaptive Fourier Neural Operators,\nwe can effectively capture the non-local dependencies and high-order operators\ncharacteristic of dynamical systems. Additionally, by structurally decoupling\nknown and unknown terms, the framework further enables interpretable discovery\nof underlying governing equations through symbolic regression, without\npresupposing functional forms.",
    "categories": [
      "cs.LG"
    ],
    "published": "2025-10-29T09:18:41Z",
    "authors": [
      "Xizhe Wang",
      "Xiaobin Song",
      "Qingshan Jia",
      "Hongbo Zhao",
      "Benben Jiang"
    ],
    "pdf_url": "http://arxiv.org/pdf/2510.25306v1"
  },
  {
    "id": "2510.25808v1",
    "title": "PRESTO: Preimage-Informed Instruction Optimization for Prompting\n  Black-Box LLMs",
    "abstract": "Large language models (LLMs) have achieved remarkable success across diverse\ndomains, due to their strong instruction-following capabilities. This has led\nto increasing interest in optimizing instructions for black-box LLMs, whose\ninternal parameters are inaccessible but widely used due to their strong\nperformance. To optimize instructions for black-box LLMs, recent methods employ\nwhite-box LLMs to generate candidate instructions from optimized soft prompts.\nHowever, white-box LLMs often map different soft prompts to the same\ninstruction, leading to redundant queries. While previous studies regarded this\nmany-to-one mapping as a structure that hinders optimization efficiency, we\nreinterpret it as a useful prior knowledge that can accelerate the\noptimization. To this end, we introduce PREimage-informed inSTruction\nOptimization (PRESTO), a novel framework that leverages the preimage structure\nof soft prompts for efficient optimization. PRESTO consists of three key\ncomponents: (1) score sharing, which shares the evaluation score with all soft\nprompts in a preimage; (2) preimage-based initialization, which selects initial\ndata points that maximize search space coverage using preimage information; and\n(3) score consistency regularization, which enforces prediction consistency\nwithin each preimage. By leveraging preimages, PRESTO achieves the effect of\neffectively obtaining 14 times more scored data under the same query budget,\nresulting in more efficient optimization. Experimental results on 33\ninstruction optimization tasks demonstrate the superior performance of PRESTO.\nCode is available at https://github.com/mlvlab/PRESTO",
    "categories": [
      "cs.LG"
    ],
    "published": "2025-10-29T09:07:53Z",
    "authors": [
      "Jaewon Chu",
      "Seunghun Lee",
      "Hyunwoo J. Kim"
    ],
    "pdf_url": "http://arxiv.org/pdf/2510.25808v1"
  },
  {
    "id": "2510.25807v1",
    "title": "Discovering Interpretable Biological Concepts in Single-cell RNA-seq\n  Foundation Models",
    "abstract": "Single-cell RNA-seq foundation models achieve strong performance on\ndownstream tasks but remain black boxes, limiting their utility for biological\ndiscovery. Recent work has shown that sparse dictionary learning can extract\nconcepts from deep learning models, with promising applications in biomedical\nimaging and protein models. However, interpreting biological concepts remains\nchallenging, as biological sequences are not inherently human-interpretable. We\nintroduce a novel concept-based interpretability framework for single-cell\nRNA-seq models with a focus on concept interpretation and evaluation. We\npropose an attribution method with counterfactual perturbations that identifies\ngenes that influence concept activation, moving beyond correlational approaches\nlike differential expression analysis. We then provide two complementary\ninterpretation approaches: an expert-driven analysis facilitated by an\ninteractive interface and an ontology-driven method with attribution-based\nbiological pathway enrichment. Applying our framework to two well-known\nsingle-cell RNA-seq models from the literature, we interpret concepts extracted\nby Top-K Sparse Auto-Encoders trained on two immune cell datasets. With a\ndomain expert in immunology, we show that concepts improve interpretability\ncompared to individual neurons while preserving the richness and\ninformativeness of the latent representations. This work provides a principled\nframework for interpreting what biological knowledge foundation models have\nencoded, paving the way for their use for hypothesis generation and discovery.",
    "categories": [
      "q-bio.GN",
      "cs.LG"
    ],
    "published": "2025-10-29T08:52:55Z",
    "authors": [
      "Charlotte Claye",
      "Pierre Marschall",
      "Wassila Ouerdane",
      "C\u00e9line Hudelot",
      "Julien Duquesne"
    ],
    "pdf_url": "http://arxiv.org/pdf/2510.25807v1"
  },
  {
    "id": "2510.25282v1",
    "title": "On the Stability of Neural Networks in Deep Learning",
    "abstract": "Deep learning has achieved remarkable success across a wide range of tasks,\nbut its models often suffer from instability and vulnerability: small changes\nto the input may drastically affect predictions, while optimization can be\nhindered by sharp loss landscapes. This thesis addresses these issues through\nthe unifying perspective of sensitivity analysis, which examines how neural\nnetworks respond to perturbations at both the input and parameter levels.\n  We study Lipschitz networks as a principled way to constrain sensitivity to\ninput perturbations, thereby improving generalization, adversarial robustness,\nand training stability. To complement this architectural approach, we introduce\nregularization techniques based on the curvature of the loss function,\npromoting smoother optimization landscapes and reducing sensitivity to\nparameter variations. Randomized smoothing is also explored as a probabilistic\nmethod for enhancing robustness at decision boundaries.\n  By combining these perspectives, we develop a unified framework where\nLipschitz continuity, randomized smoothing, and curvature regularization\ninteract to address fundamental challenges in stability. The thesis contributes\nboth theoretical analysis and practical methodologies, including efficient\nspectral norm computation, novel Lipschitz-constrained layers, and improved\ncertification procedures.",
    "categories": [
      "cs.LG"
    ],
    "published": "2025-10-29T08:38:43Z",
    "authors": [
      "Blaise Delattre"
    ],
    "pdf_url": "http://arxiv.org/pdf/2510.25282v1"
  },
  {
    "id": "2510.25262v1",
    "title": "IBNorm: Information-Bottleneck Inspired Normalization for Representation\n  Learning",
    "abstract": "Normalization is fundamental to deep learning, but existing approaches such\nas BatchNorm, LayerNorm, and RMSNorm are variance-centric by enforcing zero\nmean and unit variance, stabilizing training without controlling how\nrepresentations capture task-relevant information. We propose IB-Inspired\nNormalization (IBNorm), a simple yet powerful family of methods grounded in the\nInformation Bottleneck principle. IBNorm introduces bounded compression\noperations that encourage embeddings to preserve predictive information while\nsuppressing nuisance variability, yielding more informative representations\nwhile retaining the stability and compatibility of standard normalization.\nTheoretically, we prove that IBNorm achieves a higher IB value and tighter\ngeneralization bounds than variance-centric methods. Empirically, IBNorm\nconsistently outperforms BatchNorm, LayerNorm, and RMSNorm across large-scale\nlanguage models (LLaMA, GPT-2) and vision models (ResNet, ViT), with mutual\ninformation analysis confirming superior information bottleneck behavior. Code\nwill be released publicly.",
    "categories": [
      "cs.LG",
      "cs.AI"
    ],
    "published": "2025-10-29T08:21:32Z",
    "authors": [
      "Xiandong Zou",
      "Pan Zhou"
    ],
    "pdf_url": "http://arxiv.org/pdf/2510.25262v1"
  },
  {
    "id": "2510.25259v1",
    "title": "TV-Rec: Time-Variant Convolutional Filter for Sequential Recommendation",
    "abstract": "Recently, convolutional filters have been increasingly adopted in sequential\nrecommendation for their ability to capture local sequential patterns. However,\nmost of these models complement convolutional filters with self-attention. This\nis because convolutional filters alone, generally fixed filters, struggle to\ncapture global interactions necessary for accurate recommendation. We propose\nTime-Variant Convolutional Filters for Sequential Recommendation (TV-Rec), a\nmodel inspired by graph signal processing, where time-variant graph filters\ncapture position-dependent temporal variations in user sequences. By replacing\nboth fixed kernels and self-attention with time-variant filters, TV-Rec\nachieves higher expressive power and better captures complex interaction\npatterns in user behavior. This design not only eliminates the need for\nself-attention but also reduces computation while accelerating inference.\nExtensive experiments on six public benchmarks show that TV-Rec outperforms\nstate-of-the-art baselines by an average of 7.49%.",
    "categories": [
      "cs.IR",
      "cs.AI",
      "cs.LG"
    ],
    "published": "2025-10-29T08:14:03Z",
    "authors": [
      "Yehjin Shin",
      "Jeongwhan Choi",
      "Seojin Kim",
      "Noseong Park"
    ],
    "pdf_url": "http://arxiv.org/pdf/2510.25259v1"
  },
  {
    "id": "2510.25254v1",
    "title": "Scaling Up Bayesian DAG Sampling",
    "abstract": "Bayesian inference of Bayesian network structures is often performed by\nsampling directed acyclic graphs along an appropriately constructed Markov\nchain. We present two techniques to improve sampling. First, we give an\nefficient implementation of basic moves, which add, delete, or reverse a single\narc. Second, we expedite summing over parent sets, an expensive task required\nfor more sophisticated moves: we devise a preprocessing method to prune\npossible parent sets so as to approximately preserve the sums. Our empirical\nstudy shows that our techniques can yield substantial efficiency gains compared\nto previous methods.",
    "categories": [
      "cs.LG",
      "cs.AI"
    ],
    "published": "2025-10-29T08:06:20Z",
    "authors": [
      "Daniele Nikzad",
      "Alexander Zhilkin",
      "Juha Harviainen",
      "Jack Kuipers",
      "Giusi Moffa",
      "Mikko Koivisto"
    ],
    "pdf_url": "http://arxiv.org/pdf/2510.25254v1"
  },
  {
    "id": "2510.25244v1",
    "title": "BSFA: Leveraging the Subspace Dichotomy to Accelerate Neural Network\n  Training",
    "abstract": "Recent studies \\citep{gur2018gradient,song2024does, wen2024understanding}\nhighlight a fundamental dichotomy in deep learning optimization: Although\nparameter updates along the top eigendirections of the loss Hessian (Dom-space)\ncapture most of the update magnitude, they often contribute minimally to loss\nreduction. In contrast, updates in the orthogonal component (Bulk-space) have\nsmaller magnitudes but drive most learning progress. In this work, we further\nadvance the understanding of this phenomenon and introduce the\n\\textbf{Bulk-Space-Filtration-Accelerator (BSFA)}, a novel plug-and-play\nframework. BSFA accelerates training by differentially scaling update\ncomponents projected onto these distinct subspaces, simultaneously enhancing\nstability by moderating updates in the dominant subspace and boosting\nconvergence speed by amplifying those in the bulk-space. To ensure BSFA is both\npractical and scalable for contemporary large models, we introduce two key\ninnovations: an efficient estimator using Principal Component Analysis (PCA) on\nhistorical updates for fast subspace estimation, and a block-wise strategy that\napplies this estimation on a per-parameter-block basis. These designs make BSFA\ncomputationally tractable and highly effective. We demonstrate BSFA's\nacceleration across various tasks, notably achieving approximately 2$\\times$\nspeedup when pre-training LLaMA-72M on WikiText-103 and LLaMA-134M on\nOpenWebText compared to vanilla AdamW.",
    "categories": [
      "cs.LG"
    ],
    "published": "2025-10-29T07:51:35Z",
    "authors": [
      "Wenjie Zhou",
      "Bohan Wang",
      "Wei Chen",
      "Xueqi Cheng"
    ],
    "pdf_url": "http://arxiv.org/pdf/2510.25244v1"
  },
  {
    "id": "2510.25240v1",
    "title": "Generative Bayesian Optimization: Generative Models as Acquisition\n  Functions",
    "abstract": "We present a general strategy for turning generative models into candidate\nsolution samplers for batch Bayesian optimization (BO). The use of generative\nmodels for BO enables large batch scaling as generative sampling, optimization\nof non-continuous design spaces, and high-dimensional and combinatorial design.\nInspired by the success of direct preference optimization (DPO), we show that\none can train a generative model with noisy, simple utility values directly\ncomputed from observations to then form proposal distributions whose densities\nare proportional to the expected utility, i.e., BO's acquisition function\nvalues. Furthermore, this approach is generalizable beyond preference-based\nfeedback to general types of reward signals and loss functions. This\nperspective avoids the construction of surrogate (regression or classification)\nmodels, common in previous methods that have used generative models for\nblack-box optimization. Theoretically, we show that the generative models\nwithin the BO process approximately follow a sequence of distributions which\nasymptotically concentrate at the global optima under certain conditions. We\nalso demonstrate this effect through experiments on challenging optimization\nproblems involving large batches in high dimensions.",
    "categories": [
      "stat.ML",
      "cs.LG"
    ],
    "published": "2025-10-29T07:42:25Z",
    "authors": [
      "Rafael Oliveira",
      "Daniel M. Steinberg",
      "Edwin V. Bonilla"
    ],
    "pdf_url": "http://arxiv.org/pdf/2510.25240v1"
  },
  {
    "id": "2510.25226v1",
    "title": "Cost-Sensitive Unbiased Risk Estimation for Multi-Class\n  Positive-Unlabeled Learning",
    "abstract": "Positive--Unlabeled (PU) learning considers settings in which only positive\nand unlabeled data are available, while negatives are missing or left\nunlabeled. This situation is common in real applications where annotating\nreliable negatives is difficult or costly. Despite substantial progress in PU\nlearning, the multi-class case (MPU) remains challenging: many existing\napproaches do not ensure \\emph{unbiased risk estimation}, which limits\nperformance and stability. We propose a cost-sensitive multi-class PU method\nbased on \\emph{adaptive loss weighting}. Within the empirical risk minimization\nframework, we assign distinct, data-dependent weights to the positive and\n\\emph{inferred-negative} (from the unlabeled mixture) loss components so that\nthe resulting empirical objective is an unbiased estimator of the target risk.\nWe formalize the MPU data-generating process and establish a generalization\nerror bound for the proposed estimator. Extensive experiments on \\textbf{eight}\npublic datasets, spanning varying class priors and numbers of classes, show\nconsistent gains over strong baselines in both accuracy and stability.",
    "categories": [
      "cs.LG",
      "cs.AI"
    ],
    "published": "2025-10-29T07:01:32Z",
    "authors": [
      "Miao Zhang",
      "Junpeng Li",
      "Changchun Hua",
      "Yana Yang"
    ],
    "pdf_url": "http://arxiv.org/pdf/2510.25226v1"
  },
  {
    "id": "2510.25220v1",
    "title": "GReF: A Unified Generative Framework for Efficient Reranking via Ordered\n  Multi-token Prediction",
    "abstract": "In a multi-stage recommendation system, reranking plays a crucial role in\nmodeling intra-list correlations among items. A key challenge lies in exploring\noptimal sequences within the combinatorial space of permutations. Recent\nresearch follows a two-stage (generator-evaluator) paradigm, where a generator\nproduces multiple feasible sequences, and an evaluator selects the best one. In\npractice, the generator is typically implemented as an autoregressive model.\nHowever, these two-stage methods face two main challenges. First, the\nseparation of the generator and evaluator hinders end-to-end training. Second,\nautoregressive generators suffer from inference efficiency. In this work, we\npropose a Unified Generative Efficient Reranking Framework (GReF) to address\nthe two primary challenges. Specifically, we introduce Gen-Reranker, an\nautoregressive generator featuring a bidirectional encoder and a dynamic\nautoregressive decoder to generate causal reranking sequences. Subsequently, we\npre-train Gen-Reranker on the item exposure order for high-quality parameter\ninitialization. To eliminate the need for the evaluator while integrating\nsequence-level evaluation during training for end-to-end optimization, we\npropose post-training the model through Rerank-DPO. Moreover, for efficient\nautoregressive inference, we introduce ordered multi-token prediction (OMTP),\nwhich trains Gen-Reranker to simultaneously generate multiple future items\nwhile preserving their order, ensuring practical deployment in real-time\nrecommender systems. Extensive offline experiments demonstrate that GReF\noutperforms state-of-the-art reranking methods while achieving latency that is\nnearly comparable to non-autoregressive models. Additionally, GReF has also\nbeen deployed in a real-world video app Kuaishou with over 300 million daily\nactive users, significantly improving online recommendation quality.",
    "categories": [
      "cs.IR",
      "cs.AI",
      "cs.LG"
    ],
    "published": "2025-10-29T06:54:42Z",
    "authors": [
      "Zhijie Lin",
      "Zhuofeng Li",
      "Chenglei Dai",
      "Wentian Bao",
      "Shuai Lin",
      "Enyun Yu",
      "Haoxiang Zhang",
      "Liang Zhao"
    ],
    "pdf_url": "http://arxiv.org/pdf/2510.25220v1"
  },
  {
    "id": "2510.25207v1",
    "title": "Selective Learning for Deep Time Series Forecasting",
    "abstract": "Benefiting from high capacity for capturing complex temporal patterns, deep\nlearning (DL) has significantly advanced time series forecasting (TSF).\nHowever, deep models tend to suffer from severe overfitting due to the inherent\nvulnerability of time series to noise and anomalies. The prevailing DL paradigm\nuniformly optimizes all timesteps through the MSE loss and learns those\nuncertain and anomalous timesteps without difference, ultimately resulting in\noverfitting. To address this, we propose a novel selective learning strategy\nfor deep TSF. Specifically, selective learning screens a subset of the whole\ntimesteps to calculate the MSE loss in optimization, guiding the model to focus\non generalizable timesteps while disregarding non-generalizable ones. Our\nframework introduces a dual-mask mechanism to target timesteps: (1) an\nuncertainty mask leveraging residual entropy to filter uncertain timesteps, and\n(2) an anomaly mask employing residual lower bound estimation to exclude\nanomalous timesteps. Extensive experiments across eight real-world datasets\ndemonstrate that selective learning can significantly improve the predictive\nperformance for typical state-of-the-art deep models, including 37.4% MSE\nreduction for Informer, 8.4% for TimesNet, and 6.5% for iTransformer.",
    "categories": [
      "cs.LG"
    ],
    "published": "2025-10-29T06:18:52Z",
    "authors": [
      "Yisong Fu",
      "Zezhi Shao",
      "Chengqing Yu",
      "Yujie Li",
      "Zhulin An",
      "Qi Wang",
      "Yongjun Xu",
      "Fei Wang"
    ],
    "pdf_url": "http://arxiv.org/pdf/2510.25207v1"
  },
  {
    "id": "2510.25206v1",
    "title": "RAVR: Reference-Answer-guided Variational Reasoning for Large Language\n  Models",
    "abstract": "Reinforcement learning (RL) can refine the reasoning abilities of large\nlanguage models (LLMs), but critically depends on a key prerequisite: the LLM\ncan already generate high-utility reasoning paths with non-negligible\nprobability. For tasks beyond the LLM's current competence, such reasoning path\ncan be hard to sample, and learning risks reinforcing familiar but suboptimal\nreasoning. We are motivated by the insight from cognitive science that Why is\nthis the answer is often an easier question than What is the answer, as it\navoids the heavy cognitive load of open-ended exploration, opting instead for\nexplanatory reconstruction-systematically retracing the reasoning that links a\nquestion to its answer. We show that LLMs can similarly leverage answers to\nderive high-quality reasoning paths. We formalize this phenomenon and prove\nthat conditioning on answer provably increases the expected utility of sampled\nreasoning paths, thereby transforming intractable problems into learnable ones.\nBuilding on this insight, we introduce RAVR (Reference-Answer-guided\nVariational Reasoning), an end-to-end framework that uses answer-conditioned\nreasoning as a variational surrogate for question-only reasoning. Experiments\nin both general and math domains demonstrate consistent improvements over\nstrong baselines. We further analyze the reasoning behavior and find that RAVR\nreduces hesitation, strengthens conclusion consolidation, and promotes\nproblem-specific strategies in reasoning.",
    "categories": [
      "cs.AI",
      "cs.CL",
      "cs.LG",
      "I.2.7"
    ],
    "published": "2025-10-29T06:18:37Z",
    "authors": [
      "Tianqianjin Lin",
      "Xi Zhao",
      "Xingyao Zhang",
      "Rujiao Long",
      "Yi Xu",
      "Zhuoren Jiang",
      "Wenbo Su",
      "Bo Zheng"
    ],
    "pdf_url": "http://arxiv.org/pdf/2510.25206v1"
  },
  {
    "id": "2510.25803v1",
    "title": "Mixture-of-Experts Operator Transformer for Large-Scale PDE Pre-Training",
    "abstract": "Pre-training has proven effective in addressing data scarcity and performance\nlimitations in solving PDE problems with neural operators. However, challenges\nremain due to the heterogeneity of PDE datasets in equation types, which leads\nto high errors in mixed training. Additionally, dense pre-training models that\nscale parameters by increasing network width or depth incur significant\ninference costs. To tackle these challenges, we propose a novel\nMixture-of-Experts Pre-training Operator Transformer (MoE-POT), a\nsparse-activated architecture that scales parameters efficiently while\ncontrolling inference costs. Specifically, our model adopts a layer-wise\nrouter-gating network to dynamically select 4 routed experts from 16 expert\nnetworks during inference, enabling the model to focus on equation-specific\nfeatures. Meanwhile, we also integrate 2 shared experts, aiming to capture\ncommon properties of PDE and reduce redundancy among routed experts. The final\noutput is computed as the weighted average of the results from all activated\nexperts. We pre-train models with parameters from 30M to 0.5B on 6 public PDE\ndatasets. Our model with 90M activated parameters achieves up to a 40%\nreduction in zero-shot error compared with existing models with 120M activated\nparameters. Additionally, we conduct interpretability analysis, showing that\ndataset types can be inferred from router-gating network decisions, which\nvalidates the rationality and effectiveness of the MoE architecture.",
    "categories": [
      "cs.LG",
      "cs.NA",
      "math.NA"
    ],
    "published": "2025-10-29T05:47:41Z",
    "authors": [
      "Hong Wang",
      "Haiyang Xin",
      "Jie Wang",
      "Xuanze Yang",
      "Fei Zha",
      "Huanshuo Dong",
      "Yan Jiang"
    ],
    "pdf_url": "http://arxiv.org/pdf/2510.25803v1"
  },
  {
    "id": "2510.25176v1",
    "title": "Machine Learning and CPU (Central Processing Unit) Scheduling\n  Co-Optimization over a Network of Computing Centers",
    "abstract": "In the rapidly evolving research on artificial intelligence (AI) the demand\nfor fast, computationally efficient, and scalable solutions has increased in\nrecent years. The problem of optimizing the computing resources for distributed\nmachine learning (ML) and optimization is considered in this paper. Given a set\nof data distributed over a network of computing-nodes/servers, the idea is to\noptimally assign the CPU (central processing unit) usage while simultaneously\ntraining each computing node locally via its own share of data. This formulates\nthe problem as a co-optimization setup to (i) optimize the data processing and\n(ii) optimally allocate the computing resources. The information-sharing\nnetwork among the nodes might be time-varying, but with balanced weights to\nensure consensus-type convergence of the algorithm. The algorithm is all-time\nfeasible, which implies that the computing resource-demand balance constraint\nholds at all iterations of the proposed solution. Moreover, the solution allows\naddressing possible log-scale quantization over the information-sharing\nchannels to exchange log-quantized data. For some example applications,\ndistributed support-vector-machine (SVM) and regression are considered as the\nML training models. Results from perturbation theory, along with Lyapunov\nstability and eigen-spectrum analysis, are used to prove the convergence\ntowards the optimal case. As compared to existing CPU scheduling solutions, the\nproposed algorithm improves the cost optimality gap by more than $50\\%$.",
    "categories": [
      "cs.LG",
      "cs.DC",
      "cs.MA",
      "cs.SY",
      "eess.SY",
      "math.OC"
    ],
    "published": "2025-10-29T05:21:32Z",
    "authors": [
      "Mohammadreza Doostmohammadian",
      "Zulfiya R. Gabidullina",
      "Hamid R. Rabiee"
    ],
    "pdf_url": "http://arxiv.org/pdf/2510.25176v1"
  },
  {
    "id": "2510.25166v1",
    "title": "A Study on Inference Latency for Vision Transformers on Mobile Devices",
    "abstract": "Given the significant advances in machine learning techniques on mobile\ndevices, particularly in the domain of computer vision, in this work we\nquantitatively study the performance characteristics of 190 real-world vision\ntransformers (ViTs) on mobile devices. Through a comparison with 102 real-world\nconvolutional neural networks (CNNs), we provide insights into the factors that\ninfluence the latency of ViT architectures on mobile devices. Based on these\ninsights, we develop a dataset including measured latencies of 1000 synthetic\nViTs with representative building blocks and state-of-the-art architectures\nfrom two machine learning frameworks and six mobile platforms. Using this\ndataset, we show that inference latency of new ViTs can be predicted with\nsufficient accuracy for real-world applications.",
    "categories": [
      "cs.CV",
      "cs.LG",
      "cs.PF"
    ],
    "published": "2025-10-29T04:57:49Z",
    "authors": [
      "Zhuojin Li",
      "Marco Paolieri",
      "Leana Golubchik"
    ],
    "pdf_url": "http://arxiv.org/pdf/2510.25166v1"
  },
  {
    "id": "2510.25147v1",
    "title": "Machine Learning Guided Optimal Transmission Switching to Mitigate\n  Wildfire Ignition Risk",
    "abstract": "To mitigate acute wildfire ignition risks, utilities de-energize power lines\nin high-risk areas. The Optimal Power Shutoff (OPS) problem optimizes line\nenergization statuses to manage wildfire ignition risks through\nde-energizations while reducing load shedding. OPS problems are computationally\nchallenging Mixed-Integer Linear Programs (MILPs) that must be solved rapidly\nand frequently in operational settings. For a particular power system, OPS\ninstances share a common structure with varying parameters related to wildfire\nrisks, loads, and renewable generation. This motivates the use of Machine\nLearning (ML) for solving OPS problems by exploiting shared patterns across\ninstances. In this paper, we develop an ML-guided framework that quickly\nproduces high-quality de-energization decisions by extending existing ML-guided\nMILP solution methods while integrating domain knowledge on the number of\nenergized and de-energized lines. Results on a large-scale realistic\nCalifornia-based synthetic test system show that the proposed ML-guided method\nproduces high-quality solutions faster than traditional optimization methods.",
    "categories": [
      "cs.LG",
      "math.OC"
    ],
    "published": "2025-10-29T03:56:46Z",
    "authors": [
      "Weimin Huang",
      "Ryan Piansky",
      "Bistra Dilkina",
      "Daniel K. Molzahn"
    ],
    "pdf_url": "http://arxiv.org/pdf/2510.25147v1"
  },
  {
    "id": "2510.25802v1",
    "title": "Attention Augmented GNN RNN-Attention Models for Advanced Cybersecurity\n  Intrusion Detection",
    "abstract": "In this paper, we propose a novel hybrid deep learning architecture that\nsynergistically combines Graph Neural Networks (GNNs), Recurrent Neural\nNetworks (RNNs), and multi-head attention mechanisms to significantly enhance\ncybersecurity intrusion detection capabilities. By leveraging the comprehensive\nUNSW-NB15 dataset containing diverse network traffic patterns, our approach\neffectively captures both spatial dependencies through graph structural\nrelationships and temporal dynamics through sequential analysis of network\nevents. The integrated attention mechanism provides dual benefits of improved\nmodel interpretability and enhanced feature selection, enabling cybersecurity\nanalysts to focus computational resources on high-impact security events -- a\ncritical requirement in modern real-time intrusion detection systems. Our\nextensive experimental evaluation demonstrates that the proposed hybrid model\nachieves superior performance compared to traditional machine learning\napproaches and standalone deep learning models across multiple evaluation\nmetrics, including accuracy, precision, recall, and F1-score. The model\nachieves particularly strong performance in detecting sophisticated attack\npatterns such as Advanced Persistent Threats (APTs), Distributed Denial of\nService (DDoS) attacks, and zero-day exploits, making it a promising solution\nfor next-generation cybersecurity applications in complex network environments.",
    "categories": [
      "cs.CR",
      "cs.LG"
    ],
    "published": "2025-10-29T03:47:02Z",
    "authors": [
      "Jayant Biradar",
      "Smit Shah",
      "Tanmay Naik"
    ],
    "pdf_url": "http://arxiv.org/pdf/2510.25802v1"
  },
  {
    "id": "2510.25801v1",
    "title": "Metis-SPECS: Decoupling Multimodal Learning via Self-distilled\n  Preference-based Cold Start",
    "abstract": "Reinforcement learning (RL) with verifiable rewards has recently catalyzed a\nwave of \"MLLM-r1\" approaches that bring RL to vision language models. Most\nrepresentative paradigms begin with a cold start, typically employing\nsupervised fine-tuning (SFT), to initialize the policy before RL. However,\nSFT-based cold start adopts the reasoning paradigm intertwined with task\nsolution and output format, which may induce instruction-style overfitting,\nweakens out-of-distribution generalization, and ultimately affects downstream\nRL. We revisit the cold start along two views, its training method and data\nconstruction, and introduce the Generalization Factor (GF) coefficient to\nquantify the generalization capability under different methods. Our empirical\nstudy finds that preference-based training methods (e.g. DPO) generalizes\nbetter than SFT-based methods in cold start. Motivated by this, we propose\nSPECS-a Self-distilled, Preference-based Cold Start framework that decouples\nmultimodal learning: (1) generates introspective preference data pairs via\nself-distillation, avoiding reliance on larger teachers or manual annotation;\n(2) performs preference-based training to learn, focusing on shallow,\ntransferable surface-form criteria (format, structure, style) rather than\nmemorizing content; and (3) hands off to RL with verifiable rewards for deep\nreasoning results. Experimental results across multiple multimodal benchmarks\nshow that our decoupling learning framework yields consistent performance gains\nover strong baselines, improving MEGA-Bench by 4.1% and MathVista by 12.2%.\nAdditional experiments indicate that SPECS contributes to reducing\nin-distribution \"stuckness,\" improving exploration, stabilizing training, and\nraising the performance ceiling.",
    "categories": [
      "cs.LG",
      "cs.AI",
      "cs.CL",
      "cs.CV"
    ],
    "published": "2025-10-29T03:42:23Z",
    "authors": [
      "Kun Chen",
      "Peng Shi",
      "Haibo Qiu",
      "Zhixiong Zeng",
      "Siqi Yang",
      "Wenji Mao",
      "Lin Ma"
    ],
    "pdf_url": "http://arxiv.org/pdf/2510.25801v1"
  },
  {
    "id": "2510.25135v1",
    "title": "Conditional neural field for spatial dimension reduction of turbulence\n  data: a comparison study",
    "abstract": "We investigate conditional neural fields (CNFs), mesh-agnostic,\ncoordinate-based decoders conditioned on a low-dimensional latent, for spatial\ndimensionality reduction of turbulent flows. CNFs are benchmarked against\nProper Orthogonal Decomposition and a convolutional autoencoder within a\nunified encoding-decoding framework and a common evaluation protocol that\nexplicitly separates in-range (interpolative) from out-of-range (strict\nextrapolative) testing beyond the training horizon, with identical\npreprocessing, metrics, and fixed splits across all baselines. We examine three\nconditioning mechanisms: (i) activation-only modulation (often termed FiLM),\n(ii) low-rank weight and bias modulation (termed FP), and (iii) last-layer\ninner-product coupling, and introduce a novel domain-decomposed CNF that\nlocalizes complexities. Across representative turbulence datasets (WMLES\nchannel inflow, DNS channel inflow, and wall pressure fluctuations over\nturbulent boundary layers), CNF-FP achieves the lowest training and in-range\ntesting errors, while CNF-FiLM generalizes best for out-of-range scenarios once\nmoderate latent capacity is available. Domain decomposition significantly\nimproves out-of-range accuracy, especially for the more demanding datasets. The\nstudy provides a rigorous, physics-aware basis for selecting conditioning,\ncapacity, and domain decomposition when using CNFs for turbulence compression\nand reconstruction.",
    "categories": [
      "physics.flu-dyn",
      "cs.LG"
    ],
    "published": "2025-10-29T03:29:10Z",
    "authors": [
      "Junyi Guo",
      "Pan Du",
      "Xiantao Fan",
      "Yahui Li",
      "Jian-Xun Wang"
    ],
    "pdf_url": "http://arxiv.org/pdf/2510.25135v1"
  },
  {
    "id": "2510.25800v1",
    "title": "FreIE: Low-Frequency Spectral Bias in Neural Networks for Time-Series\n  Tasks",
    "abstract": "The inherent autocorrelation of time series data presents an ongoing\nchallenge to multivariate time series prediction. Recently, a widely adopted\napproach has been the incorporation of frequency domain information to assist\nin long-term prediction tasks. Many researchers have independently observed the\nspectral bias phenomenon in neural networks, where models tend to fit\nlow-frequency signals before high-frequency ones. However, these observations\nhave often been attributed to the specific architectures designed by the\nresearchers, rather than recognizing the phenomenon as a universal\ncharacteristic across models. To unify the understanding of the spectral bias\nphenomenon in long-term time series prediction, we conducted extensive\nempirical experiments to measure spectral bias in existing mainstream models.\nOur findings reveal that virtually all models exhibit this phenomenon. To\nmitigate the impact of spectral bias, we propose the FreLE (Frequency Loss\nEnhancement) algorithm, which enhances model generalization through both\nexplicit and implicit frequency regularization. This is a plug-and-play model\nloss function unit. A large number of experiments have proven the superior\nperformance of FreLE. Code is available at\nhttps://github.com/Chenxing-Xuan/FreLE.",
    "categories": [
      "cs.LG"
    ],
    "published": "2025-10-29T03:22:51Z",
    "authors": [
      "Jialong Sun",
      "Xinpeng Ling",
      "Jiaxuan Zou",
      "Jiawen Kang",
      "Kejia Zhang"
    ],
    "pdf_url": "http://arxiv.org/pdf/2510.25800v1"
  },
  {
    "id": "2510.25132v1",
    "title": "EnzyControl: Adding Functional and Substrate-Specific Control for Enzyme\n  Backbone Generation",
    "abstract": "Designing enzyme backbones with substrate-specific functionality is a\ncritical challenge in computational protein engineering. Current generative\nmodels excel in protein design but face limitations in binding data,\nsubstrate-specific control, and flexibility for de novo enzyme backbone\ngeneration. To address this, we introduce EnzyBind, a dataset with 11,100\nexperimentally validated enzyme-substrate pairs specifically curated from\nPDBbind. Building on this, we propose EnzyControl, a method that enables\nfunctional and substrate-specific control in enzyme backbone generation. Our\napproach generates enzyme backbones conditioned on MSA-annotated catalytic\nsites and their corresponding substrates, which are automatically extracted\nfrom curated enzyme-substrate data. At the core of EnzyControl is EnzyAdapter,\na lightweight, modular component integrated into a pretrained motif-scaffolding\nmodel, allowing it to become substrate-aware. A two-stage training paradigm\nfurther refines the model's ability to generate accurate and functional enzyme\nstructures. Experiments show that our EnzyControl achieves the best performance\nacross structural and functional metrics on EnzyBind and EnzyBench benchmarks,\nwith particularly notable improvements of 13\\% in designability and 13\\% in\ncatalytic efficiency compared to the baseline models. The code is released at\nhttps://github.com/Vecteur-libre/EnzyControl.",
    "categories": [
      "q-bio.BM",
      "cs.LG"
    ],
    "published": "2025-10-29T03:22:32Z",
    "authors": [
      "Chao Song",
      "Zhiyuan Liu",
      "Han Huang",
      "Liang Wang",
      "Qiong Wang",
      "Jianyu Shi",
      "Hui Yu",
      "Yihang Zhou",
      "Yang Zhang"
    ],
    "pdf_url": "http://arxiv.org/pdf/2510.25132v1"
  },
  {
    "id": "2510.25130v1",
    "title": "Lipschitz-aware Linearity Grafting for Certified Robustness",
    "abstract": "Lipschitz constant is a fundamental property in certified robustness, as\nsmaller values imply robustness to adversarial examples when a model is\nconfident in its prediction. However, identifying the worst-case adversarial\nexamples is known to be an NP-complete problem. Although over-approximation\nmethods have shown success in neural network verification to address this\nchallenge, reducing approximation errors remains a significant obstacle.\nFurthermore, these approximation errors hinder the ability to obtain tight\nlocal Lipschitz constants, which are crucial for certified robustness.\nOriginally, grafting linearity into non-linear activation functions was\nproposed to reduce the number of unstable neurons, enabling scalable and\ncomplete verification. However, no prior theoretical analysis has explained how\nlinearity grafting improves certified robustness. We instead consider linearity\ngrafting primarily as a means of eliminating approximation errors rather than\nreducing the number of unstable neurons, since linear functions do not require\nrelaxation. In this paper, we provide two theoretical contributions: 1) why\nlinearity grafting improves certified robustness through the lens of the\n$l_\\infty$ local Lipschitz constant, and 2) grafting linearity into non-linear\nactivation functions, the dominant source of approximation errors, yields a\ntighter local Lipschitz constant. Based on these theoretical contributions, we\npropose a Lipschitz-aware linearity grafting method that removes dominant\napproximation errors, which are crucial for tightening the local Lipschitz\nconstant, thereby improving certified robustness, even without certified\ntraining. Our extensive experiments demonstrate that grafting linearity into\nthese influential activations tightens the $l_\\infty$ local Lipschitz constant\nand enhances certified robustness.",
    "categories": [
      "cs.LG",
      "cs.AI"
    ],
    "published": "2025-10-29T03:19:55Z",
    "authors": [
      "Yongjin Han",
      "Suhyun Kim"
    ],
    "pdf_url": "http://arxiv.org/pdf/2510.25130v1"
  },
  {
    "id": "2510.25128v1",
    "title": "An Analysis of Causal Effect Estimation using Outcome Invariant Data\n  Augmentation",
    "abstract": "The technique of data augmentation (DA) is often used in machine learning for\nregularization purposes to better generalize under i.i.d. settings. In this\nwork, we present a unifying framework with topics in causal inference to make a\ncase for the use of DA beyond just the i.i.d. setting, but for generalization\nacross interventions as well. Specifically, we argue that when the outcome\ngenerating mechanism is invariant to our choice of DA, then such augmentations\ncan effectively be thought of as interventions on the treatment generating\nmechanism itself. This can potentially help to reduce bias in causal effect\nestimation arising from hidden confounders. In the presence of such unobserved\nconfounding we typically make use of instrumental variables (IVs) -- sources of\ntreatment randomization that are conditionally independent of the outcome.\nHowever, IVs may not be as readily available as DA for many applications, which\nis the main motivation behind this work. By appropriately regularizing IV based\nestimators, we introduce the concept of IV-like (IVL) regression for mitigating\nconfounding bias and improving predictive performance across interventions even\nwhen certain IV properties are relaxed. Finally, we cast parameterized DA as an\nIVL regression problem and show that when used in composition can simulate a\nworst-case application of such DA, further improving performance on causal\nestimation and generalization tasks beyond what simple DA may offer. This is\nshown both theoretically for the population case and via simulation experiments\nfor the finite sample case using a simple linear example. We also present real\ndata experiments to support our case.",
    "categories": [
      "cs.LG",
      "stat.ML"
    ],
    "published": "2025-10-29T03:17:19Z",
    "authors": [
      "Uzair Akbar",
      "Niki Kilbertus",
      "Hao Shen",
      "Krikamol Muandet",
      "Bo Dai"
    ],
    "pdf_url": "http://arxiv.org/pdf/2510.25128v1"
  },
  {
    "id": "2510.25798v1",
    "title": "MemEIC: A Step Toward Continual and Compositional Knowledge Editing",
    "abstract": "The dynamic nature of information necessitates continuously updating large\nvision-language models (LVLMs). While recent knowledge editing techniques hint\nat promising directions, they often focus on editing a single modality (vision\nor language) in isolation. This prevalent practice neglects the inherent\nmultimodality of LVLMs and the continuous nature of knowledge updates,\npotentially leading to suboptimal editing outcomes when considering the\ninterplay between modalities and the need for ongoing knowledge refinement. To\naddress these limitations, we propose MemEIC, a novel method for Continual and\nCompositional Knowledge Editing (CCKE) in LVLMs. MemEIC enables compositional\nediting of both visual and textual knowledge sequentially. Our approach employs\na hybrid external-internal editor featuring a dual external memory for\ncross-modal evidence retrieval and dual LoRA adapters that facilitate\ndisentangled parameter updates for each modality. A key component is a\nbrain-inspired knowledge connector, activated selectively for compositional\nreasoning, that integrates information across different modalities. Experiments\ndemonstrate that MemEIC significantly improves performance on complex\nmultimodal questions and effectively preserves prior edits, setting a new\nbenchmark for CCKE in LVLMs.",
    "categories": [
      "cs.LG",
      "cs.AI",
      "cs.CL"
    ],
    "published": "2025-10-29T03:11:59Z",
    "authors": [
      "Jin Seong",
      "Jiyun Park",
      "Wencke Liermann",
      "Hongseok Choi",
      "Yoonji Nam",
      "Hyun Kim",
      "Soojong Lim",
      "Namhoon Lee"
    ],
    "pdf_url": "http://arxiv.org/pdf/2510.25798v1"
  },
  {
    "id": "2510.25126v1",
    "title": "Bridging the Divide: End-to-End Sequence-Graph Learning",
    "abstract": "Many real-world datasets are both sequential and relational: each node\ncarries an event sequence while edges encode interactions. Existing methods in\nsequence modeling and graph modeling often neglect one modality or the other.\nWe argue that sequences and graphs are not separate problems but complementary\nfacets of the same dataset, and should be learned jointly. We introduce BRIDGE,\na unified end-to-end architecture that couples a sequence encoder with a GNN\nunder a single objective, allowing gradients to flow across both modules and\nlearning task-aligned representations. To enable fine-grained token-level\nmessage passing among neighbors, we add TOKENXATTN, a token-level\ncross-attention layer that passes messages between events in neighboring\nsequences. Across two settings, friendship prediction (Brightkite) and fraud\ndetection (Amazon), BRIDGE consistently outperforms static GNNs, temporal graph\nmethods, and sequence-only baselines on ranking and classification metrics.",
    "categories": [
      "cs.LG",
      "cs.AI"
    ],
    "published": "2025-10-29T03:06:54Z",
    "authors": [
      "Yuen Chen",
      "Yulun Wu",
      "Samuel Sharpe",
      "Igor Melnyk",
      "Nam H. Nguyen",
      "Furong Huang",
      "C. Bayan Bruss",
      "Rizal Fathony"
    ],
    "pdf_url": "http://arxiv.org/pdf/2510.25126v1"
  },
  {
    "id": "2510.25123v1",
    "title": "Learning Low Rank Neural Representations of Hyperbolic Wave Dynamics\n  from Data",
    "abstract": "We present a data-driven dimensionality reduction method that is well-suited\nfor physics-based data representing hyperbolic wave propagation. The method\nutilizes a specialized neural network architecture called low rank neural\nrepresentation (LRNR) inside a hypernetwork framework. The architecture is\nmotivated by theoretical results that rigorously prove the existence of\nefficient representations for this wave class. We illustrate through archetypal\nexamples that such an efficient low-dimensional representation of propagating\nwaves can be learned directly from data through a combination of deep learning\ntechniques. We observe that a low rank tensor representation arises naturally\nin the trained LRNRs, and that this reveals a new decomposition of wave\npropagation where each decomposed mode corresponds to interpretable physical\nfeatures. Furthermore, we demonstrate that the LRNR architecture enables\nefficient inference via a compression scheme, which is a potentially important\nfeature when deploying LRNRs in demanding performance regimes.",
    "categories": [
      "cs.LG",
      "cs.AI",
      "cs.NA",
      "math.NA",
      "68T07, 65D25, 65M22"
    ],
    "published": "2025-10-29T03:01:09Z",
    "authors": [
      "Woojin Cho",
      "Kookjin Lee",
      "Noseong Park",
      "Donsub Rim",
      "Gerrit Welper"
    ],
    "pdf_url": "http://arxiv.org/pdf/2510.25123v1"
  },
  {
    "id": "2510.25121v1",
    "title": "A Unified Bilevel Model for Adversarial Learning and A Case Study",
    "abstract": "Adversarial learning has been attracting more and more attention thanks to\nthe fast development of machine learning and artificial intelligence. However,\ndue to the complicated structure of most machine learning models, the mechanism\nof adversarial attacks is not well interpreted. How to measure the effect of\nattack is still not quite clear. In this paper, we propose a unified bilevel\nmodel for adversarial learning. We further investigate the adversarial attack\nin clustering models and interpret it from data perturbation point of view. We\nreveal that when the data perturbation is relatively small, the clustering\nmodel is robust, whereas if it is relatively large, the clustering result\nchanges, which leads to an attack. To measure the effect of attacks for\nclustering models, we analyse the well-definedness of the so-called\n$\\delta$-measure, which can be used in the proposed bilevel model for\nadversarial learning of clustering models.",
    "categories": [
      "cs.LG",
      "math.OC"
    ],
    "published": "2025-10-29T02:58:21Z",
    "authors": [
      "Yutong Zheng",
      "Qingna Li"
    ],
    "pdf_url": "http://arxiv.org/pdf/2510.25121v1"
  },
  {
    "id": "2510.25114v2",
    "title": "Energy Approach from $\\varepsilon$-Graph to Continuum Diffusion Model\n  with Connectivity Functional",
    "abstract": "We derive an energy-based continuum limit for $\\varepsilon$-graphs endowed\nwith a general connectivity functional. We prove that the discrete energy and\nits continuum counterpart differ by at most $O(\\varepsilon)$; the prefactor\ninvolves only the $W^{1,1}$-norm of the connectivity density as\n$\\varepsilon\\to0$, so the error bound remains valid even when that density has\nstrong local fluctuations. As an application, we introduce a neural-network\nprocedure that reconstructs the connectivity density from edge-weight data and\nthen embeds the resulting continuum model into a brain-dynamics framework. In\nthis setting, the usual constant diffusion coefficient is replaced by the\nspatially varying coefficient produced by the learned density, yielding\ndynamics that differ significantly from those obtained with conventional\nconstant-diffusion models.",
    "categories": [
      "math.NA",
      "cs.LG",
      "cs.NA",
      "stat.ML"
    ],
    "published": "2025-10-29T02:26:41Z",
    "authors": [
      "Yahong Yang",
      "Sun Lee",
      "Jeff Calder",
      "Wenrui Hao"
    ],
    "pdf_url": "http://arxiv.org/pdf/2510.25114v2"
  },
  {
    "id": "2510.25113v1",
    "title": "The Neural Differential Manifold: An Architecture with Explicit\n  Geometric Structure",
    "abstract": "This paper introduces the Neural Differential Manifold (NDM), a novel neural\nnetwork architecture that explicitly incorporates geometric structure into its\nfundamental design. Departing from conventional Euclidean parameter spaces, the\nNDM re-conceptualizes a neural network as a differentiable manifold where each\nlayer functions as a local coordinate chart, and the network parameters\ndirectly parameterize a Riemannian metric tensor at every point. The\narchitecture is organized into three synergistic layers: a Coordinate Layer\nimplementing smooth chart transitions via invertible transformations inspired\nby normalizing flows, a Geometric Layer that dynamically generates the\nmanifold's metric through auxiliary sub-networks, and an Evolution Layer that\noptimizes both task performance and geometric simplicity through a\ndual-objective loss function. This geometric regularization penalizes excessive\ncurvature and volume distortion, providing intrinsic regularization that\nenhances generalization and robustness. The framework enables natural gradient\ndescent optimization aligned with the learned manifold geometry and offers\nunprecedented interpretability by endowing internal representations with clear\ngeometric meaning. We analyze the theoretical advantages of this approach,\nincluding its potential for more efficient optimization, enhanced continual\nlearning, and applications in scientific discovery and controllable generative\nmodeling. While significant computational challenges remain, the Neural\nDifferential Manifold represents a fundamental shift towards geometrically\nstructured, interpretable, and efficient deep learning systems.",
    "categories": [
      "cs.LG",
      "cs.AI",
      "math.DG",
      "math.OC",
      "68T07, 62B11, 53B21, 65D18",
      "I.2.6; I.5.1; G.1.6; G.3"
    ],
    "published": "2025-10-29T02:24:27Z",
    "authors": [
      "Di Zhang"
    ],
    "pdf_url": "http://arxiv.org/pdf/2510.25113v1"
  },
  {
    "id": "2510.25108v1",
    "title": "Shift is Good: Mismatched Data Mixing Improves Test Performance",
    "abstract": "We consider training and testing on mixture distributions with different\ntraining and test proportions. We show that in many settings, and in some sense\ngenerically, distribution shift can be beneficial, and test performance can\nimprove due to mismatched training proportions, even if the components are\nunrelated and with no transfer between components. In a variety of scenarios,\nwe identify the optimal training proportions and the extent to which such\ndistribution shift can be beneficial. We show how the same analysis applies\nalso to a compositional setting with differing distribution of component\n\"skills'' at training and test.",
    "categories": [
      "cs.LG",
      "stat.ML"
    ],
    "published": "2025-10-29T02:18:15Z",
    "authors": [
      "Marko Medvedev",
      "Kaifeng Lyu",
      "Zhiyuan Li",
      "Nathan Srebro"
    ],
    "pdf_url": "http://arxiv.org/pdf/2510.25108v1"
  },
  {
    "id": "2510.25096v1",
    "title": "Learning Fair Graph Representations with Multi-view Information\n  Bottleneck",
    "abstract": "Graph neural networks (GNNs) excel on relational data by passing messages\nover node features and structure, but they can amplify training data biases,\npropagating discriminatory attributes and structural imbalances into unfair\noutcomes. Many fairness methods treat bias as a single source, ignoring\ndistinct attribute and structure effects and leading to suboptimal fairness and\nutility trade-offs. To overcome this challenge, we propose FairMIB, a\nmulti-view information bottleneck framework designed to decompose graphs into\nfeature, structural, and diffusion views for mitigating complexity biases in\nGNNs. Especially, the proposed FairMIB employs contrastive learning to maximize\ncross-view mutual information for bias-free representation learning. It further\nintegrates multi-perspective conditional information bottleneck objectives to\nbalance task utility and fairness by minimizing mutual information with\nsensitive attributes. Additionally, FairMIB introduces an inverse\nprobability-weighted (IPW) adjacency correction in the diffusion view, which\nreduces the spread of bias propagation during message passing. Experiments on\nfive real-world benchmark datasets demonstrate that FairMIB achieves\nstate-of-the-art performance across both utility and fairness metrics.",
    "categories": [
      "cs.LG",
      "cs.AI"
    ],
    "published": "2025-10-29T02:02:12Z",
    "authors": [
      "Chuxun Liu",
      "Debo Cheng",
      "Qingfeng Chen",
      "Jiangzhang Gan",
      "Jiuyong Li",
      "Lin Liu"
    ],
    "pdf_url": "http://arxiv.org/pdf/2510.25096v1"
  },
  {
    "id": "2510.25093v1",
    "title": "Continual Low-Rank Adapters for LLM-based Generative Recommender Systems",
    "abstract": "While large language models (LLMs) achieve strong performance in\nrecommendation, they face challenges in continual learning as users, items, and\nuser preferences evolve over time. Existing LoRA-based continual methods\nprimarily focus on preserving performance on previous tasks, but this overlooks\nthe unique nature of recommendation: the goal is not to predict past\npreferences, and outdated preferences can even harm performance when current\ninterests shift significantly. To address this, we propose PESO (Proximally\nrEgularized Single evolving lOra, a continual adaptation method for LoRA in\nrecommendation. PESO introduces a proximal regularizer that anchors the current\nadapter to its most recent frozen state, enabling the model to flexibly balance\nadaptation and preservation, and to better capture recent user behaviors.\nTheoretically, we show that this proximal design provides data-aware,\ndirection-wise guidance in the LoRA subspace. Empirically, PESO consistently\noutperforms existing LoRA-based continual learning methods.",
    "categories": [
      "cs.LG",
      "cs.IR"
    ],
    "published": "2025-10-29T01:57:38Z",
    "authors": [
      "Hyunsik Yoo",
      "Ting-Wei Li",
      "SeongKu Kang",
      "Zhining Liu",
      "Charlie Xu",
      "Qilin Qi",
      "Hanghang Tong"
    ],
    "pdf_url": "http://arxiv.org/pdf/2510.25093v1"
  },
  {
    "id": "2510.25087v1",
    "title": "BioCoref: Benchmarking Biomedical Coreference Resolution with LLMs",
    "abstract": "Coreference resolution in biomedical texts presents unique challenges due to\ncomplex domain-specific terminology, high ambiguity in mention forms, and\nlong-distance dependencies between coreferring expressions. In this work, we\npresent a comprehensive evaluation of generative large language models (LLMs)\nfor coreference resolution in the biomedical domain. Using the CRAFT corpus as\nour benchmark, we assess the LLMs' performance with four prompting experiments\nthat vary in their use of local, contextual enrichment, and domain-specific\ncues such as abbreviations and entity dictionaries. We benchmark these\napproaches against a discriminative span-based encoder, SpanBERT, to compare\nthe efficacy of generative versus discriminative methods. Our results\ndemonstrate that while LLMs exhibit strong surface-level coreference\ncapabilities, especially when supplemented with domain-grounding prompts, their\nperformance remains sensitive to long-range context and mentions ambiguity.\nNotably, the LLaMA 8B and 17B models show superior precision and F1 scores\nunder entity-augmented prompting, highlighting the potential of lightweight\nprompt engineering for enhancing LLM utility in biomedical NLP tasks.",
    "categories": [
      "cs.CL",
      "cs.LG"
    ],
    "published": "2025-10-29T01:51:00Z",
    "authors": [
      "Nourah M Salem",
      "Elizabeth White",
      "Michael Bada",
      "Lawrence Hunter"
    ],
    "pdf_url": "http://arxiv.org/pdf/2510.25087v1"
  },
  {
    "id": "2510.25080v2",
    "title": "Monopoly Deal: A Benchmark Environment for Bounded One-Sided Response\n  Games",
    "abstract": "Card games are widely used to study sequential decision-making under\nuncertainty, with real-world analogues in negotiation, finance, and\ncybersecurity. These games typically fall into three categories based on the\nflow of control: strictly sequential (players alternate single actions),\ndeterministic response (some actions trigger a fixed outcome), and unbounded\nreciprocal response (alternating counterplays are permitted). A less-explored\nbut strategically rich structure is the bounded one-sided response, where a\nplayer's action briefly transfers control to the opponent, who must satisfy a\nfixed condition through one or more moves before the turn resolves. We term\ngames featuring this mechanism Bounded One-Sided Response Games (BORGs). We\nintroduce a modified version of Monopoly Deal as a benchmark environment that\nisolates this dynamic, where a Rent action forces the opponent to choose\npayment assets. The gold-standard algorithm, Counterfactual Regret Minimization\n(CFR), converges on effective strategies without novel algorithmic extensions.\nA lightweight full-stack research platform unifies the environment, a\nparallelized CFR runtime, and a human-playable web interface. The trained CFR\nagent and source code are available at https://monopolydeal.ai.",
    "categories": [
      "cs.GT",
      "cs.AI",
      "cs.LG"
    ],
    "published": "2025-10-29T01:38:19Z",
    "authors": [
      "Will Wolf"
    ],
    "pdf_url": "http://arxiv.org/pdf/2510.25080v2"
  },
  {
    "id": "2510.25074v1",
    "title": "Training Across Reservoirs: Using Numerical Differentiation To Couple\n  Trainable Networks With Black-Box Reservoirs",
    "abstract": "We introduce Bounded Numerical Differentiation (BOND), a perturbative method\nfor estimating partial derivatives across network structures with inaccessible\ncomputational graphs. BOND demonstrates improved accuracy and scalability from\nexisting perturbative methods, enabling new explorations of trainable\narchitectures that integrate black-box functions. We observe that these\nblack-box functions, realized in our experiments as fixed, untrained networks,\ncan enhance model performance without increasing the number of trainable\nparameters. This improvement is achieved without extensive optimization of the\narchitecture or properties of the black-box function itself. Our findings\nhighlight the potential of leveraging fixed, non-trainable modules to expand\nmodel capacity, suggesting a path toward combining analogue and digital devices\nas a mechanism for scaling networks.",
    "categories": [
      "cs.LG",
      "I.2.6"
    ],
    "published": "2025-10-29T01:19:50Z",
    "authors": [
      "Andrew Clark",
      "Jack Moursounidis",
      "Osmaan Rasouli",
      "William Gan",
      "Cooper Doyle",
      "Anna Leontjeva"
    ],
    "pdf_url": "http://arxiv.org/pdf/2510.25074v1"
  },
  {
    "id": "2510.25060v1",
    "title": "Nonlinear Dynamics In Optimization Landscape of Shallow Neural Networks\n  with Tunable Leaky ReLU",
    "abstract": "In this work, we study the nonlinear dynamics of a shallow neural network\ntrained with mean-squared loss and leaky ReLU activation. Under Gaussian inputs\nand equal layer width k, (1) we establish, based on the equivariant gradient\ndegree, a theoretical framework, applicable to any number of neurons k>= 4, to\ndetect bifurcation of critical points with associated symmetries from global\nminimum as leaky parameter $\\alpha$ varies. Typically, our analysis reveals\nthat a multi-mode degeneracy consistently occurs at the critical number 0,\nindependent of k. (2) As a by-product, we further show that such bifurcations\nare width-independent, arise only for nonnegative $\\alpha$ and that the global\nminimum undergoes no further symmetry-breaking instability throughout the\nengineering regime $\\alpha$ in range (0,1). An explicit example with k=5 is\npresented to illustrate the framework and exhibit the resulting bifurcation\ntogether with their symmetries.",
    "categories": [
      "math.OC",
      "cs.LG",
      "math.DS"
    ],
    "published": "2025-10-29T01:00:07Z",
    "authors": [
      "Jingzhou Liu"
    ],
    "pdf_url": "http://arxiv.org/pdf/2510.25060v1"
  },
  {
    "id": "2510.25055v1",
    "title": "GAPMAP: Mapping Scientific Knowledge Gaps in Biomedical Literature Using\n  Large Language Models",
    "abstract": "Scientific progress is driven by the deliberate articulation of what remains\nunknown. This study investigates the ability of large language models (LLMs) to\nidentify research knowledge gaps in the biomedical literature. We define two\ncategories of knowledge gaps: explicit gaps, clear declarations of missing\nknowledge; and implicit gaps, context-inferred missing knowledge. While prior\nwork has focused mainly on explicit gap detection, we extend this line of\nresearch by addressing the novel task of inferring implicit gaps. We conducted\ntwo experiments on almost 1500 documents across four datasets, including a\nmanually annotated corpus of biomedical articles. We benchmarked both\nclosed-weight models (from OpenAI) and open-weight models (Llama and Gemma 2)\nunder paragraph-level and full-paper settings. To address the reasoning of\nimplicit gaps inference, we introduce \\textbf{\\small TABI}, a Toulmin-Abductive\nBucketed Inference scheme that structures reasoning and buckets inferred\nconclusion candidates for validation. Our results highlight the robust\ncapability of LLMs in identifying both explicit and implicit knowledge gaps.\nThis is true for both open- and closed-weight models, with larger variants\noften performing better. This suggests a strong ability of LLMs for\nsystematically identifying candidate knowledge gaps, which can support\nearly-stage research formulation, policymakers, and funding decisions. We also\nreport observed failure modes and outline directions for robust deployment,\nincluding domain adaptation, human-in-the-loop verification, and benchmarking\nacross open- and closed-weight models.",
    "categories": [
      "cs.CL",
      "cs.AI",
      "cs.LG"
    ],
    "published": "2025-10-29T00:46:45Z",
    "authors": [
      "Nourah M Salem",
      "Elizabeth White",
      "Michael Bada",
      "Lawrence Hunter"
    ],
    "pdf_url": "http://arxiv.org/pdf/2510.25055v1"
  },
  {
    "id": "2510.25053v1",
    "title": "Scalable predictive processing framework for multitask caregiving robots",
    "abstract": "The rapid aging of societies is intensifying demand for autonomous care\nrobots; however, most existing systems are task-specific and rely on\nhandcrafted preprocessing, limiting their ability to generalize across diverse\nscenarios. A prevailing theory in cognitive neuroscience proposes that the\nhuman brain operates through hierarchical predictive processing, which\nunderlies flexible cognition and behavior by integrating multimodal sensory\nsignals. Inspired by this principle, we introduce a hierarchical multimodal\nrecurrent neural network grounded in predictive processing under the\nfree-energy principle, capable of directly integrating over 30,000-dimensional\nvisuo-proprioceptive inputs without dimensionality reduction. The model was\nable to learn two representative caregiving tasks, rigid-body repositioning and\nflexible-towel wiping, without task-specific feature engineering. We\ndemonstrate three key properties: (i) self-organization of hierarchical latent\ndynamics that regulate task transitions, capture variability in uncertainty,\nand infer occluded states; (ii) robustness to degraded vision through\nvisuo-proprioceptive integration; and (iii) asymmetric interference in\nmultitask learning, where the more variable wiping task had little influence on\nrepositioning, whereas learning the repositioning task led to a modest\nreduction in wiping performance, while the model maintained overall robustness.\nAlthough the evaluation was limited to simulation, these results establish\npredictive processing as a universal and scalable computational principle,\npointing toward robust, flexible, and autonomous caregiving robots while\noffering theoretical insight into the human brain's ability to achieve flexible\nadaptation in uncertain real-world environments.",
    "categories": [
      "cs.RO",
      "cs.AI",
      "cs.LG",
      "q-bio.NC"
    ],
    "published": "2025-10-29T00:39:09Z",
    "authors": [
      "Hayato Idei",
      "Tamon Miyake",
      "Tetsuya Ogata",
      "Yuichi Yamashita"
    ],
    "pdf_url": "http://arxiv.org/pdf/2510.25053v1"
  },
  {
    "id": "2510.25051v1",
    "title": "Breast Cancer VLMs: Clinically Practical Vision-Language Train-Inference\n  Models",
    "abstract": "Breast cancer remains the most commonly diagnosed malignancy among women in\nthe developed world. Early detection through mammography screening plays a\npivotal role in reducing mortality rates. While computer-aided diagnosis (CAD)\nsystems have shown promise in assisting radiologists, existing approaches face\ncritical limitations in clinical deployment - particularly in handling the\nnuanced interpretation of multi-modal data and feasibility due to the\nrequirement of prior clinical history. This study introduces a novel framework\nthat synergistically combines visual features from 2D mammograms with\nstructured textual descriptors derived from easily accessible clinical metadata\nand synthesized radiological reports through innovative tokenization modules.\nOur proposed methods in this study demonstrate that strategic integration of\nconvolutional neural networks (ConvNets) with language representations achieves\nsuperior performance to vision transformer-based models while handling\nhigh-resolution images and enabling practical deployment across diverse\npopulations. By evaluating it on multi-national cohort screening mammograms,\nour multi-modal approach achieves superior performance in cancer detection and\ncalcification identification compared to unimodal baselines, with particular\nimprovements. The proposed method establishes a new paradigm for developing\nclinically viable VLM-based CAD systems that effectively leverage imaging data\nand contextual patient information through effective fusion mechanisms.",
    "categories": [
      "cs.CV",
      "cs.LG"
    ],
    "published": "2025-10-29T00:37:18Z",
    "authors": [
      "Shunjie-Fabian Zheng",
      "Hyeonjun Lee",
      "Thijs Kooi",
      "Ali Diba"
    ],
    "pdf_url": "http://arxiv.org/pdf/2510.25051v1"
  },
  {
    "id": "2510.25042v1",
    "title": "Dynamically Weighted Momentum with Adaptive Step Sizes for Efficient\n  Deep Network Training",
    "abstract": "Within the current sphere of deep learning research, despite the extensive\napplication of optimization algorithms such as Stochastic Gradient Descent\n(SGD) and Adaptive Moment Estimation (Adam), there remains a pronounced\ninadequacy in their capability to address fluctuations in learning efficiency,\nmeet the demands of complex models, and tackle non-convex optimization issues.\nThese challenges primarily arise from the algorithms' limitations in handling\ncomplex data structures and models, for instance, difficulties in selecting an\nappropriate learning rate, avoiding local optima, and navigating through\nhigh-dimensional spaces. To address these issues, this paper introduces a novel\noptimization algorithm named DWMGrad. This algorithm, building on the\nfoundations of traditional methods, incorporates a dynamic guidance mechanism\nreliant on historical data to dynamically update momentum and learning rates.\nThis allows the optimizer to flexibly adjust its reliance on historical\ninformation, adapting to various training scenarios. This strategy not only\nenables the optimizer to better adapt to changing environments and task\ncomplexities but also, as validated through extensive experimentation,\ndemonstrates DWMGrad's ability to achieve faster convergence rates and higher\naccuracies under a multitude of scenarios.",
    "categories": [
      "cs.LG",
      "cs.NE"
    ],
    "published": "2025-10-29T00:03:03Z",
    "authors": [
      "Zhifeng Wang",
      "Longlong Li",
      "Chunyan Zeng"
    ],
    "pdf_url": "http://arxiv.org/pdf/2510.25042v1"
  },
  {
    "id": "2510.25039v1",
    "title": "Automating Benchmark Design",
    "abstract": "The rapid progress and widespread deployment of LLMs and LLM-powered agents\nhas outpaced our ability to evaluate them. Hand-crafted, static benchmarks are\nthe primary tool for assessing model capabilities, but these quickly become\nsaturated. In contrast, dynamic benchmarks evolve alongside the models they\nevaluate, but are expensive to create and continuously update. To address these\nchallenges, we develop BeTaL (Benchmark Tuning with an LLM-in-the-loop), a\nframework that leverages environment design principles to automate the process\nof dynamic benchmark design. BeTaL works by parameterizing key design choices\nin base benchmark templates and uses LLMs to reason through the resulting\nparameter space to obtain target properties (such as difficulty and realism) in\na cost-efficient manner. We validate this approach on its ability to create\nbenchmarks with desired difficulty levels. Using BeTaL, we create two new\nbenchmarks and extend a popular agentic benchmark $\\tau$-bench. Extensive\nevaluation on these three tasks and multiple target difficulty levels shows\nthat BeTaL produces benchmarks much closer to the desired difficulty, with\naverage deviations ranging from 5.3% to 13.2% -- a 2-4x improvement over the\nbaselines.",
    "categories": [
      "cs.SE",
      "cs.LG"
    ],
    "published": "2025-10-28T23:53:36Z",
    "authors": [
      "Amanda Dsouza",
      "Harit Vishwakarma",
      "Zhengyang Qi",
      "Justin Bauer",
      "Derek Pham",
      "Thomas Walshe",
      "Armin Parchami",
      "Frederic Sala",
      "Paroma Varma"
    ],
    "pdf_url": "http://arxiv.org/pdf/2510.25039v1"
  },
  {
    "id": "2510.25037v1",
    "title": "Graph Distance Based on Cause-Effect Estimands with Latents",
    "abstract": "Causal discovery aims to recover graphs that represent causal relations among\ngiven variables from observations, and new methods are constantly being\nproposed. Increasingly, the community raises questions about how much progress\nis made, because properly evaluating discovered graphs remains notoriously\ndifficult, particularly under latent confounding. We propose a graph distance\nmeasure for acyclic directed mixed graphs (ADMGs) based on the downstream task\nof cause-effect estimation under unobserved confounding. Our approach uses\nidentification via fixing and a symbolic verifier to quantify how graph\ndifferences distort cause-effect estimands for different treatment-outcome\npairs. We analyze the behavior of the measure under different graph\nperturbations and compare it against existing distance metrics.",
    "categories": [
      "cs.LG"
    ],
    "published": "2025-10-28T23:38:43Z",
    "authors": [
      "Zhufeng Li",
      "Niki Kilbertus"
    ],
    "pdf_url": "http://arxiv.org/pdf/2510.25037v1"
  },
  {
    "id": "2510.25796v1",
    "title": "Non-myopic Matching and Rebalancing in Large-Scale On-Demand\n  Ride-Pooling Systems Using Simulation-Informed Reinforcement Learning",
    "abstract": "Ride-pooling, also known as ride-sharing, shared ride-hailing, or\nmicrotransit, is a service wherein passengers share rides. This service can\nreduce costs for both passengers and operators and reduce congestion and\nenvironmental impacts. A key limitation, however, is its myopic\ndecision-making, which overlooks long-term effects of dispatch decisions. To\naddress this, we propose a simulation-informed reinforcement learning (RL)\napproach. While RL has been widely studied in the context of ride-hailing\nsystems, its application in ride-pooling systems has been less explored. In\nthis study, we extend the learning and planning framework of Xu et al. (2018)\nfrom ride-hailing to ride-pooling by embedding a ride-pooling simulation within\nthe learning mechanism to enable non-myopic decision-making. In addition, we\npropose a complementary policy for rebalancing idle vehicles. By employing\nn-step temporal difference learning on simulated experiences, we derive\nspatiotemporal state values and subsequently evaluate the effectiveness of the\nnon-myopic policy using NYC taxi request data. Results demonstrate that the\nnon-myopic policy for matching can increase the service rate by up to 8.4%\nversus a myopic policy while reducing both in-vehicle and wait times for\npassengers. Furthermore, the proposed non-myopic policy can decrease fleet size\nby over 25% compared to a myopic policy, while maintaining the same level of\nperformance, thereby offering significant cost savings for operators.\nIncorporating rebalancing operations into the proposed framework cuts wait time\nby up to 27.3%, in-vehicle time by 12.5%, and raises service rate by 15.1%\ncompared to using the framework for matching decisions alone at the cost of\nincreased vehicle minutes traveled per passenger.",
    "categories": [
      "cs.LG",
      "cs.AI",
      "cs.CY"
    ],
    "published": "2025-10-28T23:21:27Z",
    "authors": [
      "Farnoosh Namdarpour",
      "Joseph Y. J. Chow"
    ],
    "pdf_url": "http://arxiv.org/pdf/2510.25796v1"
  },
  {
    "id": "2510.25026v1",
    "title": "Machine Learning based Analysis for Radiomics Features Robustness in\n  Real-World Deployment Scenarios",
    "abstract": "Radiomics-based machine learning models show promise for clinical decision\nsupport but are vulnerable to distribution shifts caused by variations in\nimaging protocols, positioning, and segmentation. This study systematically\ninvestigates the robustness of radiomics-based machine learning models under\ndistribution shifts across five MRI sequences. We evaluated how different\nacquisition protocols and segmentation strategies affect model reliability in\nterms of predictive power and uncertainty-awareness. Using a phantom of 16\nfruits, we evaluated distribution shifts through: (1) protocol variations\nacross T2-HASTE, T2-TSE, T2-MAP, T1-TSE, and T2-FLAIR sequences; (2)\nsegmentation variations (full, partial, rotated); and (3) inter-observer\nvariability. We trained XGBoost classifiers on 8 consistent robust features\nversus sequence-specific features, testing model performance under in-domain\nand out-of-domain conditions. Results demonstrate that models trained on\nprotocol-invariant features maintain F1-scores >0.85 across distribution\nshifts, while models using all features showed 40% performance degradation\nunder protocol changes. Dataset augmentation substantially improved the quality\nof uncertainty estimates and reduced the expected calibration error (ECE) by\n35% without sacrificing accuracy. Temperature scaling provided minimal\ncalibration benefits, confirming XGBoost's inherent reliability. Our findings\nreveal that protocol-aware feature selection and controlled phantom studies\neffectively predict model behavior under distribution shifts, providing a\nframework for developing robust radiomics models resilient to real-world\nprotocol variations.",
    "categories": [
      "cs.LG"
    ],
    "published": "2025-10-28T22:54:43Z",
    "authors": [
      "Sarmad Ahmad Khan",
      "Simon Bernatz",
      "Zahra Moslehi",
      "Florian Buettner"
    ],
    "pdf_url": "http://arxiv.org/pdf/2510.25026v1"
  },
  {
    "id": "2510.25025v1",
    "title": "Secure Retrieval-Augmented Generation against Poisoning Attacks",
    "abstract": "Large language models (LLMs) have transformed natural language processing\n(NLP), enabling applications from content generation to decision support.\nRetrieval-Augmented Generation (RAG) improves LLMs by incorporating external\nknowledge but also introduces security risks, particularly from data poisoning,\nwhere the attacker injects poisoned texts into the knowledge database to\nmanipulate system outputs. While various defenses have been proposed, they\noften struggle against advanced attacks. To address this, we introduce RAGuard,\na detection framework designed to identify poisoned texts. RAGuard first\nexpands the retrieval scope to increase the proportion of clean texts, reducing\nthe likelihood of retrieving poisoned content. It then applies chunk-wise\nperplexity filtering to detect abnormal variations and text similarity\nfiltering to flag highly similar texts. This non-parametric approach enhances\nRAG security, and experiments on large-scale datasets demonstrate its\neffectiveness in detecting and mitigating poisoning attacks, including strong\nadaptive attacks.",
    "categories": [
      "cs.CR",
      "cs.IR",
      "cs.LG"
    ],
    "published": "2025-10-28T22:54:19Z",
    "authors": [
      "Zirui Cheng",
      "Jikai Sun",
      "Anjun Gao",
      "Yueyang Quan",
      "Zhuqing Liu",
      "Xiaohua Hu",
      "Minghong Fang"
    ],
    "pdf_url": "http://arxiv.org/pdf/2510.25025v1"
  },
  {
    "id": "2510.25023v1",
    "title": "Disentangling Shared and Private Neural Dynamics with SPIRE: A Latent\n  Modeling Framework for Deep Brain Stimulation",
    "abstract": "Disentangling shared network-level dynamics from region-specific activity is\na central challenge in modeling multi-region neural data. We introduce SPIRE\n(Shared-Private Inter-Regional Encoder), a deep multi-encoder autoencoder that\nfactorizes recordings into shared and private latent subspaces with novel\nalignment and disentanglement losses. Trained solely on baseline data, SPIRE\nrobustly recovers cross-regional structure and reveals how external\nperturbations reorganize it. On synthetic benchmarks with ground-truth latents,\nSPIRE outperforms classical probabilistic models under nonlinear distortions\nand temporal misalignments. Applied to intracranial deep brain stimulation\n(DBS) recordings, SPIRE shows that shared latents reliably encode\nstimulation-specific signatures that generalize across sites and frequencies.\nThese results establish SPIRE as a practical, reproducible tool for analyzing\nmulti-region neural dynamics under stimulation.",
    "categories": [
      "cs.LG",
      "eess.SP"
    ],
    "published": "2025-10-28T22:45:52Z",
    "authors": [
      "Rahil Soroushmojdehi",
      "Sina Javadzadeh",
      "Mehrnaz Asadi",
      "Terence D. Sanger"
    ],
    "pdf_url": "http://arxiv.org/pdf/2510.25023v1"
  },
  {
    "id": "2510.25016v1",
    "title": "Towards Human-AI Synergy in Requirements Engineering: A Framework and\n  Preliminary Study",
    "abstract": "The future of Requirements Engineering (RE) is increasingly driven by\nartificial intelligence (AI), reshaping how we elicit, analyze, and validate\nrequirements. Traditional RE is based on labor-intensive manual processes prone\nto errors and complexity. AI-powered approaches, specifically large language\nmodels (LLMs), natural language processing (NLP), and generative AI, offer\ntransformative solutions and reduce inefficiencies. However, the use of AI in\nRE also brings challenges like algorithmic bias, lack of explainability, and\nethical concerns related to automation. To address these issues, this study\nintroduces the Human-AI RE Synergy Model (HARE-SM), a conceptual framework that\nintegrates AI-driven analysis with human oversight to improve requirements\nelicitation, analysis, and validation. The model emphasizes ethical AI use\nthrough transparency, explainability, and bias mitigation. We outline a\nmulti-phase research methodology focused on preparing RE datasets, fine-tuning\nAI models, and designing collaborative human-AI workflows. This preliminary\nstudy presents the conceptual framework and early-stage prototype\nimplementation, establishing a research agenda and practical design direction\nfor applying intelligent data science techniques to semi-structured and\nunstructured RE data in collaborative environments.",
    "categories": [
      "cs.SE",
      "cs.AI",
      "cs.HC",
      "cs.LG",
      "68T07, 68N30",
      "D.2.1; I.2.6; I.2.7"
    ],
    "published": "2025-10-28T22:29:11Z",
    "authors": [
      "Mateen Ahmed Abbasi",
      "Petri Ihantola",
      "Tommi Mikkonen",
      "Niko M\u00e4kitalo"
    ],
    "pdf_url": "http://arxiv.org/pdf/2510.25016v1"
  },
  {
    "id": "2510.25013v1",
    "title": "Emergence of Minimal Circuits for Indirect Object Identification in\n  Attention-Only Transformers",
    "abstract": "Mechanistic interpretability aims to reverse-engineer large language models\n(LLMs) into human-understandable computational circuits. However, the\ncomplexity of pretrained models often obscures the minimal mechanisms required\nfor specific reasoning tasks. In this work, we train small, attention-only\ntransformers from scratch on a symbolic version of the Indirect Object\nIdentification (IOI) task -- a benchmark for studying coreference -- like\nreasoning in transformers. Surprisingly, a single-layer model with only two\nattention heads achieves perfect IOI accuracy, despite lacking MLPs and\nnormalization layers. Through residual stream decomposition, spectral analysis,\nand embedding interventions, we find that the two heads specialize into\nadditive and contrastive subcircuits that jointly implement IOI resolution.\nFurthermore, we show that a two-layer, one-head model achieves similar\nperformance by composing information across layers through query-value\ninteractions. These results demonstrate that task-specific training induces\nhighly interpretable, minimal circuits, offering a controlled testbed for\nprobing the computational foundations of transformer reasoning.",
    "categories": [
      "cs.CL",
      "cs.AI",
      "cs.LG"
    ],
    "published": "2025-10-28T22:25:19Z",
    "authors": [
      "Rabin Adhikari"
    ],
    "pdf_url": "http://arxiv.org/pdf/2510.25013v1"
  },
  {
    "id": "2510.25007v1",
    "title": "Taming the Real-world Complexities in CPT E/M Coding with Large Language\n  Models",
    "abstract": "Evaluation and Management (E/M) coding, under the Current Procedural\nTerminology (CPT) taxonomy, documents medical services provided to patients by\nphysicians. Used primarily for billing purposes, it is in physicians' best\ninterest to provide accurate CPT E/M codes. %While important, it is an\nauxiliary task that adds to physicians' documentation burden. Automating this\ncoding task will help alleviate physicians' documentation burden, improve\nbilling efficiency, and ultimately enable better patient care. However, a\nnumber of real-world complexities have made E/M encoding automation a\nchallenging task. In this paper, we elaborate some of the key complexities and\npresent ProFees, our LLM-based framework that tackles them, followed by a\nsystematic evaluation. On an expert-curated real-world dataset, ProFees\nachieves an increase in coding accuracy of more than 36\\% over a commercial CPT\nE/M coding system and almost 5\\% over our strongest single-prompt baseline,\ndemonstrating its effectiveness in addressing the real-world complexities.",
    "categories": [
      "cs.AI",
      "cs.LG"
    ],
    "published": "2025-10-28T22:06:59Z",
    "authors": [
      "Islam Nassar",
      "Yang Lin",
      "Yuan Jin",
      "Rongxin Zhu",
      "Chang Wei Tan",
      "Zenan Zhai",
      "Nitika Mathur",
      "Thanh Tien Vu",
      "Xu Zhong",
      "Long Duong",
      "Yuan-Fang Li"
    ],
    "pdf_url": "http://arxiv.org/pdf/2510.25007v1"
  },
  {
    "id": "2510.25005v1",
    "title": "Cyclic Counterfactuals under Shift-Scale Interventions",
    "abstract": "Most counterfactual inference frameworks traditionally assume acyclic\nstructural causal models (SCMs), i.e. directed acyclic graphs (DAGs). However,\nmany real-world systems (e.g. biological systems) contain feedback loops or\ncyclic dependencies that violate acyclicity. In this work, we study\ncounterfactual inference in cyclic SCMs under shift-scale interventions, i.e.,\nsoft, policy-style changes that rescale and/or shift a variable's mechanism.",
    "categories": [
      "cs.AI",
      "cs.LG",
      "math.ST",
      "stat.ML",
      "stat.TH"
    ],
    "published": "2025-10-28T22:03:01Z",
    "authors": [
      "Saptarshi Saha",
      "Dhruv Vansraj Rathore",
      "Utpal Garain"
    ],
    "pdf_url": "http://arxiv.org/pdf/2510.25005v1"
  },
  {
    "id": "2510.25001v1",
    "title": "Bayesian Neural Networks vs. Mixture Density Networks: Theoretical and\n  Empirical Insights for Uncertainty-Aware Nonlinear Modeling",
    "abstract": "This paper investigates two prominent probabilistic neural modeling\nparadigms: Bayesian Neural Networks (BNNs) and Mixture Density Networks (MDNs)\nfor uncertainty-aware nonlinear regression. While BNNs incorporate epistemic\nuncertainty by placing prior distributions over network parameters, MDNs\ndirectly model the conditional output distribution, thereby capturing\nmultimodal and heteroscedastic data-generating mechanisms. We present a unified\ntheoretical and empirical framework comparing these approaches. On the\ntheoretical side, we derive convergence rates and error bounds under H\\\"older\nsmoothness conditions, showing that MDNs achieve faster Kullback-Leibler (KL)\ndivergence convergence due to their likelihood-based nature, whereas BNNs\nexhibit additional approximation bias induced by variational inference.\nEmpirically, we evaluate both architectures on synthetic nonlinear datasets and\na radiographic benchmark (RSNA Pediatric Bone Age Challenge). Quantitative and\nqualitative results demonstrate that MDNs more effectively capture multimodal\nresponses and adaptive uncertainty, whereas BNNs provide more interpretable\nepistemic uncertainty under limited data. Our findings clarify the\ncomplementary strengths of posterior-based and likelihood-based probabilistic\nlearning, offering guidance for uncertainty-aware modeling in nonlinear\nsystems.",
    "categories": [
      "stat.CO",
      "cs.LG",
      "68T07, 62G08, 62C10, 41A25"
    ],
    "published": "2025-10-28T22:00:30Z",
    "authors": [
      "Riddhi Pratim Ghosh",
      "Ian Barnett"
    ],
    "pdf_url": "http://arxiv.org/pdf/2510.25001v1"
  },
  {
    "id": "2510.25000v1",
    "title": "What Really Matters in Matrix-Whitening Optimizers?",
    "abstract": "A range of recent optimizers have emerged that approximate the same\n\"matrix-whitening\" transformation in various ways. In this work, we\nsystematically deconstruct such optimizers, aiming to disentangle the key\ncomponents that explain performance. Across tuned hyperparameters across the\nboard, all flavors of matrix-whitening methods reliably outperform elementwise\ncounterparts, such as Adam. Matrix-whitening is often related to spectral\ndescent -- however, experiments reveal that performance gains are *not\nexplained solely by accurate spectral normalization* -- particularly, SOAP\ndisplays the largest per-step gain, even though Muon more accurately descends\nalong the steepest spectral descent direction. Instead, we argue that\nmatrix-whitening serves two purposes, and the variance adaptation component of\nmatrix-whitening is the overlooked ingredient explaining this performance gap.\nExperiments show that variance-adapted versions of optimizers consistently\noutperform their sign-descent counterparts, including an adaptive version of\nMuon. We further ablate variance adaptation strategies, finding that while\nlookahead style approximations are not as effective, low-rank variance\nestimators can effectively reduce memory costs without a performance loss.",
    "categories": [
      "cs.LG"
    ],
    "published": "2025-10-28T21:59:49Z",
    "authors": [
      "Kevin Frans",
      "Pieter Abbeel",
      "Sergey Levine"
    ],
    "pdf_url": "http://arxiv.org/pdf/2510.25000v1"
  },
  {
    "id": "2510.25793v1",
    "title": "Optimal Information Combining for Multi-Agent Systems Using Adaptive\n  Bias Learning",
    "abstract": "Modern multi-agent systems ranging from sensor networks monitoring critical\ninfrastructure to crowdsourcing platforms aggregating human intelligence can\nsuffer significant performance degradation due to systematic biases that vary\nwith environmental conditions. Current approaches either ignore these biases,\nleading to suboptimal decisions, or require expensive calibration procedures\nthat are often infeasible in practice. This performance gap has real\nconsequences: inaccurate environmental monitoring, unreliable financial\npredictions, and flawed aggregation of human judgments. This paper addresses\nthe fundamental question: when can we learn and correct for these unknown\nbiases to recover near-optimal performance, and when is such learning futile?\nWe develop a theoretical framework that decomposes biases into learnable\nsystematic components and irreducible stochastic components, introducing the\nconcept of learnability ratio as the fraction of bias variance predictable from\nobservable covariates. This ratio determines whether bias learning is\nworthwhile for a given system. We prove that the achievable performance\nimprovement is fundamentally bounded by this learnability ratio, providing\nsystem designers with quantitative guidance on when to invest in bias learning\nversus simpler approaches. We present the Adaptive Bias Learning and Optimal\nCombining (ABLOC) algorithm, which iteratively learns bias-correcting\ntransformations while optimizing combination weights through closedform\nsolutions, guaranteeing convergence to these theoretical bounds. Experimental\nvalidation demonstrates that systems with high learnability ratios can recover\nsignificant performance (we achieved 40%-70% of theoretical maximum improvement\nin our examples), while those with low learnability show minimal benefit,\nvalidating our diagnostic criteria for practical deployment decisions.",
    "categories": [
      "cs.LG",
      "cs.IT",
      "math.IT"
    ],
    "published": "2025-10-28T21:52:33Z",
    "authors": [
      "Siavash M. Alamouti",
      "Fay Arjomandi"
    ],
    "pdf_url": "http://arxiv.org/pdf/2510.25793v1"
  },
  {
    "id": "2510.24988v1",
    "title": "Enhancing Hierarchical Reinforcement Learning through Change Point\n  Detection in Time Series",
    "abstract": "Hierarchical Reinforcement Learning (HRL) enhances the scalability of\ndecision-making in long-horizon tasks by introducing temporal abstraction\nthrough options-policies that span multiple timesteps. Despite its theoretical\nappeal, the practical implementation of HRL suffers from the challenge of\nautonomously discovering semantically meaningful subgoals and learning optimal\noption termination boundaries. This paper introduces a novel architecture that\nintegrates a self-supervised, Transformer-based Change Point Detection (CPD)\nmodule into the Option-Critic framework, enabling adaptive segmentation of\nstate trajectories and the discovery of options. The CPD module is trained\nusing heuristic pseudo-labels derived from intrinsic signals to infer latent\nshifts in environment dynamics without external supervision. These inferred\nchange-points are leveraged in three critical ways: (i) to serve as supervisory\nsignals for stabilizing termination function gradients, (ii) to pretrain\nintra-option policies via segment-wise behavioral cloning, and (iii) to enforce\nfunctional specialization through inter-option divergence penalties over\nCPD-defined state partitions. The overall optimization objective enhances the\nstandard actor-critic loss using structure-aware auxiliary losses. In our\nframework, option discovery arises naturally as CPD-defined trajectory segments\nare mapped to distinct intra-option policies, enabling the agent to\nautonomously partition its behavior into reusable, semantically meaningful\nskills. Experiments on the Four-Rooms and Pinball tasks demonstrate that\nCPD-guided agents exhibit accelerated convergence, higher cumulative returns,\nand significantly improved option specialization. These findings confirm that\nintegrating structural priors via change-point segmentation leads to more\ninterpretable, sample-efficient, and robust hierarchical policies in complex\nenvironments.",
    "categories": [
      "cs.LG"
    ],
    "published": "2025-10-28T21:34:23Z",
    "authors": [
      "Hemanath Arumugam",
      "Falong Fan",
      "Bo Liu"
    ],
    "pdf_url": "http://arxiv.org/pdf/2510.24988v1"
  },
  {
    "id": "2510.24987v1",
    "title": "scMRDR: A scalable and flexible framework for unpaired single-cell\n  multi-omics data integration",
    "abstract": "Advances in single-cell sequencing have enabled high-resolution profiling of\ndiverse molecular modalities, while integrating unpaired multi-omics\nsingle-cell data remains challenging. Existing approaches either rely on pair\ninformation or prior correspondences, or require computing a global pairwise\ncoupling matrix, limiting their scalability and flexibility. In this paper, we\nintroduce a scalable and flexible generative framework called single-cell\nMulti-omics Regularized Disentangled Representations (scMRDR) for unpaired\nmulti-omics integration. Specifically, we disentangle each cell's latent\nrepresentations into modality-shared and modality-specific components using a\nwell-designed $\\beta$-VAE architecture, which are augmented with isometric\nregularization to preserve intra-omics biological heterogeneity, adversarial\nobjective to encourage cross-modal alignment, and masked reconstruction loss\nstrategy to address the issue of missing features across modalities. Our method\nachieves excellent performance on benchmark datasets in terms of batch\ncorrection, modality alignment, and biological signal preservation. Crucially,\nit scales effectively to large-level datasets and supports integration of more\nthan two omics, offering a powerful and flexible solution for large-scale\nmulti-omics data integration and downstream biological discovery.",
    "categories": [
      "q-bio.QM",
      "cs.LG",
      "q-bio.GN"
    ],
    "published": "2025-10-28T21:28:39Z",
    "authors": [
      "Jianle Sun",
      "Chaoqi Liang",
      "Ran Wei",
      "Peng Zheng",
      "Lei Bai",
      "Wanli Ouyang",
      "Hongliang Yan",
      "Peng Ye"
    ],
    "pdf_url": "http://arxiv.org/pdf/2510.24987v1"
  },
  {
    "id": "2510.24986v1",
    "title": "Epileptic Seizure Detection and Prediction from EEG Data: A Machine\n  Learning Approach with Clinical Validation",
    "abstract": "In recent years, machine learning has become an increasingly powerful tool\nfor supporting seizure detection and monitoring in epilepsy care. Traditional\napproaches focus on identifying seizures only after they begin, which limits\nthe opportunity for early intervention and proactive treatment. In this study,\nwe propose a novel approach that integrates both real-time seizure detection\nand prediction, aiming to capture subtle temporal patterns in EEG data that may\nindicate an upcoming seizure. Our approach was evaluated using the CHB-MIT\nScalp EEG Database, which includes 969 hours of recordings and 173 seizures\ncollected from 23 pediatric and young adult patients with drug-resistant\nepilepsy. To support seizure detection, we implemented a range of supervised\nmachine learning algorithms, including K-Nearest Neighbors, Logistic\nRegression, Random Forest, and Support Vector Machine. The Logistic Regression\nachieved 90.9% detection accuracy with 89.6% recall, demonstrating balanced\nperformance suitable for clinical screening. Random Forest and Support Vector\nMachine models achieved higher accuracy (94.0%) but with 0% recall, failing to\ndetect any seizures, illustrating that accuracy alone is insufficient for\nevaluating medical ML models with class imbalance. For seizure prediction, we\nemployed Long Short-Term Memory (LSTM) networks, which use deep learning to\nmodel temporal dependencies in EEG data. The LSTM model achieved 89.26%\nprediction accuracy. These results highlight the potential of developing\naccessible, real-time monitoring tools that not only detect seizures as\ntraditionally done, but also predict them before they occur. This ability to\npredict seizures marks a significant shift from reactive seizure management to\na more proactive approach, allowing patients to anticipate seizures and take\nprecautionary measures to reduce the risk of injury or other complications.",
    "categories": [
      "cs.LG",
      "cs.AI"
    ],
    "published": "2025-10-28T21:28:18Z",
    "authors": [
      "Ria Jayanti",
      "Tanish Jain"
    ],
    "pdf_url": "http://arxiv.org/pdf/2510.24986v1"
  },
  {
    "id": "2510.24983v1",
    "title": "LRT-Diffusion: Calibrated Risk-Aware Guidance for Diffusion Policies",
    "abstract": "Diffusion policies are competitive for offline reinforcement learning (RL)\nbut are typically guided at sampling time by heuristics that lack a statistical\nnotion of risk. We introduce LRT-Diffusion, a risk-aware sampling rule that\ntreats each denoising step as a sequential hypothesis test between the\nunconditional prior and the state-conditional policy head. Concretely, we\naccumulate a log-likelihood ratio and gate the conditional mean with a logistic\ncontroller whose threshold tau is calibrated once under H0 to meet a\nuser-specified Type-I level alpha. This turns guidance from a fixed push into\nan evidence-driven adjustment with a user-interpretable risk budget.\nImportantly, we deliberately leave training vanilla (two heads with standard\nepsilon-prediction) under the structure of DDPM. LRT guidance composes\nnaturally with Q-gradients: critic-gradient updates can be taken at the\nunconditional mean, at the LRT-gated mean, or a blend, exposing a continuum\nfrom exploitation to conservatism. We standardize states and actions\nconsistently at train and test time and report a state-conditional\nout-of-distribution (OOD) metric alongside return. On D4RL MuJoCo tasks,\nLRT-Diffusion improves the return-OOD trade-off over strong Q-guided baselines\nin our implementation while honoring the desired alpha. Theoretically, we\nestablish level-alpha calibration, concise stability bounds, and a return\ncomparison showing when LRT surpasses Q-guidance-especially when off-support\nerrors dominate. Overall, LRT-Diffusion is a drop-in, inference-time method\nthat adds principled, calibrated risk control to diffusion policies for offline\nRL.",
    "categories": [
      "cs.LG",
      "cs.AI"
    ],
    "published": "2025-10-28T21:26:18Z",
    "authors": [
      "Ximan Sun",
      "Xiang Cheng"
    ],
    "pdf_url": "http://arxiv.org/pdf/2510.24983v1"
  },
  {
    "id": "2510.24982v1",
    "title": "Strategic inputs: feature selection from game-theoretic perspective",
    "abstract": "The exponential growth of data volumes has led to escalating computational\ncosts in machine learning model training. However, many features fail to\ncontribute positively to model performance while consuming substantial\ncomputational resources. This paper presents an end-to-end feature selection\nframework for tabular data based on game theory. We formulate feature selection\nprocedure based on a cooperative game where features are modeled as players,\nand their importance is determined through the evaluation of synergistic\ninteractions and marginal contributions. The proposed framework comprises four\ncore components: sample selection, game-theoretic feature importance\nevaluation, redundant feature elimination, and optimized model training.\nExperimental results demonstrate that the proposed method achieves substantial\ncomputation reduction while preserving predictive performance, thereby offering\nan efficient solution of the computational challenges of large-scale machine\nlearning. The source code is available at\nhttps://github.com/vectorsss/strategy_inputs.",
    "categories": [
      "cs.LG",
      "68T01, 68T20"
    ],
    "published": "2025-10-28T21:24:43Z",
    "authors": [
      "Chi Zhao",
      "Jing Liu",
      "Elena Parilina"
    ],
    "pdf_url": "http://arxiv.org/pdf/2510.24982v1"
  },
  {
    "id": "2510.24974v1",
    "title": "Conformational Rank Conditioned Committees for Machine Learning-Assisted\n  Directed Evolution",
    "abstract": "Machine Learning-assisted directed evolution (MLDE) is a powerful tool for\nefficiently navigating antibody fitness landscapes. Many structure-aware MLDE\npipelines rely on a single conformation or a single committee across all\nconformations, limiting their ability to separate conformational uncertainty\nfrom epistemic uncertainty. Here, we introduce a rank -conditioned committee\n(RCC) framework that leverages ranked conformations to assign a deep neural\nnetwork committee per rank. This design enables a principled separation between\nepistemic uncertainty and conformational uncertainty. We validate our approach\non SARS-CoV-2 antibody docking, demonstrating significant improvements over\nbaseline strategies. Our results offer a scalable route for therapeutic\nantibody discovery while directly addressing the challenge of modeling\nconformational uncertainty.",
    "categories": [
      "cs.LG"
    ],
    "published": "2025-10-28T21:13:37Z",
    "authors": [
      "Mia Adler",
      "Carrie Liang",
      "Brian Peng",
      "Oleg Presnyakov",
      "Justin M. Baker",
      "Jannelle Lauffer",
      "Himani Sharma",
      "Barry Merriman"
    ],
    "pdf_url": "http://arxiv.org/pdf/2510.24974v1"
  },
  {
    "id": "2510.24966v1",
    "title": "Sequences of Logits Reveal the Low Rank Structure of Language Models",
    "abstract": "A major problem in the study of large language models is to understand their\ninherent low-dimensional structure. We introduce an approach to study the\nlow-dimensional structure of language models at a model-agnostic level: as\nsequential probabilistic models. We first empirically demonstrate that a wide\nrange of modern language models exhibit low-rank structure: in particular,\nmatrices built from the model's logits for varying sets of prompts and\nresponses have low approximate rank. We then show that this low-rank structure\ncan be leveraged for generation -- in particular, we can generate a response to\na target prompt using a linear combination of the model's outputs on unrelated,\nor even nonsensical prompts.\n  On the theoretical front, we observe that studying the approximate rank of\nlanguage models in the sense discussed above yields a simple universal\nabstraction whose theoretical predictions parallel our experiments. We then\nanalyze the representation power of the abstraction and give provable learning\nguarantees.",
    "categories": [
      "cs.LG",
      "cs.AI",
      "cs.CL",
      "stat.ML"
    ],
    "published": "2025-10-28T20:55:58Z",
    "authors": [
      "Noah Golowich",
      "Allen Liu",
      "Abhishek Shetty"
    ],
    "pdf_url": "http://arxiv.org/pdf/2510.24966v1"
  },
  {
    "id": "2510.24951v1",
    "title": "Resource-Efficient and Robust Inference of Deep and Bayesian Neural\n  Networks on Embedded and Analog Computing Platforms",
    "abstract": "While modern machine learning has transformed numerous application domains,\nits growing computational demands increasingly constrain scalability and\nefficiency, particularly on embedded and resource-limited platforms. In\npractice, neural networks must not only operate efficiently but also provide\nreliable predictions under distributional shifts or unseen data. Bayesian\nneural networks offer a principled framework for quantifying uncertainty, yet\ntheir computational overhead further compounds these challenges.\n  This work advances resource-efficient and robust inference for both\nconventional and Bayesian neural networks through the joint pursuit of\nalgorithmic and hardware efficiency. The former reduces computation through\nmodel compression and approximate Bayesian inference, while the latter\noptimizes deployment on digital accelerators and explores analog hardware,\nbridging algorithmic design and physical realization. The first contribution,\nGalen, performs automatic layer-specific compression guided by sensitivity\nanalysis and hardware-in-the-loop feedback. Analog accelerators offer\nefficiency gains at the cost of noise; this work models device imperfections\nand extends noisy training to nonstationary conditions, improving robustness\nand stability. A second line of work advances probabilistic inference,\ndeveloping analytic and ensemble approximations that replace costly sampling,\nintegrate into a compiler stack, and optimize embedded inference. Finally,\nprobabilistic photonic computing introduces a paradigm where controlled analog\nnoise acts as an intrinsic entropy source, enabling fast, energy-efficient\nprobabilistic inference directly in hardware.\n  Together, these studies demonstrate how efficiency and reliability can be\nadvanced jointly through algorithm-hardware co-design, laying the foundation\nfor the next generation of trustworthy, energy-efficient machine-learning\nsystems.",
    "categories": [
      "cs.LG",
      "cs.AR",
      "cs.NE"
    ],
    "published": "2025-10-28T20:34:53Z",
    "authors": [
      "Bernhard Klein"
    ],
    "pdf_url": "http://arxiv.org/pdf/2510.24951v1"
  },
  {
    "id": "2510.24949v1",
    "title": "SCOUT: A Lightweight Framework for Scenario Coverage Assessment in\n  Autonomous Driving",
    "abstract": "Assessing scenario coverage is crucial for evaluating the robustness of\nautonomous agents, yet existing methods rely on expensive human annotations or\ncomputationally intensive Large Vision-Language Models (LVLMs). These\napproaches are impractical for large-scale deployment due to cost and\nefficiency constraints. To address these shortcomings, we propose SCOUT\n(Scenario Coverage Oversight and Understanding Tool), a lightweight surrogate\nmodel designed to predict scenario coverage labels directly from an agent's\nlatent sensor representations. SCOUT is trained through a distillation process,\nlearning to approximate LVLM-generated coverage labels while eliminating the\nneed for continuous LVLM inference or human annotation. By leveraging\nprecomputed perception features, SCOUT avoids redundant computations and\nenables fast, scalable scenario coverage estimation. We evaluate our method\nacross a large dataset of real-life autonomous navigation scenarios,\ndemonstrating that it maintains high accuracy while significantly reducing\ncomputational cost. Our results show that SCOUT provides an effective and\npractical alternative for large-scale coverage analysis. While its performance\ndepends on the quality of LVLM-generated training labels, SCOUT represents a\nmajor step toward efficient scenario coverage oversight in autonomous systems.",
    "categories": [
      "cs.RO",
      "cs.AI",
      "cs.CV",
      "cs.LG"
    ],
    "published": "2025-10-28T20:31:19Z",
    "authors": [
      "Anil Yildiz",
      "Sarah M. Thornton",
      "Carl Hildebrandt",
      "Sreeja Roy-Singh",
      "Mykel J. Kochenderfer"
    ],
    "pdf_url": "http://arxiv.org/pdf/2510.24949v1"
  },
  {
    "id": "2510.24942v1",
    "title": "Finding Culture-Sensitive Neurons in Vision-Language Models",
    "abstract": "Despite their impressive performance, vision-language models (VLMs) still\nstruggle on culturally situated inputs. To understand how VLMs process\nculturally grounded information, we study the presence of culture-sensitive\nneurons, i.e. neurons whose activations show preferential sensitivity to inputs\nassociated with particular cultural contexts. We examine whether such neurons\nare important for culturally diverse visual question answering and where they\nare located. Using the CVQA benchmark, we identify neurons of culture\nselectivity and perform causal tests by deactivating the neurons flagged by\ndifferent identification methods. Experiments on three VLMs across 25 cultural\ngroups demonstrate the existence of neurons whose ablation disproportionately\nharms performance on questions about the corresponding cultures, while having\nminimal effects on others. Moreover, we propose a new margin-based selector -\nContrastive Activation Selection (CAS), and show that it outperforms existing\nprobability- and entropy-based methods in identifying culture-sensitive\nneurons. Finally, our layer-wise analyses reveals that such neurons tend to\ncluster in certain decoder layers. Overall, our findings shed new light on the\ninternal organization of multimodal representations.",
    "categories": [
      "cs.LG",
      "cs.AI",
      "cs.CL"
    ],
    "published": "2025-10-28T20:14:37Z",
    "authors": [
      "Xiutian Zhao",
      "Rochelle Choenni",
      "Rohit Saxena",
      "Ivan Titov"
    ],
    "pdf_url": "http://arxiv.org/pdf/2510.24942v1"
  },
  {
    "id": "2510.25791v1",
    "title": "The Kinetics of Reasoning: How Chain-of-Thought Shapes Learning in\n  Transformers?",
    "abstract": "Chain-of-thought (CoT) supervision can substantially improve transformer\nperformance, yet the mechanisms by which models learn to follow and benefit\nfrom CoT remain poorly understood. We investigate these learning dynamics\nthrough the lens of grokking by pretraining transformers on symbolic reasoning\ntasks with tunable algorithmic complexity and controllable data composition to\nstudy their generalization. Models were trained under two settings: (i)\nproducing only final answers, and (ii) emitting explicit CoT traces before\nanswering. Our results show that while CoT generally improves task performance,\nits benefits depend on task complexity. To quantify these effects, we model the\naccuracy of the logarithmic training steps with a three-parameter logistic\ncurve, revealing how the learning speed and shape vary with task complexity,\ndata distribution, and the presence of CoT supervision. We also uncover a\ntransient trace unfaithfulness phase: early in training, models often produce\ncorrect answers while skipping or contradicting CoT steps, before later\naligning their reasoning traces with answers. Empirically, we (1) demonstrate\nthat CoT accelerates generalization but does not overcome tasks with higher\nalgorithmic complexity, such as finding list intersections; (2) introduce a\nkinetic modeling framework for understanding transformer learning; (3)\ncharacterize trace faithfulness as a dynamic property that emerges over\ntraining; and (4) show CoT alters internal transformer computation\nmechanistically.",
    "categories": [
      "cs.LG",
      "cs.AI"
    ],
    "published": "2025-10-28T20:14:26Z",
    "authors": [
      "Zihan Pengmei",
      "Costas Mavromatis",
      "Zhengyuan Shen",
      "Yunyi Zhang",
      "Vassilis N. Ioannidis",
      "Huzefa Rangwala"
    ],
    "pdf_url": "http://arxiv.org/pdf/2510.25791v1"
  },
  {
    "id": "2510.24941v1",
    "title": "Can Aha Moments Be Fake? Identifying True and Decorative Thinking Steps\n  in Chain-of-Thought",
    "abstract": "Recent large language models (LLMs) can generate long Chain-of-Thought (CoT)\nat test time, enabling them to solve complex tasks. These reasoning steps in\nCoT are often assumed as a faithful reflection of the model's internal thinking\nprocess, and used to monitor unsafe intentions. However, we find many reasoning\nsteps don't truly contribute to LLMs' prediction. We measure the step-wise\ncausal influence of each reasoning step on the model's final prediction with a\nproposed True Thinking Score (TTS). We reveal that LLMs often interleave\nbetween true-thinking steps (which are genuinely used to produce the final\noutput) and decorative-thinking steps (which only give the appearance of\nreasoning but have minimal causal impact). Notably, only a small subset of the\ntotal reasoning steps have a high TTS that causally drive the model's\nprediction: e.g., for the AIME dataset, only an average of 2.3% of reasoning\nsteps in CoT have a TTS >= 0.7 (range: 0-1) under the Qwen-2.5 model.\nFurthermore, we identify a TrueThinking direction in the latent space of LLMs.\nBy steering along or against this direction, we can force the model to perform\nor disregard certain CoT steps when computing the final result. Finally, we\nhighlight that self-verification steps in CoT (i.e., aha moments) can also be\ndecorative, where LLMs do not truly verify their solution. Steering along the\nTrueThinking direction can force internal reasoning over these steps, resulting\nin a change in the final results. Overall, our work reveals that LLMs often\nverbalize reasoning steps without actually performing them internally, which\nundermines both the efficiency of LLM reasoning and the trustworthiness of CoT.",
    "categories": [
      "cs.LG"
    ],
    "published": "2025-10-28T20:14:02Z",
    "authors": [
      "Jiachen Zhao",
      "Yiyou Sun",
      "Weiyan Shi",
      "Dawn Song"
    ],
    "pdf_url": "http://arxiv.org/pdf/2510.24941v1"
  },
  {
    "id": "2510.24927v1",
    "title": "WBT-BGRL: A Non-Contrastive Weighted Bipartite Link Prediction Model for\n  Inductive Learning",
    "abstract": "Link prediction in bipartite graphs is crucial for applications like\nrecommendation systems and failure detection, yet it is less studied than in\nmonopartite graphs. Contrastive methods struggle with inefficient and biased\nnegative sampling, while non-contrastive approaches rely solely on positive\nsamples. Existing models perform well in transductive settings, but their\neffectiveness in inductive, weighted, and bipartite scenarios remains untested.\nTo address this, we propose Weighted Bipartite Triplet-Bootstrapped Graph\nLatents (WBT-BGRL), a non-contrastive framework that enhances bootstrapped\nlearning with a novel weighting mechanism in the triplet loss. Using a\nbipartite architecture with dual GCN encoders, WBT-BGRL is evaluated against\nadapted state-of-the-art models (T-BGRL, BGRL, GBT, CCA-SSG). Results on\nreal-world datasets (Industry and E-commerce) show competitive performance,\nespecially when weighting is applied during pretraining-highlighting the value\nof weighted, non-contrastive learning for inductive link prediction in\nbipartite graphs.",
    "categories": [
      "cs.LG"
    ],
    "published": "2025-10-28T19:56:13Z",
    "authors": [
      "Joel Frank Huarayo Quispe",
      "Lilian Berton",
      "Didier Vega-Oliveros"
    ],
    "pdf_url": "http://arxiv.org/pdf/2510.24927v1"
  },
  {
    "id": "2510.24926v1",
    "title": "KAN-GCN: Combining Kolmogorov-Arnold Network with Graph Convolution\n  Network for an Accurate Ice Sheet Emulator",
    "abstract": "We introduce KAN-GCN, a fast and accurate emulator for ice sheet modeling\nthat places a Kolmogorov-Arnold Network (KAN) as a feature-wise calibrator\nbefore graph convolution networks (GCNs). The KAN front end applies learnable\none-dimensional warps and a linear mixing step, improving feature conditioning\nand nonlinear encoding without increasing message-passing depth. We employ this\narchitecture to improve the performance of emulators for numerical ice sheet\nmodels. Our emulator is trained and tested using 36 melting-rate simulations\nwith 3 mesh-size settings for Pine Island Glacier, Antarctica. Across 2- to\n5-layer architectures, KAN-GCN matches or exceeds the accuracy of pure GCN and\nMLP-GCN baselines. Despite a small parameter overhead, KAN-GCN improves\ninference throughput on coarser meshes by replacing one edge-wise\nmessage-passing layer with a node-wise transform; only the finest mesh shows a\nmodest cost. Overall, KAN-first designs offer a favorable accuracy vs.\nefficiency trade-off for large transient scenario sweeps.",
    "categories": [
      "cs.LG",
      "cs.AI",
      "cs.NA",
      "math.NA"
    ],
    "published": "2025-10-28T19:55:29Z",
    "authors": [
      "Zesheng Liu",
      "YoungHyun Koo",
      "Maryam Rahnemoonfar"
    ],
    "pdf_url": "http://arxiv.org/pdf/2510.24926v1"
  },
  {
    "id": "2510.24919v1",
    "title": "Modality-Aware SAM: Sharpness-Aware-Minimization Driven Gradient\n  Modulation for Harmonized Multimodal Learning",
    "abstract": "In multimodal learning, dominant modalities often overshadow others, limiting\ngeneralization. We propose Modality-Aware Sharpness-Aware Minimization (M-SAM),\na model-agnostic framework that applies to many modalities and supports early\nand late fusion scenarios. In every iteration, M-SAM in three steps optimizes\nlearning. \\textbf{First, it identifies the dominant modality} based on\nmodalities' contribution in the accuracy using Shapley. \\textbf{Second, it\ndecomposes the loss landscape}, or in another language, it modulates the loss\nto prioritize the robustness of the model in favor of the dominant modality,\nand \\textbf{third, M-SAM updates the weights} by backpropagation of modulated\ngradients. This ensures robust learning for the dominant modality while\nenhancing contributions from others, allowing the model to explore and exploit\ncomplementary features that strengthen overall performance. Extensive\nexperiments on four diverse datasets show that M-SAM outperforms the latest\nstate-of-the-art optimization and gradient manipulation methods and\nsignificantly balances and improves multimodal learning.",
    "categories": [
      "cs.CV",
      "cs.LG"
    ],
    "published": "2025-10-28T19:44:20Z",
    "authors": [
      "Hossein R. Nowdeh",
      "Jie Ji",
      "Xiaolong Ma",
      "Fatemeh Afghah"
    ],
    "pdf_url": "http://arxiv.org/pdf/2510.24919v1"
  },
  {
    "id": "2510.24918v1",
    "title": "Topic Analysis with Side Information: A Neural-Augmented LDA Approach",
    "abstract": "Traditional topic models such as Latent Dirichlet Allocation (LDA) have been\nwidely used to uncover latent structures in text corpora, but they often\nstruggle to integrate auxiliary information such as metadata, user attributes,\nor document labels. These limitations restrict their expressiveness,\npersonalization, and interpretability. To address this, we propose nnLDA, a\nneural-augmented probabilistic topic model that dynamically incorporates side\ninformation through a neural prior mechanism. nnLDA models each document as a\nmixture of latent topics, where the prior over topic proportions is generated\nby a neural network conditioned on auxiliary features. This design allows the\nmodel to capture complex nonlinear interactions between side information and\ntopic distributions that static Dirichlet priors cannot represent. We develop a\nstochastic variational Expectation-Maximization algorithm to jointly optimize\nthe neural and probabilistic components. Across multiple benchmark datasets,\nnnLDA consistently outperforms LDA and Dirichlet-Multinomial Regression in\ntopic coherence, perplexity, and downstream classification. These results\nhighlight the benefits of combining neural representation learning with\nprobabilistic topic modeling in settings where side information is available.",
    "categories": [
      "cs.LG",
      "stat.ME",
      "stat.ML"
    ],
    "published": "2025-10-28T19:38:36Z",
    "authors": [
      "Biyi Fang",
      "Kripa Rajshekhar",
      "Truong Vo",
      "Diego Klabjan"
    ],
    "pdf_url": "http://arxiv.org/pdf/2510.24918v1"
  },
  {
    "id": "2510.24907v1",
    "title": "Understanding Multi-View Transformers",
    "abstract": "Multi-view transformers such as DUSt3R are revolutionizing 3D vision by\nsolving 3D tasks in a feed-forward manner. However, contrary to previous\noptimization-based pipelines, the inner mechanisms of multi-view transformers\nare unclear. Their black-box nature makes further improvements beyond data\nscaling challenging and complicates usage in safety- and reliability-critical\napplications. Here, we present an approach for probing and visualizing 3D\nrepresentations from the residual connections of the multi-view transformers'\nlayers. In this manner, we investigate a variant of the DUSt3R model, shedding\nlight on the development of its latent state across blocks, the role of the\nindividual layers, and suggest how it differs from methods with stronger\ninductive biases of explicit global pose. Finally, we show that the\ninvestigated variant of DUSt3R estimates correspondences that are refined with\nreconstructed geometry. The code used for the analysis is available at\nhttps://github.com/JulienGaubil/und3rstand .",
    "categories": [
      "cs.CV",
      "cs.AI",
      "cs.LG"
    ],
    "published": "2025-10-28T19:19:35Z",
    "authors": [
      "Michal Stary",
      "Julien Gaubil",
      "Ayush Tewari",
      "Vincent Sitzmann"
    ],
    "pdf_url": "http://arxiv.org/pdf/2510.24907v1"
  },
  {
    "id": "2510.24891v1",
    "title": "Idea2Plan: Exploring AI-Powered Research Planning",
    "abstract": "Large language models (LLMs) have demonstrated significant potential to\naccelerate scientific discovery as valuable tools for analyzing data,\ngenerating hypotheses, and supporting innovative approaches in various\nscientific fields. In this work, we investigate how LLMs can handle the\ntransition from conceptual research ideas to well-structured research plans.\nEffective research planning not only supports scientists in advancing their\nresearch but also represents a crucial capability for the development of\nautonomous research agents. Despite its importance, the field lacks a\nsystematic understanding of LLMs' research planning capability. To rigorously\nmeasure this capability, we introduce the Idea2Plan task and Idea2Plan Bench, a\nbenchmark built from 200 ICML 2025 Spotlight and Oral papers released after\nmajor LLM training cutoffs. Each benchmark instance includes a research idea\nand a grading rubric capturing the key components of valid plans. We further\npropose Idea2Plan JudgeEval, a complementary benchmark to assess the\nreliability of LLM-based judges against expert annotations. Experimental\nresults show that GPT-5 and GPT-5-mini achieve the strongest performance on the\nbenchmark, though substantial headroom remains for future improvement. Our\nstudy provides new insights into LLMs' capability for research planning and lay\nthe groundwork for future progress.",
    "categories": [
      "cs.CL",
      "cs.LG"
    ],
    "published": "2025-10-28T18:54:51Z",
    "authors": [
      "Jin Huang",
      "Silviu Cucerzan",
      "Sujay Kumar Jauhar",
      "Ryen W. White"
    ],
    "pdf_url": "http://arxiv.org/pdf/2510.24891v1"
  },
  {
    "id": "2510.24889v2",
    "title": "Adaptive EEG-based stroke diagnosis with a GRU-TCN classifier and deep\n  Q-learning thresholding",
    "abstract": "Rapid triage of suspected stroke needs accurate, bedside-deployable tools;\nEEG is promising but underused at first contact. We present an adaptive\nmultitask EEG classifier that converts 32-channel signals to power spectral\ndensity features (Welch), uses a recurrent-convolutional network (GRU-TCN) to\npredict stroke type (healthy, ischemic, hemorrhagic), hemispheric\nlateralization, and severity, and applies a deep Q-network (DQN) to tune\ndecision thresholds in real time. Using a patient-wise split of the UCLH Stroke\nEIT/EEG data set (44 recordings; about 26 acute stroke, 10 controls), the\nprimary outcome was stroke-type performance; secondary outcomes were severity\nand lateralization. The baseline GRU-TCN reached 89.3% accuracy (F1 92.8%) for\nstroke type, about 96.9% (F1 95.9%) for severity, and about 96.7% (F1 97.4%)\nfor lateralization. With DQN threshold adaptation, stroke-type accuracy\nincreased to about 98.0% (F1 97.7%). We also tested robustness on an\nindependent, low-density EEG cohort (ZJU4H) and report paired patient-level\nstatistics. Analyses follow STARD 2015 guidance for diagnostic accuracy studies\n(index test: GRU-TCN+DQN; reference standard: radiology/clinical diagnosis;\npatient-wise evaluation). Adaptive thresholding shifts the operating point to\nclinically preferred sensitivity-specificity trade-offs, while integrated\nscalp-map and spectral visualizations support interpretability.",
    "categories": [
      "cs.LG"
    ],
    "published": "2025-10-28T18:48:48Z",
    "authors": [
      "Shakeel Abdulkareem",
      "Bora Yimenicioglu",
      "Khartik Uppalapati",
      "Aneesh Gudipati",
      "Adan Eftekhari",
      "Saleh Yassin"
    ],
    "pdf_url": "http://arxiv.org/pdf/2510.24889v2"
  },
  {
    "id": "2510.25788v1",
    "title": "SHA-256 Infused Embedding-Driven Generative Modeling of High-Energy\n  Molecules in Low-Data Regimes",
    "abstract": "High-energy materials (HEMs) are critical for propulsion and defense domains,\nyet their discovery remains constrained by experimental data and restricted\naccess to testing facilities. This work presents a novel approach toward\nhigh-energy molecules by combining Long Short-Term Memory (LSTM) networks for\nmolecular generation and Attentive Graph Neural Networks (GNN) for property\npredictions. We propose a transformative embedding space construction strategy\nthat integrates fixed SHA-256 embeddings with partially trainable\nrepresentations. Unlike conventional regularization techniques, this changes\nthe representational basis itself, reshaping the molecular input space before\nlearning begins. Without recourse to pretraining, the generator achieves 67.5%\nvalidity and 37.5% novelty. The generated library exhibits a mean Tanimoto\ncoefficient of 0.214 relative to training set signifying the ability of\nframework to generate a diverse chemical space. We identified 37 new super\nexplosives higher than 9 km/s predicted detonation velocity.",
    "categories": [
      "cs.LG",
      "cond-mat.mtrl-sci"
    ],
    "published": "2025-10-28T18:48:22Z",
    "authors": [
      "Siddharth Verma",
      "Alankar Alankar"
    ],
    "pdf_url": "http://arxiv.org/pdf/2510.25788v1"
  },
  {
    "id": "2510.24884v1",
    "title": "Aggregation Hides Out-of-Distribution Generalization Failures from\n  Spurious Correlations",
    "abstract": "Benchmarks for out-of-distribution (OOD) generalization frequently show a\nstrong positive correlation between in-distribution (ID) and OOD accuracy\nacross models, termed \"accuracy-on-the-line.\" This pattern is often taken to\nimply that spurious correlations - correlations that improve ID but reduce OOD\nperformance - are rare in practice. We find that this positive correlation is\noften an artifact of aggregating heterogeneous OOD examples. Using a simple\ngradient-based method, OODSelect, we identify semantically coherent OOD subsets\nwhere accuracy on the line does not hold. Across widely used distribution shift\nbenchmarks, the OODSelect uncovers subsets, sometimes over half of the standard\nOOD set, where higher ID accuracy predicts lower OOD accuracy. Our findings\nindicate that aggregate metrics can obscure important failure modes of OOD\nrobustness. We release code and the identified subsets to facilitate further\nresearch.",
    "categories": [
      "cs.LG"
    ],
    "published": "2025-10-28T18:35:57Z",
    "authors": [
      "Olawale Salaudeen",
      "Haoran Zhang",
      "Kumail Alhamoud",
      "Sara Beery",
      "Marzyeh Ghassemi"
    ],
    "pdf_url": "http://arxiv.org/pdf/2510.24884v1"
  },
  {
    "id": "2510.24718v1",
    "title": "Generative View Stitching",
    "abstract": "Autoregressive video diffusion models are capable of long rollouts that are\nstable and consistent with history, but they are unable to guide the current\ngeneration with conditioning from the future. In camera-guided video generation\nwith a predefined camera trajectory, this limitation leads to collisions with\nthe generated scene, after which autoregression quickly collapses. To address\nthis, we propose Generative View Stitching (GVS), which samples the entire\nsequence in parallel such that the generated scene is faithful to every part of\nthe predefined camera trajectory. Our main contribution is a sampling algorithm\nthat extends prior work on diffusion stitching for robot planning to video\ngeneration. While such stitching methods usually require a specially trained\nmodel, GVS is compatible with any off-the-shelf video model trained with\nDiffusion Forcing, a prevalent sequence diffusion framework that we show\nalready provides the affordances necessary for stitching. We then introduce\nOmni Guidance, a technique that enhances the temporal consistency in stitching\nby conditioning on both the past and future, and that enables our proposed\nloop-closing mechanism for delivering long-range coherence. Overall, GVS\nachieves camera-guided video generation that is stable, collision-free,\nframe-to-frame consistent, and closes loops for a variety of predefined camera\npaths, including Oscar Reutersv\\\"ard's Impossible Staircase. Results are best\nviewed as videos at https://andrewsonga.github.io/gvs.",
    "categories": [
      "cs.CV",
      "cs.LG"
    ],
    "published": "2025-10-28T17:59:58Z",
    "authors": [
      "Chonghyuk Song",
      "Michal Stary",
      "Boyuan Chen",
      "George Kopanas",
      "Vincent Sitzmann"
    ],
    "pdf_url": "http://arxiv.org/pdf/2510.24718v1"
  },
  {
    "id": "2510.24710v1",
    "title": "A Single-Loop First-Order Algorithm for Linearly Constrained Bilevel\n  Optimization",
    "abstract": "We study bilevel optimization problems where the lower-level problems are\nstrongly convex and have coupled linear constraints. To overcome the potential\nnon-smoothness of the hyper-objective and the computational challenges\nassociated with the Hessian matrix, we utilize penalty and augmented Lagrangian\nmethods to reformulate the original problem as a single-level one. Especially,\nwe establish a strong theoretical connection between the reformulated function\nand the original hyper-objective by characterizing the closeness of their\nvalues and derivatives. Based on this reformulation, we propose a single-loop,\nfirst-order algorithm for linearly constrained bilevel optimization (SFLCB). We\nprovide rigorous analyses of its non-asymptotic convergence rates, showing an\nimprovement over prior double-loop algorithms -- form\n$O(\\epsilon^{-3}\\log(\\epsilon^{-1}))$ to $O(\\epsilon^{-3})$. The experiments\ncorroborate our theoretical findings and demonstrate the practical efficiency\nof the proposed SFLCB algorithm. Simulation code is provided at\nhttps://github.com/ShenGroup/SFLCB.",
    "categories": [
      "math.OC",
      "cs.IT",
      "cs.LG",
      "math.IT",
      "stat.ML"
    ],
    "published": "2025-10-28T17:58:17Z",
    "authors": [
      "Wei Shen",
      "Jiawei Zhang",
      "Minhui Huang",
      "Cong Shen"
    ],
    "pdf_url": "http://arxiv.org/pdf/2510.24710v1"
  },
  {
    "id": "2510.24709v1",
    "title": "Does Object Binding Naturally Emerge in Large Pretrained Vision\n  Transformers?",
    "abstract": "Object binding, the brain's ability to bind the many features that\ncollectively represent an object into a coherent whole, is central to human\ncognition. It groups low-level perceptual features into high-level object\nrepresentations, stores those objects efficiently and compositionally in\nmemory, and supports human reasoning about individual object instances. While\nprior work often imposes object-centric attention (e.g., Slot Attention)\nexplicitly to probe these benefits, it remains unclear whether this ability\nnaturally emerges in pre-trained Vision Transformers (ViTs). Intuitively, they\ncould: recognizing which patches belong to the same object should be useful for\ndownstream prediction and thus guide attention. Motivated by the quadratic\nnature of self-attention, we hypothesize that ViTs represent whether two\npatches belong to the same object, a property we term IsSameObject. We decode\nIsSameObject from patch embeddings across ViT layers using a similarity probe,\nwhich reaches over 90% accuracy. Crucially, this object-binding capability\nemerges reliably in self-supervised ViTs (DINO, MAE, CLIP), but markedly weaker\nin ImageNet-supervised models, suggesting that binding is not a trivial\narchitectural artifact, but an ability acquired through specific pretraining\nobjectives. We further discover that IsSameObject is encoded in a\nlow-dimensional subspace on top of object features, and that this signal\nactively guides attention. Ablating IsSameObject from model activations\ndegrades downstream performance and works against the learning objective,\nimplying that emergent object binding naturally serves the pretraining\nobjective. Our findings challenge the view that ViTs lack object binding and\nhighlight how symbolic knowledge of \"which parts belong together\" emerges\nnaturally in a connectionist system.",
    "categories": [
      "cs.CV",
      "cs.AI",
      "cs.LG",
      "q-bio.NC"
    ],
    "published": "2025-10-28T17:57:05Z",
    "authors": [
      "Yihao Li",
      "Saeed Salehi",
      "Lyle Ungar",
      "Konrad P. Kording"
    ],
    "pdf_url": "http://arxiv.org/pdf/2510.24709v1"
  },
  {
    "id": "2510.24701v1",
    "title": "Tongyi DeepResearch Technical Report",
    "abstract": "We present Tongyi DeepResearch, an agentic large language model, which is\nspecifically designed for long-horizon, deep information-seeking research\ntasks. To incentivize autonomous deep research agency, Tongyi DeepResearch is\ndeveloped through an end-to-end training framework that combines agentic\nmid-training and agentic post-training, enabling scalable reasoning and\ninformation seeking across complex tasks. We design a highly scalable data\nsynthesis pipeline that is fully automatic, without relying on costly human\nannotation, and empowers all training stages. By constructing customized\nenvironments for each stage, our system enables stable and consistent\ninteractions throughout. Tongyi DeepResearch, featuring 30.5 billion total\nparameters, with only 3.3 billion activated per token, achieves\nstate-of-the-art performance across a range of agentic deep research\nbenchmarks, including Humanity's Last Exam, BrowseComp, BrowseComp-ZH,\nWebWalkerQA, xbench-DeepSearch, FRAMES and xbench-DeepSearch-2510. We\nopen-source the model, framework, and complete solutions to empower the\ncommunity.",
    "categories": [
      "cs.CL",
      "cs.AI",
      "cs.IR",
      "cs.LG",
      "cs.MA"
    ],
    "published": "2025-10-28T17:53:02Z",
    "authors": [
      " Tongyi DeepResearch Team",
      "Baixuan Li",
      "Bo Zhang",
      "Dingchu Zhang",
      "Fei Huang",
      "Guangyu Li",
      "Guoxin Chen",
      "Huifeng Yin",
      "Jialong Wu",
      "Jingren Zhou",
      "Kuan Li",
      "Liangcai Su",
      "Litu Ou",
      "Liwen Zhang",
      "Pengjun Xie",
      "Rui Ye",
      "Wenbiao Yin",
      "Xinmiao Yu",
      "Xinyu Wang",
      "Xixi Wu",
      "Xuanzhong Chen",
      "Yida Zhao",
      "Zhen Zhang",
      "Zhengwei Tao",
      "Zhongwang Zhang",
      "Zile Qiao",
      "Chenxi Wang",
      "Donglei Yu",
      "Gang Fu",
      "Haiyang Shen",
      "Jiayin Yang",
      "Jun Lin",
      "Junkai Zhang",
      "Kui Zeng",
      "Li Yang",
      "Hailong Yin",
      "Maojia Song",
      "Ming Yan",
      "Peng Xia",
      "Qian Xiao",
      "Rui Min",
      "Ruixue Ding",
      "Runnan Fang",
      "Shaowei Chen",
      "Shen Huang",
      "Shihang Wang",
      "Shihao Cai",
      "Weizhou Shen",
      "Xiaobin Wang",
      "Xin Guan",
      "Xinyu Geng",
      "Yingcheng Shi",
      "Yuning Wu",
      "Zhuo Chen",
      "Zijian Li",
      "Yong Jiang"
    ],
    "pdf_url": "http://arxiv.org/pdf/2510.24701v1"
  },
  {
    "id": "2510.24700v1",
    "title": "Greedy Sampling Is Provably Efficient for RLHF",
    "abstract": "Reinforcement Learning from Human Feedback (RLHF) has emerged as a key\ntechnique for post-training large language models. Despite its empirical\nsuccess, the theoretical understanding of RLHF is still limited, as learning\nthe KL-regularized target with only preference feedback poses additional\nchallenges compared with canonical RL. Existing works mostly study the\nreward-based Bradley-Terry (BT) preference model, and extend classical designs\nutilizing optimism or pessimism. This work, instead, considers the general\npreference model (whose practical relevance has been observed recently) and\nobtains performance guarantees with major, order-wise improvements over\nexisting ones. Surprisingly, these results are derived from algorithms that\ndirectly use the empirical estimates (i.e., greedy sampling), as opposed to\nconstructing optimistic or pessimistic estimates in previous works. This\ninsight has a deep root in the unique structural property of the optimal policy\nclass under the KL-regularized target, and we further specialize it to the BT\nmodel, highlighting the surprising sufficiency of greedy sampling in RLHF.",
    "categories": [
      "cs.LG",
      "cs.AI",
      "cs.IT",
      "math.IT",
      "stat.ML"
    ],
    "published": "2025-10-28T17:52:08Z",
    "authors": [
      "Di Wu",
      "Chengshuai Shi",
      "Jing Yang",
      "Cong Shen"
    ],
    "pdf_url": "http://arxiv.org/pdf/2510.24700v1"
  },
  {
    "id": "2510.24699v1",
    "title": "AgentFold: Long-Horizon Web Agents with Proactive Context Management",
    "abstract": "LLM-based web agents show immense promise for information seeking, yet their\neffectiveness on long-horizon tasks is hindered by a fundamental trade-off in\ncontext management. Prevailing ReAct-based agents suffer from context\nsaturation as they accumulate noisy, raw histories, while methods that fixedly\nsummarize the full history at each step risk the irreversible loss of critical\ndetails. Addressing these, we introduce AgentFold, a novel agent paradigm\ncentered on proactive context management, inspired by the human cognitive\nprocess of retrospective consolidation. AgentFold treats its context as a\ndynamic cognitive workspace to be actively sculpted, rather than a passive log\nto be filled. At each step, it learns to execute a `folding' operation, which\nmanages its historical trajectory at multiple scales: it can perform granular\ncondensations to preserve vital, fine-grained details, or deep consolidations\nto abstract away entire multi-step sub-tasks. The results on prominent\nbenchmarks are striking: with simple supervised fine-tuning (without continual\npre-training or RL), our AgentFold-30B-A3B agent achieves 36.2% on BrowseComp\nand 47.3% on BrowseComp-ZH. Notably, this performance not only surpasses or\nmatches open-source models of a dramatically larger scale, such as the\nDeepSeek-V3.1-671B-A37B, but also surpasses leading proprietary agents like\nOpenAI's o4-mini.",
    "categories": [
      "cs.CL",
      "cs.AI",
      "cs.LG"
    ],
    "published": "2025-10-28T17:51:50Z",
    "authors": [
      "Rui Ye",
      "Zhongwang Zhang",
      "Kuan Li",
      "Huifeng Yin",
      "Zhengwei Tao",
      "Yida Zhao",
      "Liangcai Su",
      "Liwen Zhang",
      "Zile Qiao",
      "Xinyu Wang",
      "Pengjun Xie",
      "Fei Huang",
      "Siheng Chen",
      "Jingren Zhou",
      "Yong Jiang"
    ],
    "pdf_url": "http://arxiv.org/pdf/2510.24699v1"
  },
  {
    "id": "2510.25787v1",
    "title": "Unsupervised local learning based on voltage-dependent synaptic\n  plasticity for resistive and ferroelectric synapses",
    "abstract": "The deployment of AI on edge computing devices faces significant challenges\nrelated to energy consumption and functionality. These devices could greatly\nbenefit from brain-inspired learning mechanisms, allowing for real-time\nadaptation while using low-power. In-memory computing with nanoscale resistive\nmemories may play a crucial role in enabling the execution of AI workloads on\nthese edge devices. In this study, we introduce voltage-dependent synaptic\nplasticity (VDSP) as an efficient approach for unsupervised and local learning\nin memristive synapses based on Hebbian principles. This method enables online\nlearning without requiring complex pulse-shaping circuits typically necessary\nfor spike-timing-dependent plasticity (STDP). We show how VDSP can be\nadvantageously adapted to three types of memristive devices (TiO$_2$,\nHfO$_2$-based metal-oxide filamentary synapses, and HfZrO$_4$-based\nferroelectric tunnel junctions (FTJ)) with disctinctive switching\ncharacteristics. System-level simulations of spiking neural networks\nincorporating these devices were conducted to validate unsupervised learning on\nMNIST-based pattern recognition tasks, achieving state-of-the-art performance.\nThe results demonstrated over 83% accuracy across all devices using 200\nneurons. Additionally, we assessed the impact of device variability, such as\nswitching thresholds and ratios between high and low resistance state levels,\nand proposed mitigation strategies to enhance robustness.",
    "categories": [
      "cs.NE",
      "cs.AI",
      "cs.ET",
      "cs.LG"
    ],
    "published": "2025-10-28T17:47:26Z",
    "authors": [
      "Nikhil Garg",
      "Ismael Balafrej",
      "Joao Henrique Quintino Palhares",
      "Laura B\u00e9gon-Lours",
      "Davide Florini",
      "Donato Francesco Falcone",
      "Tommaso Stecconi",
      "Valeria Bragaglia",
      "Bert Jan Offrein",
      "Jean-Michel Portal",
      "Damien Querlioz",
      "Yann Beilliard",
      "Dominique Drouin",
      "Fabien Alibart"
    ],
    "pdf_url": "http://arxiv.org/pdf/2510.25787v1"
  },
  {
    "id": "2510.24674v1",
    "title": "Learning to Drive Safely with Hybrid Options",
    "abstract": "Out of the many deep reinforcement learning approaches for autonomous\ndriving, only few make use of the options (or skills) framework. That is\nsurprising, as this framework is naturally suited for hierarchical control\napplications in general, and autonomous driving tasks in specific. Therefore,\nin this work the options framework is applied and tailored to autonomous\ndriving tasks on highways. More specifically, we define dedicated options for\nlongitudinal and lateral manoeuvres with embedded safety and comfort\nconstraints. This way, prior domain knowledge can be incorporated into the\nlearning process and the learned driving behaviour can be constrained more\neasily. We propose several setups for hierarchical control with options and\nderive practical algorithms following state-of-the-art reinforcement learning\ntechniques. By separately selecting actions for longitudinal and lateral\ncontrol, the introduced policies over combined and hybrid options obtain the\nsame expressiveness and flexibility that human drivers have, while being easier\nto interpret than classical policies over continuous actions. Of all the\ninvestigated approaches, these flexible policies over hybrid options perform\nthe best under varying traffic conditions, outperforming the baseline policies\nover actions.",
    "categories": [
      "cs.LG",
      "cs.AI",
      "cs.SY",
      "eess.SY"
    ],
    "published": "2025-10-28T17:40:04Z",
    "authors": [
      "Bram De Cooman",
      "Johan Suykens"
    ],
    "pdf_url": "http://arxiv.org/pdf/2510.24674v1"
  },
  {
    "id": "2510.24672v1",
    "title": "Eigenfunction Extraction for Ordered Representation Learning",
    "abstract": "Recent advances in representation learning reveal that widely used\nobjectives, such as contrastive and non-contrastive, implicitly perform\nspectral decomposition of a contextual kernel, induced by the relationship\nbetween inputs and their contexts. Yet, these methods recover only the linear\nspan of top eigenfunctions of the kernel, whereas exact spectral decomposition\nis essential for understanding feature ordering and importance. In this work,\nwe propose a general framework to extract ordered and identifiable\neigenfunctions, based on modular building blocks designed to satisfy key\ndesiderata, including compatibility with the contextual kernel and scalability\nto modern settings. We then show how two main methodological paradigms,\nlow-rank approximation and Rayleigh quotient optimization, align with this\nframework for eigenfunction extraction. Finally, we validate our approach on\nsynthetic kernels and demonstrate on real-world image datasets that the\nrecovered eigenvalues act as effective importance scores for feature selection,\nenabling principled efficiency-accuracy tradeoffs via adaptive-dimensional\nrepresentations.",
    "categories": [
      "cs.LG",
      "stat.ML"
    ],
    "published": "2025-10-28T17:37:12Z",
    "authors": [
      "Burak Var\u0131c\u0131",
      "Che-Ping Tsai",
      "Ritabrata Ray",
      "Nicholas M. Boffi",
      "Pradeep Ravikumar"
    ],
    "pdf_url": "http://arxiv.org/pdf/2510.24672v1"
  },
  {
    "id": "2510.24670v2",
    "title": "Pearl: A Foundation Model for Placing Every Atom in the Right Location",
    "abstract": "Accurately predicting the three-dimensional structures of protein-ligand\ncomplexes remains a fundamental challenge in computational drug discovery that\nlimits the pace and success of therapeutic design. Deep learning methods have\nrecently shown strong potential as structural prediction tools, achieving\npromising accuracy across diverse biomolecular systems. However, their\nperformance and utility are constrained by scarce experimental data,\ninefficient architectures, physically invalid poses, and the limited ability to\nexploit auxiliary information available at inference. To address these issues,\nwe introduce Pearl (Placing Every Atom in the Right Location), a foundation\nmodel for protein-ligand cofolding at scale. Pearl addresses these challenges\nwith three key innovations: (1) training recipes that include large-scale\nsynthetic data to overcome data scarcity; (2) architectures that incorporate an\nSO(3)-equivariant diffusion module to inherently respect 3D rotational\nsymmetries, improving generalization and sample efficiency, and (3)\ncontrollable inference, including a generalized multi-chain templating system\nsupporting both protein and non-polymeric components as well as dual\nunconditional/conditional modes. Pearl establishes a new state-of-the-art\nperformance in protein-ligand cofolding. On the key metric of generating\naccurate (RMSD < 2 \\r{A}) and physically valid poses, Pearl surpasses AlphaFold\n3 and other open source baselines on the public Runs N' Poses and PoseBusters\nbenchmarks, delivering 14.5% and 14.2% improvements, respectively, over the\nnext best model. In the pocket-conditional cofolding regime, Pearl delivers\n$3.6\\times$ improvement on a proprietary set of challenging, real-world drug\ntargets at the more rigorous RMSD < 1 \\r{A} threshold. Finally, we demonstrate\nthat model performance correlates directly with synthetic dataset size used in\ntraining.",
    "categories": [
      "cs.LG",
      "q-bio.QM"
    ],
    "published": "2025-10-28T17:36:51Z",
    "authors": [
      " Genesis Research Team",
      "Alejandro Dobles",
      "Nina Jovic",
      "Kenneth Leidal",
      "Pranav Murugan",
      "David C. Williams",
      "Drausin Wulsin",
      "Nate Gruver",
      "Christina X. Ji",
      "Korrawat Pruegsanusak",
      "Gianluca Scarpellini",
      "Ansh Sharma",
      "Wojciech Swiderski",
      "Andrea Bootsma",
      "Richard Strong Bowen",
      "Charlotte Chen",
      "Jamin Chen",
      "Marc Andr\u00e9 D\u00e4mgen",
      "Benjamin DiFrancesco",
      "J. D. Fishman",
      "Alla Ivanova",
      "Zach Kagin",
      "David Li-Bland",
      "Zuli Liu",
      "Igor Morozov",
      "Jeffrey Ouyang-Zhang",
      "Frank C. Pickard IV",
      "Kushal S. Shah",
      "Ben Shor",
      "Gabriel Monteiro da Silva",
      "Roy Tal",
      "Maxx Tessmer",
      "Carl Tilbury",
      "Cyr Vetcher",
      "Daniel Zeng",
      "Maruan Al-Shedivat",
      "Aleksandra Faust",
      "Evan N. Feinberg",
      "Michael V. LeVine",
      "Matteus Pan"
    ],
    "pdf_url": "http://arxiv.org/pdf/2510.24670v2"
  },
  {
    "id": "2510.24643v1",
    "title": "The Cost of Robustness: Tighter Bounds on Parameter Complexity for\n  Robust Memorization in ReLU Nets",
    "abstract": "We study the parameter complexity of robust memorization for $\\mathrm{ReLU}$\nnetworks: the number of parameters required to interpolate any given dataset\nwith $\\epsilon$-separation between differently labeled points, while ensuring\npredictions remain consistent within a $\\mu$-ball around each training sample.\nWe establish upper and lower bounds on the parameter count as a function of the\nrobustness ratio $\\rho = \\mu / \\epsilon$. Unlike prior work, we provide a\nfine-grained analysis across the entire range $\\rho \\in (0,1)$ and obtain\ntighter upper and lower bounds that improve upon existing results. Our findings\nreveal that the parameter complexity of robust memorization matches that of\nnon-robust memorization when $\\rho$ is small, but grows with increasing $\\rho$.",
    "categories": [
      "cs.LG",
      "cs.AI"
    ],
    "published": "2025-10-28T17:09:43Z",
    "authors": [
      "Yujun Kim",
      "Chaewon Moon",
      "Chulhee Yun"
    ],
    "pdf_url": "http://arxiv.org/pdf/2510.24643v1"
  },
  {
    "id": "2510.24639v1",
    "title": "Causal Ordering for Structure Learning From Time Series",
    "abstract": "Predicting causal structure from time series data is crucial for\nunderstanding complex phenomena in physiology, brain connectivity, climate\ndynamics, and socio-economic behaviour. Causal discovery in time series is\nhindered by the combinatorial complexity of identifying true causal\nrelationships, especially as the number of variables and time points grow. A\ncommon approach to simplify the task is the so-called ordering-based methods.\nTraditional ordering methods inherently limit the representational capacity of\nthe resulting model. In this work, we fix this issue by leveraging multiple\nvalid causal orderings, instead of a single one as standard practice. We\npropose DOTS (Diffusion Ordered Temporal Structure), using diffusion-based\ncausal discovery for temporal data. By integrating multiple orderings, DOTS\neffectively recovers the transitive closure of the underlying directed acyclic\ngraph, mitigating spurious artifacts inherent in single-ordering approaches. We\nformalise the problem under standard assumptions such as stationarity and the\nadditive noise model, and leverage score matching with diffusion processes to\nenable efficient Hessian estimation. Extensive experiments validate the\napproach. Empirical evaluations on synthetic and real-world datasets\ndemonstrate that DOTS outperforms state-of-the-art baselines, offering a\nscalable and robust approach to temporal causal discovery. On synthetic\nbenchmarks ($d{=}\\!3-\\!6$ variables, $T{=}200\\!-\\!5{,}000$ samples), DOTS\nimproves mean window-graph $F1$ from $0.63$ (best baseline) to $0.81$. On the\nCausalTime real-world benchmark ($d{=}20\\!-\\!36$), while baselines remain the\nbest on individual datasets, DOTS attains the highest average summary-graph\n$F1$ while halving runtime relative to graph-optimisation methods. These\nresults establish DOTS as a scalable and accurate solution for temporal causal\ndiscovery.",
    "categories": [
      "cs.LG",
      "cs.AI"
    ],
    "published": "2025-10-28T17:06:15Z",
    "authors": [
      "Pedro P. Sanchez",
      "Damian Machlanski",
      "Steven McDonagh",
      "Sotirios A. Tsaftaris"
    ],
    "pdf_url": "http://arxiv.org/pdf/2510.24639v1"
  },
  {
    "id": "2510.24633v1",
    "title": "Symbolic Snapshot Ensembles",
    "abstract": "Inductive logic programming (ILP) is a form of logical machine learning. Most\nILP algorithms learn a single hypothesis from a single training run. Ensemble\nmethods train an ILP algorithm multiple times to learn multiple hypotheses. In\nthis paper, we train an ILP algorithm only once and save intermediate\nhypotheses. We then combine the hypotheses using a minimum description length\nweighting scheme. Our experiments on multiple benchmarks, including game\nplaying and visual reasoning, show that our approach improves predictive\naccuracy by 4% with less than 1% computational overhead.",
    "categories": [
      "cs.LG",
      "cs.LO"
    ],
    "published": "2025-10-28T17:01:38Z",
    "authors": [
      "Mingyue Liu",
      "Andrew Cropper"
    ],
    "pdf_url": "http://arxiv.org/pdf/2510.24633v1"
  },
  {
    "id": "2510.24621v1",
    "title": "Coreset for Robust Geometric Median: Eliminating Size Dependency on\n  Outliers",
    "abstract": "We study the robust geometric median problem in Euclidean space\n$\\mathbb{R}^d$, with a focus on coreset construction.A coreset is a compact\nsummary of a dataset $P$ of size $n$ that approximates the robust cost for all\ncenters $c$ within a multiplicative error $\\varepsilon$. Given an outlier count\n$m$, we construct a coreset of size $\\tilde{O}(\\varepsilon^{-2} \\cdot\n\\min\\{\\varepsilon^{-2}, d\\})$ when $n \\geq 4m$, eliminating the $O(m)$\ndependency present in prior work [Huang et al., 2022 & 2023]. For the special\ncase of $d = 1$, we achieve an optimal coreset size of\n$\\tilde{\\Theta}(\\varepsilon^{-1/2} + \\frac{m}{n} \\varepsilon^{-1})$, revealing\na clear separation from the vanilla case studied in [Huang et al., 2023;\nAfshani and Chris, 2024]. Our results further extend to robust\n$(k,z)$-clustering in various metric spaces, eliminating the $m$-dependence\nunder mild data assumptions. The key technical contribution is a novel\nnon-component-wise error analysis, enabling substantial reduction of outlier\ninfluence, unlike prior methods that retain them.Empirically, our algorithms\nconsistently outperform existing baselines in terms of size-accuracy tradeoffs\nand runtime, even when data assumptions are violated across a wide range of\ndatasets.",
    "categories": [
      "cs.DS",
      "cs.CG",
      "cs.LG",
      "stat.ML"
    ],
    "published": "2025-10-28T16:49:03Z",
    "authors": [
      "Ziyi Fang",
      "Lingxiao Huang",
      "Runkai Yang"
    ],
    "pdf_url": "http://arxiv.org/pdf/2510.24621v1"
  },
  {
    "id": "2510.24619v1",
    "title": "Zero-Shot Cross-Lingual Transfer using Prefix-Based Adaptation",
    "abstract": "With the release of new large language models (LLMs) like Llama and Mistral,\nzero-shot cross-lingual transfer has become increasingly feasible due to their\nmultilingual pretraining and strong generalization capabilities. However,\nadapting these decoder-only LLMs to new tasks across languages remains\nchallenging. While parameter-efficient fine-tuning (PeFT) techniques like\nLow-Rank Adaptation (LoRA) are widely used, prefix-based techniques such as\nsoft prompt tuning, prefix tuning, and Llama Adapter are less explored,\nespecially for zero-shot transfer in decoder-only models. We present a\ncomprehensive study of three prefix-based methods for zero-shot cross-lingual\ntransfer from English to 35+ high- and low-resource languages. Our analysis\nfurther explores transfer across linguistic families and scripts, as well as\nthe impact of scaling model sizes from 1B to 24B. With Llama 3.1 8B, prefix\nmethods outperform LoRA-baselines by up to 6% on the Belebele benchmark.\nSimilar improvements were observed with Mistral v0.3 7B as well. Despite using\nonly 1.23M learning parameters with prefix tuning, we achieve consistent\nimprovements across diverse benchmarks. These findings highlight the potential\nof prefix-based techniques as an effective and scalable alternative to LoRA,\nparticularly in low-resource multilingual settings.",
    "categories": [
      "cs.CL",
      "cs.AI",
      "cs.LG",
      "I.2.7"
    ],
    "published": "2025-10-28T16:48:03Z",
    "authors": [
      "Snegha A",
      "Sayambhu Sen",
      "Piyush Singh Pasi",
      "Abhishek Singhania",
      "Preethi Jyothi"
    ],
    "pdf_url": "http://arxiv.org/pdf/2510.24619v1"
  },
  {
    "id": "2510.24616v2",
    "title": "Statistical physics of deep learning: Optimal learning of a multi-layer\n  perceptron near interpolation",
    "abstract": "For three decades statistical physics has been providing a framework to\nanalyse neural networks. A long-standing question remained on its capacity to\ntackle deep learning models capturing rich feature learning effects, thus going\nbeyond the narrow networks or kernel methods analysed until now. We positively\nanswer through the study of the supervised learning of a multi-layer\nperceptron. Importantly, (i) its width scales as the input dimension, making it\nmore prone to feature learning than ultra wide networks, and more expressive\nthan narrow ones or with fixed embedding layers; and (ii) we focus on the\nchallenging interpolation regime where the number of trainable parameters and\ndata are comparable, which forces the model to adapt to the task. We consider\nthe matched teacher-student setting. It provides the fundamental limits of\nlearning random deep neural network targets and helps in identifying the\nsufficient statistics describing what is learnt by an optimally trained network\nas the data budget increases. A rich phenomenology emerges with various\nlearning transitions. With enough data optimal performance is attained through\nmodel's \"specialisation\" towards the target, but it can be hard to reach for\ntraining algorithms which get attracted by sub-optimal solutions predicted by\nthe theory. Specialisation occurs inhomogeneously across layers, propagating\nfrom shallow towards deep ones, but also across neurons in each layer.\nFurthermore, deeper targets are harder to learn. Despite its simplicity, the\nBayesian-optimal setting provides insights on how the depth, non-linearity and\nfinite (proportional) width influence neural networks in the feature learning\nregime that are potentially relevant way beyond it.",
    "categories": [
      "stat.ML",
      "cond-mat.dis-nn",
      "cond-mat.stat-mech",
      "cs.IT",
      "cs.LG",
      "math.IT"
    ],
    "published": "2025-10-28T16:44:34Z",
    "authors": [
      "Jean Barbier",
      "Francesco Camilli",
      "Minh-Toan Nguyen",
      "Mauro Pastore",
      "Rudy Skerk"
    ],
    "pdf_url": "http://arxiv.org/pdf/2510.24616v2"
  },
  {
    "id": "2510.24614v1",
    "title": "Semi-supervised and unsupervised learning for health indicator\n  extraction from guided waves in aerospace composite structures",
    "abstract": "Health indicators (HIs) are central to diagnosing and prognosing the\ncondition of aerospace composite structures, enabling efficient maintenance and\noperational safety. However, extracting reliable HIs remains challenging due to\nvariability in material properties, stochastic damage evolution, and diverse\ndamage modes. Manufacturing defects (e.g., disbonds) and in-service incidents\n(e.g., bird strikes) further complicate this process. This study presents a\ncomprehensive data-driven framework that learns HIs via two learning approaches\nintegrated with multi-domain signal processing. Because ground-truth HIs are\nunavailable, a semi-supervised and an unsupervised approach are proposed: (i) a\ndiversity deep semi-supervised anomaly detection (Diversity-DeepSAD) approach\naugmented with continuous auxiliary labels used as hypothetical damage proxies,\nwhich overcomes the limitation of prior binary labels that only distinguish\nhealthy and failed states while neglecting intermediate degradation, and (ii) a\ndegradation-trend-constrained variational autoencoder (DTC-VAE), in which the\nmonotonicity criterion is embedded via an explicit trend constraint. Guided\nwaves with multiple excitation frequencies are used to monitor single-stiffener\ncomposite structures under fatigue loading. Time, frequency, and time-frequency\nrepresentations are explored, and per-frequency HIs are fused via unsupervised\nensemble learning to mitigate frequency dependence and reduce variance. Using\nfast Fourier transform features, the augmented Diversity-DeepSAD model achieved\n81.6% performance, while DTC-VAE delivered the most consistent HIs with 92.3%\nperformance, outperforming existing baselines.",
    "categories": [
      "cs.LG",
      "cs.CE",
      "eess.SP"
    ],
    "published": "2025-10-28T16:44:11Z",
    "authors": [
      "James Josep Perry",
      "Pablo Garcia-Conde Ortiz",
      "George Konstantinou",
      "Cornelie Vergouwen",
      "Edlyn Santha Kumaran",
      "Morteza Moradi"
    ],
    "pdf_url": "http://arxiv.org/pdf/2510.24614v1"
  },
  {
    "id": "2510.24830v1",
    "title": "The Generation Phases of Flow Matching: a Denoising Perspective",
    "abstract": "Flow matching has achieved remarkable success, yet the factors influencing\nthe quality of its generation process remain poorly understood. In this work,\nwe adopt a denoising perspective and design a framework to empirically probe\nthe generation process. Laying down the formal connections between flow\nmatching models and denoisers, we provide a common ground to compare their\nperformances on generation and denoising. This enables the design of principled\nand controlled perturbations to influence sample generation: noise and drift.\nThis leads to new insights on the distinct dynamical phases of the generative\nprocess, enabling us to precisely characterize at which stage of the generative\nprocess denoisers succeed or fail and why this matters.",
    "categories": [
      "cs.CV",
      "cs.AI",
      "cs.LG"
    ],
    "published": "2025-10-28T16:42:53Z",
    "authors": [
      "Anne Gagneux",
      "S\u00e9gol\u00e8ne Martin",
      "R\u00e9mi Gribonval",
      "Mathurin Massias"
    ],
    "pdf_url": "http://arxiv.org/pdf/2510.24830v1"
  },
  {
    "id": "2510.24601v1",
    "title": "Comparison of generalised additive models and neural networks in\n  applications: A systematic review",
    "abstract": "Neural networks have become a popular tool in predictive modelling, more\ncommonly associated with machine learning and artificial intelligence than with\nstatistics. Generalised Additive Models (GAMs) are flexible non-linear\nstatistical models that retain interpretability. Both are state-of-the-art in\ntheir own right, with their respective advantages and disadvantages. This paper\nanalyses how these two model classes have performed on real-world tabular data.\nFollowing PRISMA guidelines, we conducted a systematic review of papers that\nperformed empirical comparisons of GAMs and neural networks. Eligible papers\nwere identified, yielding 143 papers, with 430 datasets. Key attributes at both\npaper and dataset levels were extracted and reported. Beyond summarising\ncomparisons, we analyse reported performance metrics using mixed-effects\nmodelling to investigate potential characteristics that can explain and\nquantify observed differences, including application area, study year, sample\nsize, number of predictors, and neural network complexity. Across datasets, no\nconsistent evidence of superiority was found for either GAMs or neural networks\nwhen considering the most frequently reported metrics (RMSE, $R^2$, and AUC).\nNeural networks tended to outperform in larger datasets and in those with more\npredictors, but this advantage narrowed over time. Conversely, GAMs remained\ncompetitive, particularly in smaller data settings, while retaining\ninterpretability. Reporting of dataset characteristics and neural network\ncomplexity was incomplete in much of the literature, limiting transparency and\nreproducibility. This review highlights that GAMs and neural networks should be\nviewed as complementary approaches rather than competitors. For many tabular\napplications, the performance trade-off is modest, and interpretability may\nfavour GAMs.",
    "categories": [
      "stat.ML",
      "cs.LG",
      "68T07, 62J02"
    ],
    "published": "2025-10-28T16:28:42Z",
    "authors": [
      "Jessica Doohan",
      "Lucas Kook",
      "Kevin Burke"
    ],
    "pdf_url": "http://arxiv.org/pdf/2510.24601v1"
  },
  {
    "id": "2510.24598v1",
    "title": "A Novel XAI-Enhanced Quantum Adversarial Networks for Velocity\n  Dispersion Modeling in MaNGA Galaxies",
    "abstract": "Current quantum machine learning approaches often face challenges balancing\npredictive accuracy, robustness, and interpretability. To address this, we\npropose a novel quantum adversarial framework that integrates a hybrid quantum\nneural network (QNN) with classical deep learning layers, guided by an\nevaluator model with LIME-based interpretability, and extended through quantum\nGAN and self-supervised variants. In the proposed model, an adversarial\nevaluator concurrently guides the QNN by computing feedback loss, thereby\noptimizing both prediction accuracy and model explainability. Empirical\nevaluations show that the Vanilla model achieves RMSE = 0.27, MSE = 0.071, MAE\n= 0.21, and R^2 = 0.59, delivering the most consistent performance across\nregression metrics compared to adversarial counterparts. These results\ndemonstrate the potential of combining quantum-inspired methods with classical\narchitectures to develop lightweight, high-performance, and interpretable\npredictive models, advancing the applicability of QML beyond current\nlimitations.",
    "categories": [
      "cs.LG",
      "cs.CR"
    ],
    "published": "2025-10-28T16:27:10Z",
    "authors": [
      "Sathwik Narkedimilli",
      "N V Saran Kumar",
      "Aswath Babu H",
      "Manjunath K Vanahalli",
      "Manish M",
      "Vinija Jain",
      "Aman Chadha"
    ],
    "pdf_url": "http://arxiv.org/pdf/2510.24598v1"
  },
  {
    "id": "2510.24829v2",
    "title": "Send Less, Save More: Energy-Efficiency Benchmark of Embedded CNN\n  Inference vs. Data Transmission in IoT",
    "abstract": "The integration of the Internet of Things (IoT) and Artificial Intelligence\noffers significant opportunities to enhance our ability to monitor and address\necological changes. As environmental challenges become increasingly pressing,\nthe need for effective remote monitoring solutions is more critical than ever.\nA major challenge in designing IoT applications for environmental monitoring -\nparticularly those involving image data - is to create energy-efficient IoT\ndevices capable of long-term operation in remote areas with limited power\navailability. Advancements in the field of Tiny Machine Learning allow the use\nof Convolutional Neural Networks (CNNs) on resource-constrained,\nbattery-operated microcontrollers. Since data transfer is energy-intensive,\nperforming inference directly on microcontrollers to reduce the message size\ncan extend the operational lifespan of IoT nodes. This work evaluates the use\nof common Low Power Wide Area Networks and compressed CNNs trained on domain\nspecific datasets on an ESP32-S3. Our experiments demonstrate, among other\nthings, that executing CNN inference on-device and transmitting only the\nresults reduces the overall energy consumption by a factor of up to five\ncompared to sending raw image data. These findings advocate the development of\nIoT applications with reduced carbon footprint and capable of operating\nautonomously in environmental monitoring scenarios by incorporating EmbeddedML.",
    "categories": [
      "cs.LG"
    ],
    "published": "2025-10-28T16:18:14Z",
    "authors": [
      "Benjamin Karic",
      "Nina Herrmann",
      "Jan Stenkamp",
      "Paula Scharf",
      "Fabian Gieseke",
      "Angela Schwering"
    ],
    "pdf_url": "http://arxiv.org/pdf/2510.24829v2"
  },
  {
    "id": "2510.24577v1",
    "title": "Physics-Informed Extreme Learning Machine (PIELM): Opportunities and\n  Challenges",
    "abstract": "We are very delighted to see the fast development of physics-informed extreme\nlearning machine (PIELM) in recent years for higher computation efficiency and\naccuracy in physics-informed machine learning. As a summary or review on PIELM\nis currently not available, we would like to take this opportunity to show our\nperspective and experience for this promising research direction. We can see\nmany efforts are made to solve PDEs with sharp gradients, nonlinearities,\nhigh-frequency behavior, hard constraints, uncertainty, multiphysics coupling.\nDespite the success, many urgent challenges remain to be tackled, which also\nprovides us opportunities to develop more robust, interpretable, and\ngeneralizable PIELM frameworks with applications in science and engineering.",
    "categories": [
      "cs.LG"
    ],
    "published": "2025-10-28T16:11:16Z",
    "authors": [
      "He Yang",
      "Fei Ren",
      "Hai-Sui Yu",
      "Xiaohui Chen",
      "Pei-Zhi Zhuang"
    ],
    "pdf_url": "http://arxiv.org/pdf/2510.24577v1"
  },
  {
    "id": "2510.24574v1",
    "title": "DistDF: Time-Series Forecasting Needs Joint-Distribution Wasserstein\n  Alignment",
    "abstract": "Training time-series forecast models requires aligning the conditional\ndistribution of model forecasts with that of the label sequence. The standard\ndirect forecast (DF) approach resorts to minimize the conditional negative\nlog-likelihood of the label sequence, typically estimated using the mean\nsquared error. However, this estimation proves to be biased in the presence of\nlabel autocorrelation. In this paper, we propose DistDF, which achieves\nalignment by alternatively minimizing a discrepancy between the conditional\nforecast and label distributions. Because conditional discrepancies are\ndifficult to estimate from finite time-series observations, we introduce a\nnewly proposed joint-distribution Wasserstein discrepancy for time-series\nforecasting, which provably upper bounds the conditional discrepancy of\ninterest. This discrepancy admits tractable, differentiable estimation from\nempirical samples and integrates seamlessly with gradient-based training.\nExtensive experiments show that DistDF improves the performance diverse\nforecast models and achieves the state-of-the-art forecasting performance. Code\nis available at https://anonymous.4open.science/r/DistDF-F66B.",
    "categories": [
      "cs.LG",
      "cs.AI"
    ],
    "published": "2025-10-28T16:09:59Z",
    "authors": [
      "Hao Wang",
      "Licheng Pan",
      "Yuan Lu",
      "Zhixuan Chu",
      "Xiaoxi Li",
      "Shuting He",
      "Zhichao Chen",
      "Haoxuan Li",
      "Qingsong Wen",
      "Zhouchen Lin"
    ],
    "pdf_url": "http://arxiv.org/pdf/2510.24574v1"
  },
  {
    "id": "2510.24561v1",
    "title": "LoRA-DA: Data-Aware Initialization for Low-Rank Adaptation via\n  Asymptotic Analysis",
    "abstract": "With the widespread adoption of LLMs, LoRA has become a dominant method for\nPEFT, and its initialization methods have attracted increasing attention.\nHowever, existing methods have notable limitations: many methods do not\nincorporate target-domain data, while gradient-based methods exploit data only\nat a shallow level by relying on one-step gradient decomposition, which remains\nunsatisfactory due to the weak empirical performance of the one-step\nfine-tuning model that serves as their basis, as well as the fact that these\nmethods either lack a rigorous theoretical foundation or depend heavily on\nrestrictive isotropic assumptions. In this paper, we establish a theoretical\nframework for data-aware LoRA initialization based on asymptotic analysis.\nStarting from a general optimization objective that minimizes the expectation\nof the parameter discrepancy between the fine-tuned and target models, we\nderive an optimization problem with two components: a bias term, which is\nrelated to the parameter distance between the fine-tuned and target models, and\nis approximated using a Fisher-gradient formulation to preserve anisotropy; and\na variance term, which accounts for the uncertainty introduced by sampling\nstochasticity through the Fisher information. By solving this problem, we\nobtain an optimal initialization strategy for LoRA. Building on this\ntheoretical framework, we develop an efficient algorithm, LoRA-DA, which\nestimates the terms in the optimization problem from a small set of target\ndomain samples and obtains the optimal LoRA initialization. Empirical results\nacross multiple benchmarks demonstrate that LoRA-DA consistently improves final\naccuracy over existing initialization methods. Additional studies show faster,\nmore stable convergence, robustness across ranks, and only a small\ninitialization overhead for LoRA-DA. The source code will be released upon\npublication.",
    "categories": [
      "cs.LG",
      "cs.AI"
    ],
    "published": "2025-10-28T15:55:36Z",
    "authors": [
      "Qingyue Zhang",
      "Chang Chu",
      "Tianren Peng",
      "Qi Li",
      "Xiangyang Luo",
      "Zhihao Jiang",
      "Shao-Lun Huang"
    ],
    "pdf_url": "http://arxiv.org/pdf/2510.24561v1"
  },
  {
    "id": "2510.24557v1",
    "title": "Enforcing boundary conditions for physics-informed neural operators",
    "abstract": "Machine-learning based methods like physics-informed neural networks and\nphysics-informed neural operators are becoming increasingly adept at solving\neven complex systems of partial differential equations. Boundary conditions can\nbe enforced either weakly by penalizing deviations in the loss function or\nstrongly by training a solution structure that inherently matches the\nprescribed values and derivatives. The former approach is easy to implement but\nthe latter can provide benefits with respect to accuracy and training times.\nHowever, previous approaches to strongly enforcing Neumann or Robin boundary\nconditions require a domain with a fully $C^1$ boundary and, as we demonstrate,\ncan lead to instability if those boundary conditions are posed on a segment of\nthe boundary that is piecewise $C^1$ but only $C^0$ globally. We introduce a\ngeneralization of the approach by Sukumar \\& Srivastava (doi:\n10.1016/j.cma.2021.114333), and a new approach based on orthogonal projections\nthat overcome this limitation. The performance of these new techniques is\ncompared against weakly and semi-weakly enforced boundary conditions for the\nscalar Darcy flow equation and the stationary Navier-Stokes equations.",
    "categories": [
      "math.NA",
      "cs.LG",
      "cs.NA",
      "65N99, 68T07"
    ],
    "published": "2025-10-28T15:51:48Z",
    "authors": [
      "Niklas G\u00f6schel",
      "Sebastian G\u00f6tschel",
      "Daniel Ruprecht"
    ],
    "pdf_url": "http://arxiv.org/pdf/2510.24557v1"
  },
  {
    "id": "2510.24826v1",
    "title": "Augmenting Biological Fitness Prediction Benchmarks with Landscapes\n  Features from GraphFLA",
    "abstract": "Machine learning models increasingly map biological sequence-fitness\nlandscapes to predict mutational effects. Effective evaluation of these models\nrequires benchmarks curated from empirical data. Despite their impressive\nscales, existing benchmarks lack topographical information regarding the\nunderlying fitness landscapes, which hampers interpretation and comparison of\nmodel performance beyond averaged scores. Here, we introduce GraphFLA, a Python\nframework that constructs and analyzes fitness landscapes from mutagensis data\nin diverse modalities (e.g., DNA, RNA, protein, and beyond) with up to millions\nof mutants. GraphFLA calculates 20 biologically relevant features that\ncharacterize 4 fundamental aspects of landscape topography. By applying\nGraphFLA to over 5,300 landscapes from ProteinGym, RNAGym, and CIS-BP, we\ndemonstrate its utility in interpreting and comparing the performance of dozens\nof fitness prediction models, highlighting factors influencing model accuracy\nand respective advantages of different models. In addition, we release 155\ncombinatorially complete empirical fitness landscapes, encompassing over 2.2\nmillion sequences across various modalities. All the codes and datasets are\navailable at https://github.com/COLA-Laboratory/GraphFLA.",
    "categories": [
      "cs.LG"
    ],
    "published": "2025-10-28T15:50:58Z",
    "authors": [
      "Mingyu Huang",
      "Shasha Zhou",
      "Ke Li"
    ],
    "pdf_url": "http://arxiv.org/pdf/2510.24826v1"
  },
  {
    "id": "2510.24546v1",
    "title": "Dual-Mind World Models: A General Framework for Learning in Dynamic\n  Wireless Networks",
    "abstract": "Despite the popularity of reinforcement learning (RL) in wireless networks,\nexisting approaches that rely on model-free RL (MFRL) and model-based RL (MBRL)\nare data inefficient and short-sighted. Such RL-based solutions cannot\ngeneralize to novel network states since they capture only statistical patterns\nrather than the underlying physics and logic from wireless data. These\nlimitations become particularly challenging in complex wireless networks with\nhigh dynamics and long-term planning requirements. To address these\nlimitations, in this paper, a novel dual-mind world model-based learning\nframework is proposed with the goal of optimizing completeness-weighted age of\ninformation (CAoI) in a challenging mmWave V2X scenario. Inspired by cognitive\npsychology, the proposed dual-mind world model encompasses a pattern-driven\nSystem 1 component and a logic-driven System 2 component to learn dynamics and\nlogic of the wireless network, and to provide long-term link scheduling over\nreliable imagined trajectories. Link scheduling is learned through end-to-end\ndifferentiable imagined trajectories with logical consistency over an extended\nhorizon rather than relying on wireless data obtained from environment\ninteractions. Moreover, through imagination rollouts, the proposed world model\ncan jointly reason network states and plan link scheduling. During intervals\nwithout observations, the proposed method remains capable of making efficient\ndecisions. Extensive experiments are conducted on a realistic simulator based\non Sionna with real-world physical channel, ray-tracing, and scene objects with\nmaterial properties. Simulation results show that the proposed world model\nachieves a significant improvement in data efficiency and achieves strong\ngeneralization and adaptation to unseen environments, compared to the\nstate-of-the-art RL baselines, and the world model approach with only System 1.",
    "categories": [
      "cs.IT",
      "cs.LG",
      "math.IT"
    ],
    "published": "2025-10-28T15:45:15Z",
    "authors": [
      "Lingyi Wang",
      "Rashed Shelim",
      "Walid Saad",
      "Naren Ramakrishnan"
    ],
    "pdf_url": "http://arxiv.org/pdf/2510.24546v1"
  },
  {
    "id": "2510.24523v1",
    "title": "Unsupervised Machine-Learning Pipeline for Data-Driven Defect Detection\n  and Characterisation: Application to Displacement Cascades",
    "abstract": "Neutron irradiation produces, within a few picoseconds, displacement cascades\nthat are sequences of atomic collisions generating point and extended defects\nwhich subsequently affects the long-term evolution of materials. The diversity\nof these defects, characterized morphologically and statistically, defines what\nis called the \"primary damage\". In this work, we present a fully unsupervised\nmachine learning (ML) workflow that detects and classifies these defects\ndirectly from molecular dynamics data. Local environments are encoded by the\nSmooth Overlap of Atomic Positions (SOAP) vector, anomalous atoms are isolated\nwith autoencoder neural networks (AE), embedded with Uniform Manifold\nApproximation and Projection (UMAP) and clustered using Hierarchical\nDensity-Based Spatial Clustering of Applications with Noise (HDBSCAN). Applied\nto 80 keV displacement cascades in Ni, Fe$_7$0Ni$_{10}$Cr$_{20}$, and Zr, the\nAE successfully identify the small fraction of outlier atoms that participate\nin defect formation. HDBSCAN then partitions the UMAP latent space of\nAE-flagged SOAP descriptors into well defined groups representing vacancy- and\ninterstitial-dominated regions and, within each, separates small from large\naggregates, assigning 99.7 % of outliers to compact physical motifs. A signed\ncluster-identification score confirms this separation, and cluster size scales\nwith net defect counts (R2 > 0.89). Statistical cross analyses between the ML\noutlier map and several conventional detectors (centrosymmetry, dislocation\nextraction, etc.) reveal strong overlap and complementary coverage, all\nachieved without template or threshold tuning. This ML workflow thus provides\nan efficient tool for the quantitative mapping of structural anomalies in\nmaterials, particularly those arising from irradiation damage in displacement\ncascades.",
    "categories": [
      "cond-mat.mtrl-sci",
      "cs.LG"
    ],
    "published": "2025-10-28T15:34:23Z",
    "authors": [
      "Samuel Del Fr\u00e9",
      "Andr\u00e9e de Backer",
      "Christophe Domain",
      "Ludovic Thuinet",
      "Charlotte S. Becquart"
    ],
    "pdf_url": "http://arxiv.org/pdf/2510.24523v1"
  },
  {
    "id": "2510.24503v1",
    "title": "Local Performance vs. Out-of-Distribution Generalization: An Empirical\n  Analysis of Personalized Federated Learning in Heterogeneous Data\n  Environments",
    "abstract": "In the context of Federated Learning with heterogeneous data environments,\nlocal models tend to converge to their own local model optima during local\ntraining steps, deviating from the overall data distributions. Aggregation of\nthese local updates, e.g., with FedAvg, often does not align with the global\nmodel optimum (client drift), resulting in an update that is suboptimal for\nmost clients. Personalized Federated Learning approaches address this challenge\nby exclusively focusing on the average local performances of clients' models on\ntheir own data distribution. Generalization to out-of-distribution samples,\nwhich is a substantial benefit of FedAvg and represents a significant component\nof robustness, appears to be inadequately incorporated into the assessment and\nevaluation processes. This study involves a thorough evaluation of Federated\nLearning approaches, encompassing both their local performance and their\ngeneralization capabilities. Therefore, we examine different stages within a\nsingle communication round to enable a more nuanced understanding of the\nconsidered metrics. Furthermore, we propose and incorporate a modified approach\nof FedAvg, designated as Federated Learning with Individualized Updates (FLIU),\nextending the algorithm by a straightforward individualization step with an\nadaptive personalization factor. We evaluate and compare the approaches\nempirically using MNIST and CIFAR-10 under various distributional conditions,\nincluding benchmark IID and pathological non-IID, as well as additional novel\ntest environments with Dirichlet distribution specifically developed to stress\nthe algorithms on complex data heterogeneity.",
    "categories": [
      "cs.LG",
      "cs.AI",
      "cs.CV",
      "cs.DC",
      "cs.MA"
    ],
    "published": "2025-10-28T15:15:14Z",
    "authors": [
      "Mortesa Hussaini",
      "Jan Thei\u00df",
      "Anthony Stein"
    ],
    "pdf_url": "http://arxiv.org/pdf/2510.24503v1"
  },
  {
    "id": "2510.24500v1",
    "title": "MIMIC-Sepsis: A Curated Benchmark for Modeling and Learning from Sepsis\n  Trajectories in the ICU",
    "abstract": "Sepsis is a leading cause of mortality in intensive care units (ICUs), yet\nexisting research often relies on outdated datasets, non-reproducible\npreprocessing pipelines, and limited coverage of clinical interventions. We\nintroduce MIMIC-Sepsis, a curated cohort and benchmark framework derived from\nthe MIMIC-IV database, designed to support reproducible modeling of sepsis\ntrajectories. Our cohort includes 35,239 ICU patients with time-aligned\nclinical variables and standardized treatment data, including vasopressors,\nfluids, mechanical ventilation and antibiotics. We describe a transparent\npreprocessing pipeline-based on Sepsis-3 criteria, structured imputation\nstrategies, and treatment inclusion-and release it alongside benchmark tasks\nfocused on early mortality prediction, length-of-stay estimation, and shock\nonset classification. Empirical results demonstrate that incorporating\ntreatment variables substantially improves model performance, particularly for\nTransformer-based architectures. MIMIC-Sepsis serves as a robust platform for\nevaluating predictive and sequential models in critical care research.",
    "categories": [
      "cs.LG"
    ],
    "published": "2025-10-28T15:13:38Z",
    "authors": [
      "Yong Huang",
      "Zhongqi Yang",
      "Amir Rahmani"
    ],
    "pdf_url": "http://arxiv.org/pdf/2510.24500v1"
  },
  {
    "id": "2510.24482v1",
    "title": "Sample-efficient and Scalable Exploration in Continuous-Time RL",
    "abstract": "Reinforcement learning algorithms are typically designed for discrete-time\ndynamics, even though the underlying real-world control systems are often\ncontinuous in time. In this paper, we study the problem of continuous-time\nreinforcement learning, where the unknown system dynamics are represented using\nnonlinear ordinary differential equations (ODEs). We leverage probabilistic\nmodels, such as Gaussian processes and Bayesian neural networks, to learn an\nuncertainty-aware model of the underlying ODE. Our algorithm, COMBRL, greedily\nmaximizes a weighted sum of the extrinsic reward and model epistemic\nuncertainty. This yields a scalable and sample-efficient approach to\ncontinuous-time model-based RL. We show that COMBRL achieves sublinear regret\nin the reward-driven setting, and in the unsupervised RL setting (i.e., without\nextrinsic rewards), we provide a sample complexity bound. In our experiments,\nwe evaluate COMBRL in both standard and unsupervised RL settings and\ndemonstrate that it scales better, is more sample-efficient than prior methods,\nand outperforms baselines across several deep RL tasks.",
    "categories": [
      "cs.LG",
      "cs.AI",
      "cs.RO"
    ],
    "published": "2025-10-28T14:54:12Z",
    "authors": [
      "Klemens Iten",
      "Lenart Treven",
      "Bhavya Sukhija",
      "Florian D\u00f6rfler",
      "Andreas Krause"
    ],
    "pdf_url": "http://arxiv.org/pdf/2510.24482v1"
  },
  {
    "id": "2510.24473v1",
    "title": "Methodology for Comparing Machine Learning Algorithms for Survival\n  Analysis",
    "abstract": "This study presents a comparative methodological analysis of six machine\nlearning models for survival analysis (MLSA). Using data from nearly 45,000\ncolorectal cancer patients in the Hospital-Based Cancer Registries of S\\~ao\nPaulo, we evaluated Random Survival Forest (RSF), Gradient Boosting for\nSurvival Analysis (GBSA), Survival SVM (SSVM), XGBoost-Cox (XGB-Cox),\nXGBoost-AFT (XGB-AFT), and LightGBM (LGBM), capable of predicting survival\nconsidering censored data. Hyperparameter optimization was performed with\ndifferent samplers, and model performance was assessed using the Concordance\nIndex (C-Index), C-Index IPCW, time-dependent AUC, and Integrated Brier Score\n(IBS). Survival curves produced by the models were compared with predictions\nfrom classification algorithms, and predictor interpretation was conducted\nusing SHAP and permutation importance. XGB-AFT achieved the best performance\n(C-Index = 0.7618; IPCW = 0.7532), followed by GBSA and RSF. The results\nhighlight the potential and applicability of MLSA to improve survival\nprediction and support decision making.",
    "categories": [
      "cs.LG"
    ],
    "published": "2025-10-28T14:42:28Z",
    "authors": [
      "Lucas Buk Cardoso",
      "Simone Aldrey Angelo",
      "Yasmin Pacheco Gil Bonilha",
      "Fernando Maia",
      "Adeylson Guimar\u00e3es Ribeiro",
      "Maria Paula Curado",
      "Gisele Aparecida Fernandes",
      "Vanderlei Cunha Parro",
      "Fl\u00e1vio Almeida de Magalh\u00e3es Cipparrone",
      "Alexandre Dias Porto Chiavegatto Filho",
      "Tatiana Natasha Toporcov"
    ],
    "pdf_url": "http://arxiv.org/pdf/2510.24473v1"
  },
  {
    "id": "2510.24466v1",
    "title": "Non-Singularity of the Gradient Descent map for Neural Networks with\n  Piecewise Analytic Activations",
    "abstract": "The theory of training deep networks has become a central question of modern\nmachine learning and has inspired many practical advancements. In particular,\nthe gradient descent (GD) optimization algorithm has been extensively studied\nin recent years. A key assumption about GD has appeared in several recent\nworks: the \\emph{GD map is non-singular} -- it preserves sets of measure zero\nunder preimages. Crucially, this assumption has been used to prove that GD\navoids saddle points and maxima, and to establish the existence of a computable\nquantity that determines the convergence to global minima (both for GD and\nstochastic GD). However, the current literature either assumes the\nnon-singularity of the GD map or imposes restrictive assumptions, such as\nLipschitz smoothness of the loss (for example, Lipschitzness does not hold for\ndeep ReLU networks with the cross-entropy loss) and restricts the analysis to\nGD with small step-sizes. In this paper, we investigate the neural network map\nas a function on the space of weights and biases. We also prove, for the first\ntime, the non-singularity of the gradient descent (GD) map on the loss\nlandscape of realistic neural network architectures (with fully connected,\nconvolutional, or softmax attention layers) and piecewise analytic activations\n(which includes sigmoid, ReLU, leaky ReLU, etc.) for almost all step-sizes. Our\nwork significantly extends the existing results on the convergence of GD and\nSGD by guaranteeing that they apply to practical neural network settings and\nhas the potential to unlock further exploration of learning dynamics.",
    "categories": [
      "math.OC",
      "cs.LG"
    ],
    "published": "2025-10-28T14:34:33Z",
    "authors": [
      "Alexandru Cr\u0103ciun",
      "Debarghya Ghoshdastidar"
    ],
    "pdf_url": "http://arxiv.org/pdf/2510.24466v1"
  },
  {
    "id": "2510.24452v1",
    "title": "ARIMA_PLUS: Large-scale, Accurate, Automatic and Interpretable\n  In-Database Time Series Forecasting and Anomaly Detection in Google BigQuery",
    "abstract": "Time series forecasting and anomaly detection are common tasks for\npractitioners in industries such as retail, manufacturing, advertising and\nenergy. Two unique challenges stand out: (1) efficiently and accurately\nforecasting time series or detecting anomalies in large volumes automatically;\nand (2) ensuring interpretability of results to effectively incorporate\nbusiness insights. We present ARIMA_PLUS, a novel framework to overcome these\ntwo challenges by a unique combination of (a) accurate and interpretable time\nseries models and (b) scalable and fully managed system infrastructure. The\nmodel has a sequential and modular structure to handle different components of\nthe time series, including holiday effects, seasonality, trend, and anomalies,\nwhich enables high interpretability of the results. Novel enhancements are made\nto each module, and a unified framework is established to address both\nforecasting and anomaly detection tasks simultaneously. In terms of accuracy,\nits comprehensive benchmark on the 42 public datasets in the Monash forecasting\nrepository shows superior performance over not only well-established\nstatistical alternatives (such as ETS, ARIMA, TBATS, Prophet) but also newer\nneural network models (such as DeepAR, N-BEATS, PatchTST, TimeMixer). In terms\nof infrastructure, it is directly built into the query engine of BigQuery in\nGoogle Cloud. It uses a simple SQL interface and automates tedious\ntechnicalities such as data cleaning and model selection. It automatically\nscales with managed cloud computational and storage resources, making it\npossible to forecast 100 million time series using only 1.5 hours with a\nthroughput of more than 18000 time series per second. In terms of\ninterpretability, we present several case studies to demonstrate time series\ninsights it generates and customizability it offers.",
    "categories": [
      "cs.DC",
      "cs.LG"
    ],
    "published": "2025-10-28T14:18:50Z",
    "authors": [
      "Xi Cheng",
      "Weijie Shen",
      "Haoming Chen",
      "Chaoyi Shen",
      "Jean Ortega",
      "Jiashang Liu",
      "Steve Thomas",
      "Honglin Zheng",
      "Haoyun Wu",
      "Yuxiang Li",
      "Casey Lichtendahl",
      "Jenny Ortiz",
      "Gang Liu",
      "Haiyang Qi",
      "Omid Fatemieh",
      "Chris Fry",
      "Jing Jing Long"
    ],
    "pdf_url": "http://arxiv.org/pdf/2510.24452v1"
  },
  {
    "id": "2510.25785v1",
    "title": "HiMAE: Hierarchical Masked Autoencoders Discover Resolution-Specific\n  Structure in Wearable Time Series",
    "abstract": "Wearable sensors provide abundant physiological time series, yet the\nprinciples governing their predictive utility remain unclear. We hypothesize\nthat temporal resolution is a fundamental axis of representation learning, with\ndifferent clinical and behavioral outcomes relying on structure at distinct\nscales. To test this resolution hypothesis, we introduce HiMAE (Hierarchical\nMasked Autoencoder), a self supervised framework that combines masked\nautoencoding with a hierarchical convolutional encoder decoder. HiMAE produces\nmulti resolution embeddings that enable systematic evaluation of which temporal\nscales carry predictive signal, transforming resolution from a hyperparameter\ninto a probe for interpretability. Across classification, regression, and\ngenerative benchmarks, HiMAE consistently outperforms state of the art\nfoundation models that collapse scale, while being orders of magnitude smaller.\nHiMAE is an efficient representation learner compact enough to run entirely on\nwatch, achieving sub millisecond inference on smartwatch class CPUs for true\nedge inference. Together, these contributions position HiMAE as both an\nefficient self supervised learning method and a discovery tool for scale\nsensitive structure in wearable health.",
    "categories": [
      "cs.LG",
      "cs.AI",
      "eess.SP"
    ],
    "published": "2025-10-28T14:15:45Z",
    "authors": [
      "Simon A. Lee",
      "Cyrus Tanade",
      "Hao Zhou",
      "Juhyeon Lee",
      "Megha Thukral",
      "Minji Han",
      "Rachel Choi",
      "Md Sazzad Hissain Khan",
      "Baiying Lu",
      "Migyeong Gwak",
      "Mehrab Bin Morshed",
      "Viswam Nathan",
      "Md Mahbubur Rahman",
      "Li Zhu",
      "Subramaniam Venkatraman",
      "Sharanya Arcot Desai"
    ],
    "pdf_url": "http://arxiv.org/pdf/2510.25785v1"
  },
  {
    "id": "2510.24433v1",
    "title": "Nearest Neighbor Matching as Least Squares Density Ratio Estimation and\n  Riesz Regression",
    "abstract": "This study proves that Nearest Neighbor (NN) matching can be interpreted as\nan instance of Riesz regression for automatic debiased machine learning. Lin et\nal. (2023) shows that NN matching is an instance of density-ratio estimation\nwith their new density-ratio estimator. Chernozhukov et al. (2024) develops\nRiesz regression for automatic debiased machine learning, which directly\nestimates the Riesz representer (or equivalently, the bias-correction term) by\nminimizing the mean squared error. In this study, we first prove that the\ndensity-ratio estimation method proposed in Lin et al. (2023) is essentially\nequivalent to Least-Squares Importance Fitting (LSIF) proposed in Kanamori et\nal. (2009) for direct density-ratio estimation. Furthermore, we derive Riesz\nregression using the LSIF framework. Based on these results, we derive NN\nmatching from Riesz regression. This study is based on our work Kato (2025a)\nand Kato (2025b).",
    "categories": [
      "econ.EM",
      "cs.LG",
      "math.ST",
      "stat.ME",
      "stat.ML",
      "stat.TH"
    ],
    "published": "2025-10-28T14:01:51Z",
    "authors": [
      "Masahiro Kato"
    ],
    "pdf_url": "http://arxiv.org/pdf/2510.24433v1"
  },
  {
    "id": "2510.24432v1",
    "title": "Fill in the Blanks: Accelerating Q-Learning with a Handful of\n  Demonstrations in Sparse Reward Settings",
    "abstract": "Reinforcement learning (RL) in sparse-reward environments remains a\nsignificant challenge due to the lack of informative feedback. We propose a\nsimple yet effective method that uses a small number of successful\ndemonstrations to initialize the value function of an RL agent. By precomputing\nvalue estimates from offline demonstrations and using them as targets for early\nlearning, our approach provides the agent with a useful prior over promising\nactions. The agent then refines these estimates through standard online\ninteraction. This hybrid offline-to-online paradigm significantly reduces the\nexploration burden and improves sample efficiency in sparse-reward settings.\nExperiments on benchmark tasks demonstrate that our method accelerates\nconvergence and outperforms standard baselines, even with minimal or suboptimal\ndemonstration data.",
    "categories": [
      "cs.LG"
    ],
    "published": "2025-10-28T14:01:13Z",
    "authors": [
      "Seyed Mahdi Basiri Azad",
      "Joschka Boedecker"
    ],
    "pdf_url": "http://arxiv.org/pdf/2510.24432v1"
  },
  {
    "id": "2510.24422v1",
    "title": "Attack on a PUF-based Secure Binary Neural Network",
    "abstract": "Binarized Neural Networks (BNNs) deployed on memristive crossbar arrays\nprovide energy-efficient solutions for edge computing but are susceptible to\nphysical attacks due to memristor nonvolatility. Recently, Rajendran et al.\n(IEEE Embedded Systems Letter 2025) proposed a Physical Unclonable Function\n(PUF)-based scheme to secure BNNs against theft attacks. Specifically, the\nweight and bias matrices of the BNN layers were secured by swapping columns\nbased on device's PUF key bits.\n  In this paper, we demonstrate that this scheme to secure BNNs is vulnerable\nto PUF-key recovery attack. As a consequence of our attack, we recover the\nsecret weight and bias matrices of the BNN. Our approach is motivated by\ndifferential cryptanalysis and reconstructs the PUF key bit-by-bit by observing\nthe change in model accuracy, and eventually recovering the BNN model\nparameters. Evaluated on a BNN trained on the MNIST dataset, our attack could\nrecover 85% of the PUF key, and recover the BNN model up to 93% classification\naccuracy compared to the original model's 96% accuracy. Our attack is very\nefficient and it takes a couple of minutes to recovery the PUF key and the\nmodel parameters.",
    "categories": [
      "cs.CR",
      "cs.AR",
      "cs.LG"
    ],
    "published": "2025-10-28T13:43:00Z",
    "authors": [
      "Bijeet Basak",
      "Nupur Patil",
      "Kurian Polachan",
      "Srinivas Vivek"
    ],
    "pdf_url": "http://arxiv.org/pdf/2510.24422v1"
  },
  {
    "id": "2510.25784v1",
    "title": "zFLoRA: Zero-Latency Fused Low-Rank Adapters",
    "abstract": "Large language models (LLMs) are increasingly deployed with task-specific\nadapters catering to multiple downstream applications. In such a scenario, the\nadditional compute associated with these apparently insignificant number of\nadapter parameters (typically less than 1% of the base model) turns out to be\ndisproportionately significant during inference time (upto 2.5x times that of\nthe base model). In this paper, we propose a new zero-latency fused low-rank\nadapter (zFLoRA) that introduces zero or negligible latency overhead on top of\nthe base model. Experimental results on LLMs of size 1B, 3B and 7B show that\nzFLoRA compares favorably against the popular supervised fine-tuning benchmarks\nincluding low-rank adapters (LoRA) as well as full fine-tuning (FFT).\nExperiments are conducted on 18 different tasks across three different\ncategories namely commonsense reasoning, math reasoning and summary-dialogue.\nLatency measurements made on NPU (Samsung Galaxy S25+) as well as GPU (NVIDIA\nH100) platforms show that the proposed zFLoRA adapters introduce zero to\nnegligible latency overhead.",
    "categories": [
      "cs.CL",
      "cs.AI",
      "cs.LG"
    ],
    "published": "2025-10-28T13:10:41Z",
    "authors": [
      "Dhananjaya Gowda",
      "Seoha Song",
      "Harshith Goka",
      "Junhyun Lee"
    ],
    "pdf_url": "http://arxiv.org/pdf/2510.25784v1"
  },
  {
    "id": "2510.24380v1",
    "title": "APEX: Approximate-but-exhaustive search for ultra-large combinatorial\n  synthesis libraries",
    "abstract": "Make-on-demand combinatorial synthesis libraries (CSLs) like Enamine REAL\nhave significantly enabled drug discovery efforts. However, their large size\npresents a challenge for virtual screening, where the goal is to identify the\ntop compounds in a library according to a computational objective (e.g.,\noptimizing docking score) subject to computational constraints under a limited\ncomputational budget. For current library sizes -- numbering in the tens of\nbillions of compounds -- and scoring functions of interest, a routine virtual\nscreening campaign may be limited to scoring fewer than 0.1% of the available\ncompounds, leaving potentially many high scoring compounds undiscovered.\nFurthermore, as constraints (and sometimes objectives) change during the course\nof a virtual screening campaign, existing virtual screening algorithms\ntypically offer little room for amortization. We propose the\napproximate-but-exhaustive search protocol for CSLs, or APEX. APEX utilizes a\nneural network surrogate that exploits the structure of CSLs in the prediction\nof objectives and constraints to make full enumeration on a consumer GPU\npossible in under a minute, allowing for exact retrieval of approximate top-$k$\nsets. To demonstrate APEX's capabilities, we develop a benchmark CSL comprised\nof more than 10 million compounds, all of which have been annotated with their\ndocking scores on five medically relevant targets along with physicohemical\nproperties measured with RDKit such that, for any objective and set of\nconstraints, the ground truth top-$k$ compounds can be identified and compared\nagainst the retrievals from any virtual screening algorithm. We show APEX's\nconsistently strong performance both in retrieval accuracy and runtime compared\nto alternative methods.",
    "categories": [
      "cs.LG"
    ],
    "published": "2025-10-28T12:57:59Z",
    "authors": [
      "Aryan Pedawi",
      "Jordi Silvestre-Ryan",
      "Bradley Worley",
      "Darren J Hsu",
      "Kushal S Shah",
      "Elias Stehle",
      "Jingrong Zhang",
      "Izhar Wallach"
    ],
    "pdf_url": "http://arxiv.org/pdf/2510.24380v1"
  },
  {
    "id": "2510.24375v1",
    "title": "A Comprehensive Evaluation Framework for Synthetic Trip Data Generation\n  in Public Transport",
    "abstract": "Synthetic data offers a promising solution to the privacy and accessibility\nchallenges of using smart card data in public transport research. Despite rapid\nprogress in generative modeling, there is limited attention to comprehensive\nevaluation, leaving unclear how reliable, safe, and useful synthetic data truly\nare. Existing evaluations remain fragmented, typically limited to\npopulation-level representativeness or record-level privacy, without\nconsidering group-level variations or task-specific utility. To address this\ngap, we propose a Representativeness-Privacy-Utility (RPU) framework that\nsystematically evaluates synthetic trip data across three complementary\ndimensions and three hierarchical levels (record, group, population). The\nframework integrates a consistent set of metrics to quantify similarity,\ndisclosure risk, and practical usefulness, enabling transparent and balanced\nassessment of synthetic data quality. We apply the framework to benchmark\ntwelve representative generation methods, spanning conventional statistical\nmodels, deep generative networks, and privacy-enhanced variants. Results show\nthat synthetic data do not inherently guarantee privacy and there is no\n\"one-size-fits-all\" model, the trade-off between privacy and\nrepresentativeness/utility is obvious. Conditional Tabular generative\nadversarial network (CTGAN) provide the most balanced trade-off and is\nsuggested for practical applications. The RPU framework provides a systematic\nand reproducible basis for researchers and practitioners to compare synthetic\ndata generation techniques and select appropriate methods in public transport\napplications.",
    "categories": [
      "cs.LG"
    ],
    "published": "2025-10-28T12:52:47Z",
    "authors": [
      "Yuanyuan Wu",
      "Zhenlin Qin",
      "Zhenliang Ma"
    ],
    "pdf_url": "http://arxiv.org/pdf/2510.24375v1"
  },
  {
    "id": "2510.24368v1",
    "title": "Filtering instances and rejecting predictions to obtain reliable models\n  in healthcare",
    "abstract": "Machine Learning (ML) models are widely used in high-stakes domains such as\nhealthcare, where the reliability of predictions is critical. However, these\nmodels often fail to account for uncertainty, providing predictions even with\nlow confidence. This work proposes a novel two-step data-centric approach to\nenhance the performance of ML models by improving data quality and filtering\nlow-confidence predictions. The first step involves leveraging Instance\nHardness (IH) to filter problematic instances during training, thereby refining\nthe dataset. The second step introduces a confidence-based rejection mechanism\nduring inference, ensuring that only reliable predictions are retained. We\nevaluate our approach using three real-world healthcare datasets, demonstrating\nits effectiveness at improving model reliability while balancing predictive\nperformance and rejection rate. Additionally, we use alternative criteria -\ninfluence values for filtering and uncertainty for rejection - as baselines to\nevaluate the efficiency of the proposed method. The results demonstrate that\nintegrating IH filtering with confidence-based rejection effectively enhances\nmodel performance while preserving a large proportion of instances. This\napproach provides a practical method for deploying ML systems in\nsafety-critical applications.",
    "categories": [
      "cs.LG"
    ],
    "published": "2025-10-28T12:45:20Z",
    "authors": [
      "Maria Gabriela Valeriano",
      "David Kohan Marzag\u00e3o",
      "Alfredo Montelongo",
      "Carlos Roberto Veiga Kiffer",
      "Natan Katz",
      "Ana Carolina Lorena"
    ],
    "pdf_url": "http://arxiv.org/pdf/2510.24368v1"
  },
  {
    "id": "2510.24356v1",
    "title": "Perception Learning: A Formal Separation of Sensory Representation\n  Learning from Decision Learning",
    "abstract": "We introduce Perception Learning (PeL), a paradigm that optimizes an agent's\nsensory interface $f_\\phi:\\mathcal{X}\\to\\mathcal{Z}$ using task-agnostic\nsignals, decoupled from downstream decision learning\n$g_\\theta:\\mathcal{Z}\\to\\mathcal{Y}$. PeL directly targets label-free\nperceptual properties, such as stability to nuisances, informativeness without\ncollapse, and controlled geometry, assessed via objective\nrepresentation-invariant metrics. We formalize the separation of perception and\ndecision, define perceptual properties independent of objectives or\nreparameterizations, and prove that PeL updates preserving sufficient\ninvariants are orthogonal to Bayes task-risk gradients. Additionally, we\nprovide a suite of task-agnostic evaluation metrics to certify perceptual\nquality.",
    "categories": [
      "cs.LG",
      "cs.AI",
      "stat.ML"
    ],
    "published": "2025-10-28T12:19:49Z",
    "authors": [
      "Suman Sanyal"
    ],
    "pdf_url": "http://arxiv.org/pdf/2510.24356v1"
  },
  {
    "id": "2510.24331v1",
    "title": "What do vision-language models see in the context? Investigating\n  multimodal in-context learning",
    "abstract": "In-context learning (ICL) enables Large Language Models (LLMs) to learn tasks\nfrom demonstration examples without parameter updates. Although it has been\nextensively studied in LLMs, its effectiveness in Vision-Language Models (VLMs)\nremains underexplored. In this work, we present a systematic study of ICL in\nVLMs, evaluating seven models spanning four architectures on three image\ncaptioning benchmarks. We analyze how prompt design, architectural choices, and\ntraining strategies influence multimodal ICL. To our knowledge, we are the\nfirst to analyze how attention patterns in VLMs vary with an increasing number\nof in-context demonstrations. Our results reveal that training on imag-text\ninterleaved data enhances ICL performance but does not imply effective\nintegration of visual and textual information from demonstration examples. In\ncontrast, instruction tuning improves instruction-following but can reduce\nreliance on in-context demonstrations, suggesting a trade-off between\ninstruction alignment and in-context adaptation. Attention analyses further\nshow that current VLMs primarily focus on textual cues and fail to leverage\nvisual information, suggesting a limited capacity for multimodal integration.\nThese findings highlight key limitations in the ICL abilities of current VLMs\nand provide insights for enhancing their ability to learn from multimodal\nin-context examples.",
    "categories": [
      "cs.LG",
      "cs.CV"
    ],
    "published": "2025-10-28T11:55:24Z",
    "authors": [
      "Gabriel O. dos Santos",
      "Esther Colombini",
      "Sandra Avila"
    ],
    "pdf_url": "http://arxiv.org/pdf/2510.24331v1"
  },
  {
    "id": "2510.24318v1",
    "title": "Transformers can do Bayesian Clustering",
    "abstract": "Bayesian clustering accounts for uncertainty but is computationally demanding\nat scale. Furthermore, real-world datasets often contain missing values, and\nsimple imputation ignores the associated uncertainty, resulting in suboptimal\nresults. We present Cluster-PFN, a Transformer-based model that extends\nPrior-Data Fitted Networks (PFNs) to unsupervised Bayesian clustering. Trained\nentirely on synthetic datasets generated from a finite Gaussian Mixture Model\n(GMM) prior, Cluster-PFN learns to estimate the posterior distribution over\nboth the number of clusters and the cluster assignments. Our method estimates\nthe number of clusters more accurately than handcrafted model selection\nprocedures such as AIC, BIC and Variational Inference (VI), and achieves\nclustering quality competitive with VI while being orders of magnitude faster.\nCluster-PFN can be trained on complex priors that include missing data,\noutperforming imputation-based baselines on real-world genomic datasets, at\nhigh missingness. These results show that the Cluster-PFN can provide scalable\nand flexible Bayesian clustering.",
    "categories": [
      "cs.LG",
      "cs.AI"
    ],
    "published": "2025-10-28T11:36:31Z",
    "authors": [
      "Prajit Bhaskaran",
      "Tom Viering"
    ],
    "pdf_url": "http://arxiv.org/pdf/2510.24318v1"
  },
  {
    "id": "2510.24310v1",
    "title": "EDC: Equation Discovery for Classification",
    "abstract": "Equation Discovery techniques have shown considerable success in regression\ntasks, where they are used to discover concise and interpretable models\n(\\textit{Symbolic Regression}). In this paper, we propose a new ED-based binary\nclassification framework. Our proposed method EDC finds analytical functions of\nmanageable size that specify the location and shape of the decision boundary.\nIn extensive experiments on artificial and real-life data, we demonstrate how\nEDC is able to discover both the structure of the target equation as well as\nthe value of its parameters, outperforming the current state-of-the-art\nED-based classification methods in binary classification and achieving\nperformance comparable to the state of the art in binary classification. We\nsuggest a grammar of modest complexity that appears to work well on the tested\ndatasets but argue that the exact grammar -- and thus the complexity of the\nmodels -- is configurable, and especially domain-specific expressions can be\nincluded in the pattern language, where that is required. The presented grammar\nconsists of a series of summands (additive terms) that include linear,\nquadratic and exponential terms, as well as products of two features (producing\nhyperbolic curves ideal for capturing XOR-like dependencies). The experiments\ndemonstrate that this grammar allows fairly flexible decision boundaries while\nnot so rich to cause overfitting.",
    "categories": [
      "cs.LG"
    ],
    "published": "2025-10-28T11:20:06Z",
    "authors": [
      "Guus Toussaint",
      "Arno Knobbe"
    ],
    "pdf_url": "http://arxiv.org/pdf/2510.24310v1"
  },
  {
    "id": "2510.24288v1",
    "title": "Problem-Parameter-Free Decentralized Bilevel Optimization",
    "abstract": "Decentralized bilevel optimization has garnered significant attention due to\nits critical role in solving large-scale machine learning problems. However,\nexisting methods often rely on prior knowledge of problem parameters-such as\nsmoothness, convexity, or communication network topologies-to determine\nappropriate stepsizes. In practice, these problem parameters are typically\nunavailable, leading to substantial manual effort for hyperparameter tuning. In\nthis paper, we propose AdaSDBO, a fully problem-parameter-free algorithm for\ndecentralized bilevel optimization with a single-loop structure. AdaSDBO\nleverages adaptive stepsizes based on cumulative gradient norms to update all\nvariables simultaneously, dynamically adjusting its progress and eliminating\nthe need for problem-specific hyperparameter tuning. Through rigorous\ntheoretical analysis, we establish that AdaSDBO achieves a convergence rate of\n$\\widetilde{\\mathcal{O}}\\left(\\frac{1}{T}\\right)$, matching the performance of\nwell-tuned state-of-the-art methods up to polylogarithmic factors. Extensive\nnumerical experiments demonstrate that AdaSDBO delivers competitive performance\ncompared to existing decentralized bilevel optimization methods while\nexhibiting remarkable robustness across diverse stepsize configurations.",
    "categories": [
      "math.OC",
      "cs.LG",
      "stat.ML"
    ],
    "published": "2025-10-28T10:50:04Z",
    "authors": [
      "Zhiwei Zhai",
      "Wenjing Yan",
      "Ying-Jun Angela Zhang"
    ],
    "pdf_url": "http://arxiv.org/pdf/2510.24288v1"
  },
  {
    "id": "2510.24287v1",
    "title": "Towards actionable hypotension prediction -- predicting catecholamine\n  therapy initiation in the intensive care unit",
    "abstract": "Hypotension in critically ill ICU patients is common and life-threatening.\nEscalation to catecholamine therapy marks a key management step, with both\nundertreatment and overtreatment posing risks. Most machine learning (ML)\nmodels predict hypotension using fixed MAP thresholds or MAP forecasting,\noverlooking the clinical decision behind treatment escalation. Predicting\ncatecholamine initiation, the start of vasoactive or inotropic agent\nadministration offers a more clinically actionable target reflecting real\ndecision-making. Using the MIMIC-III database, we modeled catecholamine\ninitiation as a binary event within a 15-minute prediction window. Input\nfeatures included statistical descriptors from a two-hour sliding MAP context\nwindow, along with demographics, biometrics, comorbidities, and ongoing\ntreatments. An Extreme Gradient Boosting (XGBoost) model was trained and\ninterpreted via SHapley Additive exPlanations (SHAP). The model achieved an\nAUROC of 0.822 (0.813-0.830), outperforming the hypotension baseline (MAP < 65,\nAUROC 0.686 [0.675-0.699]). SHAP analysis highlighted recent MAP values, MAP\ntrends, and ongoing treatments (e.g., sedatives, electrolytes) as dominant\npredictors. Subgroup analysis showed higher performance in males, younger\npatients (<53 years), those with higher BMI (>32), and patients without\ncomorbidities or concurrent medications. Predicting catecholamine initiation\nbased on MAP dynamics, treatment context, and patient characteristics supports\nthe critical decision of when to escalate therapy, shifting focus from\nthreshold-based alarms to actionable decision support. This approach is\nfeasible across a broad ICU cohort under natural event imbalance. Future work\nshould enrich temporal and physiological context, extend label definitions to\ninclude therapy escalation, and benchmark against existing hypotension\nprediction systems.",
    "categories": [
      "eess.SP",
      "cs.LG"
    ],
    "published": "2025-10-28T10:49:42Z",
    "authors": [
      "Richard Koebe",
      "Noah Saibel",
      "Juan Miguel Lopez Alcaraz",
      "Simon Sch\u00e4fer",
      "Nils Strodthoff"
    ],
    "pdf_url": "http://arxiv.org/pdf/2510.24287v1"
  },
  {
    "id": "2510.24279v1",
    "title": "HergNet: a Fast Neural Surrogate Model for Sound Field Predictions via\n  Superposition of Plane Waves",
    "abstract": "We present a novel neural network architecture for the efficient prediction\nof sound fields in two and three dimensions. The network is designed to\nautomatically satisfy the Helmholtz equation, ensuring that the outputs are\nphysically valid. Therefore, the method can effectively learn solutions to\nboundary-value problems in various wave phenomena, such as acoustics, optics,\nand electromagnetism. Numerical experiments show that the proposed strategy can\npotentially outperform state-of-the-art methods in room acoustics simulation,\nin particular in the range of mid to high frequencies.",
    "categories": [
      "cs.SD",
      "cs.CE",
      "cs.LG",
      "eess.AS"
    ],
    "published": "2025-10-28T10:39:10Z",
    "authors": [
      "Matteo Calaf\u00e0",
      "Yuanxin Xia",
      "Cheol-Ho Jeong"
    ],
    "pdf_url": "http://arxiv.org/pdf/2510.24279v1"
  },
  {
    "id": "2510.24273v1",
    "title": "SALS: Sparse Attention in Latent Space for KV cache Compression",
    "abstract": "Large Language Models capable of handling extended contexts are in high\ndemand, yet their inference remains challenging due to substantial Key-Value\ncache size and high memory bandwidth requirements. Previous research has\ndemonstrated that KV cache exhibits low-rank characteristics within the hidden\ndimension, suggesting the potential for effective compression. However, due to\nthe widely adopted Rotary Position Embedding mechanism in modern LLMs, naive\nlow-rank compression suffers severe accuracy degradation or creates a new speed\nbottleneck, as the low-rank cache must first be reconstructed in order to apply\nRoPE. In this paper, we introduce two key insights: first, the application of\nRoPE to the key vectors increases their variance, which in turn results in a\nhigher rank; second, after the key vectors are transformed into the latent\nspace, they largely maintain their representation across most layers. Based on\nthese insights, we propose the Sparse Attention in Latent Space framework. SALS\nprojects the KV cache into a compact latent space via low-rank projection, and\nperforms sparse token selection using RoPE-free query-key interactions in this\nspace. By reconstructing only a small subset of important tokens, it avoids the\noverhead of full KV cache reconstruction. We comprehensively evaluate SALS on\nvarious tasks using two large-scale models: LLaMA2-7b-chat and Mistral-7b, and\nadditionally verify its scalability on the RULER-128k benchmark with\nLLaMA3.1-8B-Instruct. Experimental results demonstrate that SALS achieves SOTA\nperformance by maintaining competitive accuracy. Under different settings, SALS\nachieves 6.4-fold KV cache compression and 5.7-fold speed-up in the attention\noperator compared to FlashAttention2 on the 4K sequence. For the end-to-end\nthroughput performance, we achieves 1.4-fold and 4.5-fold improvement compared\nto GPT-fast on 4k and 32K sequences, respectively.",
    "categories": [
      "cs.LG"
    ],
    "published": "2025-10-28T10:32:52Z",
    "authors": [
      "Junlin Mu",
      "Hantao Huang",
      "Jihang Zhang",
      "Minghui Yu",
      "Tao Wang",
      "Yidong Li"
    ],
    "pdf_url": "http://arxiv.org/pdf/2510.24273v1"
  },
  {
    "id": "2510.24262v1",
    "title": "UtilGen: Utility-Centric Generative Data Augmentation with Dual-Level\n  Task Adaptation",
    "abstract": "Data augmentation using generative models has emerged as a powerful paradigm\nfor enhancing performance in computer vision tasks. However, most existing\naugmentation approaches primarily focus on optimizing intrinsic data attributes\n-- such as fidelity and diversity -- to generate visually high-quality\nsynthetic data, while often neglecting task-specific requirements. Yet, it is\nessential for data generators to account for the needs of downstream tasks, as\ntraining data requirements can vary significantly across different tasks and\nnetwork architectures. To address these limitations, we propose UtilGen, a\nnovel utility-centric data augmentation framework that adaptively optimizes the\ndata generation process to produce task-specific, high-utility training data\nvia downstream task feedback. Specifically, we first introduce a weight\nallocation network to evaluate the task-specific utility of each synthetic\nsample. Guided by these evaluations, UtilGen iteratively refines the data\ngeneration process using a dual-level optimization strategy to maximize the\nsynthetic data utility: (1) model-level optimization tailors the generative\nmodel to the downstream task, and (2) instance-level optimization adjusts\ngeneration policies -- such as prompt embeddings and initial noise -- at each\ngeneration round. Extensive experiments on eight benchmark datasets of varying\ncomplexity and granularity demonstrate that UtilGen consistently achieves\nsuperior performance, with an average accuracy improvement of 3.87% over\nprevious SOTA. Further analysis of data influence and distribution reveals that\nUtilGen produces more impactful and task-relevant synthetic data, validating\nthe effectiveness of the paradigm shift from visual characteristics-centric to\ntask utility-centric data augmentation.",
    "categories": [
      "cs.CV",
      "cs.LG"
    ],
    "published": "2025-10-28T10:17:11Z",
    "authors": [
      "Jiyu Guo",
      "Shuo Yang",
      "Yiming Huang",
      "Yancheng Long",
      "Xiaobo Xia",
      "Xiu Su",
      "Bo Zhao",
      "Zeke Xie",
      "Liqiang Nie"
    ],
    "pdf_url": "http://arxiv.org/pdf/2510.24262v1"
  },
  {
    "id": "2510.24256v1",
    "title": "From Memorization to Reasoning in the Spectrum of Loss Curvature",
    "abstract": "We characterize how memorization is represented in transformer models and\nshow that it can be disentangled in the weights of both language models (LMs)\nand vision transformers (ViTs) using a decomposition based on the loss\nlandscape curvature. This insight is based on prior theoretical and empirical\nwork showing that the curvature for memorized training points is much sharper\nthan non memorized, meaning ordering weight components from high to low\ncurvature can reveal a distinction without explicit labels. This motivates a\nweight editing procedure that suppresses far more recitation of untargeted\nmemorized data more effectively than a recent unlearning method\n(BalancedSubnet), while maintaining lower perplexity. Since the basis of\ncurvature has a natural interpretation for shared structure in model weights,\nwe analyze the editing procedure extensively on its effect on downstream tasks\nin LMs, and find that fact retrieval and arithmetic are specifically and\nconsistently negatively affected, even though open book fact retrieval and\ngeneral logical reasoning is conserved. We posit these tasks rely heavily on\nspecialized directions in weight space rather than general purpose mechanisms,\nregardless of whether those individual datapoints are memorized. We support\nthis by showing a correspondence between task data's activation strength with\nlow curvature components that we edit out, and the drop in task performance\nafter the edit. Our work enhances the understanding of memorization in neural\nnetworks with practical applications towards removing it, and provides evidence\nfor idiosyncratic, narrowly-used structures involved in solving tasks like math\nand fact retrieval.",
    "categories": [
      "cs.CL",
      "cs.LG"
    ],
    "published": "2025-10-28T10:09:35Z",
    "authors": [
      "Jack Merullo",
      "Srihita Vatsavaya",
      "Lucius Bushnaq",
      "Owen Lewis"
    ],
    "pdf_url": "http://arxiv.org/pdf/2510.24256v1"
  },
  {
    "id": "2510.24817v2",
    "title": "Towards a Method for Synthetic Generation of Persons with Aphasia\n  Transcripts",
    "abstract": "In aphasia research, Speech-Language Pathologists (SLPs) devote extensive\ntime to manually coding speech samples using Correct Information Units (CIUs),\na measure of how informative an individual sample of speech is. Developing\nautomated systems to recognize aphasic language is limited by data scarcity.\nFor example, only about 600 transcripts are available in AphasiaBank yet\nbillions of tokens are used to train large language models (LLMs). In the\nbroader field of machine learning (ML), researchers increasingly turn to\nsynthetic data when such are sparse. Therefore, this study constructs and\nvalidates two methods to generate synthetic transcripts of the AphasiaBank Cat\nRescue picture description task. One method leverages a procedural programming\napproach while the second uses Mistral 7b Instruct and Llama 3.1 8b Instruct\nLLMs. The methods generate transcripts across four severity levels (Mild,\nModerate, Severe, Very Severe) through word dropping, filler insertion, and\nparaphasia substitution. Overall, we found, compared to human-elicited\ntranscripts, Mistral 7b Instruct best captures key aspects of linguistic\ndegradation observed in aphasia, showing realistic directional changes in NDW,\nword count, and word length amongst the synthetic generation methods. Based on\nthe results, future work should plan to create a larger dataset, fine-tune\nmodels for better aphasic representation, and have SLPs assess the realism and\nusefulness of the synthetic transcripts.",
    "categories": [
      "cs.CL",
      "cs.AI",
      "cs.LG"
    ],
    "published": "2025-10-28T10:06:49Z",
    "authors": [
      "Jason M. Pittman",
      "Anton Phillips Jr.",
      "Yesenia Medina-Santos",
      "Brielle C. Stark"
    ],
    "pdf_url": "http://arxiv.org/pdf/2510.24817v2"
  },
  {
    "id": "2510.24254v1",
    "title": "Forecasting precipitation in the Arctic using probabilistic machine\n  learning informed by causal climate drivers",
    "abstract": "Understanding and forecasting precipitation events in the Arctic maritime\nenvironments, such as Bear Island and Ny-{\\AA}lesund, is crucial for assessing\nclimate risk and developing early warning systems in vulnerable marine regions.\nThis study proposes a probabilistic machine learning framework for modeling and\npredicting the dynamics and severity of precipitation. We begin by analyzing\nthe scale-dependent relationships between precipitation and key atmospheric\ndrivers (e.g., temperature, relative humidity, cloud cover, and air pressure)\nusing wavelet coherence, which captures localized dependencies across time and\nfrequency domains. To assess joint causal influences, we employ\nSynergistic-Unique-Redundant Decomposition, which quantifies the impact of\ninteraction effects among each variable on future precipitation dynamics. These\ninsights inform the development of data-driven forecasting models that\nincorporate both historical precipitation and causal climate drivers. To\naccount for uncertainty, we employ the conformal prediction method, which\nenables the generation of calibrated non-parametric prediction intervals. Our\nresults underscore the importance of utilizing a comprehensive framework that\ncombines causal analysis with probabilistic forecasting to enhance the\nreliability and interpretability of precipitation predictions in Arctic marine\nenvironments.",
    "categories": [
      "physics.ao-ph",
      "cs.LG",
      "physics.data-an"
    ],
    "published": "2025-10-28T10:05:34Z",
    "authors": [
      "Madhurima Panja",
      "Dhiman Das",
      "Tanujit Chakraborty",
      "Arnob Ray",
      "R. Athulya",
      "Chittaranjan Hens",
      "Syamal K. Dana",
      "Nuncio Murukesh",
      "Dibakar Ghosh"
    ],
    "pdf_url": "http://arxiv.org/pdf/2510.24254v1"
  },
  {
    "id": "2510.24815v1",
    "title": "Tree Ensemble Explainability through the Hoeffding Functional\n  Decomposition and TreeHFD Algorithm",
    "abstract": "Tree ensembles have demonstrated state-of-the-art predictive performance\nacross a wide range of problems involving tabular data. Nevertheless, the\nblack-box nature of tree ensembles is a strong limitation, especially for\napplications with critical decisions at stake. The Hoeffding or ANOVA\nfunctional decomposition is a powerful explainability method, as it breaks down\nblack-box models into a unique sum of lower-dimensional functions, provided\nthat input variables are independent. In standard learning settings, input\nvariables are often dependent, and the Hoeffding decomposition is generalized\nthrough hierarchical orthogonality constraints. Such generalization leads to\nunique and sparse decompositions with well-defined main effects and\ninteractions. However, the practical estimation of this decomposition from a\ndata sample is still an open problem. Therefore, we introduce the TreeHFD\nalgorithm to estimate the Hoeffding decomposition of a tree ensemble from a\ndata sample. We show the convergence of TreeHFD, along with the main properties\nof orthogonality, sparsity, and causal variable selection. The high performance\nof TreeHFD is demonstrated through experiments on both simulated and real data,\nusing our treehfd Python package (https://github.com/ThalesGroup/treehfd).\nBesides, we empirically show that the widely used TreeSHAP method, based on\nShapley values, is strongly connected to the Hoeffding decomposition.",
    "categories": [
      "stat.ML",
      "cs.LG"
    ],
    "published": "2025-10-28T09:49:01Z",
    "authors": [
      "Cl\u00e9ment B\u00e9nard"
    ],
    "pdf_url": "http://arxiv.org/pdf/2510.24815v1"
  },
  {
    "id": "2510.24242v1",
    "title": "Enabling Near-realtime Remote Sensing via Satellite-Ground Collaboration\n  of Large Vision-Language Models",
    "abstract": "Large vision-language models (LVLMs) have recently demonstrated great\npotential in remote sensing (RS) tasks (e.g., disaster monitoring) conducted by\nlow Earth orbit (LEO) satellites. However, their deployment in real-world LEO\nsatellite systems remains largely unexplored, hindered by limited onboard\ncomputing resources and brief satellite-ground contacts. We propose Grace, a\nsatellite-ground collaborative system designed for near-realtime LVLM inference\nin RS tasks. Accordingly, we deploy compact LVLM on satellites for realtime\ninference, but larger ones on ground stations (GSs) to guarantee end-to-end\nperformance. Grace is comprised of two main phases that are asynchronous\nsatellite-GS Retrieval-Augmented Generation (RAG), and a task dispatch\nalgorithm. Firstly, we still the knowledge archive of GS RAG to satellite\narchive with tailored adaptive update algorithm during limited satellite-ground\ndata exchange period. Secondly, propose a confidence-based test algorithm that\neither processes the task onboard the satellite or offloads it to the GS.\nExtensive experiments based on real-world satellite orbital data show that\nGrace reduces the average latency by 76-95% compared to state-of-the-art\nmethods, without compromising inference accuracy.",
    "categories": [
      "cs.NI",
      "cs.AI",
      "cs.LG"
    ],
    "published": "2025-10-28T09:48:26Z",
    "authors": [
      "Zihan Li",
      "Jiahao Yang",
      "Yuxin Zhang",
      "Zhe Chen",
      "Yue Gao"
    ],
    "pdf_url": "http://arxiv.org/pdf/2510.24242v1"
  },
  {
    "id": "2510.24240v1",
    "title": "Temporal Knowledge Graph Hyperedge Forecasting: Exploring\n  Entity-to-Category Link Prediction",
    "abstract": "Temporal Knowledge Graphs have emerged as a powerful way of not only modeling\nstatic relationships between entities but also the dynamics of how relations\nevolve over time. As these informational structures can be used to store\ninformation from a real-world setting, such as a news flow, predicting future\ngraph components to a certain extent equates predicting real-world events. Most\nof the research in this field focuses on embedding-based methods, often\nleveraging convolutional neural net architectures. These solutions act as black\nboxes, limiting insight. In this paper, we explore an extension to an\nestablished rule-based framework, TLogic, that yields a high accuracy in\ncombination with explainable predictions. This offers transparency and allows\nthe end-user to critically evaluate the rules applied at the end of the\nprediction stage. The new rule format incorporates entity category as a key\ncomponent with the purpose of limiting rule application only to relevant\nentities. When categories are unknown for building the graph, we propose a\ndata-driven method to generate them with an LLM-based approach. Additionally,\nwe investigate the choice of aggregation method for scores of retrieved\nentities when performing category prediction.",
    "categories": [
      "cs.LG"
    ],
    "published": "2025-10-28T09:47:38Z",
    "authors": [
      "Edward Markai",
      "Sina Molavipour"
    ],
    "pdf_url": "http://arxiv.org/pdf/2510.24240v1"
  },
  {
    "id": "2510.24235v1",
    "title": "PaTaRM: Bridging Pairwise and Pointwise Signals via Preference-Aware\n  Task-Adaptive Reward Modeling",
    "abstract": "Reward models (RMs) are central to reinforcement learning from human feedback\n(RLHF), providing the critical supervision signals that align large language\nmodels (LLMs) with human preferences. While generative reward models (GRMs)\noffer greater interpretability than traditional scalar RMs, current training\nparadigms remain limited. Pair-wise methods rely on binary good-versus-bad\nlabels, which cause mismatches for point-wise inference and necessitate complex\npairing strategies for effective application in RLHF. On the other hand,\npoint-wise methods require more elaborate absolute labeling with rubric-driven\ncriteria, resulting in poor adaptability and high annotation costs. In this\nwork, we propose the Preference-Aware Task-Adaptive Reward Model (PaTaRM), a\nunified framework that integrates a preference-aware reward (PAR) mechanism\nwith dynamic rubric adaptation. PaTaRM leverages relative preference\ninformation from pairwise data to construct robust point-wise training signals,\neliminating the need for explicit point-wise labels. Simultaneously, it employs\na task-adaptive rubric system that flexibly generates evaluation criteria for\nboth global task consistency and instance-specific fine-grained reasoning. This\ndesign enables efficient, generalizable, and interpretable reward modeling for\nRLHF. Extensive experiments show that PaTaRM achieves an average relative\nimprovement of 4.7% on RewardBench and RMBench across Qwen3-8B and Qwen3-14B\nmodels. Furthermore, PaTaRM boosts downstream RLHF performance, with an average\nimprovement of 13.6% across IFEval and InFoBench benchmarks, confirming its\neffectiveness and robustness. Our code is available at\nhttps://github.com/JaneEyre0530/PaTaRM.",
    "categories": [
      "cs.LG",
      "cs.AI"
    ],
    "published": "2025-10-28T09:43:47Z",
    "authors": [
      "Ai Jian",
      "Jingqing Ruan",
      "Xing Ma",
      "Dailin Li",
      "QianLin Zhou",
      "Ke Zeng",
      "Xunliang Cai"
    ],
    "pdf_url": "http://arxiv.org/pdf/2510.24235v1"
  },
  {
    "id": "2510.24234v1",
    "title": "Sparse Optimistic Information Directed Sampling",
    "abstract": "Many high-dimensional online decision-making problems can be modeled as\nstochastic sparse linear bandits. Most existing algorithms are designed to\nachieve optimal worst-case regret in either the data-rich regime, where\npolynomial dependence on the ambient dimension is unavoidable, or the data-poor\nregime, where dimension-independence is possible at the cost of worse\ndependence on the number of rounds. In contrast, the sparse Information\nDirected Sampling (IDS) algorithm satisfies a Bayesian regret bound that has\nthe optimal rate in both regimes simultaneously. In this work, we explore the\nuse of Sparse Optimistic Information Directed Sampling (SOIDS) to achieve the\nsame adaptivity in the worst-case setting, without Bayesian assumptions.\nThrough a novel analysis that enables the use of a time-dependent learning\nrate, we show that SOIDS can optimally balance information and regret. Our\nresults extend the theoretical guarantees of IDS, providing the first algorithm\nthat simultaneously achieves optimal worst-case regret in both the data-rich\nand data-poor regimes. We empirically demonstrate the good performance of\nSOIDS.",
    "categories": [
      "cs.LG"
    ],
    "published": "2025-10-28T09:42:15Z",
    "authors": [
      "Ludovic Schwartz",
      "Hamish Flynn",
      "Gergely Neu"
    ],
    "pdf_url": "http://arxiv.org/pdf/2510.24234v1"
  },
  {
    "id": "2510.24233v1",
    "title": "PRIVET: Privacy Metric Based on Extreme Value Theory",
    "abstract": "Deep generative models are often trained on sensitive data, such as genetic\nsequences, health data, or more broadly, any copyrighted, licensed or protected\ncontent. This raises critical concerns around privacy-preserving synthetic\ndata, and more specifically around privacy leakage, an issue closely tied to\noverfitting. Existing methods almost exclusively rely on global criteria to\nestimate the risk of privacy failure associated to a model, offering only\nquantitative non interpretable insights. The absence of rigorous evaluation\nmethods for data privacy at the sample-level may hinder the practical\ndeployment of synthetic data in real-world applications. Using extreme value\nstatistics on nearest-neighbor distances, we propose PRIVET, a generic\nsample-based, modality-agnostic algorithm that assigns an individual privacy\nleak score to each synthetic sample. We empirically demonstrate that PRIVET\nreliably detects instances of memorization and privacy leakage across diverse\ndata modalities, including settings with very high dimensionality, limited\nsample sizes such as genetic data and even under underfitting regimes. We\ncompare our method to existing approaches under controlled settings and show\nits advantage in providing both dataset level and sample level assessments\nthrough qualitative and quantitative outputs. Additionally, our analysis\nreveals limitations in existing computer vision embeddings to yield\nperceptually meaningful distances when identifying near-duplicate samples.",
    "categories": [
      "cs.LG"
    ],
    "published": "2025-10-28T09:42:03Z",
    "authors": [
      "Antoine Szatkownik",
      "Aur\u00e9lien Decelle",
      "Beatriz Seoane",
      "Nicolas Bereux",
      "L\u00e9o Planche",
      "Guillaume Charpiat",
      "Burak Yelmen",
      "Flora Jay",
      "Cyril Furtlehner"
    ],
    "pdf_url": "http://arxiv.org/pdf/2510.24233v1"
  },
  {
    "id": "2510.24228v1",
    "title": "A comparison between joint and dual UKF implementations for state\n  estimation and leak localization in water distribution networks",
    "abstract": "The sustainability of modern cities highly depends on efficient water\ndistribution management, including effective pressure control and leak\ndetection and localization. Accurate information about the network hydraulic\nstate is therefore essential. This article presents a comparison between two\ndata-driven state estimation methods based on the Unscented Kalman Filter\n(UKF), fusing pressure, demand and flow data for head and flow estimation. One\napproach uses a joint state vector with a single estimator, while the other\nuses a dual-estimator scheme. We analyse their main characteristics, discussing\ndifferences, advantages and limitations, and compare them theoretically in\nterms of accuracy and complexity. Finally, we show several estimation results\nfor the L-TOWN benchmark, allowing to discuss their properties in a real\nimplementation.",
    "categories": [
      "eess.SY",
      "cs.LG",
      "cs.NA",
      "cs.SY",
      "math.NA"
    ],
    "published": "2025-10-28T09:39:41Z",
    "authors": [
      "Luis Romero-Ben",
      "Paul Irofti",
      "Florin Stoican",
      "Vicen\u00e7 Puig"
    ],
    "pdf_url": "http://arxiv.org/pdf/2510.24228v1"
  },
  {
    "id": "2510.24217v1",
    "title": "Closing Gaps: An Imputation Analysis of ICU Vital Signs",
    "abstract": "As more Intensive Care Unit (ICU) data becomes available, the interest in\ndeveloping clinical prediction models to improve healthcare protocols\nincreases. However, the lack of data quality still hinders clinical prediction\nusing Machine Learning (ML). Many vital sign measurements, such as heart rate,\ncontain sizeable missing segments, leaving gaps in the data that could\nnegatively impact prediction performance. Previous works have introduced\nnumerous time-series imputation techniques. Nevertheless, more comprehensive\nwork is needed to compare a representative set of methods for imputing ICU\nvital signs and determine the best practice. In reality, ad-hoc imputation\ntechniques that could decrease prediction accuracy, like zero imputation, are\nstill used. In this work, we compare established imputation techniques to guide\nresearchers in improving the performance of clinical prediction models by\nselecting the most accurate imputation technique. We introduce an extensible\nand reusable benchmark with currently 15 imputation and 4 amputation methods,\ncreated for benchmarking on major ICU datasets. We hope to provide a\ncomparative basis and facilitate further ML development to bring more models\ninto clinical practice.",
    "categories": [
      "cs.LG",
      "cs.AI"
    ],
    "published": "2025-10-28T09:30:52Z",
    "authors": [
      "Alisher Turubayev",
      "Anna Shopova",
      "Fabian Lange",
      "Mahmut Kamalak",
      "Paul Mattes",
      "Victoria Ayvasky",
      "Bert Arnrich",
      "Bjarne Pfitzner",
      "Robin P. van de Water"
    ],
    "pdf_url": "http://arxiv.org/pdf/2510.24217v1"
  },
  {
    "id": "2510.24216v1",
    "title": "Unlocking Out-of-Distribution Generalization in Dynamics through\n  Physics-Guided Augmentation",
    "abstract": "In dynamical system modeling, traditional numerical methods are limited by\nhigh computational costs, while modern data-driven approaches struggle with\ndata scarcity and distribution shifts. To address these fundamental\nlimitations, we first propose SPARK, a physics-guided quantitative augmentation\nplugin. Specifically, SPARK utilizes a reconstruction autoencoder to integrate\nphysical parameters into a physics-rich discrete state dictionary. This state\ndictionary then acts as a structured dictionary of physical states, enabling\nthe creation of new, physically-plausible training samples via principled\ninterpolation in the latent space. Further, for downstream prediction, these\naugmented representations are seamlessly integrated with a Fourier-enhanced\nGraph ODE, a combination designed to robustly model the enriched data\ndistribution while capturing long-term temporal dependencies. Extensive\nexperiments on diverse benchmarks demonstrate that SPARK significantly\noutperforms state-of-the-art baselines, particularly in challenging\nout-of-distribution scenarios and data-scarce regimes, proving the efficacy of\nour physics-guided augmentation paradigm.",
    "categories": [
      "cs.LG"
    ],
    "published": "2025-10-28T09:30:35Z",
    "authors": [
      "Fan Xu",
      "Hao Wu",
      "Kun Wang",
      "Nan Wang",
      "Qingsong Wen",
      "Xian Wu",
      "Wei Gong",
      "Xibin Zhao"
    ],
    "pdf_url": "http://arxiv.org/pdf/2510.24216v1"
  },
  {
    "id": "2510.24215v1",
    "title": "What Can Be Recovered Under Sparse Adversarial Corruption?\n  Assumption-Free Theory for Linear Measurements",
    "abstract": "Let $\\mathbf{A} \\in \\mathbb{R}^{m \\times n}$ be an arbitrary, known matrix\nand $\\mathbf{e}$ a $q$-sparse adversarial vector. Given $\\mathbf{y} =\n\\mathbf{A} x^* + \\mathbf{e}$ and $q$, we seek the smallest set containing\n$x^*$-hence the one conveying maximal information about $x^*$-that is uniformly\nrecoverable from $\\mathbf{y}$ without knowing $\\mathbf{e}$. While exact\nrecovery of $x^*$ via strong (and often impractical) structural assumptions on\n$\\mathbf{A}$ or $x^*$ (for example, restricted isometry, sparsity) is well\nstudied, recoverability for arbitrary $\\mathbf{A}$ and $x^*$ remains open. Our\nmain result shows that the best that one can hope to recover is $x^* +\n\\ker(\\mathbf{U})$, where $\\mathbf{U}$ is the unique projection matrix onto the\nintersection of rowspaces of all possible submatrices of $\\mathbf{A}$ obtained\nby deleting $2q$ rows. Moreover, we prove that every $x$ that minimizes the\n$\\ell_0$-norm of $\\mathbf{y} - \\mathbf{A} x$ lies in $x^* + \\ker(\\mathbf{U})$,\nwhich then gives a constructive approach to recover this set.",
    "categories": [
      "cs.IT",
      "cs.LG",
      "eess.SP",
      "math.IT"
    ],
    "published": "2025-10-28T09:29:46Z",
    "authors": [
      "Vishal Halder",
      "Alexandre Reiffers-Masson",
      "Abdeldjalil A\u00efssa-El-Bey",
      "Gugan Thoppe"
    ],
    "pdf_url": "http://arxiv.org/pdf/2510.24215v1"
  },
  {
    "id": "2510.24208v1",
    "title": "Beyond Neural Incompatibility: Easing Cross-Scale Knowledge Transfer in\n  Large Language Models through Latent Semantic Alignment",
    "abstract": "Large Language Models (LLMs) encode vast amounts of knowledge in their\nmassive parameters, which is accessible to locate, trace, and analyze. Despite\nadvances in neural interpretability, it is still not clear how to transfer\nknowledge in a fine-grained manner, namely parametric knowledge transfer (PKT).\nA key problem is enabling effective and efficient knowledge transfer across\nLLMs of different scales, which is essential for achieving greater flexibility\nand broader applicability in transferring knowledge between LLMs. Due to neural\nincompatibility, referring to the architectural and parametric differences\nbetween LLMs of varying scales, existing methods that directly reuse layer\nparameters are severely limited. In this paper, we identify the semantic\nalignment in latent space as the fundamental prerequisite for LLM cross-scale\nknowledge transfer. Instead of directly using the layer parameters, our\napproach takes activations as the medium of layer-wise knowledge transfer.\nLeveraging the semantics in latent space, our approach is simple and\noutperforms prior work, better aligning model behaviors across varying scales.\nEvaluations on four benchmarks demonstrate the efficacy of our method. Further\nanalysis reveals the key factors easing cross-scale knowledge transfer and\nprovides insights into the nature of latent semantic alignment.",
    "categories": [
      "cs.CL",
      "cs.LG"
    ],
    "published": "2025-10-28T09:25:40Z",
    "authors": [
      "Jian Gu",
      "Aldeida Aleti",
      "Chunyang Chen",
      "Hongyu Zhang"
    ],
    "pdf_url": "http://arxiv.org/pdf/2510.24208v1"
  },
  {
    "id": "2510.24200v1",
    "title": "SPEAR++: Scaling Gradient Inversion via Sparsely-Used Dictionary\n  Learning",
    "abstract": "Federated Learning has seen an increased deployment in real-world scenarios\nrecently, as it enables the distributed training of machine learning models\nwithout explicit data sharing between individual clients. Yet, the introduction\nof the so-called gradient inversion attacks has fundamentally challenged its\nprivacy-preserving properties. Unfortunately, as these attacks mostly rely on\ndirect data optimization without any formal guarantees, the vulnerability of\nreal-world systems remains in dispute and requires tedious testing for each new\nfederated deployment. To overcome these issues, recently the SPEAR attack was\nintroduced, which is based on a theoretical analysis of the gradients of linear\nlayers with ReLU activations. While SPEAR is an important theoretical\nbreakthrough, the attack's practicality was severely limited by its exponential\nruntime in the batch size b. In this work, we fill this gap by applying\nState-of-the-Art techniques from Sparsely-Used Dictionary Learning to make the\nproblem of gradient inversion on linear layers with ReLU activations tractable.\nOur experiments demonstrate that our new attack, SPEAR++, retains all desirable\nproperties of SPEAR, such as robustness to DP noise and FedAvg aggregation,\nwhile being applicable to 10x bigger batch sizes.",
    "categories": [
      "cs.LG",
      "cs.CR",
      "cs.DC",
      "I.2.11"
    ],
    "published": "2025-10-28T09:06:19Z",
    "authors": [
      "Alexander Bakarsky",
      "Dimitar I. Dimitrov",
      "Maximilian Baader",
      "Martin Vechev"
    ],
    "pdf_url": "http://arxiv.org/pdf/2510.24200v1"
  },
  {
    "id": "2510.24194v1",
    "title": "Blindfolded Experts Generalize Better: Insights from Robotic\n  Manipulation and Videogames",
    "abstract": "Behavioral cloning is a simple yet effective technique for learning\nsequential decision-making from demonstrations. Recently, it has gained\nprominence as the core of foundation models for the physical world, where\nachieving generalization requires countless demonstrations of a multitude of\ntasks. Typically, a human expert with full information on the task demonstrates\na (nearly) optimal behavior. In this paper, we propose to hide some of the\ntask's information from the demonstrator. This ``blindfolded'' expert is\ncompelled to employ non-trivial exploration to solve the task. We show that\ncloning the blindfolded expert generalizes better to unseen tasks than its\nfully-informed counterpart. We conduct experiments of real-world robot peg\ninsertion tasks with (limited) human demonstrations, alongside videogames from\nthe Procgen benchmark. Additionally, we support our findings with theoretical\nanalysis, which confirms that the generalization error scales with\n$\\sqrt{I/m}$, where $I$ measures the amount of task information available to\nthe demonstrator, and $m$ is the number of demonstrated tasks. Both theory and\npractice indicate that cloning blindfolded experts generalizes better with\nfewer demonstrated tasks. Project page with videos and code:\nhttps://sites.google.com/view/blindfoldedexperts/home",
    "categories": [
      "cs.RO",
      "cs.LG"
    ],
    "published": "2025-10-28T08:57:27Z",
    "authors": [
      "Ev Zisselman",
      "Mirco Mutti",
      "Shelly Francis-Meretzki",
      "Elisei Shafer",
      "Aviv Tamar"
    ],
    "pdf_url": "http://arxiv.org/pdf/2510.24194v1"
  },
  {
    "id": "2510.24187v1",
    "title": "Self-Concordant Perturbations for Linear Bandits",
    "abstract": "We study the adversarial linear bandits problem and present a unified\nalgorithmic framework that bridges Follow-the-Regularized-Leader (FTRL) and\nFollow-the-Perturbed-Leader (FTPL) methods, extending the known connection\nbetween them from the full-information setting. Within this framework, we\nintroduce self-concordant perturbations, a family of probability distributions\nthat mirror the role of self-concordant barriers previously employed in the\nFTRL-based SCRiBLe algorithm. Using this idea, we design a novel FTPL-based\nalgorithm that combines self-concordant regularization with efficient\nstochastic exploration. Our approach achieves a regret of $O(d\\sqrt{n \\ln n})$\non both the $d$-dimensional hypercube and the Euclidean ball. On the Euclidean\nball, this matches the rate attained by existing self-concordant FTRL methods.\nFor the hypercube, this represents a $\\sqrt{d}$ improvement over these methods\nand matches the optimal bound up to logarithmic factors.",
    "categories": [
      "stat.ML",
      "cs.LG"
    ],
    "published": "2025-10-28T08:47:15Z",
    "authors": [
      "Lucas L\u00e9vy",
      "Jean-Lou Valeau",
      "Arya Akhavan",
      "Patrick Rebeschini"
    ],
    "pdf_url": "http://arxiv.org/pdf/2510.24187v1"
  },
  {
    "id": "2510.24180v1",
    "title": "V-SAT: Video Subtitle Annotation Tool",
    "abstract": "The surge of audiovisual content on streaming platforms and social media has\nheightened the demand for accurate and accessible subtitles. However, existing\nsubtitle generation methods primarily speech-based transcription or OCR-based\nextraction suffer from several shortcomings, including poor synchronization,\nincorrect or harmful text, inconsistent formatting, inappropriate reading\nspeeds, and the inability to adapt to dynamic audio-visual contexts. Current\napproaches often address isolated issues, leaving post-editing as a\nlabor-intensive and time-consuming process. In this paper, we introduce V-SAT\n(Video Subtitle Annotation Tool), a unified framework that automatically\ndetects and corrects a wide range of subtitle quality issues. By combining\nLarge Language Models(LLMs), Vision-Language Models (VLMs), Image Processing,\nand Automatic Speech Recognition (ASR), V-SAT leverages contextual cues from\nboth audio and video. Subtitle quality improved, with the SUBER score reduced\nfrom 9.6 to 3.54 after resolving all language mode issues and F1-scores of\n~0.80 for image mode issues. Human-in-the-loop validation ensures high-quality\nresults, providing the first comprehensive solution for robust subtitle\nannotation.",
    "categories": [
      "cs.LG"
    ],
    "published": "2025-10-28T08:34:27Z",
    "authors": [
      "Arpita Kundu",
      "Joyita Chakraborty",
      "Anindita Desarkar",
      "Aritra Sen",
      "Srushti Anil Patil",
      "Vishwanathan Raman"
    ],
    "pdf_url": "http://arxiv.org/pdf/2510.24180v1"
  },
  {
    "id": "2510.24173v1",
    "title": "EddyFormer: Accelerated Neural Simulations of Three-Dimensional\n  Turbulence at Scale",
    "abstract": "Computationally resolving turbulence remains a central challenge in fluid\ndynamics due to its multi-scale interactions. Fully resolving large-scale\nturbulence through direct numerical simulation (DNS) is computationally\nprohibitive, motivating data-driven machine learning alternatives. In this\nwork, we propose EddyFormer, a Transformer-based spectral-element (SEM)\narchitecture for large-scale turbulence simulation that combines the accuracy\nof spectral methods with the scalability of the attention mechanism. We\nintroduce an SEM tokenization that decomposes the flow into grid-scale and\nsubgrid-scale components, enabling capture of both local and global features.\nWe create a new three-dimensional isotropic turbulence dataset and train\nEddyFormer to achieves DNS-level accuracy at 256^3 resolution, providing a 30x\nspeedup over DNS. When applied to unseen domains up to 4x larger than in\ntraining, EddyFormer preserves accuracy on physics-invariant metrics-energy\nspectra, correlation functions, and structure functions-showing domain\ngeneralization. On The Well benchmark suite of diverse turbulent flows,\nEddyFormer resolves cases where prior ML models fail to converge, accurately\nreproducing complex dynamics across a wide range of physical conditions.",
    "categories": [
      "cs.LG",
      "cs.NA",
      "math.DS",
      "math.NA",
      "physics.flu-dyn"
    ],
    "published": "2025-10-28T08:27:37Z",
    "authors": [
      "Yiheng Du",
      "Aditi S. Krishnapriyan"
    ],
    "pdf_url": "http://arxiv.org/pdf/2510.24173v1"
  },
  {
    "id": "2510.24160v1",
    "title": "Identifiable learning of dissipative dynamics",
    "abstract": "Complex dissipative systems appear across science and engineering, from\npolymers and active matter to learning algorithms. These systems operate far\nfrom equilibrium, where energy dissipation and time irreversibility are key to\ntheir behavior, but are difficult to quantify from data. Learning accurate and\ninterpretable models of such dynamics remains a major challenge: the models\nmust be expressive enough to describe diverse processes, yet constrained enough\nto remain physically meaningful and mathematically identifiable. Here, we\nintroduce I-OnsagerNet, a neural framework that learns dissipative stochastic\ndynamics directly from trajectories while ensuring both interpretability and\nuniqueness. I-OnsagerNet extends the Onsager principle to guarantee that the\nlearned potential is obtained from the stationary density and that the drift\ndecomposes cleanly into time-reversible and time-irreversible components, as\ndictated by the Helmholtz decomposition. Our approach enables us to calculate\nthe entropy production and to quantify irreversibility, offering a principled\nway to detect and quantify deviations from equilibrium. Applications to polymer\nstretching in elongational flow and to stochastic gradient Langevin dynamics\nreveal new insights, including super-linear scaling of barrier heights and\nsub-linear scaling of entropy production rates with the strain rate, and the\nsuppression of irreversibility with increasing batch size. I-OnsagerNet thus\nestablishes a general, data-driven framework for discovering and interpreting\nnon-equilibrium dynamics.",
    "categories": [
      "cs.LG"
    ],
    "published": "2025-10-28T07:57:14Z",
    "authors": [
      "Aiqing Zhu",
      "Beatrice W. Soh",
      "Grigorios A. Pavliotis",
      "Qianxiao Li"
    ],
    "pdf_url": "http://arxiv.org/pdf/2510.24160v1"
  },
  {
    "id": "2510.24159v1",
    "title": "Self-supervised Synthetic Pretraining for Inference of Stellar Mass\n  Embedded in Dense Gas",
    "abstract": "Stellar mass is a fundamental quantity that determines the properties and\nevolution of stars. However, estimating stellar masses in star-forming regions\nis challenging because young stars are obscured by dense gas and the regions\nare highly inhomogeneous, making spherical dynamical estimates unreliable.\nSupervised machine learning could link such complex structures to stellar mass,\nbut it requires large, high-quality labeled datasets from high-resolution\nmagneto-hydrodynamical (MHD) simulations, which are computationally expensive.\nWe address this by pretraining a vision transformer on one million synthetic\nfractal images using the self-supervised framework DINOv2, and then applying\nthe frozen model to limited high-resolution MHD simulations. Our results\ndemonstrate that synthetic pretraining improves frozen-feature regression\nstellar mass predictions, with the pretrained model performing slightly better\nthan a supervised model trained on the same limited simulations. Principal\ncomponent analysis of the extracted features further reveals semantically\nmeaningful structures, suggesting that the model enables unsupervised\nsegmentation of star-forming regions without the need for labeled data or\nfine-tuning.",
    "categories": [
      "astro-ph.GA",
      "astro-ph.IM",
      "cs.AI",
      "cs.LG"
    ],
    "published": "2025-10-28T07:55:34Z",
    "authors": [
      "Keiya Hirashima",
      "Shingo Nozaki",
      "Naoto Harada"
    ],
    "pdf_url": "http://arxiv.org/pdf/2510.24159v1"
  },
  {
    "id": "2510.24812v1",
    "title": "From Linear to Nonlinear: Provable Weak-to-Strong Generalization through\n  Feature Learning",
    "abstract": "Weak-to-strong generalization refers to the phenomenon where a stronger model\ntrained under supervision from a weaker one can outperform its teacher. While\nprior studies aim to explain this effect, most theoretical insights are limited\nto abstract frameworks or linear/random feature models. In this paper, we\nprovide a formal analysis of weak-to-strong generalization from a linear CNN\n(weak) to a two-layer ReLU CNN (strong). We consider structured data composed\nof label-dependent signals of varying difficulty and label-independent noise,\nand analyze gradient descent dynamics when the strong model is trained on data\nlabeled by the pretrained weak model. Our analysis identifies two regimes --\ndata-scarce and data-abundant -- based on the signal-to-noise characteristics\nof the dataset, and reveals distinct mechanisms of weak-to-strong\ngeneralization. In the data-scarce regime, generalization occurs via benign\noverfitting or fails via harmful overfitting, depending on the amount of data,\nand we characterize the transition boundary. In the data-abundant regime,\ngeneralization emerges in the early phase through label correction, but we\nobserve that overtraining can subsequently degrade performance.",
    "categories": [
      "cs.LG",
      "stat.ML"
    ],
    "published": "2025-10-28T07:53:24Z",
    "authors": [
      "Junsoo Oh",
      "Jerry Song",
      "Chulhee Yun"
    ],
    "pdf_url": "http://arxiv.org/pdf/2510.24812v1"
  },
  {
    "id": "2510.24135v1",
    "title": "Fixed Point Neural Acceleration and Inverse Surrogate Model for Battery\n  Parameter Identification",
    "abstract": "The rapid expansion of electric vehicles has intensified the need for\naccurate and efficient diagnosis of lithium-ion batteries. Parameter\nidentification of electrochemical battery models is widely recognized as a\npowerful method for battery health assessment. However, conventional\nmetaheuristic approaches suffer from high computational cost and slow\nconvergence, and recent machine learning methods are limited by their reliance\non constant current data, which may not be available in practice. To overcome\nthese challenges, we propose deep learning-based framework for parameter\nidentification of electrochemical battery models. The proposed framework\ncombines a neural surrogate model of the single particle model with electrolyte\n(NeuralSPMe) and a deep learning-based fixed-point iteration method. NeuralSPMe\nis trained on realistic EV load profiles to accurately predict lithium\nconcentration dynamics under dynamic operating conditions while a parameter\nupdate network (PUNet) performs fixed-point iterative updates to significantly\nreduce both the evaluation time per sample and the overall number of iterations\nrequired for convergence. Experimental evaluations demonstrate that the\nproposed framework accelerates the parameter identification by more than 2000\ntimes, achieves superior sample efficiency and more than 10 times higher\naccuracy compared to conventional metaheuristic algorithms, particularly under\ndynamic load scenarios encountered in practical applications.",
    "categories": [
      "cs.LG"
    ],
    "published": "2025-10-28T07:20:38Z",
    "authors": [
      "Hojin Cheon",
      "Hyeongseok Seo",
      "Jihun Jeon",
      "Wooju Lee",
      "Dohyun Jeong",
      "Hongseok Kim"
    ],
    "pdf_url": "http://arxiv.org/pdf/2510.24135v1"
  },
  {
    "id": "2510.24125v1",
    "title": "Causal Convolutional Neural Networks as Finite Impulse Response Filters",
    "abstract": "This study investigates the behavior of Causal Convolutional Neural Networks\n(CNNs) with quasi-linear activation functions when applied to time-series data\ncharacterized by multimodal frequency content. We demonstrate that, once\ntrained, such networks exhibit properties analogous to Finite Impulse Response\n(FIR) filters, particularly when the convolutional kernels are of extended\nlength exceeding those typically employed in standard CNN architectures. Causal\nCNNs are shown to capture spectral features both implicitly and explicitly,\noffering enhanced interpretability for tasks involving dynamic systems.\nLeveraging the associative property of convolution, we further show that the\nentire network can be reduced to an equivalent single-layer filter resembling\nan FIR filter optimized via least-squares criteria. This equivalence yields new\ninsights into the spectral learning behavior of CNNs trained on signals with\nsparse frequency content. The approach is validated on both simulated beam\ndynamics and real-world bridge vibration datasets, underlining its relevance\nfor modeling and identifying physical systems governed by dynamic responses.",
    "categories": [
      "cs.LG"
    ],
    "published": "2025-10-28T06:57:14Z",
    "authors": [
      "Kiran Bacsa",
      "Wei Liu",
      "Xudong Jian",
      "Huangbin Liang",
      "Eleni Chatzi"
    ],
    "pdf_url": "http://arxiv.org/pdf/2510.24125v1"
  },
  {
    "id": "2510.24120v1",
    "title": "Graph-Guided Concept Selection for Efficient Retrieval-Augmented\n  Generation",
    "abstract": "Graph-based RAG constructs a knowledge graph (KG) from text chunks to enhance\nretrieval in Large Language Model (LLM)-based question answering. It is\nespecially beneficial in domains such as biomedicine, law, and political\nscience, where effective retrieval often involves multi-hop reasoning over\nproprietary documents. However, these methods demand numerous LLM calls to\nextract entities and relations from text chunks, incurring prohibitive costs at\nscale. Through a carefully designed ablation study, we observe that certain\nwords (termed concepts) and their associated documents are more important.\nBased on this insight, we propose Graph-Guided Concept Selection (G2ConS). Its\ncore comprises a chunk selection method and an LLM-independent concept graph.\nThe former selects salient document chunks to reduce KG construction costs; the\nlatter closes knowledge gaps introduced by chunk selection at zero cost.\nEvaluations on multiple real-world datasets show that G2ConS outperforms all\nbaselines in construction cost, retrieval effectiveness, and answering quality.",
    "categories": [
      "cs.LG"
    ],
    "published": "2025-10-28T06:47:30Z",
    "authors": [
      "Ziyu Liu",
      "Yijing Liu",
      "Jianfei Yuan",
      "Minzhi Yan",
      "Le Yue",
      "Honghui Xiong",
      "Yi Yang"
    ],
    "pdf_url": "http://arxiv.org/pdf/2510.24120v1"
  },
  {
    "id": "2510.24115v1",
    "title": "HistoLens: An Interactive XAI Toolkit for Verifying and Mitigating Flaws\n  in Vision-Language Models for Histopathology",
    "abstract": "For doctors to truly trust artificial intelligence, it can't be a black box.\nThey need to understand its reasoning, almost as if they were consulting a\ncolleague. We created HistoLens1 to be that transparent, collaborative partner.\nIt allows a pathologist to simply ask a question in plain English about a\ntissue slide--just as they would ask a trainee. Our system intelligently\ntranslates this question into a precise query for its AI engine, which then\nprovides a clear, structured report. But it doesn't stop there. If a doctor\never asks, \"Why?\", HistoLens can instantly provide a 'visual proof' for any\nfinding--a heatmap that points to the exact cells and regions the AI used for\nits analysis. We've also ensured the AI focuses only on the patient's tissue,\njust like a trained pathologist would, by teaching it to ignore distracting\nbackground noise. The result is a workflow where the pathologist remains the\nexpert in charge, using a trustworthy AI assistant to verify their insights and\nmake faster, more confident diagnoses.",
    "categories": [
      "cs.AI",
      "cs.LG"
    ],
    "published": "2025-10-28T06:38:59Z",
    "authors": [
      "Sandeep Vissapragada",
      "Vikrant Sahu",
      "Gagan Raj Gupta",
      "Vandita Singh"
    ],
    "pdf_url": "http://arxiv.org/pdf/2510.24115v1"
  },
  {
    "id": "2510.24113v1",
    "title": "Taming the Tail: NoI Topology Synthesis for Mixed DL Workloads on\n  Chiplet-Based Accelerators",
    "abstract": "Heterogeneous chiplet-based systems improve scaling by disag-gregating\nCPUs/GPUs and emerging technologies (HBM/DRAM).However this on-package\ndisaggregation introduces a latency inNetwork-on-Interposer(NoI). We observe\nthat in modern large-modelinference, parameters and activations routinely move\nbackand forth from HBM/DRAM, injecting large, bursty flows into theinterposer.\nThese memory-driven transfers inflate tail latency andviolate Service Level\nAgreements (SLAs) across k-ary n-cube base-line NoI topologies. To address this\ngap we introduce an InterferenceScore (IS) that quantifies worst-case slowdown\nunder contention.We then formulate NoI synthesis as a multi-objective\noptimization(MOO) problem. We develop PARL (Partition-Aware\nReinforcementLearner), a topology generator that balances throughput,\nlatency,and power. PARL-generated topologies reduce contention at the memory\ncut, meet SLAs, and cut worst-case slowdown to 1.2 times while maintaining\ncompetitive mean throughput relative to link-rich meshes. Overall, this\nreframes NoI design for heterogeneouschiplet accelerators with workload-aware\nobjectives.",
    "categories": [
      "cs.AR",
      "cs.AI",
      "cs.LG"
    ],
    "published": "2025-10-28T06:36:44Z",
    "authors": [
      "Arnav Shukla",
      "Harsh Sharma",
      "Srikant Bharadwaj",
      "Vinayak Abrol",
      "Sujay Deb"
    ],
    "pdf_url": "http://arxiv.org/pdf/2510.24113v1"
  },
  {
    "id": "2510.24811v1",
    "title": "ProofSketch: Efficient Verified Reasoning for Large Language Models",
    "abstract": "Reasoning methods such as chain-of-thought prompting and self-consistency\nhave shown immense potential to improve the accuracy of large language models\nacross various reasoning tasks. However such methods involve generation of\nlengthy reasoning chains, which substantially increases token consumption,\ncomputational cost, and latency. To address this inefficiency, we propose\nProofSketch, a verification-guided reasoning framework that integrates symbolic\nclosure computation, lexicographic verification and adaptive sketch generation.\nOur experiments show that ProofSketch consistently reduces token usage while\nimproving accuracy, demonstrating that this approach offers a promising path\nfor efficient and trustworthy reasoning.",
    "categories": [
      "cs.CL",
      "cs.AI",
      "cs.LG"
    ],
    "published": "2025-10-28T06:34:15Z",
    "authors": [
      "Disha Sheshanarayana",
      "Tanishka Magar"
    ],
    "pdf_url": "http://arxiv.org/pdf/2510.24811v1"
  },
  {
    "id": "2510.24105v1",
    "title": "Enhancing Pre-trained Representation Classifiability can Boost its\n  Interpretability",
    "abstract": "The visual representation of a pre-trained model prioritizes the\nclassifiability on downstream tasks, while the widespread applications for\npre-trained visual models have posed new requirements for representation\ninterpretability. However, it remains unclear whether the pre-trained\nrepresentations can achieve high interpretability and classifiability\nsimultaneously. To answer this question, we quantify the representation\ninterpretability by leveraging its correlation with the ratio of interpretable\nsemantics within the representations. Given the pre-trained representations,\nonly the interpretable semantics can be captured by interpretations, whereas\nthe uninterpretable part leads to information loss. Based on this fact, we\npropose the Inherent Interpretability Score (IIS) that evaluates the\ninformation loss, measures the ratio of interpretable semantics, and quantifies\nthe representation interpretability. In the evaluation of the representation\ninterpretability with different classifiability, we surprisingly discover that\nthe interpretability and classifiability are positively correlated, i.e.,\nrepresentations with higher classifiability provide more interpretable\nsemantics that can be captured in the interpretations. This observation further\nsupports two benefits to the pre-trained representations. First, the\nclassifiability of representations can be further improved by fine-tuning with\ninterpretability maximization. Second, with the classifiability improvement for\nthe representations, we obtain predictions based on their interpretations with\nless accuracy degradation. The discovered positive correlation and\ncorresponding applications show that practitioners can unify the improvements\nin interpretability and classifiability for pre-trained vision models. Codes\nare available at https://github.com/ssfgunner/IIS.",
    "categories": [
      "cs.CV",
      "cs.LG"
    ],
    "published": "2025-10-28T06:21:06Z",
    "authors": [
      "Shufan Shen",
      "Zhaobo Qi",
      "Junshu Sun",
      "Qingming Huang",
      "Qi Tian",
      "Shuhui Wang"
    ],
    "pdf_url": "http://arxiv.org/pdf/2510.24105v1"
  },
  {
    "id": "2510.24095v1",
    "title": "Learning Parameterized Skills from Demonstrations",
    "abstract": "We present DEPS, an end-to-end algorithm for discovering parameterized skills\nfrom expert demonstrations. Our method learns parameterized skill policies\njointly with a meta-policy that selects the appropriate discrete skill and\ncontinuous parameters at each timestep. Using a combination of temporal\nvariational inference and information-theoretic regularization methods, we\naddress the challenge of degeneracy common in latent variable models, ensuring\nthat the learned skills are temporally extended, semantically meaningful, and\nadaptable. We empirically show that learning parameterized skills from\nmultitask expert demonstrations significantly improves generalization to unseen\ntasks. Our method outperforms multitask as well as skill learning baselines on\nboth LIBERO and MetaWorld benchmarks. We also demonstrate that DEPS discovers\ninterpretable parameterized skills, such as an object grasping skill whose\ncontinuous arguments define the grasp location.",
    "categories": [
      "cs.LG",
      "cs.AI",
      "cs.RO"
    ],
    "published": "2025-10-28T06:08:25Z",
    "authors": [
      "Vedant Gupta",
      "Haotian Fu",
      "Calvin Luo",
      "Yiding Jiang",
      "George Konidaris"
    ],
    "pdf_url": "http://arxiv.org/pdf/2510.24095v1"
  },
  {
    "id": "2510.24088v1",
    "title": "Information-Theoretic Discrete Diffusion",
    "abstract": "We present an information-theoretic framework for discrete diffusion models\nthat yields principled estimators of log-likelihood using score-matching\nlosses. Inspired by the I-MMSE identity for the Gaussian setup, we derive\nanalogous results for the discrete setting. Specifically, we introduce the\nInformation-Minimum Denoising Score Entropy (I-MDSE) relation, which links\nmutual information between data and its diffused version to the minimum\ndenoising score entropy (DSE) loss. We extend this theory to masked diffusion\nand establish the Information-Minimum Denoising Cross-Entropy (I-MDCE)\nrelation, connecting cross-entropy losses to mutual information in discrete\nmasked processes. These results provide a time-integral decomposition of the\nlog-likelihood of the data in terms of optimal score-based losses, showing that\ncommonly used losses such as DSE and DCE are not merely variational bounds but\ntight and principled estimators of log-likelihood. The I-MDCE decomposition\nfurther enables practical extensions, including time-free formula, conditional\nlikelihood estimation in prompt-response tasks, and coupled Monte Carlo\nestimation of likelihood ratios. Experiments on synthetic and real-world data\nconfirm the accuracy, variance stability, and utility of our estimators. The\ncode is publicly available at https://github.com/Dongjae0324/infodis.",
    "categories": [
      "cs.LG",
      "cs.IT",
      "math.IT"
    ],
    "published": "2025-10-28T05:59:05Z",
    "authors": [
      "Moongyu Jeon",
      "Sangwoo Shin",
      "Dongjae Jeon",
      "Albert No"
    ],
    "pdf_url": "http://arxiv.org/pdf/2510.24088v1"
  },
  {
    "id": "2510.24085v1",
    "title": "Modeling Electric Vehicle Car-Following Behavior: Classical vs Machine\n  Learning Approach",
    "abstract": "The increasing adoption of electric vehicles (EVs) necessitates an\nunderstanding of their driving behavior to enhance traffic safety and develop\nsmart driving systems. This study compares classical and machine learning\nmodels for EV car following behavior. Classical models include the Intelligent\nDriver Model (IDM), Optimum Velocity Model (OVM), Optimal Velocity Relative\nVelocity (OVRV), and a simplified CACC model, while the machine learning\napproach employs a Random Forest Regressor. Using a real world dataset of an EV\nfollowing an internal combustion engine (ICE) vehicle under varied driving\nconditions, we calibrated classical model parameters by minimizing the RMSE\nbetween predictions and real data. The Random Forest model predicts\nacceleration using spacing, speed, and gap type as inputs. Results demonstrate\nthe Random Forest's superior accuracy, achieving RMSEs of 0.0046 (medium gap),\n0.0016 (long gap), and 0.0025 (extra long gap). Among physics based models,\nCACC performed best, with an RMSE of 2.67 for long gaps. These findings\nhighlight the machine learning model's performance across all scenarios. Such\nmodels are valuable for simulating EV behavior and analyzing mixed autonomy\ntraffic dynamics in EV integrated environments.",
    "categories": [
      "cs.AI",
      "cs.LG"
    ],
    "published": "2025-10-28T05:54:50Z",
    "authors": [
      "Md. Shihab Uddin",
      "Md Nazmus Shakib",
      "Rahul Bhadani"
    ],
    "pdf_url": "http://arxiv.org/pdf/2510.24085v1"
  },
  {
    "id": "2510.24074v1",
    "title": "Deep Learning-Enhanced Calibration of the Heston Model: A Unified\n  Framework",
    "abstract": "The Heston stochastic volatility model is a widely used tool in financial\nmathematics for pricing European options. However, its calibration remains\ncomputationally intensive and sensitive to local minima due to the model's\nnonlinear structure and high-dimensional parameter space. This paper introduces\na hybrid deep learning-based framework that enhances both the computational\nefficiency and the accuracy of the calibration procedure. The proposed approach\nintegrates two supervised feedforward neural networks: the Price Approximator\nNetwork (PAN), which approximates the option price surface based on strike and\nmoneyness inputs, and the Calibration Correction Network (CCN), which refines\nthe Heston model's output by correcting systematic pricing errors. Experimental\nresults on real S\\&P 500 option data demonstrate that the deep learning\napproach outperforms traditional calibration techniques across multiple error\nmetrics, achieving faster convergence and superior generalization in both\nin-sample and out-of-sample settings. This framework offers a practical and\nrobust solution for real-time financial model calibration.",
    "categories": [
      "math.AP",
      "cs.LG"
    ],
    "published": "2025-10-28T05:21:55Z",
    "authors": [
      "Arman Zadgar",
      "Somayeh Fallah",
      "Farshid Mehrdoust"
    ],
    "pdf_url": "http://arxiv.org/pdf/2510.24074v1"
  },
  {
    "id": "2510.24061v1",
    "title": "FALQON: Accelerating LoRA Fine-tuning with Low-Bit Floating-Point\n  Arithmetic",
    "abstract": "Low-bit floating-point (FP) formats, such as FP8, provide significant\nacceleration and memory savings in model training thanks to native hardware\nsupport on modern GPUs and NPUs. However, we analyze that FP8 quantization\noffers speedup primarily for large-dimensional matrix multiplications, while\ninherent quantization overheads diminish speedup when applied to low-rank\nadaptation (LoRA), which uses small-dimensional matrices for efficient\nfine-tuning of large language models (LLMs). To address this limitation, we\npropose FALQON, a novel framework that eliminates the quantization overhead\nfrom separate LoRA computational paths by directly merging LoRA adapters into\nan FP8-quantized backbone during fine-tuning. Furthermore, we reformulate the\nforward and backward computations for merged adapters to significantly reduce\nquantization overhead, and introduce a row-wise proxy update mechanism that\nefficiently integrates substantial updates into the quantized backbone.\nExperimental evaluations demonstrate that FALQON achieves approximately a\n3$\\times$ training speedup over existing quantized LoRA methods with a similar\nlevel of accuracy, providing a practical solution for efficient large-scale\nmodel fine-tuning. Moreover, FALQON's end-to-end FP8 workflow removes the need\nfor post-training quantization, facilitating efficient deployment. Code is\navailable at https://github.com/iamkanghyunchoi/falqon.",
    "categories": [
      "cs.LG",
      "cs.AI"
    ],
    "published": "2025-10-28T04:44:49Z",
    "authors": [
      "Kanghyun Choi",
      "Hyeyoon Lee",
      "SunJong Park",
      "Dain Kwon",
      "Jinho Lee"
    ],
    "pdf_url": "http://arxiv.org/pdf/2510.24061v1"
  },
  {
    "id": "2510.24058v1",
    "title": "PULSE: Privileged Knowledge Transfer from Electrodermal Activity to\n  Low-Cost Sensors for Stress Monitoring",
    "abstract": "Electrodermal activity (EDA), the primary signal for stress detection,\nrequires costly hardware often unavailable in real-world wearables. In this\npaper, we propose PULSE, a framework that utilizes EDA exclusively during\nself-supervised pretraining, while enabling inference without EDA but with more\nreadily available modalities such as ECG, BVP, ACC, and TEMP. Our approach\nseparates encoder outputs into shared and private embeddings. We align shared\nembeddings across modalities and fuse them into a modality-invariant\nrepresentation. The private embeddings carry modality-specific information to\nsupport the reconstruction objective. Pretraining is followed by knowledge\ntransfer where a frozen EDA teacher transfers sympathetic-arousal\nrepresentations into student encoders. On WESAD, our method achieves strong\nstress-detection performance, showing that representations of privileged EDA\ncan be transferred to low-cost sensors to improve accuracy while reducing\nhardware cost.",
    "categories": [
      "eess.SP",
      "cs.AI",
      "cs.LG"
    ],
    "published": "2025-10-28T04:35:05Z",
    "authors": [
      "Zihan Zhao",
      "Masood Mortazavi",
      "Ning Yan"
    ],
    "pdf_url": "http://arxiv.org/pdf/2510.24058v1"
  },
  {
    "id": "2510.24056v1",
    "title": "Copula-Stein Discrepancy: A Generator-Based Stein Operator for\n  Archimedean Dependence",
    "abstract": "Kernel Stein discrepancies (KSDs) have become a principal tool for\ngoodness-of-fit testing, but standard KSDs are often insensitive to\nhigher-order dependency structures, such as tail dependence, which are critical\nin many scientific and financial domains. We address this gap by introducing\nthe Copula-Stein Discrepancy (CSD), a novel class of discrepancies tailored to\nthe geometry of statistical dependence. By defining a Stein operator directly\non the copula density, CSD leverages the generative structure of dependence,\nrather than relying on the joint density's score function. For the broad class\nof Archimedean copulas, this approach yields a closed-form Stein kernel derived\nfrom the scalar generator function. We provide a comprehensive theoretical\nanalysis, proving that CSD (i) metrizes weak convergence of copula\ndistributions, ensuring it detects any mismatch in dependence; (ii) has an\nempirical estimator that converges at the minimax optimal rate of\n$O_P(n^{-1/2})$; and (iii) is provably sensitive to differences in tail\ndependence coefficients. The framework is extended to general non-Archimedean\ncopulas, including elliptical and vine copulas. Computationally, the exact CSD\nkernel evaluation scales linearly in dimension, while a novel random feature\napproximation reduces the $n$-dependence from quadratic $O(n^2)$ to near-linear\n$\\tilde{O}(n)$, making CSD a practical and theoretically principled tool for\ndependence-aware inference.",
    "categories": [
      "stat.ML",
      "cs.LG"
    ],
    "published": "2025-10-28T04:33:57Z",
    "authors": [
      "Agnideep Aich",
      "Ashit Baran Aich"
    ],
    "pdf_url": "http://arxiv.org/pdf/2510.24056v1"
  },
  {
    "id": "2510.24807v1",
    "title": "Learning to Attack: Uncovering Privacy Risks in Sequential Data Releases",
    "abstract": "Privacy concerns have become increasingly critical in modern AI and data\nscience applications, where sensitive information is collected, analyzed, and\nshared across diverse domains such as healthcare, finance, and mobility. While\nprior research has focused on protecting privacy in a single data release, many\nreal-world systems operate under sequential or continuous data publishing,\nwhere the same or related data are released over time. Such sequential\ndisclosures introduce new vulnerabilities, as temporal correlations across\nreleases may enable adversaries to infer sensitive information that remains\nhidden in any individual release. In this paper, we investigate whether an\nattacker can compromise privacy in sequential data releases by exploiting\ndependencies between consecutive publications, even when each individual\nrelease satisfies standard privacy guarantees. To this end, we propose a novel\nattack model that captures these sequential dependencies by integrating a\nHidden Markov Model with a reinforcement learning-based bi-directional\ninference mechanism. This enables the attacker to leverage both earlier and\nlater observations in the sequence to infer private information. We instantiate\nour framework in the context of trajectory data, demonstrating how an adversary\ncan recover sensitive locations from sequential mobility datasets. Extensive\nexperiments on Geolife, Porto Taxi, and SynMob datasets show that our model\nconsistently outperforms baseline approaches that treat each release\nindependently. The results reveal a fundamental privacy risk inherent to\nsequential data publishing, where individually protected releases can\ncollectively leak sensitive information when analyzed temporally. These\nfindings underscore the need for new privacy-preserving frameworks that\nexplicitly model temporal dependencies, such as time-aware differential privacy\nor sequential data obfuscation strategies.",
    "categories": [
      "cs.CR",
      "cs.LG"
    ],
    "published": "2025-10-28T04:32:42Z",
    "authors": [
      "Ziyao Cui",
      "Minxing Zhang",
      "Jian Pei"
    ],
    "pdf_url": "http://arxiv.org/pdf/2510.24807v1"
  },
  {
    "id": "2510.24055v1",
    "title": "Language-Conditioned Representations and Mixture-of-Experts Policy for\n  Robust Multi-Task Robotic Manipulation",
    "abstract": "Perceptual ambiguity and task conflict limit multitask robotic manipulation\nvia imitation learning. We propose a framework combining a Language-Conditioned\nVisual Representation (LCVR) module and a Language-conditioned\nMixture-ofExperts Density Policy (LMoE-DP). LCVR resolves perceptual\nambiguities by grounding visual features with language instructions, enabling\ndifferentiation between visually similar tasks. To mitigate task conflict,\nLMoE-DP uses a sparse expert architecture to specialize in distinct, multimodal\naction distributions, stabilized by gradient modulation. On real-robot\nbenchmarks, LCVR boosts Action Chunking with Transformers (ACT) and Diffusion\nPolicy (DP) success rates by 33.75% and 25%, respectively. The full framework\nachieves a 79% average success, outperforming the advanced baseline by 21%. Our\nwork shows that combining semantic grounding and expert specialization enables\nrobust, efficient multi-task manipulation",
    "categories": [
      "cs.RO",
      "cs.LG"
    ],
    "published": "2025-10-28T04:27:03Z",
    "authors": [
      "Xiucheng Zhang",
      "Yang Jiang",
      "Hongwei Qing",
      "Jiashuo Bai"
    ],
    "pdf_url": "http://arxiv.org/pdf/2510.24055v1"
  },
  {
    "id": "2510.24053v1",
    "title": "Low-N Protein Activity Optimization with FolDE",
    "abstract": "Proteins are traditionally optimized through the costly construction and\nmeasurement of many mutants. Active Learning-assisted Directed Evolution (ALDE)\nalleviates that cost by predicting the best improvements and iteratively\ntesting mutants to inform predictions. However, existing ALDE methods face a\ncritical limitation: selecting the highest-predicted mutants in each round\nyields homogeneous training data insufficient for accurate prediction models in\nsubsequent rounds. Here we present FolDE, an ALDE method designed to maximize\nend-of-campaign success. In simulations across 20 protein targets, FolDE\ndiscovers 23% more top 10% mutants than the best baseline ALDE method (p=0.005)\nand is 55% more likely to find top 1% mutants. FolDE achieves this primarily\nthrough naturalness-based warm-starting, which augments limited activity\nmeasurements with protein language model outputs to improve activity\nprediction. We also introduce a constant-liar batch selector, which improves\nbatch diversity; this is important in multi-mutation campaigns but had limited\neffect in our benchmarks. The complete workflow is freely available as\nopen-source software, making efficient protein optimization accessible to any\nlaboratory.",
    "categories": [
      "cs.LG",
      "q-bio.QM"
    ],
    "published": "2025-10-28T04:24:39Z",
    "authors": [
      "Jacob B. Roberts",
      "Catherine R. Ji",
      "Isaac Donnell",
      "Thomas D. Young",
      "Allison N. Pearson",
      "Graham A. Hudson",
      "Leah S. Keiser",
      "Mia Wesselkamper",
      "Peter H. Winegar",
      "Janik Ludwig",
      "Sarah H. Klass",
      "Isha V. Sheth",
      "Ezechinyere C. Ukabiala",
      "Maria C. T. Astolfi",
      "Benjamin Eysenbach",
      "Jay D. Keasling"
    ],
    "pdf_url": "http://arxiv.org/pdf/2510.24053v1"
  },
  {
    "id": "2510.24049v1",
    "title": "Learning from History: A Retrieval-Augmented Framework for\n  Spatiotemporal Prediction",
    "abstract": "Accurate and long-term spatiotemporal prediction for complex physical systems\nremains a fundamental challenge in scientific computing. While deep learning\nmodels, as powerful parametric approximators, have shown remarkable success,\nthey suffer from a critical limitation: the accumulation of errors during\nlong-term autoregressive rollouts often leads to physically implausible\nartifacts. This deficiency arises from their purely parametric nature, which\nstruggles to capture the full constraints of a system's intrinsic dynamics. To\naddress this, we introduce a novel \\textbf{Retrieval-Augmented Prediction\n(RAP)} framework, a hybrid paradigm that synergizes the predictive power of\ndeep networks with the grounded truth of historical data. The core philosophy\nof RAP is to leverage historical evolutionary exemplars as a non-parametric\nestimate of the system's local dynamics. For any given state, RAP efficiently\nretrieves the most similar historical analog from a large-scale database. The\ntrue future evolution of this analog then serves as a \\textbf{reference\ntarget}. Critically, this target is not a hard constraint in the loss function\nbut rather a powerful conditional input to a specialized dual-stream\narchitecture. It provides strong \\textbf{dynamic guidance}, steering the\nmodel's predictions towards physically viable trajectories. In extensive\nbenchmarks across meteorology, turbulence, and fire simulation, RAP not only\nsurpasses state-of-the-art methods but also significantly outperforms a strong\n\\textbf{analog-only forecasting baseline}. More importantly, RAP generates\npredictions that are more physically realistic by effectively suppressing error\ndivergence in long-term rollouts.",
    "categories": [
      "cs.LG",
      "cs.AI"
    ],
    "published": "2025-10-28T04:09:16Z",
    "authors": [
      "Hao Jia",
      "Penghao Zhao",
      "Hao Wu",
      "Yuan Gao",
      "Yangyu Tao",
      "Bin Cui"
    ],
    "pdf_url": "http://arxiv.org/pdf/2510.24049v1"
  },
  {
    "id": "2510.24046v1",
    "title": "Causal-Aware Generative Adversarial Networks with Reinforcement Learning",
    "abstract": "The utility of tabular data for tasks ranging from model training to\nlarge-scale data analysis is often constrained by privacy concerns or\nregulatory hurdles. While existing data generation methods, particularly those\nbased on Generative Adversarial Networks (GANs), have shown promise, they\nfrequently struggle with capturing complex causal relationship, maintaining\ndata utility, and providing provable privacy guarantees suitable for enterprise\ndeployment. We introduce CA-GAN, a novel generative framework specifically\nengineered to address these challenges for real-world tabular datasets. CA-GAN\nutilizes a two-step approach: causal graph extraction to learn a robust,\ncomprehensive causal relationship in the data's manifold, followed by a custom\nConditional WGAN-GP (Wasserstein GAN with Gradient Penalty) that operates\nexclusively as per the structure of nodes in the causal graph. More\nimportantly, the generator is trained with a new Reinforcement Learning-based\nobjective that aligns the causal graphs constructed from real and fake data,\nensuring the causal awareness in both training and sampling phases. We\ndemonstrate CA-GAN superiority over six SOTA methods across 14 tabular\ndatasets. Our evaluations, focused on core data engineering metrics: causal\npreservation, utility preservation, and privacy preservation. Our method offers\na practical, high-performance solution for data engineers seeking to create\nhigh-quality, privacy-compliant synthetic datasets to benchmark database\nsystems, accelerate software development, and facilitate secure data-driven\nresearch.",
    "categories": [
      "cs.LG",
      "cs.AI"
    ],
    "published": "2025-10-28T04:02:49Z",
    "authors": [
      "Tu Anh Hoang Nguyen",
      "Dang Nguyen",
      "Tri-Nhan Vo",
      "Thuc Duy Le",
      "Sunil Gupta"
    ],
    "pdf_url": "http://arxiv.org/pdf/2510.24046v1"
  },
  {
    "id": "2510.24044v1",
    "title": "Mitigating Negative Transfer via Reducing Environmental Disagreement",
    "abstract": "Unsupervised Domain Adaptation~(UDA) focuses on transferring knowledge from a\nlabeled source domain to an unlabeled target domain, addressing the challenge\nof \\emph{domain shift}. Significant domain shifts hinder effective knowledge\ntransfer, leading to \\emph{negative transfer} and deteriorating model\nperformance. Therefore, mitigating negative transfer is essential. This study\nrevisits negative transfer through the lens of causally disentangled learning,\nemphasizing cross-domain discriminative disagreement on non-causal\nenvironmental features as a critical factor. Our theoretical analysis reveals\nthat overreliance on non-causal environmental features as the environment\nevolves can cause discriminative disagreements~(termed \\emph{environmental\ndisagreement}), thereby resulting in negative transfer. To address this, we\npropose Reducing Environmental Disagreement~(RED), which disentangles each\nsample into domain-invariant causal features and domain-specific non-causal\nenvironmental features via adversarially training domain-specific environmental\nfeature extractors in the opposite domains. Subsequently, RED estimates and\nreduces environmental disagreement based on domain-specific non-causal\nenvironmental features. Experimental results confirm that RED effectively\nmitigates negative transfer and achieves state-of-the-art performance.",
    "categories": [
      "cs.LG"
    ],
    "published": "2025-10-28T03:56:20Z",
    "authors": [
      "Hui Sun",
      "Zheng Xie",
      "Hao-Yuan He",
      "Ming Li"
    ],
    "pdf_url": "http://arxiv.org/pdf/2510.24044v1"
  },
  {
    "id": "2510.24043v2",
    "title": "Localized Kernel Projection Outlyingness: A Two-Stage Approach for\n  Multi-Modal Outlier Detection",
    "abstract": "This paper presents Two-Stage LKPLO, a novel multi-stage outlier detection\nframework that overcomes the coexisting limitations of conventional\nprojection-based methods: their reliance on a fixed statistical metric and\ntheir assumption of a single data structure. Our framework uniquely synthesizes\nthree key concepts: (1) a generalized loss-based outlyingness measure (PLO)\nthat replaces the fixed metric with flexible, adaptive loss functions like our\nproposed SVM-like loss; (2) a global kernel PCA stage to linearize non-linear\ndata structures; and (3) a subsequent local clustering stage to handle\nmulti-modal distributions. Comprehensive 5-fold cross-validation experiments on\n10 benchmark datasets, with automated hyperparameter optimization, demonstrate\nthat Two-Stage LKPLO achieves state-of-the-art performance. It significantly\noutperforms strong baselines on datasets with challenging structures where\nexisting methods fail, most notably on multi-cluster data (Optdigits) and\ncomplex, high-dimensional data (Arrhythmia). Furthermore, an ablation study\nempirically confirms that the synergistic combination of both the kernelization\nand localization stages is indispensable for its superior performance. This\nwork contributes a powerful new tool for a significant class of outlier\ndetection problems and underscores the importance of hybrid, multi-stage\narchitectures.",
    "categories": [
      "cs.LG",
      "stat.ML"
    ],
    "published": "2025-10-28T03:53:46Z",
    "authors": [
      "Akira Tamamori"
    ],
    "pdf_url": "http://arxiv.org/pdf/2510.24043v2"
  },
  {
    "id": "2510.24039v1",
    "title": "Geometric Algorithms for Neural Combinatorial Optimization with\n  Constraints",
    "abstract": "Self-Supervised Learning (SSL) for Combinatorial Optimization (CO) is an\nemerging paradigm for solving combinatorial problems using neural networks. In\nthis paper, we address a central challenge of SSL for CO: solving problems with\ndiscrete constraints. We design an end-to-end differentiable framework that\nenables us to solve discrete constrained optimization problems with neural\nnetworks. Concretely, we leverage algorithmic techniques from the literature on\nconvex geometry and Carath\\'eodory's theorem to decompose neural network\noutputs into convex combinations of polytope corners that correspond to\nfeasible sets. This decomposition-based approach enables self-supervised\ntraining but also ensures efficient quality-preserving rounding of the neural\nnet output into feasible solutions. Extensive experiments in\ncardinality-constrained optimization show that our approach can consistently\noutperform neural baselines. We further provide worked-out examples of how our\nmethod can be applied beyond cardinality-constrained problems to a diverse set\nof combinatorial optimization tasks, including finding independent sets in\ngraphs, and solving matroid-constrained problems.",
    "categories": [
      "cs.LG",
      "cs.AI"
    ],
    "published": "2025-10-28T03:49:01Z",
    "authors": [
      "Nikolaos Karalias",
      "Akbar Rafiey",
      "Yifei Xu",
      "Zhishang Luo",
      "Behrooz Tahmasebi",
      "Connie Jiang",
      "Stefanie Jegelka"
    ],
    "pdf_url": "http://arxiv.org/pdf/2510.24039v1"
  },
  {
    "id": "2510.24037v1",
    "title": "Kernelized Sparse Fine-Tuning with Bi-level Parameter Competition for\n  Vision Models",
    "abstract": "Parameter-efficient fine-tuning (PEFT) aims to adapt pre-trained vision\nmodels to downstream tasks. Among PEFT paradigms, sparse tuning achieves\nremarkable performance by adjusting only the weights most relevant to\ndownstream tasks, rather than densely tuning the entire weight matrix. Current\nmethods follow a two-stage paradigm. First, it locates task-relevant weights by\ngradient information, which overlooks the parameter adjustments during\nfine-tuning and limits the performance. Second, it updates only the located\nweights by applying a sparse mask to the gradient of the weight matrix, which\nresults in high memory usage due to the storage of all weight matrices in the\noptimizer. In this paper, we propose a one-stage method named SNELLA to\novercome the above limitations. For memory usage, SNELLA selectively updates\nthe weight matrix by adding it to another sparse matrix that is merged by two\nlow-rank learnable matrices. We extend the low-rank decomposition by\nintroducing nonlinear kernel functions, thereby increasing the rank of the\nresulting merged matrix to prevent the interdependency among weight updates,\nenabling better adaptation to downstream tasks. For locating task-relevant\nweights, we propose an adaptive bi-level sparsity allocation mechanism that\nencourages weights to compete across and inside layers based on their\nimportance scores in an end-to-end manner. Extensive experiments are conducted\non classification, segmentation, and generation tasks using different\npre-trained vision models. The results show that SNELLA achieves SOTA\nperformance with low memory usage. Notably, SNELLA obtains 1.8% (91.9% v.s.\n90.1%) higher Top-1 accuracy on the FGVC benchmark compared to SPT-LoRA.\nCompared to previous methods, SNELLA achieves a memory reduction of 31.1%-39.9%\nacross models with parameter scales from 86M to 632M. Our source codes are\navailable at https://github.com/ssfgunner/SNELL.",
    "categories": [
      "cs.CV",
      "cs.LG"
    ],
    "published": "2025-10-28T03:39:18Z",
    "authors": [
      "Shufan Shen",
      "Junshu Sun",
      "Shuhui Wang",
      "Qingming Huang"
    ],
    "pdf_url": "http://arxiv.org/pdf/2510.24037v1"
  },
  {
    "id": "2510.24035v1",
    "title": "GraphNet: A Large-Scale Computational Graph Dataset for Tensor Compiler\n  Research",
    "abstract": "We introduce GraphNet, a dataset of 2.7K real-world deep learning\ncomputational graphs with rich metadata, spanning six major task categories\nacross multiple deep learning frameworks. To evaluate tensor compiler\nperformance on these samples, we propose the benchmark metric Speedup Score\nS(t), which jointly considers runtime speedup and execution correctness under\ntunable tolerance levels, offering a reliable measure of general optimization\ncapability. Furthermore, we extend S(t) to the Error-aware Speedup Score ES(t),\nwhich incorporates error information and helps compiler developers identify key\nperformance bottlenecks. In this report, we benchmark the default tensor\ncompilers, CINN for PaddlePaddle and TorchInductor for PyTorch, on computer\nvision (CV) and natural language processing (NLP) samples to demonstrate the\npracticality of GraphNet. The full construction pipeline with graph extraction\nand compiler evaluation tools is available at\nhttps://github.com/PaddlePaddle/GraphNet .",
    "categories": [
      "cs.LG",
      "cs.CL"
    ],
    "published": "2025-10-28T03:36:05Z",
    "authors": [
      "Xinqi Li",
      "Yiqun Liu",
      "Shan Jiang",
      "Enrong Zheng",
      "Huaijin Zheng",
      "Wenhao Dai",
      "Haodong Deng",
      "Dianhai Yu",
      "Yanjun Ma"
    ],
    "pdf_url": "http://arxiv.org/pdf/2510.24035v1"
  },
  {
    "id": "2510.24029v1",
    "title": "Improved Accuracy of Robot Localization Using 3-D LiDAR in a\n  Hippocampus-Inspired Model",
    "abstract": "Boundary Vector Cells (BVCs) are a class of neurons in the brains of\nvertebrates that encode environmental boundaries at specific distances and\nallocentric directions, playing a central role in forming place fields in the\nhippocampus. Most computational BVC models are restricted to two-dimensional\n(2D) environments, making them prone to spatial ambiguities in the presence of\nhorizontal symmetries in the environment. To address this limitation, we\nincorporate vertical angular sensitivity into the BVC framework, thereby\nenabling robust boundary detection in three dimensions, and leading to\nsignificantly more accurate spatial localization in a biologically-inspired\nrobot model.\n  The proposed model processes LiDAR data to capture vertical contours, thereby\ndisambiguating locations that would be indistinguishable under a purely 2D\nrepresentation. Experimental results show that in environments with minimal\nvertical variation, the proposed 3D model matches the performance of a 2D\nbaseline; yet, as 3D complexity increases, it yields substantially more\ndistinct place fields and markedly reduces spatial aliasing. These findings\nshow that adding a vertical dimension to BVC-based localization can\nsignificantly enhance navigation and mapping in real-world 3D spaces while\nretaining performance parity in simpler, near-planar scenarios.",
    "categories": [
      "cs.RO",
      "cs.AI",
      "cs.LG",
      "cs.SY",
      "eess.SY",
      "q-bio.NC",
      "I.2.9; I.2.6"
    ],
    "published": "2025-10-28T03:24:02Z",
    "authors": [
      "Andrew Gerstenslager",
      "Bekarys Dukenbaev",
      "Ali A. Minai"
    ],
    "pdf_url": "http://arxiv.org/pdf/2510.24029v1"
  },
  {
    "id": "2510.24027v1",
    "title": "Spatio-temporal Multivariate Time Series Forecast with Chosen Variables",
    "abstract": "Spatio-Temporal Multivariate time series Forecast (STMF) uses the time series\nof $n$ spatially distributed variables in a period of recent past to forecast\ntheir values in a period of near future. It has important applications in\nspatio-temporal sensing forecast such as road traffic prediction and air\npollution prediction. Recent papers have addressed a practical problem of\nmissing variables in the model input, which arises in the sensing applications\nwhere the number $m$ of sensors is far less than the number $n$ of locations to\nbe monitored, due to budget constraints. We observe that the state of the art\nassumes that the $m$ variables (i.e., locations with sensors) in the model\ninput are pre-determined and the important problem of how to choose the $m$\nvariables in the input has never been studied. This paper fills the gap by\nstudying a new problem of STMF with chosen variables, which optimally selects\n$m$-out-of-$n$ variables for the model input in order to maximize the forecast\naccuracy. We propose a unified framework that jointly performs variable\nselection and model optimization for both forecast accuracy and model\nefficiency. It consists of three novel technical components: (1) masked\nvariable-parameter pruning, which progressively prunes less informative\nvariables and attention parameters through quantile-based masking; (2)\nprioritized variable-parameter replay, which replays low-loss past samples to\npreserve learned knowledge for model stability; (3) dynamic extrapolation\nmechanism, which propagates information from variables selected for the input\nto all other variables via learnable spatial embeddings and adjacency\ninformation. Experiments on five real-world datasets show that our work\nsignificantly outperforms the state-of-the-art baselines in both accuracy and\nefficiency, demonstrating the effectiveness of joint variable selection and\nmodel optimization.",
    "categories": [
      "cs.LG",
      "cs.AI"
    ],
    "published": "2025-10-28T03:19:06Z",
    "authors": [
      "Zibo Liu",
      "Zhe Jiang",
      "Zelin Xu",
      "Tingsong Xiao",
      "Yupu Zhang",
      "Zhengkun Xiao",
      "Haibo Wang",
      "Shigang Chen"
    ],
    "pdf_url": "http://arxiv.org/pdf/2510.24027v1"
  },
  {
    "id": "2510.24026v1",
    "title": "Efficient Global-Local Fusion Sampling for Physics-Informed Neural\n  Networks",
    "abstract": "The accuracy of Physics-Informed Neural Networks (PINNs) critically depends\non the placement of collocation points, as the PDE loss is approximated through\nsampling over the solution domain. Global sampling ensures stability by\ncovering the entire domain but requires many samples and is computationally\nexpensive, whereas local sampling improves efficiency by focusing on\nhigh-residual regions but may neglect well-learned areas, reducing robustness.\nWe propose a Global-Local Fusion (GLF) Sampling Strategy that combines the\nstrengths of both approaches. Specifically, new collocation points are\ngenerated by perturbing training points with Gaussian noise scaled inversely to\nthe residual, thereby concentrating samples in difficult regions while\npreserving exploration. To further reduce computational overhead, a lightweight\nlinear surrogate is introduced to approximate the global residual-based\ndistribution, achieving similar effectiveness at a fraction of the cost.\nTogether, these components, residual-adaptive sampling and residual-based\napproximation, preserve the stability of global methods while retaining the\nefficiency of local refinement. Extensive experiments on benchmark PDEs\ndemonstrate that GLF consistently improves both accuracy and efficiency\ncompared with global and local sampling strategies. This study provides a\npractical and scalable framework for enhancing the reliability and efficiency\nof PINNs in solving complex and high-dimensional PDEs.",
    "categories": [
      "cs.LG"
    ],
    "published": "2025-10-28T03:10:54Z",
    "authors": [
      "Jiaqi Luo",
      "Shixin Xu",
      "Zhouwang Yang"
    ],
    "pdf_url": "http://arxiv.org/pdf/2510.24026v1"
  },
  {
    "id": "2510.24025v2",
    "title": "NeuroPathNet: Dynamic Path Trajectory Learning for Brain Functional\n  Connectivity Analysis",
    "abstract": "Understanding the evolution of brain functional networks over time is of\ngreat significance for the analysis of cognitive mechanisms and the diagnosis\nof neurological diseases. Existing methods often have difficulty in capturing\nthe temporal evolution characteristics of connections between specific\nfunctional communities. To this end, this paper proposes a new path-level\ntrajectory modeling framework (NeuroPathNet) to characterize the dynamic\nbehavior of connection pathways between brain functional partitions. Based on\nmedically supported static partitioning schemes (such as Yeo and Smith ICA), we\nextract the time series of connection strengths between each pair of functional\npartitions and model them using a temporal neural network. We validate the\nmodel performance on three public functional Magnetic Resonance Imaging (fMRI)\ndatasets, and the results show that it outperforms existing mainstream methods\nin multiple indicators. This study can promote the development of dynamic graph\nlearning methods for brain network analysis, and provide possible clinical\napplications for the diagnosis of neurological diseases.",
    "categories": [
      "cs.LG",
      "cs.AI"
    ],
    "published": "2025-10-28T03:07:06Z",
    "authors": [
      "Tianqi Guo",
      "Liping Chen",
      "Ciyuan Peng",
      "Jingjing Zhou",
      "Jing Ren"
    ],
    "pdf_url": "http://arxiv.org/pdf/2510.24025v2"
  },
  {
    "id": "2510.25781v1",
    "title": "A Practitioner's Guide to Kolmogorov-Arnold Networks",
    "abstract": "Kolmogorov-Arnold Networks (KANs) have recently emerged as a promising\nalternative to traditional Multilayer Perceptrons (MLPs), inspired by the\nKolmogorov-Arnold representation theorem. Unlike MLPs, which use fixed\nactivation functions on nodes, KANs employ learnable univariate basis functions\non edges, offering enhanced expressivity and interpretability. This review\nprovides a systematic and comprehensive overview of the rapidly expanding KAN\nlandscape, moving beyond simple performance comparisons to offer a structured\nsynthesis of theoretical foundations, architectural variants, and practical\nimplementation strategies. By collecting and categorizing a vast array of\nopen-source implementations, we map the vibrant ecosystem supporting KAN\ndevelopment. We begin by bridging the conceptual gap between KANs and MLPs,\nestablishing their formal equivalence and highlighting the superior parameter\nefficiency of the KAN formulation. A central theme of our review is the\ncritical role of the basis function; we survey a wide array of choices,\nincluding B-splines, Chebyshev and Jacobi polynomials, ReLU compositions,\nGaussian RBFs, and Fourier series, and analyze their respective trade-offs in\nterms of smoothness, locality, and computational cost. We then categorize\nrecent advancements into a clear roadmap, covering techniques for improving\naccuracy, efficiency, and regularization. Key topics include physics-informed\nloss design, adaptive sampling, domain decomposition, hybrid architectures, and\nspecialized methods for handling discontinuities. Finally, we provide a\npractical \"Choose-Your-KAN\" guide to help practitioners select appropriate\narchitectures, and we conclude by identifying current research gaps. The\nassociated GitHub repository https://github.com/AmirNoori68/kan-review\ncomplements this paper and serves as a structured reference for ongoing KAN\nresearch.",
    "categories": [
      "cs.LG",
      "cs.AI",
      "cs.NA",
      "cs.NE",
      "math.NA"
    ],
    "published": "2025-10-28T03:03:44Z",
    "authors": [
      "Amir Noorizadegan",
      "Sifan Wang",
      "Leevan Ling"
    ],
    "pdf_url": "http://arxiv.org/pdf/2510.25781v1"
  },
  {
    "id": "2510.24013v1",
    "title": "Discovering Heuristics with Large Language Models (LLMs) for\n  Mixed-Integer Programs: Single-Machine Scheduling",
    "abstract": "Our study contributes to the scheduling and combinatorial optimization\nliterature with new heuristics discovered by leveraging the power of Large\nLanguage Models (LLMs). We focus on the single-machine total tardiness (SMTT)\nproblem, which aims to minimize total tardiness by sequencing n jobs on a\nsingle processor without preemption, given processing times and due dates. We\ndevelop and benchmark two novel LLM-discovered heuristics, the EDD Challenger\n(EDDC) and MDD Challenger (MDDC), inspired by the well-known Earliest Due Date\n(EDD) and Modified Due Date (MDD) rules. In contrast to prior studies that\nemployed simpler rule-based heuristics, we evaluate our LLM-discovered\nalgorithms using rigorous criteria, including optimality gaps and solution time\nderived from a mixed-integer programming (MIP) formulation of SMTT. We compare\ntheir performance against state-of-the-art heuristics and exact methods across\nvarious job sizes (20, 100, 200, and 500 jobs). For instances with more than\n100 jobs, exact methods such as MIP and dynamic programming become\ncomputationally intractable. Up to 500 jobs, EDDC improves upon the classic EDD\nrule and another widely used algorithm in the literature. MDDC consistently\noutperforms traditional heuristics and remains competitive with exact\napproaches, particularly on larger and more complex instances. This study shows\nthat human-LLM collaboration can produce scalable, high-performing heuristics\nfor NP-hard constrained combinatorial optimization, even under limited\nresources when effectively configured.",
    "categories": [
      "cs.AI",
      "cs.LG",
      "cs.NE",
      "math.CO",
      "math.OC"
    ],
    "published": "2025-10-28T02:43:04Z",
    "authors": [
      "\u0130brahim O\u011fuz \u00c7etinkaya",
      "\u0130. Esra B\u00fcy\u00fcktahtak\u0131n",
      "Parshin Shojaee",
      "Chandan K. Reddy"
    ],
    "pdf_url": "http://arxiv.org/pdf/2510.24013v1"
  },
  {
    "id": "2510.24012v1",
    "title": "Training-Free Safe Text Embedding Guidance for Text-to-Image Diffusion\n  Models",
    "abstract": "Text-to-image models have recently made significant advances in generating\nrealistic and semantically coherent images, driven by advanced diffusion models\nand large-scale web-crawled datasets. However, these datasets often contain\ninappropriate or biased content, raising concerns about the generation of\nharmful outputs when provided with malicious text prompts. We propose Safe Text\nembedding Guidance (STG), a training-free approach to improve the safety of\ndiffusion models by guiding the text embeddings during sampling. STG adjusts\nthe text embeddings based on a safety function evaluated on the expected final\ndenoised image, allowing the model to generate safer outputs without additional\ntraining. Theoretically, we show that STG aligns the underlying model\ndistribution with safety constraints, thereby achieving safer outputs while\nminimally affecting generation quality. Experiments on various safety\nscenarios, including nudity, violence, and artist-style removal, show that STG\nconsistently outperforms both training-based and training-free baselines in\nremoving unsafe content while preserving the core semantic intent of input\nprompts. Our code is available at https://github.com/aailab-kaist/STG.",
    "categories": [
      "cs.LG",
      "cs.AI"
    ],
    "published": "2025-10-28T02:37:20Z",
    "authors": [
      "Byeonghu Na",
      "Mina Kang",
      "Jiseok Kwak",
      "Minsang Park",
      "Jiwoo Shin",
      "SeJoon Jun",
      "Gayoung Lee",
      "Jin-Hwa Kim",
      "Il-Chul Moon"
    ],
    "pdf_url": "http://arxiv.org/pdf/2510.24012v1"
  },
  {
    "id": "2510.24010v1",
    "title": "Mars-Bench: A Benchmark for Evaluating Foundation Models for Mars\n  Science Tasks",
    "abstract": "Foundation models have enabled rapid progress across many specialized domains\nby leveraging large-scale pre-training on unlabeled data, demonstrating strong\ngeneralization to a variety of downstream tasks. While such models have gained\nsignificant attention in fields like Earth Observation, their application to\nMars science remains limited. A key enabler of progress in other domains has\nbeen the availability of standardized benchmarks that support systematic\nevaluation. In contrast, Mars science lacks such benchmarks and standardized\nevaluation frameworks, which have limited progress toward developing foundation\nmodels for Martian tasks. To address this gap, we introduce Mars-Bench, the\nfirst benchmark designed to systematically evaluate models across a broad range\nof Mars-related tasks using both orbital and surface imagery. Mars-Bench\ncomprises 20 datasets spanning classification, segmentation, and object\ndetection, focused on key geologic features such as craters, cones, boulders,\nand frost. We provide standardized, ready-to-use datasets and baseline\nevaluations using models pre-trained on natural images, Earth satellite data,\nand state-of-the-art vision-language models. Results from all analyses suggest\nthat Mars-specific foundation models may offer advantages over general-domain\ncounterparts, motivating further exploration of domain-adapted pre-training.\nMars-Bench aims to establish a standardized foundation for developing and\ncomparing machine learning models for Mars science. Our data, models, and code\nare available at: https://mars-bench.github.io/.",
    "categories": [
      "cs.CV",
      "cs.AI",
      "cs.LG"
    ],
    "published": "2025-10-28T02:34:08Z",
    "authors": [
      "Mirali Purohit",
      "Bimal Gajera",
      "Vatsal Malaviya",
      "Irish Mehta",
      "Kunal Kasodekar",
      "Jacob Adler",
      "Steven Lu",
      "Umaa Rebbapragada",
      "Hannah Kerner"
    ],
    "pdf_url": "http://arxiv.org/pdf/2510.24010v1"
  },
  {
    "id": "2510.23999v2",
    "title": "Auto-Adaptive PINNs with Applications to Phase Transitions",
    "abstract": "We propose an adaptive sampling method for the training of Physics Informed\nNeural Networks (PINNs) which allows for sampling based on an arbitrary\nproblem-specific heuristic which may depend on the network and its gradients.\nIn particular we focus our analysis on the Allen-Cahn equations, attempting to\naccurately resolve the characteristic interfacial regions using a PINN without\nany post-hoc resampling. In experiments, we show the effectiveness of these\nmethods over residual-adaptive frameworks.",
    "categories": [
      "math.NA",
      "cs.LG",
      "cs.NA"
    ],
    "published": "2025-10-28T02:03:39Z",
    "authors": [
      "Kevin Buck",
      "Woojeong Kim"
    ],
    "pdf_url": "http://arxiv.org/pdf/2510.23999v2"
  },
  {
    "id": "2510.23994v1",
    "title": "Predicting Barge Tow Size on Inland Waterways Using Vessel Trajectory\n  Derived Features: Proof of Concept",
    "abstract": "Accurate, real-time estimation of barge quantity on inland waterways remains\na critical challenge due to the non-self-propelled nature of barges and the\nlimitations of existing monitoring systems. This study introduces a novel\nmethod to use Automatic Identification System (AIS) vessel tracking data to\npredict the number of barges in tow using Machine Learning (ML). To train and\ntest the model, barge instances were manually annotated from satellite scenes\nacross the Lower Mississippi River. Labeled images were matched to AIS vessel\ntracks using a spatiotemporal matching procedure. A comprehensive set of 30\nAIS-derived features capturing vessel geometry, dynamic movement, and\ntrajectory patterns were created and evaluated using Recursive Feature\nElimination (RFE) to identify the most predictive variables. Six regression\nmodels, including ensemble, kernel-based, and generalized linear approaches,\nwere trained and evaluated. The Poisson Regressor model yielded the best\nperformance, achieving a Mean Absolute Error (MAE) of 1.92 barges using 12 of\nthe 30 features. The feature importance analysis revealed that metrics\ncapturing vessel maneuverability such as course entropy, speed variability and\ntrip length were most predictive of barge count. The proposed approach provides\na scalable, readily implementable method for enhancing Maritime Domain\nAwareness (MDA), with strong potential applications in lock scheduling, port\nmanagement, and freight planning. Future work will expand the proof of concept\npresented here to explore model transferability to other inland rivers with\ndiffering operational and environmental conditions.",
    "categories": [
      "cs.LG"
    ],
    "published": "2025-10-28T01:51:23Z",
    "authors": [
      "Geoffery Agorku",
      "Sarah Hernandez",
      "Hayley Hames",
      "Cade Wagner"
    ],
    "pdf_url": "http://arxiv.org/pdf/2510.23994v1"
  },
  {
    "id": "2510.23992v1",
    "title": "Optimal Arm Elimination Algorithms for Combinatorial Bandits",
    "abstract": "Combinatorial bandits extend the classical bandit framework to settings where\nthe learner selects multiple arms in each round, motivated by applications such\nas online recommendation and assortment optimization. While extensions of upper\nconfidence bound (UCB) algorithms arise naturally in this context, adapting arm\nelimination methods has proved more challenging. We introduce a novel\nelimination scheme that partitions arms into three categories (confirmed,\nactive, and eliminated), and incorporates explicit exploration to update these\nsets. We demonstrate the efficacy of our algorithm in two settings: the\ncombinatorial multi-armed bandit with general graph feedback, and the\ncombinatorial linear contextual bandit. In both cases, our approach achieves\nnear-optimal regret, whereas UCB-based methods can provably fail due to\ninsufficient explicit exploration. Matching lower bounds are also provided.",
    "categories": [
      "cs.LG",
      "cs.IT",
      "math.IT",
      "stat.ML"
    ],
    "published": "2025-10-28T01:50:24Z",
    "authors": [
      "Yuxiao Wen",
      "Yanjun Han",
      "Zhengyuan Zhou"
    ],
    "pdf_url": "http://arxiv.org/pdf/2510.23992v1"
  },
  {
    "id": "2510.23986v1",
    "title": "STNet: Spectral Transformation Network for Solving Operator Eigenvalue\n  Problem",
    "abstract": "Operator eigenvalue problems play a critical role in various scientific\nfields and engineering applications, yet numerical methods are hindered by the\ncurse of dimensionality. Recent deep learning methods provide an efficient\napproach to address this challenge by iteratively updating neural networks.\nThese methods' performance relies heavily on the spectral distribution of the\ngiven operator: larger gaps between the operator's eigenvalues will improve\nprecision, thus tailored spectral transformations that leverage the spectral\ndistribution can enhance their performance. Based on this observation, we\npropose the Spectral Transformation Network (STNet). During each iteration,\nSTNet uses approximate eigenvalues and eigenfunctions to perform spectral\ntransformations on the original operator, turning it into an equivalent but\neasier problem. Specifically, we employ deflation projection to exclude the\nsubspace corresponding to already solved eigenfunctions, thereby reducing the\nsearch space and avoiding converging to existing eigenfunctions. Additionally,\nour filter transform magnifies eigenvalues in the desired region and suppresses\nthose outside, further improving performance. Extensive experiments demonstrate\nthat STNet consistently outperforms existing learning-based methods, achieving\nstate-of-the-art performance in accuracy.",
    "categories": [
      "cs.LG",
      "cs.AI",
      "cs.NA",
      "math.NA"
    ],
    "published": "2025-10-28T01:43:54Z",
    "authors": [
      "Hong Wang",
      "Jiang Yixuan",
      "Jie Wang",
      "Xinyi Li",
      "Jian Luo",
      "Huanshuo Dong"
    ],
    "pdf_url": "http://arxiv.org/pdf/2510.23986v1"
  },
  {
    "id": "2510.23985v1",
    "title": "Score-based constrained generative modeling via Langevin diffusions with\n  boundary conditions",
    "abstract": "Score-based generative models based on stochastic differential equations\n(SDEs) achieve impressive performance in sampling from unknown distributions,\nbut often fail to satisfy underlying constraints. We propose a constrained\ngenerative model using kinetic (underdamped) Langevin dynamics with specular\nreflection of velocity on the boundary defining constraints. This results in\npiecewise continuously differentiable noising and denoising process where the\nlatter is characterized by a time-reversed dynamics restricted to a domain with\nboundary due to specular boundary condition. In addition, we also contribute to\nexisting reflected SDEs based constrained generative models, where the\nstochastic dynamics is restricted through an abstract local time term. By\npresenting efficient numerical samplers which converge with optimal rate in\nterms of discretizations step, we provide a comprehensive comparison of models\nbased on confined (specularly reflected kinetic) Langevin diffusion with models\nbased on reflected diffusion with local time.",
    "categories": [
      "stat.ML",
      "cs.LG",
      "cs.NA",
      "math.NA",
      "68T07, 60H35, 65C30, 60H10"
    ],
    "published": "2025-10-28T01:36:54Z",
    "authors": [
      "Adam Nordenh\u00f6g",
      "Akash Sharma"
    ],
    "pdf_url": "http://arxiv.org/pdf/2510.23985v1"
  },
  {
    "id": "2510.23980v1",
    "title": "HyperGraphX: Graph Transductive Learning with Hyperdimensional Computing\n  and Message Passing",
    "abstract": "We present a novel algorithm, \\hdgc, that marries graph convolution with\nbinding and bundling operations in hyperdimensional computing for transductive\ngraph learning. For prediction accuracy \\hdgc outperforms major and popular\ngraph neural network implementations as well as state-of-the-art\nhyperdimensional computing implementations for a collection of homophilic\ngraphs and heterophilic graphs. Compared with the most accurate learning\nmethodologies we have tested, on the same target GPU platform, \\hdgc is on\naverage 9561.0 and 144.5 times faster than \\gcnii, a graph neural network\nimplementation and HDGL, a hyperdimensional computing implementation,\nrespectively. As the majority of the learning operates on binary vectors, we\nexpect outstanding energy performance of \\hdgc on neuromorphic and emerging\nprocess-in-memory devices.",
    "categories": [
      "cs.LG",
      "cs.AI",
      "cs.NE"
    ],
    "published": "2025-10-28T01:21:54Z",
    "authors": [
      "Guojing Cong",
      "Tom Potok",
      "Hamed Poursiami",
      "Maryam Parsa"
    ],
    "pdf_url": "http://arxiv.org/pdf/2510.23980v1"
  },
  {
    "id": "2510.23977v1",
    "title": "Synergistic Neural Forecasting of Air Pollution with Stochastic Sampling",
    "abstract": "Air pollution remains a leading global health and environmental risk,\nparticularly in regions vulnerable to episodic air pollution spikes due to\nwildfires, urban haze and dust storms. Accurate forecasting of particulate\nmatter (PM) concentrations is essential to enable timely public health warnings\nand interventions, yet existing models often underestimate rare but hazardous\npollution events. Here, we present SynCast, a high-resolution neural\nforecasting model that integrates meteorological and air composition data to\nimprove predictions of both average and extreme pollution levels. Built on a\nregionally adapted transformer backbone and enhanced with a diffusion-based\nstochastic refinement module, SynCast captures the nonlinear dynamics driving\nPM spikes more accurately than existing approaches. Leveraging on harmonized\nERA5 and CAMS datasets, our model shows substantial gains in forecasting\nfidelity across multiple PM variables (PM$_1$, PM$_{2.5}$, PM$_{10}$),\nespecially under extreme conditions. We demonstrate that conventional loss\nfunctions underrepresent distributional tails (rare pollution events) and show\nthat SynCast, guided by domain-aware objectives and extreme value theory,\nsignificantly enhances performance in highly impacted regions without\ncompromising global accuracy. This approach provides a scalable foundation for\nnext-generation air quality early warning systems and supports climate-health\nrisk mitigation in vulnerable regions.",
    "categories": [
      "cs.LG",
      "cs.CV"
    ],
    "published": "2025-10-28T01:18:00Z",
    "authors": [
      "Yohan Abeysinghe",
      "Muhammad Akhtar Munir",
      "Sanoojan Baliah",
      "Ron Sarafian",
      "Fahad Shahbaz Khan",
      "Yinon Rudich",
      "Salman Khan"
    ],
    "pdf_url": "http://arxiv.org/pdf/2510.23977v1"
  },
  {
    "id": "2510.23974v1",
    "title": "Diffusion Adaptive Text Embedding for Text-to-Image Diffusion Models",
    "abstract": "Text-to-image diffusion models rely on text embeddings from a pre-trained\ntext encoder, but these embeddings remain fixed across all diffusion timesteps,\nlimiting their adaptability to the generative process. We propose Diffusion\nAdaptive Text Embedding (DATE), which dynamically updates text embeddings at\neach diffusion timestep based on intermediate perturbed data. We formulate an\noptimization problem and derive an update rule that refines the text embeddings\nat each sampling step to improve alignment and preference between the mean\npredicted image and the text. This allows DATE to dynamically adapts the text\nconditions to the reverse-diffused images throughout diffusion sampling without\nrequiring additional model training. Through theoretical analysis and empirical\nresults, we show that DATE maintains the generative capability of the model\nwhile providing superior text-image alignment over fixed text embeddings across\nvarious tasks, including multi-concept generation and text-guided image\nediting. Our code is available at https://github.com/aailab-kaist/DATE.",
    "categories": [
      "cs.LG",
      "cs.AI"
    ],
    "published": "2025-10-28T01:10:15Z",
    "authors": [
      "Byeonghu Na",
      "Minsang Park",
      "Gyuwon Sim",
      "Donghyeok Shin",
      "HeeSun Bae",
      "Mina Kang",
      "Se Jung Kwon",
      "Wanmo Kang",
      "Il-Chul Moon"
    ],
    "pdf_url": "http://arxiv.org/pdf/2510.23974v1"
  },
  {
    "id": "2510.23972v1",
    "title": "An efficient probabilistic hardware architecture for diffusion-like\n  models",
    "abstract": "The proliferation of probabilistic AI has promoted proposals for specialized\nstochastic computers. Despite promising efficiency gains, these proposals have\nfailed to gain traction because they rely on fundamentally limited modeling\ntechniques and exotic, unscalable hardware. In this work, we address these\nshortcomings by proposing an all-transistor probabilistic computer that\nimplements powerful denoising models at the hardware level. A system-level\nanalysis indicates that devices based on our architecture could achieve\nperformance parity with GPUs on a simple image benchmark using approximately\n10,000 times less energy.",
    "categories": [
      "cs.LG",
      "cs.AI"
    ],
    "published": "2025-10-28T01:09:19Z",
    "authors": [
      "Andra\u017e Jelin\u010di\u010d",
      "Owen Lockwood",
      "Akhil Garlapati",
      "Guillaume Verdon",
      "Trevor McCourt"
    ],
    "pdf_url": "http://arxiv.org/pdf/2510.23972v1"
  },
  {
    "id": "2510.23966v1",
    "title": "A Pragmatic Way to Measure Chain-of-Thought Monitorability",
    "abstract": "While Chain-of-Thought (CoT) monitoring offers a unique opportunity for AI\nsafety, this opportunity could be lost through shifts in training practices or\nmodel architecture. To help preserve monitorability, we propose a pragmatic way\nto measure two components of it: legibility (whether the reasoning can be\nfollowed by a human) and coverage (whether the CoT contains all the reasoning\nneeded for a human to also produce the final output). We implement these\nmetrics with an autorater prompt that enables any capable LLM to compute the\nlegibility and coverage of existing CoTs. After sanity-checking our prompted\nautorater with synthetic CoT degradations, we apply it to several frontier\nmodels on challenging benchmarks, finding that they exhibit high\nmonitorability. We present these metrics, including our complete autorater\nprompt, as a tool for developers to track how design decisions impact\nmonitorability. While the exact prompt we share is still a preliminary version\nunder ongoing development, we are sharing it now in the hopes that others in\nthe community will find it useful. Our method helps measure the default\nmonitorability of CoT - it should be seen as a complement, not a replacement,\nfor the adversarial stress-testing needed to test robustness against\ndeliberately evasive models.",
    "categories": [
      "cs.LG",
      "cs.SE"
    ],
    "published": "2025-10-28T00:44:25Z",
    "authors": [
      "Scott Emmons",
      "Roland S. Zimmermann",
      "David K. Elson",
      "Rohin Shah"
    ],
    "pdf_url": "http://arxiv.org/pdf/2510.23966v1"
  },
  {
    "id": "2510.23965v2",
    "title": "The Sign Estimator: LLM Alignment in the Face of Choice Heterogeneity",
    "abstract": "Traditional LLM alignment methods are vulnerable to heterogeneity in human\npreferences. Fitting a na\\\"ive probabilistic model to pairwise comparison data\n(say over prompt-completion pairs) yields an inconsistent estimate of the\npopulation-average utility -a canonical measure of social welfare. We propose a\nnew method, dubbed the sign estimator, that provides a simple, provably\nconsistent, and efficient estimator by replacing cross-entropy with binary\nclassification loss in the aggregation step. This simple modification recovers\nconsistent ordinal alignment under mild assumptions and achieves the first\npolynomial finite-sample error bounds in this setting. In realistic simulations\nof LLM alignment using digital twins, the sign estimator substantially reduces\npreference distortion over a panel of simulated personas, cutting (angular)\nestimation error by nearly 35% and decreasing disagreement with true population\npreferences from 12% to 8% compared to standard RLHF. Our method also compares\nfavorably to panel data heuristics that explicitly model user heterogeneity and\nrequire tracking individual-level preference data-all while maintaining the\nimplementation simplicity of existing LLM alignment pipelines.",
    "categories": [
      "cs.AI",
      "cs.LG",
      "stat.ML"
    ],
    "published": "2025-10-28T00:42:38Z",
    "authors": [
      "Ali Aouad",
      "Aymane El Gadarri",
      "Vivek F. Farias"
    ],
    "pdf_url": "http://arxiv.org/pdf/2510.23965v2"
  },
  {
    "id": "2510.23948v1",
    "title": "ChessQA: Evaluating Large Language Models for Chess Understanding",
    "abstract": "Chess provides an ideal testbed for evaluating the reasoning, modeling, and\nabstraction capabilities of large language models (LLMs), as it has\nwell-defined structure and objective ground truth while admitting a wide\nspectrum of skill levels. However, existing evaluations of LLM ability in chess\nare ad hoc and narrow in scope, making it difficult to accurately measure LLM\nchess understanding and how it varies with scale, post-training methodologies,\nor architecture choices. We present ChessQA, a comprehensive benchmark that\nassesses LLM chess understanding across five task categories (Structural,\nMotifs, Short Tactics, Position Judgment, and Semantic), which approximately\ncorrespond to the ascending abstractions that players master as they accumulate\nchess knowledge, from understanding basic rules and learning tactical motifs to\ncorrectly calculating tactics, evaluating positions, and semantically\ndescribing high-level concepts. In this way, ChessQA captures a more\ncomprehensive picture of chess ability and understanding, going significantly\nbeyond the simple move quality evaluations done previously, and offers a\ncontrolled, consistent setting for diagnosis and comparison. Furthermore,\nChessQA is inherently dynamic, with prompts, answer keys, and construction\nscripts that can evolve as models improve. Evaluating a range of contemporary\nLLMs, we find persistent weaknesses across all five categories and provide\nresults and error analyses by category. We will release the code, periodically\nrefreshed datasets, and a public leaderboard to support further research.",
    "categories": [
      "cs.LG",
      "cs.AI"
    ],
    "published": "2025-10-28T00:02:52Z",
    "authors": [
      "Qianfeng Wen",
      "Zhenwei Tang",
      "Ashton Anderson"
    ],
    "pdf_url": "http://arxiv.org/pdf/2510.23948v1"
  },
  {
    "id": "2510.23940v1",
    "title": "Modeling Biological Multifunctionality with Echo State Networks",
    "abstract": "In this work, a three-dimensional multicomponent reaction-diffusion model has\nbeen developed, combining excitable-system dynamics with diffusion processes\nand sharing conceptual features with the FitzHugh-Nagumo model. Designed to\ncapture the spatiotemporal behavior of biological systems, particularly\nelectrophysiological processes, the model was solved numerically to generate\ntime-series data. These data were subsequently used to train and evaluate an\nEcho State Network (ESN), which successfully reproduced the system's dynamic\nbehavior. The results demonstrate that simulating biological dynamics using\ndata-driven, multifunctional ESN models is both feasible and effective.",
    "categories": [
      "cs.LG",
      "cs.AI"
    ],
    "published": "2025-10-27T23:47:51Z",
    "authors": [
      "Anastasia-Maria Leventi-Peetz",
      "J\u00f6rg-Volker Peetz",
      "Kai Weber",
      "Nikolaos Zacharis"
    ],
    "pdf_url": "http://arxiv.org/pdf/2510.23940v1"
  },
  {
    "id": "2510.23936v1",
    "title": "A data free neural operator enabling fast inference of 2D and 3D Navier\n  Stokes equations",
    "abstract": "Ensemble simulations of high-dimensional flow models (e.g., Navier Stokes\ntype PDEs) are computationally prohibitive for real time applications. Neural\noperators enable fast inference but are limited by costly data requirements and\npoor generalization to 3D flows. We present a data-free operator network for\nthe Navier Stokes equations that eliminates the need for paired solution data\nand enables robust, real time inference for large ensemble forecasting. The\nphysics-grounded architecture takes initial and boundary conditions as well as\nforcing functions, yielding solutions robust to high variability and\nperturbations. Across 2D benchmarks and 3D test cases, the method surpasses\nprior neural operators in accuracy and, for ensembles, achieves greater\nefficiency than conventional numerical solvers. Notably, it delivers accurate\nsolutions of the three dimensional Navier Stokes equations, a regime not\npreviously demonstrated for data free neural operators. By uniting a\nnumerically grounded architecture with the scalability of machine learning,\nthis approach establishes a practical pathway toward data free, high fidelity\nPDE surrogates for end to end scientific simulation and prediction.",
    "categories": [
      "cs.LG",
      "physics.flu-dyn"
    ],
    "published": "2025-10-27T23:41:42Z",
    "authors": [
      "Junho Choi",
      "Teng-Yuan Chang",
      "Namjung Kim",
      "Youngjoon Hong"
    ],
    "pdf_url": "http://arxiv.org/pdf/2510.23936v1"
  },
  {
    "id": "2510.23935v1",
    "title": "Understanding Fairness and Prediction Error through Subspace\n  Decomposition and Influence Analysis",
    "abstract": "Machine learning models have achieved widespread success but often inherit\nand amplify historical biases, resulting in unfair outcomes. Traditional\nfairness methods typically impose constraints at the prediction level, without\naddressing underlying biases in data representations. In this work, we propose\na principled framework that adjusts data representations to balance predictive\nutility and fairness. Using sufficient dimension reduction, we decompose the\nfeature space into target-relevant, sensitive, and shared components, and\ncontrol the fairness-utility trade-off by selectively removing sensitive\ninformation. We provide a theoretical analysis of how prediction error and\nfairness gaps evolve as shared subspaces are added, and employ influence\nfunctions to quantify their effects on the asymptotic behavior of parameter\nestimates. Experiments on both synthetic and real-world datasets validate our\ntheoretical insights and show that the proposed method effectively improves\nfairness while preserving predictive performance.",
    "categories": [
      "stat.ML",
      "cs.LG"
    ],
    "published": "2025-10-27T23:38:00Z",
    "authors": [
      "Enze Shi",
      "Pankaj Bhagwat",
      "Zhixian Yang",
      "Linglong Kong",
      "Bei Jiang"
    ],
    "pdf_url": "http://arxiv.org/pdf/2510.23935v1"
  },
  {
    "id": "2510.23931v1",
    "title": "Differential Privacy: Gradient Leakage Attacks in Federated Learning\n  Environments",
    "abstract": "Federated Learning (FL) allows for the training of Machine Learning models in\na collaborative manner without the need to share sensitive data. However, it\nremains vulnerable to Gradient Leakage Attacks (GLAs), which can reveal private\ninformation from the shared model updates. In this work, we investigate the\neffectiveness of Differential Privacy (DP) mechanisms - specifically, DP-SGD\nand a variant based on explicit regularization (PDP-SGD) - as defenses against\nGLAs. To this end, we evaluate the performance of several computer vision\nmodels trained under varying privacy levels on a simple classification task,\nand then analyze the quality of private data reconstructions obtained from the\nintercepted gradients in a simulated FL environment. Our results demonstrate\nthat DP-SGD significantly mitigates the risk of gradient leakage attacks,\nalbeit with a moderate trade-off in model utility. In contrast, PDP-SGD\nmaintains strong classification performance but proves ineffective as a\npractical defense against reconstruction attacks. These findings highlight the\nimportance of empirically evaluating privacy mechanisms beyond their\ntheoretical guarantees, particularly in distributed learning scenarios where\ninformation leakage may represent an unassumable critical threat to data\nsecurity and privacy.",
    "categories": [
      "cs.LG",
      "cs.CR",
      "cs.DC",
      "68T07 (Primary) 68M14, 68P27, 68Q32, 94A16, 62H35 (Secondary)",
      "I.2.11; I.2.6; C.2.4; D.4.6; K.4.1"
    ],
    "published": "2025-10-27T23:33:21Z",
    "authors": [
      "Miguel Fernandez-de-Retana",
      "Unai Zulaika",
      "Rub\u00e9n S\u00e1nchez-Corcuera",
      "Aitor Almeida"
    ],
    "pdf_url": "http://arxiv.org/pdf/2510.23931v1"
  },
  {
    "id": "2510.24801v1",
    "title": "Fortytwo: Swarm Inference with Peer-Ranked Consensus",
    "abstract": "As centralized AI hits compute ceilings and diminishing returns from\never-larger training runs, meeting demand requires an inference layer that\nscales horizontally in both capacity and capability. We present Fortytwo, a\nnovel protocol that leverages swarm intelligence principles and distributed\npairwise ranking consensus to achieve superior performance in AI inference. Our\napproach reimagines collaboration among AI nodes using swarm inference: a\npeer-ranked, reputation-weighted consensus across heterogeneous models that\nsurfaces the highest-quality responses. Using pairwise ranking with a custom\nBradley-Terry-style aggregation model, we demonstrate that swarm inference\nsubstantially outperforms majority voting, achieving 85.90% on GPQA Diamond\nversus 68.69% for majority voting with the same model set - an improvement of\n+17.21 percentage points (approximately +25.1% relative). The protocol\nincorporates on-chain reputation so node influence adapts to demonstrated\naccuracy over time, yielding a meritocratic consensus that filters low-quality\nor malicious participants. To resist Sybil attacks, Fortytwo employs\nproof-of-capability in its consensus: nodes must successfully complete\ncalibration/test requests and stake reputation to enter ranking rounds, making\nmulti-identity attacks economically unattractive while preserving openness.\nAcross six challenging benchmarks, including GPQA Diamond, LiveCodeBench, and\nAIME, our evaluation indicates higher accuracy and strong resilience to\nadversarial and noisy free-form prompting (e.g., prompt-injection degradation\nof only 0.12% versus 6.20% for a monolithic single-model baseline), while\nretaining practical deployability. Together, these results establish a\nfoundation for decentralized AI systems - democratizing access to high-quality\ninference through collective intelligence without sacrificing reliability or\nsecurity.",
    "categories": [
      "cs.LG",
      "cs.AI",
      "cs.CL",
      "cs.MA"
    ],
    "published": "2025-10-27T23:19:48Z",
    "authors": [
      "Vladyslav Larin",
      "Ihor Naumenko",
      "Aleksei Ivashov",
      "Ivan Nikitin",
      "Alexander Firsov"
    ],
    "pdf_url": "http://arxiv.org/pdf/2510.24801v1"
  },
  {
    "id": "2510.23926v1",
    "title": "Improving the Straight-Through Estimator with Zeroth-Order Information",
    "abstract": "We study the problem of training neural networks with quantized parameters.\nLearning low-precision quantized parameters by enabling computation of\ngradients via the Straight-Through Estimator (STE) can be challenging. While\nthe STE enables back-propagation, which is a first-order method, recent works\nhave explored the use of zeroth-order (ZO) gradient descent for fine-tuning. We\nnote that the STE provides high-quality biased gradients, and ZO gradients are\nunbiased but can be expensive. We thus propose First-Order-Guided Zeroth-Order\nGradient Descent (FOGZO) that reduces STE bias while reducing computations\nrelative to ZO methods. Empirically, we show FOGZO improves the tradeoff\nbetween quality and training time in Quantization-Aware Pre-Training.\nSpecifically, versus STE at the same number of iterations, we show a 1-8\\%\naccuracy improvement for DeiT Tiny/Small, 1-2\\% accuracy improvement on ResNet\n18/50, and 1-22 perplexity point improvement for LLaMA models with up to 0.3\nbillion parameters. For the same loss, FOGZO yields a 796$\\times$ reduction in\ncomputation versus n-SPSA for a 2-layer MLP on MNIST. Code is available at\nhttps://github.com/1733116199/fogzo.",
    "categories": [
      "cs.LG"
    ],
    "published": "2025-10-27T23:14:59Z",
    "authors": [
      "Ningfeng Yang",
      "Tor M. Aamodt"
    ],
    "pdf_url": "http://arxiv.org/pdf/2510.23926v1"
  },
  {
    "id": "2510.23921v1",
    "title": "Breaking the Benchmark: Revealing LLM Bias via Minimal Contextual\n  Augmentation",
    "abstract": "Large Language Models have been shown to demonstrate stereotypical biases in\ntheir representations and behavior due to the discriminative nature of the data\nthat they have been trained on. Despite significant progress in the development\nof methods and models that refrain from using stereotypical information in\ntheir decision-making, recent work has shown that approaches used for bias\nalignment are brittle. In this work, we introduce a novel and general\naugmentation framework that involves three plug-and-play steps and is\napplicable to a number of fairness evaluation benchmarks. Through application\nof augmentation to a fairness evaluation dataset (Bias Benchmark for Question\nAnswering (BBQ)), we find that Large Language Models (LLMs), including\nstate-of-the-art open and closed weight models, are susceptible to\nperturbations to their inputs, showcasing a higher likelihood to behave\nstereotypically. Furthermore, we find that such models are more likely to have\nbiased behavior in cases where the target demographic belongs to a community\nless studied by the literature, underlining the need to expand the fairness and\nsafety research to include more diverse communities.",
    "categories": [
      "cs.CL",
      "cs.LG"
    ],
    "published": "2025-10-27T23:05:12Z",
    "authors": [
      "Kaveh Eskandari Miandoab",
      "Mahammed Kamruzzaman",
      "Arshia Gharooni",
      "Gene Louis Kim",
      "Vasanth Sarathy",
      "Ninareh Mehrabi"
    ],
    "pdf_url": "http://arxiv.org/pdf/2510.23921v1"
  },
  {
    "id": "2510.23914v1",
    "title": "Geometry-Inspired Unified Framework for Discounted and Average Reward\n  MDPs",
    "abstract": "The theoretical analysis of Markov Decision Processes (MDPs) is commonly\nsplit into two cases - the average-reward case and the discounted-reward case -\nwhich, while sharing similarities, are typically analyzed separately. In this\nwork, we extend a recently introduced geometric interpretation of MDPs for the\ndiscounted-reward case to the average-reward case, thereby unifying both. This\nallows us to extend a major result known for the discounted-reward case to the\naverage-reward case: under a unique and ergodic optimal policy, the Value\nIteration algorithm achieves a geometric convergence rate.",
    "categories": [
      "cs.LG"
    ],
    "published": "2025-10-27T22:42:53Z",
    "authors": [
      "Arsenii Mustafin",
      "Xinyi Sheng",
      "Dominik Baumann"
    ],
    "pdf_url": "http://arxiv.org/pdf/2510.23914v1"
  },
  {
    "id": "2510.23912v1",
    "title": "Key and Value Weights Are Probably All You Need: On the Necessity of the\n  Query, Key, Value weight Triplet in Decoder-Only Transformers",
    "abstract": "The Query, Key, Value weight triplet is a building block of current attention\nmechanisms in state-of-the-art LLMs. We theoretically investigate whether this\ntriplet can be reduced, proving under simplifying assumptions that the Query\nweights are redundant, thereby reducing the number of non-embedding/lm-head\nparameters by over 8%. We validate the theory on full-complexity GPT-3 small\narchitectures (with layer normalization, skip connections, and weight decay)\ntrained from scratch, demonstrating that the reduced model achieves comparable\nvalidation loss to standard baselines. These findings motivate the\ninvestigation of the Query weight redundancy at scale.",
    "categories": [
      "cs.LG",
      "cs.AI"
    ],
    "published": "2025-10-27T22:39:34Z",
    "authors": [
      "Marko Karbevski",
      "Antonij Mijoski"
    ],
    "pdf_url": "http://arxiv.org/pdf/2510.23912v1"
  },
  {
    "id": "2510.23907v1",
    "title": "DynaStride: Dynamic Stride Windowing with MMCoT for Instructional\n  Multi-Scene Captioning",
    "abstract": "Scene-level captioning in instructional videos can enhance learning by\nrequiring an understanding of both visual cues and temporal structure. By\naligning visual cues with textual guidance, this understanding supports\nprocedural learning and multimodal reasoning, providing a richer context for\nskill acquisition. However, captions that fail to capture this structure may\nlack coherence and quality, which can create confusion and undermine the\nvideo's educational intent. To address this gap, we introduce DynaStride, a\npipeline to generate coherent, scene-level captions without requiring manual\nscene segmentation. Using the YouCookII dataset's scene annotations, DynaStride\nperforms adaptive frame sampling and multimodal windowing to capture key\ntransitions within each scene. It then employs a multimodal chain-of-thought\nprocess to produce multiple action-object pairs, which are refined and fused\nusing a dynamic stride window selection algorithm that adaptively balances\ntemporal context and redundancy. The final scene-level caption integrates\nvisual semantics and temporal reasoning in a single instructional caption.\nEmpirical evaluations against strong baselines, including VLLaMA3 and GPT-4o,\ndemonstrate consistent gains on both N-gram-based metrics (BLEU, METEOR) and\nsemantic similarity measures (BERTScore, CLIPScore). Qualitative analyses\nfurther show that DynaStride produces captions that are more temporally\ncoherent and informative, suggesting a promising direction for improving\nAI-powered instructional content generation.",
    "categories": [
      "cs.CV",
      "cs.AI",
      "cs.LG"
    ],
    "published": "2025-10-27T22:29:08Z",
    "authors": [
      "Eddison Pham",
      "Prisha Priyadarshini",
      "Adrian Maliackel",
      "Kanishk Bandi",
      "Cristian Meo",
      "Kevin Zhu"
    ],
    "pdf_url": "http://arxiv.org/pdf/2510.23907v1"
  },
  {
    "id": "2510.23906v2",
    "title": "Group Interventions on Deep Networks for Causal Discovery in Subsystems",
    "abstract": "Causal discovery uncovers complex relationships between variables, enhancing\npredictions, decision-making, and insights into real-world systems, especially\nin nonlinear multivariate time series. However, most existing methods primarily\nfocus on pairwise cause-effect relationships, overlooking interactions among\ngroups of variables, i.e., subsystems and their collective causal influence. In\nthis study, we introduce gCDMI, a novel multi-group causal discovery method\nthat leverages group-level interventions on trained deep neural networks and\nemploys model invariance testing to infer causal relationships. Our approach\ninvolves three key steps. First, we use deep learning to jointly model the\nstructural relationships among groups of all time series. Second, we apply\ngroup-wise interventions to the trained model. Finally, we conduct model\ninvariance testing to determine the presence of causal links among variable\ngroups. We evaluate our method on simulated datasets, demonstrating its\nsuperior performance in identifying group-level causal relationships compared\nto existing methods. Additionally, we validate our approach on real-world\ndatasets, including brain networks and climate ecosystems. Our results\nhighlight that applying group-level interventions to deep learning models,\ncombined with invariance testing, can effectively reveal complex causal\nstructures, offering valuable insights for domains such as neuroscience and\nclimate science.",
    "categories": [
      "cs.LG",
      "cs.AI"
    ],
    "published": "2025-10-27T22:26:20Z",
    "authors": [
      "Wasim Ahmad",
      "Joachim Denzler",
      "Maha Shadaydeh"
    ],
    "pdf_url": "http://arxiv.org/pdf/2510.23906v2"
  },
  {
    "id": "2510.23905v1",
    "title": "Inferring Group Intent as a Cooperative Game. An NLP-based Framework for\n  Trajectory Analysis using Graph Transformer Neural Network",
    "abstract": "This paper studies group target trajectory intent as the outcome of a\ncooperative game where the complex-spatio trajectories are modeled using an\nNLP-based generative model. In our framework, the group intent is specified by\nthe characteristic function of a cooperative game, and allocations for players\nin the cooperative game are specified by either the core, the Shapley value, or\nthe nucleolus. The resulting allocations induce probability distributions that\ngovern the coordinated spatio-temporal trajectories of the targets that reflect\nthe group's underlying intent. We address two key questions: (1) How can the\nintent of a group trajectory be optimally formalized as the characteristic\nfunction of a cooperative game? (2) How can such intent be inferred from noisy\nobservations of the targets? To answer the first question, we introduce a\nFisher-information-based characteristic function of the cooperative game, which\nyields probability distributions that generate coordinated spatio-temporal\npatterns. As a generative model for these patterns, we develop an NLP-based\ngenerative model built on formal grammar, enabling the creation of realistic\nmulti-target trajectory data. To answer the second question, we train a Graph\nTransformer Neural Network (GTNN) to infer group trajectory intent-expressed as\nthe characteristic function of the cooperative game-from observational data\nwith high accuracy. The self-attention function of the GTNN depends on the\ntrack estimates. Thus, the formulation and algorithms provide a multi-layer\napproach that spans target tracking (Bayesian signal processing) and the GTNN\n(for group intent inference).",
    "categories": [
      "eess.SP",
      "cs.LG"
    ],
    "published": "2025-10-27T22:23:53Z",
    "authors": [
      "Yiming Zhang",
      "Vikram Krishnamurthy",
      "Shashwat Jain"
    ],
    "pdf_url": "http://arxiv.org/pdf/2510.23905v1"
  },
  {
    "id": "2510.23901v1",
    "title": "RS-ORT: A Reduced-Space Branch-and-Bound Algorithm for Optimal\n  Regression Trees",
    "abstract": "Mixed-integer programming (MIP) has emerged as a powerful framework for\nlearning optimal decision trees. Yet, existing MIP approaches for regression\ntasks are either limited to purely binary features or become computationally\nintractable when continuous, large-scale data are involved. Naively binarizing\ncontinuous features sacrifices global optimality and often yields needlessly\ndeep trees. We recast the optimal regression-tree training as a two-stage\noptimization problem and propose Reduced-Space Optimal Regression Trees\n(RS-ORT) - a specialized branch-and-bound (BB) algorithm that branches\nexclusively on tree-structural variables. This design guarantees the\nalgorithm's convergence and its independence from the number of training\nsamples. Leveraging the model's structure, we introduce several bound\ntightening techniques - closed-form leaf prediction, empirical threshold\ndiscretization, and exact depth-1 subtree parsing - that combine with\ndecomposable upper and lower bounding strategies to accelerate the training.\nThe BB node-wise decomposition enables trivial parallel execution, further\nalleviating the computational intractability even for million-size datasets.\nBased on the empirical studies on several regression benchmarks containing both\nbinary and continuous features, RS-ORT also delivers superior training and\ntesting performance than state-of-the-art methods. Notably, on datasets with up\nto 2,000,000 samples with continuous features, RS-ORT can obtain guaranteed\ntraining performance with a simpler tree structure and a better generalization\nability in four hours.",
    "categories": [
      "cs.LG",
      "cs.AI"
    ],
    "published": "2025-10-27T22:17:09Z",
    "authors": [
      "Cristobal Heredia",
      "Pedro Chumpitaz-Flores",
      "Kaixun Hua"
    ],
    "pdf_url": "http://arxiv.org/pdf/2510.23901v1"
  },
  {
    "id": "2510.23891v1",
    "title": "PRO: Enabling Precise and Robust Text Watermark for Open-Source LLMs",
    "abstract": "Text watermarking for large language models (LLMs) enables model owners to\nverify text origin and protect intellectual property. While watermarking\nmethods for closed-source LLMs are relatively mature, extending them to\nopen-source models remains challenging, as developers cannot control the\ndecoding process. Consequently, owners of open-source LLMs lack practical means\nto verify whether text was generated by their models. A core difficulty lies in\nembedding watermarks directly into model weights without hurting detectability.\nA promising idea is to distill watermarks from a closed-source model into an\nopen one, but this suffers from (i) poor detectability due to mismatch between\nlearned and predefined patterns, and (ii) fragility to downstream modifications\nsuch as fine-tuning or model merging. To overcome these limitations, we propose\nPRO, a Precise and Robust text watermarking method for open-source LLMs. PRO\njointly trains a watermark policy model with the LLM, producing patterns that\nare easier for the model to learn and more consistent with detection criteria.\nA regularization term further simulates downstream perturbations and penalizes\ndegradation in watermark detectability, ensuring robustness under model edits.\nExperiments on open-source LLMs (e.g., LLaMA-3.2, LLaMA-3, Phi-2) show that PRO\nsubstantially improves both watermark detectability and resilience to model\nmodifications.",
    "categories": [
      "cs.CR",
      "cs.AI",
      "cs.LG"
    ],
    "published": "2025-10-27T22:00:49Z",
    "authors": [
      "Jiaqi Xue",
      "Yifei Zhao",
      "Mansour Al Ghanim",
      "Shangqian Gao",
      "Ruimin Sun",
      "Qian Lou",
      "Mengxin Zheng"
    ],
    "pdf_url": "http://arxiv.org/pdf/2510.23891v1"
  },
  {
    "id": "2510.23881v1",
    "title": "Generating Creative Chess Puzzles",
    "abstract": "While Generative AI rapidly advances in various domains, generating truly\ncreative, aesthetic, and counter-intuitive outputs remains a challenge. This\npaper presents an approach to tackle these difficulties in the domain of chess\npuzzles. We start by benchmarking Generative AI architectures, and then\nintroduce an RL framework with novel rewards based on chess engine search\nstatistics to overcome some of those shortcomings. The rewards are designed to\nenhance a puzzle's uniqueness, counter-intuitiveness, diversity, and realism.\nOur RL approach dramatically increases counter-intuitive puzzle generation by\n10x, from 0.22\\% (supervised) to 2.5\\%, surpassing existing dataset rates\n(2.1\\%) and the best Lichess-trained model (0.4\\%). Our puzzles meet novelty\nand diversity benchmarks, retain aesthetic themes, and are rated by human\nexperts as more creative, enjoyable, and counter-intuitive than composed book\npuzzles, even approaching classic compositions. Our final outcome is a curated\nbooklet of these AI-generated puzzles, which is acknowledged for creativity by\nthree world-renowned experts.",
    "categories": [
      "cs.AI",
      "cs.LG"
    ],
    "published": "2025-10-27T21:43:39Z",
    "authors": [
      "Xidong Feng",
      "Vivek Veeriah",
      "Marcus Chiam",
      "Michael Dennis",
      "Ryan Pachauri",
      "Thomas Tumiel",
      "Federico Barbero",
      "Johan Obando-Ceron",
      "Jiaxin Shi",
      "Satinder Singh",
      "Shaobo Hou",
      "Nenad Toma\u0161ev",
      "Tom Zahavy"
    ],
    "pdf_url": "http://arxiv.org/pdf/2510.23881v1"
  },
  {
    "id": "2510.23879v1",
    "title": "Artificial Intelligence Based Predictive Maintenance for Electric Buses",
    "abstract": "Predictive maintenance (PdM) is crucial for optimizing efficiency and\nminimizing downtime of electric buses. While these vehicles provide\nenvironmental benefits, they pose challenges for PdM due to complex electric\ntransmission and battery systems. Traditional maintenance, often based on\nscheduled inspections, struggles to capture anomalies in multi-dimensional\nreal-time CAN Bus data. This study employs a graph-based feature selection\nmethod to analyze relationships among CAN Bus parameters of electric buses and\ninvestigates the prediction performance of targeted alarms using artificial\nintelligence techniques. The raw data collected over two years underwent\nextensive preprocessing to ensure data quality and consistency. A hybrid\ngraph-based feature selection tool was developed by combining statistical\nfiltering (Pearson correlation, Cramer's V, ANOVA F-test) with\noptimization-based community detection algorithms (InfoMap, Leiden, Louvain,\nFast Greedy). Machine learning models, including SVM, Random Forest, and\nXGBoost, were optimized through grid and random search with data balancing via\nSMOTEEN and binary search-based down-sampling. Model interpretability was\nachieved using LIME to identify the features influencing predictions. The\nresults demonstrate that the developed system effectively predicts vehicle\nalarms, enhances feature interpretability, and supports proactive maintenance\nstrategies aligned with Industry 4.0 principles.",
    "categories": [
      "cs.LG"
    ],
    "published": "2025-10-27T21:39:25Z",
    "authors": [
      "Ayse Irmak Ercevik",
      "Ahmet Murat Ozbayoglu"
    ],
    "pdf_url": "http://arxiv.org/pdf/2510.23879v1"
  },
  {
    "id": "2510.23868v1",
    "title": "GIFT: Group-relative Implicit Fine Tuning Integrates GRPO with DPO and\n  UNA",
    "abstract": "I propose \\textbf{G}roup-relative \\textbf{I}mplicit \\textbf{F}ine\n\\textbf{T}uning (GIFT), a novel reinforcement learning framework for aligning\nLLMs. Instead of directly maximizing cumulative rewards like PPO or GRPO, GIFT\nminimizes the discrepancy between implicit and explicit reward models. It\ncombines three key ideas: (1) the online multi-response generation and\nnormalization of GRPO, (2) the implicit reward formulation of DPO, and (3) the\nimplicit-explicit reward alignment principle of UNA. By jointly normalizing the\nimplicit and explicit rewards, GIFT eliminates an otherwise intractable term\nthat prevents effective use of implicit rewards. This normalization transforms\nthe complex reward maximization objective into a simple mean squared error\n(MSE) loss between the normalized reward functions, converting a non-convex\noptimization problem into a convex, stable, and analytically differentiable\nformulation. Unlike offline methods such as DPO and UNA, GIFT remains on-policy\nand thus retains exploration capability. Compared to GRPO, it requires fewer\nhyperparameters, converges faster, and generalizes better with significantly\nreduced training overfitting. Empirically, GIFT achieves superior reasoning and\nalignment performance on mathematical benchmarks while remaining\ncomputationally efficient.",
    "categories": [
      "cs.LG",
      "cs.CL"
    ],
    "published": "2025-10-27T21:18:19Z",
    "authors": [
      "Zhichao Wang"
    ],
    "pdf_url": "http://arxiv.org/pdf/2510.23868v1"
  },
  {
    "id": "2510.23866v1",
    "title": "A PDE-Informed Latent Diffusion Model for 2-m Temperature Downscaling",
    "abstract": "This work presents a physics-conditioned latent diffusion model tailored for\ndynamical downscaling of atmospheric data, with a focus on reconstructing\nhigh-resolution 2-m temperature fields. Building upon a pre-existing diffusion\narchitecture and employing a residual formulation against a reference UNet, we\nintegrate a partial differential equation (PDE) loss term into the model's\ntraining objective. The PDE loss is computed in the full resolution (pixel)\nspace by decoding the latent representation and is designed to enforce physical\nconsistency through a finite-difference approximation of an effective\nadvection-diffusion balance. Empirical observations indicate that conventional\ndiffusion training already yields low PDE residuals, and we investigate how\nfine-tuning with this additional loss further regularizes the model and\nenhances the physical plausibility of the generated fields. The entirety of our\ncodebase is available on Github, for future reference and development.",
    "categories": [
      "cs.LG",
      "cs.AI"
    ],
    "published": "2025-10-27T21:17:03Z",
    "authors": [
      "Paul Rosu",
      "Muchang Bahng",
      "Erick Jiang",
      "Rico Zhu",
      "Vahid Tarokh"
    ],
    "pdf_url": "http://arxiv.org/pdf/2510.23866v1"
  },
  {
    "id": "2510.23831v1",
    "title": "Testing-driven Variable Selection in Bayesian Modal Regression",
    "abstract": "We propose a Bayesian variable selection method in the framework of modal\nregression for heavy-tailed responses. An efficient expectation-maximization\nalgorithm is employed to expedite parameter estimation. A test statistic is\nconstructed to exploit the shape of the model error distribution to effectively\nseparate informative covariates from unimportant ones. Through simulations, we\ndemonstrate and evaluate the efficacy of the proposed method in identifying\nimportant covariates in the presence of non-Gaussian model errors. Finally, we\napply the proposed method to analyze two datasets arising in genetic and\nepigenetic studies.",
    "categories": [
      "stat.ME",
      "cs.LG",
      "stat.CO",
      "stat.ML",
      "62J05, 62J07, 62F15, 62F40"
    ],
    "published": "2025-10-27T20:17:34Z",
    "authors": [
      "Jiasong Duan",
      "Hongmei Zhang",
      "Xianzheng Huang"
    ],
    "pdf_url": "http://arxiv.org/pdf/2510.23831v1"
  },
  {
    "id": "2510.23818v1",
    "title": "ScaLoRA: Optimally Scaled Low-Rank Adaptation for Efficient High-Rank\n  Fine-Tuning",
    "abstract": "As large language models (LLMs) continue to scale in size, the computational\noverhead has become a major bottleneck for task-specific fine-tuning. While\nlow-rank adaptation (LoRA) effectively curtails this cost by confining the\nweight updates to a low-dimensional subspace, such a restriction can hinder\neffectiveness and slow convergence. This contribution deals with these\nlimitations by accumulating progressively a high-rank weight update from\nconsecutive low-rank increments. Specifically, the per update optimal low-rank\nmatrix is identified to minimize the loss function and closely approximate full\nfine-tuning. To endow efficient and seamless optimization without restarting,\nthis optimal choice is formed by appropriately scaling the columns of the\noriginal low-rank matrix. Rigorous performance guarantees reveal that the\noptimal scaling can be found analytically. Extensive numerical tests with\npopular LLMs scaling up to 12 billion parameters demonstrate a consistent\nperformance gain and fast convergence relative to state-of-the-art LoRA\nvariants on diverse tasks including natural language understanding, commonsense\nreasoning, and mathematical problem solving.",
    "categories": [
      "cs.LG"
    ],
    "published": "2025-10-27T19:59:46Z",
    "authors": [
      "Yilang Zhang",
      "Xiaodong Yang",
      "Yiwei Cai",
      "Georgios B. Giannakis"
    ],
    "pdf_url": "http://arxiv.org/pdf/2510.23818v1"
  },
  {
    "id": "2510.23817v1",
    "title": "Combining SHAP and Causal Analysis for Interpretable Fault Detection in\n  Industrial Processes",
    "abstract": "Industrial processes generate complex data that challenge fault detection\nsystems, often yielding opaque or underwhelming results despite advanced\nmachine learning techniques. This study tackles such difficulties using the\nTennessee Eastman Process, a well-established benchmark known for its intricate\ndynamics, to develop an innovative fault detection framework. Initial attempts\nwith standard models revealed limitations in both performance and\ninterpretability, prompting a shift toward a more tractable approach. By\nemploying SHAP (SHapley Additive exPlanations), we transform the problem into a\nmore manageable and transparent form, pinpointing the most critical process\nfeatures driving fault predictions. This reduction in complexity unlocks the\nability to apply causal analysis through Directed Acyclic Graphs, generated by\nmultiple algorithms, to uncover the underlying mechanisms of fault propagation.\nThe resulting causal structures align strikingly with SHAP findings,\nconsistently highlighting key process elements-like cooling and separation\nsystems-as pivotal to fault development. Together, these methods not only\nenhance detection accuracy but also provide operators with clear, actionable\ninsights into fault origins, a synergy that, to our knowledge, has not been\npreviously explored in this context. This dual approach bridges predictive\npower with causal understanding, offering a robust tool for monitoring complex\nmanufacturing environments and paving the way for smarter, more interpretable\nfault detection in industrial systems.",
    "categories": [
      "cs.LG",
      "stat.ME"
    ],
    "published": "2025-10-27T19:56:46Z",
    "authors": [
      "Pedro Cortes dos Santos",
      "Matheus Becali Rocha",
      "Renato A Krohling"
    ],
    "pdf_url": "http://arxiv.org/pdf/2510.23817v1"
  },
  {
    "id": "2510.23810v1",
    "title": "A Physics-informed Multi-resolution Neural Operator",
    "abstract": "The predictive accuracy of operator learning frameworks depends on the\nquality and quantity of available training data (input-output function pairs),\noften requiring substantial amounts of high-fidelity data, which can be\nchallenging to obtain in some real-world engineering applications. These\ndatasets may be unevenly discretized from one realization to another, with the\ngrid resolution varying across samples. In this study, we introduce a\nphysics-informed operator learning approach by extending the Resolution\nIndependent Neural Operator (RINO) framework to a fully data-free setup,\naddressing both challenges simultaneously. Here, the arbitrarily (but\nsufficiently finely) discretized input functions are projected onto a latent\nembedding space (i.e., a vector space of finite dimensions), using pre-trained\nbasis functions. The operator associated with the underlying partial\ndifferential equations (PDEs) is then approximated by a simple multi-layer\nperceptron (MLP), which takes as input a latent code along with spatiotemporal\ncoordinates to produce the solution in the physical space. The PDEs are\nenforced via a finite difference solver in the physical space. The validation\nand performance of the proposed method are benchmarked on several numerical\nexamples with multi-resolution data, where input functions are sampled at\nvarying resolutions, including both coarse and fine discretizations.",
    "categories": [
      "cs.LG",
      "math.AP",
      "physics.comp-ph",
      "stat.ML"
    ],
    "published": "2025-10-27T19:50:02Z",
    "authors": [
      "Sumanta Roy",
      "Bahador Bahmani",
      "Ioannis G. Kevrekidis",
      "Michael D. Shields"
    ],
    "pdf_url": "http://arxiv.org/pdf/2510.23810v1"
  },
  {
    "id": "2510.23804v1",
    "title": "How do simple rotations affect the implicit bias of Adam?",
    "abstract": "Adaptive gradient methods such as Adam and Adagrad are widely used in machine\nlearning, yet their effect on the generalization of learned models -- relative\nto methods like gradient descent -- remains poorly understood. Prior work on\nbinary classification suggests that Adam exhibits a ``richness bias,'' which\ncan help it learn nonlinear decision boundaries closer to the Bayes-optimal\ndecision boundary relative to gradient descent. However, the coordinate-wise\npreconditioning scheme employed by Adam renders the overall method sensitive to\northogonal transformations of feature space. We show that this sensitivity can\nmanifest as a reversal of Adam's competitive advantage: even small rotations of\nthe underlying data distribution can make Adam forfeit its richness bias and\nconverge to a linear decision boundary that is farther from the Bayes-optimal\ndecision boundary than the one learned by gradient descent. To alleviate this\nissue, we show that a recently proposed reparameterization method -- which\napplies an orthogonal transformation to the optimization objective -- endows\nany first-order method with equivariance to data rotations, and we empirically\ndemonstrate its ability to restore Adam's bias towards rich decision\nboundaries.",
    "categories": [
      "cs.LG"
    ],
    "published": "2025-10-27T19:38:46Z",
    "authors": [
      "Adela DePavia",
      "Vasileios Charisopoulos",
      "Rebecca Willett"
    ],
    "pdf_url": "http://arxiv.org/pdf/2510.23804v1"
  },
  {
    "id": "2510.23802v1",
    "title": "Learning Interpretable Features in Audio Latent Spaces via Sparse\n  Autoencoders",
    "abstract": "While sparse autoencoders (SAEs) successfully extract interpretable features\nfrom language models, applying them to audio generation faces unique\nchallenges: audio's dense nature requires compression that obscures semantic\nmeaning, and automatic feature characterization remains limited. We propose a\nframework for interpreting audio generative models by mapping their latent\nrepresentations to human-interpretable acoustic concepts. We train SAEs on\naudio autoencoder latents, then learn linear mappings from SAE features to\ndiscretized acoustic properties (pitch, amplitude, and timbre). This enables\nboth controllable manipulation and analysis of the AI music generation process,\nrevealing how acoustic properties emerge during synthesis. We validate our\napproach on continuous (DiffRhythm-VAE) and discrete (EnCodec, WavTokenizer)\naudio latent spaces, and analyze DiffRhythm, a state-of-the-art text-to-music\nmodel, to demonstrate how pitch, timbre, and loudness evolve throughout\ngeneration. While our work is only done on audio modality, our framework can be\nextended to interpretable analysis of visual latent space generation models.",
    "categories": [
      "cs.LG",
      "cs.SD"
    ],
    "published": "2025-10-27T19:35:39Z",
    "authors": [
      "Nathan Paek",
      "Yongyi Zang",
      "Qihui Yang",
      "Randal Leistikow"
    ],
    "pdf_url": "http://arxiv.org/pdf/2510.23802v1"
  },
  {
    "id": "2510.23794v1",
    "title": "Revealing the Potential of Learnable Perturbation Ensemble Forecast\n  Model for Tropical Cyclone Prediction",
    "abstract": "Tropical cyclones (TCs) are highly destructive and inherently uncertain\nweather systems. Ensemble forecasting helps quantify these uncertainties, yet\ntraditional systems are constrained by high computational costs and limited\ncapability to fully represent atmospheric nonlinearity. FuXi-ENS introduces a\nlearnable perturbation scheme for ensemble generation, representing a novel\nAI-based forecasting paradigm. Here, we systematically compare FuXi-ENS with\nECMWF-ENS using all 90 global TCs in 2018, examining their performance in\nTC-related physical variables, track and intensity forecasts, and the\nassociated dynamical and thermodynamical fields. FuXi-ENS demonstrates clear\nadvantages in predicting TC-related physical variables, and achieves more\naccurate track forecasts with reduced ensemble spread, though it still\nunderestimates intensity relative to observations. Further dynamical and\nthermodynamical analyses reveal that FuXi-ENS better captures large-scale\ncirculation, with moisture turbulent energy more tightly concentrated around\nthe TC warm core, whereas ECMWF-ENS exhibits a more dispersed distribution.\nThese findings highlight the potential of learnable perturbations to improve TC\nforecasting skill and provide valuable insights for advancing AI-based ensemble\nprediction of extreme weather events that have significant societal impacts.",
    "categories": [
      "cs.LG"
    ],
    "published": "2025-10-27T19:27:04Z",
    "authors": [
      "Jun Liu",
      "Tao Zhou",
      "Jiarui Li",
      "Xiaohui Zhong",
      "Peng Zhang",
      "Jie Feng",
      "Lei Chen",
      "Hao Li"
    ],
    "pdf_url": "http://arxiv.org/pdf/2510.23794v1"
  },
  {
    "id": "2510.23786v1",
    "title": "Relaxed Sequence Sampling for Diverse Protein Design",
    "abstract": "Protein design using structure prediction models such as AlphaFold2 has shown\nremarkable success, but existing approaches like relaxed sequence optimization\n(RSO) rely on single-path gradient descent and ignore sequence-space\nconstraints, limiting diversity and designability. We introduce Relaxed\nSequence Sampling (RSS), a Markov chain Monte Carlo (MCMC) framework that\nintegrates structural and evolutionary information for protein design. RSS\noperates in continuous logit space, combining gradient-guided exploration with\nprotein language model-informed jumps. Its energy function couples\nAlphaFold2-derived structural objectives with ESM2-derived sequence priors,\nbalancing accuracy and biological plausibility. In an in silico protein binder\ndesign task, RSS produces 5$\\times$ more designable structures and 2-3$\\times$\ngreater structural diversity than RSO baselines, at equal computational cost.\nThese results highlight RSS as a principled approach for efficiently exploring\nthe protein design landscape.",
    "categories": [
      "cs.LG"
    ],
    "published": "2025-10-27T19:18:36Z",
    "authors": [
      "Joohwan Ko",
      "Aristofanis Rontogiannis",
      "Yih-En Andrew Ban",
      "Axel Elaldi",
      "Nicholas Franklin"
    ],
    "pdf_url": "http://arxiv.org/pdf/2510.23786v1"
  },
  {
    "id": "2510.23772v1",
    "title": "Evaluating In Silico Creativity: An Expert Review of AI Chess\n  Compositions",
    "abstract": "The rapid advancement of Generative AI has raised significant questions\nregarding its ability to produce creative and novel outputs. Our recent work\ninvestigates this question within the domain of chess puzzles and presents an\nAI system designed to generate puzzles characterized by aesthetic appeal,\nnovelty, counter-intuitive and unique solutions. We briefly discuss our method\nbelow and refer the reader to the technical paper for more details. To assess\nour system's creativity, we presented a curated booklet of AI-generated puzzles\nto three world-renowned experts: International Master for chess compositions\nAmatzia Avni, Grandmaster Jonathan Levitt, and Grandmaster Matthew Sadler. All\nthree are noted authors on chess aesthetics and the evolving role of computers\nin the game. They were asked to select their favorites and explain what made\nthem appealing, considering qualities such as their creativity, level of\nchallenge, or aesthetic design.",
    "categories": [
      "cs.AI",
      "cs.LG"
    ],
    "published": "2025-10-27T19:00:02Z",
    "authors": [
      "Vivek Veeriah",
      "Federico Barbero",
      "Marcus Chiam",
      "Xidong Feng",
      "Michael Dennis",
      "Ryan Pachauri",
      "Thomas Tumiel",
      "Johan Obando-Ceron",
      "Jiaxin Shi",
      "Shaobo Hou",
      "Satinder Singh",
      "Nenad Toma\u0161ev",
      "Tom Zahavy"
    ],
    "pdf_url": "http://arxiv.org/pdf/2510.23772v1"
  },
  {
    "id": "2510.23756v1",
    "title": "Explaining Robustness to Catastrophic Forgetting Through Incremental\n  Concept Formation",
    "abstract": "Catastrophic forgetting remains a central challenge in continual learning,\nwhere models are required to integrate new knowledge over time without losing\nwhat they have previously learned. In prior work, we introduced Cobweb/4V, a\nhierarchical concept formation model that exhibited robustness to catastrophic\nforgetting in visual domains. Motivated by this robustness, we examine three\nhypotheses regarding the factors that contribute to such stability: (1)\nadaptive structural reorganization enhances knowledge retention, (2) sparse and\nselective updates reduce interference, and (3) information-theoretic learning\nbased on sufficiency statistics provides advantages over gradient-based\nbackpropagation. To test these hypotheses, we compare Cobweb/4V with neural\nbaselines, including CobwebNN, a neural implementation of the Cobweb framework\nintroduced in this work. Experiments on datasets of varying complexity (MNIST,\nFashion-MNIST, MedMNIST, and CIFAR-10) show that adaptive restructuring\nenhances learning plasticity, sparse updates help mitigate interference, and\nthe information-theoretic learning process preserves prior knowledge without\nrevisiting past data. Together, these findings provide insight into mechanisms\nthat can mitigate catastrophic forgetting and highlight the potential of\nconcept-based, information-theoretic approaches for building stable and\nadaptive continual learning systems.",
    "categories": [
      "cs.LG",
      "cs.AI"
    ],
    "published": "2025-10-27T18:41:25Z",
    "authors": [
      "Nicki Barari",
      "Edward Kim",
      "Christopher MacLellan"
    ],
    "pdf_url": "http://arxiv.org/pdf/2510.23756v1"
  },
  {
    "id": "2510.23751v1",
    "title": "Debiasing Reward Models by Representation Learning with Guarantees",
    "abstract": "Recent alignment techniques, such as reinforcement learning from human\nfeedback, have been widely adopted to align large language models with human\npreferences by learning and leveraging reward models. In practice, these models\noften exploit spurious correlations, involving, e.g., response length,\ndiscrimination, sycophancy, and conceptual bias, which is a problem that has\nreceived increasing attention. In this work, we propose a principled framework\nthat mitigates these biases in reward models while preserving the underlying\nfactors that reflect intended preferences. We first provide a formulation of\nthe data-generating process, assuming that the observed data (e.g., text) is\ngenerated from both spurious and non-spurious latent variables. We show that,\ninterestingly, these non-spurious latent variables can be theoretically\nidentified from data, regardless of whether a surrogate for the spurious latent\nvariables is available. This further inspires a practical method that uses\nvariational inference to recover these variables and leverages them to train\nreward models. Experiments on synthetic and real-world datasets demonstrate\nthat our method effectively mitigates spurious correlation issues and yields\nmore robust reward models.",
    "categories": [
      "cs.LG",
      "cs.AI",
      "stat.ML"
    ],
    "published": "2025-10-27T18:37:57Z",
    "authors": [
      "Ignavier Ng",
      "Patrick Bl\u00f6baum",
      "Siddharth Bhandari",
      "Kun Zhang",
      "Shiva Kasiviswanathan"
    ],
    "pdf_url": "http://arxiv.org/pdf/2510.23751v1"
  },
  {
    "id": "2510.23749v1",
    "title": "Re-envisioning Euclid Galaxy Morphology: Identifying and Interpreting\n  Features with Sparse Autoencoders",
    "abstract": "Sparse Autoencoders (SAEs) can efficiently identify candidate monosemantic\nfeatures from pretrained neural networks for galaxy morphology. We demonstrate\nthis on Euclid Q1 images using both supervised (Zoobot) and new self-supervised\n(MAE) models. Our publicly released MAE achieves superhuman image\nreconstruction performance. While a Principal Component Analysis (PCA) on the\nsupervised model primarily identifies features already aligned with the Galaxy\nZoo decision tree, SAEs can identify interpretable features outside of this\nframework. SAE features also show stronger alignment than PCA with Galaxy Zoo\nlabels. Although challenges in interpretability remain, SAEs provide a powerful\nengine for discovering astrophysical phenomena beyond the confines of\nhuman-defined classification.",
    "categories": [
      "astro-ph.IM",
      "cs.LG"
    ],
    "published": "2025-10-27T18:28:56Z",
    "authors": [
      "John F. Wu",
      "Michael Walmsley"
    ],
    "pdf_url": "http://arxiv.org/pdf/2510.23749v1"
  },
  {
    "id": "2510.23746v1",
    "title": "Test-Time Tuned Language Models Enable End-to-end De Novo Molecular\n  Structure Generation from MS/MS Spectra",
    "abstract": "Tandem Mass Spectrometry enables the identification of unknown compounds in\ncrucial fields such as metabolomics, natural product discovery and\nenvironmental analysis. However, current methods rely on database matching from\npreviously observed molecules, or on multi-step pipelines that require\nintermediate fragment or fingerprint prediction. This makes finding the correct\nmolecule highly challenging, particularly for compounds absent from reference\ndatabases. We introduce a framework that, by leveraging test-time tuning,\nenhances the learning of a pre-trained transformer model to address this gap,\nenabling end-to-end de novo molecular structure generation directly from the\ntandem mass spectra and molecular formulae, bypassing manual annotations and\nintermediate steps. We surpass the de-facto state-of-the-art approach DiffMS on\ntwo popular benchmarks NPLIB1 and MassSpecGym by 100% and 20%, respectively.\nTest-time tuning on experimental spectra allows the model to dynamically adapt\nto novel spectra, and the relative performance gain over conventional\nfine-tuning is of 62% on MassSpecGym. When predictions deviate from the ground\ntruth, the generated molecular candidates remain structurally accurate,\nproviding valuable guidance for human interpretation and more reliable\nidentification.",
    "categories": [
      "cs.AI",
      "cs.LG"
    ],
    "published": "2025-10-27T18:25:36Z",
    "authors": [
      "Laura Mismetti",
      "Marvin Alberts",
      "Andreas Krause",
      "Mara Graziani"
    ],
    "pdf_url": "http://arxiv.org/pdf/2510.23746v1"
  },
  {
    "id": "2510.23745v1",
    "title": "Bayesian neural networks with interpretable priors from Mercer kernels",
    "abstract": "Quantifying the uncertainty in the output of a neural network is essential\nfor deployment in scientific or engineering applications where decisions must\nbe made under limited or noisy data. Bayesian neural networks (BNNs) provide a\nframework for this purpose by constructing a Bayesian posterior distribution\nover the network parameters. However, the prior, which is of key importance in\nany Bayesian setting, is rarely meaningful for BNNs. This is because the\ncomplexity of the input-to-output map of a BNN makes it difficult to understand\nhow certain distributions enforce any interpretable constraint on the output\nspace. Gaussian processes (GPs), on the other hand, are often preferred in\nuncertainty quantification tasks due to their interpretability. The drawback is\nthat GPs are limited to small datasets without advanced techniques, which often\nrely on the covariance kernel having a specific structure. To address these\nchallenges, we introduce a new class of priors for BNNs, called Mercer priors,\nsuch that the resulting BNN has samples which approximate that of a specified\nGP. The method works by defining a prior directly over the network parameters\nfrom the Mercer representation of the covariance kernel, and does not rely on\nthe network having a specific structure. In doing so, we can exploit the\nscalability of BNNs in a meaningful Bayesian way.",
    "categories": [
      "stat.ML",
      "cs.LG"
    ],
    "published": "2025-10-27T18:25:21Z",
    "authors": [
      "Alex Alberts",
      "Ilias Bilionis"
    ],
    "pdf_url": "http://arxiv.org/pdf/2510.23745v1"
  },
  {
    "id": "2510.23727v1",
    "title": "MUStReason: A Benchmark for Diagnosing Pragmatic Reasoning in Video-LMs\n  for Multimodal Sarcasm Detection",
    "abstract": "Sarcasm is a specific type of irony which involves discerning what is said\nfrom what is meant. Detecting sarcasm depends not only on the literal content\nof an utterance but also on non-verbal cues such as speaker's tonality, facial\nexpressions and conversational context. However, current multimodal models\nstruggle with complex tasks like sarcasm detection, which require identifying\nrelevant cues across modalities and pragmatically reasoning over them to infer\nthe speaker's intention. To explore these limitations in VideoLMs, we introduce\nMUStReason, a diagnostic benchmark enriched with annotations of\nmodality-specific relevant cues and underlying reasoning steps to identify\nsarcastic intent. In addition to benchmarking sarcasm classification\nperformance in VideoLMs, using MUStReason we quantitatively and qualitatively\nevaluate the generated reasoning by disentangling the problem into perception\nand reasoning, we propose PragCoT, a framework that steers VideoLMs to focus on\nimplied intentions over literal meaning, a property core to detecting sarcasm.",
    "categories": [
      "cs.LG",
      "cs.CL"
    ],
    "published": "2025-10-27T18:03:11Z",
    "authors": [
      "Anisha Saha",
      "Varsha Suresh",
      "Timothy Hospedales",
      "Vera Demberg"
    ],
    "pdf_url": "http://arxiv.org/pdf/2510.23727v1"
  },
  {
    "id": "2510.23702v1",
    "title": "In Search of the Unknown Unknowns: A Multi-Metric Distance Ensemble for\n  Out of Distribution Anomaly Detection in Astronomical Surveys",
    "abstract": "Distance-based methods involve the computation of distance values between\nfeatures and are a well-established paradigm in machine learning. In anomaly\ndetection, anomalies are identified by their large distance from normal data\npoints. However, the performance of these methods often hinges on a single,\nuser-selected distance metric (e.g., Euclidean), which may not be optimal for\nthe complex, high-dimensional feature spaces common in astronomy. Here, we\nintroduce a novel anomaly detection method, Distance Multi-Metric Anomaly\nDetection (DiMMAD), which uses an ensemble of distance metrics to find\nnovelties.\n  Using multiple distance metrics is effectively equivalent to using different\ngeometries in the feature space. By using a robust ensemble of diverse distance\nmetrics, we overcome the metric-selection problem, creating an anomaly score\nthat is not reliant on any single definition of distance. We demonstrate this\nmulti-metric approach as a tool for simple, interpretable scientific discovery\non astronomical time series -- (1) with simulated data for the upcoming Vera C.\nRubin Observatory Legacy Survey of Space and Time, and (2) real data from the\nZwicky Transient Facility.\n  We find that DiMMAD excels at out-of-distribution anomaly detection --\nanomalies in the data that might be new classes -- and beats other\nstate-of-the-art methods in the goal of maximizing the diversity of new classes\ndiscovered. For rare in-distribution anomaly detection, DiMMAD performs\nsimilarly to other methods, but may allow for improved interpretability. All\nour code is open source: DiMMAD is implemented within DistClassiPy:\nhttps://github.com/sidchaini/distclassipy/, while all code to reproduce the\nresults of this paper is available here: https://github.com/sidchaini/dimmad/.",
    "categories": [
      "astro-ph.IM",
      "cs.LG"
    ],
    "published": "2025-10-27T18:00:00Z",
    "authors": [
      "Siddharth Chaini",
      "Federica B. Bianco",
      "Ashish Mahabal"
    ],
    "pdf_url": "http://arxiv.org/pdf/2510.23702v1"
  },
  {
    "id": "2510.23606v1",
    "title": "Variational Masked Diffusion Models",
    "abstract": "Masked diffusion models have recently emerged as a flexible framework for\ndiscrete generative modeling. However, a key limitation of standard masked\ndiffusion is its inability to effectively capture dependencies among tokens\nthat are predicted concurrently, leading to degraded generation quality when\ndependencies among tokens are important. To explicitly model dependencies among\ntokens, we propose Variational Masked Diffusion (VMD), a framework that\nintroduces latent variables into the masked diffusion process. Through\ncontrolled experiments on synthetic datasets, we demonstrate that VMD\nsuccessfully learns dependencies that conventional masked diffusion fails to\ncapture. We further validate the effectiveness of our approach on Sudoku\npuzzles and text datasets, where learning of dependencies among tokens improves\nglobal consistency. Across these domains, VMD enhances both generation quality\nand dependency awareness, highlighting the value of integrating variational\ninference into masked diffusion. Our code is available at:\nhttps://riccizz.github.io/VMD.",
    "categories": [
      "cs.LG",
      "cs.AI",
      "cs.CL"
    ],
    "published": "2025-10-27T17:59:57Z",
    "authors": [
      "Yichi Zhang",
      "Alex Schwing",
      "Zhizhen Zhao"
    ],
    "pdf_url": "http://arxiv.org/pdf/2510.23606v1"
  },
  {
    "id": "2510.23605v1",
    "title": "Track, Inpaint, Resplat: Subject-driven 3D and 4D Generation with\n  Progressive Texture Infilling",
    "abstract": "Current 3D/4D generation methods are usually optimized for photorealism,\nefficiency, and aesthetics. However, they often fail to preserve the semantic\nidentity of the subject across different viewpoints. Adapting generation\nmethods with one or few images of a specific subject (also known as\nPersonalization or Subject-driven generation) allows generating visual content\nthat align with the identity of the subject. However, personalized 3D/4D\ngeneration is still largely underexplored. In this work, we introduce TIRE\n(Track, Inpaint, REsplat), a novel method for subject-driven 3D/4D generation.\nIt takes an initial 3D asset produced by an existing 3D generative model as\ninput and uses video tracking to identify the regions that need to be modified.\nThen, we adopt a subject-driven 2D inpainting model for progressively infilling\nthe identified regions. Finally, we resplat the modified 2D multi-view\nobservations back to 3D while still maintaining consistency. Extensive\nexperiments demonstrate that our approach significantly improves identity\npreservation in 3D/4D generation compared to state-of-the-art methods. Our\nproject website is available at\nhttps://zsh2000.github.io/track-inpaint-resplat.github.io/.",
    "categories": [
      "cs.CV",
      "cs.AI",
      "cs.GR",
      "cs.LG",
      "cs.RO"
    ],
    "published": "2025-10-27T17:59:51Z",
    "authors": [
      "Shuhong Zheng",
      "Ashkan Mirzaei",
      "Igor Gilitschenski"
    ],
    "pdf_url": "http://arxiv.org/pdf/2510.23605v1"
  },
  {
    "id": "2510.23693v1",
    "title": "On the Societal Impact of Machine Learning",
    "abstract": "This PhD thesis investigates the societal impact of machine learning (ML). ML\nincreasingly informs consequential decisions and recommendations, significantly\naffecting many aspects of our lives. As these data-driven systems are often\ndeveloped without explicit fairness considerations, they carry the risk of\ndiscriminatory effects. The contributions in this thesis enable more\nappropriate measurement of fairness in ML systems, systematic decomposition of\nML systems to anticipate bias dynamics, and effective interventions that reduce\nalgorithmic discrimination while maintaining system utility. I conclude by\ndiscussing ongoing challenges and future research directions as ML systems,\nincluding generative artificial intelligence, become increasingly integrated\ninto society. This work offers a foundation for ensuring that ML's societal\nimpact aligns with broader social values.",
    "categories": [
      "cs.LG",
      "cs.AI",
      "cs.CY"
    ],
    "published": "2025-10-27T17:59:48Z",
    "authors": [
      "Joachim Baumann"
    ],
    "pdf_url": "http://arxiv.org/pdf/2510.23693v1"
  },
  {
    "id": "2510.24795v1",
    "title": "A Survey on Efficient Vision-Language-Action Models",
    "abstract": "Vision-Language-Action models (VLAs) represent a significant frontier in\nembodied intelligence, aiming to bridge digital knowledge with physical-world\ninteraction. While these models have demonstrated remarkable generalist\ncapabilities, their deployment is severely hampered by the substantial\ncomputational and data requirements inherent to their underlying large-scale\nfoundation models. Motivated by the urgent need to address these challenges,\nthis survey presents the first comprehensive review of Efficient\nVision-Language-Action models (Efficient VLAs) across the entire\ndata-model-training process. Specifically, we introduce a unified taxonomy to\nsystematically organize the disparate efforts in this domain, categorizing\ncurrent techniques into three core pillars: (1) Efficient Model Design,\nfocusing on efficient architectures and model compression; (2) Efficient\nTraining, which reduces computational burdens during model learning; and (3)\nEfficient Data Collection, which addresses the bottlenecks in acquiring and\nutilizing robotic data. Through a critical review of state-of-the-art methods\nwithin this framework, this survey not only establishes a foundational\nreference for the community but also summarizes representative applications,\ndelineates key challenges, and charts a roadmap for future research. We\nmaintain a continuously updated project page to track our latest developments:\nhttps://evla-survey.github.io/",
    "categories": [
      "cs.CV",
      "cs.AI",
      "cs.LG",
      "cs.RO"
    ],
    "published": "2025-10-27T17:57:33Z",
    "authors": [
      "Zhaoshu Yu",
      "Bo Wang",
      "Pengpeng Zeng",
      "Haonan Zhang",
      "Ji Zhang",
      "Lianli Gao",
      "Jingkuan Song",
      "Nicu Sebe",
      "Heng Tao Shen"
    ],
    "pdf_url": "http://arxiv.org/pdf/2510.24795v1"
  },
  {
    "id": "2510.23590v1",
    "title": "Lightweight Robust Direct Preference Optimization",
    "abstract": "Direct Preference Optimization (DPO) has become a popular method for\nfine-tuning large language models (LLMs) due to its stability and simplicity.\nHowever, it is also known to be sensitive to noise in the data and prone to\noverfitting. Recent works have proposed using distributionally robust\noptimization (DRO) to address potential noise and distributional shift in the\ndata. However, these methods often suffer from excessive conservatism and high\ncomputational cost. We propose DPO-PRO (DPO with Preference Robustness), a\nrobust fine-tuning algorithm based on DPO which accounts for uncertainty in the\npreference distribution through a lightweight DRO formulation. Unlike prior\nDRO-based variants, DPO-PRO focuses solely on uncertainty in preferences,\navoiding unnecessary conservatism and incurring negligible computational\noverhead. We further show that DPO-PRO is equivalent to a regularized DPO\nobjective that penalizes model overconfidence under weak preference signals. We\nevaluate DPO-PRO on standard alignment benchmarks and a real-world public\nhealth task. Experimental results show that our method consistently improves\nrobustness to noisy preference signals compared to existing DPO variants.",
    "categories": [
      "cs.LG"
    ],
    "published": "2025-10-27T17:55:06Z",
    "authors": [
      "Cheol Woo Kim",
      "Shresth Verma",
      "Mauricio Tec",
      "Milind Tambe"
    ],
    "pdf_url": "http://arxiv.org/pdf/2510.23590v1"
  },
  {
    "id": "2510.23581v1",
    "title": "Lookahead Anchoring: Preserving Character Identity in Audio-Driven Human\n  Animation",
    "abstract": "Audio-driven human animation models often suffer from identity drift during\ntemporal autoregressive generation, where characters gradually lose their\nidentity over time. One solution is to generate keyframes as intermediate\ntemporal anchors that prevent degradation, but this requires an additional\nkeyframe generation stage and can restrict natural motion dynamics. To address\nthis, we propose Lookahead Anchoring, which leverages keyframes from future\ntimesteps ahead of the current generation window, rather than within it. This\ntransforms keyframes from fixed boundaries into directional beacons: the model\ncontinuously pursues these future anchors while responding to immediate audio\ncues, maintaining consistent identity through persistent guidance. This also\nenables self-keyframing, where the reference image serves as the lookahead\ntarget, eliminating the need for keyframe generation entirely. We find that the\ntemporal lookahead distance naturally controls the balance between expressivity\nand consistency: larger distances allow for greater motion freedom, while\nsmaller ones strengthen identity adherence. When applied to three recent human\nanimation models, Lookahead Anchoring achieves superior lip synchronization,\nidentity preservation, and visual quality, demonstrating improved temporal\nconditioning across several different architectures. Video results are\navailable at the following link: https://lookahead-anchoring.github.io.",
    "categories": [
      "cs.CV",
      "cs.LG"
    ],
    "published": "2025-10-27T17:50:19Z",
    "authors": [
      "Junyoung Seo",
      "Rodrigo Mira",
      "Alexandros Haliassos",
      "Stella Bounareli",
      "Honglie Chen",
      "Linh Tran",
      "Seungryong Kim",
      "Zoe Landgraf",
      "Jie Shen"
    ],
    "pdf_url": "http://arxiv.org/pdf/2510.23581v1"
  },
  {
    "id": "2510.23571v1",
    "title": "RobotArena $\\infty$: Scalable Robot Benchmarking via Real-to-Sim\n  Translation",
    "abstract": "The pursuit of robot generalists - instructable agents capable of performing\ndiverse tasks across diverse environments - demands rigorous and scalable\nevaluation. Yet real-world testing of robot policies remains fundamentally\nconstrained: it is labor-intensive, slow, unsafe at scale, and difficult to\nreproduce. Existing simulation benchmarks are similarly limited, as they train\nand test policies within the same synthetic domains and cannot assess models\ntrained from real-world demonstrations or alternative simulation environments.\nAs policies expand in scope and complexity, these barriers only intensify,\nsince defining \"success\" in robotics often hinges on nuanced human judgments of\nexecution quality. In this paper, we introduce a new benchmarking framework\nthat overcomes these challenges by shifting VLA evaluation into large-scale\nsimulated environments augmented with online human feedback. Leveraging\nadvances in vision-language models, 2D-to-3D generative modeling, and\ndifferentiable rendering, our approach automatically converts video\ndemonstrations from widely used robot datasets into simulated counterparts.\nWithin these digital twins, we assess VLA policies using both automated\nVLM-guided scoring and scalable human preference judgments collected from\ncrowdworkers, transforming human involvement from tedious scene setup,\nresetting, and safety supervision into lightweight preference comparisons. To\nmeasure robustness, we systematically perturb simulated environments along\nmultiple axes, such as textures and object placements, stress-testing policy\ngeneralization under controlled variation. The result is a continuously\nevolving, reproducible, and scalable benchmark for real-world trained robot\nmanipulation policies, addressing a critical missing capability in today's\nrobotics landscape.",
    "categories": [
      "cs.RO",
      "cs.AI",
      "cs.CV",
      "cs.LG"
    ],
    "published": "2025-10-27T17:41:38Z",
    "authors": [
      "Yash Jangir",
      "Yidi Zhang",
      "Kashu Yamazaki",
      "Chenyu Zhang",
      "Kuan-Hsun Tu",
      "Tsung-Wei Ke",
      "Lei Ke",
      "Yonatan Bisk",
      "Katerina Fragkiadaki"
    ],
    "pdf_url": "http://arxiv.org/pdf/2510.23571v1"
  },
  {
    "id": "2510.23564v2",
    "title": "ReCode: Unify Plan and Action for Universal Granularity Control",
    "abstract": "Real-world tasks require decisions at varying granularities, and humans excel\nat this by leveraging a unified cognitive representation where planning is\nfundamentally understood as a high-level form of action. However, current Large\nLanguage Model (LLM)-based agents lack this crucial capability to operate\nfluidly across decision granularities. This limitation stems from existing\nparadigms that enforce a rigid separation between high-level planning and\nlow-level action, which impairs dynamic adaptability and limits generalization.\nWe propose ReCode (Recursive Code Generation), a novel paradigm that addresses\nthis limitation by unifying planning and action within a single code\nrepresentation. In this representation, ReCode treats high-level plans as\nabstract placeholder functions, which the agent then recursively decomposes\ninto finer-grained sub-functions until reaching primitive actions. This\nrecursive approach dissolves the rigid boundary between plan and action,\nenabling the agent to dynamically control its decision granularity.\nFurthermore, the recursive structure inherently generates rich,\nmulti-granularity training data, enabling models to learn hierarchical\ndecision-making processes. Extensive experiments show ReCode significantly\nsurpasses advanced baselines in inference performance and demonstrates\nexceptional data efficiency in training, validating our core insight that\nunifying planning and action through recursive code generation is a powerful\nand effective approach to achieving universal granularity control. The code is\navailable at https://github.com/FoundationAgents/ReCode.",
    "categories": [
      "cs.AI",
      "cs.CL",
      "cs.LG"
    ],
    "published": "2025-10-27T17:35:15Z",
    "authors": [
      "Zhaoyang Yu",
      "Jiayi Zhang",
      "Huixue Su",
      "Yufan Zhao",
      "Yifan Wu",
      "Mingyi Deng",
      "Jinyu Xiang",
      "Yizhang Lin",
      "Lingxiao Tang",
      "Yingchao Li",
      "Yuyu Luo",
      "Bang Liu",
      "Chenglin Wu"
    ],
    "pdf_url": "http://arxiv.org/pdf/2510.23564v2"
  },
  {
    "id": "2510.23557v1",
    "title": "Minimizing Human Intervention in Online Classification",
    "abstract": "We introduce and study an online problem arising in question answering\nsystems. In this problem, an agent must sequentially classify user-submitted\nqueries represented by $d$-dimensional embeddings drawn i.i.d. from an unknown\ndistribution. The agent may consult a costly human expert for the correct\nlabel, or guess on her own without receiving feedback. The goal is to minimize\nregret against an oracle with free expert access. When the time horizon $T$ is\nat least exponential in the embedding dimension $d$, one can learn the geometry\nof the class regions: in this regime, we propose the Conservative Hull-based\nClassifier (CHC), which maintains convex hulls of expert-labeled queries and\ncalls the expert as soon as a query lands outside all known hulls. CHC attains\n$\\mathcal{O}(\\log^d T)$ regret in $T$ and is minimax optimal for $d=1$.\nOtherwise, the geometry cannot be reliably learned without additional\ndistributional assumptions. We show that when the queries are drawn from a\nsubgaussian mixture, for $T \\le e^d$, a Center-based Classifier (CC) achieves\nregret proportional to $N\\log{N}$ where $N$ is the number of labels. To bridge\nthese regimes, we introduce the Generalized Hull-based Classifier (GHC), a\npractical extension of CHC that allows for more aggressive guessing via a\ntunable threshold parameter. Our approach is validated with experiments,\nnotably on real-world question-answering datasets using embeddings derived from\nstate-of-the-art large language models.",
    "categories": [
      "stat.ML",
      "cs.LG"
    ],
    "published": "2025-10-27T17:31:24Z",
    "authors": [
      "William R\u00e9veillard",
      "Vasileios Saketos",
      "Alexandre Proutiere",
      "Richard Combes"
    ],
    "pdf_url": "http://arxiv.org/pdf/2510.23557v1"
  },
  {
    "id": "2510.23554v1",
    "title": "A U-Net and Transformer Pipeline for Multilingual Image Translation",
    "abstract": "This paper presents an end-to-end multilingual translation pipeline that\nintegrates a custom U-Net for text detection, the Tesseract engine for text\nrecognition, and a from-scratch sequence-to-sequence (Seq2Seq) Transformer for\nNeural Machine Translation (NMT). Our approach first utilizes a U-Net model,\ntrained on a synthetic dataset , to accurately segment and detect text regions\nfrom an image. These detected regions are then processed by Tesseract to\nextract the source text. This extracted text is fed into a custom Transformer\nmodel trained from scratch on a multilingual parallel corpus spanning 5\nlanguages. Unlike systems reliant on monolithic pre-trained models, our\narchitecture emphasizes full customization and adaptability. The system is\nevaluated on its text detection accuracy, text recognition quality, and\ntranslation performance via BLEU scores. The complete pipeline demonstrates\npromising results, validating the viability of a custom-built system for\ntranslating text directly from images.",
    "categories": [
      "cs.LG",
      "cs.CL",
      "cs.CV"
    ],
    "published": "2025-10-27T17:28:55Z",
    "authors": [
      "Siddharth Sahay",
      "Radhika Agarwal"
    ],
    "pdf_url": "http://arxiv.org/pdf/2510.23554v1"
  },
  {
    "id": "2510.23535v1",
    "title": "Sequential Multi-Agent Dynamic Algorithm Configuration",
    "abstract": "Dynamic algorithm configuration (DAC) is a recent trend in automated machine\nlearning, which can dynamically adjust the algorithm's configuration during the\nexecution process and relieve users from tedious trial-and-error tuning tasks.\nRecently, multi-agent reinforcement learning (MARL) approaches have improved\nthe configuration of multiple heterogeneous hyperparameters, making various\nparameter configurations for complex algorithms possible. However, many complex\nalgorithms have inherent inter-dependencies among multiple parameters (e.g.,\ndetermining the operator type first and then the operator's parameter), which\nare, however, not considered in previous approaches, thus leading to\nsub-optimal results. In this paper, we propose the sequential multi-agent DAC\n(Seq-MADAC) framework to address this issue by considering the inherent\ninter-dependencies of multiple parameters. Specifically, we propose a\nsequential advantage decomposition network, which can leverage action-order\ninformation through sequential advantage decomposition. Experiments from\nsynthetic functions to the configuration of multi-objective optimization\nalgorithms demonstrate Seq-MADAC's superior performance over state-of-the-art\nMARL methods and show strong generalization across problem classes. Seq-MADAC\nestablishes a new paradigm for the widespread dependency-aware automated\nalgorithm configuration. Our code is available at\nhttps://github.com/lamda-bbo/seq-madac.",
    "categories": [
      "cs.LG",
      "cs.NE"
    ],
    "published": "2025-10-27T17:11:03Z",
    "authors": [
      "Chen Lu",
      "Ke Xue",
      "Lei Yuan",
      "Yao Wang",
      "Yaoyuan Wang",
      "Sheng Fu",
      "Chao Qian"
    ],
    "pdf_url": "http://arxiv.org/pdf/2510.23535v1"
  },
  {
    "id": "2510.23534v2",
    "title": "Direct Debiased Machine Learning via Bregman Divergence Minimization",
    "abstract": "We develop a direct debiased machine learning framework comprising Neyman\ntargeted estimation and generalized Riesz regression. Our framework unifies\nRiesz regression for automatic debiased machine learning, covariate balancing,\ntargeted maximum likelihood estimation (TMLE), and density-ratio estimation. In\nmany problems involving causal effects or structural models, the parameters of\ninterest depend on regression functions. Plugging regression functions\nestimated by machine learning methods into the identifying equations can yield\npoor performance because of first-stage bias. To reduce such bias, debiased\nmachine learning employs Neyman orthogonal estimating equations. Debiased\nmachine learning typically requires estimation of the Riesz representer and the\nregression function. For this problem, we develop a direct debiased machine\nlearning framework with an end-to-end algorithm. We formulate estimation of the\nnuisance parameters, the regression function and the Riesz representer, as\nminimizing the discrepancy between Neyman orthogonal scores computed with known\nand unknown nuisance parameters, which we refer to as Neyman targeted\nestimation. Neyman targeted estimation includes Riesz representer estimation,\nand we measure discrepancies using the Bregman divergence. The Bregman\ndivergence encompasses various loss functions as special cases, where the\nsquared loss yields Riesz regression and the Kullback-Leibler divergence yields\nentropy balancing. We refer to this Riesz representer estimation as generalized\nRiesz regression. Neyman targeted estimation also yields TMLE as a special case\nfor regression function estimation. Furthermore, for specific pairs of models\nand Riesz representer estimation methods, we can automatically obtain the\ncovariate balancing property without explicitly solving the covariate balancing\nobjective.",
    "categories": [
      "econ.EM",
      "cs.LG",
      "math.ST",
      "stat.ME",
      "stat.ML",
      "stat.TH"
    ],
    "published": "2025-10-27T17:10:43Z",
    "authors": [
      "Masahiro Kato"
    ],
    "pdf_url": "http://arxiv.org/pdf/2510.23534v2"
  },
  {
    "id": "2510.23532v1",
    "title": "When No Paths Lead to Rome: Benchmarking Systematic Neural Relational\n  Reasoning",
    "abstract": "Designing models that can learn to reason in a systematic way is an important\nand long-standing challenge. In recent years, a wide range of solutions have\nbeen proposed for the specific case of systematic relational reasoning,\nincluding Neuro-Symbolic approaches, variants of the Transformer architecture,\nand specialised Graph Neural Networks. However, existing benchmarks for\nsystematic relational reasoning focus on an overly simplified setting, based on\nthe assumption that reasoning can be reduced to composing relational paths. In\nfact, this assumption is hard-baked into the architecture of several recent\nmodels, leading to approaches that can perform well on existing benchmarks but\nare difficult to generalise to other settings. To support further progress in\nthe field of systematic relational reasoning with neural networks, we introduce\nNoRA, a new benchmark which adds several levels of difficulty and requires\nmodels to go beyond path-based reasoning.",
    "categories": [
      "cs.AI",
      "cs.LG"
    ],
    "published": "2025-10-27T17:09:16Z",
    "authors": [
      "Anirban Das",
      "Irtaza Khalid",
      "Rafael Pe\u00f1aloza",
      "Steven Schockaert"
    ],
    "pdf_url": "http://arxiv.org/pdf/2510.23532v1"
  },
  {
    "id": "2510.23530v1",
    "title": "Learning Linearity in Audio Consistency Autoencoders via Implicit\n  Regularization",
    "abstract": "Audio autoencoders learn useful, compressed audio representations, but their\nnon-linear latent spaces prevent intuitive algebraic manipulation such as\nmixing or scaling. We introduce a simple training methodology to induce\nlinearity in a high-compression Consistency Autoencoder (CAE) by using data\naugmentation, thereby inducing homogeneity (equivariance to scalar gain) and\nadditivity (the decoder preserves addition) without altering the model's\narchitecture or loss function. When trained with our method, the CAE exhibits\nlinear behavior in both the encoder and decoder while preserving reconstruction\nfidelity. We test the practical utility of our learned space on music source\ncomposition and separation via simple latent arithmetic. This work presents a\nstraightforward technique for constructing structured latent spaces, enabling\nmore intuitive and efficient audio processing.",
    "categories": [
      "cs.SD",
      "cs.AI",
      "cs.LG",
      "eess.AS"
    ],
    "published": "2025-10-27T17:08:27Z",
    "authors": [
      "Bernardo Torres",
      "Manuel Moussallam",
      "Gabriel Meseguer-Brocal"
    ],
    "pdf_url": "http://arxiv.org/pdf/2510.23530v1"
  },
  {
    "id": "2510.23524v1",
    "title": "Toward Carbon-Neutral Human AI: Rethinking Data, Computation, and\n  Learning Paradigms for Sustainable Intelligence",
    "abstract": "The rapid advancement of Artificial Intelligence (AI) has led to\nunprecedented computational demands, raising significant environmental and\nethical concerns. This paper critiques the prevailing reliance on large-scale,\nstatic datasets and monolithic training paradigms, advocating for a shift\ntoward human-inspired, sustainable AI solutions. We introduce a novel\nframework, Human AI (HAI), which emphasizes incremental learning, carbon-aware\noptimization, and human-in-the-loop collaboration to enhance adaptability,\nefficiency, and accountability. By drawing parallels with biological cognition\nand leveraging dynamic architectures, HAI seeks to balance performance with\necological responsibility. We detail the theoretical foundations, system\ndesign, and operational principles that enable AI to learn continuously and\ncontextually while minimizing carbon footprints and human annotation costs. Our\napproach addresses pressing challenges in active learning, continual\nadaptation, and energy-efficient model deployment, offering a pathway toward\nresponsible, human-centered artificial intelligence.",
    "categories": [
      "cs.AI",
      "cs.LG"
    ],
    "published": "2025-10-27T17:02:30Z",
    "authors": [
      "KC Santosh",
      "Rodrigue Rizk",
      "Longwei Wang"
    ],
    "pdf_url": "http://arxiv.org/pdf/2510.23524v1"
  },
  {
    "id": "2510.23507v1",
    "title": "A Deep Latent Factor Graph Clustering with Fairness-Utility Trade-off\n  Perspective",
    "abstract": "Fair graph clustering seeks partitions that respect network structure while\nmaintaining proportional representation across sensitive groups, with\napplications spanning community detection, team formation, resource allocation,\nand social network analysis. Many existing approaches enforce rigid constraints\nor rely on multi-stage pipelines (e.g., spectral embedding followed by\n$k$-means), limiting trade-off control, interpretability, and scalability. We\nintroduce \\emph{DFNMF}, an end-to-end deep nonnegative tri-factorization\ntailored to graphs that directly optimizes cluster assignments with a soft\nstatistical-parity regularizer. A single parameter $\\lambda$ tunes the\nfairness--utility balance, while nonnegativity yields parts-based factors and\ntransparent soft memberships. The optimization uses sparse-friendly alternating\nupdates and scales near-linearly with the number of edges. Across synthetic and\nreal networks, DFNMF achieves substantially higher group balance at comparable\nmodularity, often dominating state-of-the-art baselines on the Pareto front.\nThe code is available at https://github.com/SiamakGhodsi/DFNMF.git.",
    "categories": [
      "cs.LG",
      "cs.AI",
      "cs.IT",
      "math.IT"
    ],
    "published": "2025-10-27T16:40:52Z",
    "authors": [
      "Siamak Ghodsi",
      "Amjad Seyedi",
      "Tai Le Quy",
      "Fariba Karimi",
      "Eirini Ntoutsi"
    ],
    "pdf_url": "http://arxiv.org/pdf/2510.23507v1"
  },
  {
    "id": "2510.23503v1",
    "title": "Bayes-Split-Edge: Bayesian Optimization for Constrained Collaborative\n  Inference in Wireless Edge Systems",
    "abstract": "Mobile edge devices (e.g., AR/VR headsets) typically need to complete timely\ninference tasks while operating with limited on-board computing and energy\nresources. In this paper, we investigate the problem of collaborative inference\nin wireless edge networks, where energy-constrained edge devices aim to\ncomplete inference tasks within given deadlines. These tasks are carried out\nusing neural networks, and the edge device seeks to optimize inference\nperformance under energy and delay constraints. The inference process can be\nsplit between the edge device and an edge server, thereby achieving\ncollaborative inference over wireless networks. We formulate an inference\nutility optimization problem subject to energy and delay constraints, and\npropose a novel solution called Bayes-Split-Edge, which leverages Bayesian\noptimization for collaborative split inference over wireless edge networks. Our\nsolution jointly optimizes the transmission power and the neural network split\npoint. The Bayes-Split-Edge framework incorporates a novel hybrid acquisition\nfunction that balances inference task utility, sample efficiency, and\nconstraint violation penalties. We evaluate our approach using the VGG19 model\non the ImageNet-Mini dataset, and Resnet101 on Tiny-ImageNet, and real-world\nmMobile wireless channel datasets. Numerical results demonstrate that\nBayes-Split-Edge achieves up to 2.4x reduction in evaluation cost compared to\nstandard Bayesian optimization and achieves near-linear convergence. It also\noutperforms several baselines, including CMA-ES, DIRECT, exhaustive search, and\nProximal Policy Optimization (PPO), while matching exhaustive search\nperformance under tight constraints. These results confirm that the proposed\nframework provides a sample-efficient solution requiring maximum 20 function\nevaluations and constraint-aware optimization for wireless split inference in\nedge computing systems.",
    "categories": [
      "cs.DC",
      "cs.LG",
      "eess.SP"
    ],
    "published": "2025-10-27T16:36:51Z",
    "authors": [
      "Fatemeh Zahra Safaeipour",
      "Jacob Chakareski",
      "Morteza Hashemi"
    ],
    "pdf_url": "http://arxiv.org/pdf/2510.23503v1"
  },
  {
    "id": "2510.23501v1",
    "title": "Towards Deep Physics-Informed Kolmogorov-Arnold Networks",
    "abstract": "Since their introduction, Kolmogorov-Arnold Networks (KANs) have been\nsuccessfully applied across several domains, with physics-informed machine\nlearning (PIML) emerging as one of the areas where they have thrived. In the\nPIML setting, Chebyshev-based physics-informed KANs (cPIKANs) have become the\nstandard due to their computational efficiency. However, like their multilayer\nperceptron-based counterparts, cPIKANs face significant challenges when scaled\nto depth, leading to training instabilities that limit their applicability to\nseveral PDE problems. To address this, we propose a basis-agnostic, Glorot-like\ninitialization scheme that preserves activation variance and yields substantial\nimprovements in stability and accuracy over the default initialization of\ncPIKANs. Inspired by the PirateNet architecture, we further introduce\nResidual-Gated Adaptive KANs (RGA KANs), designed to mitigate divergence in\ndeep cPIKANs where initialization alone is not sufficient. Through empirical\ntests and information bottleneck analysis, we show that RGA KANs successfully\ntraverse all training phases, unlike baseline cPIKANs, which stagnate in the\ndiffusion phase in specific PDE settings. Evaluations on seven standard forward\nPDE benchmarks under a fixed training pipeline with adaptive components\ndemonstrate that RGA KANs consistently outperform parameter-matched cPIKANs and\nPirateNets - often by several orders of magnitude - while remaining stable in\nsettings where the others diverge.",
    "categories": [
      "cs.LG",
      "physics.comp-ph"
    ],
    "published": "2025-10-27T16:35:01Z",
    "authors": [
      "Spyros Rigas",
      "Fotios Anagnostopoulos",
      "Michalis Papachristou",
      "Georgios Alexandridis"
    ],
    "pdf_url": "http://arxiv.org/pdf/2510.23501v1"
  },
  {
    "id": "2510.23498v1",
    "title": "Mixed Precision Training of Neural ODEs",
    "abstract": "Exploiting low-precision computations has become a standard strategy in deep\nlearning to address the growing computational costs imposed by ever larger\nmodels and datasets. However, naively performing all computations in low\nprecision can lead to roundoff errors and instabilities. Therefore, mixed\nprecision training schemes usually store the weights in high precision and use\nlow-precision computations only for whitelisted operations. Despite their\nsuccess, these principles are currently not reliable for training\ncontinuous-time architectures such as neural ordinary differential equations\n(Neural ODEs). This paper presents a mixed precision training framework for\nneural ODEs, combining explicit ODE solvers with a custom backpropagation\nscheme, and demonstrates its effectiveness across a range of learning tasks.\nOur scheme uses low-precision computations for evaluating the velocity,\nparameterized by the neural network, and for storing intermediate states, while\nstability is provided by a custom dynamic adjoint scaling and by accumulating\nthe solution and gradients in higher precision. These contributions address two\nkey challenges in training neural ODE: the computational cost of repeated\nnetwork evaluations and the growth of memory requirements with the number of\ntime steps or layers. Along with the paper, we publish our extendable,\nopen-source PyTorch package rampde, whose syntax resembles that of leading\npackages to provide a drop-in replacement in existing codes. We demonstrate the\nreliability and effectiveness of our scheme using challenging test cases and on\nneural ODE applications in image classification and generative models,\nachieving approximately 50% memory reduction and up to 2x speedup while\nmaintaining accuracy comparable to single-precision training.",
    "categories": [
      "cs.LG",
      "cs.AI",
      "cs.NA",
      "math.NA",
      "68T07, 65L06, 65G50",
      "I.2; G.1"
    ],
    "published": "2025-10-27T16:32:56Z",
    "authors": [
      "Elena Celledoni",
      "Brynjulf Owren",
      "Lars Ruthotto",
      "Tianjiao Nicole Yang"
    ],
    "pdf_url": "http://arxiv.org/pdf/2510.23498v1"
  },
  {
    "id": "2510.23489v1",
    "title": "Quantum Phase Classification of Rydberg Atom Systems Using\n  Resource-Efficient Variational Quantum Circuits and Classical Shadows",
    "abstract": "Quantum phase transitions in Rydberg atom arrays present significant\nopportunities for studying many-body physics, yet distinguishing between\ndifferent ordered phases without explicit order parameters remains challenging.\nWe present a resource-efficient quantum machine learning approach combining\nclassical shadow tomography with variational quantum circuits (VQCs) for binary\nphase classification of Z2 and Z3 ordered phases. Our pipeline processes 500\nrandomized measurements per 51-atom chain state, reconstructs shadow operators,\nperforms PCA dimensionality reduction (514 features), and encodes features\nusing angle embedding onto a 2-qubit parameterized circuit. The circuit employs\nRY-RZ angle encoding, strong entanglement via all-to-all CZ gates, and a\nminimal 2-parameter ansatz achieving depth 7. Training via simultaneous\nperturbation stochastic approximation (SPSA) with hinge loss converged in 120\niterations. The model achieved 100% test accuracy with perfect precision,\nrecall, and F1 scores, demonstrating that minimal quantum resources suffice for\nhigh-accuracy phase classification. This work establishes pathways for\nquantum-enhanced condensed matter physics on near-term quantum devices.",
    "categories": [
      "quant-ph",
      "cs.LG",
      "81P68"
    ],
    "published": "2025-10-27T16:25:16Z",
    "authors": [
      "Hemish Ahuja",
      "Samradh Bhardwaj",
      "Kirti Dhir",
      "Roman Bagdasarian",
      "Ziwoong Jang"
    ],
    "pdf_url": "http://arxiv.org/pdf/2510.23489v1"
  },
  {
    "id": "2510.23486v1",
    "title": "Learning to Reason Efficiently with Discounted Reinforcement Learning",
    "abstract": "Large reasoning models (LRMs) often consume excessive tokens, inflating\ncomputational cost and latency. We challenge the assumption that longer\nresponses improve accuracy. By penalizing reasoning tokens using a discounted\nreinforcement learning setup (interpretable as a small token cost) and\nanalyzing Blackwell optimality in restricted policy classes, we encourage\nconcise yet accurate reasoning. Experiments confirm our theoretical results\nthat this approach shortens chains of thought while preserving accuracy.",
    "categories": [
      "cs.LG"
    ],
    "published": "2025-10-27T16:17:45Z",
    "authors": [
      "Alex Ayoub",
      "Kavosh Asadi",
      "Dale Schuurmans",
      "Csaba Szepesv\u00e1ri",
      "Karim Bouyarmane"
    ],
    "pdf_url": "http://arxiv.org/pdf/2510.23486v1"
  },
  {
    "id": "2510.23685v1",
    "title": "Parallel BiLSTM-Transformer networks for forecasting chaotic dynamics",
    "abstract": "The nonlinear nature of chaotic systems results in extreme sensitivity to\ninitial conditions and highly intricate dynamical behaviors, posing fundamental\nchallenges for accurately predicting their evolution. To overcome the\nlimitation that conventional approaches fail to capture both local features and\nglobal dependencies in chaotic time series simultaneously, this study proposes\na parallel predictive framework integrating Transformer and Bidirectional Long\nShort-Term Memory (BiLSTM) networks. The hybrid model employs a dual-branch\narchitecture, where the Transformer branch mainly captures long-range\ndependencies while the BiLSTM branch focuses on extracting local temporal\nfeatures. The complementary representations from the two branches are fused in\na dedicated feature-fusion layer to enhance predictive accuracy. As\nillustrating examples, the model's performance is systematically evaluated on\ntwo representative tasks in the Lorenz system. The first is autonomous\nevolution prediction, in which the model recursively extrapolates system\ntrajectories from the time-delay embeddings of the state vector to evaluate\nlong-term tracking accuracy and stability. The second is inference of\nunmeasured variable, where the model reconstructs the unobserved states from\nthe time-delay embeddings of partial observations to assess its\nstate-completion capability. The results consistently indicate that the\nproposed hybrid framework outperforms both single-branch architectures across\ntasks, demonstrating its robustness and effectiveness in chaotic system\nprediction.",
    "categories": [
      "cs.LG",
      "cs.AI"
    ],
    "published": "2025-10-27T16:17:10Z",
    "authors": [
      "Junwen Ma",
      "Mingyu Ge",
      "Yisen Wang",
      "Yong Zhang",
      "Weicheng Fu"
    ],
    "pdf_url": "http://arxiv.org/pdf/2510.23685v1"
  },
  {
    "id": "2510.23485v1",
    "title": "Tighter CMI-Based Generalization Bounds via Stochastic Projection and\n  Quantization",
    "abstract": "In this paper, we leverage stochastic projection and lossy compression to\nestablish new conditional mutual information (CMI) bounds on the generalization\nerror of statistical learning algorithms. It is shown that these bounds are\ngenerally tighter than the existing ones. In particular, we prove that for\ncertain problem instances for which existing MI and CMI bounds were recently\nshown in Attias et al. [2024] and Livni [2023] to become vacuous or fail to\ndescribe the right generalization behavior, our bounds yield suitable\ngeneralization guarantees of the order of $\\mathcal{O}(1/\\sqrt{n})$, where $n$\nis the size of the training dataset. Furthermore, we use our bounds to\ninvestigate the problem of data \"memorization\" raised in those works, and which\nasserts that there are learning problem instances for which any learning\nalgorithm that has good prediction there exist distributions under which the\nalgorithm must \"memorize\" a big fraction of the training dataset. We show that\nfor every learning algorithm, there exists an auxiliary algorithm that does not\nmemorize and which yields comparable generalization error for any data\ndistribution. In part, this shows that memorization is not necessary for good\ngeneralization.",
    "categories": [
      "stat.ML",
      "cs.IT",
      "cs.LG",
      "math.IT"
    ],
    "published": "2025-10-27T16:17:09Z",
    "authors": [
      "Milad Sefidgaran",
      "Kimia Nadjahi",
      "Abdellatif Zaidi"
    ],
    "pdf_url": "http://arxiv.org/pdf/2510.23485v1"
  },
  {
    "id": "2510.23484v1",
    "title": "T-REGS: Minimum Spanning Tree Regularization for Self-Supervised\n  Learning",
    "abstract": "Self-supervised learning (SSL) has emerged as a powerful paradigm for\nlearning representations without labeled data, often by enforcing invariance to\ninput transformations such as rotations or blurring. Recent studies have\nhighlighted two pivotal properties for effective representations: (i) avoiding\ndimensional collapse-where the learned features occupy only a low-dimensional\nsubspace, and (ii) enhancing uniformity of the induced distribution. In this\nwork, we introduce T-REGS, a simple regularization framework for SSL based on\nthe length of the Minimum Spanning Tree (MST) over the learned representation.\nWe provide theoretical analysis demonstrating that T-REGS simultaneously\nmitigates dimensional collapse and promotes distribution uniformity on\narbitrary compact Riemannian manifolds. Several experiments on synthetic data\nand on classical SSL benchmarks validate the effectiveness of our approach at\nenhancing representation quality.",
    "categories": [
      "cs.LG",
      "cs.CG",
      "cs.CV"
    ],
    "published": "2025-10-27T16:16:40Z",
    "authors": [
      "Julie Mordacq",
      "David Loiseaux",
      "Vicky Kalogeiton",
      "Steve Oudot"
    ],
    "pdf_url": "http://arxiv.org/pdf/2510.23484v1"
  },
  {
    "id": "2510.23472v1",
    "title": "BBOPlace-Bench: Benchmarking Black-Box Optimization for Chip Placement",
    "abstract": "Chip placement is a vital stage in modern chip design as it has a substantial\nimpact on the subsequent processes and the overall quality of the final chip.\nThe use of black-box optimization (BBO) for chip placement has a history of\nseveral decades. However, early efforts were limited by immature problem\nformulations and inefficient algorithm designs. Recent progress has shown the\neffectiveness and efficiency of BBO for chip placement, proving its potential\nto achieve state-of-the-art results. Despite these advancements, the field\nlacks a unified, BBO-specific benchmark for thoroughly assessing various\nproblem formulations and BBO algorithms. To fill this gap, we propose\nBBOPlace-Bench, the first benchmark designed specifically for evaluating and\ndeveloping BBO algorithms for chip placement tasks. It integrates three problem\nformulations of BBO for chip placement, and offers a modular, decoupled, and\nflexible framework that enables users to seamlessly implement, test, and\ncompare their own algorithms. BBOPlace-Bench integrates a wide variety of\nexisting BBO algorithms, including simulated annealing (SA), evolutionary\nalgorithms (EAs), and Bayesian optimization (BO). Experimental results show\nthat the problem formulations of mask-guided optimization and hyperparameter\noptimization exhibit superior performance than the sequence pair problem\nformulation, while EAs demonstrate better overall performance than SA and BO,\nespecially in high-dimensional search spaces, and also achieve state-of-the-art\nperformance compared to the mainstream chip placement methods. BBOPlace-Bench\nnot only facilitates the development of efficient BBO-driven solutions for chip\nplacement but also broadens the practical application scenarios (which are\nurgently needed) for the BBO community. The code of BBOPlace-Bench is available\nat https://github.com/lamda-bbo/BBOPlace-Bench.",
    "categories": [
      "cs.LG",
      "cs.AI",
      "cs.AR",
      "cs.NE"
    ],
    "published": "2025-10-27T16:10:32Z",
    "authors": [
      "Ke Xue",
      "Ruo-Tong Chen",
      "Rong-Xi Tan",
      "Xi Lin",
      "Yunqi Shi",
      "Siyuan Xu",
      "Mingxuan Yuan",
      "Chao Qian"
    ],
    "pdf_url": "http://arxiv.org/pdf/2510.23472v1"
  },
  {
    "id": "2510.23471v1",
    "title": "Robust Decision Making with Partially Calibrated Forecasts",
    "abstract": "Calibration has emerged as a foundational goal in ``trustworthy machine\nlearning'', in part because of its strong decision theoretic semantics.\nIndependent of the underlying distribution, and independent of the decision\nmaker's utility function, calibration promises that amongst all policies\nmapping predictions to actions, the uniformly best policy is the one that\n``trusts the predictions'' and acts as if they were correct. But this is true\nonly of \\emph{fully calibrated} forecasts, which are tractable to guarantee\nonly for very low dimensional prediction problems. For higher dimensional\nprediction problems (e.g. when outcomes are multiclass), weaker forms of\ncalibration have been studied that lack these decision theoretic properties. In\nthis paper we study how a conservative decision maker should map predictions\nendowed with these weaker (``partial'') calibration guarantees to actions, in a\nway that is robust in a minimax sense: i.e. to maximize their expected utility\nin the worst case over distributions consistent with the calibration\nguarantees. We characterize their minimax optimal decision rule via a duality\nargument, and show that surprisingly, ``trusting the predictions and acting\naccordingly'' is recovered in this minimax sense by \\emph{decision calibration}\n(and any strictly stronger notion of calibration), a substantially weaker and\nmore tractable condition than full calibration. For calibration guarantees that\nfall short of decision calibration, the minimax optimal decision rule is still\nefficiently computable, and we provide an empirical evaluation of a natural one\nthat applies to any regression model solved to optimize squared error.",
    "categories": [
      "stat.ML",
      "cs.AI",
      "cs.LG"
    ],
    "published": "2025-10-27T16:09:07Z",
    "authors": [
      "Shayan Kiyani",
      "Hamed Hassani",
      "George Pappas",
      "Aaron Roth"
    ],
    "pdf_url": "http://arxiv.org/pdf/2510.23471v1"
  },
  {
    "id": "2510.23469v1",
    "title": "Adaptive Dual Prompting: Hierarchical Debiasing for Fairness-aware Graph\n  Neural Networks",
    "abstract": "In recent years, pre-training Graph Neural Networks (GNNs) through\nself-supervised learning on unlabeled graph data has emerged as a widely\nadopted paradigm in graph learning. Although the paradigm is effective for\npre-training powerful GNN models, the objective gap often exists between\npre-training and downstream tasks. To bridge this gap, graph prompting adapts\npre-trained GNN models to specific downstream tasks with extra learnable\nprompts while keeping the pre-trained GNN models frozen. As recent graph\nprompting methods largely focus on enhancing model utility on downstream tasks,\nthey often overlook fairness concerns when designing prompts for adaptation. In\nfact, pre-trained GNN models will produce discriminative node representations\nacross demographic subgroups, as downstream graph data inherently contains\nbiases in both node attributes and graph structures. To address this issue, we\npropose an Adaptive Dual Prompting (ADPrompt) framework that enhances fairness\nfor adapting pre-trained GNN models to downstream tasks. To mitigate attribute\nbias, we design an Adaptive Feature Rectification module that learns customized\nattribute prompts to suppress sensitive information at the input layer,\nreducing bias at the source. Afterward, we propose an Adaptive Message\nCalibration module that generates structure prompts at each layer, which adjust\nthe message from neighboring nodes to enable dynamic and soft calibration of\nthe information flow. Finally, ADPrompt jointly optimizes the two prompting\nmodules to adapt the pre-trained GNN while enhancing fairness. We conduct\nextensive experiments on four datasets with four pre-training strategies to\nevaluate the performance of ADPrompt. The results demonstrate that our proposed\nADPrompt outperforms seven baseline methods on node classification tasks.",
    "categories": [
      "cs.LG"
    ],
    "published": "2025-10-27T16:07:36Z",
    "authors": [
      "Yuhan Yang",
      "Xingbo Fu",
      "Jundong Li"
    ],
    "pdf_url": "http://arxiv.org/pdf/2510.23469v1"
  },
  {
    "id": "2510.23463v2",
    "title": "Differential Privacy as a Perk: Federated Learning over Multiple-Access\n  Fading Channels with a Multi-Antenna Base Station",
    "abstract": "Federated Learning (FL) is a distributed learning paradigm that preserves\nprivacy by eliminating the need to exchange raw data during training. In its\nprototypical edge instantiation with underlying wireless transmissions enabled\nby analog over-the-air computing (AirComp), referred to as \\emph{over-the-air\nFL (AirFL)}, the inherent channel noise plays a unique role of \\emph{frenemy}\nin the sense that it degrades training due to noisy global aggregation while\nproviding a natural source of randomness for privacy-preserving mechanisms,\nformally quantified by \\emph{differential privacy (DP)}. It remains,\nnevertheless, challenging to effectively harness such channel impairments, as\nprior arts, under assumptions of either simple channel models or restricted\ntypes of loss functions, mostly considering (local) DP enhancement with a\nsingle-round or non-convergent bound on privacy loss. In this paper, we study\nAirFL over multiple-access fading channels with a multi-antenna base station\n(BS) subject to user-level DP requirements. Despite a recent study, which\nclaimed in similar settings that artificial noise (AN) must be injected to\nensure DP in general, we demonstrate, on the contrary, that DP can be gained as\na \\emph{perk} even \\emph{without} employing any AN. Specifically, we derive a\nnovel bound on DP that converges under general bounded-domain assumptions on\nmodel parameters, along with a convergence bound with general smooth and\nnon-convex loss functions. Next, we optimize over receive beamforming and power\nallocations to characterize the optimal convergence-privacy trade-offs, which\nalso reveal explicit conditions in which DP is achievable without compromising\ntraining. Finally, our theoretical findings are validated by extensive\nnumerical results.",
    "categories": [
      "cs.LG",
      "cs.CR",
      "stat.ML"
    ],
    "published": "2025-10-27T16:01:15Z",
    "authors": [
      "Hao Liang",
      "Haifeng Wen",
      "Kaishun Wu",
      "Hong Xing"
    ],
    "pdf_url": "http://arxiv.org/pdf/2510.23463v2"
  },
  {
    "id": "2510.23455v3",
    "title": "SGFusion: Stochastic Geographic Gradient Fusion in Federated Learning",
    "abstract": "This paper proposes Stochastic Geographic Gradient Fusion (SGFusion), a novel\ntraining algorithm to leverage the geographic information of mobile users in\nFederated Learning (FL). SGFusion maps the data collected by mobile devices\nonto geographical zones and trains one FL model per zone, which adapts well to\nthe data and behaviors of users in that zone. SGFusion models the local\ndata-based correlation among geographical zones as a hierarchical random graph\n(HRG) optimized by Markov Chain Monte Carlo sampling. At each training step,\nevery zone fuses its local gradient with gradients derived from a small set of\nother zones sampled from the HRG. This approach enables knowledge fusion and\nsharing among geographical zones in a probabilistic and stochastic gradient\nfusion process with self-attention weights, such that \"more similar\" zones have\n\"higher probabilities\" of sharing gradients with \"larger attention weights.\"\nSGFusion remarkably improves model utility without introducing undue\ncomputational cost. Extensive theoretical and empirical results using a\nheart-rate prediction dataset collected across 6 countries show that models\ntrained with SGFusion converge with upper-bounded expected errors and\nsignificantly improve utility in all countries compared to existing approaches\nwithout notable cost in system scalability.",
    "categories": [
      "cs.LG"
    ],
    "published": "2025-10-27T15:56:19Z",
    "authors": [
      "Khoa Nguyen",
      "Khang Tran",
      "NhatHai Phan",
      "Cristian Borcea",
      "Ruoming Jin",
      "Issa Khalil"
    ],
    "pdf_url": "http://arxiv.org/pdf/2510.23455v3"
  },
  {
    "id": "2510.23449v1",
    "title": "Schrodinger Neural Network and Uncertainty Quantification: Quantum\n  Machine",
    "abstract": "We introduce the Schrodinger Neural Network (SNN), a principled architecture\nfor conditional density estimation and uncertainty quantification inspired by\nquantum mechanics. The SNN maps each input to a normalized wave function on the\noutput domain and computes predictive probabilities via the Born rule. The SNN\ndeparts from standard parametric likelihood heads by learning complex\ncoefficients of a spectral expansion (e . g ., Chebyshev polynomials) whose\nsquared modulus yields the conditional density $p(y|x)=\\left| \\psi _x(y)\\right|\n{}^2$ with analytic normalization. This representation confers three practical\nadvantages: positivity and exact normalization by construction, native\nmultimodality through interference among basis modes without explicit mixture\nbookkeeping, and yields closed-form (or efficiently computable)\nfunctionals$-$such as moments and several calibration diagnostics$-$as\nquadratic forms in coefficient space. We develop the statistical and\ncomputational foundations of the SNN, including (i) training by exact\nmaximum-likelihood with unit-sphere coefficient parameterization, (ii)\nphysics-inspired quadratic regularizers (kinetic and potential energies)\nmotivated by uncertainty relations between localization and spectral\ncomplexity, (iii) scalable low-rank and separable extensions for multivariate\noutputs, (iv) operator-based extensions that represent observables,\nconstraints, and weak labels as self-adjoint matrices acting on the amplitude\nspace, and (v) a comprehensive framework for evaluating multimodal predictions.\nThe SNN provides a coherent, tractable framework to elevate probabilistic\nprediction from point estimates to physically inspired amplitude-based\ndistributions.",
    "categories": [
      "cs.LG"
    ],
    "published": "2025-10-27T15:52:47Z",
    "authors": [
      "M. M. Hammad"
    ],
    "pdf_url": "http://arxiv.org/pdf/2510.23449v1"
  },
  {
    "id": "2510.23448v1",
    "title": "An Information-Theoretic Analysis of Out-of-Distribution Generalization\n  in Meta-Learning with Applications to Meta-RL",
    "abstract": "In this work, we study out-of-distribution generalization in meta-learning\nfrom an information-theoretic perspective. We focus on two scenarios: (i) when\nthe testing environment mismatches the training environment, and (ii) when the\ntraining environment is broader than the testing environment. The first\ncorresponds to the standard distribution mismatch setting, while the second\nreflects a broad-to-narrow training scenario. We further formalize the\ngeneralization problem in meta-reinforcement learning and establish\ncorresponding generalization bounds. Finally, we analyze the generalization\nperformance of a gradient-based meta-reinforcement learning algorithm.",
    "categories": [
      "cs.LG",
      "stat.ML"
    ],
    "published": "2025-10-27T15:52:23Z",
    "authors": [
      "Xingtu Liu"
    ],
    "pdf_url": "http://arxiv.org/pdf/2510.23448v1"
  },
  {
    "id": "2510.23438v1",
    "title": "Coresets for Clustering Under Stochastic Noise",
    "abstract": "We study the problem of constructing coresets for $(k, z)$-clustering when\nthe input dataset is corrupted by stochastic noise drawn from a known\ndistribution. In this setting, evaluating the quality of a coreset is\ninherently challenging, as the true underlying dataset is unobserved. To\naddress this, we investigate coreset construction using surrogate error metrics\nthat are tractable and provably related to the true clustering cost. We analyze\na traditional metric from prior work and introduce a new error metric that more\nclosely aligns with the true cost. Although our metric is defined independently\nof the noise distribution, it enables approximation guarantees that scale with\nthe noise level. We design a coreset construction algorithm based on this\nmetric and show that, under mild assumptions on the data and noise, enforcing\nan $\\varepsilon$-bound under our metric yields smaller coresets and tighter\nguarantees on the true clustering cost than those obtained via classical\nmetrics. In particular, we prove that the coreset size can improve by a factor\nof up to $\\mathrm{poly}(k)$, where $n$ is the dataset size. Experiments on\nreal-world datasets support our theoretical findings and demonstrate the\npractical advantages of our approach.",
    "categories": [
      "cs.LG",
      "cs.CG",
      "cs.DS",
      "stat.ML"
    ],
    "published": "2025-10-27T15:41:27Z",
    "authors": [
      "Lingxiao Huang",
      "Zhize Li",
      "Nisheeth K. Vishnoi",
      "Runkai Yang",
      "Haoyu Zhao"
    ],
    "pdf_url": "http://arxiv.org/pdf/2510.23438v1"
  },
  {
    "id": "2510.23684v1",
    "title": "VIKING: Deep variational inference with stochastic projections",
    "abstract": "Variational mean field approximations tend to struggle with contemporary\noverparametrized deep neural networks. Where a Bayesian treatment is usually\nassociated with high-quality predictions and uncertainties, the practical\nreality has been the opposite, with unstable training, poor predictive power,\nand subpar calibration. Building upon recent work on reparametrizations of\nneural networks, we propose a simple variational family that considers two\nindependent linear subspaces of the parameter space. These represent functional\nchanges inside and outside the support of training data. This allows us to\nbuild a fully-correlated approximate posterior reflecting the\noverparametrization that tunes easy-to-interpret hyperparameters. We develop\nscalable numerical routines that maximize the associated evidence lower bound\n(ELBO) and sample from the approximate posterior. Empirically, we observe\nstate-of-the-art performance across tasks, models, and datasets compared to a\nwide array of baseline methods. Our results show that approximate Bayesian\ninference applied to deep neural networks is far from a lost cause when\nconstructing inference mechanisms that reflect the geometry of\nreparametrizations.",
    "categories": [
      "stat.ML",
      "cs.LG"
    ],
    "published": "2025-10-27T15:38:35Z",
    "authors": [
      "Samuel G. Fadel",
      "Hrittik Roy",
      "Nicholas Kr\u00e4mer",
      "Yevgen Zainchkovskyy",
      "Stas Syrota",
      "Alejandro Valverde Mahou",
      "Carl Henrik Ek",
      "S\u00f8ren Hauberg"
    ],
    "pdf_url": "http://arxiv.org/pdf/2510.23684v1"
  },
  {
    "id": "2510.23428v1",
    "title": "Improving Predictions of Molecular Properties with Graph Featurisation\n  and Heterogeneous Ensemble Models",
    "abstract": "We explore a \"best-of-both\" approach to modelling molecular properties by\ncombining learned molecular descriptors from a graph neural network (GNN) with\ngeneral-purpose descriptors and a mixed ensemble of machine learning (ML)\nmodels. We introduce a MetaModel framework to aggregate predictions from a\ndiverse set of leading ML models. We present a featurisation scheme for\ncombining task-specific GNN-derived features with conventional molecular\ndescriptors.\n  We demonstrate that our framework outperforms the cutting-edge ChemProp model\non all regression datasets tested and 6 of 9 classification datasets. We\nfurther show that including the GNN features derived from ChemProp boosts the\nensemble model's performance on several datasets where it otherwise would have\nunderperformed. We conclude that to achieve optimal performance across a wide\nset of problems, it is vital to combine general-purpose descriptors with\ntask-specific learned features and use a diverse set of ML models to make the\npredictions.",
    "categories": [
      "cs.LG"
    ],
    "published": "2025-10-27T15:33:05Z",
    "authors": [
      "Michael L. Parker",
      "Samar Mahmoud",
      "Bailey Montefiore",
      "Mario \u00d6eren",
      "Himani Tandon",
      "Charlotte Wharrick",
      "Matthew D. Segall"
    ],
    "pdf_url": "http://arxiv.org/pdf/2510.23428v1"
  },
  {
    "id": "2510.23427v1",
    "title": "PrivacyGuard: A Modular Framework for Privacy Auditing in Machine\n  Learning",
    "abstract": "The increasing deployment of Machine Learning (ML) models in sensitive\ndomains motivates the need for robust, practical privacy assessment tools.\nPrivacyGuard is a comprehensive tool for empirical differential privacy (DP)\nanalysis, designed to evaluate privacy risks in ML models through\nstate-of-the-art inference attacks and advanced privacy measurement techniques.\nTo this end, PrivacyGuard implements a diverse suite of privacy attack --\nincluding membership inference , extraction, and reconstruction attacks --\nenabling both off-the-shelf and highly configurable privacy analyses. Its\nmodular architecture allows for the seamless integration of new attacks, and\nprivacy metrics, supporting rapid adaptation to emerging research advances. We\nmake PrivacyGuard available at\nhttps://github.com/facebookresearch/PrivacyGuard.",
    "categories": [
      "cs.LG"
    ],
    "published": "2025-10-27T15:33:01Z",
    "authors": [
      "Luca Melis",
      "Matthew Grange",
      "Iden Kalemaj",
      "Karan Chadha",
      "Shengyuan Hu",
      "Elena Kashtelyan",
      "Will Bullock"
    ],
    "pdf_url": "http://arxiv.org/pdf/2510.23427v1"
  },
  {
    "id": "2510.23682v1",
    "title": "Beyond Prompt Engineering: Neuro-Symbolic-Causal Architecture for Robust\n  Multi-Objective AI Agents",
    "abstract": "Large language models show promise as autonomous decision-making agents, yet\ntheir deployment in high-stakes domains remains fraught with risk. Without\narchitectural safeguards, LLM agents exhibit catastrophic brittleness:\nidentical capabilities produce wildly different outcomes depending solely on\nprompt framing. We present Chimera, a neuro-symbolic-causal architecture that\nintegrates three complementary components - an LLM strategist, a formally\nverified symbolic constraint engine, and a causal inference module for\ncounterfactual reasoning. We benchmark Chimera against baseline architectures\n(LLM-only, LLM with symbolic constraints) across 52-week simulations in a\nrealistic e-commerce environment featuring price elasticity, trust dynamics,\nand seasonal demand. Under organizational biases toward either volume or margin\noptimization, LLM-only agents fail catastrophically (total loss of \\$99K in\nvolume scenarios) or destroy brand trust (-48.6% in margin scenarios). Adding\nsymbolic constraints prevents disasters but achieves only 43-87% of Chimera's\nprofit. Chimera consistently delivers the highest returns (\\$1.52M and \\$1.96M\nrespectively, some cases +\\$2.2M) while improving brand trust (+1.8% and\n+10.8%, some cases +20.86%), demonstrating prompt-agnostic robustness. Our TLA+\nformal verification proves zero constraint violations across all scenarios.\nThese results establish that architectural design not prompt engineering\ndetermines the reliability of autonomous agents in production environments. We\nprovide open-source implementations and interactive demonstrations for\nreproducibility.",
    "categories": [
      "cs.LG",
      "cs.AI",
      "cs.LO",
      "cs.SE",
      "I.2.11; I.2.6; I.2.8"
    ],
    "published": "2025-10-27T15:25:35Z",
    "authors": [
      "Gokturk Aytug Akarlar"
    ],
    "pdf_url": "http://arxiv.org/pdf/2510.23682v1"
  },
  {
    "id": "2510.23409v2",
    "title": "Eigen-Value: Efficient Domain-Robust Data Valuation via Eigenvalue-Based\n  Approach",
    "abstract": "Data valuation has become central in the era of data-centric AI. It drives\nefficient training pipelines and enables objective pricing in data markets by\nassigning a numeric value to each data point. Most existing data valuation\nmethods estimate the effect of removing individual data points by evaluating\nchanges in model validation performance under in-distribution (ID) settings, as\nopposed to out-of-distribution (OOD) scenarios where data follow different\npatterns. Since ID and OOD data behave differently, data valuation methods\nbased on ID loss often fail to generalize to OOD settings, particularly when\nthe validation set contains no OOD data. Furthermore, although OOD-aware\nmethods exist, they involve heavy computational costs, which hinder practical\ndeployment. To address these challenges, we introduce \\emph{Eigen-Value} (EV),\na plug-and-play data valuation framework for OOD robustness that uses only an\nID data subset, including during validation. EV provides a new spectral\napproximation of domain discrepancy, which is the gap of loss between ID and\nOOD using ratios of eigenvalues of ID data's covariance matrix. EV then\nestimates the marginal contribution of each data point to this discrepancy via\nperturbation theory, alleviating the computational burden. Subsequently, EV\nplugs into ID loss-based methods by adding an EV term without any additional\ntraining loop. We demonstrate that EV achieves improved OOD robustness and\nstable value rankings across real-world datasets, while remaining\ncomputationally lightweight. These results indicate that EV is practical for\nlarge-scale settings with domain shift, offering an efficient path to\nOOD-robust data valuation.",
    "categories": [
      "cs.LG",
      "cs.AI"
    ],
    "published": "2025-10-27T15:12:49Z",
    "authors": [
      "Youngjun Choi",
      "Joonseong Kang",
      "Sungjun Lim",
      "Kyungwoo Song"
    ],
    "pdf_url": "http://arxiv.org/pdf/2510.23409v2"
  },
  {
    "id": "2510.23408v1",
    "title": "AutoStreamPipe: LLM Assisted Automatic Generation of Data Stream\n  Processing Pipelines",
    "abstract": "Data pipelines are essential in stream processing as they enable the\nefficient collection, processing, and delivery of real-time data, supporting\nrapid data analysis. In this paper, we present AutoStreamPipe, a novel\nframework that employs Large Language Models (LLMs) to automate the design,\ngeneration, and deployment of stream processing pipelines. AutoStreamPipe\nbridges the semantic gap between high-level user intent and platform-specific\nimplementations across distributed stream processing systems for structured\nmulti-agent reasoning by integrating a Hypergraph of Thoughts (HGoT) as an\nextended version of GoT. AutoStreamPipe combines resilient execution\nstrategies, advanced query analysis, and HGoT to deliver pipelines with good\naccuracy. Experimental evaluations on diverse pipelines demonstrate that\nAutoStreamPipe significantly reduces development time (x6.3) and error rates\n(x5.19), as measured by a novel Error-Free Score (EFS), compared to LLM\ncode-generation methods.",
    "categories": [
      "cs.AI",
      "cs.DC",
      "cs.ET",
      "cs.LG",
      "cs.MA"
    ],
    "published": "2025-10-27T15:11:31Z",
    "authors": [
      "Abolfazl Younesi",
      "Zahra Najafabadi Samani",
      "Thomas Fahringer"
    ],
    "pdf_url": "http://arxiv.org/pdf/2510.23408v1"
  },
  {
    "id": "2510.23681v1",
    "title": "Informed Initialization for Bayesian Optimization and Active Learning",
    "abstract": "Bayesian Optimization is a widely used method for optimizing expensive\nblack-box functions, relying on probabilistic surrogate models such as Gaussian\nProcesses. The quality of the surrogate model is crucial for good optimization\nperformance, especially in the few-shot setting where only a small number of\nbatches of points can be evaluated. In this setting, the initialization plays a\ncritical role in shaping the surrogate's predictive quality and guiding\nsubsequent optimization. Despite this, practitioners typically rely on\n(quasi-)random designs to cover the input space. However, such approaches\nneglect two key factors: (a) space-filling designs may not be desirable to\nreduce predictive uncertainty, and (b) efficient hyperparameter learning during\ninitialization is essential for high-quality prediction, which may conflict\nwith space-filling designs. To address these limitations, we propose\nHyperparameter-Informed Predictive Exploration (HIPE), a novel acquisition\nstrategy that balances predictive uncertainty reduction with hyperparameter\nlearning using information-theoretic principles. We derive a closed-form\nexpression for HIPE in the Gaussian Process setting and demonstrate its\neffectiveness through extensive experiments in active learning and few-shot BO.\nOur results show that HIPE outperforms standard initialization strategies in\nterms of predictive accuracy, hyperparameter identification, and subsequent\noptimization performance, particularly in large-batch, few-shot settings\nrelevant to many real-world Bayesian Optimization applications.",
    "categories": [
      "cs.LG"
    ],
    "published": "2025-10-27T15:05:12Z",
    "authors": [
      "Carl Hvarfner",
      "David Eriksson",
      "Eytan Bakshy",
      "Max Balandat"
    ],
    "pdf_url": "http://arxiv.org/pdf/2510.23681v1"
  },
  {
    "id": "2510.25778v1",
    "title": "Review Based Entity Ranking using Fuzzy Logic Algorithmic Approach:\n  Analysis",
    "abstract": "Opinion mining, also called sentiment analysis, is the field of study that\nanalyzes people opinions, sentiments, evaluations, appraisals, attitudes, and\nemotions towards entities such as products, services, organizations,\nindividuals, issues, events, topics, and their attributes. Holistic\nlexicon-based approach does not consider the strength of each opinion, i.e.,\nwhether the opinion is very strongly negative (or positive), strongly negative\n(or positive), moderate negative (or positive), very weakly negative (or\npositive) and weakly negative (or positive). In this paper, we propose approach\nto rank entities based on orientation and strength of the entity reviews and\nuser's queries by classifying them in granularity levels (i.e. very weak, weak,\nmoderate, very strong and strong) by combining opinion words (i.e. adverb,\nadjective, noun and verb) that are related to aspect of interest of certain\nproduct. We shall use fuzzy logic algorithmic approach in order to classify\nopinion words into different category and syntactic dependency resolution to\nfind relations for desired aspect words. Opinion words related to certain\naspects of interest are considered to find the entity score for that aspect in\nthe review.",
    "categories": [
      "cs.CL",
      "cs.LG"
    ],
    "published": "2025-10-27T14:56:11Z",
    "authors": [
      "Pratik N. Kalamkar",
      "Anupama G. Phakatkar"
    ],
    "pdf_url": "http://arxiv.org/pdf/2510.25778v1"
  },
  {
    "id": "2510.23393v1",
    "title": "The Best of N Worlds: Aligning Reinforcement Learning with Best-of-N\n  Sampling via max@k Optimisation",
    "abstract": "The application of Reinforcement Learning with Verifiable Rewards (RLVR) to\nmathematical and coding domains has demonstrated significant improvements in\nthe reasoning and problem-solving abilities of Large Language Models. Despite\nits success in single generation problem solving, the reinforcement learning\nfine-tuning process may harm the model's exploration ability, as reflected in\ndecreased diversity of generations and a resulting degradation of performance\nduring Best-of-N sampling for large N values. In this work, we focus on\noptimizing the max@k metric, a continuous generalization of pass@k. We derive\nan unbiased on-policy gradient estimate for direct optimization of this metric.\nFurthermore, we extend our derivations to the off-policy updates, a common\nelement in modern RLVR algorithms, that allows better sample efficiency.\nEmpirically, we show that our objective effectively optimizes max@k metric in\noff-policy scenarios, aligning the model with the Best-of-N inference strategy.",
    "categories": [
      "cs.LG"
    ],
    "published": "2025-10-27T14:47:30Z",
    "authors": [
      "Farid Bagirov",
      "Mikhail Arkhipov",
      "Ksenia Sycheva",
      "Evgeniy Glukhov",
      "Egor Bogomolov"
    ],
    "pdf_url": "http://arxiv.org/pdf/2510.23393v1"
  },
  {
    "id": "2510.23389v1",
    "title": "Floating-Point Neural Network Verification at the Software Level",
    "abstract": "The behaviour of neural network components must be proven correct before\ndeployment in safety-critical systems. Unfortunately, existing neural network\nverification techniques cannot certify the absence of faults at the software\nlevel. In this paper, we show how to specify and verify that neural networks\nare safe, by explicitly reasoning about their floating-point implementation. In\ndoing so, we construct NeuroCodeBench 2.0, a benchmark comprising 912 neural\nnetwork verification examples that cover activation functions, common layers,\nand full neural networks of up to 170K parameters. Our verification suite is\nwritten in plain C and is compatible with the format of the International\nCompetition on Software Verification (SV-COMP). Thanks to it, we can conduct\nthe first rigorous evaluation of eight state-of-the-art software verifiers on\nneural network code. The results show that existing automated verification\ntools can correctly solve an average of 11% of our benchmark, while producing\naround 3% incorrect verdicts. At the same time, a historical analysis reveals\nthat the release of our benchmark has already had a significantly positive\nimpact on the latter.",
    "categories": [
      "cs.SE",
      "cs.CR",
      "cs.LG"
    ],
    "published": "2025-10-27T14:43:19Z",
    "authors": [
      "Edoardo Manino",
      "Bruno Farias",
      "Rafael S\u00e1 Menezes",
      "Fedor Shmarov",
      "Lucas C. Cordeiro"
    ],
    "pdf_url": "http://arxiv.org/pdf/2510.23389v1"
  },
  {
    "id": "2510.23384v1",
    "title": "Opinion Mining Based Entity Ranking using Fuzzy Logic Algorithmic\n  Approach",
    "abstract": "Opinions are central to almost all human activities and are key influencers\nof our behaviors. In current times due to growth of social networking website\nand increase in number of e-commerce site huge amount of opinions are now\navailable on web. Given a set of evaluative statements that contain opinions\n(or sentiments) about an Entity, opinion mining aims to extract attributes and\ncomponents of the object that have been commented on in each statement and to\ndetermine whether the comments are positive, negative or neutral. While lot of\nresearch recently has been done in field of opinion mining and some of it\ndealing with ranking of entities based on review or opinion set, classifying\nopinions into finer granularity level and then ranking entities has never been\ndone before. In this paper method for opinion mining from statements at a\ndeeper level of granularity is proposed. This is done by using fuzzy logic\nreasoning, after which entities are ranked as per this information.",
    "categories": [
      "cs.AI",
      "cs.LG"
    ],
    "published": "2025-10-27T14:35:20Z",
    "authors": [
      "Pratik N. Kalamkar",
      "A. G. Phakatkar"
    ],
    "pdf_url": "http://arxiv.org/pdf/2510.23384v1"
  },
  {
    "id": "2510.23379v1",
    "title": "Symbolic Neural Generation with Applications to Lead Discovery in Drug\n  Design",
    "abstract": "We investigate a relatively underexplored class of hybrid neurosymbolic\nmodels integrating symbolic learning with neural reasoning to construct data\ngenerators meeting formal correctness criteria. In \\textit{Symbolic Neural\nGenerators} (SNGs), symbolic learners examine logical specifications of\nfeasible data from a small set of instances -- sometimes just one. Each\nspecification in turn constrains the conditional information supplied to a\nneural-based generator, which rejects any instance violating the symbolic\nspecification. Like other neurosymbolic approaches, SNG exploits the\ncomplementary strengths of symbolic and neural methods. The outcome of an SNG\nis a triple $(H, X, W)$, where $H$ is a symbolic description of feasible\ninstances constructed from data, $X$ a set of generated new instances that\nsatisfy the description, and $W$ an associated weight. We introduce a semantics\nfor such systems, based on the construction of appropriate \\textit{base} and\n\\textit{fibre} partially-ordered sets combined into an overall partial order,\nand outline a probabilistic extension relevant to practical applications. In\nthis extension, SNGs result from searching over a weighted partial ordering. We\nimplement an SNG combining a restricted form of Inductive Logic Programming\n(ILP) with a large language model (LLM) and evaluate it on early-stage drug\ndesign. Our main interest is the description and the set of potential inhibitor\nmolecules generated by the SNG. On benchmark problems -- where drug targets are\nwell understood -- SNG performance is statistically comparable to\nstate-of-the-art methods. On exploratory problems with poorly understood\ntargets, generated molecules exhibit binding affinities on par with leading\nclinical candidates. Experts further find the symbolic specifications useful as\npreliminary filters, with several generated molecules identified as viable for\nsynthesis and wet-lab testing.",
    "categories": [
      "cs.LG",
      "cs.AI",
      "cs.NE",
      "q-bio.BM",
      "I.2.6; I.2.1; J.3"
    ],
    "published": "2025-10-27T14:29:22Z",
    "authors": [
      "Ashwin Srinivasan",
      "A Baskar",
      "Tirtharaj Dash",
      "Michael Bain",
      "Sanjay Kumar Dey",
      "Mainak Banerjee"
    ],
    "pdf_url": "http://arxiv.org/pdf/2510.23379v1"
  },
  {
    "id": "2510.23371v1",
    "title": "Towards a Generalizable AI for Materials Discovery: Validation through\n  Immersion Coolant Screening",
    "abstract": "Artificial intelligence (AI) has emerged as a powerful accelerator of\nmaterials discovery, yet most existing models remain problem-specific,\nrequiring additional data collection and retraining for each new property. Here\nwe introduce and validate GATE (Geometrically Aligned Transfer Encoder) -- a\ngeneralizable AI framework that jointly learns 34 physicochemical properties\nspanning thermal, electrical, mechanical, and optical domains. By aligning\nthese properties within a shared geometric space, GATE captures cross-property\ncorrelations that reduce disjoint-property bias -- a key factor causing false\nnegatives in multi-criteria screening. To demonstrate its generalizability,\nGATE -- without any problem-specific reconfiguration -- was directly applied to\nthe discovery of immersion cooling fluids for data centers, a stringent\nreal-world challenge defined by the Open Compute Project (OCP). Screening\nbillions of candidates, GATE identified 92,861 molecules as promising for\npractical deployment. Four were experimentally or literarily validated, showing\nstrong agreement with wet-lab measurements and performance comparable to or\nexceeding a commercial coolant. These results establish GATE as a ready-to-use,\ngeneralizable AI platform readily applicable across diverse materials discovery\ntasks.",
    "categories": [
      "cs.LG",
      "cs.CE"
    ],
    "published": "2025-10-27T14:21:05Z",
    "authors": [
      "Hyunseung Kim",
      "Dae-Woong Jeong",
      "Changyoung Park",
      "Won-Ji Lee",
      "Ha-Eun Lee",
      "Ji-Hye Lee",
      "Rodrigo Hormazabal",
      "Sung Moon Ko",
      "Sumin Lee",
      "Soorin Yim",
      "Chanhui Lee",
      "Sehui Han",
      "Sang-Ho Cha",
      "Woohyung Lim"
    ],
    "pdf_url": "http://arxiv.org/pdf/2510.23371v1"
  },
  {
    "id": "2510.23364v1",
    "title": "ZeroFlood: A Geospatial Foundation Model for Data-Efficient Flood\n  Susceptibility Mapping",
    "abstract": "Flood susceptibility mapping (FSM) is vital for disaster prevention but\nremains challenging in data-scarce regions where hydrodynamic models require\ndense geophysical inputs. This work introduces ZeroFlood, a geospatial\nfoundation model framework for data-efficient FSM. The approach fine-tunes\nGeospatial Foundation Models (GFMs) with Thinking-in-Modality (TiM) reasoning,\nenabling flood prediction from basic Earth observation data such as Sentinel-1\nor Sentinel-2 imagery. Using paired EO and simulated flood maps from data-rich\nregions, ZeroFlood bridges data availability gaps through cross-modal\nrepresentation learning. Experiments with TerraMind and Prithvi GFMs show that\nTiM enhances model robustness, with the TerraMind-Large configuration achieving\nan F1 score of 67.21. The results demonstrate the feasibility of\nfoundation-model-based FSM as a scalable and data-efficient solution for flood\nrisk management.",
    "categories": [
      "cs.LG",
      "cs.AI"
    ],
    "published": "2025-10-27T14:14:09Z",
    "authors": [
      "Hyeongkyun Kim",
      "Orestis Oikonomou"
    ],
    "pdf_url": "http://arxiv.org/pdf/2510.23364v1"
  },
  {
    "id": "2510.23362v1",
    "title": "Robust Non-negative Proximal Gradient Algorithm for Inverse Problems",
    "abstract": "Proximal gradient algorithms (PGA), while foundational for inverse problems\nlike image reconstruction, often yield unstable convergence and suboptimal\nsolutions by violating the critical non-negativity constraint. We identify the\ngradient descent step as the root cause of this issue, which introduces\nnegative values and induces high sensitivity to hyperparameters. To overcome\nthese limitations, we propose a novel multiplicative update proximal gradient\nalgorithm (SSO-PGA) with convergence guarantees, which is designed for\nrobustness in non-negative inverse problems. Our key innovation lies in\nsuperseding the gradient descent step with a learnable sigmoid-based operator,\nwhich inherently enforces non-negativity and boundedness by transforming\ntraditional subtractive updates into multiplicative ones. This design,\naugmented by a sliding parameter for enhanced stability and convergence, not\nonly improves robustness but also boosts expressive capacity and noise\nimmunity. We further formulate a degradation model for multi-modal restoration\nand derive its SSO-PGA-based optimization algorithm, which is then unfolded\ninto a deep network to marry the interpretability of optimization with the\npower of deep learning. Extensive numerical and real-world experiments\ndemonstrate that our method significantly surpasses traditional PGA and other\nstate-of-the-art algorithms, ensuring superior performance and stability.",
    "categories": [
      "cs.LG",
      "stat.ML"
    ],
    "published": "2025-10-27T14:10:25Z",
    "authors": [
      "Hanzhang Wang",
      "Zonglin Liu",
      "Jingyi Xu",
      "Chenyang Wang",
      "Zhiwei Zhong",
      "Qiangqiang Shen"
    ],
    "pdf_url": "http://arxiv.org/pdf/2510.23362v1"
  },
  {
    "id": "2510.23347v1",
    "title": "Macroeconomic Forecasting for the G7 countries under Uncertainty Shocks",
    "abstract": "Accurate macroeconomic forecasting has become harder amid geopolitical\ndisruptions, policy reversals, and volatile financial markets. Conventional\nvector autoregressions (VARs) overfit in high dimensional settings, while\nthreshold VARs struggle with time varying interdependencies and complex\nparameter structures. We address these limitations by extending the Sims Zha\nBayesian VAR with exogenous variables (SZBVARx) to incorporate domain-informed\nshrinkage and four newspaper based uncertainty shocks such as economic policy\nuncertainty, geopolitical risk, US equity market volatility, and US monetary\npolicy uncertainty. The framework improves structural interpretability,\nmitigates dimensionality, and imposes empirically guided regularization. Using\nG7 data, we study spillovers from uncertainty shocks to five core variables\n(unemployment, real broad effective exchange rates, short term rates, oil\nprices, and CPI inflation), combining wavelet coherence (time frequency\ndynamics) with nonlinear local projections (state dependent impulse responses).\nOut-of-sample results at 12 and 24 month horizons show that SZBVARx outperforms\n14 benchmarks, including classical VARs and leading machine learning models, as\nconfirmed by Murphy difference diagrams, multivariate Diebold Mariano tests,\nand Giacomini White predictability tests. Credible Bayesian prediction\nintervals deliver robust uncertainty quantification for scenario analysis and\nrisk management. The proposed SZBVARx offers G7 policymakers a transparent,\nwell calibrated tool for modern macroeconomic forecasting under pervasive\nuncertainty.",
    "categories": [
      "econ.EM",
      "cs.LG",
      "stat.AP"
    ],
    "published": "2025-10-27T14:01:41Z",
    "authors": [
      "Shovon Sengupta",
      "Sunny Kumar Singh",
      "Tanujit Chakraborty"
    ],
    "pdf_url": "http://arxiv.org/pdf/2510.23347v1"
  },
  {
    "id": "2510.23346v1",
    "title": "Block-Diagonal LoRA for Eliminating Communication Overhead in Tensor\n  Parallel LoRA Serving",
    "abstract": "When serving a single base LLM with several different LoRA adapters\nsimultaneously, the adapters cannot simply be merged with the base model's\nweights as the adapter swapping would create overhead and requests using\ndifferent adapters could not be batched. Rather, the LoRA computations have to\nbe separated from the base LLM computations, and in a multi-device setup the\nLoRA adapters can be sharded in a way that is well aligned with the base\nmodel's tensor parallel execution, as proposed in S-LoRA. However, the S-LoRA\nsharding strategy encounters some communication overhead, which may be small in\ntheory, but can be large in practice. In this paper, we propose to constrain\ncertain LoRA factors to be block-diagonal, which allows for an alternative way\nof sharding LoRA adapters that does not require any additional communication\nfor the LoRA computations. We demonstrate in extensive experiments that our\nblock-diagonal LoRA approach is similarly parameter efficient as standard LoRA\n(i.e., for a similar number of parameters it achieves similar downstream\nperformance) and that it leads to significant end-to-end speed-up over S-LoRA.\nFor example, when serving on eight A100 GPUs, we observe up to 1.79x (1.23x)\nend-to-end speed-up with 0.87x (1.74x) the number of adapter parameters for\nLlama-3.1-70B, and up to 1.63x (1.3x) end-to-end speed-up with 0.86x (1.73x)\nthe number of adapter parameters for Llama-3.1-8B.",
    "categories": [
      "cs.LG"
    ],
    "published": "2025-10-27T14:01:29Z",
    "authors": [
      "Xinyu Wang",
      "Jonas M. K\u00fcbler",
      "Kailash Budhathoki",
      "Yida Wang",
      "Matth\u00e4us Kleindessner"
    ],
    "pdf_url": "http://arxiv.org/pdf/2510.23346v1"
  },
  {
    "id": "2510.25183v1",
    "title": "Sustainable NARMA-10 Benchmarking for Quantum Reservoir Computing",
    "abstract": "This study compares Quantum Reservoir Computing (QRC) with classical models\nsuch as Echo State Networks (ESNs) and Long Short-Term Memory networks (LSTMs),\nas well as hybrid quantum-classical architectures (QLSTM), for the nonlinear\nautoregressive moving average task (NARMA-10). We evaluate forecasting accuracy\n(NRMSE), computational cost, and evaluation time. Results show that QRC\nachieves competitive accuracy while offering potential sustainability\nadvantages, particularly in resource-constrained settings, highlighting its\npromise for sustainable time-series AI applications.",
    "categories": [
      "quant-ph",
      "cs.LG"
    ],
    "published": "2025-10-27T13:46:06Z",
    "authors": [
      "Avyay Kodali",
      "Priyanshi Singh",
      "Pranay Pandey",
      "Krishna Bhatia",
      "Shalini Devendrababu",
      "Srinjoy Ganguly"
    ],
    "pdf_url": "http://arxiv.org/pdf/2510.25183v1"
  },
  {
    "id": "2510.23330v1",
    "title": "The First Star-by-star $N$-body/Hydrodynamics Simulation of Our Galaxy\n  Coupling with a Surrogate Model",
    "abstract": "A major goal of computational astrophysics is to simulate the Milky Way\nGalaxy with sufficient resolution down to individual stars. However, the\nscaling fails due to some small-scale, short-timescale phenomena, such as\nsupernova explosions. We have developed a novel integration scheme of\n$N$-body/hydrodynamics simulations working with machine learning. This approach\nbypasses the short timesteps caused by supernova explosions using a surrogate\nmodel, thereby improving scalability. With this method, we reached 300 billion\nparticles using 148,900 nodes, equivalent to 7,147,200 CPU cores, breaking\nthrough the billion-particle barrier currently faced by state-of-the-art\nsimulations. This resolution allows us to perform the first star-by-star galaxy\nsimulation, which resolves individual stars in the Milky Way Galaxy. The\nperformance scales over $10^4$ CPU cores, an upper limit in the current\nstate-of-the-art simulations using both A64FX and X86-64 processors and NVIDIA\nCUDA GPUs.",
    "categories": [
      "astro-ph.GA",
      "cs.DC",
      "cs.LG",
      "physics.comp-ph"
    ],
    "published": "2025-10-27T13:45:55Z",
    "authors": [
      "Keiya Hirashima",
      "Michiko S. Fujii",
      "Takayuki R. Saitoh",
      "Naoto Harada",
      "Kentaro Nomura",
      "Kohji Yoshikawa",
      "Yutaka Hirai",
      "Tetsuro Asano",
      "Kana Moriwaki",
      "Masaki Iwasawa",
      "Takashi Okamoto",
      "Junichiro Makino"
    ],
    "pdf_url": "http://arxiv.org/pdf/2510.23330v1"
  },
  {
    "id": "2510.23327v1",
    "title": "GRAD: Real-Time Gated Recurrent Anomaly Detection in Autonomous Vehicle\n  Sensors Using Reinforced EMA and Multi-Stage Sliding Window Techniques",
    "abstract": "This paper introduces GRAD, a real-time anomaly detection method for\nautonomous vehicle sensors that integrates statistical analysis and deep\nlearning to ensure the reliability of sensor data. The proposed approach\ncombines the Reinforced Exponential Moving Average (REMA), which adapts\nsmoothing factors and thresholding for outlier detection, with the Multi-Stage\nSliding Window (MS-SW) technique for capturing both short- and long-term\npatterns. These features are processed using a lightweight Gated Recurrent Unit\n(GRU) model, which detects and classifies anomalies based on bias types, while\na recovery module restores damaged sensor data to ensure continuous system\noperation. GRAD has a lightweight architecture consisting of two layers of GRU\nwith a limited number of neurons that make it appropriate for real-time\napplications while maintaining high detection accuracy. The GRAD framework\nachieved remarkable performance in anomaly detection and classification. The\nmodel demonstrated an overall F1-score of 97.6% for abnormal data and 99.4% for\nnormal data, signifying its high accuracy in distinguishing between normal and\nanomalous sensor data. Regarding the anomaly classification, GRAD successfully\ncategorized different anomaly types with high precision, enabling the recovery\nmodule to accurately restore damaged sensor data. Relative to analogous\nstudies, GRAD surpasses current models by attaining a balance between elevated\ndetection accuracy and diminished computational expense. These results\ndemonstrate GRAD's potential as a reliable and efficient solution for real-time\nanomaly detection in autonomous vehicle systems, guaranteeing safe vehicle\noperation with minimal computational overhead.",
    "categories": [
      "cs.LG"
    ],
    "published": "2025-10-27T13:44:15Z",
    "authors": [
      "Mohammad Hossein Jafari Naeimi",
      "Ali Norouzi",
      "Athena Abdi"
    ],
    "pdf_url": "http://arxiv.org/pdf/2510.23327v1"
  },
  {
    "id": "2510.23325v1",
    "title": "Multitask Multimodal Self-Supervised Learning for Medical Images",
    "abstract": "This thesis works to address a pivotal challenge in medical image analysis:\nthe reliance on extensive labeled datasets, which are often limited due to the\nneed for expert annotation and constrained by privacy and legal issues. By\nfocusing on the development of self-supervised learning techniques and domain\nadaptation methods, this research aims to circumvent these limitations,\npresenting a novel approach to enhance the utility and efficacy of deep\nlearning in medical imaging.\n  Central to this thesis is the development of the Medformer, an innovative\nneural network architecture designed for multitask learning and deep domain\nadaptation. This model is adept at pre-training on diverse medical image\ndatasets, handling varying sizes and modalities, and is equipped with a dynamic\ninput-output adaptation mechanism. This enables efficient processing and\nintegration of a wide range of medical image types, from 2D X-rays to complex\n3D MRIs, thus mitigating the dependency on large labeled datasets.\n  Further, the thesis explores the current state of self-supervised learning in\nmedical imaging. It introduces novel pretext tasks that are capable of\nextracting meaningful information from unlabeled data, significantly advancing\nthe model's interpretative abilities. This approach is validated through\nrigorous experimentation, including the use of the MedMNIST dataset,\ndemonstrating the model's proficiency in learning generalized features\napplicable to various downstream tasks.\n  In summary, this thesis contributes to the advancement of medical image\nanalysis by offering a scalable, adaptable framework that reduces reliance on\nlabeled data. It paves the way for more accurate, efficient diagnostic tools in\nhealthcare, signifying a major step forward in the application of deep learning\nin medical imaging.",
    "categories": [
      "cs.CV",
      "cs.AI",
      "cs.LG"
    ],
    "published": "2025-10-27T13:42:16Z",
    "authors": [
      "Cristian Simionescu"
    ],
    "pdf_url": "http://arxiv.org/pdf/2510.23325v1"
  },
  {
    "id": "2510.23319v1",
    "title": "Arabic Little STT: Arabic Children Speech Recognition Dataset",
    "abstract": "The performance of Artificial Intelligence (AI) systems fundamentally depends\non high-quality training data. However, low-resource languages like Arabic\nsuffer from severe data scarcity. Moreover, the absence of child-specific\nspeech corpora is an essential gap that poses significant challenges. To\naddress this gap, we present our created dataset, Arabic Little STT, a dataset\nof Levantine Arabic child speech recorded in classrooms, containing 355\nutterances from 288 children (ages 6 - 13). We further conduct a systematic\nassessment of Whisper, a state-of-the-art automatic speech recognition (ASR)\nmodel, on this dataset and compare its performance with adult Arabic\nbenchmarks. Our evaluation across eight Whisper variants reveals that even the\nbest-performing model (Large_v3) struggles significantly, achieving a 0.66 word\nerror rate (WER) on child speech, starkly contrasting with its sub 0.20 WER on\nadult datasets. These results align with other research on English speech.\nResults highlight the critical need for dedicated child speech benchmarks and\ninclusive training data in ASR development. Emphasizing that such data must be\ngoverned by strict ethical and privacy frameworks to protect sensitive child\ninformation. We hope that this study provides an initial step for future work\non equitable speech technologies for Arabic-speaking children. We hope that our\npublicly available dataset enrich the children's demographic representation in\nASR datasets.",
    "categories": [
      "cs.CL",
      "cs.AI",
      "cs.HC",
      "cs.LG",
      "cs.SD"
    ],
    "published": "2025-10-27T13:30:54Z",
    "authors": [
      "Mouhand Alkadri",
      "Dania Desouki",
      "Khloud Al Jallad"
    ],
    "pdf_url": "http://arxiv.org/pdf/2510.23319v1"
  },
  {
    "id": "2510.23295v1",
    "title": "Predicting symbolic ODEs from multiple trajectories",
    "abstract": "We introduce MIO, a transformer-based model for inferring symbolic ordinary\ndifferential equations (ODEs) from multiple observed trajectories of a\ndynamical system. By combining multiple instance learning with\ntransformer-based symbolic regression, the model effectively leverages repeated\nobservations of the same system to learn more generalizable representations of\nthe underlying dynamics. We investigate different instance aggregation\nstrategies and show that even simple mean aggregation can substantially boost\nperformance. MIO is evaluated on systems ranging from one to four dimensions\nand under varying noise levels, consistently outperforming existing baselines.",
    "categories": [
      "cs.LG"
    ],
    "published": "2025-10-27T13:03:29Z",
    "authors": [
      "Yakup Emre \u015eahin",
      "Niki Kilbertus",
      "S\u00f6ren Becker"
    ],
    "pdf_url": "http://arxiv.org/pdf/2510.23295v1"
  },
  {
    "id": "2510.23288v1",
    "title": "Learning from Frustration: Torsor CNNs on Graphs",
    "abstract": "Most equivariant neural networks rely on a single global symmetry, limiting\ntheir use in domains where symmetries are instead local. We introduce Torsor\nCNNs, a framework for learning on graphs with local symmetries encoded as edge\npotentials -- group-valued transformations between neighboring coordinate\nframes. We establish that this geometric construction is fundamentally\nequivalent to the classical group synchronization problem, yielding: (1) a\nTorsor Convolutional Layer that is provably equivariant to local changes in\ncoordinate frames, and (2) the frustration loss -- a standalone geometric\nregularizer that encourages locally equivariant representations when added to\nany NN's training objective. The Torsor CNN framework unifies and generalizes\nseveral architectures -- including classical CNNs and Gauge CNNs on manifolds\n-- by operating on arbitrary graphs without requiring a global coordinate\nsystem or smooth manifold structure. We establish the mathematical foundations\nof this framework and demonstrate its applicability to multi-view 3D\nrecognition, where relative camera poses naturally define the required edge\npotentials.",
    "categories": [
      "cs.LG",
      "math.AT",
      "es: 68T07, 22E70"
    ],
    "published": "2025-10-27T12:59:45Z",
    "authors": [
      "Daiyuan Li",
      "Shreya Arya",
      "Robert Ghrist"
    ],
    "pdf_url": "http://arxiv.org/pdf/2510.23288v1"
  },
  {
    "id": "2510.23273v1",
    "title": "A Novel Framework for Multi-Modal Protein Representation Learning",
    "abstract": "Accurate protein function prediction requires integrating heterogeneous\nintrinsic signals (e.g., sequence and structure) with noisy extrinsic contexts\n(e.g., protein-protein interactions and GO term annotations). However, two key\nchallenges hinder effective fusion: (i) cross-modal distributional mismatch\namong embeddings produced by pre-trained intrinsic encoders, and (ii) noisy\nrelational graphs of extrinsic data that degrade GNN-based information\naggregation. We propose Diffused and Aligned Multi-modal Protein Embedding\n(DAMPE), a unified framework that addresses these through two core mechanisms.\nFirst, we propose Optimal Transport (OT)-based representation alignment that\nestablishes correspondence between intrinsic embedding spaces of different\nmodalities, effectively mitigating cross-modal heterogeneity. Second, we\ndevelop a Conditional Graph Generation (CGG)-based information fusion method,\nwhere a condition encoder fuses the aligned intrinsic embeddings to provide\ninformative cues for graph reconstruction. Meanwhile, our theoretical analysis\nimplies that the CGG objective drives this condition encoder to absorb\ngraph-aware knowledge into its produced protein representations. Empirically,\nDAMPE outperforms or matches state-of-the-art methods such as DPFunc on\nstandard GO benchmarks, achieving AUPR gains of 0.002-0.013 pp and Fmax gains\n0.004-0.007 pp. Ablation studies further show that OT-based alignment\ncontributes 0.043-0.064 pp AUPR, while CGG-based fusion adds 0.005-0.111 pp\nFmax. Overall, DAMPE offers a scalable and theoretically grounded approach for\nrobust multi-modal protein representation learning, substantially enhancing\nprotein function prediction.",
    "categories": [
      "cs.LG",
      "cs.AI",
      "q-bio.QM"
    ],
    "published": "2025-10-27T12:33:01Z",
    "authors": [
      "Runjie Zheng",
      "Zhen Wang",
      "Anjie Qiao",
      "Jiancong Xie",
      "Jiahua Rao",
      "Yuedong Yang"
    ],
    "pdf_url": "http://arxiv.org/pdf/2510.23273v1"
  },
  {
    "id": "2510.23264v1",
    "title": "PAHQ: Accelerating Automated Circuit Discovery through Mixed-Precision\n  Inference Optimization",
    "abstract": "Circuit discovery, which involves identifying sparse and task-relevant\nsubnetworks in pre-trained language models, is a cornerstone of mechanistic\ninterpretability. Automated Circuit Discovery (ACDC) has emerged as a pivotal\nmethodology in circuit discovery, but its application to large language models\nis severely limited by computational inefficiency and prohibitively high memory\nrequirements. Although several accelerated approaches have been proposed, they\nprimarily rely on linear approximations to ACDC, which significantly\ncompromises analytical faithfulness. Our proposed method for accelerating\nautomated circuit discovery, Per Attention Head Quantization (PAHQ), takes a\nfundamentally different approach by optimizing the efficiency of each\nindividual patching operation. PAHQ leverages a fundamental alignment between\nactivation patching and mixed-precision quantization (MPQ): interpretability\nanalysis through patching essentially performs targeted ablation studies.\nTherefore, we can maintain high precision exclusively for investigated\ncomponents while safely reducing precision elsewhere in the network.\nPAHQ-accelerated ACDC reduces runtime by up to 80\\% and memory consumption by\nup to 30\\% compared to unaccelerated ACDC while maintaining faithfulness.\nImportantly, our method readily integrates with existing edge-based circuit\ndiscovery techniques by modifying the attention computation mechanism. This\ntraining-free approach provides a practical and novel pathway for accelerating\nmechanistic interpretability methods. Our code is available at\nhttps://github.com/626619403/PAHQ.",
    "categories": [
      "cs.LG",
      "cs.AI"
    ],
    "published": "2025-10-27T12:24:14Z",
    "authors": [
      "Xinhai Wang",
      "Shu Yang",
      "Liangyu Wang",
      "Lin Zhang",
      "Huanyi Xie",
      "Lijie Hu",
      "Di Wang"
    ],
    "pdf_url": "http://arxiv.org/pdf/2510.23264v1"
  },
  {
    "id": "2510.23261v1",
    "title": "Toward Interpretable Evaluation Measures for Time Series Segmentation",
    "abstract": "Time series segmentation is a fundamental task in analyzing temporal data\nacross various domains, from human activity recognition to energy monitoring.\nWhile numerous state-of-the-art methods have been developed to tackle this\nproblem, the evaluation of their performance remains critically limited.\nExisting measures predominantly focus on change point accuracy or rely on\npoint-based measures such as Adjusted Rand Index (ARI), which fail to capture\nthe quality of the detected segments, ignore the nature of errors, and offer\nlimited interpretability. In this paper, we address these shortcomings by\nintroducing two novel evaluation measures: WARI (Weighted Adjusted Rand Index),\nthat accounts for the position of segmentation errors, and SMS (State Matching\nScore), a fine-grained measure that identifies and scores four fundamental\ntypes of segmentation errors while allowing error-specific weighting. We\nempirically validate WARI and SMS on synthetic and real-world benchmarks,\nshowing that they not only provide a more accurate assessment of segmentation\nquality but also uncover insights, such as error provenance and type, that are\ninaccessible with traditional measures.",
    "categories": [
      "cs.LG"
    ],
    "published": "2025-10-27T12:23:37Z",
    "authors": [
      "F\u00e9lix Chavelli",
      "Paul Boniol",
      "Micha\u00ebl Thomazo"
    ],
    "pdf_url": "http://arxiv.org/pdf/2510.23261v1"
  },
  {
    "id": "2510.23259v1",
    "title": "GCAO: Group-driven Clustering via Gravitational Attraction and\n  Optimization",
    "abstract": "Traditional clustering algorithms often struggle with high-dimensional and\nnon-uniformly distributed data, where low-density boundary samples are easily\ndisturbed by neighboring clusters, leading to unstable and distorted clustering\nresults. To address this issue, we propose a Group-driven Clustering via\nGravitational Attraction and Optimization (GCAO) algorithm. GCAO introduces a\ngroup-level optimization mechanism that aggregates low-density boundary points\ninto collaboratively moving groups, replacing the traditional point-based\ncontraction process. By combining local density estimation with neighborhood\ntopology, GCAO constructs effective gravitational interactions between groups\nand their surroundings, enhancing boundary clarity and structural consistency.\nUsing groups as basic motion units, a gravitational contraction strategy\nensures globally stable and directionally consistent convergence. Experiments\non multiple high-dimensional datasets demonstrate that GCAO outperforms 11\nrepresentative clustering methods, achieving average improvements of 37.13%,\n52.08%, 44.98%, and 38.81% in NMI, ARI, Homogeneity, and ACC, respectively,\nwhile maintaining competitive efficiency and scalability. These results\nhighlight GCAO's superiority in preserving cluster integrity, enhancing\nboundary separability, and ensuring robust performance on complex data\ndistributions.",
    "categories": [
      "cs.LG",
      "stat.ML"
    ],
    "published": "2025-10-27T12:22:24Z",
    "authors": [
      "Qi Li",
      "Jun Wang"
    ],
    "pdf_url": "http://arxiv.org/pdf/2510.23259v1"
  },
  {
    "id": "2510.23258v1",
    "title": "Deep Active Inference with Diffusion Policy and Multiple Timescale World\n  Model for Real-World Exploration and Navigation",
    "abstract": "Autonomous robotic navigation in real-world environments requires exploration\nto acquire environmental information as well as goal-directed navigation in\norder to reach specified targets. Active inference (AIF) based on the\nfree-energy principle provides a unified framework for these behaviors by\nminimizing the expected free energy (EFE), thereby combining epistemic and\nextrinsic values. To realize this practically, we propose a deep AIF framework\nthat integrates a diffusion policy as the policy model and a multiple timescale\nrecurrent state-space model (MTRSSM) as the world model. The diffusion policy\ngenerates diverse candidate actions while the MTRSSM predicts their\nlong-horizon consequences through latent imagination, enabling action selection\nthat minimizes EFE. Real-world navigation experiments demonstrated that our\nframework achieved higher success rates and fewer collisions compared with the\nbaselines, particularly in exploration-demanding scenarios. These results\nhighlight how AIF based on EFE minimization can unify exploration and\ngoal-directed navigation in real-world robotic settings.",
    "categories": [
      "cs.RO",
      "cs.AI",
      "cs.LG"
    ],
    "published": "2025-10-27T12:21:33Z",
    "authors": [
      "Riko Yokozawa",
      "Kentaro Fujii",
      "Yuta Nomura",
      "Shingo Murata"
    ],
    "pdf_url": "http://arxiv.org/pdf/2510.23258v1"
  },
  {
    "id": "2510.23254v1",
    "title": "Provable test-time adaptivity and distributional robustness of\n  in-context learning",
    "abstract": "We study in-context learning problems where a Transformer is pretrained on\ntasks drawn from a mixture distribution $\\pi=\\sum_{\\alpha\\in\\mathcal{A}}\n\\lambda_{\\alpha} \\pi_{\\alpha}$, called the pretraining prior, in which each\nmixture component $\\pi_{\\alpha}$ is a distribution on tasks of a specific\ndifficulty level indexed by $\\alpha$. Our goal is to understand the performance\nof the pretrained Transformer when evaluated on a different test distribution\n$\\mu$, consisting of tasks of fixed difficulty $\\beta\\in\\mathcal{A}$, and with\npotential distribution shift relative to $\\pi_\\beta$, subject to the\nchi-squared divergence $\\chi^2(\\mu,\\pi_{\\beta})$ being at most $\\kappa$. In\nparticular, we consider nonparametric regression problems with random\nsmoothness, and multi-index models with random smoothness as well as random\neffective dimension. We prove that a large Transformer pretrained on sufficient\ndata achieves the optimal rate of convergence corresponding to the difficulty\nlevel $\\beta$, uniformly over test distributions $\\mu$ in the chi-squared\ndivergence ball. Thus, the pretrained Transformer is able to achieve faster\nrates of convergence on easier tasks and is robust to distribution shift at\ntest time. Finally, we prove that even if an estimator had access to the test\ndistribution $\\mu$, the convergence rate of its expected risk over $\\mu$ could\nnot be faster than that of our pretrained Transformers, thereby providing a\nmore appropriate optimality guarantee than minimax lower bounds.",
    "categories": [
      "stat.ML",
      "cs.LG",
      "math.ST",
      "stat.TH",
      "62G08, 68T07"
    ],
    "published": "2025-10-27T12:16:49Z",
    "authors": [
      "Tianyi Ma",
      "Tengyao Wang",
      "Richard J. Samworth"
    ],
    "pdf_url": "http://arxiv.org/pdf/2510.23254v1"
  },
  {
    "id": "2510.23241v1",
    "title": "Progressive Growing of Patch Size: Curriculum Learning for Accelerated\n  and Improved Medical Image Segmentation",
    "abstract": "In this work, we introduce Progressive Growing of Patch Size, an automatic\ncurriculum learning approach for 3D medical image segmentation. Our approach\nprogressively increases the patch size during model training, resulting in an\nimproved class balance for smaller patch sizes and accelerated convergence of\nthe training process. We evaluate our curriculum approach in two settings: a\nresource-efficient mode and a performance mode, both regarding Dice score\nperformance and computational costs across 15 diverse and popular 3D medical\nimage segmentation tasks. The resource-efficient mode matches the Dice score\nperformance of the conventional constant patch size sampling baseline with a\nnotable reduction in training time to only 44%. The performance mode improves\nupon constant patch size segmentation results, achieving a statistically\nsignificant relative mean performance gain of 1.28% in Dice Score. Remarkably,\nacross all 15 tasks, our proposed performance mode manages to surpass the\nconstant patch size baseline in Dice Score performance, while simultaneously\nreducing training time to only 89%. The benefits are particularly pronounced\nfor highly imbalanced tasks such as lesion segmentation tasks. Rigorous\nexperiments demonstrate that our performance mode not only improves mean\nsegmentation performance but also reduces performance variance, yielding more\ntrustworthy model comparison. Furthermore, our findings reveal that the\nproposed curriculum sampling is not tied to a specific architecture but\nrepresents a broadly applicable strategy that consistently boosts performance\nacross diverse segmentation models, including UNet, UNETR, and SwinUNETR. In\nsummary, we show that this simple yet elegant transformation on input data\nsubstantially improves both Dice Score performance and training runtime, while\nbeing compatible across diverse segmentation backbones.",
    "categories": [
      "cs.CV",
      "cs.AI",
      "cs.LG"
    ],
    "published": "2025-10-27T11:55:12Z",
    "authors": [
      "Stefan M. Fischer",
      "Johannes Kiechle",
      "Laura Daza",
      "Lina Felsner",
      "Richard Osuala",
      "Daniel M. Lang",
      "Karim Lekadir",
      "Jan C. Peeken",
      "Julia A. Schnabel"
    ],
    "pdf_url": "http://arxiv.org/pdf/2510.23241v1"
  },
  {
    "id": "2510.23237v1",
    "title": "Robust Iterative Learning Hidden Quantum Markov Models",
    "abstract": "Hidden Quantum Markov Models (HQMMs) extend classical Hidden Markov Models to\nthe quantum domain, offering a powerful probabilistic framework for modeling\nsequential data with quantum coherence. However, existing HQMM learning\nalgorithms are highly sensitive to data corruption and lack mechanisms to\nensure robustness under adversarial perturbations. In this work, we introduce\nthe Adversarially Corrupted HQMM (AC-HQMM), which formalizes robustness\nanalysis by allowing a controlled fraction of observation sequences to be\nadversarially corrupted. To learn AC-HQMMs, we propose the Robust Iterative\nLearning Algorithm (RILA), a derivative-free method that integrates a Remove\nCorrupted Rows by Entropy Filtering (RCR-EF) module with an iterative\nstochastic resampling procedure for physically valid Kraus operator updates.\nRILA incorporates L1-penalized likelihood objectives to enhance stability,\nresist overfitting, and remain effective under non-differentiable conditions.\nAcross multiple HQMM and HMM benchmarks, RILA demonstrates superior convergence\nstability, corruption resilience, and preservation of physical validity\ncompared to existing algorithms, establishing a principled and efficient\napproach for robust quantum sequential learning.",
    "categories": [
      "cs.LG",
      "quant-ph",
      "stat.CO",
      "stat.ME",
      "stat.ML"
    ],
    "published": "2025-10-27T11:48:44Z",
    "authors": [
      "Ning Ning"
    ],
    "pdf_url": "http://arxiv.org/pdf/2510.23237v1"
  },
  {
    "id": "2510.23235v1",
    "title": "Grassmanian Interpolation of Low-Pass Graph Filters: Theory and\n  Applications",
    "abstract": "Low-pass graph filters are fundamental for signal processing on graphs and\nother non-Euclidean domains. However, the computation of such filters for\nparametric graph families can be prohibitively expensive as computation of the\ncorresponding low-frequency subspaces, requires the repeated solution of an\neigenvalue problem. We suggest a novel algorithm of low-pass graph filter\ninterpolation based on Riemannian interpolation in normal coordinates on the\nGrassmann manifold. We derive an error bound estimate for the subspace\ninterpolation and suggest two possible applications for induced parametric\ngraph families. First, we argue that the temporal evolution of the node\nfeatures may be translated to the evolving graph topology via a similarity\ncorrection to adjust the homophily degree of the network. Second, we suggest a\ndot product graph family induced by a given static graph which allows to infer\nimproved message passing scheme for node classification facilitated by the\nfilter interpolation.",
    "categories": [
      "cs.LG",
      "cs.NA",
      "cs.SI",
      "eess.SP",
      "math.NA",
      "math.SP"
    ],
    "published": "2025-10-27T11:40:14Z",
    "authors": [
      "Anton Savostianov",
      "Michael T. Schaub",
      "Benjamin Stamm"
    ],
    "pdf_url": "http://arxiv.org/pdf/2510.23235v1"
  },
  {
    "id": "2510.23216v3",
    "title": "Human-Like Goalkeeping in a Realistic Football Simulation: a\n  Sample-Efficient Reinforcement Learning Approach",
    "abstract": "While several high profile video games have served as testbeds for Deep\nReinforcement Learning (DRL), this technique has rarely been employed by the\ngame industry for crafting authentic AI behaviors. Previous research focuses on\ntraining super-human agents with large models, which is impractical for game\nstudios with limited resources aiming for human-like agents. This paper\nproposes a sample-efficient DRL method tailored for training and fine-tuning\nagents in industrial settings such as the video game industry. Our method\nimproves sample efficiency of value-based DRL by leveraging pre-collected data\nand increasing network plasticity. We evaluate our method training a goalkeeper\nagent in EA SPORTS FC 25, one of the best-selling football simulations today.\nOur agent outperforms the game's built-in AI by 10% in ball saving rate.\nAblation studies show that our method trains agents 50% faster compared to\nstandard DRL methods. Finally, qualitative evaluation from domain experts\nindicates that our approach creates more human-like gameplay compared to\nhand-crafted agents. As a testament to the impact of the approach, the method\nhas been adopted for use in the most recent release of the series.",
    "categories": [
      "cs.AI",
      "cs.LG"
    ],
    "published": "2025-10-27T11:06:00Z",
    "authors": [
      "Alessandro Sestini",
      "Joakim Bergdahl",
      "Jean-Philippe Barrette-LaPierre",
      "Florian Fuchs",
      "Brady Chen",
      "Michael Jones",
      "Linus Gissl\u00e9n"
    ],
    "pdf_url": "http://arxiv.org/pdf/2510.23216v3"
  },
  {
    "id": "2510.23215v1",
    "title": "Accelerating Eigenvalue Dataset Generation via Chebyshev Subspace Filter",
    "abstract": "Eigenvalue problems are among the most important topics in many scientific\ndisciplines. With the recent surge and development of machine learning, neural\neigenvalue methods have attracted significant attention as a forward pass of\ninference requires only a tiny fraction of the computation time compared to\ntraditional solvers. However, a key limitation is the requirement for large\namounts of labeled data in training, including operators and their eigenvalues.\nTo tackle this limitation, we propose a novel method, named Sorting Chebyshev\nSubspace Filter (SCSF), which significantly accelerates eigenvalue data\ngeneration by leveraging similarities between operators -- a factor overlooked\nby existing methods. Specifically, SCSF employs truncated fast Fourier\ntransform sorting to group operators with similar eigenvalue distributions and\nconstructs a Chebyshev subspace filter that leverages eigenpairs from\npreviously solved problems to assist in solving subsequent ones, reducing\nredundant computations. To the best of our knowledge, SCSF is the first method\nto accelerate eigenvalue data generation. Experimental results show that SCSF\nachieves up to a $3.5\\times$ speedup compared to various numerical solvers.",
    "categories": [
      "cs.LG",
      "cs.AI",
      "cs.NA",
      "math.NA"
    ],
    "published": "2025-10-27T11:05:16Z",
    "authors": [
      "Hong Wang",
      "Jie Wang",
      "Jian Luo",
      "huanshuo dong",
      "Yeqiu Chen",
      "Runmin Jiang",
      "Zhen huang"
    ],
    "pdf_url": "http://arxiv.org/pdf/2510.23215v1"
  },
  {
    "id": "2510.23208v1",
    "title": "Increasing LLM Coding Capabilities through Diverse Synthetic Coding\n  Tasks",
    "abstract": "Large language models (LLMs) have shown impressive promise in code\ngeneration, yet their progress remains limited by the shortage of large-scale\ndatasets that are both diverse and well-aligned with human reasoning. Most\nexisting resources pair problems with solutions, but omit the intermediate\nthought process that guides coding. To close this gap, we present a scalable\nsynthetic data generation pipeline that produces nearly 800k\ninstruction-reasoning-code-test quadruplets. Each sample combines a task, a\nstep-by-step reasoning trace, a working solution, and executable tests,\nenabling models to learn not just the what but also the how of problem solving.\nOur pipeline combines four key components: curated contest problems, web-mined\ncontent filtered by relevance classifiers, data expansion guided by reasoning\npatterns, and multi-stage execution-based validation. A genetic mutation\nalgorithm further increases task diversity while maintaining consistency\nbetween reasoning traces and code implementations. Our key finding is that\nfine-tuning LLMs on this dataset yields consistent improvements on coding\nbenchmarks. Beyond raw accuracy, reasoning-aware data can substitute for model\nscaling, generalize across architectures, and outperform leading open-source\nalternatives under identical sample budgets. Our work establishes\nreasoning-centered synthetic data generation as an efficient approach for\nadvancing coding capabilities in LLMs. We publish our dataset and generation\npipeline to facilitate further research.",
    "categories": [
      "cs.LG",
      "cs.AI"
    ],
    "published": "2025-10-27T10:54:25Z",
    "authors": [
      "Amal Abed",
      "Ivan Lukic",
      "J\u00f6rg K. H. Franke",
      "Frank Hutter"
    ],
    "pdf_url": "http://arxiv.org/pdf/2510.23208v1"
  },
  {
    "id": "2510.23199v1",
    "title": "Rate-optimal Design for Anytime Best Arm Identification",
    "abstract": "We consider the best arm identification problem, where the goal is to\nidentify the arm with the highest mean reward from a set of $K$ arms under a\nlimited sampling budget. This problem models many practical scenarios such as\nA/B testing. We consider a class of algorithms for this problem, which is\nprovably minimax optimal up to a constant factor. This idea is a generalization\nof existing works in fixed-budget best arm identification, which are limited to\na particular choice of risk measures. Based on the framework, we propose Almost\nTracking, a closed-form algorithm that has a provable guarantee on the popular\nrisk measure $H_1$. Unlike existing algorithms, Almost Tracking does not\nrequire the total budget in advance nor does it need to discard a significant\npart of samples, which gives a practical advantage. Through experiments on\nsynthetic and real-world datasets, we show that our algorithm outperforms\nexisting anytime algorithms as well as fixed-budget algorithms.",
    "categories": [
      "stat.ML",
      "cs.LG"
    ],
    "published": "2025-10-27T10:36:56Z",
    "authors": [
      "Junpei Komiyama",
      "Kyoungseok Jang",
      "Junya Honda"
    ],
    "pdf_url": "http://arxiv.org/pdf/2510.23199v1"
  },
  {
    "id": "2510.23198v1",
    "title": "PTPP-Aware Adaptation Scaling Laws: Predicting Domain-Adaptation\n  Performance at Unseen Pre-Training Budgets",
    "abstract": "Continual pre-training (CPT) for domain adaptation must balance target-domain\ngains with stability on the base domain. Existing CPT scaling laws typically\nassume a fixed pre-training budget, which limits their ability to forecast\nadaptation outcomes for models trained at different tokens-per-parameter\n(PTPP). We present \\emph{PTPP-aware} adaptation scaling laws that make the\npre-training budget an explicit variable, enabling accurate \\emph{prediction}\nof adaptation loss at unseen \\ptpp. On a multilingual setup (English/Arabic\n$\\rightarrow$ French), PTPP-aware formulations trained on early stages\n(\\ptpp{}=\\{15,31\\}) predict target loss at \\ptpp{}=279 and outperform a\nPTPP-agnostic \\dcpt{} transfer baseline on metrics (Huber-on-log,\nMAE$_\\mathrm{rel}$, calibration slope); full diagnostics (RMSE, MAPE) are in\nthe appendix. Beyond forecasting, we show a practical use case: planning replay\nratios and adaptation token budgets that satisfy target and forgetting\nconstraints under compute limits.",
    "categories": [
      "cs.LG",
      "cs.AI",
      "cs.CL"
    ],
    "published": "2025-10-27T10:36:15Z",
    "authors": [
      "Etienne Goffinet",
      "Shane Bergsma",
      "Avraham Sheinin",
      "Natalia Vassilieva",
      "Shaheer Muhammad",
      "Preslav Nakov",
      "Gurpreet Gosal"
    ],
    "pdf_url": "http://arxiv.org/pdf/2510.23198v1"
  },
  {
    "id": "2510.23191v1",
    "title": "The Benchmarking Epistemology: Construct Validity for Evaluating Machine\n  Learning Models",
    "abstract": "Predictive benchmarking, the evaluation of machine learning models based on\npredictive performance and competitive ranking, is a central epistemic practice\nin machine learning research and an increasingly prominent method for\nscientific inquiry. Yet, benchmark scores alone provide at best measurements of\nmodel performance relative to an evaluation dataset and a concrete learning\nproblem. Drawing substantial scientific inferences from the results, say about\ntheoretical tasks like image classification, requires additional assumptions\nabout the theoretical structure of the learning problems, evaluation functions,\nand data distributions. We make these assumptions explicit by developing\nconditions of construct validity inspired by psychological measurement theory.\nWe examine these assumptions in practice through three case studies, each\nexemplifying a typical intended inference: measuring engineering progress in\ncomputer vision with ImageNet; evaluating policy-relevant weather predictions\nwith WeatherBench; and examining limitations of the predictability of life\nevents with the Fragile Families Challenge. Our framework clarifies the\nconditions under which benchmark scores can support diverse scientific claims,\nbringing predictive benchmarking into perspective as an epistemological\npractice and a key site of conceptual and theoretical reasoning in machine\nlearning.",
    "categories": [
      "cs.LG",
      "stat.ML"
    ],
    "published": "2025-10-27T10:30:30Z",
    "authors": [
      "Timo Freiesleben",
      "Sebastian Zezulka"
    ],
    "pdf_url": "http://arxiv.org/pdf/2510.23191v1"
  },
  {
    "id": "2510.23189v1",
    "title": "DREaM: Drug-Drug Relation Extraction via Transfer Learning Method",
    "abstract": "Relation extraction between drugs plays a crucial role in identifying drug\ndrug interactions and predicting side effects. The advancement of machine\nlearning methods in relation extraction, along with the development of large\nmedical text databases, has enabled the low cost extraction of such relations\ncompared to other approaches that typically require expert knowledge. However,\nto the best of our knowledge, there are limited datasets specifically designed\nfor drug drug relation extraction currently available. Therefore, employing\ntransfer learning becomes necessary to apply machine learning methods in this\ndomain. In this study, we propose DREAM, a method that first employs a trained\nrelation extraction model to discover relations between entities and then\napplies this model to a corpus of medical texts to construct an ontology of\ndrug relationships. The extracted relations are subsequently validated using a\nlarge language model. Quantitative results indicate that the LLM agreed with 71\nof the relations extracted from a subset of PubMed abstracts. Furthermore, our\nqualitative analysis indicates that this approach can uncover ambiguities in\nthe medical domain, highlighting the challenges inherent in relation extraction\nin this field.",
    "categories": [
      "cs.CL",
      "cs.AI",
      "cs.LG"
    ],
    "published": "2025-10-27T10:27:00Z",
    "authors": [
      "Ali Fata",
      "Hossein Rahmani",
      "Parinaz Soltanzadeh",
      "Amirhossein Derakhshan",
      "Behrouz Minaei Bidgoli"
    ],
    "pdf_url": "http://arxiv.org/pdf/2510.23189v1"
  },
  {
    "id": "2510.23181v1",
    "title": "Physics-informed diffusion models for extrapolating crystal structures\n  beyond known motifs",
    "abstract": "Discovering materials with previously unreported crystal frameworks is key to\nachieving transformative functionality. Generative artificial intelligence\noffers a scalable means to propose candidate crystal structures, however\nexisting approaches mainly reproduce decorated variants of established motifs\nrather than uncover new configurations. Here we develop a physics-informed\ndiffusion method, supported by chemically grounded validation protocol, which\nembeds descriptors of compactness and local environment diversity to balance\nphysical plausibility with structural novelty. Conditioning on these metrics\nimproves generative performance across architectures, increasing the fraction\nof structures outside 100 most common prototypes up to 67%. When crystal\nstructure prediction (CSP) is seeded with generative structures, most\ncandidates (97%) are reconstructed by CSP, yielding 145 (66%) low-energy\nframeworks not matching any known prototypes. These results show that while\ngenerative models are not substitutes for CSP, their chemically informed,\ndiversity-guided outputs can enhance CSP efficiency, establishing a practical\ngenerative-CSP synergy for discovery-oriented exploration of chemical space.",
    "categories": [
      "cond-mat.mtrl-sci",
      "cs.LG"
    ],
    "published": "2025-10-27T10:21:35Z",
    "authors": [
      "Andrij Vasylenko",
      "Federico Ottomano",
      "Christopher M. Collins",
      "Rahul Savani",
      "Matthew S. Dyer",
      "Matthew J. Rosseinsky"
    ],
    "pdf_url": "http://arxiv.org/pdf/2510.23181v1"
  },
  {
    "id": "2510.23176v1",
    "title": "TARC: Time-Adaptive Robotic Control",
    "abstract": "Fixed-frequency control in robotics imposes a trade-off between the\nefficiency of low-frequency control and the robustness of high-frequency\ncontrol, a limitation not seen in adaptable biological systems. We address this\nwith a reinforcement learning approach in which policies jointly select control\nactions and their application durations, enabling robots to autonomously\nmodulate their control frequency in response to situational demands. We\nvalidate our method with zero-shot sim-to-real experiments on two distinct\nhardware platforms: a high-speed RC car and a quadrupedal robot. Our method\nmatches or outperforms fixed-frequency baselines in terms of rewards while\nsignificantly reducing the control frequency and exhibiting adaptive frequency\ncontrol under real-world conditions.",
    "categories": [
      "cs.RO",
      "cs.LG"
    ],
    "published": "2025-10-27T10:10:19Z",
    "authors": [
      "Arnav Sukhija",
      "Lenart Treven",
      "Jin Cheng",
      "Florian D\u00f6rfler",
      "Stelian Coros",
      "Andreas Krause"
    ],
    "pdf_url": "http://arxiv.org/pdf/2510.23176v1"
  },
  {
    "id": "2510.24791v1",
    "title": "A Re-node Self-training Approach for Deep Graph-based Semi-supervised\n  Classification on Multi-view Image Data",
    "abstract": "Recently, graph-based semi-supervised learning and pseudo-labeling have\ngained attention due to their effectiveness in reducing the need for extensive\ndata annotations. Pseudo-labeling uses predictions from unlabeled data to\nimprove model training, while graph-based methods are characterized by\nprocessing data represented as graphs. However, the lack of clear graph\nstructures in images combined with the complexity of multi-view data limits the\nefficiency of traditional and existing techniques. Moreover, the integration of\ngraph structures in multi-view data is still a challenge. In this paper, we\npropose Re-node Self-taught Graph-based Semi-supervised Learning for Multi-view\nData (RSGSLM). Our method addresses these challenges by (i) combining linear\nfeature transformation and multi-view graph fusion within a Graph Convolutional\nNetwork (GCN) framework, (ii) dynamically incorporating pseudo-labels into the\nGCN loss function to improve classification in multi-view data, and (iii)\ncorrecting topological imbalances by adjusting the weights of labeled samples\nnear class boundaries. Additionally, (iv) we introduce an unsupervised\nsmoothing loss applicable to all samples. This combination optimizes\nperformance while maintaining computational efficiency. Experimental results on\nmulti-view benchmark image datasets demonstrate that RSGSLM surpasses existing\nsemi-supervised learning approaches in multi-view contexts.",
    "categories": [
      "cs.CV",
      "cs.LG"
    ],
    "published": "2025-10-27T10:02:53Z",
    "authors": [
      "Jingjun Bi",
      "Fadi Dornaika"
    ],
    "pdf_url": "http://arxiv.org/pdf/2510.24791v1"
  },
  {
    "id": "2510.23171v1",
    "title": "Benchmarking VQE Configurations: Architectures, Initializations, and\n  Optimizers for Silicon Ground State Energy",
    "abstract": "Quantum computing presents a promising path toward precise quantum chemical\nsimulations, particularly for systems that challenge classical methods. This\nwork investigates the performance of the Variational Quantum Eigensolver (VQE)\nin estimating the ground-state energy of the silicon atom, a relatively heavy\nelement that poses significant computational complexity. Within a hybrid\nquantum-classical optimization framework, we implement VQE using a range of\nansatz, including Double Excitation Gates, ParticleConservingU2, UCCSD, and\nk-UpCCGSD, combined with various optimizers such as gradient descent, SPSA, and\nADAM. The main contribution of this work lies in a systematic methodological\nexploration of how these configuration choices interact to influence VQE\nperformance, establishing a structured benchmark for selecting optimal settings\nin quantum chemical simulations. Key findings show that parameter\ninitialization plays a decisive role in the algorithm's stability, and that the\ncombination of a chemically inspired ansatz with adaptive optimization yields\nsuperior convergence and precision compared to conventional approaches.",
    "categories": [
      "quant-ph",
      "cs.LG"
    ],
    "published": "2025-10-27T09:57:26Z",
    "authors": [
      "Zakaria Boutakka",
      "Nouhaila Innan",
      "Muhammed Shafique",
      "Mohamed Bennai",
      "Z. Sakhi"
    ],
    "pdf_url": "http://arxiv.org/pdf/2510.23171v1"
  },
  {
    "id": "2510.23156v1",
    "title": "Enabling Vibration-Based Gesture Recognition on Everyday Furniture via\n  Energy-Efficient FPGA Implementation of 1D Convolutional Networks",
    "abstract": "The growing demand for smart home interfaces has increased interest in\nnon-intrusive sensing methods like vibration-based gesture recognition. While\nprior studies demonstrated feasibility, they often rely on complex\npreprocessing and large Neural Networks (NNs) requiring costly high-performance\nhardware, resulting in high energy usage and limited real-world deployability.\nThis study proposes an energy-efficient solution deploying compact NNs on\nlow-power Field-Programmable Gate Arrays (FPGAs) to enable real-time gesture\nrecognition with competitive accuracy. We adopt a series of optimizations: (1)\nWe replace complex spectral preprocessing with raw waveform input, eliminating\ncomplex on-board preprocessing while reducing input size by 21x without\nsacrificing accuracy. (2) We design two lightweight architectures (1D-CNN and\n1D-SepCNN) tailored for embedded FPGAs, reducing parameters from 369 million to\nas few as 216 while maintaining comparable accuracy. (3) With integer-only\nquantization and automated RTL generation, we achieve seamless FPGA deployment.\nA ping-pong buffering mechanism in 1D-SepCNN further improves deployability\nunder tight memory constraints. (4) We extend a hardware-aware search framework\nto support constraint-driven model configuration selection, considering\naccuracy, deployability, latency, and energy consumption. Evaluated on two\nswipe-direction datasets with multiple users and ordinary tables, our approach\nachieves low-latency, energy-efficient inference on the AMD Spartan-7 XC7S25\nFPGA. Under the PS data splitting setting, the selected 6-bit 1D-CNN reaches\n0.970 average accuracy across users with 9.22 ms latency. The chosen 8-bit\n1D-SepCNN further reduces latency to 6.83 ms (over 53x CPU speedup) with\nslightly lower accuracy (0.949). Both consume under 1.2 mJ per inference,\ndemonstrating suitability for long-term edge operation.",
    "categories": [
      "cs.LG",
      "cs.AI"
    ],
    "published": "2025-10-27T09:30:36Z",
    "authors": [
      "Koki Shibata",
      "Tianheng Ling",
      "Chao Qian",
      "Tomokazu Matsui",
      "Hirohiko Suwa",
      "Keiichi Yasumoto",
      "Gregor Schiele"
    ],
    "pdf_url": "http://arxiv.org/pdf/2510.23156v1"
  },
  {
    "id": "2510.23151v1",
    "title": "AG-Fusion: adaptive gated multimodal fusion for 3d object detection in\n  complex scenes",
    "abstract": "Multimodal camera-LiDAR fusion technology has found extensive application in\n3D object detection, demonstrating encouraging performance. However, existing\nmethods exhibit significant performance degradation in challenging scenarios\ncharacterized by sensor degradation or environmental disturbances. We propose a\nnovel Adaptive Gated Fusion (AG-Fusion) approach that selectively integrates\ncross-modal knowledge by identifying reliable patterns for robust detection in\ncomplex scenes. Specifically, we first project features from each modality into\na unified BEV space and enhance them using a window-based attention mechanism.\nSubsequently, an adaptive gated fusion module based on cross-modal attention is\ndesigned to integrate these features into reliable BEV representations robust\nto challenging environments. Furthermore, we construct a new dataset named\nExcavator3D (E3D) focusing on challenging excavator operation scenarios to\nbenchmark performance in complex conditions. Our method not only achieves\ncompetitive performance on the standard KITTI dataset with 93.92% accuracy, but\nalso significantly outperforms the baseline by 24.88% on the challenging E3D\ndataset, demonstrating superior robustness to unreliable modal information in\ncomplex industrial scenes.",
    "categories": [
      "cs.CV",
      "cs.LG"
    ],
    "published": "2025-10-27T09:26:27Z",
    "authors": [
      "Sixian Liu",
      "Chen Xu",
      "Qiang Wang",
      "Donghai Shi",
      "Yiwen Li"
    ],
    "pdf_url": "http://arxiv.org/pdf/2510.23151v1"
  },
  {
    "id": "2510.23149v1",
    "title": "Complexity Dependent Error Rates for Physics-informed Statistical\n  Learning via the Small-ball Method",
    "abstract": "Physics-informed statistical learning (PISL) integrates empirical data with\nphysical knowledge to enhance the statistical performance of estimators. While\nPISL methods are widely used in practice, a comprehensive theoretical\nunderstanding of how informed regularization affects statistical properties is\nstill missing. Specifically, two fundamental questions have yet to be fully\naddressed: (1) what is the trade-off between considering soft penalties versus\nhard constraints, and (2) what is the statistical gain of incorporating\nphysical knowledge compared to purely data-driven empirical error minimisation.\nIn this paper, we address these questions for PISL in convex classes of\nfunctions under physical knowledge expressed as linear equations by developing\nappropriate complexity dependent error rates based on the small-ball method. We\nshow that, under suitable assumptions, (1) the error rates of physics-informed\nestimators are comparable to those of hard constrained empirical error\nminimisers, differing only by constant terms, and that (2) informed\npenalization can effectively reduce model complexity, akin to dimensionality\nreduction, thereby improving learning performance. This work establishes a\ntheoretical framework for evaluating the statistical properties of\nphysics-informed estimators in convex classes of functions, contributing to\nclosing the gap between statistical theory and practical PISL, with potential\napplications to cases not yet explored in the literature.",
    "categories": [
      "stat.ML",
      "cs.LG",
      "math.ST",
      "stat.TH"
    ],
    "published": "2025-10-27T09:26:07Z",
    "authors": [
      "Diego Marcondes"
    ],
    "pdf_url": "http://arxiv.org/pdf/2510.23149v1"
  },
  {
    "id": "2510.23148v1",
    "title": "Adapting Interleaved Encoders with PPO for Language-Guided Reinforcement\n  Learning in BabyAI",
    "abstract": "Deep reinforcement learning agents often struggle when tasks require\nunderstanding both vision and language. Conventional architectures typically\nisolate perception (for example, CNN-based visual encoders) from\ndecision-making (policy networks). This separation can be inefficient, since\nthe policy's failures do not directly help the perception module learn what is\nimportant. To address this, we implement the Perception-Decision Interleaving\nTransformer (PDiT) architecture introduced by Mao et al. (2023), a model that\nalternates between perception and decision layers within a single transformer.\nThis interleaving allows feedback from decision-making to refine perceptual\nfeatures dynamically. In addition, we integrate a contrastive loss inspired by\nCLIP to align textual mission embeddings with visual scene features. We\nevaluate the PDiT encoders on the BabyAI GoToLocal environment and find that\nthe approach achieves more stable rewards and stronger alignment compared to a\nstandard PPO baseline. The results suggest that interleaved transformer\nencoders are a promising direction for developing more integrated autonomous\nagents.",
    "categories": [
      "cs.LG",
      "cs.AI",
      "eess.IV",
      "I.2.6; I.2.9; I.5.4"
    ],
    "published": "2025-10-27T09:24:51Z",
    "authors": [
      "Aryan Mathur",
      "Asaduddin Ahmed"
    ],
    "pdf_url": "http://arxiv.org/pdf/2510.23148v1"
  },
  {
    "id": "2510.23142v1",
    "title": "Rethinking GSPO: The Perplexity-Entropy Equivalence",
    "abstract": "We provide a new perspective on GSPO's length-normalized importance ratios by\nestablishing their connection to information-theoretic quantities. We show that\nGSPO's sequence-level weight $s(\\theta) =\n(\\pi_\\theta/\\pi_{\\theta_{\\text{old}}})^{1/|y|}$ can be equivalently expressed\nas the inverse perplexity ratio\n$\\text{PPL}_{\\theta_{\\text{old}}}/\\text{PPL}_\\theta$ and as the exponential\ncross-entropy change $\\exp(\\Delta H)$. While the perplexity-entropy\nrelationship follows from standard definitions, this observation provides a\nuseful lens for understanding GSPO: the algorithm weights policy gradient\nupdates by perplexity ratios, offering an information-theoretic interpretation\nof the importance weights. This perspective helps explain GSPO's empirical\nproperties, including log-domain variance reduction through geometric averaging\nand stability in training mixture-of-experts models. We validate the\nmathematical equivalences and variance predictions through controlled\nexperiments on mathematical reasoning tasks.",
    "categories": [
      "cs.LG",
      "cs.AI",
      "cs.CL"
    ],
    "published": "2025-10-27T09:19:10Z",
    "authors": [
      "Chi Liu"
    ],
    "pdf_url": "http://arxiv.org/pdf/2510.23142v1"
  },
  {
    "id": "2510.23141v1",
    "title": "Treble10: A high-quality dataset for far-field speech recognition,\n  dereverberation, and enhancement",
    "abstract": "Accurate far-field speech datasets are critical for tasks such as automatic\nspeech recognition (ASR), dereverberation, speech enhancement, and source\nseparation. However, current datasets are limited by the trade-off between\nacoustic realism and scalability. Measured corpora provide faithful physics but\nare expensive, low-coverage, and rarely include paired clean and reverberant\ndata. In contrast, most simulation-based datasets rely on simplified\ngeometrical acoustics, thus failing to reproduce key physical phenomena like\ndiffraction, scattering, and interference that govern sound propagation in\ncomplex environments. We introduce Treble10, a large-scale, physically accurate\nroom-acoustic dataset. Treble10 contains over 3000 broadband room impulse\nresponses (RIRs) simulated in 10 fully furnished real-world rooms, using a\nhybrid simulation paradigm implemented in the Treble SDK that combines a\nwave-based and geometrical acoustics solver. The dataset provides six\ncomplementary subsets, spanning mono, 8th-order Ambisonics, and 6-channel\ndevice RIRs, as well as pre-convolved reverberant speech scenes paired with\nLibriSpeech utterances. All signals are simulated at 32 kHz, accurately\nmodelling low-frequency wave effects and high-frequency reflections. Treble10\nbridges the realism gap between measurement and simulation, enabling\nreproducible, physically grounded evaluation and large-scale data augmentation\nfor far-field speech tasks. The dataset is openly available via the Hugging\nFace Hub, and is intended as both a benchmark and a template for\nnext-generation simulation-driven audio research.",
    "categories": [
      "eess.AS",
      "cs.LG"
    ],
    "published": "2025-10-27T09:17:44Z",
    "authors": [
      "Sarabeth S. Mullins",
      "Georg G\u00f6tz",
      "Eric Bezzam",
      "Steven Zheng",
      "Daniel Gert Nielsen"
    ],
    "pdf_url": "http://arxiv.org/pdf/2510.23141v1"
  },
  {
    "id": "2510.23136v1",
    "title": "A method for outlier detection based on cluster analysis and visual\n  expert criteria",
    "abstract": "Outlier detection is an important problem occurring in a wide range of areas.\nOutliers are the outcome of fraudulent behaviour, mechanical faults, human\nerror, or simply natural deviations. Many data mining applications perform\noutlier detection, often as a preliminary step in order to filter out outliers\nand build more representative models. In this paper, we propose an outlier\ndetection method based on a clustering process. The aim behind the proposal\noutlined in this paper is to overcome the specificity of many existing outlier\ndetection techniques that fail to take into account the inherent dispersion of\ndomain objects. The outlier detection method is based on four criteria designed\nto represent how human beings (experts in each domain) visually identify\noutliers within a set of objects after analysing the clusters. This has an\nadvantage over other clustering-based outlier detection techniques that are\nfounded on a purely numerical analysis of clusters. Our proposal has been\nevaluated, with satisfactory results, on data (particularly time series) from\ntwo different domains: stabilometry, a branch of medicine studying\nbalance-related functions in human beings and electroencephalography (EEG), a\nneurological exploration used to diagnose nervous system disorders. To validate\nthe proposed method, we studied method outlier detection and efficiency in\nterms of runtime. The results of regression analyses confirm that our proposal\nis useful for detecting outlier data in different domains, with a false\npositive rate of less than 2% and a reliability greater than 99%.",
    "categories": [
      "cs.LG"
    ],
    "published": "2025-10-27T09:16:16Z",
    "authors": [
      "Juan A. Lara",
      "David Lizcano",
      "V\u00edctor Ramp\u00e9rez",
      "Javier Soriano"
    ],
    "pdf_url": "http://arxiv.org/pdf/2510.23136v1"
  },
  {
    "id": "2510.23124v1",
    "title": "DeepSalt: Bridging Laboratory and Satellite Spectra through Domain\n  Adaptation and Knowledge Distillation for Large-Scale Soil Salinity\n  Estimation",
    "abstract": "Soil salinization poses a significant threat to both ecosystems and\nagriculture because it limits plants' ability to absorb water and, in doing so,\nreduces crop productivity. This phenomenon alters the soil's spectral\nproperties, creating a measurable relationship between salinity and light\nreflectance that enables remote monitoring. While laboratory spectroscopy\nprovides precise measurements, its reliance on in-situ sampling limits\nscalability to regional or global levels. Conversely, hyperspectral satellite\nimagery enables wide-area observation but lacks the fine-grained\ninterpretability of laboratory instruments. To bridge this gap, we introduce\nDeepSalt, a deep-learning-based spectral transfer framework that leverages\nknowledge distillation and a novel Spectral Adaptation Unit to transfer\nhigh-resolution spectral insights from laboratory-based spectroscopy to\nsatellite-based hyperspectral sensing. Our approach eliminates the need for\nextensive ground sampling while enabling accurate, large-scale salinity\nestimation, as demonstrated through comprehensive empirical benchmarks.\nDeepSalt achieves significant performance gains over methods without explicit\ndomain adaptation, underscoring the impact of the proposed Spectral Adaptation\nUnit and the knowledge distillation strategy. The model also effectively\ngeneralized to unseen geographic regions, explaining a substantial portion of\nthe salinity variance.",
    "categories": [
      "cs.CV",
      "cs.LG"
    ],
    "published": "2025-10-27T08:57:59Z",
    "authors": [
      "Rupasree Dey",
      "Abdul Matin",
      "Everett Lewark",
      "Tanjim Bin Faruk",
      "Andrei Bachinin",
      "Sam Leuthold",
      "M. Francesca Cotrufo",
      "Shrideep Pallickara",
      "Sangmi Lee Pallickara"
    ],
    "pdf_url": "http://arxiv.org/pdf/2510.23124v1"
  },
  {
    "id": "2510.23123v1",
    "title": "Beyond Higher Rank: Token-wise Input-Output Projections for Efficient\n  Low-Rank Adaptation",
    "abstract": "Low-rank adaptation (LoRA) is a parameter-efficient fine-tuning (PEFT) method\nwidely used in large language models (LLMs). LoRA essentially describes the\nprojection of an input space into a low-dimensional output space, with the\ndimensionality determined by the LoRA rank. In standard LoRA, all input tokens\nshare the same weights and undergo an identical input-output projection. This\nlimits LoRA's ability to capture token-specific information due to the inherent\nsemantic differences among tokens. To address this limitation, we propose\nToken-wise Projected Low-Rank Adaptation (TopLoRA), which dynamically adjusts\nLoRA weights according to the input token, thereby learning token-wise\ninput-output projections in an end-to-end manner. Formally, the weights of\nTopLoRA can be expressed as $B\\Sigma_X A$, where $A$ and $B$ are low-rank\nmatrices (as in standard LoRA), and $\\Sigma_X$ is a diagonal matrix generated\nfrom each input token $X$. Notably, TopLoRA does not increase the rank of LoRA\nweights but achieves more granular adaptation by learning token-wise LoRA\nweights (i.e., token-wise input-output projections). Extensive experiments\nacross multiple models and datasets demonstrate that TopLoRA consistently\noutperforms LoRA and its variants. The code is available at\nhttps://github.com/Leopold1423/toplora-neurips25.",
    "categories": [
      "cs.CL",
      "cs.LG"
    ],
    "published": "2025-10-27T08:57:24Z",
    "authors": [
      "Shiwei Li",
      "Xiandi Luo",
      "Haozhao Wang",
      "Xing Tang",
      "Ziqiang Cui",
      "Dugang Liu",
      "Yuhua Li",
      "Xiuqiang He",
      "Ruixuan Li"
    ],
    "pdf_url": "http://arxiv.org/pdf/2510.23123v1"
  },
  {
    "id": "2510.23117v2",
    "title": "Seeing Structural Failure Before it Happens: An Image-Based\n  Physics-Informed Neural Network (PINN) for Spaghetti Bridge Load Prediction",
    "abstract": "Physics Informed Neural Networks (PINNs) are gaining attention for their\nability to embed physical laws into deep learning models, which is particularly\nuseful in structural engineering tasks with limited data. This paper aims to\nexplore the use of PINNs to predict the weight of small scale spaghetti\nbridges, a task relevant to understanding load limits and potential failure\nmodes in simplified structural models. Our proposed framework incorporates\nphysics-based constraints to the prediction model for improved performance. In\naddition to standard PINNs, we introduce a novel architecture named Physics\nInformed Kolmogorov Arnold Network (PIKAN), which blends universal function\napproximation theory with physical insights. The structural parameters provided\nas input to the model are collected either manually or through computer vision\nmethods. Our dataset includes 15 real bridges, augmented to 100 samples, and\nour best model achieves an $R^2$ score of 0.9603 and a mean absolute error\n(MAE) of 10.50 units. From applied perspective, we also provide a web based\ninterface for parameter entry and prediction. These results show that PINNs can\noffer reliable estimates of structural weight, even with limited data, and may\nhelp inform early stage failure analysis in lightweight bridge designs.\n  The complete data and code are available at\nhttps://github.com/OmerJauhar/PINNS-For-Spaghetti-Bridges.",
    "categories": [
      "cs.LG",
      "cs.CV",
      "65M70 (Primary), 68T07 (Secondary)",
      "I.2.6; I.4.8; G.1.8"
    ],
    "published": "2025-10-27T08:38:17Z",
    "authors": [
      "Omer Jauhar Khan",
      "Sudais Khan",
      "Hafeez Anwar",
      "Shahzeb Khan",
      "Shams Ul Arifeen"
    ],
    "pdf_url": "http://arxiv.org/pdf/2510.23117v2"
  },
  {
    "id": "2510.23111v1",
    "title": "Neural Emulator Superiority: When Machine Learning for PDEs Surpasses\n  its Training Data",
    "abstract": "Neural operators or emulators for PDEs trained on data from numerical solvers\nare conventionally assumed to be limited by their training data's fidelity. We\nchallenge this assumption by identifying \"emulator superiority,\" where neural\nnetworks trained purely on low-fidelity solver data can achieve higher accuracy\nthan those solvers when evaluated against a higher-fidelity reference. Our\ntheoretical analysis reveals how the interplay between emulator inductive\nbiases, training objectives, and numerical error characteristics enables\nsuperior performance during multi-step rollouts. We empirically validate this\nfinding across different PDEs using standard neural architectures,\ndemonstrating that emulators can implicitly learn dynamics that are more\nregularized or exhibit more favorable error accumulation properties than their\ntraining data, potentially surpassing training data limitations and mitigating\nnumerical artifacts. This work prompts a re-evaluation of emulator\nbenchmarking, suggesting neural emulators might achieve greater physical\nfidelity than their training source within specific operational regimes.\nProject Page: https://tum-pbs.github.io/emulator-superiority",
    "categories": [
      "cs.LG"
    ],
    "published": "2025-10-27T08:31:55Z",
    "authors": [
      "Felix Koehler",
      "Nils Thuerey"
    ],
    "pdf_url": "http://arxiv.org/pdf/2510.23111v1"
  },
  {
    "id": "2510.23106v1",
    "title": "Sampling from Energy distributions with Target Concrete Score Identity",
    "abstract": "We introduce the Target Concrete Score Identity Sampler (TCSIS), a method for\nsampling from unnormalized densities on discrete state spaces by learning the\nreverse dynamics of a Continuous-Time Markov Chain (CTMC). Our approach builds\non a forward in time CTMC with a uniform noising kernel and relies on the\nproposed Target Concrete Score Identity, which relates the concrete score, the\nratio of marginal probabilities of two states, to a ratio of expectations of\nBoltzmann factors under the forward uniform diffusion kernel. This formulation\nenables Monte Carlo estimation of the concrete score without requiring samples\nfrom the target distribution or computation of the partition function. We\napproximate the concrete score with a neural network and propose two\nalgorithms: Self-Normalized TCSIS and Unbiased TCSIS. Finally, we demonstrate\nthe effectiveness of TCSIS on problems from statistical physics.",
    "categories": [
      "cs.LG"
    ],
    "published": "2025-10-27T08:21:09Z",
    "authors": [
      "Sergei Kholkin",
      "Francisco Vargas",
      "Alexander Korotin"
    ],
    "pdf_url": "http://arxiv.org/pdf/2510.23106v1"
  },
  {
    "id": "2510.23083v1",
    "title": "Smaller Models, Smarter Rewards: A Two-Sided Approach to Process and\n  Outcome Rewards",
    "abstract": "Generating high-quality code remains a challenge for Large Language Models\n(LLMs). For the evolution of reasoning models on this task, reward models are a\nnecessary intermediate step. These models judge outcomes or intermediate steps.\nDecoder-only transformer models can be turned into reward models by introducing\na regression layer and supervised fine-tuning. While it is known that\nreflection capabilities generally increase with the size of a model, we want to\ninvestigate whether state-of-the-art small language models like the Phi-4\nfamily can be turned into usable reward models blending the consideration of\nprocess rewards and outcome rewards.\n  Targeting this goal, we construct a dataset of code samples with correctness\nlabels derived from the APPS coding challenge benchmark. We then train a\nvalue-head model to estimate the success probability of intermediate outputs.\nOur evaluation shows that small LLMs are capable of serving as effective reward\nmodels or code evaluation critics, successfully identifying correct solutions\namong multiple candidates. Using this critic, we achieve over a 20% improvement\nin the search capability of the most accurate code out of multiple generations.",
    "categories": [
      "cs.AI",
      "cs.LG",
      "cs.SE",
      "I.2.7"
    ],
    "published": "2025-10-27T07:36:41Z",
    "authors": [
      "Jan Niklas Groeneveld",
      "Xi Qin",
      "Alexander Schaefer",
      "Yaad Oren"
    ],
    "pdf_url": "http://arxiv.org/pdf/2510.23083v1"
  },
  {
    "id": "2510.23053v1",
    "title": "AirFed: Federated Graph-Enhanced Multi-Agent Reinforcement Learning for\n  Multi-UAV Cooperative Mobile Edge Computing",
    "abstract": "Multiple Unmanned Aerial Vehicles (UAVs) cooperative Mobile Edge Computing\n(MEC) systems face critical challenges in coordinating trajectory planning,\ntask offloading, and resource allocation while ensuring Quality of Service\n(QoS) under dynamic and uncertain environments. Existing approaches suffer from\nlimited scalability, slow convergence, and inefficient knowledge sharing among\nUAVs, particularly when handling large-scale IoT device deployments with\nstringent deadline constraints. This paper proposes AirFed, a novel federated\ngraph-enhanced multi-agent reinforcement learning framework that addresses\nthese challenges through three key innovations. First, we design dual-layer\ndynamic Graph Attention Networks (GATs) that explicitly model spatial-temporal\ndependencies among UAVs and IoT devices, capturing both service relationships\nand collaborative interactions within the network topology. Second, we develop\na dual-Actor single-Critic architecture that jointly optimizes continuous\ntrajectory control and discrete task offloading decisions. Third, we propose a\nreputation-based decentralized federated learning mechanism with\ngradient-sensitive adaptive quantization, enabling efficient and robust\nknowledge sharing across heterogeneous UAVs. Extensive experiments demonstrate\nthat AirFed achieves 42.9% reduction in weighted cost compared to\nstate-of-the-art baselines, attains over 99% deadline satisfaction and 94.2%\nIoT device coverage rate, and reduces communication overhead by 54.5%.\nScalability analysis confirms robust performance across varying UAV numbers,\nIoT device densities, and system scales, validating AirFed's practical\napplicability for large-scale UAV-MEC deployments.",
    "categories": [
      "cs.LG",
      "cs.DC"
    ],
    "published": "2025-10-27T06:31:35Z",
    "authors": [
      "Zhiyu Wang",
      "Suman Raj",
      "Rajkumar Buyya"
    ],
    "pdf_url": "http://arxiv.org/pdf/2510.23053v1"
  },
  {
    "id": "2510.23051v1",
    "title": "SwiftTS: A Swift Selection Framework for Time Series Pre-trained Models\n  via Multi-task Meta-Learning",
    "abstract": "Pre-trained models exhibit strong generalization to various downstream tasks.\nHowever, given the numerous models available in the model hub, identifying the\nmost suitable one by individually fine-tuning is time-consuming. In this paper,\nwe propose \\textbf{SwiftTS}, a swift selection framework for time series\npre-trained models. To avoid expensive forward propagation through all\ncandidates, SwiftTS adopts a learning-guided approach that leverages historical\ndataset-model performance pairs across diverse horizons to predict model\nperformance on unseen datasets. It employs a lightweight dual-encoder\narchitecture that embeds time series and candidate models with rich\ncharacteristics, computing patchwise compatibility scores between data and\nmodel embeddings for efficient selection. To further enhance the generalization\nacross datasets and horizons, we introduce a horizon-adaptive expert\ncomposition module that dynamically adjusts expert weights, and the\ntransferable cross-task learning with cross-dataset and cross-horizon task\nsampling to enhance out-of-distribution (OOD) robustness. Extensive experiments\non 14 downstream datasets and 8 pre-trained models demonstrate that SwiftTS\nachieves state-of-the-art performance in time series pre-trained model\nselection.",
    "categories": [
      "cs.LG"
    ],
    "published": "2025-10-27T06:26:45Z",
    "authors": [
      "Tengxue Zhang",
      "Biao Ouyang",
      "Yang Shu",
      "Xinyang Chen",
      "Chenjuan Guo",
      "Bin Yang"
    ],
    "pdf_url": "http://arxiv.org/pdf/2510.23051v1"
  },
  {
    "id": "2510.23049v1",
    "title": "Advantage Shaping as Surrogate Reward Maximization: Unifying Pass@K\n  Policy Gradients",
    "abstract": "This note reconciles two seemingly distinct approaches to policy gradient\noptimization for the Pass@K objective in reinforcement learning with verifiable\nrewards: (1) direct REINFORCE-style methods, and (2) advantage-shaping\ntechniques that directly modify GRPO. We show that these are two sides of the\nsame coin. By reverse-engineering existing advantage-shaping algorithms, we\nreveal that they implicitly optimize surrogate rewards. We specifically\ninterpret practical ``hard-example up-weighting'' modifications to GRPO as\nreward-level regularization. Conversely, starting from surrogate reward\nobjectives, we provide a simple recipe for deriving both existing and new\nadvantage-shaping methods. This perspective provides a lens for RLVR policy\ngradient optimization beyond our original motivation of Pass@K.",
    "categories": [
      "cs.LG",
      "cs.AI"
    ],
    "published": "2025-10-27T06:24:56Z",
    "authors": [
      "Christos Thrampoulidis",
      "Sadegh Mahdavi",
      "Wenlong Deng"
    ],
    "pdf_url": "http://arxiv.org/pdf/2510.23049v1"
  },
  {
    "id": "2510.23040v1",
    "title": "LLM Meets Diffusion: A Hybrid Framework for Crystal Material Generation",
    "abstract": "Recent advances in generative modeling have shown significant promise in\ndesigning novel periodic crystal structures. Existing approaches typically rely\non either large language models (LLMs) or equivariant denoising models, each\nwith complementary strengths: LLMs excel at handling discrete atomic types but\noften struggle with continuous features such as atomic positions and lattice\nparameters, while denoising models are effective at modeling continuous\nvariables but encounter difficulties in generating accurate atomic\ncompositions. To bridge this gap, we propose CrysLLMGen, a hybrid framework\nthat integrates an LLM with a diffusion model to leverage their complementary\nstrengths for crystal material generation. During sampling, CrysLLMGen first\nemploys a fine-tuned LLM to produce an intermediate representation of atom\ntypes, atomic coordinates, and lattice structure. While retaining the predicted\natom types, it passes the atomic coordinates and lattice structure to a\npre-trained equivariant diffusion model for refinement. Our framework\noutperforms state-of-the-art generative models across several benchmark tasks\nand datasets. Specifically, CrysLLMGen not only achieves a balanced performance\nin terms of structural and compositional validity but also generates more\nstable and novel materials compared to LLM-based and denoisingbased models\nFurthermore, CrysLLMGen exhibits strong conditional generation capabilities,\neffectively producing materials that satisfy user-defined constraints. Code is\navailable at https://github.com/kdmsit/crysllmgen",
    "categories": [
      "cs.LG",
      "cond-mat.mtrl-sci",
      "cs.AI"
    ],
    "published": "2025-10-27T06:08:19Z",
    "authors": [
      "Subhojyoti Khastagir",
      "Kishalay Das",
      "Pawan Goyal",
      "Seung-Cheol Lee",
      "Satadeep Bhattacharjee",
      "Niloy Ganguly"
    ],
    "pdf_url": "http://arxiv.org/pdf/2510.23040v1"
  },
  {
    "id": "2510.23039v1",
    "title": "Sublinear Sketches for Approximate Nearest Neighbor and Kernel Density\n  Estimation",
    "abstract": "Approximate Nearest Neighbor (ANN) search and Approximate Kernel Density\nEstimation (A-KDE) are fundamental problems at the core of modern machine\nlearning, with broad applications in data analysis, information systems, and\nlarge-scale decision making. In massive and dynamic data streams, a central\nchallenge is to design compact sketches that preserve essential structural\nproperties of the data while enabling efficient queries.\n  In this work, we develop new sketching algorithms that achieve sublinear\nspace and query time guarantees for both ANN and A-KDE for a dynamic stream of\ndata. For ANN in the streaming model, under natural assumptions, we design a\nsublinear sketch that requires only $\\mathcal{O}(n^{1+\\rho-\\eta})$ memory by\nstoring only a sublinear ($n^{-\\eta}$) fraction of the total inputs, where\n$\\rho$ is a parameter of the LSH family, and $0<\\eta<1$. Our method supports\nsublinear query time, batch queries, and extends to the more general Turnstile\nmodel. While earlier works have focused on Exact NN, this is the first result\non ANN that achieves near-optimal trade-offs between memory size and\napproximation error.\n  Next, for A-KDE in the Sliding-Window model, we propose a sketch of size\n$\\mathcal{O}\\left(RW \\cdot \\frac{1}{\\sqrt{1+\\epsilon} - 1} \\log^2 N\\right)$,\nwhere $R$ is the number of sketch rows, $W$ is the LSH range, $N$ is the window\nsize, and $\\epsilon$ is the approximation error. This, to the best of our\nknowledge, is the first theoretical sublinear sketch guarantee for A-KDE in the\nSliding-Window model.\n  We complement our theoretical results with experiments on various real-world\ndatasets, which show that the proposed sketches are lightweight and achieve\nconsistently low error in practice.",
    "categories": [
      "cs.LG",
      "cs.DS",
      "stat.ML"
    ],
    "published": "2025-10-27T06:05:45Z",
    "authors": [
      "Ved Danait",
      "Srijan Das",
      "Sujoy Bhore"
    ],
    "pdf_url": "http://arxiv.org/pdf/2510.23039v1"
  },
  {
    "id": "2510.23038v1",
    "title": "Incentivizing Agentic Reasoning in LLM Judges via Tool-Integrated\n  Reinforcement Learning",
    "abstract": "Large Language Models (LLMs) are widely used as judges to evaluate response\nquality, providing a scalable alternative to human evaluation. However, most\nLLM judges operate solely on intrinsic text-based reasoning, limiting their\nability to verify complex constraints or perform accurate computation.\nMotivated by the success of tool-integrated reasoning (TIR) in numerous tasks,\nwe propose TIR-Judge, an end-to-end RL framework for training LLM judges that\nintegrates a code executor for precise evaluation. TIR-Judge is built on three\nprinciples: (i) diverse training across verifiable and non-verifiable domains,\n(ii) flexible judgment formats (pointwise, pairwise, listwise), and (iii)\niterative RL that bootstraps directly from the initial model without\ndistillation. On seven public benchmarks, TIR-Judge surpasses strong\nreasoning-based judges by up to 6.4% (pointwise) and 7.7% (pairwise), and\nachieves listwise performance comparable to Claude-Opus-4 despite having only\n8B parameters. Remarkably, TIR-Judge-Zero - trained entirely without distilled\njudge trajectories, matches the performance of distilled variants,\ndemonstrating that tool-augmented judges can self-evolve through iterative\nreinforcement learning.",
    "categories": [
      "cs.CL",
      "cs.AI",
      "cs.LG"
    ],
    "published": "2025-10-27T06:03:37Z",
    "authors": [
      "Ran Xu",
      "Jingjing Chen",
      "Jiayu Ye",
      "Yu Wu",
      "Jun Yan",
      "Carl Yang",
      "Hongkun Yu"
    ],
    "pdf_url": "http://arxiv.org/pdf/2510.23038v1"
  },
  {
    "id": "2510.23027v1",
    "title": "Towards Stable and Effective Reinforcement Learning for\n  Mixture-of-Experts",
    "abstract": "Recent advances in reinforcement learning (RL) have substantially improved\nthe training of large-scale language models, leading to significant gains in\ngeneration quality and reasoning ability. However, most existing research\nfocuses on dense models, while RL training for Mixture-of-Experts (MoE)\narchitectures remains underexplored. To address the instability commonly\nobserved in MoE training, we propose a novel router-aware approach to optimize\nimportance sampling (IS) weights in off-policy RL. Specifically, we design a\nrescaling strategy guided by router logits, which effectively reduces gradient\nvariance and mitigates training divergence. Experimental results demonstrate\nthat our method significantly improves both the convergence stability and the\nfinal performance of MoE models, highlighting the potential of RL algorithmic\ninnovations tailored to MoE architectures and providing a promising direction\nfor efficient training of large-scale expert models.",
    "categories": [
      "cs.LG",
      "cs.CL"
    ],
    "published": "2025-10-27T05:47:48Z",
    "authors": [
      "Di Zhang",
      "Xun Wu",
      "Shaohan Huang",
      "Yaru Hao",
      "Li Dong",
      "Zewen Chi",
      "Zhifang Sui",
      "Furu Wei"
    ],
    "pdf_url": "http://arxiv.org/pdf/2510.23027v1"
  },
  {
    "id": "2510.23019v1",
    "title": "Sentinel: Dynamic Knowledge Distillation for Personalized Federated\n  Intrusion Detection in Heterogeneous IoT Networks",
    "abstract": "Federated learning (FL) offers a privacy-preserving paradigm for machine\nlearning, but its application in intrusion detection systems (IDS) within IoT\nnetworks is challenged by severe class imbalance, non-IID data, and high\ncommunication overhead.These challenges severely degrade the performance of\nconventional FL methods in real-world network traffic classification. To\novercome these limitations, we propose Sentinel, a personalized federated IDS\n(pFed-IDS) framework that incorporates a dual-model architecture on each\nclient, consisting of a personalized teacher and a lightweight shared student\nmodel. This design effectively balances deep local adaptation with efficient\nglobal model consensus while preserving client privacy by transmitting only the\ncompact student model, thus reducing communication costs. Sentinel integrates\nthree key mechanisms to ensure robust performance: bidirectional knowledge\ndistillation with adaptive temperature scaling, multi-faceted feature\nalignment, and class-balanced loss functions. Furthermore, the server employs\nnormalized gradient aggregation with equal client weighting to enhance fairness\nand mitigate client drift. Extensive experiments on the IoTID20 and 5GNIDD\nbenchmark datasets demonstrate that Sentinel significantly outperforms\nstate-of-the-art federated methods, establishing a new performance benchmark,\nespecially under extreme data heterogeneity, while maintaining communication\nefficiency.",
    "categories": [
      "cs.LG",
      "cs.DC"
    ],
    "published": "2025-10-27T05:32:48Z",
    "authors": [
      "Gurpreet Singh",
      "Keshav Sood",
      "P. Rajalakshmi",
      "Yong Xiang"
    ],
    "pdf_url": "http://arxiv.org/pdf/2510.23019v1"
  },
  {
    "id": "2510.23015v1",
    "title": "Coupled Flow Matching",
    "abstract": "We introduce Coupled Flow Matching (CPFM), a framework that integrates\ncontrollable dimensionality reduction and high-fidelity reconstruction. CPFM\nlearns coupled continuous flows for both the high-dimensional data x and the\nlow-dimensional embedding y, which enables sampling p(y|x) via a latent-space\nflow and p(x|y) via a data-space flow. Unlike classical dimension-reduction\nmethods, where information discarded during compression is often difficult to\nrecover, CPFM preserves the knowledge of residual information within the\nweights of a flow network. This design provides bespoke controllability: users\nmay decide which semantic factors to retain explicitly in the latent space,\nwhile the complementary information remains recoverable through the flow\nnetwork. Coupled flow matching builds on two components: (i) an extended\nGromov-Wasserstein optimal transport objective that establishes a probabilistic\ncorrespondence between data and embeddings, and (ii) a dual-conditional\nflow-matching network that extrapolates the correspondence to the underlying\nspace. Experiments on multiple benchmarks show that CPFM yields semantically\nrich embeddings and reconstructs data with higher fidelity than existing\nbaselines.",
    "categories": [
      "stat.ML",
      "cs.LG"
    ],
    "published": "2025-10-27T05:22:35Z",
    "authors": [
      "Wenxi Cai",
      "Yuheng Wang",
      "Naichen Shi"
    ],
    "pdf_url": "http://arxiv.org/pdf/2510.23015v1"
  },
  {
    "id": "2510.23013v1",
    "title": "MoEMeta: Mixture-of-Experts Meta Learning for Few-Shot Relational\n  Learning",
    "abstract": "Few-shot knowledge graph relational learning seeks to perform reasoning over\nrelations given only a limited number of training examples. While existing\napproaches largely adopt a meta-learning framework for enabling fast adaptation\nto new relations, they suffer from two key pitfalls. First, they learn relation\nmeta-knowledge in isolation, failing to capture common relational patterns\nshared across tasks. Second, they struggle to effectively incorporate local,\ntask-specific contexts crucial for rapid adaptation. To address these\nlimitations, we propose MoEMeta, a novel meta-learning framework that\ndisentangles globally shared knowledge from task-specific contexts to enable\nboth effective generalization and rapid adaptation. MoEMeta introduces two key\ninnovations: (i) a mixture-of-experts (MoE) model that learns globally shared\nrelational prototypes to enhance generalization, and (ii) a task-tailored\nadaptation mechanism that captures local contexts for fast task-specific\nadaptation. By balancing global generalization with local adaptability, MoEMeta\nsignificantly advances few-shot relational learning. Extensive experiments and\nanalyses on three KG benchmarks demonstrate that MoEMeta consistently\noutperforms existing baselines, achieving state-of-the-art performance.",
    "categories": [
      "cs.LG",
      "cs.AI"
    ],
    "published": "2025-10-27T05:16:10Z",
    "authors": [
      "Han Wu",
      "Jie Yin"
    ],
    "pdf_url": "http://arxiv.org/pdf/2510.23013v1"
  },
  {
    "id": "2510.23012v1",
    "title": "Softmax is $1/2$-Lipschitz: A tight bound across all $\\ell_p$ norms",
    "abstract": "The softmax function is a basic operator in machine learning and\noptimization, used in classification, attention mechanisms, reinforcement\nlearning, game theory, and problems involving log-sum-exp terms. Existing\nrobustness guarantees of learning models and convergence analysis of\noptimization algorithms typically consider the softmax operator to have a\nLipschitz constant of $1$ with respect to the $\\ell_2$ norm. In this work, we\nprove that the softmax function is contractive with the Lipschitz constant\n$1/2$, uniformly across all $\\ell_p$ norms with $p \\ge 1$. We also show that\nthe local Lipschitz constant of softmax attains $1/2$ for $p = 1$ and $p =\n\\infty$, and for $p \\in (1,\\infty)$, the constant remains strictly below $1/2$\nand the supremum $1/2$ is achieved only in the limit. To our knowledge, this is\nthe first comprehensive norm-uniform analysis of softmax Lipschitz continuity.\nWe demonstrate how the sharper constant directly improves a range of existing\ntheoretical results on robustness and convergence. We further validate the\nsharpness of the $1/2$ Lipschitz constant of the softmax operator through\nempirical studies on attention-based architectures (ViT, GPT-2, Qwen3-8B) and\non stochastic policies in reinforcement learning.",
    "categories": [
      "cs.LG",
      "cs.AI"
    ],
    "published": "2025-10-27T05:16:04Z",
    "authors": [
      "Pravin Nair"
    ],
    "pdf_url": "http://arxiv.org/pdf/2510.23012v1"
  },
  {
    "id": "2510.25776v1",
    "title": "StreetMath: Study of LLMs' Approximation Behaviors",
    "abstract": "There is a substantial body of literature examining the mathematical\nreasoning capabilities of large language models (LLMs), particularly their\nperformance on precise arithmetic operations in autoregressive architectures.\nHowever, their ability to perform approximate reasoning in informal, fast-paced\nmathematical operations has received far less attention, especially among\nnon-autoregressive decoder models. Our work addresses this gap by introducing\nStreetMath, a benchmark designed to evaluate models' approximation abilities\nunder real-world approximation scenarios. We conduct extensive evaluations\nacross different LLM architectures: Qwen3-4B-Instruct-2507,\nQwen3-4B-Thinking-2507, Dream-v0-Instruct-7B, Falcon-Mamba-7B-Instruct, and\nMamba-GPT-3B. Furthermore, we apply mechanistic interpretability techniques to\nprobe their internal computational states. Our analysis reveals that LLMs\ngenerally attempt to compute exact values or invoke external tools even in\ntasks that call for approximation. Moreover, while models sometimes reach the\ncorrect answer in early layers or steps, they still consume more tokens when\nsolving approximation tasks. Additional experiments indicate that exact and\napproximate arithmetic operations rely on largely separate neural components.\nDrawing upon research on cognitive psychology, we argue that LLMs do not\nexhibit cognitive miserliness in the same way humans do in street math\nsettings. We open source our work https://github.com/ctseng777/StreetMath",
    "categories": [
      "cs.CL",
      "cs.LG"
    ],
    "published": "2025-10-27T05:16:00Z",
    "authors": [
      "Chiung-Yi Tseng",
      "Somshubhra Roy",
      "Maisha Thasin",
      "Danyang Zhang",
      "Blessing Effiong"
    ],
    "pdf_url": "http://arxiv.org/pdf/2510.25776v1"
  },
  {
    "id": "2510.24788v1",
    "title": "The Underappreciated Power of Vision Models for Graph Structural\n  Understanding",
    "abstract": "Graph Neural Networks operate through bottom-up message-passing,\nfundamentally differing from human visual perception, which intuitively\ncaptures global structures first. We investigate the underappreciated potential\nof vision models for graph understanding, finding they achieve performance\ncomparable to GNNs on established benchmarks while exhibiting distinctly\ndifferent learning patterns. These divergent behaviors, combined with\nlimitations of existing benchmarks that conflate domain features with\ntopological understanding, motivate our introduction of GraphAbstract. This\nbenchmark evaluates models' ability to perceive global graph properties as\nhumans do: recognizing organizational archetypes, detecting symmetry, sensing\nconnectivity strength, and identifying critical elements. Our results reveal\nthat vision models significantly outperform GNNs on tasks requiring holistic\nstructural understanding and maintain generalizability across varying graph\nscales, while GNNs struggle with global pattern abstraction and degrade with\nincreasing graph size. This work demonstrates that vision models possess\nremarkable yet underutilized capabilities for graph structural understanding,\nparticularly for problems requiring global topological awareness and\nscale-invariant reasoning. These findings open new avenues to leverage this\nunderappreciated potential for developing more effective graph foundation\nmodels for tasks dominated by holistic pattern recognition.",
    "categories": [
      "cs.CV",
      "cs.AI",
      "cs.LG"
    ],
    "published": "2025-10-27T05:11:44Z",
    "authors": [
      "Xinjian Zhao",
      "Wei Pang",
      "Zhongkai Xue",
      "Xiangru Jian",
      "Lei Zhang",
      "Yaoyao Xu",
      "Xiaozhuang Song",
      "Shu Wu",
      "Tianshu Yu"
    ],
    "pdf_url": "http://arxiv.org/pdf/2510.24788v1"
  },
  {
    "id": "2510.22993v1",
    "title": "Can Language Models Compose Skills In-Context?",
    "abstract": "Composing basic skills from simple tasks to accomplish composite tasks is\ncrucial for modern intelligent systems. We investigate the in-context\ncomposition ability of language models to perform composite tasks that combine\nbasic skills demonstrated in in-context examples. This is more challenging than\nthe standard setting, where skills and their composition can be learned in\ntraining. We conduct systematic experiments on various representative\nopen-source language models, utilizing linguistic and logical tasks designed to\nprobe composition abilities. The results reveal that simple task examples can\nhave a surprising negative impact on the performance, because the models\ngenerally struggle to recognize and assemble the skills correctly, even with\nChain-of-Thought examples. Theoretical analysis further shows that it is\ncrucial to align examples with the corresponding steps in the composition. This\ninspires a method for the probing tasks, whose improved performance provides\npositive support for our insights.",
    "categories": [
      "cs.LG",
      "cs.CL"
    ],
    "published": "2025-10-27T04:18:59Z",
    "authors": [
      "Zidong Liu",
      "Zhuoyan Xu",
      "Zhenmei Shi",
      "Yingyu Liang"
    ],
    "pdf_url": "http://arxiv.org/pdf/2510.22993v1"
  },
  {
    "id": "2510.22991v1",
    "title": "Adaptive Forests For Classification",
    "abstract": "Random Forests (RF) and Extreme Gradient Boosting (XGBoost) are two of the\nmost widely used and highly performing classification and regression models.\nThey aggregate equally weighted CART trees, generated randomly in RF or\nsequentially in XGBoost. In this paper, we propose Adaptive Forests (AF), a\nnovel approach that adaptively selects the weights of the underlying CART\nmodels. AF combines (a) the Optimal Predictive-Policy Trees (OP2T) framework to\nprescribe tailored, input-dependent unequal weights to trees and (b) Mixed\nInteger Optimization (MIO) to refine weight candidates dynamically, enhancing\noverall performance. We demonstrate that AF consistently outperforms RF,\nXGBoost, and other weighted RF in binary and multi-class classification\nproblems over 20+ real-world datasets.",
    "categories": [
      "cs.LG",
      "stat.ML"
    ],
    "published": "2025-10-27T04:17:41Z",
    "authors": [
      "Dimitris Bertsimas",
      "Yubing Cui"
    ],
    "pdf_url": "http://arxiv.org/pdf/2510.22991v1"
  },
  {
    "id": "2510.22984v1",
    "title": "Equivariant Neural Networks for General Linear Symmetries on Lie\n  Algebras",
    "abstract": "Encoding symmetries is a powerful inductive bias for improving the\ngeneralization of deep neural networks. However, most existing equivariant\nmodels are limited to simple symmetries like rotations, failing to address the\nbroader class of general linear transformations, GL(n), that appear in many\nscientific domains. We introduce Reductive Lie Neurons (ReLNs), a novel neural\nnetwork architecture exactly equivariant to these general linear symmetries.\nReLNs are designed to operate directly on a wide range of structured inputs,\nincluding general n-by-n matrices. ReLNs introduce a novel adjoint-invariant\nbilinear layer to achieve stable equivariance for both Lie-algebraic features\nand matrix-valued inputs, without requiring redesign for each subgroup. This\narchitecture overcomes the limitations of prior equivariant networks that only\napply to compact groups or simple vector data. We validate ReLNs' versatility\nacross a spectrum of tasks: they outperform existing methods on algebraic\nbenchmarks with sl(3) and sp(4) symmetries and achieve competitive results on a\nLorentz-equivariant particle physics task. In 3D drone state estimation with\ngeometric uncertainty, ReLNs jointly process velocities and covariances,\nyielding significant improvements in trajectory accuracy. ReLNs provide a\npractical and general framework for learning with broad linear group symmetries\non Lie algebras and matrix-valued data. Project page:\nhttps://reductive-lie-neuron.github.io/",
    "categories": [
      "cs.LG",
      "cs.NE"
    ],
    "published": "2025-10-27T04:08:39Z",
    "authors": [
      "Chankyo Kim",
      "Sicheng Zhao",
      "Minghan Zhu",
      "Tzu-Yuan Lin",
      "Maani Ghaffari"
    ],
    "pdf_url": "http://arxiv.org/pdf/2510.22984v1"
  },
  {
    "id": "2510.22982v1",
    "title": "QoSGMAA: A Robust Multi-Order Graph Attention and Adversarial Framework\n  for Sparse QoS Prediction",
    "abstract": "With the rapid advancement of internet technologies, network services have\nbecome critical for delivering diverse and reliable applications to users.\nHowever, the exponential growth in the number of available services has\nresulted in many similar offerings, posing significant challenges in selecting\noptimal services. Predicting Quality of Service (QoS) accurately thus becomes a\nfundamental prerequisite for ensuring reliability and user satisfaction.\nHowever, existing QoS prediction methods often fail to capture rich contextual\ninformation and exhibit poor performance under extreme data sparsity and\nstructural noise. To bridge this gap, we propose a novel architecture, QoSMGAA,\nspecifically designed to enhance prediction accuracy in complex and noisy\nnetwork service environments. QoSMGAA integrates a multi-order attention\nmechanism to aggregate extensive contextual data and predict missing QoS values\neffectively. Additionally, our method incorporates adversarial neural networks\nto perform autoregressive supervised learning based on transformed interaction\nmatrices. To capture complex, higher-order interactions among users and\nservices, we employ a discrete sampling technique leveraging the Gumbel-Softmax\nmethod to generate informative negative samples. Comprehensive experimental\nvalidation conducted on large-scale real-world datasets demonstrates that our\nproposed model significantly outperforms existing baseline methods,\nhighlighting its strong potential for practical deployment in service selection\nand recommendation scenarios.",
    "categories": [
      "cs.LG",
      "H.3.5; I.2.6; I.2.10; I.2.7; I.6.5"
    ],
    "published": "2025-10-27T04:03:28Z",
    "authors": [
      "Guanchen Du",
      "Jianlong Xu",
      "Mingtong Li",
      "Ruiqi Wang",
      "Qianqing Guo",
      "Caiyi Chen",
      "Qingcao Dai",
      "Yuxiang Zeng"
    ],
    "pdf_url": "http://arxiv.org/pdf/2510.22982v1"
  },
  {
    "id": "2510.22980v1",
    "title": "How Muon's Spectral Design Benefits Generalization: A Study on\n  Imbalanced Data",
    "abstract": "The growing adoption of spectrum-aware matrix-valued optimizers such as Muon\nand Shampoo in deep learning motivates a systematic study of their\ngeneralization properties and, in particular, when they might outperform\ncompetitive algorithms. We approach this question by introducing appropriate\nsimplifying abstractions as follows: First, we use imbalanced data as a\ntestbed. Second, we study the canonical form of such optimizers, which is\nSpectral Gradient Descent (SpecGD) -- each update step is $UV^T$ where $U\\Sigma\nV^T$ is the truncated SVD of the gradient. Third, within this framework we\nidentify a canonical setting for which we precisely quantify when SpecGD\noutperforms vanilla Euclidean GD. For a Gaussian mixture data model and both\nlinear and bilinear models, we show that unlike GD, which prioritizes learning\ndominant principal components of the data first, SpecGD learns all principal\ncomponents of the data at equal rates. We demonstrate how this translates to a\ngrowing gap in balanced accuracy favoring SpecGD early in training and further\nshow that the gap remains consistent even when the GD counterpart uses adaptive\nstep-sizes via normalization. By extending the analysis to deep linear models,\nwe show that depth amplifies these effects. We empirically verify our\ntheoretical findings on a variety of imbalanced datasets. Our experiments\ncompare practical variants of spectral methods, like Muon and Shampoo, against\ntheir Euclidean counterparts and Adam. The results validate our findings that\nthese spectral optimizers achieve superior generalization by promoting a more\nbalanced learning of the data's underlying components.",
    "categories": [
      "cs.LG",
      "stat.ML"
    ],
    "published": "2025-10-27T04:00:42Z",
    "authors": [
      "Bhavya Vasudeva",
      "Puneesh Deora",
      "Yize Zhao",
      "Vatsal Sharan",
      "Christos Thrampoulidis"
    ],
    "pdf_url": "http://arxiv.org/pdf/2510.22980v1"
  },
  {
    "id": "2510.22977v1",
    "title": "The Reasoning Trap: How Enhancing LLM Reasoning Amplifies Tool\n  Hallucination",
    "abstract": "Enhancing the reasoning capabilities of Large Language Models (LLMs) is a key\nstrategy for building Agents that \"think then act.\" However, recent\nobservations, like OpenAI's o3, suggest a paradox: stronger reasoning often\ncoincides with increased hallucination, yet no prior work has systematically\nexamined whether reasoning enhancement itself causes tool hallucination. To\naddress this gap, we pose the central question: Does strengthening reasoning\nincrease tool hallucination? To answer this, we introduce SimpleToolHalluBench,\na diagnostic benchmark measuring tool hallucination in two failure modes: (i)\nno tool available, and (ii) only distractor tools available. Through controlled\nexperiments, we establish three key findings. First, we demonstrate a causal\nrelationship: progressively enhancing reasoning through RL increases tool\nhallucination proportionally with task performance gains. Second, this effect\ntranscends overfitting - training on non-tool tasks (e.g., mathematics) still\namplifies subsequent tool hallucination. Third, the effect is method-agnostic,\nappearing when reasoning is instilled via supervised fine-tuning and when it is\nmerely elicited at inference by switching from direct answers to step-by-step\nthinking. We also evaluate mitigation strategies including Prompt Engineering\nand Direct Preference Optimization (DPO), revealing a fundamental\nreliability-capability trade-off: reducing hallucination consistently degrades\nutility. Mechanistically, Reasoning RL disproportionately collapses\ntool-reliability-related representations, and hallucinations surface as\namplified divergences concentrated in late-layer residual streams. These\nfindings reveal that current reasoning enhancement methods inherently amplify\ntool hallucination, highlighting the need for new training objectives that\njointly optimize for capability and reliability.",
    "categories": [
      "cs.LG",
      "cs.AI",
      "I.2"
    ],
    "published": "2025-10-27T03:58:29Z",
    "authors": [
      "Chenlong Yin",
      "Zeyang Sha",
      "Shiwen Cui",
      "Changhua Meng"
    ],
    "pdf_url": "http://arxiv.org/pdf/2510.22977v1"
  },
  {
    "id": "2510.22976v1",
    "title": "Analysis of accuracy and efficiency of neural networks to simulate\n  Navier-Stokes fluid flows with obstacles",
    "abstract": "Conventional fluid simulations can be time consuming and energy intensive. We\nresearched the viability of a neural network for simulating incompressible\nfluids in a randomized obstacle-heavy environment, as an alternative to the\nnumerical simulation of the Navier-Stokes equation. We hypothesized that the\nneural network predictions would have a relatively low error for simulations\nover a small number of time steps, but errors would eventually accumulate to\nthe point that the output would become very noisy. Over a rich set of obstacle\nconfigurations, we achieved a root mean square error of 0.32% on our training\ndataset and 0.36% on a testing dataset. These errors only grew to 1.45% and\n2.34% at t = 10 and, 2.11% and 4.16% at timestep t = 20. We also found that our\nselected neural network was approximately 8,800 times faster at predicting the\nflow than a conventional simulation. Our findings indicate neural networks can\nbe extremely useful at simulating fluids in obstacle-heavy environments. Useful\napplications include modeling forest fire smoke, pipe fluid flow, and\nunderwater/flood currents.",
    "categories": [
      "physics.flu-dyn",
      "cs.LG"
    ],
    "published": "2025-10-27T03:57:29Z",
    "authors": [
      "Rui Hespanha",
      "Elliot McGuire",
      "Jo\u00e3o Hespanha"
    ],
    "pdf_url": "http://arxiv.org/pdf/2510.22976v1"
  },
  {
    "id": "2510.22975v1",
    "title": "VoMP: Predicting Volumetric Mechanical Property Fields",
    "abstract": "Physical simulation relies on spatially-varying mechanical properties, often\nlaboriously hand-crafted. VoMP is a feed-forward method trained to predict\nYoung's modulus ($E$), Poisson's ratio ($\\nu$), and density ($\\rho$) throughout\nthe volume of 3D objects, in any representation that can be rendered and\nvoxelized. VoMP aggregates per-voxel multi-view features and passes them to our\ntrained Geometry Transformer to predict per-voxel material latent codes. These\nlatents reside on a manifold of physically plausible materials, which we learn\nfrom a real-world dataset, guaranteeing the validity of decoded per-voxel\nmaterials. To obtain object-level training data, we propose an annotation\npipeline combining knowledge from segmented 3D datasets, material databases,\nand a vision-language model, along with a new benchmark. Experiments show that\nVoMP estimates accurate volumetric properties, far outperforming prior art in\naccuracy and speed.",
    "categories": [
      "cs.CV",
      "cs.GR",
      "cs.LG"
    ],
    "published": "2025-10-27T03:56:25Z",
    "authors": [
      "Rishit Dagli",
      "Donglai Xiang",
      "Vismay Modi",
      "Charles Loop",
      "Clement Fuji Tsang",
      "Anka He Chen",
      "Anita Hu",
      "Gavriel State",
      "David I. W. Levin",
      "Maria Shugrina"
    ],
    "pdf_url": "http://arxiv.org/pdf/2510.22975v1"
  },
  {
    "id": "2510.22955v1",
    "title": "SARNet: A Spike-Aware consecutive validation Framework for Accurate\n  Remaining Useful Life Prediction",
    "abstract": "Accurate prediction of remaining useful life (RUL) is essential to enhance\nsystem reliability and reduce maintenance risk. Yet many strong contemporary\nmodels are fragile around fault onset and opaque to engineers: short,\nhigh-energy spikes are smoothed away or misread, fixed thresholds blunt\nsensitivity, and physics-based explanations are scarce. To remedy this, we\nintroduce SARNet (Spike-Aware Consecutive Validation Framework), which builds\non a Modern Temporal Convolutional Network (ModernTCN) and adds spike-aware\ndetection to provide physics-informed interpretability. ModernTCN forecasts\ndegradation-sensitive indicators; an adaptive consecutive threshold validates\ntrue spikes while suppressing noise. Failure-prone segments then receive\ntargeted feature engineering (spectral slopes, statistical derivatives, energy\nratios), and the final RUL is produced by a stacked RF--LGBM regressor. Across\nbenchmark-ported datasets under an event-triggered protocol, SARNet\nconsistently lowers error compared to recent baselines (RMSE 0.0365, MAE\n0.0204) while remaining lightweight, robust, and easy to deploy.",
    "categories": [
      "cs.LG"
    ],
    "published": "2025-10-27T03:23:11Z",
    "authors": [
      "Junhao Fan",
      "Wenrui Liang",
      "Wei-Qiang Zhang"
    ],
    "pdf_url": "http://arxiv.org/pdf/2510.22955v1"
  },
  {
    "id": "2510.22953v1",
    "title": "Manifold Approximation leads to Robust Kernel Alignment",
    "abstract": "Centered kernel alignment (CKA) is a popular metric for comparing\nrepresentations, determining equivalence of networks, and neuroscience\nresearch. However, CKA does not account for the underlying manifold and relies\non numerous heuristics that cause it to behave differently at different scales\nof data. In this work, we propose Manifold approximated Kernel Alignment (MKA),\nwhich incorporates manifold geometry into the alignment task. We derive a\ntheoretical framework for MKA. We perform empirical evaluations on synthetic\ndatasets and real-world examples to characterize and compare MKA to its\ncontemporaries. Our findings suggest that manifold-aware kernel alignment\nprovides a more robust foundation for measuring representations, with potential\napplications in representation learning.",
    "categories": [
      "cs.LG",
      "cs.AI",
      "stat.ML"
    ],
    "published": "2025-10-27T03:16:15Z",
    "authors": [
      "Mohammad Tariqul Islam",
      "Du Liu",
      "Deblina Sarkar"
    ],
    "pdf_url": "http://arxiv.org/pdf/2510.22953v1"
  },
  {
    "id": "2510.22951v1",
    "title": "Hankel Singular Value Regularization for Highly Compressible State Space\n  Models",
    "abstract": "Deep neural networks using state space models as layers are well suited for\nlong-range sequence tasks but can be challenging to compress after training. We\nuse that regularizing the sum of Hankel singular values of state space models\nleads to a fast decay of these singular values and thus to compressible models.\nTo make the proposed Hankel singular value regularization scalable, we develop\nan algorithm to efficiently compute the Hankel singular values during training\niterations by exploiting the specific block-diagonal structure of the system\nmatrices that is we use in our state space model parametrization. Experiments\non Long Range Arena benchmarks demonstrate that the regularized state space\nlayers are up to 10$\\times$ more compressible than standard state space layers\nwhile maintaining high accuracy.",
    "categories": [
      "cs.LG",
      "math.DS"
    ],
    "published": "2025-10-27T03:09:45Z",
    "authors": [
      "Paul Schwerdtner",
      "Jules Berman",
      "Benjamin Peherstorfer"
    ],
    "pdf_url": "http://arxiv.org/pdf/2510.22951v1"
  },
  {
    "id": "2510.22941v1",
    "title": "Hazard-Responsive Digital Twin for Climate-Driven Urban Resilience and\n  Equity",
    "abstract": "Compounding climate hazards, such as wildfire-induced outages and urban\nheatwaves, challenge the stability and equity of cities. We present a\nHazard-Responsive Digital Twin (H-RDT) that combines physics-informed neural\nnetwork modeling, multimodal data fusion, and equity-aware risk analytics for\nurban-scale response. In a synthetic district with diverse building archetypes\nand populations, a simulated wildfire-outage-heatwave cascade shows that H-RDT\nmaintains stable indoor temperature predictions (approximately 31 to 33 C)\nunder partial sensor loss, reproducing outage-driven surges and recovery. The\nreinforcement learning based fusion module adaptively reweights IoT, UAV, and\nsatellite inputs to sustain spatiotemporal coverage, while the equity-adjusted\nmapping isolates high-vulnerability clusters (schools, clinics, low-income\nhousing). Prospective interventions, such as preemptive cooling-center\nactivation and microgrid sharing, reduce population-weighted thermal risk by 11\nto 13 percent, shrink the 95th-percentile (tail) risk by 7 to 17 percent, and\ncut overheating hours by up to 9 percent. Beyond the synthetic demonstration,\nthe framework establishes a transferable foundation for real-city\nimplementation, linking physical hazard modeling with social equity and\ndecision intelligence. The H-RDT advances digital urban resilience toward\nadaptive, learning-based, and equity-centered decision support for climate\nadaptation.",
    "categories": [
      "cs.LG",
      "68T07, 68U20, 49M41, 93A30",
      "I.2.6; I.6.4; I.2.11; C.3; H.4.2"
    ],
    "published": "2025-10-27T02:55:09Z",
    "authors": [
      "Zhenglai Shen",
      "Hongyu Zhou"
    ],
    "pdf_url": "http://arxiv.org/pdf/2510.22941v1"
  },
  {
    "id": "2510.22940v2",
    "title": "RL-AUX: Reinforcement Learning for Auxiliary Task Generation",
    "abstract": "Auxiliary Learning (AL) is a special case of Multi-task Learning (MTL) in\nwhich a network trains on auxiliary tasks to improve performance on its main\ntask. This technique is used to improve generalization and, ultimately,\nperformance on the network's main task. AL has been demonstrated to improve\nperformance across multiple domains, including navigation, image\nclassification, and natural language processing. One weakness of AL is the need\nfor labeled auxiliary tasks, which can require human effort and domain\nexpertise to generate. Meta Learning techniques have been used to solve this\nissue by learning an additional auxiliary task generation network that can\ncreate helpful tasks for the primary network. The most prominent techniques\nrely on Bi-Level Optimization, which incurs computational cost and increased\ncode complexity. To avoid the need for Bi-Level Optimization, we present an\nRL-based approach to dynamically create auxiliary tasks. In this framework, an\nRL agent is tasked with selecting auxiliary labels for every data point in a\ntraining set. The agent is rewarded when their selection improves the\nperformance on the primary task. We also experiment with learning optimal\nstrategies for weighing the auxiliary loss per data point. On the 20-Superclass\nCIFAR100 problem, our RL approach outperforms human-labeled auxiliary tasks and\nperforms as well as a prominent Bi-Level Optimization technique. Our weight\nlearning approaches significantly outperform all of these benchmarks. For\nexample, a Weight-Aware RL-based approach helps the VGG16 architecture achieve\n80.9% test accuracy while the human-labeled auxiliary task setup achieved\n75.53%. The goal of this work is to (1) prove that RL is a viable approach to\ndynamically generate auxiliary tasks and (2) demonstrate that per-sample\nauxiliary task weights can be learned alongside the auxiliary task labels and\ncan achieve strong results.",
    "categories": [
      "cs.LG"
    ],
    "published": "2025-10-27T02:51:51Z",
    "authors": [
      "Judah Goldfeder",
      "Matthew So",
      "Hod Lipson"
    ],
    "pdf_url": "http://arxiv.org/pdf/2510.22940v2"
  },
  {
    "id": "2510.22938v1",
    "title": "AQCat25: Unlocking spin-aware, high-fidelity machine learning potentials\n  for heterogeneous catalysis",
    "abstract": "Large-scale datasets have enabled highly accurate machine learning\ninteratomic potentials (MLIPs) for general-purpose heterogeneous catalysis\nmodeling. There are, however, some limitations in what can be treated with\nthese potentials because of gaps in the underlying training data. To extend\nthese capabilities, we introduce AQCat25, a complementary dataset of 13.5\nmillion density functional theory (DFT) single point calculations designed to\nimprove the treatment of systems where spin polarization and/or higher fidelity\nare critical. We also investigate methodologies for integrating new datasets,\nsuch as AQCat25, with the broader Open Catalyst 2020 (OC20) dataset to create\nspin-aware models without sacrificing generalizability. We find that directly\ntuning a general model on AQCat25 leads to catastrophic forgetting of the\noriginal dataset's knowledge. Conversely, joint training strategies prove\neffective for improving accuracy on the new data without sacrificing general\nperformance. This joint approach introduces a challenge, as the model must\nlearn from a dataset containing both mixed-fidelity calculations and\nmixed-physics (spin-polarized vs. unpolarized). We show that explicitly\nconditioning the model on this system-specific metadata, for example by using\nFeature-wise Linear Modulation (FiLM), successfully addresses this challenge\nand further enhances model accuracy. Ultimately, our work establishes an\neffective protocol for bridging DFT fidelity domains to advance the predictive\npower of foundational models in catalysis.",
    "categories": [
      "cond-mat.mtrl-sci",
      "cs.LG"
    ],
    "published": "2025-10-27T02:47:20Z",
    "authors": [
      "Omar Allam",
      "Brook Wander",
      "Aayush R. Singh"
    ],
    "pdf_url": "http://arxiv.org/pdf/2510.22938v1"
  },
  {
    "id": "2510.23672v1",
    "title": "DBLoss: Decomposition-based Loss Function for Time Series Forecasting",
    "abstract": "Time series forecasting holds significant value in various domains such as\neconomics, traffic, energy, and AIOps, as accurate predictions facilitate\ninformed decision-making. However, the existing Mean Squared Error (MSE) loss\nfunction sometimes fails to accurately capture the seasonality or trend within\nthe forecasting horizon, even when decomposition modules are used in the\nforward propagation to model the trend and seasonality separately. To address\nthese challenges, we propose a simple yet effective Decomposition-Based Loss\nfunction called DBLoss. This method uses exponential moving averages to\ndecompose the time series into seasonal and trend components within the\nforecasting horizon, and then calculates the loss for each of these components\nseparately, followed by weighting them. As a general loss function, DBLoss can\nbe combined with any deep learning forecasting model. Extensive experiments\ndemonstrate that DBLoss significantly improves the performance of\nstate-of-the-art models across diverse real-world datasets and provides a new\nperspective on the design of time series loss functions.",
    "categories": [
      "cs.LG"
    ],
    "published": "2025-10-27T02:42:25Z",
    "authors": [
      "Xiangfei Qiu",
      "Xingjian Wu",
      "Hanyin Cheng",
      "Xvyuan Liu",
      "Chenjuan Guo",
      "Jilin Hu",
      "Bin Yang"
    ],
    "pdf_url": "http://arxiv.org/pdf/2510.23672v1"
  },
  {
    "id": "2510.22937v1",
    "title": "Bi-Encoder Contrastive Learning for Fingerprint and Iris Biometrics",
    "abstract": "There has been a historic assumption that the biometrics of an individual are\nstatistically uncorrelated. We test this assumption by training Bi-Encoder\nnetworks on three verification tasks, including fingerprint-to-fingerprint\nmatching, iris-to-iris matching, and cross-modal fingerprint-to-iris matching\nusing 274 subjects with $\\sim$100k fingerprints and 7k iris images. We trained\nResNet-50 and Vision Transformer backbones in Bi-Encoder architectures such\nthat the contrastive loss between images sampled from the same individual is\nminimized. The iris ResNet architecture reaches 91 ROC AUC score for\niris-to-iris matching, providing clear evidence that the left and right irises\nof an individual are correlated. Fingerprint models reproduce the positive\nintra-subject suggested by prior work in this space. This is the first work\nattempting to use Vision Transformers for this matching. Cross-modal matching\nrises only slightly above chance, which suggests that more data and a more\nsophisticated pipeline is needed to obtain compelling results. These findings\ncontinue challenge independence assumptions of biometrics and we plan to extend\nthis work to other biometrics in the future. Code available:\nhttps://github.com/MatthewSo/bio_fingerprints_iris.",
    "categories": [
      "cs.CV",
      "cs.LG"
    ],
    "published": "2025-10-27T02:41:43Z",
    "authors": [
      "Matthew So",
      "Judah Goldfeder",
      "Mark Lis",
      "Hod Lipson"
    ],
    "pdf_url": "http://arxiv.org/pdf/2510.22937v1"
  },
  {
    "id": "2510.22931v2",
    "title": "Robust Uncertainty Quantification for Self-Evolving Large Language\n  Models via Continual Domain Pretraining",
    "abstract": "Continual Learning (CL) is essential for enabling self-evolving large\nlanguage models (LLMs) to adapt and remain effective amid rapid knowledge\ngrowth. Yet, despite its importance, little attention has been given to\nestablishing statistical reliability guarantees for LLMs under CL, particularly\nin the setting of continual domain pretraining (CDP). Conformal Prediction (CP)\nhas shown promise in offering correctness guarantees for LLMs, but it faces\nmajor challenges in CDP: testing data often stems from unknown or shifting\ndomain distributions, under which CP may no longer provide valid guarantees.\nMoreover, when high coverage is required, CP can yield excessively large\nprediction sets for unanswerable queries, reducing informativeness. To address\nthese challenges, we introduce an adaptive rejection and non-exchangeable CP\nframework. Our method first estimates the distribution of questions across\ndomains in the test set using transformer-based clustering, then reweights or\nresamples the calibration data accordingly. Building on this, adaptive\nrejection CP allows the LLM to selectively abstain from answering when its\nconfidence or competence shifts significantly. Extensive experiments\ndemonstrate that our framework enhances both the effectiveness and reliability\nof CP under CDP scenarios. Our code is available at:\nhttps://anonymous.4open.science/r/CPCL-8C12/",
    "categories": [
      "cs.LG",
      "cs.AI"
    ],
    "published": "2025-10-27T02:15:51Z",
    "authors": [
      "Xiaofan Zhou",
      "Lu Cheng"
    ],
    "pdf_url": "http://arxiv.org/pdf/2510.22931v2"
  },
  {
    "id": "2510.22928v1",
    "title": "Diffuse to Detect: A Generalizable Framework for Anomaly Detection with\n  Diffusion Models Applications to UAVs and Beyond",
    "abstract": "Anomaly detection in complex, high-dimensional data, such as UAV sensor\nreadings, is essential for operational safety but challenging for existing\nmethods due to their limited sensitivity, scalability, and inability to capture\nintricate dependencies. We propose the Diffuse to Detect (DTD) framework, a\nnovel approach that innovatively adapts diffusion models for anomaly detection,\ndiverging from their conventional use in generative tasks with high inference\ntime. By comparison, DTD employs a single-step diffusion process to predict\nnoise patterns, enabling rapid and precise identification of anomalies without\nreconstruction errors. This approach is grounded in robust theoretical\nfoundations that link noise prediction to the data distribution's score\nfunction, ensuring reliable deviation detection. By integrating Graph Neural\nNetworks to model sensor relationships as dynamic graphs, DTD effectively\ncaptures spatial (inter-sensor) and temporal anomalies. Its two-branch\narchitecture, with parametric neural network-based energy scoring for\nscalability and nonparametric statistical methods for interpretability,\nprovides flexible trade-offs between computational efficiency and transparency.\nExtensive evaluations on UAV sensor data, multivariate time series, and images\ndemonstrate DTD's superior performance over existing methods, underscoring its\ngenerality across diverse data modalities. This versatility, combined with its\nadaptability, positions DTD as a transformative solution for safety-critical\napplications, including industrial monitoring and beyond.",
    "categories": [
      "cs.LG"
    ],
    "published": "2025-10-27T02:08:08Z",
    "authors": [
      "Mingze Gong",
      "Juan Du",
      "Jianbang You"
    ],
    "pdf_url": "http://arxiv.org/pdf/2510.22928v1"
  },
  {
    "id": "2510.22926v1",
    "title": "Simple Denoising Diffusion Language Models",
    "abstract": "Diffusion models have recently been extended to language generation through\nMasked Diffusion Language Models (MDLMs), which achieve performance competitive\nwith strong autoregressive models. However, MDLMs tend to degrade in the\nfew-step regime and cannot directly adopt existing few-step distillation\nmethods designed for continuous diffusion models, as they lack the intrinsic\nproperty of mapping from noise to data. Recent Uniform-state Diffusion Models\n(USDMs), initialized from a uniform prior, alleviate some limitations but still\nsuffer from complex loss formulations that hinder scalability. In this work, we\npropose a simplified denoising-based loss for USDMs that optimizes only\nnoise-replaced tokens, stabilizing training and matching ELBO-level\nperformance. Furthermore, by framing denoising as self-supervised learning, we\nintroduce a simple modification to our denoising loss with contrastive-inspired\nnegative gradients, which is practical and yield additional improvements in\ngeneration quality.",
    "categories": [
      "cs.LG"
    ],
    "published": "2025-10-27T02:05:26Z",
    "authors": [
      "Huaisheng Zhu",
      "Zhengyu Chen",
      "Shijie Zhou",
      "Zhihui Xie",
      "Yige Yuan",
      "Zhimeng Guo",
      "Siyuan Xu",
      "Hangfan Zhang",
      "Vasant Honavar",
      "Teng Xiao"
    ],
    "pdf_url": "http://arxiv.org/pdf/2510.22926v1"
  },
  {
    "id": "2510.22913v1",
    "title": "Clinic-Oriented Feasibility of a Sensor-Fused Wearable for Upper-Limb\n  Function",
    "abstract": "Background: Upper-limb weakness and tremor (4--12 Hz) limit activities of\ndaily living (ADL) and reduce adherence to home rehabilitation. Objective: To\nassess technical feasibility and clinician-relevant signals of a sensor-fused\nwearable targeting the triceps brachii and extensor pollicis brevis. Methods: A\nlightweight node integrates surface EMG (1 kHz), IMU (100--200 Hz), and\nflex/force sensors with on-device INT8 inference (Tiny 1D-CNN/Transformer) and\na safety-bounded assist policy (angle/torque/jerk limits; stall/time-out).\nHealthy adults (n = 12) performed three ADL-like tasks. Primary outcomes:\nTremor Index (TI), range of motion (ROM), repetitions (Reps min$^{-1}$).\nSecondary: EMG median-frequency slope (fatigue trend), closed-loop latency,\nsession completion, and device-related adverse events. Analyses used\nsubject-level paired medians with BCa 95\\% CIs; exact Wilcoxon $p$-values are\nreported in the Results. Results: Assistance was associated with lower tremor\nprominence and improved task throughput: TI decreased by $-0.092$ (95\\% CI\n[$-0.102$, $-0.079$]), ROM increased by $+12.65\\%$ (95\\% CI [$+8.43$,\n$+13.89$]), and Reps rose by $+2.99$ min$^{-1}$ (95\\% CI [$+2.61$, $+3.35$]).\nMedian on-device latency was 8.7 ms at a 100 Hz loop rate; all sessions were\ncompleted with no device-related adverse events. Conclusions: Multimodal\nsensing with low-latency, safety-bounded assistance produced improved movement\nquality (TI $\\downarrow$) and throughput (ROM, Reps $\\uparrow$) in a pilot\ntechnical-feasibility setting, supporting progression to IRB-approved patient\nstudies. Trial registration: Not applicable (pilot non-clinical).",
    "categories": [
      "eess.SP",
      "cs.HC",
      "cs.LG",
      "cs.RO",
      "q-bio.NC"
    ],
    "published": "2025-10-27T01:30:26Z",
    "authors": [
      "Thanyanee Srichaisak",
      "Arissa Ieochai",
      "Aueaphum Aueawattthanaphisut"
    ],
    "pdf_url": "http://arxiv.org/pdf/2510.22913v1"
  },
  {
    "id": "2510.22911v2",
    "title": "Towards Personalized Treatment Plan: Geometrical Model-Agnostic Approach\n  to Counterfactual Explanations",
    "abstract": "In our article, we describe a method for generating counterfactual\nexplanations in high-dimensional spaces using four steps that involve fitting\nour dataset to a model, finding the decision boundary, determining constraints\non the problem, and computing the closest point (counterfactual explanation)\nfrom that boundary. We propose a discretized approach where we find many\ndiscrete points on the boundary and then identify the closest feasible\ncounterfactual explanation. This method, which we later call $\\textit{Segmented\nSampling for Boundary Approximation}$ (SSBA), applies binary search to find\ndecision boundary points and then searches for the closest boundary point.\nAcross four datasets of varying dimensionality, we show that our method can\noutperform current methods for counterfactual generation with reductions in\ndistance between $5\\%$ to $50\\%$ in terms of the $L_2$ norm. Our method can\nalso handle real-world constraints by restricting changes to immutable and\ncategorical features, such as age, gender, sex, height, and other related\ncharacteristics such as the case for a health-based dataset. In terms of\nruntime, the SSBA algorithm generates decision boundary points on multiple\norders of magnitude in the same given time when we compare to a grid-based\napproach. In general, our method provides a simple and effective model-agnostic\nmethod that can compute nearest feasible (i.e. realistic with constraints)\ncounterfactual explanations. All of our results and code are available at:\nhttps://github.com/dsin85691/SSBA_For_Counterfactuals",
    "categories": [
      "cs.LG",
      "stat.ML"
    ],
    "published": "2025-10-27T01:28:57Z",
    "authors": [
      "Daniel Sin",
      "Milad Toutounchian"
    ],
    "pdf_url": "http://arxiv.org/pdf/2510.22911v2"
  },
  {
    "id": "2510.22899v1",
    "title": "On the Anisotropy of Score-Based Generative Models",
    "abstract": "We investigate the role of network architecture in shaping the inductive\nbiases of modern score-based generative models. To this end, we introduce the\nScore Anisotropy Directions (SADs), architecture-dependent directions that\nreveal how different networks preferentially capture data structure. Our\nanalysis shows that SADs form adaptive bases aligned with the architecture's\noutput geometry, providing a principled way to predict generalization ability\nin score models prior to training. Through both synthetic data and standard\nimage benchmarks, we demonstrate that SADs reliably capture fine-grained model\nbehavior and correlate with downstream performance, as measured by Wasserstein\nmetrics. Our work offers a new lens for explaining and predicting directional\nbiases of generative models.",
    "categories": [
      "cs.LG",
      "stat.ML"
    ],
    "published": "2025-10-27T01:01:41Z",
    "authors": [
      "Andreas Floros",
      "Seyed-Mohsen Moosavi-Dezfooli",
      "Pier Luigi Dragotti"
    ],
    "pdf_url": "http://arxiv.org/pdf/2510.22899v1"
  },
  {
    "id": "2510.22897v1",
    "title": "Charting the Design Space of Neural Graph Representations for Subgraph\n  Matching",
    "abstract": "Subgraph matching is vital in knowledge graph (KG) question answering,\nmolecule design, scene graph, code and circuit search, etc. Neural methods have\nshown promising results for subgraph matching. Our study of recent systems\nsuggests refactoring them into a unified design space for graph matching\nnetworks. Existing methods occupy only a few isolated patches in this space,\nwhich remains largely uncharted. We undertake the first comprehensive\nexploration of this space, featuring such axes as attention-based vs. soft\npermutation-based interaction between query and corpus graphs, aligning nodes\nvs. edges, and the form of the final scoring network that integrates neural\nrepresentations of the graphs. Our extensive experiments reveal that judicious\nand hitherto-unexplored combinations of choices in this space lead to large\nperformance benefits. Beyond better performance, our study uncovers valuable\ninsights and establishes general design principles for neural graph\nrepresentation and interaction, which may be of wider interest.",
    "categories": [
      "cs.LG"
    ],
    "published": "2025-10-27T00:58:29Z",
    "authors": [
      "Vaibhav Raj",
      "Indradyumna Roy",
      "Ashwin Ramachandran",
      "Soumen Chakrabarti",
      "Abir De"
    ],
    "pdf_url": "http://arxiv.org/pdf/2510.22897v1"
  },
  {
    "id": "2510.22889v1",
    "title": "Transforming volcanic monitoring: A dataset and benchmark for onboard\n  volcano activity detection",
    "abstract": "Natural disasters, such as volcanic eruptions, pose significant challenges to\ndaily life and incur considerable global economic losses. The emergence of\nnext-generation small-satellites, capable of constellation-based operations,\noffers unparalleled opportunities for near-real-time monitoring and onboard\nprocessing of such events. However, a major bottleneck remains the lack of\nextensive annotated datasets capturing volcanic activity, which hinders the\ndevelopment of robust detection systems. This paper introduces a novel dataset\nexplicitly designed for volcanic activity and eruption detection, encompassing\ndiverse volcanoes worldwide. The dataset provides binary annotations to\nidentify volcanic anomalies or non-anomalies, covering phenomena such as\ntemperature anomalies, eruptions, and volcanic ash emissions. These annotations\noffer a foundational resource for developing and evaluating detection models,\naddressing a critical gap in volcanic monitoring research. Additionally, we\npresent comprehensive benchmarks using state-of-the-art models to establish\nbaselines for future studies. Furthermore, we explore the potential for\ndeploying these models onboard next-generation satellites. Using the Intel\nMovidius Myriad X VPU as a testbed, we demonstrate the feasibility of volcanic\nactivity detection directly onboard. This capability significantly reduces\nlatency and enhances response times, paving the way for advanced early warning\nsystems. This paves the way for innovative solutions in volcanic disaster\nmanagement, encouraging further exploration and refinement of onboard\nmonitoring technologies.",
    "categories": [
      "cs.LG"
    ],
    "published": "2025-10-27T00:42:16Z",
    "authors": [
      "Darshana Priyasad",
      "Tharindu Fernando",
      "Maryam Haghighat",
      "Harshala Gammulle",
      "Clinton Fookes"
    ],
    "pdf_url": "http://arxiv.org/pdf/2510.22889v1"
  },
  {
    "id": "2510.22885v1",
    "title": "AI based signage classification for linguistic landscape studies",
    "abstract": "Linguistic Landscape (LL) research traditionally relies on manual photography\nand annotation of public signages to examine distribution of languages in urban\nspace. While such methods yield valuable findings, the process is\ntime-consuming and difficult for large study areas. This study explores the use\nof AI powered language detection method to automate LL analysis. Using Honolulu\nChinatown as a case study, we constructed a georeferenced photo dataset of\n1,449 images collected by researchers and applied AI for optical character\nrecognition (OCR) and language classification. We also conducted manual\nvalidations for accuracy checking. This model achieved an overall accuracy of\n79%. Five recurring types of mislabeling were identified, including distortion,\nreflection, degraded surface, graffiti, and hallucination. The analysis also\nreveals that the AI model treats all regions of an image equally, detecting\nperipheral or background texts that human interpreters typically ignore.\nDespite these limitations, the results demonstrate the potential of integrating\nAI-assisted workflows into LL research to reduce such time-consuming processes.\nHowever, due to all the limitations and mis-labels, we recognize that AI cannot\nbe fully trusted during this process. This paper encourages a hybrid approach\ncombining AI automation with human validation for a more reliable and efficient\nworkflow.",
    "categories": [
      "cs.LG"
    ],
    "published": "2025-10-27T00:23:04Z",
    "authors": [
      "Yuqin Jiang",
      "Song Jiang",
      "Jacob Algrim",
      "Trevor Harms",
      "Maxwell Koenen",
      "Xinya Lan",
      "Xingyu Li",
      "Chun-Han Lin",
      "Jia Liu",
      "Jiayang Sun",
      "Henry Zenger"
    ],
    "pdf_url": "http://arxiv.org/pdf/2510.22885v1"
  },
  {
    "id": "2510.22881v1",
    "title": "Offline Preference Optimization via Maximum Marginal Likelihood\n  Estimation",
    "abstract": "Aligning Large Language Models (LLMs) with human preferences is crucial, but\nstandard methods like Reinforcement Learning from Human Feedback (RLHF) are\noften complex and unstable. In this work, we propose a new, simpler approach\nthat recasts alignment through the lens of Maximum Marginal Likelihood (MML)\nestimation. Our new MML based Preference Optimization (MMPO) maximizes the\nmarginal log-likelihood of a preferred text output, using the preference pair\nas samples for approximation, and forgoes the need for both an explicit reward\nmodel and entropy maximization. We theoretically demonstrate that MMPO\nimplicitly performs preference optimization, producing a weighted gradient that\nnaturally up-weights chosen responses over rejected ones. Across models ranging\nfrom 135M to 8B parameters, we empirically show that MMPO: 1) is more stable\nwith respect to the hyperparameter $\\beta$ compared to alternative baselines,\nand 2) achieves competitive or superior preference alignment while better\npreserving the base model's general language capabilities. Through a series of\nablation experiments, we show that this improved performance is indeed\nattributable to MMPO's implicit preference optimization within the gradient\nupdates.",
    "categories": [
      "cs.LG",
      "cs.CL"
    ],
    "published": "2025-10-27T00:15:57Z",
    "authors": [
      "Saeed Najafi",
      "Alona Fyshe"
    ],
    "pdf_url": "http://arxiv.org/pdf/2510.22881v1"
  },
  {
    "id": "2510.22880v1",
    "title": "Learning Reconfigurable Representations for Multimodal Federated\n  Learning with Missing Data",
    "abstract": "Multimodal federated learning in real-world settings often encounters\nincomplete and heterogeneous data across clients. This results in misaligned\nlocal feature representations that limit the effectiveness of model\naggregation. Unlike prior work that assumes either differing modality sets\nwithout missing input features or a shared modality set with missing features\nacross clients, we consider a more general and realistic setting where each\nclient observes a different subset of modalities and might also have missing\ninput features within each modality. To address the resulting misalignment in\nlearned representations, we propose a new federated learning framework\nfeaturing locally adaptive representations based on learnable client-side\nembedding controls that encode each client's data-missing patterns.\n  These embeddings serve as reconfiguration signals that align the globally\naggregated representation with each client's local context, enabling more\neffective use of shared information. Furthermore, the embedding controls can be\nalgorithmically aggregated across clients with similar data-missing patterns to\nenhance the robustness of reconfiguration signals in adapting the global\nrepresentation. Empirical results on multiple federated multimodal benchmarks\nwith diverse data-missing patterns across clients demonstrate the efficacy of\nthe proposed method, achieving up to 36.45\\% performance improvement under\nsevere data incompleteness. The method is also supported by a theoretical\nanalysis with an explicit performance bound that matches our empirical\nobservations. Our source codes are provided at\nhttps://github.com/nmduonggg/PEPSY",
    "categories": [
      "cs.LG",
      "cs.AI"
    ],
    "published": "2025-10-27T00:09:58Z",
    "authors": [
      "Duong M. Nguyen",
      "Trong Nghia Hoang",
      "Thanh Trung Huynh",
      "Quoc Viet Hung Nguyen",
      "Phi Le Nguyen"
    ],
    "pdf_url": "http://arxiv.org/pdf/2510.22880v1"
  },
  {
    "id": "2510.22878v1",
    "title": "Limits of Generative Pre-Training in Structured EMR Trajectories with\n  Irregular Sampling",
    "abstract": "Foundation models refer to architectures trained on vast datasets using\nautoregressive pre-training from natural language processing to capture\nintricate patterns and motifs. They were originally developed to transfer such\nlearned knowledge to downstream predictive tasks. Recently, however, some\nstudies repurpose these learned representations for phenotype discovery without\nrigorous validation, risking superficially realistic but clinically incoherent\nembeddings. To test this mismatch, we trained two autoregressive models -- a\nsequence-to-sequence LSTM and a reduced Transformer -- on longitudinal ART for\nHIV and Acute Hypotension datasets. Controlled irregularity was added during\ntraining via random inter-visit gaps, while test sequences stayed complete.\nPatient-trajectory synthesis evaluated distributional and correlational\nfidelity. Both reproduced feature distributions but failed to preserve\ncross-feature structure -- showing that generative pre-training yields local\nrealism but limited clinical coherence. These results highlight the need for\ndomain-specific evaluation and support trajectory synthesis as a practical\nprobe before fine-tuning or deployment.",
    "categories": [
      "cs.LG"
    ],
    "published": "2025-10-27T00:04:17Z",
    "authors": [
      "Nicholas I-Hsien Kuo",
      "Blanca Gallego",
      "Louisa Jorm"
    ],
    "pdf_url": "http://arxiv.org/pdf/2510.22878v1"
  },
  {
    "id": "2510.22866v1",
    "title": "Interpreting and Mitigating Unwanted Uncertainty in LLMs",
    "abstract": "Despite their impressive capabilities, Large Language Models (LLMs) exhibit\nunwanted uncertainty, a phenomenon where a model changes a previously correct\nanswer into an incorrect one when re-prompted. This behavior undermines trust\nand poses serious risks in high-stakes domains. In this work, we investigate\nthe mechanisms that drive this phenomenon. We adapt the Needle-in-a-Haystack\nretrieval framework and integrate a Flip-style re-evaluation prompt to simulate\nrealistic answer-flipping scenarios. We find that retrieval heads are not\nprimarily responsible for avoiding uncertainty. Instead, we identify a small\nset of non-retrieval attention heads that disproportionately attend to\nmisleading tokens in uncertain contexts. Masking these heads yields significant\nimprovements, reducing flip behavior by up to 15% without introducing\nincoherence or overcorrection. However, when tested for downstream tasks, we\nobserve trade-offs with flip behavior. Our findings contribute to the growing\nfield of mechanistic interpretability and present a simple yet effective\ntechnique for mitigating uncertainty-driven failure modes in LLMs.",
    "categories": [
      "cs.CL",
      "cs.LG"
    ],
    "published": "2025-10-26T23:16:59Z",
    "authors": [
      "Tiasa Singha Roy",
      "Ayush Rajesh Jhaveri",
      "Ilias Triantafyllopoulos"
    ],
    "pdf_url": "http://arxiv.org/pdf/2510.22866v1"
  },
  {
    "id": "2510.24784v1",
    "title": "Sub-microsecond Transformers for Jet Tagging on FPGAs",
    "abstract": "We present the first sub-microsecond transformer implementation on an FPGA\nachieving competitive performance for state-of-the-art high-energy physics\nbenchmarks. Transformers have shown exceptional performance on multiple tasks\nin modern machine learning applications, including jet tagging at the CERN\nLarge Hadron Collider (LHC). However, their computational complexity prohibits\nuse in real-time applications, such as the hardware trigger system of the\ncollider experiments up until now. In this work, we demonstrate the first\napplication of transformers for jet tagging on FPGAs, achieving\n$\\mathcal{O}(100)$ nanosecond latency with superior performance compared to\nalternative baseline models. We leverage high-granularity quantization and\ndistributed arithmetic optimization to fit the entire transformer model on a\nsingle FPGA, achieving the required throughput and latency. Furthermore, we add\nmulti-head attention and linear attention support to hls4ml, making our work\naccessible to the broader fast machine learning community. This work advances\nthe next-generation trigger systems for the High Luminosity LHC, enabling the\nuse of transformers for real-time applications in high-energy physics and\nbeyond.",
    "categories": [
      "physics.ins-det",
      "cs.LG",
      "cs.PF",
      "hep-ex"
    ],
    "published": "2025-10-26T23:13:00Z",
    "authors": [
      "Lauri Laatu",
      "Chang Sun",
      "Arianna Cox",
      "Abhijith Gandrakota",
      "Benedikt Maier",
      "Jennifer Ngadiuba",
      "Zhiqiang Que",
      "Wayne Luk",
      "Maria Spiropulu",
      "Alexander Tapper"
    ],
    "pdf_url": "http://arxiv.org/pdf/2510.24784v1"
  },
  {
    "id": "2510.22863v1",
    "title": "Long-Term PM2.5 Forecasting Using a DTW-Enhanced CNN-GRU Model",
    "abstract": "Reliable long-term forecasting of PM2.5 concentrations is critical for public\nhealth early-warning systems, yet existing deep learning approaches struggle to\nmaintain prediction stability beyond 48 hours, especially in cities with sparse\nmonitoring networks. This paper presents a deep learning framework that\ncombines Dynamic Time Warping (DTW) for intelligent station similarity\nselection with a CNN-GRU architecture to enable extended-horizon PM2.5\nforecasting in Isfahan, Iran, a city characterized by complex pollution\ndynamics and limited monitoring coverage. Unlike existing approaches that rely\non computationally intensive transformer models or external simulation tools,\nour method integrates three key innovations: (i) DTW-based historical sampling\nto identify similar pollution patterns across peer stations, (ii) a lightweight\nCNN-GRU architecture augmented with meteorological features, and (iii) a\nscalable design optimized for sparse networks. Experimental validation using\nmulti-year hourly data from eight monitoring stations demonstrates superior\nperformance compared to state-of-the-art deep learning methods, achieving R2 =\n0.91 for 24-hour forecasts. Notably, this is the first study to demonstrate\nstable 10-day PM2.5 forecasting (R2 = 0.73 at 240 hours) without performance\ndegradation, addressing critical early-warning system requirements. The\nframework's computational efficiency and independence from external tools make\nit particularly suitable for deployment in resource-constrained urban\nenvironments.",
    "categories": [
      "cs.LG",
      "cs.AI"
    ],
    "published": "2025-10-26T23:04:10Z",
    "authors": [
      "Amirali Ataee Naeini",
      "Arshia Ataee Naeini",
      "Fatemeh Karami Mohammadi",
      "Omid Ghaffarpasand"
    ],
    "pdf_url": "http://arxiv.org/pdf/2510.22863v1"
  },
  {
    "id": "2510.23671v1",
    "title": "Sparsity and Superposition in Mixture of Experts",
    "abstract": "Mixture of Experts (MoE) models have become central to scaling large language\nmodels, yet their mechanistic differences from dense networks remain poorly\nunderstood. Previous work has explored how dense models use\n\\textit{superposition} to represent more features than dimensions, and how\nsuperposition is a function of feature sparsity and feature importance. MoE\nmodels cannot be explained mechanistically through the same lens. We find that\nneither feature sparsity nor feature importance cause discontinuous phase\nchanges, and that network sparsity (the ratio of active to total experts)\nbetter characterizes MoEs. We develop new metrics for measuring superposition\nacross experts. Our findings demonstrate that models with greater network\nsparsity exhibit greater \\emph{monosemanticity}. We propose a new definition of\nexpert specialization based on monosemantic feature representation rather than\nload balancing, showing that experts naturally organize around coherent feature\ncombinations when initialized appropriately. These results suggest that network\nsparsity in MoEs may enable more interpretable models without sacrificing\nperformance, challenging the common assumption that interpretability and\ncapability are fundamentally at odds.",
    "categories": [
      "cs.LG",
      "cs.AI"
    ],
    "published": "2025-10-26T22:44:35Z",
    "authors": [
      "Marmik Chaudhari",
      "Jeremi Nuer",
      "Rome Thorstenson"
    ],
    "pdf_url": "http://arxiv.org/pdf/2510.23671v1"
  },
  {
    "id": "2510.22859v1",
    "title": "Guardian: Decoupling Exploration from Safety in Reinforcement Learning",
    "abstract": "Hybrid offline--online reinforcement learning (O2O RL) promises both sample\nefficiency and robust exploration, but suffers from instability due to\ndistribution shift between offline and online data. We introduce RLPD-GX, a\nframework that decouples policy optimization from safety enforcement: a\nreward-seeking learner explores freely, while a projection-based guardian\nguarantees rule-consistent execution and safe value backups. This design\npreserves the exploratory value of online interactions without collapsing to\nconservative policies. To further stabilize training, we propose dynamic\ncurricula that gradually extend temporal horizons and anneal offline--online\ndata mixing. We prove convergence via a contraction property of the guarded\nBellman operator, and empirically show state-of-the-art performance on\nAtari-100k, achieving a normalized mean score of 3.02 (+45\\% over prior hybrid\nmethods) with stronger safety and stability. Beyond Atari, ablations\ndemonstrate consistent gains across safety-critical and long-horizon tasks,\nunderscoring the generality of our design. Extensive and comprehensive results\nhighlight decoupled safety enforcement as a simple yet principled route to\nrobust O2O RL, suggesting a broader paradigm for reconciling exploration and\nsafety in reinforcement learning.",
    "categories": [
      "cs.LG",
      "cs.AI"
    ],
    "published": "2025-10-26T22:25:47Z",
    "authors": [
      "Kaitong Cai",
      "Jusheng Zhang",
      "Jing Yang",
      "Keze Wang"
    ],
    "pdf_url": "http://arxiv.org/pdf/2510.22859v1"
  },
  {
    "id": "2510.22855v1",
    "title": "A Review of End-to-End Precipitation Prediction Using Remote Sensing\n  Data: from Divination to Machine Learning",
    "abstract": "Precipitation prediction has undergone a profound transformation -- from\nearly symbolic and empirical methods rooted in divination and observation, to\nmodern technologies based on atmospheric physics and artificial intelligence.\nThis review traces the historical and technological evolution of precipitation\nforecasting, presenting a survey about end-to-end precipitation prediction\ntechnologies that spans ancient practices, the foundations of meteorological\nscience, the rise of numerical weather prediction (NWP), and the emergence of\nmachine learning (ML) and deep learning (DL) models. We first explore\ntraditional and indigenous forecasting methods, then describe the development\nof physical modeling and statistical frameworks that underpin contemporary\noperational forecasting. Particular emphasis is placed on recent advances in\nneural network-based approaches, including automated deep learning,\ninterpretability-driven design, and hybrid physical-data models. By compositing\nresearch across multiple eras and paradigms, this review not only depicts the\nhistory of end-to-end precipitation prediction but also outlines future\ndirections in next generation forecasting systems.",
    "categories": [
      "cs.LG"
    ],
    "published": "2025-10-26T22:14:07Z",
    "authors": [
      "Yugong Zeng",
      "Jonathan Wu"
    ],
    "pdf_url": "http://arxiv.org/pdf/2510.22855v1"
  },
  {
    "id": "2510.22852v1",
    "title": "Encoder-Decoder Diffusion Language Models for Efficient Training and\n  Inference",
    "abstract": "Discrete diffusion models enable parallel token sampling for faster inference\nthan autoregressive approaches. However, prior diffusion models use a\ndecoder-only architecture, which requires sampling algorithms that invoke the\nfull network at every denoising step and incur high computational cost. Our key\ninsight is that discrete diffusion models perform two types of computation: 1)\nrepresenting clean tokens and 2) denoising corrupted tokens, which enables us\nto use separate modules for each task. We propose an encoder-decoder\narchitecture to accelerate discrete diffusion inference, which relies on an\nencoder to represent clean tokens and a lightweight decoder to iteratively\nrefine a noised sequence. We also show that this architecture enables faster\ntraining of block diffusion models, which partition sequences into blocks for\nbetter quality and are commonly used in diffusion language model inference. We\nintroduce a framework for Efficient Encoder-Decoder Diffusion (E2D2),\nconsisting of an architecture with specialized training and sampling\nalgorithms, and we show that E2D2 achieves superior trade-offs between\ngeneration quality and inference throughput on summarization, translation, and\nmathematical reasoning tasks. We provide the code, model weights, and blog post\non the project page: https://m-arriola.com/e2d2",
    "categories": [
      "cs.LG",
      "cs.AI"
    ],
    "published": "2025-10-26T22:05:22Z",
    "authors": [
      "Marianne Arriola",
      "Yair Schiff",
      "Hao Phung",
      "Aaron Gokaslan",
      "Volodymyr Kuleshov"
    ],
    "pdf_url": "http://arxiv.org/pdf/2510.22852v1"
  },
  {
    "id": "2510.22849v1",
    "title": "Once Upon an Input: Reasoning via Per-Instance Program Synthesis",
    "abstract": "Large language models (LLMs) excel at zero-shot inference but continue to\nstruggle with complex, multi-step reasoning. Recent methods that augment LLMs\nwith intermediate reasoning steps such as Chain of Thought (CoT) and Program of\nThought (PoT) improve performance but often produce undesirable solutions,\nespecially in algorithmic domains. We introduce Per-Instance Program Synthesis\n(PIPS), a method that generates and refines programs at the instance-level\nusing structural feedback without relying on task-specific guidance or explicit\ntest cases. To further improve performance, PIPS incorporates a confidence\nmetric that dynamically chooses between direct inference and program synthesis\non a per-instance basis. Experiments across three frontier LLMs and 30\nbenchmarks including all tasks of Big Bench Extra Hard (BBEH), visual question\nanswering tasks, relational reasoning tasks, and mathematical reasoning tasks\nshow that PIPS improves the absolute harmonic mean accuracy by up to 8.6% and\n9.4% compared to PoT and CoT respectively, and reduces undesirable program\ngenerations by 65.1% on the algorithmic tasks compared to PoT with\nGemini-2.0-Flash.",
    "categories": [
      "cs.CL",
      "cs.AI",
      "cs.LG"
    ],
    "published": "2025-10-26T21:58:33Z",
    "authors": [
      "Adam Stein",
      "Neelay Velingker",
      "Mayur Naik",
      "Eric Wong"
    ],
    "pdf_url": "http://arxiv.org/pdf/2510.22849v1"
  },
  {
    "id": "2510.22848v1",
    "title": "Self-induced stochastic resonance: A physics-informed machine learning\n  approach",
    "abstract": "Self-induced stochastic resonance (SISR) is the emergence of coherent\noscillations in slow-fast excitable systems driven solely by noise, without\nexternal periodic forcing or proximity to a bifurcation. This work presents a\nphysics-informed machine learning framework for modeling and predicting SISR in\nthe stochastic FitzHugh-Nagumo neuron. We embed the governing stochastic\ndifferential equations and SISR-asymptotic timescale-matching constraints\ndirectly into a Physics-Informed Neural Network (PINN) based on a\nNoise-Augmented State Predictor architecture. The composite loss integrates\ndata fidelity, dynamical residuals, and barrier-based physical constraints\nderived from Kramers' escape theory. The trained PINN accurately predicts the\ndependence of spike-train coherence on noise intensity, excitability, and\ntimescale separation, matching results from direct stochastic simulations with\nsubstantial improvements in accuracy and generalization compared with purely\ndata-driven methods, while requiring significantly less computation. The\nframework provides a data-efficient and interpretable surrogate model for\nsimulating and analyzing noise-induced coherence in multiscale stochastic\nsystems.",
    "categories": [
      "cs.LG",
      "nlin.AO",
      "stat.ML"
    ],
    "published": "2025-10-26T21:49:20Z",
    "authors": [
      "Divyesh Savaliya",
      "Marius E. Yamakou"
    ],
    "pdf_url": "http://arxiv.org/pdf/2510.22848v1"
  },
  {
    "id": "2510.22835v1",
    "title": "Clustering by Denoising: Latent plug-and-play diffusion for single-cell\n  data",
    "abstract": "Single-cell RNA sequencing (scRNA-seq) enables the study of cellular\nheterogeneity. Yet, clustering accuracy, and with it downstream analyses based\non cell labels, remain challenging due to measurement noise and biological\nvariability. In standard latent spaces (e.g., obtained through PCA), data from\ndifferent cell types can be projected close together, making accurate\nclustering difficult. We introduce a latent plug-and-play diffusion framework\nthat separates the observation and denoising space. This separation is\noperationalized through a novel Gibbs sampling procedure: the learned diffusion\nprior is applied in a low-dimensional latent space to perform denoising, while\nto steer this process, noise is reintroduced into the original high-dimensional\nobservation space. This unique \"input-space steering\" ensures the denoising\ntrajectory remains faithful to the original data structure. Our approach offers\nthree key advantages: (1) adaptive noise handling via a tunable balance between\nprior and observed data; (2) uncertainty quantification through principled\nuncertainty estimates for downstream analysis; and (3) generalizable denoising\nby leveraging clean reference data to denoise noisier datasets, and via\naveraging, improve quality beyond the training set. We evaluate robustness on\nboth synthetic and real single-cell genomics data. Our method improves\nclustering accuracy on synthetic data across varied noise levels and dataset\nshifts. On real-world single-cell data, our method demonstrates improved\nbiological coherence in the resulting cell clusters, with cluster boundaries\nthat better align with known cell type markers and developmental trajectories.",
    "categories": [
      "cs.LG",
      "stat.CO",
      "stat.ML"
    ],
    "published": "2025-10-26T21:03:56Z",
    "authors": [
      "Dominik Meier",
      "Shixing Yu",
      "Sagnik Nandy",
      "Promit Ghosal",
      "Kyra Gan"
    ],
    "pdf_url": "http://arxiv.org/pdf/2510.22835v1"
  },
  {
    "id": "2510.22833v1",
    "title": "Toward Agents That Reason About Their Computation",
    "abstract": "While reinforcement learning agents can achieve superhuman performance in\nmany complex tasks, they typically do not become more computationally efficient\nas they improve. In contrast, humans gradually require less cognitive effort as\nthey become more proficient at a task. If agents could reason about their\ncompute as they learn, could they similarly reduce their computation footprint?\nIf they could, we could have more energy efficient agents or free up compute\ncycles for other processes like planning. In this paper, we experiment with\nshowing agents the cost of their computation and giving them the ability to\ncontrol when they use compute. We conduct our experiments on the Arcade\nLearning Environment, and our results demonstrate that with the same training\ncompute budget, agents that reason about their compute perform better on 75% of\ngames. Furthermore, these agents use three times less compute on average. We\nanalyze individual games and show where agents gain these efficiencies.",
    "categories": [
      "cs.AI",
      "cs.LG"
    ],
    "published": "2025-10-26T21:01:30Z",
    "authors": [
      "Adrian Orenstein",
      "Jessica Chen",
      "Gwyneth Anne Delos Santos",
      "Bayley Sapara",
      "Michael Bowling"
    ],
    "pdf_url": "http://arxiv.org/pdf/2510.22833v1"
  },
  {
    "id": "2510.22832v1",
    "title": "HRM-Agent: Training a recurrent reasoning model in dynamic environments\n  using reinforcement learning",
    "abstract": "The Hierarchical Reasoning Model (HRM) has impressive reasoning abilities\ngiven its small size, but has only been applied to supervised, static,\nfully-observable problems. One of HRM's strengths is its ability to adapt its\ncomputational effort to the difficulty of the problem. However, in its current\nform it cannot integrate and reuse computation from previous time-steps if the\nproblem is dynamic, uncertain or partially observable, or be applied where the\ncorrect action is undefined, characteristics of many real-world problems.\n  This paper presents HRM-Agent, a variant of HRM trained using only\nreinforcement learning. We show that HRM can learn to navigate to goals in\ndynamic and uncertain maze environments. Recent work suggests that HRM's\nreasoning abilities stem from its recurrent inference process. We explore the\ndynamics of the recurrent inference process and find evidence that it is\nsuccessfully reusing computation from earlier environment time-steps.",
    "categories": [
      "cs.AI",
      "cs.LG",
      "stat.ML",
      "68T07 (Primary) 62M45, 37N99 (Secondary)",
      "I.2.6; I.2.8"
    ],
    "published": "2025-10-26T21:01:04Z",
    "authors": [
      "Long H Dang",
      "David Rawlinson"
    ],
    "pdf_url": "http://arxiv.org/pdf/2510.22832v1"
  },
  {
    "id": "2510.22830v2",
    "title": "Exploration of Summarization by Generative Language Models for Automated\n  Scoring of Long Essays",
    "abstract": "BERT and its variants are extensively explored for automated scoring.\nHowever, a limit of 512 tokens for these encoder-based models showed the\ndeficiency in automated scoring of long essays. Thus, this research explores\ngenerative language models for automated scoring of long essays via\nsummarization and prompting. The results revealed great improvement of scoring\naccuracy with QWK increased from 0.822 to 0.8878 for the Learning Agency Lab\nAutomated Essay Scoring 2.0 dataset.",
    "categories": [
      "cs.CL",
      "cs.LG"
    ],
    "published": "2025-10-26T20:59:22Z",
    "authors": [
      "Haowei Hua",
      "Hong Jiao",
      "Xinyi Wang"
    ],
    "pdf_url": "http://arxiv.org/pdf/2510.22830v2"
  },
  {
    "id": "2510.22827v1",
    "title": "FairJudge: MLLM Judging for Social Attributes and Prompt Image Alignment",
    "abstract": "Text-to-image (T2I) systems lack simple, reproducible ways to evaluate how\nwell images match prompts and how models treat social attributes. Common\nproxies -- face classifiers and contrastive similarity -- reward surface cues,\nlack calibrated abstention, and miss attributes only weakly visible (for\nexample, religion, culture, disability). We present FairJudge, a lightweight\nprotocol that treats instruction-following multimodal LLMs as fair judges. It\nscores alignment with an explanation-oriented rubric mapped to [-1, 1];\nconstrains judgments to a closed label set; requires evidence grounded in the\nvisible content; and mandates abstention when cues are insufficient. Unlike\nCLIP-only pipelines, FairJudge yields accountable, evidence-aware decisions;\nunlike mitigation that alters generators, it targets evaluation fairness. We\nevaluate gender, race, and age on FairFace, PaTA, and FairCoT; extend to\nreligion, culture, and disability; and assess profession correctness and\nalignment on IdenProf, FairCoT-Professions, and our new DIVERSIFY-Professions.\nWe also release DIVERSIFY, a 469-image corpus of diverse, non-iconic scenes.\nAcross datasets, judge models outperform contrastive and face-centric baselines\non demographic prediction and improve mean alignment while maintaining high\nprofession accuracy, enabling more reliable, reproducible fairness audits.",
    "categories": [
      "cs.CV",
      "cs.LG"
    ],
    "published": "2025-10-26T20:43:48Z",
    "authors": [
      "Zahraa Al Sahili",
      "Maryam Fetanat",
      "Maimuna Nowaz",
      "Ioannis Patras",
      "Matthew Purver"
    ],
    "pdf_url": "http://arxiv.org/pdf/2510.22827v1"
  },
  {
    "id": "2510.22824v1",
    "title": "Logical GANs: Adversarial Learning through Ehrenfeucht Fraisse Games",
    "abstract": "GANs promise indistinguishability, logic explains it. We put the two on a\nbudget: a discriminator that can only ``see'' up to a logical depth $k$, and a\ngenerator that must look correct to that bounded observer. \\textbf{LOGAN}\n(LOGical GANs) casts the discriminator as a depth-$k$ Ehrenfeucht--Fra\\\"iss\\'e\n(EF) \\emph{Opponent} that searches for small, legible faults (odd cycles,\nnonplanar crossings, directed bridges), while the generator plays\n\\emph{Builder}, producing samples that admit a $k$-round matching to a target\ntheory $T$. We ship a minimal toolkit -- an EF-probe simulator and MSO-style\ngraph checkers -- and four experiments including real neural GAN training with\nPyTorch. Beyond verification, we score samples with a \\emph{logical loss} that\nmixes budgeted EF round-resilience with cheap certificate terms, enabling a\npractical curriculum on depth. Framework validation demonstrates $92\\%$--$98\\%$\nproperty satisfaction via simulation (Exp.~3), while real neural GAN training\nachieves $5\\%$--$14\\%$ improvements on challenging properties and $98\\%$\nsatisfaction on connectivity (matching simulation) through adversarial learning\n(Exp.~4). LOGAN is a compact, reproducible path toward logic-bounded generation\nwith interpretable failures, proven effectiveness (both simulated and real\ntraining), and dials for control.",
    "categories": [
      "cs.LG",
      "cs.LO",
      "math.LO"
    ],
    "published": "2025-10-26T20:34:00Z",
    "authors": [
      "Mirco A. Mannucci"
    ],
    "pdf_url": "http://arxiv.org/pdf/2510.22824v1"
  },
  {
    "id": "2510.22819v1",
    "title": "Last Iterate Analyses of FTRL in Stochasitc Bandits",
    "abstract": "The convergence analysis of online learning algorithms is central to machine\nlearning theory, where last-iterate convergence is particularly important, as\nit captures the learner's actual decisions and describes the evolution of the\nlearning process over time. However, in multi-armed bandits, most existing\nalgorithmic analyses mainly focus on the order of regret, while the\nlast-iterate (simple regret) convergence rate remains less explored --\nespecially for the widely studied Follow-the-Regularized-Leader (FTRL)\nalgorithms. Recently, a growing line of work has established the\nBest-of-Both-Worlds (BOBW) property of FTRL algorithms in bandit problems,\nshowing in particular that they achieve logarithmic regret in stochastic\nbandits. Nevertheless, their last-iterate convergence rate has not yet been\nstudied. Intuitively, logarithmic regret should correspond to a $t^{-1}$\nlast-iterate convergence rate. This paper partially confirms this intuition\nthrough theoretical analysis, showing that the Bregman divergence, defined by\nthe regular function $\\Psi(p)=-4\\sum_{i=1}^{d}\\sqrt{p_i}$ associated with the\nBOBW FTRL algorithm $1/2$-Tsallis-INF (arXiv:1807.07623), between the point\nmass on the optimal arm and the probability distribution over the arm set\nobtained at iteration $t$, decays at a rate of $t^{-1/2}$.",
    "categories": [
      "cs.LG"
    ],
    "published": "2025-10-26T20:20:10Z",
    "authors": [
      "Jingxin Zhan",
      "Yuze Han",
      "Zhihua Zhang"
    ],
    "pdf_url": "http://arxiv.org/pdf/2510.22819v1"
  },
  {
    "id": "2510.22818v1",
    "title": "Air Quality Prediction Using LOESS-ARIMA and Multi-Scale CNN-BiLSTM with\n  Residual-Gated Attention",
    "abstract": "Air pollution remains a critical environmental and public health concern in\nIndian megacities such as Delhi, Kolkata, and Mumbai, where sudden spikes in\npollutant levels challenge timely intervention. Accurate Air Quality Index\n(AQI) forecasting is difficult due to the coexistence of linear trends,\nseasonal variations, and volatile nonlinear patterns. This paper proposes a\nhybrid forecasting framework that integrates LOESS decomposition, ARIMA\nmodeling, and a multi-scale CNN-BiLSTM network with a residual-gated attention\nmechanism. The LOESS step separates the AQI series into trend, seasonal, and\nresidual components, with ARIMA modeling the smooth components and the proposed\ndeep learning module capturing multi-scale volatility in the residuals. Model\nhyperparameters are tuned via the Unified Adaptive Multi-Stage Metaheuristic\nOptimizer (UAMMO), combining multiple optimization strategies for efficient\nconvergence. Experiments on 2021-2023 AQI datasets from the Central Pollution\nControl Board show that the proposed method consistently outperforms\nstatistical, deep learning, and hybrid baselines across PM2.5, O3, CO, and NOx\nin three major cities, achieving up to 5-8% lower MSE and higher R^2 scores\n(>0.94) for all pollutants. These results demonstrate the framework's\nrobustness, sensitivity to sudden pollution events, and applicability to urban\nair quality management.",
    "categories": [
      "cs.LG",
      "cs.AI",
      "68T07, 68U35",
      "I.2.7; I.5.4; C.3"
    ],
    "published": "2025-10-26T20:18:30Z",
    "authors": [
      "Soham Pahari",
      "Sandeep Chand Kumain"
    ],
    "pdf_url": "http://arxiv.org/pdf/2510.22818v1"
  },
  {
    "id": "2510.22811v1",
    "title": "Distributed Multi-Agent Bandits Over Erd\u0151s-R\u00e9nyi Random Networks",
    "abstract": "We study the distributed multi-agent multi-armed bandit problem with\nheterogeneous rewards over random communication graphs. Uniquely, at each time\nstep $t$ agents communicate over a time-varying random graph $G_t$ generated by\napplying the Erd\\H{o}s-R\\'enyi model to a fixed connected base graph $G$ (for\nclassical Erd\\H{o}s-R\\'enyi graphs, $G$ is a complete graph), where each\npotential edge in $G$ is randomly and independently present with the link\nprobability $p$. Notably, the resulting random graph is not necessarily\nconnected at each time step. Each agent's arm rewards follow time-invariant\ndistributions, and the reward distribution for the same arm may differ across\nagents. The goal is to minimize the cumulative expected regret relative to the\nglobal mean reward of each arm, defined as the average of that arm's mean\nrewards across all agents. To this end, we propose a fully distributed\nalgorithm that integrates the arm elimination strategy with the random gossip\nalgorithm. We theoretically show that the regret upper bound is of order $\\log\nT$ and is highly interpretable, where $T$ is the time horizon. It includes the\noptimal centralized regret $O\\left(\\sum_{k: \\Delta_k>0} \\frac{\\log\nT}{\\Delta_k}\\right)$ and an additional term $O\\left(\\frac{N^2 \\log T}{p\n\\lambda_{N-1}(Lap(G))} + \\frac{KN^2 \\log T}{p}\\right)$ where $N$ and $K$ denote\nthe total number of agents and arms, respectively. This term reflects the\nimpact of $G$'s algebraic connectivity $\\lambda_{N-1}(Lap(G))$ and the link\nprobability $p$, and thus highlights a fundamental trade-off between\ncommunication efficiency and regret. As a by-product, we show a nearly optimal\nregret lower bound. Finally, our numerical experiments not only show the\nsuperiority of our algorithm over existing benchmarks, but also validate the\ntheoretical regret scaling with problem complexity.",
    "categories": [
      "cs.LG"
    ],
    "published": "2025-10-26T19:53:52Z",
    "authors": [
      "Jingyuan Liu",
      "Hao Qiu",
      "Lin Yang",
      "Mengfan Xu"
    ],
    "pdf_url": "http://arxiv.org/pdf/2510.22811v1"
  },
  {
    "id": "2510.22809v1",
    "title": "A Theory of the Mechanics of Information: Generalization Through\n  Measurement of Uncertainty (Learning is Measuring)",
    "abstract": "Traditional machine learning relies on explicit models and domain\nassumptions, limiting flexibility and interpretability. We introduce a\nmodel-free framework using surprisal (information theoretic uncertainty) to\ndirectly analyze and perform inferences from raw data, eliminating distribution\nmodeling, reducing bias, and enabling efficient updates including direct edits\nand deletion of training data. By quantifying relevance through uncertainty,\nthe approach enables generalizable inference across tasks including generative\ninference, causal discovery, anomaly detection, and time series forecasting. It\nemphasizes traceability, interpretability, and data-driven decision making,\noffering a unified, human-understandable framework for machine learning, and\nachieves at or near state-of-the-art performance across most common machine\nlearning tasks. The mathematical foundations create a ``physics'' of\ninformation, which enable these techniques to apply effectively to a wide\nvariety of complex data types, including missing data. Empirical results\nindicate that this may be a viable alternative path to neural networks with\nregard to scalable machine learning and artificial intelligence that can\nmaintain human understandability of the underlying mechanics.",
    "categories": [
      "cs.LG",
      "cs.AI",
      "math.ST",
      "stat.ML",
      "stat.TH"
    ],
    "published": "2025-10-26T19:45:25Z",
    "authors": [
      "Christopher J. Hazard",
      "Michael Resnick",
      "Jacob Beel",
      "Jack Xia",
      "Cade Mack",
      "Dominic Glennie",
      "Matthew Fulp",
      "David Maze",
      "Andrew Bassett",
      "Martin Koistinen"
    ],
    "pdf_url": "http://arxiv.org/pdf/2510.22809v1"
  },
  {
    "id": "2510.22799v1",
    "title": "Inductive Transfer Learning for Graph-Based Recommenders",
    "abstract": "Graph-based recommender systems are commonly trained in transductive\nsettings, which limits their applicability to new users, items, or datasets. We\npropose NBF-Rec, a graph-based recommendation model that supports inductive\ntransfer learning across datasets with disjoint user and item sets. Unlike\nconventional embedding-based methods that require retraining for each domain,\nNBF-Rec computes node embeddings dynamically at inference time. We evaluate the\nmethod on seven real-world datasets spanning movies, music, e-commerce, and\nlocation check-ins. NBF-Rec achieves competitive performance in zero-shot\nsettings, where no target domain data is used for training, and demonstrates\nfurther improvements through lightweight fine-tuning. These results show that\ninductive transfer is feasible in graph-based recommendation and that\ninteraction-level message passing supports generalization across datasets\nwithout requiring aligned users or items.",
    "categories": [
      "cs.LG"
    ],
    "published": "2025-10-26T19:07:41Z",
    "authors": [
      "Florian Gr\u00f6tschla",
      "Elia Trachsel",
      "Luca A. Lanzend\u00f6rfer",
      "Roger Wattenhofer"
    ],
    "pdf_url": "http://arxiv.org/pdf/2510.22799v1"
  },
  {
    "id": "2510.22798v1",
    "title": "VEHME: A Vision-Language Model For Evaluating Handwritten Mathematics\n  Expressions",
    "abstract": "Automatically assessing handwritten mathematical solutions is an important\nproblem in educational technology with practical applications, but it remains a\nsignificant challenge due to the diverse formats, unstructured layouts, and\nsymbolic complexity of student work. To address this challenge, we introduce\nVEHME-a Vision-Language Model for Evaluating Handwritten Mathematics\nExpressions-designed to assess open-form handwritten math responses with high\naccuracy and interpretable reasoning traces. VEHME integrates a two-phase\ntraining pipeline: (i) supervised fine-tuning using structured reasoning data,\nand (ii) reinforcement learning that aligns model outputs with\nmulti-dimensional grading objectives, including correctness, reasoning depth,\nand error localization. To enhance spatial understanding, we propose an\nExpression-Aware Visual Prompting Module, trained on our synthesized multi-line\nmath expressions dataset to robustly guide attention in visually heterogeneous\ninputs. Evaluated on AIHub and FERMAT datasets, VEHME achieves state-of-the-art\nperformance among open-source models and approaches the accuracy of proprietary\nsystems, demonstrating its potential as a scalable and accessible tool for\nautomated math assessment. Our training and experiment code is publicly\navailable at our GitHub repository.",
    "categories": [
      "cs.CL",
      "cs.LG"
    ],
    "published": "2025-10-26T19:03:27Z",
    "authors": [
      "Thu Phuong Nguyen",
      "Duc M. Nguyen",
      "Hyotaek Jeon",
      "Hyunwook Lee",
      "Hyunmin Song",
      "Sungahn Ko",
      "Taehwan Kim"
    ],
    "pdf_url": "http://arxiv.org/pdf/2510.22798v1"
  },
  {
    "id": "2510.22795v1",
    "title": "SAO-Instruct: Free-form Audio Editing using Natural Language\n  Instructions",
    "abstract": "Generative models have made significant progress in synthesizing\nhigh-fidelity audio from short textual descriptions. However, editing existing\naudio using natural language has remained largely underexplored. Current\napproaches either require the complete description of the edited audio or are\nconstrained to predefined edit instructions that lack flexibility. In this\nwork, we introduce SAO-Instruct, a model based on Stable Audio Open capable of\nediting audio clips using any free-form natural language instruction. To train\nour model, we create a dataset of audio editing triplets (input audio, edit\ninstruction, output audio) using Prompt-to-Prompt, DDPM inversion, and a manual\nediting pipeline. Although partially trained on synthetic data, our model\ngeneralizes well to real in-the-wild audio clips and unseen edit instructions.\nWe demonstrate that SAO-Instruct achieves competitive performance on objective\nmetrics and outperforms other audio editing approaches in a subjective\nlistening study. To encourage future research, we release our code and model\nweights.",
    "categories": [
      "cs.SD",
      "cs.LG"
    ],
    "published": "2025-10-26T18:57:16Z",
    "authors": [
      "Michael Ungersb\u00f6ck",
      "Florian Gr\u00f6tschla",
      "Luca A. Lanzend\u00f6rfer",
      "June Young Yi",
      "Changho Choi",
      "Roger Wattenhofer"
    ],
    "pdf_url": "http://arxiv.org/pdf/2510.22795v1"
  },
  {
    "id": "2510.22778v1",
    "title": "A Free Probabilistic Framework for Denoising Diffusion Models: Entropy,\n  Transport, and Reverse Processes",
    "abstract": "This work develops a rigorous framework for diffusion-based generative\nmodeling in the setting of free probability. We extend classical denoising\ndiffusion probabilistic models to free diffusion processes -- stochastic\ndynamics acting on noncommutative random variables whose spectral measures\nevolve by free additive convolution. The forward dynamics satisfy a free\nFokker--Planck equation that increases Voiculescu's free entropy and dissipates\nfree Fisher information, providing a noncommutative analogue of the classical\nde Bruijn identity. Using tools from free stochastic analysis, including a free\nMalliavin calculus and a Clark--Ocone representation, we derive the\nreverse-time stochastic differential equation driven by the conjugate variable,\nthe free analogue of the score function. We further develop a variational\nformulation of these flows in the free Wasserstein space, showing that the\nresulting gradient-flow structure converges to the semicircular equilibrium\nlaw. Together, these results connect modern diffusion models with the\ninformation geometry of free entropy and establish a mathematical foundation\nfor generative modeling with operator-valued or high-dimensional structured\ndata.",
    "categories": [
      "math.PR",
      "cs.LG",
      "stat.ML"
    ],
    "published": "2025-10-26T18:03:54Z",
    "authors": [
      "Swagatam Das"
    ],
    "pdf_url": "http://arxiv.org/pdf/2510.22778v1"
  },
  {
    "id": "2510.22777v2",
    "title": "SeeDNorm: Self-Rescaled Dynamic Normalization",
    "abstract": "Normalization layer constitutes an essential component in neural networks. In\ntransformers, the predominantly used RMSNorm constrains vectors to a unit\nhypersphere, followed by dimension-wise rescaling through a learnable scaling\ncoefficient $\\gamma$ to maintain the representational capacity of the model.\nHowever, RMSNorm discards the input norm information in forward pass and a\nstatic scaling factor $\\gamma$ may be insufficient to accommodate the wide\nvariability of input data and distributional shifts, thereby limiting further\nperformance improvements, particularly in zero-shot scenarios that large\nlanguage models routinely encounter. To address this limitation, we propose\nSeeDNorm, which enhances the representational capability of the model by\ndynamically adjusting the scaling coefficient based on the current input,\nthereby preserving the input norm information and enabling data-dependent,\nself-rescaled dynamic normalization. During backpropagation, SeeDNorm retains\nthe ability of RMSNorm to dynamically adjust gradient according to the input\nnorm. We provide a detailed analysis of the training optimization for SeedNorm\nand proposed corresponding solutions to address potential instability issues\nthat may arise when applying SeeDNorm. We validate the effectiveness of\nSeeDNorm across models of varying sizes in large language model pre-training as\nwell as supervised and unsupervised computer vision tasks. By introducing a\nminimal number of parameters and with neglligible impact on model efficiency,\nSeeDNorm achieves consistently superior performance compared to previously\ncommonly used normalization layers such as RMSNorm and LayerNorm, as well as\nelement-wise activation alternatives to normalization layers like DyT.",
    "categories": [
      "cs.LG"
    ],
    "published": "2025-10-26T18:01:32Z",
    "authors": [
      "Wenrui Cai",
      "Defa Zhu",
      "Qingjie Liu",
      "Qiyang Min"
    ],
    "pdf_url": "http://arxiv.org/pdf/2510.22777v2"
  },
  {
    "id": "2510.22767v1",
    "title": "TELL-TALE: Task Efficient LLMs with Task Aware Layer Elimination",
    "abstract": "In this paper we introduce Tale, Task-Aware Layer Elimination, an\ninference-time algorithm that prunes entire transformer layers in an LLM by\ndirectly optimizing task-specific validation performance. We evaluate TALE on 9\ntasks and 5 models, including LLaMA 3.1 8B, Qwen 2.5 7B, Qwen 2.5 0.5B, Mistral\n7B, and Lucie 7B, under both zero-shot and few-shot settings. Unlike prior\napproaches, TALE requires no retraining and consistently improves accuracy\nwhile reducing computational cost across all benchmarks. Furthermore, applying\nTALE during finetuning leads to additional performance gains. Finally, TALE\nprovides flexible user control over trade-offs between accuracy and efficiency.\nMutual information analysis shows that certain layers act as bottlenecks,\ndegrading task-relevant representations. Tale's selective layer removal\nremedies this problem, producing smaller, faster, and more accurate models that\nare also faster to fine-tune while offering new insights into transformer\ninterpretability.",
    "categories": [
      "cs.LG",
      "cs.CL"
    ],
    "published": "2025-10-26T17:34:40Z",
    "authors": [
      "Omar Naim",
      "Krish Sharma",
      "Nicholas Asher"
    ],
    "pdf_url": "http://arxiv.org/pdf/2510.22767v1"
  },
  {
    "id": "2510.22757v1",
    "title": "Distributionally Robust Optimization via Diffusion Ambiguity Modeling",
    "abstract": "This paper studies Distributionally Robust Optimization (DRO), a fundamental\nframework for enhancing the robustness and generalization of statistical\nlearning and optimization. An effective ambiguity set for DRO must involve\ndistributions that remain consistent with the nominal distribution while being\ndiverse enough to account for a variety of potential scenarios. Moreover, it\nshould lead to tractable DRO solutions. To this end, we propose a\ndiffusion-based ambiguity set design that captures various adversarial\ndistributions beyond the nominal support space while maintaining consistency\nwith the nominal distribution. Building on this ambiguity modeling, we propose\nDiffusion-based DRO (D-DRO), a tractable DRO algorithm that solves the inner\nmaximization over the parameterized diffusion model space. We formally\nestablish the stationary convergence performance of D-DRO and empirically\ndemonstrate its superior Out-of-Distribution (OOD) generalization performance\nin a ML prediction task.",
    "categories": [
      "cs.LG"
    ],
    "published": "2025-10-26T17:11:50Z",
    "authors": [
      "Jiaqi Wen",
      "Jianyi Yang"
    ],
    "pdf_url": "http://arxiv.org/pdf/2510.22757v1"
  },
  {
    "id": "2510.22744v1",
    "title": "OEUVRE: OnlinE Unbiased Variance-Reduced loss Estimation",
    "abstract": "Online learning algorithms continually update their models as data arrive,\nmaking it essential to accurately estimate the expected loss at the current\ntime step. The prequential method is an effective estimation approach which can\nbe practically deployed in various ways. However, theoretical guarantees have\npreviously been established under strong conditions on the algorithm, and\npractical algorithms have hyperparameters which require careful tuning. We\nintroduce OEUVRE, an estimator that evaluates each incoming sample on the\nfunction learned at the current and previous time steps, recursively updating\nthe loss estimate in constant time and memory. We use algorithmic stability, a\nproperty satisfied by many popular online learners, for optimal updates and\nprove consistency, convergence rates, and concentration bounds for our\nestimator. We design a method to adaptively tune OEUVRE's hyperparameters and\ntest it across diverse online and stochastic tasks. We observe that OEUVRE\nmatches or outperforms other estimators even when their hyperparameters are\ntuned with oracle access to ground truth.",
    "categories": [
      "stat.ML",
      "cs.LG"
    ],
    "published": "2025-10-26T16:41:17Z",
    "authors": [
      "Kanad Pardeshi",
      "Bryan Wilder",
      "Aarti Singh"
    ],
    "pdf_url": "http://arxiv.org/pdf/2510.22744v1"
  },
  {
    "id": "2510.22734v1",
    "title": "Centrum: Model-based Database Auto-tuning with Minimal Distributional\n  Assumptions",
    "abstract": "Gaussian-Process-based Bayesian optimization (GP-BO), is a prevailing\nmodel-based framework for DBMS auto-tuning. However, recent work shows\nGP-BO-based DBMS auto-tuners significantly outperformed auto-tuners based on\nSMAC, which features random forest surrogate models; such results motivate us\nto rethink and investigate the limitations of GP-BO in auto-tuner design. We\nfind the fundamental assumptions of GP-BO are widely violated when modeling and\noptimizing DBMS performance, while tree-ensemble-BOs (e.g., SMAC) can avoid the\nassumption pitfalls and deliver improved tuning efficiency and effectiveness.\nMoreover, we argue that existing tree-ensemble-BOs restrict further advancement\nin DBMS auto-tuning. First, existing tree-ensemble-BOs can only achieve\ndistribution-free point estimates, but still impose unrealistic distributional\nassumptions on uncertainty estimates, compromising surrogate modeling and\ndistort the acquisition function. Second, recent advances in gradient boosting,\nwhich can further enhance surrogate modeling against vanilla GP and random\nforest counterparts, have rarely been applied in optimizing DBMS auto-tuners.\nTo address these issues, we propose a novel model-based DBMS auto-tuner,\nCentrum. Centrum improves distribution-free point and interval estimation in\nsurrogate modeling with a two-phase learning procedure of stochastic gradient\nboosting ensembles. Moreover, Centrum adopts a generalized SGBE-estimated\nlocally-adaptive conformal prediction to facilitate a distribution-free\nuncertainty estimation and acquisition function. To our knowledge, Centrum is\nthe first auto-tuner to realize distribution-freeness, enhancing BO's\npracticality in DBMS auto-tuning, and the first to seamlessly fuse gradient\nboosting ensembles and conformal inference in BO. Extensive physical and\nsimulation experiments on two DBMSs and three workloads show Centrum\noutperforms 21 SOTA methods.",
    "categories": [
      "cs.LG",
      "cs.DB",
      "stat.ME"
    ],
    "published": "2025-10-26T16:08:15Z",
    "authors": [
      "Yuanhao Lai",
      "Pengfei Zheng",
      "Chenpeng Ji",
      "Yan Li",
      "Songhan Zhang",
      "Rutao Zhang",
      "Zhengang Wang",
      "Yunfei Du"
    ],
    "pdf_url": "http://arxiv.org/pdf/2510.22734v1"
  },
  {
    "id": "2510.22732v1",
    "title": "ATLAS: Actor-Critic Task-Completion with Look-ahead Action Simulation",
    "abstract": "We observe that current state-of-the-art web-agents are unable to effectively\nadapt to new environments without neural network fine-tuning, without which\nthey produce inefficient execution plans due to a lack of awareness of the\nstructure and dynamics of the new environment. To address this limitation, we\nintroduce ATLAS (Actor-Critic Task-completion with Look-ahead Action\nSimulation), a memory-augmented agent that is able to make plans grounded in a\nmodel of the environment by simulating the consequences of those actions in\ncognitive space. Our agent starts by building a \"cognitive map\" by performing a\nlightweight curiosity driven exploration of the environment. The planner\nproposes candidate actions; the simulator predicts their consequences in\ncognitive space; a critic analyzes the options to select the best roll-out and\nupdate the original plan; and a browser executor performs the chosen action. On\nthe WebArena-Lite Benchmark, we achieve a 63% success rate compared to 53.9%\nsuccess rate for the previously published state-of-the-art. Unlike previous\nsystems, our modular architecture requires no website-specific LLM fine-tuning.\nAblations show sizable drops without the world-model, hierarchical planner, and\nlook-ahead-based replanner confirming their complementary roles within the\ndesign of our system",
    "categories": [
      "cs.LG",
      "cs.AI",
      "cs.CL",
      "cs.IR",
      "cs.MA",
      "cs.RO"
    ],
    "published": "2025-10-26T16:03:39Z",
    "authors": [
      "Jiali Cheng",
      "Anjishnu Kumar",
      "Roshan Lal",
      "Rishi Rajasekaran",
      "Hani Ramezani",
      "Omar Zia Khan",
      "Oleg Rokhlenko",
      "Sunny Chiu-Webster",
      "Gang Hua",
      "Hadi Amiri"
    ],
    "pdf_url": "http://arxiv.org/pdf/2510.22732v1"
  },
  {
    "id": "2510.22728v1",
    "title": "S-Chain: Structured Visual Chain-of-Thought For Medicine",
    "abstract": "Faithful reasoning in medical vision-language models (VLMs) requires not only\naccurate predictions but also transparent alignment between textual rationales\nand visual evidence. While Chain-of-Thought (CoT) prompting has shown promise\nin medical visual question answering (VQA), no large-scale expert-level dataset\nhas captured stepwise reasoning with precise visual grounding. We introduce\nS-Chain, the first large-scale dataset of 12,000 expert-annotated medical\nimages with bounding boxes and structured visual CoT (SV-CoT), explicitly\nlinking visual regions to reasoning steps. The dataset further supports 16\nlanguages, totaling over 700k VQA pairs for broad multilingual applicability.\nUsing S-Chain, we benchmark state-of-the-art medical VLMs (ExGra-Med,\nLLaVA-Med) and general-purpose VLMs (Qwen2.5-VL, InternVL2.5), showing that\nSV-CoT supervision significantly improves interpretability, grounding fidelity,\nand robustness. Beyond benchmarking, we study its synergy with\nretrieval-augmented generation, revealing how domain knowledge and visual\ngrounding interact during autoregressive reasoning. Finally, we propose a new\nmechanism that strengthens the alignment between visual evidence and reasoning,\nimproving both reliability and efficiency. S-Chain establishes a new benchmark\nfor grounded medical reasoning and paves the way toward more trustworthy and\nexplainable medical VLMs.",
    "categories": [
      "cs.LG",
      "cs.CV"
    ],
    "published": "2025-10-26T15:57:14Z",
    "authors": [
      "Khai Le-Duc",
      "Duy M. H. Nguyen",
      "Phuong T. H. Trinh",
      "Tien-Phat Nguyen",
      "Nghiem T. Diep",
      "An Ngo",
      "Tung Vu",
      "Trinh Vuong",
      "Anh-Tien Nguyen",
      "Mau Nguyen",
      "Van Trung Hoang",
      "Khai-Nguyen Nguyen",
      "Hy Nguyen",
      "Chris Ngo",
      "Anji Liu",
      "Nhat Ho",
      "Anne-Christin Hauschild",
      "Khanh Xuan Nguyen",
      "Thanh Nguyen-Tang",
      "Pengtao Xie",
      "Daniel Sonntag",
      "James Zou",
      "Mathias Niepert",
      "Anh Totti Nguyen"
    ],
    "pdf_url": "http://arxiv.org/pdf/2510.22728v1"
  },
  {
    "id": "2510.23668v1",
    "title": "Traffic flow forecasting, STL decomposition, Hybrid model, LSTM, ARIMA,\n  XGBoost, Intelligent transportation systems",
    "abstract": "Accurate traffic flow forecasting is essential for intelligent transportation\nsystems and urban traffic management. However, single model approaches often\nfail to capture the complex, nonlinear, and multi scale temporal patterns in\ntraffic flow data. This study proposes a decomposition driven hybrid framework\nthat integrates Seasonal Trend decomposition using Loess (STL) with three\ncomplementary predictive models. STL first decomposes the original time series\ninto trend, seasonal, and residual components. Then, a Long Short Term Memory\n(LSTM) network models long term trends, an Autoregressive Integrated Moving\nAverage (ARIMA) model captures seasonal periodicity, and an Extreme Gradient\nBoosting (XGBoost) algorithm predicts nonlinear residual fluctuations. The\nfinal forecast is obtained through multiplicative integration of the sub model\npredictions. Using 998 traffic flow records from a New York City intersection\nbetween November and December 2015, results show that the LSTM ARIMA XGBoost\nhybrid model significantly outperforms standalone models including LSTM, ARIMA,\nand XGBoost across MAE, RMSE, and R squared metrics. The decomposition strategy\neffectively isolates temporal characteristics, allowing each model to\nspecialize, thereby improving prediction accuracy, interpretability, and\nrobustness.",
    "categories": [
      "cs.LG",
      "cs.AI"
    ],
    "published": "2025-10-26T15:54:48Z",
    "authors": [
      "Fujiang Yuan",
      "Yangrui Fan",
      "Xiaohuan Bing",
      "Zhen Tian",
      "Chunhong Yuan",
      "Yankang Li"
    ],
    "pdf_url": "http://arxiv.org/pdf/2510.23668v1"
  },
  {
    "id": "2510.22724v1",
    "title": "Scalable Neural Decoders for Practical Real-Time Quantum Error\n  Correction",
    "abstract": "Real-time, scalable, and accurate decoding is a critical component for\nrealizing a fault-tolerant quantum computer. While Transformer-based neural\ndecoders such as \\textit{AlphaQubit} have demonstrated high accuracy, the\ncomputational complexity of their core attention mechanism, which scales as\n$\\mathcal{O}(d^4)$ with code distance $d$, results in decoding speeds\ninsufficient for practical real-time applications. In this work, we introduce\nand evaluate a \\textit{Mamba}-based decoder, a state-space model with\n$\\mathcal{O}(d^2)$ complexity. In memory experiments using Sycamore hardware\ndata, our Mamba decoder matches the performance of its Transformer-based\ncounterpart, providing that its superior efficiency does not come at the cost\nof performance. Crucially, in simulated real-time scenarios that account for\ndecoder-induced noise, the Mamba decoder significantly outperforms the\nTransformer, exhibiting a higher error threshold of $0.0104$ compared to\n$0.0097$. These results demonstrate that Mamba decoders offer a compelling\nbalance between speed and accuracy, making them a promising architecture for\nscalable, real-time quantum error correction.",
    "categories": [
      "quant-ph",
      "cs.LG"
    ],
    "published": "2025-10-26T15:49:46Z",
    "authors": [
      "Changwon Lee",
      "Tak Hur",
      "Daniel K. Park"
    ],
    "pdf_url": "http://arxiv.org/pdf/2510.22724v1"
  },
  {
    "id": "2510.23667v1",
    "title": "Optimize Any Topology: A Foundation Model for Shape- and Resolution-Free\n  Structural Topology Optimization",
    "abstract": "Structural topology optimization (TO) is central to engineering design but\nremains computationally intensive due to complex physics and hard constraints.\nExisting deep-learning methods are limited to fixed square grids, a few\nhand-coded boundary conditions, and post-hoc optimization, preventing general\ndeployment. We introduce Optimize Any Topology (OAT), a foundation-model\nframework that directly predicts minimum-compliance layouts for arbitrary\naspect ratios, resolutions, volume fractions, loads, and fixtures. OAT combines\na resolution- and shape-agnostic autoencoder with an implicit neural-field\ndecoder and a conditional latent-diffusion model trained on OpenTO, a new\ncorpus of 2.2 million optimized structures covering 2 million unique\nboundary-condition configurations. On four public benchmarks and two\nchallenging unseen tests, OAT lowers mean compliance up to 90% relative to the\nbest prior models and delivers sub-1 second inference on a single GPU across\nresolutions from 64 x 64 to 256 x 256 and aspect ratios as high as 10:1. These\nresults establish OAT as a general, fast, and resolution-free framework for\nphysics-aware topology optimization and provide a large-scale dataset to spur\nfurther research in generative modeling for inverse design. Code & data can be\nfound at https://github.com/ahnobari/OptimizeAnyTopology.",
    "categories": [
      "cs.LG",
      "cs.AI",
      "cs.CE"
    ],
    "published": "2025-10-26T15:11:54Z",
    "authors": [
      "Amin Heyrani Nobari",
      "Lyle Regenwetter",
      "Cyril Picard",
      "Ligong Han",
      "Faez Ahmed"
    ],
    "pdf_url": "http://arxiv.org/pdf/2510.23667v1"
  },
  {
    "id": "2510.22711v1",
    "title": "Identification of Causal Direction under an Arbitrary Number of Latent\n  Confounders",
    "abstract": "Recovering causal structure in the presence of latent variables is an\nimportant but challenging task. While many methods have been proposed to handle\nit, most of them require strict and/or untestable assumptions on the causal\nstructure. In real-world scenarios, observed variables may be affected by\nmultiple latent variables simultaneously, which, generally speaking, cannot be\nhandled by these methods. In this paper, we consider the linear, non-Gaussian\ncase, and make use of the joint higher-order cumulant matrix of the observed\nvariables constructed in a specific way. We show that, surprisingly, causal\nasymmetry between two observed variables can be directly seen from the rank\ndeficiency properties of such higher-order cumulant matrices, even in the\npresence of an arbitrary number of latent confounders. Identifiability results\nare established, and the corresponding identification methods do not even\ninvolve iterative procedures. Experimental results demonstrate the\neffectiveness and asymptotic correctness of our proposed method.",
    "categories": [
      "cs.LG",
      "stat.ML"
    ],
    "published": "2025-10-26T15:10:00Z",
    "authors": [
      "Wei Chen",
      "Linjun Peng",
      "Zhiyi Huang",
      "Haoyue Dai",
      "Zhifeng Hao",
      "Ruichu Cai",
      "Kun Zhang"
    ],
    "pdf_url": "http://arxiv.org/pdf/2510.22711v1"
  },
  {
    "id": "2510.23666v1",
    "title": "Beyond Normality: Reliable A/B Testing with Non-Gaussian Data",
    "abstract": "A/B testing has become the cornerstone of decision-making in online markets,\nguiding how platforms launch new features, optimize pricing strategies, and\nimprove user experience. In practice, we typically employ the pairwise $t$-test\nto compare outcomes between the treatment and control groups, thereby assessing\nthe effectiveness of a given strategy. To be trustworthy, these experiments\nmust keep Type I error (i.e., false positive rate) under control; otherwise, we\nmay launch harmful strategies. However, in real-world applications, we find\nthat A/B testing often fails to deliver reliable results. When the data\ndistribution departs from normality or when the treatment and control groups\ndiffer in sample size, the commonly used pairwise $t$-test is no longer\ntrustworthy. In this paper, we quantify how skewed, long tailed data and\nunequal allocation distort error rates and derive explicit formulas for the\nminimum sample size required for the $t$-test to remain valid. We find that\nmany online feedback metrics require hundreds of millions samples to ensure\nreliable A/B testing. Thus we introduce an Edgeworth-based correction that\nprovides more accurate $p$-values when the available sample size is limited.\nOffline experiments on a leading A/B testing platform corroborate the practical\nvalue of our theoretical minimum sample size thresholds and demonstrate that\nthe corrected method substantially improves the reliability of A/B testing in\nreal-world conditions.",
    "categories": [
      "stat.ML",
      "cs.LG",
      "stat.ME",
      "I.2.6; G.3; I.5.1"
    ],
    "published": "2025-10-26T14:44:19Z",
    "authors": [
      "Junpeng Gong",
      "Chunkai Wang",
      "Hao Li",
      "Jinyong Ma",
      "Haoxuan Li",
      "Xu He"
    ],
    "pdf_url": "http://arxiv.org/pdf/2510.23666v1"
  },
  {
    "id": "2510.22691v1",
    "title": "SALSA: Single-pass Autoregressive LLM Structured Classification",
    "abstract": "Despite their impressive generalization capabilities, instruction-tuned Large\nLanguage Models often underperform on text classification benchmarks. We\nintroduce SALSA, a coherent pipeline that combines structured prompting,\nclass-to-token mapping, and parameter-efficient fine-tuning, thereby avoiding\ncold-start training. Each class label is mapped to a distinct output token, and\nprompts are constructed to elicit a single-token response. During inference,\nthe model's output is projected only onto the logits of the relevant class\ntokens, enabling efficient and accurate classification in a single forward\npass. SALSA achieves state-of-the-art results across diverse benchmarks,\ndemonstrating its robustness and scalability for LLM-based classification\napplications.",
    "categories": [
      "cs.CL",
      "cs.LG"
    ],
    "published": "2025-10-26T14:28:42Z",
    "authors": [
      "Ruslan Berdichevsky",
      "Shai Nahum-Gefen",
      "Elad Ben Zaken"
    ],
    "pdf_url": "http://arxiv.org/pdf/2510.22691v1"
  },
  {
    "id": "2510.22686v1",
    "title": "FlowCritic: Bridging Value Estimation with Flow Matching in\n  Reinforcement Learning",
    "abstract": "Reliable value estimation serves as the cornerstone of reinforcement learning\n(RL) by evaluating long-term returns and guiding policy improvement,\nsignificantly influencing the convergence speed and final performance. Existing\nworks improve the reliability of value function estimation via multi-critic\nensembles and distributional RL, yet the former merely combines multi point\nestimation without capturing distributional information, whereas the latter\nrelies on discretization or quantile regression, limiting the expressiveness of\ncomplex value distributions. Inspired by flow matching's success in generative\nmodeling, we propose a generative paradigm for value estimation, named\nFlowCritic. Departing from conventional regression for deterministic value\nprediction, FlowCritic leverages flow matching to model value distributions and\ngenerate samples for value estimation.",
    "categories": [
      "cs.LG",
      "cs.AI"
    ],
    "published": "2025-10-26T14:12:32Z",
    "authors": [
      "Shan Zhong",
      "Shutong Ding",
      "He Diao",
      "Xiangyu Wang",
      "Kah Chan Teh",
      "Bei Peng"
    ],
    "pdf_url": "http://arxiv.org/pdf/2510.22686v1"
  },
  {
    "id": "2510.23665v2",
    "title": "Transformers from Compressed Representations",
    "abstract": "Compressed file formats are the corner stone of efficient data storage and\ntransmission, yet their potential for representation learning remains largely\nunderexplored. We introduce TEMPEST (TransformErs froM comPressed\nrEpreSenTations), a method that exploits the inherent byte-stream structure of\ncompressed files to design an effective tokenization and encoding strategy. By\nleveraging this compact encoding, a standard transformer can directly learn\nsemantic representations from compressed data streams, bypassing the need for\nraw byte-level processing or full media decoding. Our proposal substantially\nreduces the number of tokens required for semantic classification, thereby\nlowering both computational complexity and memory usage. Through extensive\nexperiments across diverse datasets, coding schemes, and modalities, we show\nthat TEMPEST achieves accuracy competitive wit the state-of-the-art while\ndelivering efficiency gains in memory and compute.",
    "categories": [
      "cs.LG",
      "cs.AI"
    ],
    "published": "2025-10-26T13:48:03Z",
    "authors": [
      "Juan C. Leon Alcazar",
      "Mattia Soldan",
      "Mohammad Saatialsoruji",
      "Alejandro Pardo",
      "Hani Itani",
      "Juan Camilo Perez",
      "Bernard Ghanem"
    ],
    "pdf_url": "http://arxiv.org/pdf/2510.23665v2"
  },
  {
    "id": "2510.22667v1",
    "title": "Block Coordinate Descent for Neural Networks Provably Finds Global\n  Minima",
    "abstract": "In this paper, we consider a block coordinate descent (BCD) algorithm for\ntraining deep neural networks and provide a new global convergence guarantee\nunder strictly monotonically increasing activation functions. While existing\nworks demonstrate convergence to stationary points for BCD in neural networks,\nour contribution is the first to prove convergence to global minima, ensuring\narbitrarily small loss. We show that the loss with respect to the output layer\ndecreases exponentially while the loss with respect to the hidden layers\nremains well-controlled. Additionally, we derive generalization bounds using\nthe Rademacher complexity framework, demonstrating that BCD not only achieves\nstrong optimization guarantees but also provides favorable generalization\nperformance. Moreover, we propose a modified BCD algorithm with skip\nconnections and non-negative projection, extending our convergence guarantees\nto ReLU activation, which are not strictly monotonic. Empirical experiments\nconfirm our theoretical findings, showing that the BCD algorithm achieves a\nsmall loss for strictly monotonic and ReLU activations.",
    "categories": [
      "stat.ML",
      "cs.LG"
    ],
    "published": "2025-10-26T13:06:19Z",
    "authors": [
      "Shunta Akiyama"
    ],
    "pdf_url": "http://arxiv.org/pdf/2510.22667v1"
  },
  {
    "id": "2510.22655v1",
    "title": "Learning Without Augmenting: Unsupervised Time Series Representation\n  Learning via Frame Projections",
    "abstract": "Self-supervised learning (SSL) has emerged as a powerful paradigm for\nlearning representations without labeled data. Most SSL approaches rely on\nstrong, well-established, handcrafted data augmentations to generate diverse\nviews for representation learning. However, designing such augmentations\nrequires domain-specific knowledge and implicitly imposes representational\ninvariances on the model, which can limit generalization. In this work, we\npropose an unsupervised representation learning method that replaces\naugmentations by generating views using orthonormal bases and overcomplete\nframes. We show that embeddings learned from orthonormal and overcomplete\nspaces reside on distinct manifolds, shaped by the geometric biases introduced\nby representing samples in different spaces. By jointly leveraging the\ncomplementary geometry of these distinct manifolds, our approach achieves\nsuperior performance without artificially increasing data diversity through\nstrong augmentations. We demonstrate the effectiveness of our method on nine\ndatasets across five temporal sequence tasks, where signal-specific\ncharacteristics make data augmentations particularly challenging. Without\nrelying on augmentation-induced diversity, our method achieves performance\ngains of up to 15--20\\% over existing self-supervised approaches. Source code:\nhttps://github.com/eth-siplab/Learning-with-FrameProjections",
    "categories": [
      "cs.LG",
      "cs.AI"
    ],
    "published": "2025-10-26T12:36:29Z",
    "authors": [
      "Berken Utku Demirel",
      "Christian Holz"
    ],
    "pdf_url": "http://arxiv.org/pdf/2510.22655v1"
  },
  {
    "id": "2510.22654v1",
    "title": "UCB-type Algorithm for Budget-Constrained Expert Learning",
    "abstract": "In many modern applications, a system must dynamically choose between several\nadaptive learning algorithms that are trained online. Examples include model\nselection in streaming environments, switching between trading strategies in\nfinance, and orchestrating multiple contextual bandit or reinforcement learning\nagents. At each round, a learner must select one predictor among $K$ adaptive\nexperts to make a prediction, while being able to update at most $M \\le K$ of\nthem under a fixed training budget.\n  We address this problem in the \\emph{stochastic setting} and introduce\n\\algname{M-LCB}, a computationally efficient UCB-style meta-algorithm that\nprovides \\emph{anytime regret guarantees}. Its confidence intervals are built\ndirectly from realized losses, require no additional optimization, and\nseamlessly reflect the convergence properties of the underlying experts. If\neach expert achieves internal regret $\\tilde O(T^\\alpha)$, then \\algname{M-LCB}\nensures overall regret bounded by $\\tilde O\\!\\Bigl(\\sqrt{\\tfrac{KT}{M}} \\;+\\;\n(K/M)^{1-\\alpha}\\,T^\\alpha\\Bigr)$.\n  To our knowledge, this is the first result establishing regret guarantees\nwhen multiple adaptive experts are trained simultaneously under per-round\nbudget constraints. We illustrate the framework with two representative cases:\n(i) parametric models trained online with stochastic losses, and (ii) experts\nthat are themselves multi-armed bandit algorithms. These examples highlight how\n\\algname{M-LCB} extends the classical bandit paradigm to the more realistic\nscenario of coordinating stateful, self-learning experts under limited\nresources.",
    "categories": [
      "cs.LG",
      "cs.MA"
    ],
    "published": "2025-10-26T12:36:17Z",
    "authors": [
      "Ilgam Latypov",
      "Alexandra Suvorikova",
      "Alexey Kroshnin",
      "Alexander Gasnikov",
      "Yuriy Dorn"
    ],
    "pdf_url": "http://arxiv.org/pdf/2510.22654v1"
  },
  {
    "id": "2510.22652v1",
    "title": "If You Want to Be Robust, Be Wary of Initialization",
    "abstract": "Graph Neural Networks (GNNs) have demonstrated remarkable performance across\na spectrum of graph-related tasks, however concerns persist regarding their\nvulnerability to adversarial perturbations. While prevailing defense strategies\nfocus primarily on pre-processing techniques and adaptive message-passing\nschemes, this study delves into an under-explored dimension: the impact of\nweight initialization and associated hyper-parameters, such as training epochs,\non a model's robustness. We introduce a theoretical framework bridging the\nconnection between initialization strategies and a network's resilience to\nadversarial perturbations. Our analysis reveals a direct relationship between\ninitial weights, number of training epochs and the model's vulnerability,\noffering new insights into adversarial robustness beyond conventional defense\nmechanisms. While our primary focus is on GNNs, we extend our theoretical\nframework, providing a general upper-bound applicable to Deep Neural Networks.\nExtensive experiments, spanning diverse models and real-world datasets\nsubjected to various adversarial attacks, validate our findings. We illustrate\nthat selecting appropriate initialization not only ensures performance on clean\ndatasets but also enhances model robustness against adversarial perturbations,\nwith observed gaps of up to 50\\% compared to alternative initialization\napproaches.",
    "categories": [
      "cs.LG"
    ],
    "published": "2025-10-26T12:28:12Z",
    "authors": [
      "Sofiane Ennadir",
      "Johannes F. Lutzeyer",
      "Michalis Vazirgiannis",
      "El Houcine Bergou"
    ],
    "pdf_url": "http://arxiv.org/pdf/2510.22652v1"
  },
  {
    "id": "2510.22651v1",
    "title": "Variational Polya Tree",
    "abstract": "Density estimation is essential for generative modeling, particularly with\nthe rise of modern neural networks. While existing methods capture complex data\ndistributions, they often lack interpretability and uncertainty quantification.\nBayesian nonparametric methods, especially the \\polya tree, offer a robust\nframework that addresses these issues by accurately capturing function behavior\nover small intervals. Traditional techniques like Markov chain Monte Carlo\n(MCMC) face high computational complexity and scalability limitations,\nhindering the use of Bayesian nonparametric methods in deep learning. To tackle\nthis, we introduce the variational \\polya tree (VPT) model, which employs\nstochastic variational inference to compute posterior distributions. This model\nprovides a flexible, nonparametric Bayesian prior that captures latent\ndensities and works well with stochastic gradient optimization. We also\nleverage the joint distribution likelihood for a more precise variational\nposterior approximation than traditional mean-field methods. We evaluate the\nmodel performance on both real data and images, and demonstrate its\ncompetitiveness with other state-of-the-art deep density estimation methods. We\nalso explore its ability in enhancing interpretability and uncertainty\nquantification. Code is available at\nhttps://github.com/howardchanth/var-polya-tree.",
    "categories": [
      "cs.LG",
      "cs.AI"
    ],
    "published": "2025-10-26T12:23:22Z",
    "authors": [
      "Lu Xu",
      "Tsai Hor Chan",
      "Kwok Fai Lam",
      "Lequan Yu",
      "Guosheng Yin"
    ],
    "pdf_url": "http://arxiv.org/pdf/2510.22651v1"
  },
  {
    "id": "2510.22643v1",
    "title": "Enhancing Graph Classification Robustness with Singular Pooling",
    "abstract": "Graph Neural Networks (GNNs) have achieved strong performance across a range\nof graph representation learning tasks, yet their adversarial robustness in\ngraph classification remains underexplored compared to node classification.\nWhile most existing defenses focus on the message-passing component, this work\ninvestigates the overlooked role of pooling operations in shaping robustness.\nWe present a theoretical analysis of standard flat pooling methods (sum,\naverage and max), deriving upper bounds on their adversarial risk and\nidentifying their vulnerabilities under different attack scenarios and graph\nstructures. Motivated by these insights, we propose \\textit{Robust Singular\nPooling (RS-Pool)}, a novel pooling strategy that leverages the dominant\nsingular vector of the node embedding matrix to construct a robust graph-level\nrepresentation. We theoretically investigate the robustness of RS-Pool and\ninterpret the resulting bound leading to improved understanding of our proposed\npooling operator. While our analysis centers on Graph Convolutional Networks\n(GCNs), RS-Pool is model-agnostic and can be implemented efficiently via power\niteration. Empirical results on real-world benchmarks show that RS-Pool\nprovides better robustness than the considered pooling methods when subject to\nstate-of-the-art adversarial attacks while maintaining competitive clean\naccuracy. Our code is publicly available\nat:\\href{https://github.com/king/rs-pool}{https://github.com/king/rs-pool}.",
    "categories": [
      "cs.LG",
      "cs.AI"
    ],
    "published": "2025-10-26T12:07:06Z",
    "authors": [
      "Sofiane Ennadir",
      "Oleg Smirnov",
      "Yassine Abbahaddou",
      "Lele Cao",
      "Johannes F. Lutzeyer"
    ],
    "pdf_url": "http://arxiv.org/pdf/2510.22643v1"
  },
  {
    "id": "2510.22641v1",
    "title": "FastVLM: Self-Speculative Decoding for Fast Vision-Language Model\n  Inference",
    "abstract": "Vision-language Models (VLMs) have made significant strides in visual\nunderstanding and query response generation, but often face challenges of high\ncomputational cost and inference latency due to autoregressive decoding. In\nthis work, we introduce an imitation-learning-based Self-Speculative Decoding\n(SSD) framework, named FastVLM, to address these limitations. Our approach\nemploys a lightweight draft model for token generation in an autoregressive\nmanner, while a full model verifies these tokens non-autoregressively. Accepted\ntokens proceed seamlessly, while rejected tokens are corrected by the full\nmodel and used to guide the draft model's refinement. Through an imitation\nnetwork, FastVLM enhances the draft model by integrating deeper level insights\nfrom the full model's architecture. Also, it maintains the performance\nintegrity of the full model while training the draft model, achieving a balance\nbetween efficiency and accuracy. Our method speeds up the inference process by\n1.55-1.85x as compared to the final layer with minimal loss in performance.",
    "categories": [
      "cs.LG",
      "cs.AI"
    ],
    "published": "2025-10-26T11:49:20Z",
    "authors": [
      "Divya Jyoti Bajpai",
      "Manjesh Kumar Hanawal"
    ],
    "pdf_url": "http://arxiv.org/pdf/2510.22641v1"
  },
  {
    "id": "2510.22632v1",
    "title": "Environment-aware Motion Matching",
    "abstract": "Interactive applications demand believable characters that respond naturally\nto dynamic environments. Traditional character animation techniques often\nstruggle to handle arbitrary situations, leading to a growing trend of\ndynamically selecting motion-captured animations based on predefined features.\nWhile Motion Matching has proven effective for locomotion by aligning to target\ntrajectories, animating environment interactions and crowd behaviors remains\nchallenging due to the need to consider surrounding elements. Existing\napproaches often involve manual setup or lack the naturalism of motion capture.\nFurthermore, in crowd animation, body animation is frequently treated as a\nseparate process from trajectory planning, leading to inconsistencies between\nbody pose and root motion. To address these limitations, we present\nEnvironment-aware Motion Matching, a novel real-time system for full-body\ncharacter animation that dynamically adapts to obstacles and other agents,\nemphasizing the bidirectional relationship between pose and trajectory. In a\npreprocessing step, we extract shape, pose, and trajectory features from a\nmotion capture database. At runtime, we perform an efficient search that\nmatches user input and current pose while penalizing collisions with a dynamic\nenvironment. Our method allows characters to naturally adjust their pose and\ntrajectory to navigate crowded scenes.",
    "categories": [
      "cs.GR",
      "cs.LG"
    ],
    "published": "2025-10-26T11:28:50Z",
    "authors": [
      "Jose Luis Ponton",
      "Sheldon Andrews",
      "Carlos Andujar",
      "Nuria Pelechano"
    ],
    "pdf_url": "http://arxiv.org/pdf/2510.22632v1"
  },
  {
    "id": "2510.23663v1",
    "title": "AI-Driven Carbon Monitoring: Transformer-Based Reconstruction of\n  Atmospheric CO2 in Canadian Poultry Regions",
    "abstract": "Accurate mapping of column-averaged CO2 (XCO2) over agricultural landscapes\nis essential for guiding emission mitigation strategies. We present a\nSpatiotemporal Vision Transformer with Wavelets (ST-ViWT) framework that\nreconstructs continuous, uncertainty-quantified XCO2 fields from OCO-2 across\nsouthern Canada, emphasizing poultry-intensive regions. The model fuses wavelet\ntime-frequency representations with transformer attention over meteorology,\nvegetation indices, topography, and land cover. On 2024 OCO-2 data, ST-ViWT\nattains R2 = 0.984 and RMSE = 0.468 ppm; 92.3 percent of gap-filled predictions\nlie within +/-1 ppm. Independent validation with TCCON shows robust\ngeneralization (bias = -0.14 ppm; r = 0.928), including faithful reproduction\nof the late-summer drawdown. Spatial analysis across 14 poultry regions reveals\na moderate positive association between facility density and XCO2 (r = 0.43);\nhigh-density areas exhibit larger seasonal amplitudes (9.57 ppm) and enhanced\nsummer variability. Compared with conventional interpolation and standard\nmachine-learning baselines, ST-ViWT yields seamless 0.25 degree CO2 surfaces\nwith explicit uncertainties, enabling year-round coverage despite sparse\nobservations. The approach supports integration of satellite constraints with\nnational inventories and precision livestock platforms to benchmark emissions,\nrefine region-specific factors, and verify interventions. Importantly,\ntransformer-based Earth observation enables scalable, transparent, spatially\nexplicit carbon accounting, hotspot prioritization, and policy-relevant\nmitigation assessment.",
    "categories": [
      "cs.LG"
    ],
    "published": "2025-10-26T10:41:12Z",
    "authors": [
      "Padmanabhan Jagannathan Prajesh",
      "Kaliaperumal Ragunath",
      "Miriam Gordon",
      "Bruce Rathgeber",
      "Suresh Neethirajan"
    ],
    "pdf_url": "http://arxiv.org/pdf/2510.23663v1"
  },
  {
    "id": "2510.22620v1",
    "title": "Breaking Agent Backbones: Evaluating the Security of Backbone LLMs in AI\n  Agents",
    "abstract": "AI agents powered by large language models (LLMs) are being deployed at\nscale, yet we lack a systematic understanding of how the choice of backbone LLM\naffects agent security. The non-deterministic sequential nature of AI agents\ncomplicates security modeling, while the integration of traditional software\nwith AI components entangles novel LLM vulnerabilities with conventional\nsecurity risks. Existing frameworks only partially address these challenges as\nthey either capture specific vulnerabilities only or require modeling of\ncomplete agents. To address these limitations, we introduce threat snapshots: a\nframework that isolates specific states in an agent's execution flow where LLM\nvulnerabilities manifest, enabling the systematic identification and\ncategorization of security risks that propagate from the LLM to the agent\nlevel. We apply this framework to construct the $\\operatorname{b}^3$ benchmark,\na security benchmark based on 194331 unique crowdsourced adversarial attacks.\nWe then evaluate 31 popular LLMs with it, revealing, among other insights, that\nenhanced reasoning capabilities improve security, while model size does not\ncorrelate with security. We release our benchmark, dataset, and evaluation code\nto facilitate widespread adoption by LLM providers and practitioners, offering\nguidance for agent developers and incentivizing model developers to prioritize\nbackbone security improvements.",
    "categories": [
      "cs.CR",
      "cs.AI",
      "cs.LG"
    ],
    "published": "2025-10-26T10:36:42Z",
    "authors": [
      "Julia Bazinska",
      "Max Mathys",
      "Francesco Casucci",
      "Mateo Rojas-Carulla",
      "Xander Davies",
      "Alexandra Souly",
      "Niklas Pfister"
    ],
    "pdf_url": "http://arxiv.org/pdf/2510.22620v1"
  },
  {
    "id": "2510.22619v1",
    "title": "CLEANet: Robust and Efficient Anomaly Detection in Contaminated\n  Multivariate Time Series",
    "abstract": "Multivariate time series (MTS) anomaly detection is essential for maintaining\nthe reliability of industrial systems, yet real-world deployment is hindered by\ntwo critical challenges: training data contamination (noises and hidden\nanomalies) and inefficient model inference. Existing unsupervised methods\nassume clean training data, but contamination distorts learned patterns and\ndegrades detection accuracy. Meanwhile, complex deep models often overfit to\ncontamination and suffer from high latency, limiting practical use. To address\nthese challenges, we propose CLEANet, a robust and efficient anomaly detection\nframework in contaminated multivariate time series. CLEANet introduces a\nContamination-Resilient Training Framework (CRTF) that mitigates the impact of\ncorrupted samples through an adaptive reconstruction weighting strategy\ncombined with clustering-guided contrastive learning, thereby enhancing\nrobustness. To further avoid overfitting on contaminated data and improve\ncomputational efficiency, we design a lightweight conjugate MLP that\ndisentangles temporal and cross-feature dependencies. Across five public\ndatasets, CLEANet achieves up to 73.04% higher F1 and 81.28% lower runtime\ncompared with ten state-of-the-art baselines. Furthermore, integrating CRTF\ninto three advanced models yields an average 5.35% F1 gain, confirming its\nstrong generalizability.",
    "categories": [
      "cs.LG"
    ],
    "published": "2025-10-26T10:34:19Z",
    "authors": [
      "Songhan Zhang",
      "Yuanhao Lai",
      "Pengfei Zheng",
      "Boxi Yu",
      "Xiaoying Tang",
      "Qiuai Fu",
      "Pinjia He"
    ],
    "pdf_url": "http://arxiv.org/pdf/2510.22619v1"
  },
  {
    "id": "2510.23662v1",
    "title": "JiuTian Chuanliu: A Large Spatiotemporal Model for General-purpose\n  Dynamic Urban Sensing",
    "abstract": "As a window for urban sensing, human mobility contains rich spatiotemporal\ninformation that reflects both residents' behavior preferences and the\nfunctions of urban areas. The analysis of human mobility has attracted the\nattention of many researchers. However, existing methods often address specific\ntasks from a particular perspective, leading to insufficient modeling of human\nmobility and limited applicability of the learned knowledge in various\ndownstream applications. To address these challenges, this paper proposes to\npush massive amounts of human mobility data into a spatiotemporal model,\ndiscover latent semantics behind mobility behavior and support various urban\nsensing tasks. Specifically, a large-scale and widely covering human mobility\ndata is collected through the ubiquitous base station system and a framework\nnamed General-purpose and Dynamic Human Mobility Embedding (GDHME) for urban\nsensing is introduced. The framework follows the self-supervised learning idea\nand contains two major stages. In stage 1, GDHME treats people and regions as\nnodes within a dynamic graph, unifying human mobility data as\npeople-region-time interactions. An encoder operating in continuous-time\ndynamically computes evolving node representations, capturing dynamic states\nfor both people and regions. Moreover, an autoregressive self-supervised task\nis specially designed to guide the learning of the general-purpose node\nembeddings. In stage 2, these representations are utilized to support various\ntasks. To evaluate the effectiveness of our GDHME framework, we further\nconstruct a multi-task urban sensing benchmark. Offline experiments demonstrate\nGDHME's ability to automatically learn valuable node features from vast amounts\nof data. Furthermore, our framework is used to deploy the JiuTian ChuanLiu Big\nModel, a system that has been presented at the 2023 China Mobile Worldwide\nPartner Conference.",
    "categories": [
      "cs.SI",
      "cs.IT",
      "cs.LG",
      "math.IT"
    ],
    "published": "2025-10-26T10:04:28Z",
    "authors": [
      "Liangzhe Han",
      "Leilei Sun",
      "Tongyu Zhu",
      "Tao Tao",
      "Jibin Wang",
      "Weifeng Lv"
    ],
    "pdf_url": "http://arxiv.org/pdf/2510.23662v1"
  },
  {
    "id": "2510.22599v1",
    "title": "A roadmap for curvature-based geometric data analysis and learning",
    "abstract": "Geometric data analysis and learning has emerged as a distinct and rapidly\ndeveloping research area, increasingly recognized for its effectiveness across\ndiverse applications. At the heart of this field lies curvature, a powerful and\ninterpretable concept that captures intrinsic geometric structure and underpins\nnumerous tasks, from community detection to geometric deep learning. A wide\nrange of discrete curvature models have been proposed for various data\nrepresentations, including graphs, simplicial complexes, cubical complexes, and\npoint clouds sampled from manifolds. These models not only provide efficient\ncharacterizations of data geometry but also constitute essential components in\ngeometric learning frameworks. In this paper, we present the first\ncomprehensive review of existing discrete curvature models, covering their\nmathematical foundations, computational formulations, and practical\napplications in data analysis and learning. In particular, we discuss discrete\ncurvature from both Riemannian and metric geometry perspectives and propose a\nsystematic pipeline for curvature-driven data analysis. We further examine the\ncorresponding computational algorithms across different data representations,\noffering detailed comparisons and insights. Finally, we review state-of-the-art\napplications of curvature in both supervised and unsupervised learning. This\nsurvey provides a conceptual and practical roadmap for researchers to gain a\nbetter understanding of discrete curvature as a fundamental tool for geometric\nunderstanding and learning.",
    "categories": [
      "cs.LG",
      "math.DG",
      "05C10, 51F99, 53C44, 68T30, 97N70"
    ],
    "published": "2025-10-26T09:31:41Z",
    "authors": [
      "Yasharth Yadav",
      "Kelin Xia"
    ],
    "pdf_url": "http://arxiv.org/pdf/2510.22599v1"
  },
  {
    "id": "2510.22594v1",
    "title": "A Framework for Quantifying How Pre-Training and Context Benefit\n  In-Context Learning",
    "abstract": "Pre-trained large language models have demonstrated a strong ability to learn\nfrom context, known as in-context learning (ICL). Despite a surge of recent\napplications that leverage such capabilities, it is by no means clear, at least\ntheoretically, how the ICL capabilities arise, and in particular, what is the\nprecise role played by key factors such as pre-training procedure as well as\ncontext construction. In this work, we propose a new framework to analyze the\nICL performance, for a class of realistic settings, which includes network\narchitectures, data encoding, data generation, and prompt construction process.\nAs a first step, we construct a simple example with a one-layer transformer,\nand show an interesting result, namely when the pre-train data distribution is\ndifferent from the query task distribution, a properly constructed context can\nshift the output distribution towards the query task distribution, in a\nquantifiable manner, leading to accurate prediction on the query topic. We then\nextend the findings in the previous step to a more general case, and derive the\nprecise relationship between ICL performance, context length and the KL\ndivergence between pre-train and query task distribution. Finally, we provide\nexperiments to validate our theoretical results.",
    "categories": [
      "cs.AI",
      "cs.LG"
    ],
    "published": "2025-10-26T09:21:29Z",
    "authors": [
      "Bingqing Song",
      "Jiaxiang Li",
      "Rong Wang",
      "Songtao Lu",
      "Mingyi Hong"
    ],
    "pdf_url": "http://arxiv.org/pdf/2510.22594v1"
  },
  {
    "id": "2510.25775v1",
    "title": "Towards Piece-by-Piece Explanations for Chess Positions with SHAP",
    "abstract": "Contemporary chess engines offer precise yet opaque evaluations, typically\nexpressed as centipawn scores. While effective for decision-making, these\noutputs obscure the underlying contributions of individual pieces or patterns.\nIn this paper, we explore adapting SHAP (SHapley Additive exPlanations) to the\ndomain of chess analysis, aiming to attribute a chess engines evaluation to\nspecific pieces on the board. By treating pieces as features and systematically\nablating them, we compute additive, per-piece contributions that explain the\nengines output in a locally faithful and human-interpretable manner. This\nmethod draws inspiration from classical chess pedagogy, where players assess\npositions by mentally removing pieces, and grounds it in modern explainable AI\ntechniques. Our approach opens new possibilities for visualization, human\ntraining, and engine comparison. We release accompanying code and data to\nfoster future research in interpretable chess AI.",
    "categories": [
      "cs.AI",
      "cs.LG"
    ],
    "published": "2025-10-26T09:07:21Z",
    "authors": [
      "Francesco Spinnato"
    ],
    "pdf_url": "http://arxiv.org/pdf/2510.25775v1"
  },
  {
    "id": "2510.22586v1",
    "title": "Prediction-Powered Semi-Supervised Learning with Online Power Tuning",
    "abstract": "Prediction-Powered Inference (PPI) is a recently proposed statistical\ninference technique for parameter estimation that leverages pseudo-labels on\nboth labeled and unlabeled data to construct an unbiased, low-variance\nestimator. In this work, we extend its core idea to semi-supervised learning\n(SSL) for model training, introducing a novel unbiased gradient estimator. This\nextension addresses a key challenge in SSL: while unlabeled data can improve\nmodel performance, its benefit heavily depends on the quality of pseudo-labels.\nInaccurate pseudo-labels can introduce bias, leading to suboptimal models.To\nbalance the contributions of labeled and pseudo-labeled data, we utilize an\ninterpolation parameter and tune it on the fly, alongside the model parameters,\nusing a one-dimensional online learning algorithm. We verify the practical\nadvantage of our approach through experiments on both synthetic and real\ndatasets, demonstrating improved performance over classic SSL baselines and PPI\nmethods that tune the interpolation parameter offline.",
    "categories": [
      "cs.LG"
    ],
    "published": "2025-10-26T09:01:02Z",
    "authors": [
      "Noa Shoham",
      "Ron Dorfman",
      "Shalev Shaer",
      "Kfir Y. Levy",
      "Yaniv Romano"
    ],
    "pdf_url": "http://arxiv.org/pdf/2510.22586v1"
  },
  {
    "id": "2510.22579v1",
    "title": "Optimal Anytime Algorithms for Online Convex Optimization with\n  Adversarial Constraints",
    "abstract": "We propose an anytime online algorithm for the problem of learning a sequence\nof adversarial convex cost functions while approximately satisfying another\nsequence of adversarial online convex constraints. A sequential algorithm is\ncalled \\emph{anytime} if it provides a non-trivial performance guarantee for\nany intermediate timestep $t$ without requiring prior knowledge of the length\nof the entire time horizon $T$. Our proposed algorithm achieves optimal\nperformance bounds without resorting to the standard doubling trick, which has\npoor practical performance due to multiple restarts. Our core technical\ncontribution is the use of time-varying Lyapunov functions to keep track of\nconstraint violations. This must be contrasted with prior works that used a\nfixed Lyapunov function tuned to the known horizon length $T$. The use of\ntime-varying Lyapunov function poses unique analytical challenges as\nproperties, such as \\emph{monotonicity}, on which the prior proofs rest, no\nlonger hold. By introducing a new analytical technique, we show that our\nalgorithm achieves $O(\\sqrt{t})$ regret and $\\tilde{O}(\\sqrt{t})$ cumulative\nconstraint violation bounds for any $t\\geq 1$.\n  We extend our results to the dynamic regret setting, achieving bounds that\nadapt to the path length of the comparator sequence without prior knowledge of\nits total length. We also present an adaptive algorithm in the optimistic\nsetting, whose performance gracefully scales with the cumulative prediction\nerror. We demonstrate the practical utility of our algorithm through numerical\nexperiments involving the online shortest path problem.",
    "categories": [
      "cs.LG"
    ],
    "published": "2025-10-26T08:35:37Z",
    "authors": [
      "Dhruv Sarkar",
      "Abhishek Sinha"
    ],
    "pdf_url": "http://arxiv.org/pdf/2510.22579v1"
  },
  {
    "id": "2510.22572v1",
    "title": "Combining Deep Learning and Explainable AI for Toxicity Prediction of\n  Chemical Compounds",
    "abstract": "The task here is to predict the toxicological activity of chemical compounds\nbased on the Tox21 dataset, a benchmark in computational toxicology.\n  After a domain-specific overview of chemical toxicity, we discuss current\ncomputational strategies, focusing on machine learning and deep learning.\nSeveral architectures are compared in terms of performance, robustness, and\ninterpretability.\n  This research introduces a novel image-based pipeline based on DenseNet121,\nwhich processes 2D graphical representations of chemical structures.\nAdditionally, we employ Grad-CAM visualizations, an explainable AI technique,\nto interpret the model's predictions and highlight molecular regions\ncontributing to toxicity classification. The proposed architecture achieves\ncompetitive results compared to traditional models, demonstrating the potential\nof deep convolutional networks in cheminformatics. Our findings emphasize the\nvalue of combining image-based representations with explainable AI methods to\nimprove both predictive accuracy and model transparency in toxicology.",
    "categories": [
      "cs.LG",
      "cs.AI"
    ],
    "published": "2025-10-26T08:05:11Z",
    "authors": [
      "Eduard Popescu",
      "Adrian Groza",
      "Andreea Cernat"
    ],
    "pdf_url": "http://arxiv.org/pdf/2510.22572v1"
  },
  {
    "id": "2510.23660v1",
    "title": "Quanvolutional Neural Networks for Pneumonia Detection: An Efficient\n  Quantum-Assisted Feature Extraction Paradigm",
    "abstract": "Pneumonia poses a significant global health challenge, demanding accurate and\ntimely diagnosis. While deep learning, particularly Convolutional Neural\nNetworks (CNNs), has shown promise in medical image analysis for pneumonia\ndetection, CNNs often suffer from high computational costs, limitations in\nfeature representation, and challenges in generalizing from smaller datasets.\nTo address these limitations, we explore the application of Quanvolutional\nNeural Networks (QNNs), leveraging quantum computing for enhanced feature\nextraction. This paper introduces a novel hybrid quantum-classical model for\npneumonia detection using the PneumoniaMNIST dataset. Our approach utilizes a\nquanvolutional layer with a parameterized quantum circuit (PQC) to process 2x2\nimage patches, employing rotational Y-gates for data encoding and entangling\nlayers to generate non-classical feature representations. These\nquantum-extracted features are then fed into a classical neural network for\nclassification. Experimental results demonstrate that the proposed QNN achieves\na higher validation accuracy of 83.33 percent compared to a comparable\nclassical CNN which achieves 73.33 percent. This enhanced convergence and\nsample efficiency highlight the potential of QNNs for medical image analysis,\nparticularly in scenarios with limited labeled data. This research lays the\nfoundation for integrating quantum computing into deep-learning-driven medical\ndiagnostic systems, offering a computationally efficient alternative to\ntraditional approaches.",
    "categories": [
      "cs.LG",
      "cs.AI",
      "cs.CV"
    ],
    "published": "2025-10-26T08:01:34Z",
    "authors": [
      "Gazi Tanbhir",
      "Md. Farhan Shahriyar",
      "Abdullah Md Raihan Chy"
    ],
    "pdf_url": "http://arxiv.org/pdf/2510.23660v1"
  },
  {
    "id": "2510.23659v1",
    "title": "Quantum Machine Learning for Image Classification: A Hybrid Model of\n  Residual Network with Quantum Support Vector Machine",
    "abstract": "Recently, there has been growing attention on combining quantum machine\nlearning (QML) with classical deep learning approaches, as computational\ntechniques are key to improving the performance of image classification tasks.\nThis study presents a hybrid approach that uses ResNet-50 (Residual Network)\nfor feature extraction and Quantum Support Vector Machines (QSVM) for\nclassification in the context of potato disease detection. Classical machine\nlearning as well as deep learning models often struggle with high-dimensional\nand complex datasets, necessitating advanced techniques like quantum computing\nto improve classification efficiency. In our research, we use ResNet-50 to\nextract deep feature representations from RGB images of potato diseases. These\nfeatures are then subjected to dimensionality reduction using Principal\nComponent Analysis (PCA). The resulting features are processed through QSVM\nmodels which apply various quantum feature maps such as ZZ, Z, and Pauli-X to\ntransform classical data into quantum states. To assess the model performance,\nwe compared it with classical machine learning algorithms such as Support\nVector Machine (SVM) and Random Forest (RF) using five-fold stratified\ncross-validation for comprehensive evaluation. The experimental results\ndemonstrate that the Z-feature map-based QSVM outperforms classical models,\nachieving an accuracy of 99.23 percent, surpassing both SVM and RF models. This\nresearch highlights the advantages of integrating quantum computing into image\nclassification and provides a potential disease detection solution through\nhybrid quantum-classical modeling.",
    "categories": [
      "cs.LG",
      "cs.CV",
      "cs.ET"
    ],
    "published": "2025-10-26T07:52:53Z",
    "authors": [
      "Md. Farhan Shahriyar",
      "Gazi Tanbhir",
      "Abdullah Md Raihan Chy"
    ],
    "pdf_url": "http://arxiv.org/pdf/2510.23659v1"
  },
  {
    "id": "2510.22567v1",
    "title": "Semi-Supervised Learning under General Causal Models",
    "abstract": "Semi-supervised learning (SSL) aims to train a machine learning model using\nboth labelled and unlabelled data. While the unlabelled data have been used in\nvarious ways to improve the prediction accuracy, the reason why unlabelled data\ncould help is not fully understood. One interesting and promising direction is\nto understand SSL from a causal perspective. In light of the independent causal\nmechanisms principle, the unlabelled data can be helpful when the label causes\nthe features but not vice versa. However, the causal relations between the\nfeatures and labels can be complex in real world applications. In this paper,\nwe propose a SSL framework that works with general causal models in which the\nvariables have flexible causal relations. More specifically, we explore the\ncausal graph structures and design corresponding causal generative models which\ncan be learned with the help of unlabelled data. The learned causal generative\nmodel can generate synthetic labelled data for training a more accurate\npredictive model. We verify the effectiveness of our proposed method by\nempirical studies on both simulated and real data.",
    "categories": [
      "stat.ML",
      "cs.LG"
    ],
    "published": "2025-10-26T07:46:38Z",
    "authors": [
      "Archer Moore",
      "Heejung Shim",
      "Jingge Zhu",
      "Mingming Gong"
    ],
    "pdf_url": "http://arxiv.org/pdf/2510.22567v1"
  },
  {
    "id": "2510.22560v1",
    "title": "Statistical Analysis of the Sinkhorn Iterations for Two-Sample\n  Schr\u00f6dinger Bridge Estimation",
    "abstract": "The Schr\\\"odinger bridge problem seeks the optimal stochastic process that\nconnects two given probability distributions with minimal energy modification.\nWhile the Sinkhorn algorithm is widely used to solve the static optimal\ntransport problem, a recent work (Pooladian and Niles-Weed, 2024) proposed the\nSinkhorn bridge, which estimates Schr\\\"odinger bridges by plugging optimal\ntransport into the time-dependent drifts of SDEs, with statistical guarantees\nin the one-sample estimation setting where the true source distribution is\nfully accessible. In this work, to further justify this method, we study the\nstatistical performance of intermediate Sinkhorn iterations in the two-sample\nestimation setting, where only finite samples from both source and target\ndistributions are available. Specifically, we establish a statistical bound on\nthe squared total variation error of Sinkhorn bridge iterations: $O(1/m+1/n +\nr^{4k})~(r \\in (0,1))$, where $m$ and $n$ are the sample sizes from the source\nand target distributions, respectively, and $k$ is the number of Sinkhorn\niterations. This result provides a theoretical guarantee for the finite-sample\nperformance of the Schr\\\"odinger bridge estimator and offers practical guidance\nfor selecting sample sizes and the number of Sinkhorn iterations. Notably, our\ntheoretical results apply to several representative methods such as [SF]$^2$M,\nDSBM-IMF, BM2, and LightSB(-M) under specific settings, through the previously\nunnoticed connection between these estimators.",
    "categories": [
      "stat.ML",
      "cs.LG"
    ],
    "published": "2025-10-26T07:39:36Z",
    "authors": [
      "Ibuki Maeda",
      "Rentian Yao",
      "Atsushi Nitanda"
    ],
    "pdf_url": "http://arxiv.org/pdf/2510.22560v1"
  },
  {
    "id": "2510.22555v1",
    "title": "Cross-Paradigm Graph Backdoor Attacks with Promptable Subgraph Triggers",
    "abstract": "Graph Neural Networks(GNNs) are vulnerable to backdoor attacks, where\nadversaries implant malicious triggers to manipulate model predictions.\n  Existing trigger generators are often simplistic in structure and overly\nreliant on specific features, confining them to a single graph learning\nparadigm, such as graph supervised learning, graph contrastive learning, or\ngraph prompt learning.\n  This specialized design, which aligns the trigger with one learning\nobjective, results in poor transferability when applied to other learning\nparadigms.\n  For instance, triggers generated for the graph supervised learning paradigm\nperform poorly when tested within graph contrastive learning or graph prompt\nlearning environments.\n  Furthermore, these simple generators often fail to utilize complex structural\ninformation or node diversity within the graph data.\n  These constraints limit the attack success rates of such methods in general\ntesting scenarios.\n  Therefore, to address these limitations, we propose Cross-Paradigm Graph\nBackdoor Attacks with Promptable Subgraph Triggers(CP-GBA), a new transferable\ngraph backdoor attack that employs graph prompt learning(GPL) to train a set of\nuniversal subgraph triggers.\n  First, we distill a compact yet expressive trigger set from target graphs,\nwhich is structured as a queryable repository, by jointly enforcing\nclass-awareness, feature richness, and structural fidelity.\n  Second, we conduct the first exploration of the theoretical transferability\nof GPL to train these triggers under prompt-based objectives, enabling\neffective generalization to diverse and unseen test-time paradigms.\n  Extensive experiments across multiple real-world datasets and defense\nscenarios show that CP-GBA achieves state-of-the-art attack success rates.",
    "categories": [
      "cs.CR",
      "cs.LG"
    ],
    "published": "2025-10-26T07:10:07Z",
    "authors": [
      "Dongyi Liu",
      "Jiangtong Li",
      "Dawei Cheng",
      "Changjun Jiang"
    ],
    "pdf_url": "http://arxiv.org/pdf/2510.22555v1"
  },
  {
    "id": "2510.22553v1",
    "title": "DDTR: Diffusion Denoising Trace Recovery",
    "abstract": "With recent technological advances, process logs, which were traditionally\ndeterministic in nature, are being captured from non-deterministic sources,\nsuch as uncertain sensors or machine learning models (that predict activities\nusing cameras). In the presence of stochastically-known logs, logs that contain\nprobabilistic information, the need for stochastic trace recovery increases, to\noffer reliable means of understanding the processes that govern such systems.\nWe design a novel deep learning approach for stochastic trace recovery, based\non Diffusion Denoising Probabilistic Models (DDPM), which makes use of process\nknowledge (either implicitly by discovering a model or explicitly by injecting\nprocess knowledge in the training phase) to recover traces by denoising. We\nconduct an empirical evaluation demonstrating state-of-the-art performance with\nup to a 25% improvement over existing methods, along with increased robustness\nunder high noise levels.",
    "categories": [
      "cs.LG",
      "cs.AI"
    ],
    "published": "2025-10-26T06:43:53Z",
    "authors": [
      "Maximilian Matyash",
      "Avigdor Gal",
      "Arik Senderovich"
    ],
    "pdf_url": "http://arxiv.org/pdf/2510.22553v1"
  },
  {
    "id": "2510.22543v1",
    "title": "FAPO: Flawed-Aware Policy Optimization for Efficient and Reliable\n  Reasoning",
    "abstract": "Reinforcement learning with verifiable rewards (RLVR) has emerged as a\npromising paradigm for enhancing the reasoning capabilities of large language\nmodels (LLMs). In this context, models explore reasoning trajectories and\nexploit rollouts with correct answers as positive signals for policy\noptimization. However, these rollouts might involve flawed patterns such as\nanswer-guessing and jump-in-reasoning. Such flawed-positive rollouts are\nrewarded identically to fully correct ones, causing policy models to\ninternalize these unreliable reasoning patterns. In this work, we first conduct\na systematic study of flawed-positive rollouts in RL and find that they enable\nrapid capability gains during the early optimization stage, while constraining\nreasoning capability later by reinforcing unreliable patterns. Building on\nthese insights, we propose Flawed-Aware Policy Optimization (FAPO), which\npresents a parameter-free reward penalty for flawed-positive rollouts, enabling\nthe policy to leverage them as useful shortcuts in the warm-up stage, securing\nstable early gains, while gradually shifting optimization toward reliable\nreasoning in the later refinement stage. To accurately and comprehensively\ndetect flawed-positive rollouts, we introduce a generative reward model (GenRM)\nwith a process-level reward that precisely localizes reasoning errors.\nExperiments show that FAPO is effective in broad domains, improving outcome\ncorrectness, process reliability, and training stability without increasing the\ntoken budget.",
    "categories": [
      "cs.LG"
    ],
    "published": "2025-10-26T05:49:38Z",
    "authors": [
      "Yuyang Ding",
      "Chi Zhang",
      "Juntao Li",
      "Haibin Lin",
      "Xin Liu",
      "Min Zhang"
    ],
    "pdf_url": "http://arxiv.org/pdf/2510.22543v1"
  },
  {
    "id": "2510.22540v1",
    "title": "qc-kmeans: A Quantum Compressive K-Means Algorithm for NISQ Devices",
    "abstract": "Clustering on NISQ hardware is constrained by data loading and limited\nqubits. We present \\textbf{qc-kmeans}, a hybrid compressive $k$-means that\nsummarizes a dataset with a constant-size Fourier-feature sketch and selects\ncentroids by solving small per-group QUBOs with shallow QAOA circuits. The QFF\nsketch estimator is unbiased with mean-squared error $O(\\varepsilon^2)$ for\n$B,S=\\Theta(\\varepsilon^{-2})$, and the peak-qubit requirement\n$q_{\\text{peak}}=\\max\\{D,\\lceil \\log_2 B\\rceil + 1\\}$ does not scale with the\nnumber of samples. A refinement step with elitist retention ensures\nnon-increasing surrogate cost. In Qiskit Aer simulations (depth $p{=}1$), the\nmethod ran with $\\le 9$ qubits on low-dimensional synthetic benchmarks and\nachieved competitive sum-of-squared errors relative to quantum baselines;\nruntimes are not directly comparable. On nine real datasets (up to $4.3\\times\n10^5$ points), the pipeline maintained constant peak-qubit usage in simulation.\nUnder IBM noise models, accuracy was similar to the idealized setting. Overall,\nqc-kmeans offers a NISQ-oriented formulation with shallow, bounded-width\ncircuits and competitive clustering quality in simulation.",
    "categories": [
      "quant-ph",
      "cs.ET",
      "cs.LG"
    ],
    "published": "2025-10-26T05:44:17Z",
    "authors": [
      "Pedro Chumpitaz-Flores",
      "My Duong",
      "Ying Mao",
      "Kaixun Hua"
    ],
    "pdf_url": "http://arxiv.org/pdf/2510.22540v1"
  },
  {
    "id": "2510.22539v1",
    "title": "Approximate Gradient Coding for Distributed Learning with Heterogeneous\n  Stragglers",
    "abstract": "In this paper, we propose an optimally structured gradient coding scheme to\nmitigate the straggler problem in distributed learning. Conventional gradient\ncoding methods often assume homogeneous straggler models or rely on excessive\ndata replication, limiting performance in real-world heterogeneous systems. To\naddress these limitations, we formulate an optimization problem minimizing\nresidual error while ensuring unbiased gradient estimation by explicitly\nconsidering individual straggler probabilities. We derive closed-form solutions\nfor optimal encoding and decoding coefficients via Lagrangian duality and\nconvex optimization, and propose data allocation strategies that reduce both\nredundancy and computation load. We also analyze convergence behavior for\n$\\lambda$-strongly convex and $\\mu$-smooth loss functions. Numerical results\nshow that our approach significantly reduces the impact of stragglers and\naccelerates convergence compared to existing methods.",
    "categories": [
      "eess.SY",
      "cs.LG",
      "cs.SY"
    ],
    "published": "2025-10-26T05:32:18Z",
    "authors": [
      "Heekang Song",
      "Wan Choi"
    ],
    "pdf_url": "http://arxiv.org/pdf/2510.22539v1"
  },
  {
    "id": "2510.22538v1",
    "title": "Iteratively Refined Early Interaction Alignment for Subgraph Matching\n  based Graph Retrieval",
    "abstract": "Graph retrieval based on subgraph isomorphism has several real-world\napplications such as scene graph retrieval, molecular fingerprint detection and\ncircuit design. Roy et al. [35] proposed IsoNet, a late interaction model for\nsubgraph matching, which first computes the node and edge embeddings of each\ngraph independently of paired graph and then computes a trainable alignment\nmap. Here, we present IsoNet++, an early interaction graph neural network\n(GNN), based on several technical innovations. First, we compute embeddings of\nall nodes by passing messages within and across the two input graphs, guided by\nan injective alignment between their nodes. Second, we update this alignment in\na lazy fashion over multiple rounds. Within each round, we run a layerwise GNN\nfrom scratch, based on the current state of the alignment. After the completion\nof one round of GNN, we use the last-layer embeddings to update the alignments,\nand proceed to the next round. Third, IsoNet++ incorporates a novel notion of\nnode-pair partner interaction. Traditional early interaction computes attention\nbetween a node and its potential partners in the other graph, the attention\nthen controlling messages passed across graphs. In contrast, we consider node\npairs (not single nodes) as potential partners. Existence of an edge between\nthe nodes in one graph and non-existence in the other provide vital signals for\nrefining the alignment. Our experiments on several datasets show that the\nalignments get progressively refined with successive rounds, resulting in\nsignificantly better retrieval performance than existing methods. We\ndemonstrate that all three innovations contribute to the enhanced accuracy. Our\ncode and datasets are publicly available at\nhttps://github.com/structlearning/isonetpp.",
    "categories": [
      "cs.LG"
    ],
    "published": "2025-10-26T05:24:10Z",
    "authors": [
      "Ashwin Ramachandran",
      "Vaibhav Raj",
      "Indrayumna Roy",
      "Soumen Chakrabarti",
      "Abir De"
    ],
    "pdf_url": "http://arxiv.org/pdf/2510.22538v1"
  },
  {
    "id": "2510.25774v1",
    "title": "Pulsar Detection with Deep Learning",
    "abstract": "Pulsar surveys generate millions of candidates per run, overwhelming manual\ninspection. This thesis builds a deep learning pipeline for radio pulsar\ncandidate selection that fuses array-derived features with image diagnostics.\nFrom approximately 500 GB of Giant Metrewave Radio Telescope (GMRT) data, raw\nvoltages are converted to filterbanks (SIGPROC), then de-dispersed and folded\nacross trial dispersion measures (PRESTO) to produce approximately 32,000\ncandidates. Each candidate yields four diagnostics--summed profile, time vs.\nphase, subbands vs. phase, and DM curve--represented as arrays and images. A\nbaseline stacked model (ANNs for arrays + CNNs for images with\nlogistic-regression fusion) reaches 68% accuracy. We then refine the CNN\narchitecture and training (regularization, learning-rate scheduling, max-norm\nconstraints) and mitigate class imbalance via targeted augmentation, including\na GAN-based generator for the minority class. The enhanced CNN attains 87%\naccuracy; the final GAN+CNN system achieves 94% accuracy with balanced\nprecision and recall on a held-out test set, while remaining lightweight enough\nfor near--real-time triage. The results show that combining array and image\nchannels improves separability over image-only approaches, and that modest\ngenerative augmentation substantially boosts minority (pulsar) recall. The\nmethods are survey-agnostic and extensible to forthcoming high-throughput\nfacilities.",
    "categories": [
      "astro-ph.IM",
      "cs.LG"
    ],
    "published": "2025-10-26T05:12:45Z",
    "authors": [
      "Manideep Pendyala"
    ],
    "pdf_url": "http://arxiv.org/pdf/2510.25774v1"
  },
  {
    "id": "2510.22531v1",
    "title": "Text to Trust: Evaluating Fine-Tuning and LoRA Trade-offs in Language\n  Models for Unfair Terms of Service Detection",
    "abstract": "Large Language Models (LLMs) have transformed text understanding, yet their\nadaptation to specialized legal domains remains constrained by the cost of full\nfine-tuning. This study provides a systematic evaluation of fine tuning,\nparameter efficient adaptation (LoRA, QLoRA), and zero-shot prompting\nstrategies for unfair clause detection in Terms of Service (ToS) documents, a\nkey application in legal NLP. We finetune BERT and DistilBERT, apply 4-bit\nLow-Rank Adaptation (LoRA) to models such as TinyLlama, LLaMA 3B/7B, and\nSaulLM, and evaluate GPT-4o and O-versions in zero-shot settings. Experiments\non the CLAUDETTE-ToS benchmark and the Multilingual Scraper Corpus show that\nfull fine-tuning achieves the strongest precision recall balance, while\nLoRA-based models provide competitive recall with up to 3x lower memory cost.\nThese findings highlight practical design trade-offs for efficient and\ndomain-adapted LLMs, contributing open baselines for fine-tuning research in\nlegal text processing.",
    "categories": [
      "cs.CL",
      "cs.AI",
      "cs.LG"
    ],
    "published": "2025-10-26T04:46:06Z",
    "authors": [
      "Noshitha Padma Pratyusha Juttu",
      "Sahithi Singireddy",
      "Sravani Gona",
      "Sujal Timilsina"
    ],
    "pdf_url": "http://arxiv.org/pdf/2510.22531v1"
  },
  {
    "id": "2510.22527v1",
    "title": "Multi-Modal Masked Autoencoders for Learning Image-Spectrum Associations\n  for Galaxy Evolution and Cosmology",
    "abstract": "Upcoming surveys will produce billions of galaxy images but comparatively few\nspectra, motivating models that learn cross-modal representations. We build a\ndataset of 134,533 galaxy images (HSC-PDR2) and spectra (DESI-DR1) and adapt a\nMulti-Modal Masked Autoencoder (MMAE) to embed both images and spectra in a\nshared representation. The MMAE is a transformer-based architecture, which we\ntrain by masking 75% of the data and reconstructing missing image and spectral\ntokens. We use this model to test three applications: spectral and image\nreconstruction from heavily masked data and redshift regression from images\nalone. It recovers key physical features, such as galaxy shapes, atomic\nemission line peaks, and broad continuum slopes, though it struggles with fine\nimage details and line strengths. For redshift regression, the MMAE performs\ncomparably or better than prior multi-modal models in terms of prediction\nscatter even when missing spectra in testing. These results highlight both the\npotential and limitations of masked autoencoders in astrophysics and motivate\nextensions to additional modalities, such as text, for foundation models.",
    "categories": [
      "astro-ph.IM",
      "astro-ph.GA",
      "cs.LG"
    ],
    "published": "2025-10-26T04:29:13Z",
    "authors": [
      "Morgan Himes",
      "Samiksha Krishnamurthy",
      "Andrew Lizarraga",
      "Srinath Saikrishnan",
      "Vikram Seenivasan",
      "Jonathan Soriano",
      "Ying Nian Wu",
      "Tuan Do"
    ],
    "pdf_url": "http://arxiv.org/pdf/2510.22527v1"
  },
  {
    "id": "2510.22526v1",
    "title": "Semi-supervised Vertex Hunting, with Applications in Network and Text\n  Analysis",
    "abstract": "Vertex hunting (VH) is the task of estimating a simplex from noisy data\npoints and has many applications in areas such as network and text analysis. We\nintroduce a new variant, semi-supervised vertex hunting (SSVH), in which\npartial information is available in the form of barycentric coordinates for\nsome data points, known only up to an unknown transformation. To address this\nproblem, we develop a method that leverages properties of orthogonal projection\nmatrices, drawing on novel insights from linear algebra. We establish\ntheoretical error bounds for our method and demonstrate that it achieves a\nfaster convergence rate than existing unsupervised VH algorithms. Finally, we\napply SSVH to two practical settings, semi-supervised network mixed membership\nestimation and semi-supervised topic modeling, resulting in efficient and\nscalable algorithms.",
    "categories": [
      "stat.ME",
      "cs.LG"
    ],
    "published": "2025-10-26T04:26:26Z",
    "authors": [
      "Yicong Jiang",
      "Zheng Tracy Ke"
    ],
    "pdf_url": "http://arxiv.org/pdf/2510.22526v1"
  },
  {
    "id": "2510.22521v1",
    "title": "Open Multimodal Retrieval-Augmented Factual Image Generation",
    "abstract": "Large Multimodal Models (LMMs) have achieved remarkable progress in\ngenerating photorealistic and prompt-aligned images, but they often produce\noutputs that contradict verifiable knowledge, especially when prompts involve\nfine-grained attributes or time-sensitive events. Conventional\nretrieval-augmented approaches attempt to address this issue by introducing\nexternal information, yet they are fundamentally incapable of grounding\ngeneration in accurate and evolving knowledge due to their reliance on static\nsources and shallow evidence integration. To bridge this gap, we introduce\nORIG, an agentic open multimodal retrieval-augmented framework for Factual\nImage Generation (FIG), a new task that requires both visual realism and\nfactual grounding. ORIG iteratively retrieves and filters multimodal evidence\nfrom the web and incrementally integrates the refined knowledge into enriched\nprompts to guide generation. To support systematic evaluation, we build\nFIG-Eval, a benchmark spanning ten categories across perceptual, compositional,\nand temporal dimensions. Experiments demonstrate that ORIG substantially\nimproves factual consistency and overall image quality over strong baselines,\nhighlighting the potential of open multimodal retrieval for factual image\ngeneration.",
    "categories": [
      "cs.CV",
      "cs.AI",
      "cs.IR",
      "cs.LG"
    ],
    "published": "2025-10-26T04:13:31Z",
    "authors": [
      "Yang Tian",
      "Fan Liu",
      "Jingyuan Zhang",
      "Wei Bi",
      "Yupeng Hu",
      "Liqiang Nie"
    ],
    "pdf_url": "http://arxiv.org/pdf/2510.22521v1"
  },
  {
    "id": "2510.22520v1",
    "title": "Random Search Neural Networks for Efficient and Expressive Graph\n  Learning",
    "abstract": "Random walk neural networks (RWNNs) have emerged as a promising approach for\ngraph representation learning, leveraging recent advances in sequence models to\nprocess random walks. However, under realistic sampling constraints, RWNNs\noften fail to capture global structure even in small graphs due to incomplete\nnode and edge coverage, limiting their expressivity. To address this, we\npropose \\textit{random search neural networks} (RSNNs), which operate on random\nsearches, each of which guarantees full node coverage. Theoretically, we\ndemonstrate that in sparse graphs, only $O(\\log |V|)$ searches are needed to\nachieve full edge coverage, substantially reducing sampling complexity compared\nto the $O(|V|)$ walks required by RWNNs (assuming walk lengths scale with graph\nsize). Furthermore, when paired with universal sequence models, RSNNs are\nuniversal approximators. We lastly show RSNNs are probabilistically invariant\nto graph isomorphisms, ensuring their expectation is an isomorphism-invariant\ngraph function. Empirically, RSNNs consistently outperform RWNNs on molecular\nand protein benchmarks, achieving comparable or superior performance with up to\n16$\\times$ fewer sampled sequences. Our work bridges theoretical and practical\nadvances in random walk based approaches, offering an efficient and expressive\nframework for learning on sparse graphs.",
    "categories": [
      "cs.LG"
    ],
    "published": "2025-10-26T04:03:54Z",
    "authors": [
      "Michael Ito",
      "Danai Koutra",
      "Jenna Wiens"
    ],
    "pdf_url": "http://arxiv.org/pdf/2510.22520v1"
  },
  {
    "id": "2510.22519v1",
    "title": "A Scalable Global Optimization Algorithm For Constrained Clustering",
    "abstract": "Constrained clustering leverages limited domain knowledge to improve\nclustering performance and interpretability, but incorporating pairwise\nmust-link and cannot-link constraints is an NP-hard challenge, making global\noptimization intractable. Existing mixed-integer optimization methods are\nconfined to small-scale datasets, limiting their utility. We propose\nSample-Driven Constrained Group-Based Branch-and-Bound (SDC-GBB), a\ndecomposable branch-and-bound (BB) framework that collapses must-linked samples\ninto centroid-based pseudo-samples and prunes cannot-link through geometric\nrules, while preserving convergence and guaranteeing global optimality. By\nintegrating grouped-sample Lagrangian decomposition and geometric elimination\nrules for efficient lower and upper bounds, the algorithm attains highly\nscalable pairwise k-Means constrained clustering via parallelism. Experimental\nresults show that our approach handles datasets with 200,000 samples with\ncannot-link constraints and 1,500,000 samples with must-link constraints, which\nis 200 - 1500 times larger than the current state-of-the-art under comparable\nconstraint settings, while reaching an optimality gap of less than 3%. In\nproviding deterministic global guarantees, our method also avoids the search\nfailures that off-the-shelf heuristics often encounter on large datasets.",
    "categories": [
      "cs.LG"
    ],
    "published": "2025-10-26T04:01:07Z",
    "authors": [
      "Pedro Chumpitaz-Flores",
      "My Duong",
      "Cristobal Heredia",
      "Kaixun Hua"
    ],
    "pdf_url": "http://arxiv.org/pdf/2510.22519v1"
  },
  {
    "id": "2510.22517v1",
    "title": "Smart Sensor Placement: A Correlation-Aware Attribution Framework (CAAF)\n  for Real-world Data Modeling",
    "abstract": "Optimal sensor placement (OSP) is critical for efficient, accurate\nmonitoring, control, and inference in complex real-world systems. We propose a\nmachine-learning-based feature attribution framework to identify OSP for the\nprediction of quantities of interest. Feature attribution quantifies input\ncontributions to a model's output; however, it struggles with highly correlated\ninput data often encountered in real-world applications. To address this, we\npropose a Correlation-Aware Attribution Framework (CAAF), which introduces a\nclustering step before performing feature attribution to reduce redundancy and\nenhance generalizability. We first illustrate the core principles of the\nproposed framework through a series of validation cases, then demonstrate its\neffectiveness in real-world dynamical systems, such as structural health\nmonitoring, airfoil lift prediction, and wall-normal velocity estimation for\nturbulent channel flow. The results show that the CAAF outperforms alternative\napproaches that typically struggle due to the presence of nonlinear dynamics,\nchaotic behavior, and multi-scale interactions, and enables the effective\napplication of feature attribution for identifying OSP in real-world\nenvironments.",
    "categories": [
      "cs.CE",
      "cs.LG",
      "cs.SY",
      "eess.SY"
    ],
    "published": "2025-10-26T03:50:16Z",
    "authors": [
      "Sze Chai Leung",
      "Di Zhou",
      "H. Jane Bae"
    ],
    "pdf_url": "http://arxiv.org/pdf/2510.22517v1"
  },
  {
    "id": "2510.22513v1",
    "title": "Toward Robust Signed Graph Learning through Joint Input-Target Denoising",
    "abstract": "Signed Graph Neural Networks (SGNNs) are widely adopted to analyze complex\npatterns in signed graphs with both positive and negative links. Given the\nnoisy nature of real-world connections, the robustness of SGNN has also emerged\nas a pivotal research area. Under the supervision of empirical properties,\ngraph structure learning has shown its robustness on signed graph\nrepresentation learning, however, there remains a paucity of research\ninvestigating a robust SGNN with theoretical guidance. Inspired by the success\nof graph information bottleneck (GIB) in information extraction, we propose\nRIDGE, a novel framework for Robust sI gned graph learning through joint\nDenoising of Graph inputs and supervision targEts. Different from the basic\nGIB, we extend the GIB theory with the capability of target space denoising as\nthe co-existence of noise in both input and target spaces. In instantiation,\nRIDGE effectively cleanses input data and supervision targets via a tractable\nobjective function produced by reparameterization mechanism and variational\napproximation. We extensively validate our method on four prevalent signed\ngraph datasets, and the results show that RIDGE clearly improves the robustness\nof popular SGNN models under various levels of noise.",
    "categories": [
      "cs.LG",
      "cs.AI"
    ],
    "published": "2025-10-26T03:34:40Z",
    "authors": [
      "Junran Wu",
      "Beng Chin Ooi",
      "Ke Xu"
    ],
    "pdf_url": "http://arxiv.org/pdf/2510.22513v1"
  },
  {
    "id": "2510.22512v1",
    "title": "Transitive RL: Value Learning via Divide and Conquer",
    "abstract": "In this work, we present Transitive Reinforcement Learning (TRL), a new value\nlearning algorithm based on a divide-and-conquer paradigm. TRL is designed for\noffline goal-conditioned reinforcement learning (GCRL) problems, where the aim\nis to find a policy that can reach any state from any other state in the\nsmallest number of steps. TRL converts a triangle inequality structure present\nin GCRL into a practical divide-and-conquer value update rule. This has several\nadvantages compared to alternative value learning paradigms. Compared to\ntemporal difference (TD) methods, TRL suffers less from bias accumulation, as\nin principle it only requires $O(\\log T)$ recursions (as opposed to $O(T)$ in\nTD learning) to handle a length-$T$ trajectory. Unlike Monte Carlo methods, TRL\nsuffers less from high variance as it performs dynamic programming.\nExperimentally, we show that TRL achieves the best performance in highly\nchallenging, long-horizon benchmark tasks compared to previous offline GCRL\nalgorithms.",
    "categories": [
      "cs.LG",
      "cs.AI"
    ],
    "published": "2025-10-26T03:32:31Z",
    "authors": [
      "Seohong Park",
      "Aditya Oberai",
      "Pranav Atreya",
      "Sergey Levine"
    ],
    "pdf_url": "http://arxiv.org/pdf/2510.22512v1"
  },
  {
    "id": "2510.22510v2",
    "title": "CANDI: Hybrid Discrete-Continuous Diffusion Models",
    "abstract": "While continuous diffusion has shown remarkable success in continuous domains\nsuch as image generation, its direct application to discrete data has\nunderperformed compared to purely discrete formulations. This gap is\ncounterintuitive, given that continuous diffusion learns score functions that\nenable joint evolution across multiple positions. To understand this gap, we\nintroduce token identifiability as an analytical framework for understanding\nhow Gaussian noise corrupts discrete data through two mechanisms: discrete\nidentity corruption and continuous rank degradation. We reveal that these\nmechanisms scale differently with vocabulary size, creating a temporal\ndissonance: at noise levels where discrete corruption preserves enough\nstructure for conditional learning, continuous denoising is trivial; at noise\nlevels where continuous denoising is meaningful, discrete corruption destroys\nnearly all conditional structure. To solve this, we propose CANDI (Continuous\nANd DIscrete diffusion), a hybrid framework that decouples discrete and\ncontinuous corruption, enabling simultaneous learning of both conditional\nstructure and continuous geometry. We empirically validate the temporal\ndissonance phenomenon and demonstrate that CANDI successfully avoids it. This\nunlocks the benefits of continuous diffusion for discrete spaces: on controlled\ngeneration, CANDI enables classifier-based guidance with off-the-shelf\nclassifiers through simple gradient addition; on text generation, CANDI\noutperforms masked diffusion at low NFE, demonstrating the value of learning\ncontinuous gradients for discrete spaces. We include the code on the project\npage available here: https://patrickpynadath1.github.io/candi-lander",
    "categories": [
      "cs.LG",
      "stat.ML"
    ],
    "published": "2025-10-26T03:24:31Z",
    "authors": [
      "Patrick Pynadath",
      "Jiaxin Shi",
      "Ruqi Zhang"
    ],
    "pdf_url": "http://arxiv.org/pdf/2510.22510v2"
  },
  {
    "id": "2510.23658v1",
    "title": "Aligning Diffusion Language Models via Unpaired Preference Optimization",
    "abstract": "Diffusion language models (dLLMs) are an emerging alternative to\nautoregressive (AR) generators, but aligning them to human preferences is\nchallenging because sequence log-likelihoods are intractable and pairwise\npreference data are costly to collect. We introduce ELBO-KTO, which combines an\nELBO surrogate for diffusion log-likelihoods with a prospect-theoretic,\nunpaired preference objective (Kahneman Tversky Optimization, KTO). We analyze\nthe bias and variance induced by the ELBO substitution and employ\nvariance-reduction practices that stabilize gradients during training. Applied\nto LLaDA-8B-Instruct, ELBO-KTO yields \\textbf{65.9\\%} and \\textbf{62.3\\%}\nadjusted win rates on kto-mix-14k and UltraFeedback-Binary, respectively,\nversus the base model under an automatic LLM judge. Across downstream tasks,\nincluding GSM8K, MMLU, and additional reasoning/knowledge benchmarks, ELBO-KTO\ntrained on UltraFeedback-Binary performs on par with or better than the base\nmodel under identical decoding. This establishes unpaired preference\noptimization as a viable alternative to pairwise alignment in diffusion LLMs.",
    "categories": [
      "cs.LG",
      "cs.AI"
    ],
    "published": "2025-10-26T03:02:39Z",
    "authors": [
      "Vaibhav Jindal",
      "Hejian Sang",
      "Chun-Mao Lai",
      "Yanning Chen",
      "Zhipeng Wang"
    ],
    "pdf_url": "http://arxiv.org/pdf/2510.23658v1"
  },
  {
    "id": "2510.22503v1",
    "title": "Accelerating Materials Design via LLM-Guided Evolutionary Search",
    "abstract": "Materials discovery requires navigating vast chemical and structural spaces\nwhile satisfying multiple, often conflicting, objectives. We present LLM-guided\nEvolution for MAterials design (LLEMA), a unified framework that couples the\nscientific knowledge embedded in large language models with chemistry-informed\nevolutionary rules and memory-based refinement. At each iteration, an LLM\nproposes crystallographically specified candidates under explicit property\nconstraints; a surrogate-augmented oracle estimates physicochemical properties;\nand a multi-objective scorer updates success/failure memories to guide\nsubsequent generations. Evaluated on 14 realistic tasks spanning electronics,\nenergy, coatings, optics, and aerospace, LLEMA discovers candidates that are\nchemically plausible, thermodynamically stable, and property-aligned, achieving\nhigher hit-rates and stronger Pareto fronts than generative and LLM-only\nbaselines. Ablation studies confirm the importance of rule-guided generation,\nmemory-based refinement, and surrogate prediction. By enforcing\nsynthesizability and multi-objective trade-offs, LLEMA delivers a principled\npathway to accelerate practical materials discovery.\n  Code: https://github.com/scientific-discovery/LLEMA",
    "categories": [
      "cs.LG",
      "cond-mat.mtrl-sci",
      "cs.AI",
      "cs.NE"
    ],
    "published": "2025-10-26T02:47:15Z",
    "authors": [
      "Nikhil Abhyankar",
      "Sanchit Kabra",
      "Saaketh Desai",
      "Chandan K. Reddy"
    ],
    "pdf_url": "http://arxiv.org/pdf/2510.22503v1"
  },
  {
    "id": "2510.22500v1",
    "title": "Scalable Oversight via Partitioned Human Supervision",
    "abstract": "As artificial intelligence (AI) systems approach and surpass expert human\nperformance across a broad range of tasks, obtaining high-quality human\nsupervision for evaluation and training becomes increasingly challenging. Our\nfocus is on tasks that require deep knowledge and skills of multiple domains.\nUnfortunately, even the best human experts are knowledgeable only in a single\nnarrow area, and will not be able to evaluate the correctness of advanced AI\nsystems on such superhuman tasks. However, based on their narrow expertise,\nhumans may provide a weak signal, i.e., a complementary label indicating an\noption that is incorrect. For example, a cardiologist could state that \"this is\nnot related to cardiology,'' even if they cannot identify the true disease.\nBased on this weak signal, we propose a scalable oversight framework that\nenables us to evaluate frontier AI systems without the need to prepare the\nground truth. We derive an unbiased estimator of top-1 accuracy from\ncomplementary labels and quantify how many complementary labels are needed to\nmatch the variance of ordinary labels. We further introduce two estimators to\ncombine scarce ordinary labels with abundant complementary labels. We provide\nfinite-sample deviation guarantees for both complementary-only and the mixed\nestimators. Empirically, we show that we can evaluate the output of large\nlanguage models without the ground truth, if we have complementary labels. We\nfurther show that we can train an AI system with such weak signals: we show how\nwe can design an agentic AI system automatically that can perform better with\nthis partitioned human supervision. Our code is available at\nhttps://github.com/R-Yin-217/Scalable-Oversight-via-Human-Partitioned-Supervision.",
    "categories": [
      "cs.LG",
      "cs.AI",
      "cs.CL"
    ],
    "published": "2025-10-26T02:42:03Z",
    "authors": [
      "Ren Yin",
      "Takashi Ishida",
      "Masashi Sugiyama"
    ],
    "pdf_url": "http://arxiv.org/pdf/2510.22500v1"
  },
  {
    "id": "2510.22497v1",
    "title": "Multi-Scale Finite Expression Method for PDEs with Oscillatory Solutions\n  on Complex Domains",
    "abstract": "Solving partial differential equations (PDEs) with highly oscillatory\nsolutions on complex domains remains a challenging and important problem.\nHigh-frequency oscillations and intricate geometries often result in\nprohibitively expensive representations for traditional numerical methods and\nlead to difficult optimization landscapes for machine learning-based\napproaches. In this work, we introduce an enhanced Finite Expression Method\n(FEX) designed to address these challenges with improved accuracy,\ninterpretability, and computational efficiency. The proposed framework\nincorporates three key innovations: a symbolic spectral composition module that\nenables FEX to learn and represent multiscale oscillatory behavior; a\nredesigned linear input layer that significantly expands the expressivity of\nthe model; and an eigenvalue formulation that extends FEX to a new class of\nproblems involving eigenvalue PDEs. Through extensive numerical experiments, we\ndemonstrate that FEX accurately resolves oscillatory PDEs on domains containing\nmultiple holes of varying shapes and sizes. Compared with existing neural\nnetwork-based solvers, FEX achieves substantially higher accuracy while\nyielding interpretable, closed-form solutions that expose the underlying\nstructure of the problem. These advantages, often absent in conventional finite\nelement, finite difference, and black-box neural approaches, highlight FEX as a\npowerful and transparent framework for solving complex PDEs.",
    "categories": [
      "math.NA",
      "cs.LG",
      "cs.NA"
    ],
    "published": "2025-10-26T02:26:49Z",
    "authors": [
      "Gareth Hardwick",
      "Haizhao Yang"
    ],
    "pdf_url": "http://arxiv.org/pdf/2510.22497v1"
  },
  {
    "id": "2510.22491v1",
    "title": "LAMP: Data-Efficient Linear Affine Weight-Space Models for\n  Parameter-Controlled 3D Shape Generation and Extrapolation",
    "abstract": "Generating high-fidelity 3D geometries that satisfy specific parameter\nconstraints has broad applications in design and engineering. However, current\nmethods typically rely on large training datasets and struggle with\ncontrollability and generalization beyond the training distributions. To\novercome these limitations, we introduce LAMP (Linear Affine Mixing of\nParametric shapes), a data-efficient framework for controllable and\ninterpretable 3D generation. LAMP first aligns signed distance function (SDF)\ndecoders by overfitting each exemplar from a shared initialization, then\nsynthesizes new geometries by solving a parameter-constrained mixing problem in\nthe aligned weight space. To ensure robustness, we further propose a safety\nmetric that detects geometry validity via linearity mismatch. We evaluate LAMP\non two 3D parametric benchmarks: DrivAerNet++ and BlendedNet. We found that\nLAMP enables (i) controlled interpolation within bounds with as few as 100\nsamples, (ii) safe extrapolation by up to 100% parameter difference beyond\ntraining ranges, (iii) physics performance-guided optimization under fixed\nparameters. LAMP significantly outperforms conditional autoencoder and Deep\nNetwork Interpolation (DNI) baselines in both extrapolation and data\nefficiency. Our results demonstrate that LAMP advances controllable,\ndata-efficient, and safe 3D generation for design exploration, dataset\ngeneration, and performance-driven optimization.",
    "categories": [
      "cs.LG",
      "cs.CE",
      "cs.CV"
    ],
    "published": "2025-10-26T02:12:20Z",
    "authors": [
      "Ghadi Nehme",
      "Yanxia Zhang",
      "Dule Shu",
      "Matt Klenk",
      "Faez Ahmed"
    ],
    "pdf_url": "http://arxiv.org/pdf/2510.22491v1"
  },
  {
    "id": "2510.22489v1",
    "title": "Frustratingly Easy Task-aware Pruning for Large Language Models",
    "abstract": "Pruning provides a practical solution to reduce the resources required to run\nlarge language models (LLMs) to benefit from their effective capabilities as\nwell as control their cost for training and inference. Research on LLM pruning\noften ranks the importance of LLM parameters using their magnitudes and\ncalibration-data activations and removes (or masks) the less important ones,\naccordingly reducing LLMs' size. However, these approaches primarily focus on\npreserving the LLM's ability to generate fluent sentences, while neglecting\nperformance on specific domains and tasks. In this paper, we propose a simple\nyet effective pruning approach for LLMs that preserves task-specific\ncapabilities while shrinking their parameter space. We first analyze how\nconventional pruning minimizes loss perturbation under general-domain\ncalibration and extend this formulation by incorporating task-specific feature\ndistributions into the importance computation of existing pruning algorithms.\nThus, our framework computes separate importance scores using both general and\ntask-specific calibration data, partitions parameters into shared and exclusive\ngroups based on activation-norm differences, and then fuses their scores to\nguide the pruning process. This design enables our method to integrate\nseamlessly with various foundation pruning techniques and preserve the LLM's\nspecialized abilities under compression. Experiments on widely used benchmarks\ndemonstrate that our approach is effective and consistently outperforms the\nbaselines with identical pruning ratios and different settings.",
    "categories": [
      "cs.CL",
      "cs.LG"
    ],
    "published": "2025-10-26T02:09:22Z",
    "authors": [
      "Yuanhe Tian",
      "Junjie Liu",
      "Xican Yang",
      "Haishan Ye",
      "Yan Song"
    ],
    "pdf_url": "http://arxiv.org/pdf/2510.22489v1"
  },
  {
    "id": "2510.22481v1",
    "title": "An Analytic Theory of Quantum Imaginary Time Evolution",
    "abstract": "Quantum imaginary time evolution (QITE) algorithm is one of the most\npromising variational quantum algorithms (VQAs), bridging the current era of\nNoisy Intermediate-Scale Quantum devices and the future of fully fault-tolerant\nquantum computing. Although practical demonstrations of QITE and its potential\nadvantages over the general VQA trained with vanilla gradient descent (GD) in\ncertain tasks have been reported, a first-principle, theoretical understanding\nof QITE remains limited. Here, we aim to develop an analytic theory for the\ndynamics of QITE. First, we show that QITE can be interpreted as a form of a\ngeneral VQA trained with Quantum Natural Gradient Descent (QNGD), where the\ninverse quantum Fisher information matrix serves as the learning-rate tensor.\nThis equivalence is established not only at the level of gradient update rules,\nbut also through the action principle: the variational principle can be\ndirectly connected to the geometric geodesic distance in the quantum Fisher\ninformation metric, up to an integration constant. Second, for wide quantum\nneural networks, we employ the quantum neural tangent kernel framework to\nconstruct an analytic model for QITE. We prove that QITE always converges\nfaster than GD-based VQA, though this advantage is suppressed by the\nexponential growth of Hilbert space dimension. This helps explain certain\nexperimental results in quantum computational chemistry. Our theory encompasses\nlinear, quadratic, and more general loss functions. We validate the analytic\nresults through numerical simulations. Our findings establish a theoretical\nfoundation for QITE dynamics and provide analytic insights for the\nfirst-principle design of variational quantum algorithms.",
    "categories": [
      "quant-ph",
      "cs.AI",
      "cs.LG",
      "stat.ML"
    ],
    "published": "2025-10-26T01:43:55Z",
    "authors": [
      "Min Chen",
      "Bingzhi Zhang",
      "Quntao Zhuang",
      "Junyu Liu"
    ],
    "pdf_url": "http://arxiv.org/pdf/2510.22481v1"
  },
  {
    "id": "2510.22479v1",
    "title": "Contextual Tokenization for Graph Inverted Indices",
    "abstract": "Retrieving graphs from a large corpus, that contain a subgraph isomorphic to\na given query graph, is a core operation in many real-world applications. While\nrecent multi-vector graph representations and scores based on set alignment and\ncontainment can provide accurate subgraph isomorphism tests, their use in\nretrieval remains limited by their need to score corpus graphs exhaustively. We\nintroduce CORGII (Contextual Representation of Graphs for Inverted Indexing), a\ngraph indexing framework in which, starting with a contextual dense graph\nrepresentation, a differentiable discretization module computes sparse binary\ncodes over a learned latent vocabulary. This text document-like representation\nallows us to leverage classic, highly optimized inverted indices, while\nsupporting soft (vector) set containment scores. Pushing this paradigm further,\nwe replace the classical, fixed impact weight of a `token' on a graph (such as\nTFIDF or BM25) with a data-driven, trainable impact weight. Finally, we explore\ntoken expansion to support multi-probing the index for smoother\naccuracy-efficiency tradeoffs. To our knowledge, CORGII is the first indexer of\ndense graph representations using discrete tokens mapping to efficient inverted\nlists. Extensive experiments show that CORGII provides better trade-offs\nbetween accuracy and efficiency, compared to several baselines.",
    "categories": [
      "cs.LG"
    ],
    "published": "2025-10-26T01:38:16Z",
    "authors": [
      "Pritish Chakraborty",
      "Indradyumna Roy",
      "Soumen Chakrabarti",
      "Abir De"
    ],
    "pdf_url": "http://arxiv.org/pdf/2510.22479v1"
  },
  {
    "id": "2510.23657v1",
    "title": "A machine learning framework integrating seed traits and plasma\n  parameters for predicting germination uplift in crops",
    "abstract": "Cold plasma (CP) is an eco-friendly method to enhance seed germination, yet\noutcomes remain difficult to predict due to complex seed--plasma--environment\ninteractions. This study introduces the first machine learning framework to\nforecast germination uplift in soybean, barley, sunflower, radish, and tomato\nunder dielectric barrier discharge (DBD) plasma. Among the models tested (GB,\nXGB, ET, and hybrids), Extra Trees (ET) performed best (R\\textsuperscript{2} =\n0.919; RMSE = 3.21; MAE = 2.62), improving to R\\textsuperscript{2} = 0.925\nafter feature reduction. Engineering analysis revealed a hormetic response:\nnegligible effects at $<$7 kV or $<$200 s, maximum germination at 7--15 kV for\n200--500 s, and reduced germination beyond 20 kV or prolonged exposures.\nDischarge power was also a dominant factor, with germination rate maximizing at\n$\\geq$100 W with low exposure time. Species and cultivar-level predictions\nshowed radish (MAE = 1.46) and soybean (MAE = 2.05) were modeled with high\nconsistency, while sunflower remained slightly higher variable (MAE = 3.80).\nAmong cultivars, Williams (MAE = 1.23) and Sari (1.33) were well predicted,\nwhile Arian (2.86) and Ny\\'{\\i}rs\\'{e}gi fekete (3.74) were comparatively\npoorly captured. This framework was also embedded into MLflow, providing a\ndecision-support tool for optimizing CP seed germination in precision\nagriculture.",
    "categories": [
      "cs.LG"
    ],
    "published": "2025-10-26T01:25:24Z",
    "authors": [
      "Saklain Niam",
      "Tashfiqur Rahman",
      "Md. Amjad Patwary",
      "Mukarram Hossain"
    ],
    "pdf_url": "http://arxiv.org/pdf/2510.23657v1"
  },
  {
    "id": "2510.22471v1",
    "title": "Learning Local Stackelberg Equilibria from Repeated Interactions with a\n  Learning Agent",
    "abstract": "Motivated by the question of how a principal can maximize its utility in\nrepeated interactions with a learning agent, we study repeated games between an\nprincipal and an agent employing a mean-based learning algorithm. Prior work\nhas shown that computing or even approximating the global Stackelberg value in\nsimilar settings can require an exponential number of rounds in the size of the\nagent's action space, making it computationally intractable. In contrast, we\nshift focus to the computation of local Stackelberg equilibria and introduce an\nalgorithm that, within the smoothed analysis framework, constitutes a\nPolynomial Time Approximation Scheme (PTAS) for finding an epsilon-approximate\nlocal Stackelberg equilibrium. Notably, the algorithm's runtime is polynomial\nin the size of the agent's action space yet exponential in (1/epsilon) - a\ndependency we prove to be unavoidable.",
    "categories": [
      "cs.GT",
      "cs.LG"
    ],
    "published": "2025-10-26T01:09:15Z",
    "authors": [
      "Nivasini Ananthakrishnan",
      "Yuval Dagan",
      "Kunhe Yang"
    ],
    "pdf_url": "http://arxiv.org/pdf/2510.22471v1"
  },
  {
    "id": "2510.22467v1",
    "title": "Backward-Friendly Optimization: Training Large Language Models with\n  Approximate Gradients under Memory Constraints",
    "abstract": "Full fine-tuning of Large Language Models (LLMs) is notoriously\nmemory-intensive, primarily because conventional optimizers such as SGD or Adam\nassume access to exact gradients derived from cached activations. Existing\nsolutions either alter the model architecture (e.g., reversible networks) or\ntrade memory for computation (e.g., activation checkpointing), but the\noptimizer itself remains untouched. In this work, we introduce GradLite, a\nbackward-friendly optimizer that relaxes the requirement of exact gradients,\nenabling efficient training even when intermediate activations are aggressively\ndiscarded or approximated. GradLite leverages two key techniques: (i) low-rank\nJacobian approximation, which reduces the dimensionality of backpropagated\nerror signals, and (ii) error-feedback correction, which accumulates and\ncompensates approximation errors across iterations to preserve convergence\nguarantees. We provide a theoretical analysis showing that GradLite maintains\nunbiased gradient estimates with bounded variance, ensuring convergence rates\ncomparable to Adam. Empirically, GradLite reduces optimizer-state and\nactivation memory consumption by up to 50\\% without architectural changes, and\nachieves on-par or superior downstream performance on reasoning (MMLU, GSM8K),\nmultilingual, and dialogue benchmarks compared to checkpointing and\noptimizer-centric baselines (LoMo, GaLore).",
    "categories": [
      "cs.LG",
      "cs.AI"
    ],
    "published": "2025-10-26T00:50:12Z",
    "authors": [
      "Jing Yang",
      "Kaitong Cai",
      "Yijia Fan",
      "Yufeng Yang",
      "Keze Wang"
    ],
    "pdf_url": "http://arxiv.org/pdf/2510.22467v1"
  },
  {
    "id": "2510.23656v1",
    "title": "Error Adjustment Based on Spatiotemporal Correlation Fusion for Traffic\n  Forecasting",
    "abstract": "Deep neural networks (DNNs) play a significant role in an increasing body of\nresearch on traffic forecasting due to their effectively capturing\nspatiotemporal patterns embedded in traffic data. A general assumption of\ntraining the said forecasting models via mean squared error estimation is that\nthe errors across time steps and spatial positions are uncorrelated. However,\nthis assumption does not really hold because of the autocorrelation caused by\nboth the temporality and spatiality of traffic data. This gap limits the\nperformance of DNN-based forecasting models and is overlooked by current\nstudies. To fill up this gap, this paper proposes Spatiotemporally\nAutocorrelated Error Adjustment (SAEA), a novel and general framework designed\nto systematically adjust autocorrelated prediction errors in traffic\nforecasting. Unlike existing approaches that assume prediction errors follow a\nrandom Gaussian noise distribution, SAEA models these errors as a\nspatiotemporal vector autoregressive (VAR) process to capture their intrinsic\ndependencies. First, it explicitly captures both spatial and temporal error\ncorrelations by a coefficient matrix, which is then embedded into a newly\nformulated cost function. Second, a structurally sparse regularization is\nintroduced to incorporate prior spatial information, ensuring that the learned\ncoefficient matrix aligns with the inherent road network structure. Finally, an\ninference process with test-time error adjustment is designed to dynamically\nrefine predictions, mitigating the impact of autocorrelated errors in real-time\nforecasting. The effectiveness of the proposed approach is verified on\ndifferent traffic datasets. Results across a wide range of traffic forecasting\nmodels show that our method enhances performance in almost all cases.",
    "categories": [
      "cs.LG",
      "cs.AI"
    ],
    "published": "2025-10-25T23:48:50Z",
    "authors": [
      "Fuqiang Liu",
      "Weiping Ding",
      "Luis Miranda-Moreno",
      "Lijun Sun"
    ],
    "pdf_url": "http://arxiv.org/pdf/2510.23656v1"
  },
  {
    "id": "2510.22452v1",
    "title": "Confidence Sets for Multidimensional Scaling",
    "abstract": "We develop a formal statistical framework for classical multidimensional\nscaling (CMDS) applied to noisy dissimilarity data. We establish distributional\nconvergence results for the embeddings produced by CMDS for various noise\nmodels, which enable the construction of \\emph{bona~fide} uniform confidence\nsets for the latent configuration, up to rigid transformations. We further\npropose bootstrap procedures for constructing these confidence sets and provide\ntheoretical guarantees for their validity. We find that the multiplier\nbootstrap adapts automatically to heteroscedastic noise such as multiplicative\nnoise, while the empirical bootstrap seems to require homoscedasticity. Either\nform of bootstrap, when valid, is shown to substantially improve finite-sample\naccuracy. The empirical performance of the proposed methods is demonstrated\nthrough numerical experiments.",
    "categories": [
      "math.ST",
      "cs.LG",
      "stat.ML",
      "stat.TH",
      "62H12, 62F40, 62E20, 62G05, 62R07, 91C15",
      "G.3; F.2.2"
    ],
    "published": "2025-10-25T23:02:10Z",
    "authors": [
      "Siddharth Vishwanath",
      "Ery Arias-Castro"
    ],
    "pdf_url": "http://arxiv.org/pdf/2510.22452v1"
  },
  {
    "id": "2510.22451v1",
    "title": "GraphTOP: Graph Topology-Oriented Prompting for Graph Neural Networks",
    "abstract": "Graph Neural Networks (GNNs) have revolutionized the field of graph learning\nby learning expressive graph representations from massive graph data. As a\ncommon pattern to train powerful GNNs, the \"pre-training, adaptation\" scheme\nfirst pre-trains GNNs over unlabeled graph data and subsequently adapts them to\nspecific downstream tasks. In the adaptation phase, graph prompting is an\neffective strategy that modifies input graph data with learnable prompts while\nkeeping pre-trained GNN models frozen. Typically, existing graph prompting\nstudies mainly focus on *feature-oriented* methods that apply graph prompts to\nnode features or hidden representations. However, these studies often achieve\nsuboptimal performance, as they consistently overlook the potential of\n*topology-oriented* prompting, which adapts pre-trained GNNs by modifying the\ngraph topology. In this study, we conduct a pioneering investigation of graph\nprompting in terms of graph topology. We propose the first **Graph**\n**T**opology-**O**riented **P**rompting (GraphTOP) framework to effectively\nadapt pre-trained GNN models for downstream tasks. More specifically, we\nreformulate topology-oriented prompting as an edge rewiring problem within\nmulti-hop local subgraphs and relax it into the continuous probability space\nthrough reparameterization while ensuring tight relaxation and preserving graph\nsparsity. Extensive experiments on five graph datasets under four pre-training\nstrategies demonstrate that our proposed GraphTOP outshines six baselines on\nmultiple node classification datasets. Our code is available at\nhttps://github.com/xbfu/GraphTOP.",
    "categories": [
      "cs.LG",
      "cs.AI"
    ],
    "published": "2025-10-25T22:50:12Z",
    "authors": [
      "Xingbo Fu",
      "Zhenyu Lei",
      "Zihan Chen",
      "Binchi Zhang",
      "Chuxu Zhang",
      "Jundong Li"
    ],
    "pdf_url": "http://arxiv.org/pdf/2510.22451v1"
  },
  {
    "id": "2510.22450v1",
    "title": "SmartMixed: A Two-Phase Training Strategy for Adaptive Activation\n  Function Learning in Neural Networks",
    "abstract": "The choice of activation function plays a critical role in neural networks,\nyet most architectures still rely on fixed, uniform activation functions across\nall neurons. We introduce SmartMixed, a two-phase training strategy that allows\nnetworks to learn optimal per-neuron activation functions while preserving\ncomputational efficiency at inference. In the first phase, neurons adaptively\nselect from a pool of candidate activation functions (ReLU, Sigmoid, Tanh,\nLeaky ReLU, ELU, SELU) using a differentiable hard-mixture mechanism. In the\nsecond phase, each neuron's activation function is fixed according to the\nlearned selection, resulting in a computationally efficient network that\nsupports continued training with optimized vectorized operations. We evaluate\nSmartMixed on the MNIST dataset using feedforward neural networks of varying\ndepths. The analysis shows that neurons in different layers exhibit distinct\npreferences for activation functions, providing insights into the functional\ndiversity within neural architectures.",
    "categories": [
      "cs.LG",
      "cs.AI"
    ],
    "published": "2025-10-25T22:46:37Z",
    "authors": [
      "Amin Omidvar"
    ],
    "pdf_url": "http://arxiv.org/pdf/2510.22450v1"
  },
  {
    "id": "2510.22443v1",
    "title": "Benchmarking Egocentric Multimodal Goal Inference for Assistive Wearable\n  Agents",
    "abstract": "There has been a surge of interest in assistive wearable agents: agents\nembodied in wearable form factors (e.g., smart glasses) who take assistive\nactions toward a user's goal/query (e.g. \"Where did I leave my keys?\"). In this\nwork, we consider the important complementary problem of inferring that goal\nfrom multi-modal contextual observations. Solving this \"goal inference\" problem\nholds the promise of eliminating the effort needed to interact with such an\nagent. This work focuses on creating WAGIBench, a strong benchmark to measure\nprogress in solving this problem using vision-language models (VLMs). Given the\nlimited prior work in this area, we collected a novel dataset comprising 29\nhours of multimodal data from 348 participants across 3,477 recordings,\nfeaturing ground-truth goals alongside accompanying visual, audio, digital, and\nlongitudinal contextual observations. We validate that human performance\nexceeds model performance, achieving 93% multiple-choice accuracy compared with\n84% for the best-performing VLM. Generative benchmark results that evaluate\nseveral families of modern vision-language models show that larger models\nperform significantly better on the task, yet remain far from practical\nusefulness, as they produce relevant goals only 55% of the time. Through a\nmodality ablation, we show that models benefit from extra information in\nrelevant modalities with minimal performance degradation from irrelevant\nmodalities.",
    "categories": [
      "cs.CV",
      "cs.LG"
    ],
    "published": "2025-10-25T21:54:01Z",
    "authors": [
      "Vijay Veerabadran",
      "Fanyi Xiao",
      "Nitin Kamra",
      "Pedro Matias",
      "Joy Chen",
      "Caley Drooff",
      "Brett D Roads",
      "Riley Williams",
      "Ethan Henderson",
      "Xuanyi Zhao",
      "Kevin Carlberg",
      "Joseph Tighe",
      "Karl Ridgeway"
    ],
    "pdf_url": "http://arxiv.org/pdf/2510.22443v1"
  },
  {
    "id": "2510.22440v1",
    "title": "Low-Precision Streaming PCA",
    "abstract": "Low-precision streaming PCA estimates the top principal component in a\nstreaming setting under limited precision. We establish an\ninformation-theoretic lower bound on the quantization resolution required to\nachieve a target accuracy for the leading eigenvector. We study Oja's algorithm\nfor streaming PCA under linear and nonlinear stochastic quantization. The\nquantized variants use unbiased stochastic quantization of the weight vector\nand the updates. Under mild moment and spectral-gap assumptions on the data\ndistribution, we show that a batched version achieves the lower bound up to\nlogarithmic factors under both schemes. This leads to a nearly dimension-free\nquantization error in the nonlinear quantization setting. Empirical evaluations\non synthetic streams validate our theoretical findings and demonstrate that our\nlow-precision methods closely track the performance of standard Oja's\nalgorithm.",
    "categories": [
      "cs.LG",
      "stat.ML"
    ],
    "published": "2025-10-25T21:48:17Z",
    "authors": [
      "Sanjoy Dasgupta",
      "Syamantak Kumar",
      "Shourya Pandey",
      "Purnamrita Sarkar"
    ],
    "pdf_url": "http://arxiv.org/pdf/2510.22440v1"
  },
  {
    "id": "2510.22424v1",
    "title": "Reinforcement learning-guided optimization of critical current in\n  high-temperature superconductors",
    "abstract": "High-temperature superconductors are essential for next-generation energy and\nquantum technologies, yet their performance is often limited by the critical\ncurrent density ($J_c$), which is strongly influenced by microstructural\ndefects. Optimizing $J_c$ through defect engineering is challenging due to the\ncomplex interplay of defect type, density, and spatial correlation. Here we\npresent an integrated workflow that combines reinforcement learning (RL) with\ntime-dependent Ginzburg-Landau (TDGL) simulations to autonomously identify\noptimal defect configurations that maximize $J_c$. In our framework, TDGL\nsimulations generate current-voltage characteristics to evaluate $J_c$, which\nserves as the reward signal that guides the RL agent to iteratively refine\ndefect configurations. We find that the agent discovers optimal defect\ndensities and correlations in two-dimensional thin-film geometries, enhancing\nvortex pinning and $J_c$ relative to the pristine thin-film, approaching 60\\%\nof theoretical depairing limit with up to 15-fold enhancement compared to\nrandom initialization. This RL-driven approach provides a scalable strategy for\ndefect engineering, with broad implications for advancing HTS applications in\nfusion magnets, particle accelerators, and other high-field technologies.",
    "categories": [
      "cond-mat.mtrl-sci",
      "cond-mat.supr-con",
      "cs.LG"
    ],
    "published": "2025-10-25T20:01:33Z",
    "authors": [
      "Mouyang Cheng",
      "Qiwei Wan",
      "Bowen Yu",
      "Eunbi Rha",
      "Michael J Landry",
      "Mingda Li"
    ],
    "pdf_url": "http://arxiv.org/pdf/2510.22424v1"
  },
  {
    "id": "2510.22421v1",
    "title": "Extragradient Method for $(L_0, L_1)$-Lipschitz Root-finding Problems",
    "abstract": "Introduced by Korpelevich in 1976, the extragradient method (EG) has become a\ncornerstone technique for solving min-max optimization, root-finding problems,\nand variational inequalities (VIs). Despite its longstanding presence and\nsignificant attention within the optimization community, most works focusing on\nunderstanding its convergence guarantees assume the strong L-Lipschitz\ncondition. In this work, building on the proposed assumptions by Zhang et al.\n[2024b] for minimization and Vankov et al.[2024] for VIs, we focus on the more\nrelaxed $\\alpha$-symmetric $(L_0, L_1)$-Lipschitz condition. This condition\ngeneralizes the standard Lipschitz assumption by allowing the Lipschitz\nconstant to scale with the operator norm, providing a more refined\ncharacterization of problem structures in modern machine learning. Under the\n$\\alpha$-symmetric $(L_0, L_1)$-Lipschitz condition, we propose a novel step\nsize strategy for EG to solve root-finding problems and establish sublinear\nconvergence rates for monotone operators and linear convergence rates for\nstrongly monotone operators. Additionally, we prove local convergence\nguarantees for weak Minty operators. We supplement our analysis with\nexperiments validating our theory and demonstrating the effectiveness and\nrobustness of the proposed step sizes for EG.",
    "categories": [
      "math.OC",
      "cs.LG"
    ],
    "published": "2025-10-25T19:43:01Z",
    "authors": [
      "Sayantan Choudhury",
      "Nicolas Loizou"
    ],
    "pdf_url": "http://arxiv.org/pdf/2510.22421v1"
  },
  {
    "id": "2510.22419v1",
    "title": "Beyond Isotonization: Scalable Non-Crossing Quantile Estimation via\n  Neural Networks for Student Growth Percentiles",
    "abstract": "Student Growth Percentiles (SGPs), widely adopted across U.S. state\nassessment systems, employ independent quantile regression followed by post-hoc\ncorrection using an isotonic projection method (\\texttt{isotonize=TRUE} in the\n\\texttt{SGP} R package) to address quantile crossing. We demonstrate this\napproach contains a fundamental methodological inconsistency: interpolation\nbetween independently-estimated, potentially crossed quantiles requires\nmonotonicity, yet the post-hoc correction alters estimates in ways that may\nviolate the quantile property $P(Y \\leq \\hat{Q}_{\\tau}(Y|X) \\mid X) = \\tau$. We\nterm this the \\emph{interpolation paradox}. While theoretically sound\nconstrained joint quantile regression (CJQR) eliminates crossing by enforcing\nnon-crossing constraints during optimization, we analyze its computational\ncomplexity (often scaling poorly, e.g., $\\mathcal{O}((qn)^3)$ for standard LP\nsolvers) rendering it intractable for large-scale educational data ($n >\n100{,}000$). We examine the SGP package's switch to the Frisch-Newton interior\npoint method (\\texttt{rq.method.for.large.n=\"fn\"}) for large $N$, noting that\nwhile efficient for \\emph{independent} QR, it doesn't resolve the joint\nproblem's complexity or the paradox. We propose neural network-based\nmulti-quantile regression (NNQR) with shared hidden layers as a practical\nalternative. Leveraging the convexity of the composite pinball loss, SGD-based\noptimization used in NN training can reliably approach the global optimum,\noffering scalability ($O(n)$) and implicitly reducing crossing. Our empirical\nanalysis shows independent QR yields crossing, while both CJQR and NNQR enforce\nmonotonicity. NNQR emerges as a viable, scalable alternative for operational\nSGP systems, aligning theoretical validity with computational feasibility.",
    "categories": [
      "stat.ML",
      "cs.LG"
    ],
    "published": "2025-10-25T19:39:07Z",
    "authors": [
      "Kaihua Chang"
    ],
    "pdf_url": "http://arxiv.org/pdf/2510.22419v1"
  },
  {
    "id": "2510.22405v1",
    "title": "Knowledge-guided Continual Learning for Behavioral Analytics Systems",
    "abstract": "User behavior on online platforms is evolving, reflecting real-world changes\nin how people post, whether it's helpful messages or hate speech. Models that\nlearn to capture this content can experience a decrease in performance over\ntime due to data drift, which can lead to ineffective behavioral analytics\nsystems. However, fine-tuning such a model over time with new data can be\ndetrimental due to catastrophic forgetting. Replay-based approaches in\ncontinual learning offer a simple yet efficient method to update such models,\nminimizing forgetting by maintaining a buffer of important training instances\nfrom past learned tasks. However, the main limitation of this approach is the\nfixed size of the buffer. External knowledge bases can be utilized to overcome\nthis limitation through data augmentation. We propose a novel\naugmentation-based approach to incorporate external knowledge in the\nreplay-based continual learning framework. We evaluate several strategies with\nthree datasets from prior studies related to deviant behavior classification to\nassess the integration of external knowledge in continual learning and\ndemonstrate that augmentation helps outperform baseline replay-based\napproaches.",
    "categories": [
      "cs.LG",
      "cs.AI"
    ],
    "published": "2025-10-25T19:04:14Z",
    "authors": [
      "Yasas Senarath",
      "Hemant Purohit"
    ],
    "pdf_url": "http://arxiv.org/pdf/2510.22405v1"
  },
  {
    "id": "2510.22397v1",
    "title": "NetBurst: Event-Centric Forecasting of Bursty, Intermittent Time Series",
    "abstract": "Forecasting on widely used benchmark time series data (e.g., ETT,\nElectricity, Taxi, and Exchange Rate, etc.) has favored smooth, seasonal\nseries, but network telemetry time series -- traffic measurements at service,\nIP, or subnet granularity -- are instead highly bursty and intermittent, with\nheavy-tailed bursts and highly variable inactive periods. These properties\nplace the latter in the statistical regimes made famous and popularized more\nthan 20 years ago by B.~Mandelbrot. Yet forecasting such time series with\nmodern-day AI architectures remains underexplored. We introduce NetBurst, an\nevent-centric framework that reformulates forecasting as predicting when bursts\noccur and how large they are, using quantile-based codebooks and dual\nautoregressors. Across large-scale sets of production network telemetry time\nseries and compared to strong baselines, such as Chronos, NetBurst reduces Mean\nAverage Scaled Error (MASE) by 13--605x on service-level time series while\npreserving burstiness and producing embeddings that cluster 5x more cleanly\nthan Chronos. In effect, our work highlights the benefits that modern AI can\nreap from leveraging Mandelbrot's pioneering studies for forecasting in bursty,\nintermittent, and heavy-tailed regimes, where its operational value for\nhigh-stakes decision making is of paramount interest.",
    "categories": [
      "cs.NI",
      "cs.LG"
    ],
    "published": "2025-10-25T18:48:17Z",
    "authors": [
      "Satyandra Guthula",
      "Jaber Daneshamooz",
      "Charles Fleming",
      "Ashish Kundu",
      "Walter Willinger",
      "Arpit Gupta"
    ],
    "pdf_url": "http://arxiv.org/pdf/2510.22397v1"
  },
  {
    "id": "2510.22387v1",
    "title": "Privacy-Aware Federated nnU-Net for ECG Page Digitization",
    "abstract": "Deep neural networks can convert ECG page images into analyzable waveforms,\nyet centralized training often conflicts with cross-institutional privacy and\ndeployment constraints. A cross-silo federated digitization framework is\npresented that trains a full-model nnU-Net segmentation backbone without\nsharing images and aggregates updates across sites under realistic non-IID\nheterogeneity (layout, grid style, scanner profile, noise).\n  The protocol integrates three standard server-side aggregators--FedAvg,\nFedProx, and FedAdam--and couples secure aggregation with central, user-level\ndifferential privacy to align utility with formal guarantees. Key features\ninclude: (i) end-to-end full-model training and synchronization across clients;\n(ii) secure aggregation so the server only observes a clipped, weighted sum\nonce a participation threshold is met; (iii) central Gaussian DP with Renyi\naccounting applied post-aggregation for auditable user-level privacy; and (iv)\na calibration-aware digitization pipeline comprising page normalization, trace\nsegmentation, grid-leakage suppression, and vectorization to twelve-lead\nsignals.\n  Experiments on ECG pages rendered from PTB-XL show consistently faster\nconvergence and higher late-round plateaus with adaptive server updates\n(FedAdam) relative to FedAvg and FedProx, while approaching centralized\nperformance. The privacy mechanism maintains competitive accuracy while\npreventing exposure of raw images or per-client updates, yielding deployable,\nauditable guarantees suitable for multi-institution settings.",
    "categories": [
      "cs.CR",
      "cs.CV",
      "cs.LG"
    ],
    "published": "2025-10-25T18:10:05Z",
    "authors": [
      "Nader Nemati"
    ],
    "pdf_url": "http://arxiv.org/pdf/2510.22387v1"
  },
  {
    "id": "2510.22383v1",
    "title": "Dynamic Dropout: Leveraging Conway's Game of Life for Neural Networks\n  Regularization",
    "abstract": "Regularization techniques play a crucial role in preventing overfitting and\nimproving the generalization performance of neural networks. Dropout, a widely\nused regularization technique, randomly deactivates units during training to\nintroduce redundancy and prevent co-adaptation among neurons. Despite its\neffectiveness, dropout has limitations, such as its static nature and lack of\ninterpretability. In this paper, we propose a novel approach to regularization\nby substituting dropout with Conway's Game of Life (GoL), a cellular automata\nwith simple rules that govern the evolution of a grid of cells. We introduce\ndynamic unit deactivation during training by representing neural network units\nas cells in a GoL grid and applying the game's rules to deactivate units. This\napproach allows for the emergence of spatial patterns that adapt to the\ntraining data, potentially enhancing the network's ability to generalize. We\ndemonstrate the effectiveness of our approach on the CIFAR-10 dataset, showing\nthat dynamic unit deactivation using GoL achieves comparable performance to\ntraditional dropout techniques while offering insights into the network's\nbehavior through the visualization of evolving patterns. Furthermore, our\ndiscussion highlights the applicability of our proposal in deeper\narchitectures, demonstrating how it enhances the performance of different\ndropout techniques.",
    "categories": [
      "cs.LG",
      "cs.AI",
      "cs.CV"
    ],
    "published": "2025-10-25T17:55:13Z",
    "authors": [
      "David Freire-Obreg\u00f3n",
      "Jos\u00e9 Salas-C\u00e1ceres",
      "Modesto Castrill\u00f3n-Santana"
    ],
    "pdf_url": "http://arxiv.org/pdf/2510.22383v1"
  },
  {
    "id": "2510.22379v2",
    "title": "TraceTrans: Translation and Spatial Tracing for Surgical Prediction",
    "abstract": "Image-to-image translation models have achieved notable success in converting\nimages across visual domains and are increasingly used for medical tasks such\nas predicting post-operative outcomes and modeling disease progression.\nHowever, most existing methods primarily aim to match the target distribution\nand often neglect spatial correspondences between the source and translated\nimages. This limitation can lead to structural inconsistencies and\nhallucinations, undermining the reliability and interpretability of the\npredictions. These challenges are accentuated in clinical applications by the\nstringent requirement for anatomical accuracy. In this work, we present\nTraceTrans, a novel deformable image translation model designed for\npost-operative prediction that generates images aligned with the target\ndistribution while explicitly revealing spatial correspondences with the\npre-operative input. The framework employs an encoder for feature extraction\nand dual decoders for predicting spatial deformations and synthesizing the\ntranslated image. The predicted deformation field imposes spatial constraints\non the generated output, ensuring anatomical consistency with the source.\nExtensive experiments on medical cosmetology and brain MRI datasets demonstrate\nthat TraceTrans delivers accurate and interpretable post-operative predictions,\nhighlighting its potential for reliable clinical deployment.",
    "categories": [
      "eess.IV",
      "cs.AI",
      "cs.CV",
      "cs.LG"
    ],
    "published": "2025-10-25T17:48:46Z",
    "authors": [
      "Xiyu Luo",
      "Haodong Li",
      "Xinxing Cheng",
      "He Zhao",
      "Yang Hu",
      "Xuan Song",
      "Tianyang Zhang"
    ],
    "pdf_url": "http://arxiv.org/pdf/2510.22379v2"
  },
  {
    "id": "2510.22376v1",
    "title": "Label Smoothing Improves Gradient Ascent in LLM Unlearning",
    "abstract": "LLM unlearning has emerged as a promising approach, aiming to enable models\nto forget hazardous/undesired knowledge at low cost while preserving as much\nmodel utility as possible. Among existing techniques, the most straightforward\nmethod is performing Gradient Ascent (GA) w.r.t. the forget data, thereby\nforcing the model to unlearn the forget dataset. However, GA suffers from\nsevere instability, as it drives updates in a divergent direction, often\nresulting in drastically degraded model utility. To address this issue, we\npropose Smoothed Gradient Ascent (SGA). SGA combines the forget data with\nmultiple constructed normal data through a tunable smoothing rate. Intuitively,\nthis extends GA from learning solely on the forget data to jointly learning\nacross both forget and normal data, enabling more stable unlearning while\nbetter preserving model utility. Theoretically, we provide the theoretical\nguidance on the selection of the optimal smoothing rate. Empirically, we\nevaluate SGA on three benchmarks: TOFU, Harry Potter, and MUSE-NEWS.\nExperimental results demonstrate that SGA consistently outperforms the original\nGradient Ascent (GA) method across all metrics and achieves top-2 performance\namong all baseline methods on several key metrics.",
    "categories": [
      "cs.LG",
      "cs.CL"
    ],
    "published": "2025-10-25T17:43:34Z",
    "authors": [
      "Zirui Pang",
      "Hao Zheng",
      "Zhijie Deng",
      "Ling Li",
      "Zixin Zhong",
      "Jiaheng Wei"
    ],
    "pdf_url": "http://arxiv.org/pdf/2510.22376v1"
  },
  {
    "id": "2510.22370v1",
    "title": "BLIP-FusePPO: A Vision-Language Deep Reinforcement Learning Framework\n  for Lane Keeping in Autonomous Vehicles",
    "abstract": "In this paper, we propose Bootstrapped Language-Image Pretraining-driven\nFused State Representation in Proximal Policy Optimization (BLIP-FusePPO), a\nnovel multimodal reinforcement learning (RL) framework for autonomous\nlane-keeping (LK), in which semantic embeddings generated by a vision-language\nmodel (VLM) are directly fused with geometric states, LiDAR observations, and\nProportional-Integral-Derivative-based (PID) control feedback within the agent\nobservation space. The proposed method lets the agent learn driving rules that\nare aware of their surroundings and easy to understand by combining high-level\nscene understanding from the VLM with low-level control and spatial signals.\nOur architecture brings together semantic, geometric, and control-aware\nrepresentations to make policy learning more robust. A hybrid reward function\nthat includes semantic alignment, LK accuracy, obstacle avoidance, and speed\nregulation helps learning to be more efficient and generalizable. Our method is\ndifferent from the approaches that only use semantic models to shape rewards.\nInstead, it directly embeds semantic features into the state representation.\nThis cuts down on expensive runtime inference and makes sure that semantic\nguidance is always available. The simulation results show that the proposed\nmodel is better at LK stability and adaptability than the best vision-based and\nmultimodal RL baselines in a wide range of difficult driving situations. We\nmake our code publicly available.",
    "categories": [
      "cs.RO",
      "cs.AI",
      "cs.CV",
      "cs.LG",
      "cs.SE"
    ],
    "published": "2025-10-25T17:27:08Z",
    "authors": [
      "Seyed Ahmad Hosseini Miangoleh",
      "Amin Jalal Aghdasian",
      "Farzaneh Abdollahi"
    ],
    "pdf_url": "http://arxiv.org/pdf/2510.22370v1"
  },
  {
    "id": "2510.22363v1",
    "title": "Bias Begins with Data: The FairGround Corpus for Robust and Reproducible\n  Research on Algorithmic Fairness",
    "abstract": "As machine learning (ML) systems are increasingly adopted in high-stakes\ndecision-making domains, ensuring fairness in their outputs has become a\ncentral challenge. At the core of fair ML research are the datasets used to\ninvestigate bias and develop mitigation strategies. Yet, much of the existing\nwork relies on a narrow selection of datasets--often arbitrarily chosen,\ninconsistently processed, and lacking in diversity--undermining the\ngeneralizability and reproducibility of results.\n  To address these limitations, we present FairGround: a unified framework,\ndata corpus, and Python package aimed at advancing reproducible research and\ncritical data studies in fair ML classification. FairGround currently comprises\n44 tabular datasets, each annotated with rich fairness-relevant metadata. Our\naccompanying Python package standardizes dataset loading, preprocessing,\ntransformation, and splitting, streamlining experimental workflows. By\nproviding a diverse and well-documented dataset corpus along with robust\ntooling, FairGround enables the development of fairer, more reliable, and more\nreproducible ML models. All resources are publicly available to support open\nand collaborative research.",
    "categories": [
      "cs.LG",
      "cs.CY",
      "stat.ML"
    ],
    "published": "2025-10-25T16:48:33Z",
    "authors": [
      "Jan Simson",
      "Alessandro Fabris",
      "Cosima Fr\u00f6hner",
      "Frauke Kreuter",
      "Christoph Kern"
    ],
    "pdf_url": "http://arxiv.org/pdf/2510.22363v1"
  },
  {
    "id": "2510.22362v1",
    "title": "Mapping Faithful Reasoning in Language Models",
    "abstract": "Chain-of-thought (CoT) traces promise transparency for reasoning language\nmodels, but prior work shows they are not always faithful reflections of\ninternal computation. This raises challenges for oversight: practitioners may\nmisinterpret decorative reasoning as genuine. We introduce Concept Walk, a\ngeneral framework for tracing how a model's internal stance evolves with\nrespect to a concept direction during reasoning. Unlike surface text, Concept\nWalk operates in activation space, projecting each reasoning step onto the\nconcept direction learned from contrastive data. This allows us to observe\nwhether reasoning traces shape outcomes or are discarded. As a case study, we\napply Concept Walk to the domain of Safety using Qwen 3-4B. We find that in\n'easy' cases, perturbed CoTs are quickly ignored, indicating decorative\nreasoning, whereas in 'hard' cases, perturbations induce sustained shifts in\ninternal activations, consistent with faithful reasoning. The contribution is\nmethodological: Concept Walk provides a lens to re-examine faithfulness through\nconcept-specific internal dynamics, helping identify when reasoning traces can\nbe trusted and when they risk misleading practitioners.",
    "categories": [
      "cs.LG",
      "cs.CL"
    ],
    "published": "2025-10-25T16:48:19Z",
    "authors": [
      "Jiazheng Li",
      "Andreas Damianou",
      "J Rosser",
      "Jos\u00e9 Luis Redondo Garc\u00eda",
      "Konstantina Palla"
    ],
    "pdf_url": "http://arxiv.org/pdf/2510.22362v1"
  },
  {
    "id": "2510.23652v1",
    "title": "The Structural Scalpel: Automated Contiguous Layer Pruning for Large\n  Language Models",
    "abstract": "Although large language models (LLMs) have achieved revolutionary\nbreakthroughs in many fields, their large model size and high computational\ncost pose significant challenges for practical deployment on\nresource-constrained edge devices. To this end, layer pruning has been proposed\nto reduce the computational overhead by directly removing redundant layers.\nHowever, existing layer pruning methods typically rely on hand-crafted metrics\nto evaluate and remove individual layers, while ignoring the dependencies\nbetween layers. This can disrupt the model's information flow and severely\ndegrade performance. To address these issues, we propose CLP, a novel\ncontinuous layer pruning framework that introduces two key innovations: a\ndifferentiable concave gate algorithm that automatically identifies the best\ncontinuous layer segments for pruning via gradient-based optimization; and a\ncutoff endpoint tuning strategy that effectively restores model performance by\nfine-tuning only the layers adjacent to the pruned segments. Extensive\nexperiments across multiple model architectures (including LLaMA2, LLaMA3 and\nQwen) and sizes (from $7$B to $70$B parameters) show that CLP significantly\noutperforms existing state-of-the-art baselines. For example, at a pruning rate\nof $20\\%$, CLP achieves an average performance retention of $95.34\\%$ on\nLLaMA3-70B, outperforming baselines by $4.29\\%$-$30.52\\%$. Furthermore, CLP can\nbe seamlessly combined with quantization to further compress the model with\nonly a slight performance loss.",
    "categories": [
      "cs.LG",
      "cs.AI"
    ],
    "published": "2025-10-25T16:40:17Z",
    "authors": [
      "Yao Lu",
      "Yuqi Li",
      "Wenbin Xie",
      "Shanqing Yu",
      "Qi Xuan",
      "Zhaowei Zhu",
      "Shiping Wen"
    ],
    "pdf_url": "http://arxiv.org/pdf/2510.23652v1"
  },
  {
    "id": "2510.22345v1",
    "title": "Uncertainty quantification in model discovery by distilling\n  interpretable material constitutive models from Gaussian process posteriors",
    "abstract": "Constitutive model discovery refers to the task of identifying an appropriate\nmodel structure, usually from a predefined model library, while simultaneously\ninferring its material parameters. The data used for model discovery are\nmeasured in mechanical tests and are thus inevitably affected by noise which,\nin turn, induces uncertainties. Previously proposed methods for uncertainty\nquantification in model discovery either require the selection of a prior for\nthe material parameters, are restricted to the linear coefficients of the model\nlibrary or are limited in the flexibility of the inferred parameter probability\ndistribution. We therefore propose a four-step partially Bayesian framework for\nuncertainty quantification in model discovery that does not require prior\nselection for the material parameters and also allows for the discovery of\nnon-linear constitutive models: First, we augment the available\nstress-deformation data with a Gaussian process. Second, we approximate the\nparameter distribution by a normalizing flow, which allows for capturing\ncomplex joint distributions. Third, we distill the parameter distribution by\nmatching the distribution of stress-deformation functions induced by the\nparameters with the Gaussian process posterior. Fourth, we perform a Sobol'\nsensitivity analysis to obtain a sparse and interpretable model. We demonstrate\nthe capability of our framework for both isotropic and anisotropic experimental\ndata as well as linear and non-linear model libraries.",
    "categories": [
      "cs.LG",
      "stat.ML"
    ],
    "published": "2025-10-25T16:02:03Z",
    "authors": [
      "David Anton",
      "Henning Wessels",
      "Ulrich R\u00f6mer",
      "Alexander Henkes",
      "Jorge-Humberto Urrea-Quintero"
    ],
    "pdf_url": "http://arxiv.org/pdf/2510.22345v1"
  },
  {
    "id": "2510.22340v1",
    "title": "DynaSolidGeo: A Dynamic Benchmark for Genuine Spatial Mathematical\n  Reasoning of VLMs in Solid Geometry",
    "abstract": "Solid geometry problem solving demands spatial mathematical reasoning that\nintegrates spatial intelligence and symbolic reasoning. However, most existing\nmultimodal mathematical reasoning benchmarks focus primarily on 2D plane\ngeometry, rely on static datasets prone to data contamination and memorization,\nand evaluate models solely by final answers, overlooking the reasoning process.\nTo address these limitations, we introduce DynaSolidGeo, the first dynamic\nbenchmark for evaluating genuine spatial reasoning in Vision-Language Models\n(VLMs). Constructed through a semi-automatic annotation pipeline, DynaSolidGeo\ncontains 503 expert-curated seed questions that can, in principle, dynamically\ngenerate an unbounded number of diverse multimodal text-visual instances.\nBeyond answer accuracy, we incorporate process evaluation based on\nexpert-annotated reasoning chains to measure logical validity and causal\ncoherence. Experiments across representative open-source and closed-source VLMs\nreveal large performance gaps, severe degradation in dynamic settings, and poor\nperformance on tasks requiring high-level spatial intelligence, such as mental\nrotation and visualization. The code and dataset are available at\n\\href{https://zgca-ai4edu.github.io/DynaSolidGeo/}{DynaSolidGeo}.",
    "categories": [
      "cs.AI",
      "cs.CL",
      "cs.CV",
      "cs.LG"
    ],
    "published": "2025-10-25T15:49:45Z",
    "authors": [
      "Changti Wu",
      "Shijie Lian",
      "Zihao Liu",
      "Lei Zhang",
      "Laurence Tianruo Yang",
      "Kai Chen"
    ],
    "pdf_url": "http://arxiv.org/pdf/2510.22340v1"
  },
  {
    "id": "2510.22333v1",
    "title": "LIFT: Interpretable truck driving risk prediction with\n  literature-informed fine-tuned LLMs",
    "abstract": "This study proposes an interpretable prediction framework with\nliterature-informed fine-tuned (LIFT) LLMs for truck driving risk prediction.\nThe framework integrates an LLM-driven Inference Core that predicts and\nexplains truck driving risk, a Literature Processing Pipeline that filters and\nsummarizes domain-specific literature into a literature knowledge base, and a\nResult Evaluator that evaluates the prediction performance as well as the\ninterpretability of the LIFT LLM. After fine-tuning on a real-world truck\ndriving risk dataset, the LIFT LLM achieved accurate risk prediction,\noutperforming benchmark models by 26.7% in recall and 10.1% in F1-score.\nFurthermore, guided by the literature knowledge base automatically constructed\nfrom 299 domain papers, the LIFT LLM produced variable importance ranking\nconsistent with that derived from the benchmark model, while demonstrating\nrobustness in interpretation results to various data sampling conditions. The\nLIFT LLM also identified potential risky scenarios by detecting key combination\nof variables in truck driving risk, which were verified by PERMANOVA tests.\nFinally, we demonstrated the contribution of the literature knowledge base and\nthe fine-tuning process in the interpretability of the LIFT LLM, and discussed\nthe potential of the LIFT LLM in data-driven knowledge discovery.",
    "categories": [
      "cs.AI",
      "cs.LG"
    ],
    "published": "2025-10-25T15:37:56Z",
    "authors": [
      "Xiao Hu",
      "Yuansheng Lian",
      "Ke Zhang",
      "Yunxuan Li",
      "Yuelong Su",
      "Meng Li"
    ],
    "pdf_url": "http://arxiv.org/pdf/2510.22333v1"
  },
  {
    "id": "2510.22332v1",
    "title": "Transformer Key-Value Memories Are Nearly as Interpretable as Sparse\n  Autoencoders",
    "abstract": "Recent interpretability work on large language models (LLMs) has been\nincreasingly dominated by a feature-discovery approach with the help of proxy\nmodules. Then, the quality of features learned by, e.g., sparse auto-encoders\n(SAEs), is evaluated. This paradigm naturally raises a critical question: do\nsuch learned features have better properties than those already represented\nwithin the original model parameters, and unfortunately, only a few studies\nhave made such comparisons systematically so far. In this work, we revisit the\ninterpretability of feature vectors stored in feed-forward (FF) layers, given\nthe perspective of FF as key-value memories, with modern interpretability\nbenchmarks. Our extensive evaluation revealed that SAE and FFs exhibits a\nsimilar range of interpretability, although SAEs displayed an observable but\nminimal improvement in some aspects. Furthermore, in certain aspects,\nsurprisingly, even vanilla FFs yielded better interpretability than the SAEs,\nand features discovered in SAEs and FFs diverged. These bring questions about\nthe advantage of SAEs from both perspectives of feature quality and\nfaithfulness, compared to directly interpreting FF feature vectors, and FF\nkey-value parameters serve as a strong baseline in modern interpretability\nresearch.",
    "categories": [
      "cs.LG",
      "stat.ML"
    ],
    "published": "2025-10-25T15:34:31Z",
    "authors": [
      "Mengyu Ye",
      "Jun Suzuki",
      "Tatsuro Inaba",
      "Tatsuki Kuribayashi"
    ],
    "pdf_url": "http://arxiv.org/pdf/2510.22332v1"
  },
  {
    "id": "2510.22327v1",
    "title": "Monitoring State Transitions in Markovian Systems with Sampling Cost",
    "abstract": "We consider a node-monitor pair, where the node's state varies with time. The\nmonitor needs to track the node's state at all times; however, there is a fixed\ncost for each state query. So the monitor may instead predict the state using\ntime-series forecasting methods, including time-series foundation models\n(TSFMs), and query only when prediction uncertainty is high. Since query\ndecisions influence prediction accuracy, determining when to query is\nnontrivial. A natural approach is a greedy policy that predicts when the\nexpected prediction loss is below the query cost and queries otherwise. We\nanalyze this policy in a Markovian setting, where the optimal (OPT) strategy is\na state-dependent threshold policy minimizing the time-averaged sum of query\ncost and prediction losses. We show that, in general, the greedy policy is\nsuboptimal and can have an unbounded competitive ratio, but under common\nconditions such as identically distributed transition probabilities, it\nperforms close to OPT. For the case of unknown transition probabilities, we\nfurther propose a projected stochastic gradient descent (PSGD)-based learning\nvariant of the greedy policy, which achieves a favorable predict-query tradeoff\nwith improved computational efficiency compared to OPT.",
    "categories": [
      "cs.LG",
      "cs.IT",
      "math.IT",
      "stat.ML"
    ],
    "published": "2025-10-25T15:07:37Z",
    "authors": [
      "Kumar Saurav",
      "Ness B. Shroff",
      "Yingbin Liang"
    ],
    "pdf_url": "http://arxiv.org/pdf/2510.22327v1"
  },
  {
    "id": "2510.22319v2",
    "title": "GRPO-Guard: Mitigating Implicit Over-Optimization in Flow Matching via\n  Regulated Clipping",
    "abstract": "Recently, GRPO-based reinforcement learning has shown remarkable progress in\noptimizing flow-matching models, effectively improving their alignment with\ntask-specific rewards. Within these frameworks, the policy update relies on\nimportance-ratio clipping to constrain overconfident positive and negative\ngradients. However, in practice, we observe a systematic shift in the\nimportance-ratio distribution-its mean falls below 1 and its variance differs\nsubstantially across timesteps. This left-shifted and inconsistent distribution\nprevents positive-advantage samples from entering the clipped region, causing\nthe mechanism to fail in constraining overconfident positive updates. As a\nresult, the policy model inevitably enters an implicit over-optimization\nstage-while the proxy reward continues to increase, essential metrics such as\nimage quality and text-prompt alignment deteriorate sharply, ultimately making\nthe learned policy impractical for real-world use. To address this issue, we\nintroduce GRPO-Guard, a simple yet effective enhancement to existing GRPO\nframeworks. Our method incorporates ratio normalization, which restores a\nbalanced and step-consistent importance ratio, ensuring that PPO clipping\nproperly constrains harmful updates across denoising timesteps. In addition, a\ngradient reweighting strategy equalizes policy gradients over noise conditions,\npreventing excessive updates from particular timestep regions. Together, these\ndesigns act as a regulated clipping mechanism, stabilizing optimization and\nsubstantially mitigating implicit over-optimization without relying on heavy KL\nregularization. Extensive experiments on multiple diffusion backbones (e.g.,\nSD3.5M, Flux.1-dev) and diverse proxy tasks demonstrate that GRPO-Guard\nsignificantly reduces over-optimization while maintaining or even improving\ngeneration quality.",
    "categories": [
      "cs.CV",
      "cs.LG"
    ],
    "published": "2025-10-25T14:51:17Z",
    "authors": [
      "Jing Wang",
      "Jiajun Liang",
      "Jie Liu",
      "Henglin Liu",
      "Gongye Liu",
      "Jun Zheng",
      "Wanyuan Pang",
      "Ao Ma",
      "Zhenyu Xie",
      "Xintao Wang",
      "Meng Wang",
      "Pengfei Wan",
      "Xiaodan Liang"
    ],
    "pdf_url": "http://arxiv.org/pdf/2510.22319v2"
  },
  {
    "id": "2510.22312v1",
    "title": "LacMaterial: Large Language Models as Analogical Chemists for Materials\n  Discovery",
    "abstract": "Analogical reasoning, the transfer of relational structures across contexts\n(e.g., planet is to sun as electron is to nucleus), is fundamental to\nscientific discovery. Yet human insight is often constrained by domain\nexpertise and surface-level biases, limiting access to deeper, structure-driven\nanalogies both within and across disciplines. Large language models (LLMs),\ntrained on vast cross-domain data, present a promising yet underexplored tool\nfor analogical reasoning in science. Here, we demonstrate that LLMs can\ngenerate novel battery materials by (1) retrieving cross-domain analogs and\nanalogy-guided exemplars to steer exploration beyond conventional dopant\nsubstitutions, and (2) constructing in-domain analogical templates from few\nlabeled examples to guide targeted exploitation. These explicit analogical\nreasoning strategies yield candidates outside established compositional spaces\nand outperform standard prompting baselines. Our findings position LLMs as\ninterpretable, expert-like hypothesis generators that leverage analogy-driven\ngeneralization for scientific innovation.",
    "categories": [
      "cs.LG",
      "cs.AI"
    ],
    "published": "2025-10-25T14:25:26Z",
    "authors": [
      "Hongyu Guo"
    ],
    "pdf_url": "http://arxiv.org/pdf/2510.22312v1"
  },
  {
    "id": "2510.22301v1",
    "title": "AnyECG-Lab: An Exploration Study of Fine-tuning an ECG Foundation Model\n  to Estimate Laboratory Values from Single-Lead ECG Signals",
    "abstract": "Timely access to laboratory values is critical for clinical decision-making,\nyet current approaches rely on invasive venous sampling and are intrinsically\ndelayed. Electrocardiography (ECG), as a non-invasive and widely available\nsignal, offers a promising modality for rapid laboratory estimation. Recent\nprogress in deep learning has enabled the extraction of latent hematological\nsignatures from ECGs. However, existing models are constrained by low\nsignal-to-noise ratios, substantial inter-individual variability, limited data\ndiversity, and suboptimal generalization, especially when adapted to low-lead\nwearable devices. In this work, we conduct an exploratory study leveraging\ntransfer learning to fine-tune ECGFounder, a large-scale pre-trained ECG\nfoundation model, on the Multimodal Clinical Monitoring in the Emergency\nDepartment (MC-MED) dataset from Stanford. We generated a corpus of more than\n20 million standardized ten-second ECG segments to enhance sensitivity to\nsubtle biochemical correlates. On internal validation, the model demonstrated\nstrong predictive performance (area under the curve above 0.65) for\nthirty-three laboratory indicators, moderate performance (between 0.55 and\n0.65) for fifty-nine indicators, and limited performance (below 0.55) for\nsixteen indicators. This study provides an efficient artificial-intelligence\ndriven solution and establishes the feasibility scope for real-time,\nnon-invasive estimation of laboratory values.",
    "categories": [
      "cs.LG",
      "cs.AI"
    ],
    "published": "2025-10-25T14:04:26Z",
    "authors": [
      "Yujie Xiao",
      "Gongzhen Tang",
      "Wenhui Liu",
      "Jun Li",
      "Guangkun Nie",
      "Zhuoran Kan",
      "Deyun Zhang",
      "Qinghao Zhao",
      "Shenda Hong"
    ],
    "pdf_url": "http://arxiv.org/pdf/2510.22301v1"
  },
  {
    "id": "2510.22299v1",
    "title": "Stable neural networks and connections to continuous dynamical systems",
    "abstract": "The existence of instabilities, for example in the form of adversarial\nexamples, has given rise to a highly active area of research concerning itself\nwith understanding and enhancing the stability of neural networks. We focus on\na popular branch within this area which draws on connections to continuous\ndynamical systems and optimal control, giving a bird's eye view of this area.\nWe identify and describe the fundamental concepts that underlie much of the\nexisting work in this area. Following this, we go into more detail on a\nspecific approach to designing stable neural networks, developing the\ntheoretical background and giving a description of how these networks can be\nimplemented. We provide code that implements the approach that can be adapted\nand extended by the reader. The code further includes a notebook with a\nfleshed-out toy example on adversarial robustness of image classification that\ncan be run without heavy requirements on the reader's computer. We finish by\ndiscussing this toy example so that the reader can interactively follow along\non their computer. This work will be included as a chapter of a book on\nscientific machine learning, which is currently under revision and aimed at\nstudents.",
    "categories": [
      "math.NA",
      "cs.LG",
      "cs.NA"
    ],
    "published": "2025-10-25T14:00:03Z",
    "authors": [
      "Matthias J. Ehrhardt",
      "Davide Murari",
      "Ferdia Sherry"
    ],
    "pdf_url": "http://arxiv.org/pdf/2510.22299v1"
  },
  {
    "id": "2510.22298v1",
    "title": "MetaCaDI: A Meta-Learning Framework for Scalable Causal Discovery with\n  Unknown Interventions",
    "abstract": "Uncovering the underlying causal mechanisms of complex real-world systems\nremains a significant challenge, as these systems often entail high data\ncollection costs and involve unknown interventions. We introduce MetaCaDI, the\nfirst framework to cast the joint discovery of a causal graph and unknown\ninterventions as a meta-learning problem. MetaCaDI is a Bayesian framework that\nlearns a shared causal graph structure across multiple experiments and is\noptimized to rapidly adapt to new, few-shot intervention target prediction\ntasks. A key innovation is our model's analytical adaptation, which uses a\nclosed-form solution to bypass expensive and potentially unstable\ngradient-based bilevel optimization. Extensive experiments on synthetic and\ncomplex gene expression data demonstrate that MetaCaDI significantly\noutperforms state-of-the-art methods. It excels at both causal graph recovery\nand identifying intervention targets from as few as 10 data instances, proving\nits robustness in data-scarce scenarios.",
    "categories": [
      "stat.ML",
      "cs.LG"
    ],
    "published": "2025-10-25T13:59:42Z",
    "authors": [
      "Hans Jarett Ong",
      "Yoichi Chikahara",
      "Tomoharu Iwata"
    ],
    "pdf_url": "http://arxiv.org/pdf/2510.22298v1"
  },
  {
    "id": "2510.22293v1",
    "title": "Predicting Metabolic Dysfunction-Associated Steatotic Liver Disease\n  using Machine Learning Methods",
    "abstract": "Background: Metabolic Dysfunction-Associated Steatotic Liver Disease (MASLD)\naffects ~33% of U.S. adults and is the most common chronic liver disease.\nAlthough often asymptomatic, progression can lead to cirrhosis. Early detection\nis important, as lifestyle interventions can prevent disease progression. We\ndeveloped a fair, rigorous, and reproducible MASLD prediction model and\ncompared it to prior methods using a large electronic health record database.\n  Methods: We evaluated LASSO logistic regression, random forest, XGBoost, and\na neural network for MASLD prediction using clinical feature subsets, including\nthe top 10 SHAP-ranked features. To reduce disparities in true positive rates\nacross racial and ethnic subgroups, we applied an equal opportunity\npostprocessing method.\n  Results: This study included 59,492 patients in the training data, 24,198 in\nthe validating data, and 25,188 in the testing data. The LASSO logistic\nregression model with the top 10 features was selected for its interpretability\nand comparable performance. Before fairness adjustment, the model achieved\nAUROC of 0.84, accuracy of 78%, sensitivity of 72%, specificity of 79%, and\nF1-score of 0.617. After equal opportunity postprocessing, accuracy modestly\nincreased to 81% and specificity to 94%, while sensitivity decreased to 41% and\nF1-score to 0.515, reflecting the fairness trade-off.\n  Conclusions: We developed the MASER prediction model (MASLD Static EHR Risk\nPrediction), a LASSO logistic regression model which achieved competitive\nperformance for MASLD prediction (AUROC 0.836, accuracy 77.6%), comparable to\npreviously reported ensemble and tree-based models. Overall, this approach\ndemonstrates that interpretable models can achieve a balance of predictive\nperformance and fairness in diverse patient populations.",
    "categories": [
      "cs.LG",
      "cs.CY",
      "q-bio.QM"
    ],
    "published": "2025-10-25T13:36:18Z",
    "authors": [
      "Mary E. An",
      "Paul Griffin",
      "Jonathan G. Stine",
      "Ramakrishna Balakrishnan",
      "Ram Sriram",
      "Soundar Kumara"
    ],
    "pdf_url": "http://arxiv.org/pdf/2510.22293v1"
  },
  {
    "id": "2510.22289v1",
    "title": "Does Homophily Help in Robust Test-time Node Classification?",
    "abstract": "Homophily, the tendency of nodes from the same class to connect, is a\nfundamental property of real-world graphs, underpinning structural and semantic\npatterns in domains such as citation networks and social networks. Existing\nmethods exploit homophily through designing homophily-aware GNN architectures\nor graph structure learning strategies, yet they primarily focus on GNN\nlearning with training graphs. However, in real-world scenarios, test graphs\noften suffer from data quality issues and distribution shifts, such as domain\nshifts across users from different regions in social networks and temporal\nevolution shifts in citation network graphs collected over varying time\nperiods. These factors significantly compromise the pre-trained model's\nrobustness, resulting in degraded test-time performance. With empirical\nobservations and theoretical analysis, we reveal that transforming the test\ngraph structure by increasing homophily in homophilic graphs or decreasing it\nin heterophilic graphs can significantly improve the robustness and performance\nof pre-trained GNNs on node classifications, without requiring model training\nor update. Motivated by these insights, a novel test-time graph structural\ntransformation method grounded in homophily, named GrapHoST, is proposed.\nSpecifically, a homophily predictor is developed to discriminate test edges,\nfacilitating adaptive test-time graph structural transformation by the\nconfidence of predicted homophily scores. Extensive experiments on nine\nbenchmark datasets under a range of test-time data quality issues demonstrate\nthat GrapHoST consistently achieves state-of-the-art performance, with\nimprovements of up to 10.92%. Our code has been released at\nhttps://github.com/YanJiangJerry/GrapHoST.",
    "categories": [
      "cs.LG",
      "cs.AI"
    ],
    "published": "2025-10-25T13:17:28Z",
    "authors": [
      "Yan Jiang",
      "Ruihong Qiu",
      "Zi Huang"
    ],
    "pdf_url": "http://arxiv.org/pdf/2510.22289v1"
  },
  {
    "id": "2510.22287v1",
    "title": "Machine Learning Enabled Early Warning System For Financial Distress\n  Using Real-Time Digital Signals",
    "abstract": "The growing instability of both global and domestic economic environments has\nincreased the risk of financial distress at the household level. However,\ntraditional econometric models often rely on delayed and aggregated data,\nlimiting their effectiveness. This study introduces a machine learning-based\nearly warning system that utilizes real-time digital and macroeconomic signals\nto identify financial distress in near real-time. Using a panel dataset of 750\nhouseholds tracked over three monitoring rounds spanning 13 months, the\nframework combines socioeconomic attributes, macroeconomic indicators (such as\nGDP growth, inflation, and foreign exchange fluctuations), and digital economy\nmeasures (including ICT demand and market volatility). Through data\npreprocessing and feature engineering, we introduce lagged variables,\nvolatility measures, and interaction terms to capture both gradual and sudden\nchanges in financial stability. We benchmark baseline classifiers, such as\nlogistic regression and decision trees, against advanced ensemble models\nincluding random forests, XGBoost, and LightGBM. Our results indicate that the\nengineered features from the digital economy significantly enhance predictive\naccuracy. The system performs reliably for both binary distress detection and\nmulti-class severity classification, with SHAP-based explanations identifying\ninflation volatility and ICT demand as key predictors. Crucially, the framework\nis designed for scalable deployment in national agencies and low-bandwidth\nregional offices, ensuring it is accessible for policymakers and practitioners.\nBy implementing machine learning in a transparent and interpretable manner,\nthis study demonstrates the feasibility and impact of providing near-real-time\nearly warnings of financial distress. This offers actionable insights that can\nstrengthen household resilience and guide preemptive intervention strategies.",
    "categories": [
      "cs.LG",
      "cs.CY"
    ],
    "published": "2025-10-25T13:12:45Z",
    "authors": [
      "Laxmi pant",
      "Syed Ali Reza",
      "Md Khalilor Rahman",
      "MD Saifur Rahman",
      "Shamima Sharmin",
      "Md Fazlul Huq Mithu",
      "Kazi Nehal Hasnain",
      "Adnan Farabi",
      "Mahamuda khanom",
      "Raisul Kabir"
    ],
    "pdf_url": "http://arxiv.org/pdf/2510.22287v1"
  },
  {
    "id": "2510.22283v1",
    "title": "Adapting Noise-Driven PUF and AI for Secure WBG ICS: A Proof-of-Concept\n  Study",
    "abstract": "Wide-bandgap (WBG) technologies offer unprecedented improvements in power\nsystem efficiency, size, and performance, but also introduce unique sensor\ncorruption and cybersecurity risks in industrial control systems (ICS),\nparticularly due to high-frequency noise and sophisticated cyber-physical\nthreats. This proof-of-concept (PoC) study demonstrates the adaptation of a\nnoise-driven physically unclonable function (PUF) and machine learning\n(ML)-assisted anomaly detection framework to the demanding environment of\nWBG-based ICS sensor pathways. By extracting entropy from unavoidable WBG\nswitching noise (up to 100 kHz) as a PUF source, and simultaneously using this\nnoise as a real-time threat indicator, the proposed system unites\nhardware-level authentication and anomaly detection. Our approach integrates\nhybrid machine learning (ML) models with adaptive Bayesian filtering, providing\nrobust and low-latency detection capabilities resilient to both natural\nelectromagnetic interference (EMI) and active adversarial manipulation. Through\ndetailed simulations of WBG modules under benign and attack\nscenarios--including EMI injection, signal tampering, and node\nimpersonation--we achieve 95% detection accuracy and sub-millisecond processing\nlatency. These results demonstrate the feasibility of physics-driven, dual-use\nnoise exploitation as a scalable ICS defense primitive. Our findings lay the\ngroundwork for next-generation security strategies that leverage inherent\ndevice characteristics, bridging hardware and artificial intelligence (AI) for\nenhanced protection of critical ICS infrastructure.",
    "categories": [
      "cs.CR",
      "cs.LG",
      "cs.SY",
      "eess.SY",
      "physics.app-ph"
    ],
    "published": "2025-10-25T12:57:55Z",
    "authors": [
      "Devon A. Kelly",
      "Christiana Chamon"
    ],
    "pdf_url": "http://arxiv.org/pdf/2510.22283v1"
  },
  {
    "id": "2510.23650v1",
    "title": "Beyond Hidden-Layer Manipulation: Semantically-Aware Logit Interventions\n  for Debiasing LLMs",
    "abstract": "We proposed Static and Dynamic -- two zero-shot logits-layer debiasing\nmethods. Dynamic reduces bias by up to 70% with minimal fluency loss. Logits\nintervention outperforms hidden-layer approaches. We show semantic-aware logits\nintervention is stable and effective for debiasing aligned LLMs.",
    "categories": [
      "cs.LG",
      "cs.AI"
    ],
    "published": "2025-10-25T12:45:00Z",
    "authors": [
      "Wei Xia"
    ],
    "pdf_url": "http://arxiv.org/pdf/2510.23650v1"
  },
  {
    "id": "2510.22274v1",
    "title": "SecureLearn -- An Attack-agnostic Defense for Multiclass Machine\n  Learning Against Data Poisoning Attacks",
    "abstract": "Data poisoning attacks are a potential threat to machine learning (ML)\nmodels, aiming to manipulate training datasets to disrupt their performance.\nExisting defenses are mostly designed to mitigate specific poisoning attacks or\nare aligned with particular ML algorithms. Furthermore, most defenses are\ndeveloped to secure deep neural networks or binary classifiers. However,\ntraditional multiclass classifiers need attention to be secure from data\npoisoning attacks, as these models are significant in developing multi-modal\napplications. Therefore, this paper proposes SecureLearn, a two-layer\nattack-agnostic defense to defend multiclass models from poisoning attacks. It\ncomprises two components of data sanitization and a new feature-oriented\nadversarial training. To ascertain the effectiveness of SecureLearn, we\nproposed a 3D evaluation matrix with three orthogonal dimensions: data\npoisoning attack, data sanitization and adversarial training. Benchmarking\nSecureLearn in a 3D matrix, a detailed analysis is conducted at different\npoisoning levels (10%-20%), particularly analysing accuracy, recall, F1-score,\ndetection and correction rates, and false discovery rate. The experimentation\nis conducted for four ML algorithms, namely Random Forest (RF), Decision Tree\n(DT), Gaussian Naive Bayes (GNB) and Multilayer Perceptron (MLP), trained with\nthree public datasets, against three poisoning attacks and compared with two\nexisting mitigations. Our results highlight that SecureLearn is effective\nagainst the provided attacks. SecureLearn has strengthened resilience and\nadversarial robustness of traditional multiclass models and neural networks,\nconfirming its generalization beyond algorithm-specific defenses. It\nconsistently maintained accuracy above 90%, recall and F1-score above 75%. For\nneural networks, SecureLearn achieved 97% recall and F1-score against all\nselected poisoning attacks.",
    "categories": [
      "cs.CR",
      "cs.LG"
    ],
    "published": "2025-10-25T12:35:45Z",
    "authors": [
      "Anum Paracha",
      "Junaid Arshad",
      "Mohamed Ben Farah",
      "Khalid Ismail"
    ],
    "pdf_url": "http://arxiv.org/pdf/2510.22274v1"
  },
  {
    "id": "2510.22266v1",
    "title": "A Multi-level Analysis of Factors Associated with Student Performance: A\n  Machine Learning Approach to the SAEB Microdata",
    "abstract": "Identifying the factors that influence student performance in basic education\nis a central challenge for formulating effective public policies in Brazil.\nThis study introduces a multi-level machine learning approach to classify the\nproficiency of 9th-grade and high school students using microdata from the\nSystem of Assessment of Basic Education (SAEB). Our model uniquely integrates\nfour data sources: student socioeconomic characteristics, teacher professional\nprofiles, school indicators, and director management profiles. A comparative\nanalysis of four ensemble algorithms confirmed the superiority of a Random\nForest model, which achieved 90.2% accuracy and an Area Under the Curve (AUC)\nof 96.7%. To move beyond prediction, we applied Explainable AI (XAI) using\nSHAP, which revealed that the school's average socioeconomic level is the most\ndominant predictor, demonstrating that systemic factors have a greater impact\nthan individual characteristics in isolation. The primary conclusion is that\nacademic performance is a systemic phenomenon deeply tied to the school's\necosystem. This study provides a data-driven, interpretable tool to inform\npolicies aimed at promoting educational equity by addressing disparities\nbetween schools.",
    "categories": [
      "cs.LG",
      "cs.AI",
      "cs.CY"
    ],
    "published": "2025-10-25T12:15:30Z",
    "authors": [
      "Rodrigo Tertulino",
      "Ricardo Almeida"
    ],
    "pdf_url": "http://arxiv.org/pdf/2510.22266v1"
  },
  {
    "id": "2510.22261v1",
    "title": "Epistemic Deep Learning: Enabling Machine Learning Models to Know When\n  They Do Not Know",
    "abstract": "Machine learning has achieved remarkable successes, yet its deployment in\nsafety-critical domains remains hindered by an inherent inability to manage\nuncertainty, resulting in overconfident and unreliable predictions when models\nencounter out-of-distribution data, adversarial perturbations, or naturally\nfluctuating environments. This thesis, titled Epistemic Deep Learning: Enabling\nMachine Learning Models to 'Know When They Do Not Know', addresses these\ncritical challenges by advancing the paradigm of Epistemic Artificial\nIntelligence, which explicitly models and quantifies epistemic uncertainty: the\nuncertainty arising from limited, biased, or incomplete training data, as\nopposed to the irreducible randomness of aleatoric uncertainty, thereby\nempowering models to acknowledge their limitations and refrain from\noverconfident decisions when uncertainty is high.\n  Central to this work is the development of the Random-Set Neural Network\n(RS-NN), a novel methodology that leverages random set theory to predict belief\nfunctions over sets of classes, capturing the extent of epistemic uncertainty\nthrough the width of associated credal sets, applications of RS-NN, including\nits adaptation to Large Language Models (LLMs) and its deployment in weather\nclassification for autonomous racing. In addition, the thesis proposes a\nunified evaluation framework for uncertainty-aware classifiers. Extensive\nexperiments validate that integrating epistemic awareness into deep learning\nnot only mitigates the risks associated with overconfident predictions but also\nlays the foundation for a paradigm shift in artificial intelligence, where the\nability to 'know when it does not know' becomes a hallmark of robust and\ndependable systems. The title encapsulates the core philosophy of this work,\nemphasizing that true intelligence involves recognizing and managing the limits\nof one's own knowledge.",
    "categories": [
      "cs.LG",
      "cs.AI"
    ],
    "published": "2025-10-25T12:00:19Z",
    "authors": [
      "Shireen Kudukkil Manchingal"
    ],
    "pdf_url": "http://arxiv.org/pdf/2510.22261v1"
  },
  {
    "id": "2510.23649v1",
    "title": "Efficient Low Rank Attention for Long-Context Inference in Large\n  Language Models",
    "abstract": "As the length of input text grows, the key-value (KV) cache in LLMs imposes\nprohibitive GPU memory costs and limits long-context inference on resource\nconstrained devices. Existing approaches, such as KV quantization and pruning,\nreduce memory usage but suffer from numerical precision loss or suboptimal\nretention of key-value pairs. We introduce Low Rank Query and Key attention\n(LRQK), a two-stage framework that jointly decomposes the full-precision query\nand key matrices into compact rank-\\(r\\) factors during the prefill stage, and\nthen uses these low-dimensional projections to compute proxy attention scores\nin \\(\\mathcal{O}(lr)\\) time at each decode step. By selecting only the\ntop-\\(k\\) tokens and a small fixed set of recent tokens, LRQK employs a mixed\nGPU-CPU cache with a hit-and-miss mechanism that transfers only missing\nfull-precision KV pairs, thereby preserving exact attention outputs while\nreducing CPU-GPU data movement. Extensive experiments on the RULER and\nLongBench benchmarks with LLaMA-3-8B and Qwen2.5-7B demonstrate that LRQK\nmatches or surpasses leading sparse-attention methods in long context settings,\nwhile delivering significant memory savings with minimal loss in accuracy. Our\ncode is available at https://github.com/tenghuilee/LRQK.",
    "categories": [
      "cs.LG",
      "cs.AI"
    ],
    "published": "2025-10-25T11:43:27Z",
    "authors": [
      "Tenghui Li",
      "Guoxu Zhou",
      "Xuyang Zhao",
      "Yuning Qiu",
      "Qibin Zhao"
    ],
    "pdf_url": "http://arxiv.org/pdf/2510.23649v1"
  },
  {
    "id": "2510.22257v1",
    "title": "LUNA: Efficient and Topology-Agnostic Foundation Model for EEG Signal\n  Analysis",
    "abstract": "Electroencephalography (EEG) offers a non-invasive lens into human brain\nactivity, but building large-scale models is hampered by topological\nheterogeneity: each public EEG data defines its own electrode layout, limiting\ngeneralization. We introduce LUNA (Latent Unified Network Architecture), a\nself-supervised foundation model that reconciles disparate electrode geometries\nwhile scaling linearly -- not quadratically -- with channel count. LUNA\ncompresses multi-channel EEG into a fixed-size, topology-agnostic latent space\nvia learned queries and cross-attention. Downstream transformer blocks then\noperate exclusively on this latent representation using patch-wise temporal\nself-attention, decoupling computation from electrode count. Pre-trained on\nTUEG and Siena (over 21,000 hours of raw EEG across diverse montages) using a\nmasked-patch reconstruction objective, LUNA transfers effectively to four\ndownstream tasks: abnormality detection, artifact rejection, slowing\nclassification, and emotion recognition. It demonstrates highly competitive\nperformance across several benchmarks, achieving state-of-the-art results on\nTUAR and TUSL, e.g., 0.921 AUROC on TUAR, while reducing FLOPs by 300x and\ntrimming GPU memory use by up to 10x. Critically, these gains are consistent\nacross all evaluated electrode configurations. Code is available at\nhttps://github.com/pulp-bio/BioFoundation",
    "categories": [
      "cs.LG",
      "cs.AI"
    ],
    "published": "2025-10-25T11:31:27Z",
    "authors": [
      "Berkay D\u00f6ner",
      "Thorir Mar Ingolfsson",
      "Luca Benini",
      "Yawei Li"
    ],
    "pdf_url": "http://arxiv.org/pdf/2510.22257v1"
  },
  {
    "id": "2510.22251v1",
    "title": "You Don't Need Prompt Engineering Anymore: The Prompting Inversion",
    "abstract": "Prompt engineering, particularly Chain-of-Thought (CoT) prompting,\nsignificantly enhances LLM reasoning capabilities. We introduce \"Sculpting,\" a\nconstrained, rule-based prompting method designed to improve upon standard CoT\nby reducing errors from semantic ambiguity and flawed common sense.\n  We evaluate three prompting strategies (Zero Shot, standard CoT, and\nSculpting) across three OpenAI model generations (gpt-4o-mini, gpt-4o, gpt-5)\nusing the GSM8K mathematical reasoning benchmark (1,317 problems).\n  Our findings reveal a \"Prompting Inversion\": Sculpting provides advantages on\ngpt-4o (97% vs. 93% for standard CoT), but becomes detrimental on gpt-5 (94.00%\nvs. 96.36% for CoT on full benchmark). We trace this to a\n\"Guardrail-to-Handcuff\" transition where constraints preventing common-sense\nerrors in mid-tier models induce hyper-literalism in advanced models. Our\ndetailed error analysis demonstrates that optimal prompting strategies must\nco-evolve with model capabilities, suggesting simpler prompts for more capable\nmodels.",
    "categories": [
      "cs.CL",
      "cs.AI",
      "cs.LG"
    ],
    "published": "2025-10-25T11:04:01Z",
    "authors": [
      "Imran Khan"
    ],
    "pdf_url": "http://arxiv.org/pdf/2510.22251v1"
  },
  {
    "id": "2510.22239v1",
    "title": "Synthetic-to-Real Transfer Learning for Chromatin-Sensitive PWS\n  Microscopy",
    "abstract": "Chromatin sensitive partial wave spectroscopic (csPWS) microscopy enables\nlabel free detection of nanoscale chromatin packing alterations that occur\nbefore visible cellular transformation. However, manual nuclear segmentation\nlimits population scale analysis needed for biomarker discovery in early cancer\ndetection. The lack of annotated csPWS imaging data prevents direct use of\nstandard deep learning methods. We present CFU Net, a hierarchical segmentation\narchitecture trained with a three stage curriculum on synthetic multimodal\ndata. CFU Net achieves near perfect performance on held out synthetic test data\nthat represent diverse spectroscopic imaging conditions without manual\nannotations (Dice 0.9879, IoU 0.9895). Our approach uses physics based\nrendering that incorporates empirically supported chromatin packing statistics,\nMie scattering models, and modality specific noise, combined with a curriculum\nthat progresses from adversarial RGB pretraining to spectroscopic fine tuning\nand histology validation. CFU Net integrates five architectural elements\n(ConvNeXt backbone, Feature Pyramid Network, UNet plus plus dense connections,\ndual attention, and deep supervision) that together improve Dice over a\nbaseline UNet by 8.3 percent. We demonstrate deployment ready INT8 quantization\nwith 74.9 percent compression and 0.15 second inference, giving a 240 times\nthroughput gain over manual analysis. Applied to more than ten thousand\nautomatically segmented nuclei from synthetic test data, the pipeline extracts\nchromatin biomarkers that distinguish normal from pre cancerous tissue with\nlarge effect sizes (Cohens d between 1.31 and 2.98), reaching 94 percent\nclassification accuracy. This work provides a general framework for synthetic\nto real transfer learning in specialized microscopy and open resources for\ncommunity validation on clinical specimens.",
    "categories": [
      "eess.IV",
      "cs.LG",
      "q-bio.QM",
      "68T45, 92C55",
      "I.4.6; I.2.10; I.5.4"
    ],
    "published": "2025-10-25T10:00:34Z",
    "authors": [
      "Jahidul Arafat",
      "Sanjaya Poudel"
    ],
    "pdf_url": "http://arxiv.org/pdf/2510.22239v1"
  },
  {
    "id": "2510.22237v1",
    "title": "Bridging the Perceptual-Statistical Gap in Dysarthria Assessment: Why\n  Machine Learning Still Falls Short",
    "abstract": "Automated dysarthria detection and severity assessment from speech have\nattracted significant research attention due to their potential clinical\nimpact. Despite rapid progress in acoustic modeling and deep learning, models\nstill fall short of human expert performance. This manuscript provides a\ncomprehensive analysis of the reasons behind this gap, emphasizing a conceptual\ndivergence we term the ``perceptual-statistical gap''. We detail human expert\nperceptual processes, survey machine learning representations and methods,\nreview existing literature on feature sets and modeling strategies, and present\na theoretical analysis of limits imposed by label noise and inter-rater\nvariability. We further outline practical strategies to narrow the gap,\nperceptually motivated features, self-supervised pretraining, ASR-informed\nobjectives, multimodal fusion, human-in-the-loop training, and explainability\nmethods. Finally, we propose experimental protocols and evaluation metrics\naligned with clinical goals to guide future research toward clinically reliable\nand interpretable dysarthria assessment tools.",
    "categories": [
      "eess.AS",
      "cs.LG"
    ],
    "published": "2025-10-25T09:44:31Z",
    "authors": [
      "Krishna Gurugubelli"
    ],
    "pdf_url": "http://arxiv.org/pdf/2510.22237v1"
  },
  {
    "id": "2510.22228v1",
    "title": "When Fewer Layers Break More Chains: Layer Pruning Harms Test-Time\n  Scaling in LLMs",
    "abstract": "Layer pruning has emerged as a widely adopted technique for improving the\nefficiency of large language models (LLMs). Although existing methods\ndemonstrate strong performance retention on general knowledge tasks, their\neffect on long-chain reasoning, a more brittle yet crucial capability, remains\nlargely unexplored. In this work, we study the impact of layer pruning on\nlong-chain reasoning through the lens of test-time scaling, a key mechanism in\nmodern LLMs that enables strong reasoning capacity by allocating more\ncomputation at inference time. With extensive experiments, we demonstrate that\npruning even one or two layers can severely impair test-time scaling, with\nperformance collapsing drastically on long reasoning benchmarks even when\nperformance on knowledge-intensive and shallow reasoning tasks remains stable.\nFurthermore, we find that standard supervised fine-tuning remedies fail to\nrecover test-time scaling once it has deteriorated. Through in-depth analyses,\nwe identify the mechanisms underlying this fragility of test-time scaling and\nhighlight the fundamental risks of applying layer pruning to\nreasoning-intensive LLMs. These findings call for a rethinking of layer pruning\nstrategies and provide insights for developing methods that preserve the\nrobustness of reasoning. We open-source the codebase in\n\\href{https://github.com/keyu-wang-2002/Layer-Pruning-Harms-Inference-Scaling}{https://github.com/keyu-wang-2002/Layer-Pruning-Harms-Inference-Scaling}.",
    "categories": [
      "cs.LG",
      "cs.AI"
    ],
    "published": "2025-10-25T09:22:22Z",
    "authors": [
      "Keyu Wang",
      "Tian Lyu",
      "Guinan Su",
      "Jonas Geiping",
      "Lu Yin",
      "Marco Canini",
      "Shiwei Liu"
    ],
    "pdf_url": "http://arxiv.org/pdf/2510.22228v1"
  },
  {
    "id": "2510.24776v1",
    "title": "CFL-SparseMed: Communication-Efficient Federated Learning for Medical\n  Imaging with Top-k Sparse Updates",
    "abstract": "Secure and reliable medical image classification is crucial for effective\npatient treatment, but centralized models face challenges due to data and\nprivacy concerns. Federated Learning (FL) enables privacy-preserving\ncollaborations but struggles with heterogeneous, non-IID data and high\ncommunication costs, especially in large networks. We propose\n\\textbf{CFL-SparseMed}, an FL approach that uses Top-k Sparsification to reduce\ncommunication overhead by transmitting only the top k gradients. This unified\nsolution effectively addresses data heterogeneity while maintaining model\naccuracy. It enhances FL efficiency, preserves privacy, and improves diagnostic\naccuracy and patient care in non-IID medical imaging settings. The\nreproducibility source code is available on\n\\href{https://github.com/Aniket2241/APK_contruct}{Github}.",
    "categories": [
      "eess.IV",
      "cs.CV",
      "cs.DC",
      "cs.LG"
    ],
    "published": "2025-10-25T09:13:06Z",
    "authors": [
      "Gousia Habib",
      "Aniket Bhardwaj",
      "Ritvik Sharma",
      "Shoeib Amin Banday",
      "Ishfaq Ahmad Malik"
    ],
    "pdf_url": "http://arxiv.org/pdf/2510.24776v1"
  },
  {
    "id": "2510.22224v1",
    "title": "Taming Silent Failures: A Framework for Verifiable AI Reliability",
    "abstract": "The integration of Artificial Intelligence (AI) into safety-critical systems\nintroduces a new reliability paradigm: silent failures, where AI produces\nconfident but incorrect outputs that can be dangerous. This paper introduces\nthe Formal Assurance and Monitoring Environment (FAME), a novel framework that\nconfronts this challenge. FAME synergizes the mathematical rigor of offline\nformal synthesis with the vigilance of online runtime monitoring to create a\nverifiable safety net around opaque AI components. We demonstrate its efficacy\nin an autonomous vehicle perception system, where FAME successfully detected\n93.5% of critical safety violations that were otherwise silent. By\ncontextualizing our framework within the ISO 26262 and ISO/PAS 8800 standards,\nwe provide reliability engineers with a practical, certifiable pathway for\ndeploying trustworthy AI. FAME represents a crucial shift from accepting\nprobabilistic performance to enforcing provable safety in next-generation\nsystems.",
    "categories": [
      "cs.SE",
      "cs.AI",
      "cs.LG",
      "cs.LO",
      "cs.SY",
      "eess.SY"
    ],
    "published": "2025-10-25T09:07:47Z",
    "authors": [
      "Guan-Yan Yang",
      "Farn Wang"
    ],
    "pdf_url": "http://arxiv.org/pdf/2510.22224v1"
  },
  {
    "id": "2510.22221v1",
    "title": "HPC-Driven Modeling with ML-Based Surrogates for Magnon-Photon Dynamics\n  in Hybrid Quantum Systems",
    "abstract": "Simulating hybrid magnonic quantum systems remains a challenge due to the\nlarge disparity between the timescales of the two systems. We present a\nmassively parallel GPU-based simulation framework that enables fully coupled,\nlarge-scale modeling of on-chip magnon-photon circuits. Our approach resolves\nthe dynamic interaction between ferromagnetic and electromagnetic fields with\nhigh spatiotemporal fidelity. To accelerate design workflows, we develop a\nphysics-informed machine learning surrogate trained on the simulation data,\nreducing computational cost while maintaining accuracy. This combined approach\nreveals real-time energy exchange dynamics and reproduces key phenomena such as\nanti-crossing behavior and the suppression of ferromagnetic resonance under\nstrong electromagnetic fields. By addressing the multiscale and multiphysics\nchallenges in magnon-photon modeling, our framework enables scalable simulation\nand rapid prototyping of next-generation quantum and spintronic devices.",
    "categories": [
      "quant-ph",
      "cs.LG",
      "physics.comp-ph"
    ],
    "published": "2025-10-25T08:51:00Z",
    "authors": [
      "Jialin Song",
      "Yingheng Tang",
      "Pu Ren",
      "Shintaro Takayoshi",
      "Saurabh Sawant",
      "Yujie Zhu",
      "Jia-Mian Hu",
      "Andy Nonaka",
      "Michael W. Mahoney",
      "Benjamin Erichson",
      "Zhi Yao"
    ],
    "pdf_url": "http://arxiv.org/pdf/2510.22221v1"
  },
  {
    "id": "2510.22208v1",
    "title": "Simplifying Knowledge Transfer in Pretrained Models",
    "abstract": "Pretrained models are ubiquitous in the current deep learning landscape,\noffering strong results on a broad range of tasks. Recent works have shown that\nmodels differing in various design choices exhibit categorically diverse\ngeneralization behavior, resulting in one model grasping distinct data-specific\ninsights unavailable to the other. In this paper, we propose to leverage large\npublicly available model repositories as an auxiliary source of model\nimprovements. We introduce a data partitioning strategy where pretrained models\nautonomously adopt either the role of a student, seeking knowledge, or that of\na teacher, imparting knowledge. Experiments across various tasks demonstrate\nthe effectiveness of our proposed approach. In image classification, we\nimproved the performance of ViT-B by approximately 1.4% through bidirectional\nknowledge transfer with ViT-T. For semantic segmentation, our method boosted\nall evaluation metrics by enabling knowledge transfer both within and across\nbackbone architectures. In video saliency prediction, our approach achieved a\nnew state-of-the-art. We further extend our approach to knowledge transfer\nbetween multiple models, leading to considerable performance improvements for\nall model participants.",
    "categories": [
      "cs.LG",
      "cs.CV"
    ],
    "published": "2025-10-25T08:18:41Z",
    "authors": [
      "Siddharth Jain",
      "Shyamgopal Karthik",
      "Vineet Gandhi"
    ],
    "pdf_url": "http://arxiv.org/pdf/2510.22208v1"
  },
  {
    "id": "2510.22209v1",
    "title": "Visual Model Selection using Feature Importance Clusters in\n  Fairness-Performance Similarity Optimized Space",
    "abstract": "In the context of algorithmic decision-making, fair machine learning methods\noften yield multiple models that balance predictive fairness and performance in\nvarying degrees. This diversity introduces a challenge for stakeholders who\nmust select a model that aligns with their specific requirements and values. To\naddress this, we propose an interactive framework that assists in navigating\nand interpreting the trade-offs across a portfolio of models. Our approach\nleverages weakly supervised metric learning to learn a Mahalanobis distance\nthat reflects similarity in fairness and performance outcomes, effectively\nstructuring the feature importance space of the models according to\nstakeholder-relevant criteria. We then apply clustering technique (k-means) to\ngroup models based on their transformed representations of feature importances,\nallowing users to explore clusters of models with similar predictive behaviors\nand fairness characteristics. This facilitates informed decision-making by\nhelping users understand how models differ not only in their\nfairness-performance balance but also in the features that drive their\npredictions.",
    "categories": [
      "cs.LG"
    ],
    "published": "2025-10-25T08:18:41Z",
    "authors": [
      "Sofoklis Kitharidis",
      "Cor J. Veenman",
      "Thomas B\u00e4ck",
      "Niki van Stein"
    ],
    "pdf_url": "http://arxiv.org/pdf/2510.22209v1"
  },
  {
    "id": "2510.22207v1",
    "title": "The Lossy Horizon: Error-Bounded Predictive Coding for Lossy Text\n  Compression (Episode I)",
    "abstract": "Large Language Models (LLMs) can achieve near-optimal lossless compression by\nacting as powerful probability models. We investigate their use in the lossy\ndomain, where reconstruction fidelity is traded for higher compression ratios.\nThis paper introduces Error-Bounded Predictive Coding (EPC), a lossy text codec\nthat leverages a Masked Language Model (MLM) as a decompressor. Instead of\nstoring a subset of original tokens, EPC allows the model to predict masked\ncontent and stores minimal, rank-based corrections only when the model's top\nprediction is incorrect. This creates a residual channel that offers continuous\nrate-distortion control. We compare EPC to a simpler Predictive Masking (PM)\nbaseline and a transform-based Vector Quantisation with a Residual Patch\n(VQ+RE) approach. Through an evaluation that includes precise bit accounting\nand rate-distortion analysis, we demonstrate that EPC consistently dominates\nPM, offering superior fidelity at a significantly lower bit rate by more\nefficiently utilising the model's intrinsic knowledge.",
    "categories": [
      "cs.LG",
      "cs.CL",
      "cs.IT",
      "math.IT",
      "94A08, 68P30, 68T50",
      "E.4; I.2.7; I.2.7"
    ],
    "published": "2025-10-25T08:18:31Z",
    "authors": [
      "Nnamdi Aghanya",
      "Jun Li",
      "Kewei Wang"
    ],
    "pdf_url": "http://arxiv.org/pdf/2510.22207v1"
  },
  {
    "id": "2510.22206v1",
    "title": "Right Place, Right Time: Market Simulation-based RL for Execution\n  Optimisation",
    "abstract": "Execution algorithms are vital to modern trading, they enable market\nparticipants to execute large orders while minimising market impact and\ntransaction costs. As these algorithms grow more sophisticated, optimising them\nbecomes increasingly challenging. In this work, we present a reinforcement\nlearning (RL) framework for discovering optimal execution strategies, evaluated\nwithin a reactive agent-based market simulator. This simulator creates reactive\norder flow and allows us to decompose slippage into its constituent components:\nmarket impact and execution risk. We assess the RL agent's performance using\nthe efficient frontier based on work by Almgren and Chriss, measuring its\nability to balance risk and cost. Results show that the RL-derived strategies\nconsistently outperform baselines and operate near the efficient frontier,\ndemonstrating a strong ability to optimise for risk and impact. These findings\nhighlight the potential of reinforcement learning as a powerful tool in the\ntrader's toolkit.",
    "categories": [
      "q-fin.CP",
      "cs.AI",
      "cs.LG",
      "q-fin.RM",
      "q-fin.TR"
    ],
    "published": "2025-10-25T08:10:18Z",
    "authors": [
      "Ollie Olby",
      "Andreea Bacalum",
      "Rory Baggott",
      "Namid Stillman"
    ],
    "pdf_url": "http://arxiv.org/pdf/2510.22206v1"
  },
  {
    "id": "2510.22198v1",
    "title": "MMbeddings: Parameter-Efficient, Low-Overfitting Probabilistic\n  Embeddings Inspired by Nonlinear Mixed Models",
    "abstract": "We present MMbeddings, a probabilistic embedding approach that reinterprets\ncategorical embeddings through the lens of nonlinear mixed models, effectively\nbridging classical statistical theory with modern deep learning. By treating\nembeddings as latent random effects within a variational autoencoder framework,\nour method substantially decreases the number of parameters -- from the\nconventional embedding approach of cardinality $\\times$ embedding dimension,\nwhich quickly becomes infeasible with large cardinalities, to a significantly\nsmaller, cardinality-independent number determined primarily by the encoder\narchitecture. This reduction dramatically mitigates overfitting and\ncomputational burden in high-cardinality settings. Extensive experiments on\nsimulated and real datasets, encompassing collaborative filtering and tabular\nregression tasks using varied architectures, demonstrate that MMbeddings\nconsistently outperforms traditional embeddings, underscoring its potential\nacross diverse machine learning applications.",
    "categories": [
      "stat.ML",
      "cs.LG"
    ],
    "published": "2025-10-25T07:35:08Z",
    "authors": [
      "Giora Simchoni",
      "Saharon Rosset"
    ],
    "pdf_url": "http://arxiv.org/pdf/2510.22198v1"
  },
  {
    "id": "2510.22197v1",
    "title": "Multi-dataset Joint Pre-training of Emotional EEG Enables Generalizable\n  Affective Computing",
    "abstract": "Task-specific pre-training is essential when task representations diverge\nfrom generic pre-training features. Existing task-general pre-training EEG\nmodels struggle with complex tasks like emotion recognition due to mismatches\nbetween task-specific features and broad pre-training approaches. This work\naims to develop a task-specific multi-dataset joint pre-training framework for\ncross-dataset emotion recognition, tackling problems of large inter-dataset\ndistribution shifts, inconsistent emotion category definitions, and substantial\ninter-subject variability. We introduce a cross-dataset covariance alignment\nloss to align second-order statistical properties across datasets, enabling\nrobust generalization without the need for extensive labels or per-subject\ncalibration. To capture the long-term dependency and complex dynamics of EEG,\nwe propose a hybrid encoder combining a Mamba-like linear attention channel\nencoder and a spatiotemporal dynamics model. Our method outperforms\nstate-of-the-art large-scale EEG models by an average of 4.57% in AUROC for\nfew-shot emotion recognition and 11.92% in accuracy for zero-shot\ngeneralization to a new dataset. Performance scales with the increase of\ndatasets used in pre-training. Multi-dataset joint pre-training achieves a\nperformance gain of 8.55% over single-dataset training. This work provides a\nscalable framework for task-specific pre-training and highlights its benefit in\ngeneralizable affective computing. Our code is available at\nhttps://github.com/ncclab-sustech/mdJPT_nips2025.",
    "categories": [
      "cs.LG",
      "cs.AI",
      "q-bio.NC"
    ],
    "published": "2025-10-25T07:30:24Z",
    "authors": [
      "Qingzhu Zhang",
      "Jiani Zhong",
      "Zongsheng Li",
      "Xinke Shen",
      "Quanying Liu"
    ],
    "pdf_url": "http://arxiv.org/pdf/2510.22197v1"
  },
  {
    "id": "2510.22190v1",
    "title": "RGC: a radio AGN classifier based on deep learning. I. A semi-supervised\n  model for the VLA images of bent radio AGNs",
    "abstract": "Wide-angle tail (WAT) and narrow-angle tail (NAT) radio active galactic\nnuclei (RAGNs) are key tracers of dense environments in galaxy groups and\nclusters, yet no machine-learning classifier of bent RAGNs has been trained\nusing both unlabeled data and purely visually inspected labels. We release the\nRGC Python package, which includes two newly preprocessed labeled datasets of\n639 WATs and NATs derived from a publicly available catalog of visually\ninspected sources, along with a semi-supervised RGC model that leverages 20,000\nunlabeled RAGNs. The two labeled datasets in RGC were preprocessed using PyBDSF\nwhich retains spurious sources, and Photutils which removes them. The RGC model\nintegrates the self-supervised framework BYOL (Bootstrap YOur Latent) with the\nsupervised E2CNN (E2-equivariant Convolutional Neural Network) to form a\nsemi-supervised binary classifier. The RGC model, when trained and evaluated on\na dataset devoid of spurious sources, reaches peak performance, attaining an\naccuracy of 88.88% along with F1-scores of 0.90 for WATs and 0.85 for NATs. The\nmodel's attention patterns amid class imbalance suggest that this work can\nserve as a stepping stone toward developing physics-informed foundation models\ncapable of identifying a broad range of AGN physical properties.",
    "categories": [
      "astro-ph.IM",
      "astro-ph.CO",
      "cs.LG"
    ],
    "published": "2025-10-25T06:55:29Z",
    "authors": [
      "M. S. Hossain",
      "M. S. H. Shahal",
      "A. Khan",
      "K. M. B. Asad",
      "P. Saikia",
      "F. Akter",
      "A. Ali",
      "M. A. Amin",
      "A. Momen",
      "M. Hasan",
      "A. K. M. M. Rahman"
    ],
    "pdf_url": "http://arxiv.org/pdf/2510.22190v1"
  },
  {
    "id": "2510.22186v1",
    "title": "Quantitative Bounds for Sorting-Based Permutation-Invariant Embeddings",
    "abstract": "We study the sorting-based embedding $\\beta_{\\mathbf A} : \\mathbb R^{n \\times\nd} \\to \\mathbb R^{n \\times D}$, $\\mathbf X \\mapsto {\\downarrow}(\\mathbf X\n\\mathbf A)$, where $\\downarrow$ denotes column wise sorting of matrices. Such\nembeddings arise in graph deep learning where outputs should be invariant to\npermutations of graph nodes. Previous work showed that for large enough $D$ and\nappropriate $\\mathbf A$, the mapping $\\beta_{\\mathbf A}$ is injective, and\nmoreover satisfies a bi-Lipschitz condition. However, two gaps remain: firstly,\nthe optimal size $D$ required for injectivity is not yet known, and secondly,\nno estimates of the bi-Lipschitz constants of the mapping are known.\n  In this paper, we make substantial progress in addressing both of these gaps.\nRegarding the first gap, we improve upon the best known upper bounds for the\nembedding dimension $D$ necessary for injectivity, and also provide a lower\nbound on the minimal injectivity dimension. Regarding the second gap, we\nconstruct matrices $\\mathbf A$, so that the bi-Lipschitz distortion of\n$\\beta_{\\mathbf A} $ depends quadratically on $n$, and is completely\nindependent of $d$. We also show that the distortion of $\\beta_{\\mathbf A}$ is\nnecessarily at least in $\\Omega(\\sqrt{n})$. Finally, we provide similar results\nfor variants of $\\beta_{\\mathbf A}$ obtained by applying linear projections to\nreduce the output dimension of $\\beta_{\\mathbf A}$.",
    "categories": [
      "cs.LG",
      "cs.IT",
      "math.FA",
      "math.IT",
      "math.MG",
      "46B07 (Primary), 68T07, 54E40 (Secondary)"
    ],
    "published": "2025-10-25T06:44:08Z",
    "authors": [
      "Nadav Dym",
      "Matthias Wellershoff",
      "Efstratios Tsoukanis",
      "Daniel Levy",
      "Radu Balan"
    ],
    "pdf_url": "http://arxiv.org/pdf/2510.22186v1"
  },
  {
    "id": "2510.22178v1",
    "title": "Dopamine-driven synaptic credit assignment in neural networks",
    "abstract": "Solving the synaptic Credit Assignment Problem(CAP) is central to learning in\nboth biological and artificial neural systems. Finding an optimal solution for\nsynaptic CAP means setting the synaptic weights that assign credit to each\nneuron for influencing the final output and behavior of neural networks or\nanimals. Gradient-based methods solve this problem in artificial neural\nnetworks using back-propagation, however, not in the most efficient way. For\ninstance, back-propagation requires a chain of top-down gradient computations.\nThis leads to an expensive optimization process in terms of computing power and\nmemory linked with well-known weight transport and update locking problems. To\naddress these shortcomings, we take a NeuroAI approach and draw inspiration\nfrom neural Reinforcement Learning to develop a derivative-free optimizer for\ntraining neural networks, Dopamine. Dopamine is developed for Weight\nPerturbation (WP) learning that exploits stochastic updating of weights towards\noptima. It achieves this by minimizing the regret, a form of Reward Prediction\nError (RPE) between the expected outcome from the perturbed model and the\nactual outcome from the unperturbed model. We use this RPE to adjust the\nlearning rate in the network (i.e., creating an adaptive learning rate\nstrategy, similar to the role of dopamine in the brain). We tested the Dopamine\noptimizer for training multi-layered perceptrons for XOR tasks, and recurrent\nneural networks for chaotic time series forecasting. Dopamine-trained models\ndemonstrate accelerated convergence and outperform standard WP, and give\ncomparable performance to gradient-based algorithms, while consuming\nsignificantly less computation and memory. Overall, the Dopamine optimizer not\nonly finds robust solutions and comparable performance to the state-of-the-art\nMachine Learning optimizers but is also neurobiologically more plausible.",
    "categories": [
      "cs.AI",
      "cs.LG"
    ],
    "published": "2025-10-25T06:17:49Z",
    "authors": [
      "Saranraj Nambusubramaniyan",
      "Shervin Safavi",
      "Raja Guru",
      "Andreas Knoblauch"
    ],
    "pdf_url": "http://arxiv.org/pdf/2510.22178v1"
  },
  {
    "id": "2510.22166v1",
    "title": "Expert Validation of Synthetic Cervical Spine Radiographs Generated with\n  a Denoising Diffusion Probabilistic Model",
    "abstract": "Machine learning in neurosurgery is limited by challenges in assembling\nlarge, high-quality imaging datasets. Synthetic data offers a scalable,\nprivacy-preserving solution. We evaluated the feasibility of generating\nrealistic lateral cervical spine radiographs using a denoising diffusion\nprobabilistic model (DDPM) trained on 4,963 images from the Cervical Spine\nX-ray Atlas. Model performance was monitored via training/validation loss and\nFrechet inception distance, and synthetic image quality was assessed in a\nblinded \"clinical Turing test\" with six neuroradiologists and two\nspine-fellowship trained neurosurgeons. Experts reviewed 50 quartets containing\none real and three synthetic images, identifying the real image and rating\nrealism on a 4-point Likert scale. Experts correctly identified the real image\nin 29% of trials (Fleiss' kappa=0.061). Mean realism scores were comparable\nbetween real (3.323) and synthetic images (3.228, 3.258, and 3.320; p=0.383,\n0.471, 1.000). Nearest-neighbor analysis found no evidence of memorization. We\nalso provide a dataset of 20,063 synthetic radiographs. These results\ndemonstrate that DDPM-generated cervical spine X-rays are statistically\nindistinguishable in realism and quality from real clinical images, offering a\nnovel approach to creating large-scale neuroimaging datasets for ML\napplications in landmarking, segmentation, and classification.",
    "categories": [
      "eess.IV",
      "cs.CV",
      "cs.LG"
    ],
    "published": "2025-10-25T05:25:37Z",
    "authors": [
      "Austin A. Barr",
      "Brij S. Karmur",
      "Anthony J. Winder",
      "Eddie Guo",
      "John T. Lysack",
      "James N. Scott",
      "William F. Morrish",
      "Muneer Eesa",
      "Morgan Willson",
      "David W. Cadotte",
      "Michael M. H. Yang",
      "Ian Y. M. Chan",
      "Sanju Lama",
      "Garnette R. Sutherland"
    ],
    "pdf_url": "http://arxiv.org/pdf/2510.22166v1"
  },
  {
    "id": "2510.22158v1",
    "title": "Solving Continuous Mean Field Games: Deep Reinforcement Learning for\n  Non-Stationary Dynamics",
    "abstract": "Mean field games (MFGs) have emerged as a powerful framework for modeling\ninteractions in large-scale multi-agent systems. Despite recent advancements in\nreinforcement learning (RL) for MFGs, existing methods are typically limited to\nfinite spaces or stationary models, hindering their applicability to real-world\nproblems. This paper introduces a novel deep reinforcement learning (DRL)\nalgorithm specifically designed for non-stationary continuous MFGs. The\nproposed approach builds upon a Fictitious Play (FP) methodology, leveraging\nDRL for best-response computation and supervised learning for average policy\nrepresentation. Furthermore, it learns a representation of the time-dependent\npopulation distribution using a Conditional Normalizing Flow. To validate the\neffectiveness of our method, we evaluate it on three different examples of\nincreasing complexity. By addressing critical limitations in scalability and\ndensity approximation, this work represents a significant advancement in\napplying DRL techniques to complex MFG problems, bringing the field closer to\nreal-world multi-agent systems.",
    "categories": [
      "cs.LG",
      "cs.AI",
      "cs.MA",
      "math.OC"
    ],
    "published": "2025-10-25T04:50:52Z",
    "authors": [
      "Lorenzo Magnino",
      "Kai Shao",
      "Zida Wu",
      "Jiacheng Shen",
      "Mathieu Lauri\u00e8re"
    ],
    "pdf_url": "http://arxiv.org/pdf/2510.22158v1"
  },
  {
    "id": "2510.22154v1",
    "title": "Frequency-Spatial Interaction Driven Network for Low-Light Image\n  Enhancement",
    "abstract": "Low-light image enhancement (LLIE) aims at improving the perception or\ninterpretability of an image captured in an environment with poor illumination.\nWith the advent of deep learning, the LLIE technique has achieved significant\nbreakthroughs. However, existing LLIE methods either ignore the important role\nof frequency domain information or fail to effectively promote the propagation\nand flow of information, limiting the LLIE performance. In this paper, we\ndevelop a novel frequency-spatial interaction-driven network (FSIDNet) for LLIE\nbased on two-stage architecture. To be specific, the first stage is designed to\nrestore the amplitude of low-light images to improve the lightness, and the\nsecond stage devotes to restore phase information to refine fine-grained\nstructures. Considering that Frequency domain and spatial domain information\nare complementary and both favorable for LLIE, we further develop two\nfrequency-spatial interaction blocks which mutually amalgamate the\ncomplementary spatial and frequency information to enhance the capability of\nthe model. In addition, we construct the Information Exchange Module (IEM) to\nassociate two stages by adequately incorporating cross-stage and cross-scale\nfeatures to effectively promote the propagation and flow of information in the\ntwo-stage network structure. Finally, we conduct experiments on several widely\nused benchmark datasets (i.e., LOL-Real, LSRW-Huawei, etc.), which demonstrate\nthat our method achieves the excellent performance in terms of visual results\nand quantitative metrics while preserving good model efficiency.",
    "categories": [
      "eess.IV",
      "cs.CV",
      "cs.LG",
      "cs.MM",
      "eess.SP"
    ],
    "published": "2025-10-25T04:17:50Z",
    "authors": [
      "Yunhong Tao",
      "Wenbing Tao",
      "Xiang Xiang"
    ],
    "pdf_url": "http://arxiv.org/pdf/2510.22154v1"
  },
  {
    "id": "2510.22149v1",
    "title": "Power to the Clients: Federated Learning in a Dictatorship Setting",
    "abstract": "Federated learning (FL) has emerged as a promising paradigm for decentralized\nmodel training, enabling multiple clients to collaboratively learn a shared\nmodel without exchanging their local data. However, the decentralized nature of\nFL also introduces vulnerabilities, as malicious clients can compromise or\nmanipulate the training process. In this work, we introduce dictator clients, a\nnovel, well-defined, and analytically tractable class of malicious participants\ncapable of entirely erasing the contributions of all other clients from the\nserver model, while preserving their own. We propose concrete attack strategies\nthat empower such clients and systematically analyze their effects on the\nlearning process. Furthermore, we explore complex scenarios involving multiple\ndictator clients, including cases where they collaborate, act independently, or\nform an alliance in order to ultimately betray one another. For each of these\nsettings, we provide a theoretical analysis of their impact on the global\nmodel's convergence. Our theoretical algorithms and findings about the complex\nscenarios including multiple dictator clients are further supported by\nempirical evaluations on both computer vision and natural language processing\nbenchmarks.",
    "categories": [
      "cs.LG",
      "cs.AI",
      "cs.CL",
      "cs.CR",
      "cs.CV",
      "cs.DC"
    ],
    "published": "2025-10-25T04:02:04Z",
    "authors": [
      "Mohammadsajad Alipour",
      "Mohammad Mohammadi Amiri"
    ],
    "pdf_url": "http://arxiv.org/pdf/2510.22149v1"
  },
  {
    "id": "2510.22141v1",
    "title": "LOC: A General Language-Guided Framework for Open-Set 3D Occupancy\n  Prediction",
    "abstract": "Vision-Language Models (VLMs) have shown significant progress in open-set\nchallenges. However, the limited availability of 3D datasets hinders their\neffective application in 3D scene understanding. We propose LOC, a general\nlanguage-guided framework adaptable to various occupancy networks, supporting\nboth supervised and self-supervised learning paradigms. For self-supervised\ntasks, we employ a strategy that fuses multi-frame LiDAR points for\ndynamic/static scenes, using Poisson reconstruction to fill voids, and\nassigning semantics to voxels via K-Nearest Neighbor (KNN) to obtain\ncomprehensive voxel representations. To mitigate feature over-homogenization\ncaused by direct high-dimensional feature distillation, we introduce Densely\nContrastive Learning (DCL). DCL leverages dense voxel semantic information and\npredefined textual prompts. This efficiently enhances open-set recognition\nwithout dense pixel-level supervision, and our framework can also leverage\nexisting ground truth to further improve performance. Our model predicts dense\nvoxel features embedded in the CLIP feature space, integrating textual and\nimage pixel information, and classifies based on text and semantic similarity.\nExperiments on the nuScenes dataset demonstrate the method's superior\nperformance, achieving high-precision predictions for known classes and\ndistinguishing unknown classes without additional training data.",
    "categories": [
      "cs.CV",
      "cs.CL",
      "cs.LG",
      "cs.RO",
      "eess.IV"
    ],
    "published": "2025-10-25T03:27:19Z",
    "authors": [
      "Yuhang Gao",
      "Xiang Xiang",
      "Sheng Zhong",
      "Guoyou Wang"
    ],
    "pdf_url": "http://arxiv.org/pdf/2510.22141v1"
  },
  {
    "id": "2510.22139v1",
    "title": "Edit Less, Achieve More: Dynamic Sparse Neuron Masking for Lifelong\n  Knowledge Editing in LLMs",
    "abstract": "Lifelong knowledge editing enables continuous, precise updates to outdated\nknowledge in large language models (LLMs) without computationally expensive\nfull retraining. However, existing methods often accumulate errors throughout\nthe editing process, causing a gradual decline in both editing accuracy and\ngeneralization. To tackle this problem, we propose Neuron-Specific Masked\nKnowledge Editing (NMKE), a novel fine-grained editing framework that combines\nneuron-level attribution with dynamic sparse masking. Leveraging neuron\nfunctional attribution, we identify two key types of knowledge neurons, with\nknowledge-general neurons activating consistently across prompts and\nknowledge-specific neurons activating to specific prompts. NMKE further\nintroduces an entropy-guided dynamic sparse mask, locating relevant neurons to\nthe target knowledge. This strategy enables precise neuron-level knowledge\nediting with fewer parameter modifications. Experimental results from thousands\nof sequential edits demonstrate that NMKE outperforms existing methods in\nmaintaining high editing success rates and preserving model general\ncapabilities in lifelong editing.",
    "categories": [
      "cs.LG",
      "cs.CL"
    ],
    "published": "2025-10-25T03:22:59Z",
    "authors": [
      "Jinzhe Liu",
      "Junshu Sun",
      "Shufan Shen",
      "Chenxue Yang",
      "Shuhui Wang"
    ],
    "pdf_url": "http://arxiv.org/pdf/2510.22139v1"
  },
  {
    "id": "2510.22138v2",
    "title": "Tractable Shapley Values and Interactions via Tensor Networks",
    "abstract": "We show how to replace the O(2^n) coalition enumeration over n features\nbehind Shapley values and Shapley-style interaction indices with a\nfew-evaluation scheme on a tensor-network (TN) surrogate: TN-SHAP. The key idea\nis to represent a predictor's local behavior as a factorized multilinear map,\nso that coalitional quantities become linear probes of a coefficient tensor.\nTN-SHAP replaces exhaustive coalition sweeps with just a small number of\ntargeted evaluations to extract order-k Shapley interactions. In particular,\nboth order-1 (single-feature) and order-2 (pairwise) computations have cost\nO(n*poly(chi) + n^2), where chi is the TN's maximal cut rank. We provide\ntheoretical guarantees on the approximation error and tractability of TN-SHAP.\nOn UCI datasets, our method matches enumeration on the fitted surrogate while\nreducing evaluation by orders of magnitude and achieves 25-1000x wall-clock\nspeedups over KernelSHAP-IQ at comparable accuracy, while amortizing training\nacross local cohorts.",
    "categories": [
      "cs.LG"
    ],
    "published": "2025-10-25T03:21:20Z",
    "authors": [
      "Farzaneh Heidari",
      "Chao Li",
      "Guillaume Rabusseau"
    ],
    "pdf_url": "http://arxiv.org/pdf/2510.22138v2"
  },
  {
    "id": "2510.22133v1",
    "title": "HandPass: A Wi-Fi CSI Palm Authentication Approach for Access Control",
    "abstract": "Wi-Fi Channel State Information (CSI) has been extensively studied for\nsensing activities. However, its practical application in user authentication\nstill needs to be explored. This study presents a novel approach to biometric\nauthentication using Wi-Fi Channel State Information (CSI) data for palm\nrecognition. The research delves into utilizing a Raspberry Pi encased in a\ncustom-built box with antenna power reduced to 1dBm, which was used to capture\nCSI data from the right hands of 20 participants (10 men and 10 women). The\ndataset was normalized using MinMax scaling to ensure uniformity and accuracy.\nBy focusing on biophysical aspects such as hand size, shape, angular spread\nbetween fingers, and finger phalanx lengths, among other characteristics, the\nstudy explores how these features affect electromagnetic signals, which are\nthen reflected in Wi-Fi CSI, allowing for precise user identification. Five\nclassification algorithms were evaluated, with the Random Forest classifier\nachieving an average F1-Score of 99.82\\% using 10-fold cross-validation.\nAmplitude and Phase data were used, with each capture session recording\napproximately 1000 packets per second in five 5-second intervals for each User.\nThis high accuracy highlights the potential of Wi-Fi CSI in developing robust\nand reliable user authentication systems based on palm biometric data.",
    "categories": [
      "cs.NI",
      "cs.CR",
      "cs.LG",
      "C.2.0; I.5.4; K.6.5"
    ],
    "published": "2025-10-25T03:13:45Z",
    "authors": [
      "Eduardo Fabricio Gomes Trindade",
      "Felipe Silveira de Almeida",
      "Gioliano de Oliveira Braga",
      "Rafael Pimenta de Mattos Paix\u00e3o",
      "Pedro Henrique dos Santos Rocha",
      "Lourenco Alves Pereira Jr"
    ],
    "pdf_url": "http://arxiv.org/pdf/2510.22133v1"
  },
  {
    "id": "2510.22131v1",
    "title": "Probing Neural Combinatorial Optimization Models",
    "abstract": "Neural combinatorial optimization (NCO) has achieved remarkable performance,\nyet its learned model representations and decision rationale remain a black\nbox. This impedes both academic research and practical deployment, since\nresearchers and stakeholders require deeper insights into NCO models. In this\npaper, we take the first critical step towards interpreting NCO models by\ninvestigating their representations through various probing tasks. Moreover, we\nintroduce a novel probing tool named Coefficient Significance Probing\n(CS-Probing) to enable deeper analysis of NCO representations by examining the\ncoefficients and statistical significance during probing. Extensive experiments\nand analysis reveal that NCO models encode low-level information essential for\nsolution construction, while capturing high-level knowledge to facilitate\nbetter decisions. Using CS-Probing, we find that prevalent NCO models impose\nvarying inductive biases on their learned representations, uncover direct\nevidence related to model generalization, and identify key embedding dimensions\nassociated with specific knowledge. These insights can be potentially\ntranslated into practice, for example, with minor code modifications, we\nimprove the generalization of the analyzed model. Our work represents a first\nsystematic attempt to interpret black-box NCO models, showcasing probing as a\npromising tool for analyzing their internal mechanisms and revealing insights\nfor the NCO community. The source code is publicly available.",
    "categories": [
      "cs.LG",
      "cs.AI"
    ],
    "published": "2025-10-25T03:11:10Z",
    "authors": [
      "Zhiqin Zhang",
      "Yining Ma",
      "Zhiguang Cao",
      "Hoong Chuin Lau"
    ],
    "pdf_url": "http://arxiv.org/pdf/2510.22131v1"
  },
  {
    "id": "2510.22127v1",
    "title": "Mint: A Simple Test-Time Adaptation of Vision-Language Models against\n  Common Corruptions",
    "abstract": "Pretrained vision-language models such as CLIP achieve strong zero-shot\ngeneralization but remain vulnerable to distribution shifts caused by input\ncorruptions. In this work, we investigate how corruptions affect CLIP's image\nembeddings and uncover a consistent phenomenon we term as embedding variance\ncollapse, where both intra-class and inter-class variances shrink as corruption\nseverity increases. We find that this collapse is closely tied to performance\ndegradation, with inter-class variance strongly correlated with classification\naccuracy. To explain this phenomenon, we analyze how corruptions alter the\nstructure of the embedding space. Our theoretical results suggest that the\nvisual encoder tends to encode corruption-related signals, which dilute\nclass-discriminative features and compress the representation geometry. We\nfurther show that maximizing inter-class variance, even when estimated from\npseudo-labels, can provably enhance embedding quality. Based on this insight,\nwe propose Mint, a simple test-time adaptation method that maximizes\npseudo-label-based inter-class variance on the fly using a mean accumulator and\na gradient accumulator. Mint operates effectively with small batch sizes and\nconsistently improves performance across multiple corruption benchmarks and\nCLIP architectures. Our code is available at https://github.com/baowenxuan/Mint .",
    "categories": [
      "cs.CV",
      "cs.LG"
    ],
    "published": "2025-10-25T02:55:08Z",
    "authors": [
      "Wenxuan Bao",
      "Ruxi Deng",
      "Jingrui He"
    ],
    "pdf_url": "http://arxiv.org/pdf/2510.22127v1"
  },
  {
    "id": "2510.22124v1",
    "title": "Efficient Utility-Preserving Machine Unlearning with Implicit Gradient\n  Surgery",
    "abstract": "Machine unlearning (MU) aims to efficiently remove sensitive or harmful\nmemory from a pre-trained model. The key challenge is to balance the potential\ntradeoff between unlearning efficacy and utility preservation, which involves\nforgetting undesirable information as defined while maintaining the model's\noriginal performance. One potential way to tackle this problem is to use\nmulti-objective optimization to jointly optimize both the unlearning and\nutility preservation objectives. However, existing multi-objective methods only\nguarantee finding a Pareto-optimal solution without fine-grained control, which\ncauses under-optimization of the unlearning objective. To this end, we first\nmodel MU as a constrained optimization problem, that is, optimizing the\nunlearning objective under the constraint of a bounded increase for utility\nloss. We then show that solving this optimization problem is equivalent to\nunilateral gradient surgery on the unlearning objective. To resolve the\nadditional computational cost brought by gradient surgery, we propose an\nimplicit gradient surgery method, which approximates the solution to the\naforementioned constrained optimization problem via only one backpropagation,\nthereby achieving efficient utility-preserving MU. Theoretically, we provide a\ntight convergence analysis of the algorithm. Empirically, our extensive\nexperiments show that the proposed algorithm achieves better tradeoff results\nthan existing baselines. Codes are available at\nhttps://github.com/anseryuer/EUPMU-Efficient-Utility-Preserving-Machine-Unlearning.",
    "categories": [
      "cs.LG",
      "cs.AI"
    ],
    "published": "2025-10-25T02:49:26Z",
    "authors": [
      "Shiji Zhou",
      "Tianbai Yu",
      "Zhi Zhang",
      "Heng Chang",
      "Xiao Zhou",
      "Dong Wu",
      "Han Zhao"
    ],
    "pdf_url": "http://arxiv.org/pdf/2510.22124v1"
  },
  {
    "id": "2510.22123v1",
    "title": "Learning 3D Anisotropic Noise Distributions Improves Molecular Force\n  Field Modeling",
    "abstract": "Coordinate denoising has emerged as a promising method for 3D molecular\npretraining due to its theoretical connection to learning molecular force\nfield. However, existing denoising methods rely on oversimplied molecular\ndynamics that assume atomic motions to be isotropic and homoscedastic. To\naddress these limitations, we propose a novel denoising framework AniDS:\nAnisotropic Variational Autoencoder for 3D Molecular Denoising. AniDS\nintroduces a structure-aware anisotropic noise generator that can produce\natom-specific, full covariance matrices for Gaussian noise distributions to\nbetter reflect directional and structural variability in molecular systems.\nThese covariances are derived from pairwise atomic interactions as anisotropic\ncorrections to an isotropic base. Our design ensures that the resulting\ncovariance matrices are symmetric, positive semi-definite, and\nSO(3)-equivariant, while providing greater capacity to model complex molecular\ndynamics. Extensive experiments show that AniDS outperforms prior isotropic and\nhomoscedastic denoising models and other leading methods on the MD17 and OC22\nbenchmarks, achieving average relative improvements of 8.9% and 6.2% in force\nprediction accuracy. Our case study on a crystal and molecule structure shows\nthat AniDS adaptively suppresses noise along the bonding direction, consistent\nwith physicochemical principles. Our code is available at\nhttps://github.com/ZeroKnighting/AniDS.",
    "categories": [
      "cs.LG",
      "stat.ML"
    ],
    "published": "2025-10-25T02:31:17Z",
    "authors": [
      "Xixian Liu",
      "Rui Jiao",
      "Zhiyuan Liu",
      "Yurou Liu",
      "Yang Liu",
      "Ziheng Lu",
      "Wenbing Huang",
      "Yang Zhang",
      "Yixin Cao"
    ],
    "pdf_url": "http://arxiv.org/pdf/2510.22123v1"
  },
  {
    "id": "2510.22101v1",
    "title": "Scaling Up Efficient Small Language Models Serving and Deployment for\n  Semantic Job Search",
    "abstract": "Large Language Models (LLMs) have demonstrated impressive quality when\napplied to predictive tasks such as relevance ranking and semantic search.\nHowever, deployment of such LLMs remains prohibitively expensive for industry\napplications with strict latency and throughput requirements. In this work, we\npresent lessons and efficiency insights from developing a purely text-based\ndecoder-only Small Language Model (SLM) for a semantic search application at\nLinkedIn. Particularly, we discuss model compression techniques such as pruning\nthat allow us to reduce the model size by up to $40\\%$ while maintaining the\naccuracy. Additionally, we present context compression techniques that allow us\nto reduce the input context length by up to $10$x with minimal loss of\naccuracy. Finally, we present practical lessons from optimizing the serving\ninfrastructure for deploying such a system on GPUs at scale, serving millions\nof requests per second. Taken together, this allows us to increase our system's\nthroughput by $10$x in a real-world deployment, while meeting our quality bar.",
    "categories": [
      "cs.IR",
      "cs.LG"
    ],
    "published": "2025-10-25T00:56:06Z",
    "authors": [
      "Kayhan Behdin",
      "Qingquan Song",
      "Sriram Vasudevan",
      "Jian Sheng",
      "Xiaojing Ma",
      "Z Zhou",
      "Chuanrui Zhu",
      "Guoyao Li",
      "Chanh Nguyen",
      "Sayan Ghosh",
      "Hejian Sang",
      "Ata Fatahi Baarzi",
      "Sundara Raman Ramachandran",
      "Xiaoqing Wang",
      "Qing Lan",
      "Vinay Y S",
      "Qi Guo",
      "Caleb Johnson",
      "Zhipeng Wang",
      "Fedor Borisyuk"
    ],
    "pdf_url": "http://arxiv.org/pdf/2510.22101v1"
  },
  {
    "id": "2510.22096v1",
    "title": "Dynamic Graph Neural Network for Data-Driven Physiologically Based\n  Pharmacokinetic Modeling",
    "abstract": "Physiologically Based Pharmacokinetic (PBPK) modeling plays a critical role\nin drug development by predicting drug concentration dynamics across organs.\nTraditional approaches rely on ordinary differential equations with strong\nsimplifying assumptions, which limit their adaptability to nonlinear\nphysiological interactions. In this study, we explore data-driven alternatives\nfor PBPK prediction using deep learning. Two baseline architectures - a\nmultilayer perceptron (MLP) and a long short-term memory (LSTM) network - are\nimplemented to capture molecular and temporal dependencies, respectively. To\nincorporate inter-organ interactions, we propose a Dynamic Graph Neural Network\n(Dynamic GNN) that models physiological connections as recurrent\nmessage-passing processes between organs. Experimental results demonstrate that\nthe proposed Dynamic GNN achieves the highest predictive performance among all\nmodels, with an R^2 of 0.9342, an RMSE of 0.0159, and an MAE of 0.0116. In\ncomparison, the MLP baseline obtains an R^2 of 0.8705 and the LSTM achieves\n0.8059. These results highlight that explicitly modeling the spatial and\ntemporal dependencies of organ interactions enables more accurate and\ngeneralizable drug concentration prediction. The Dynamic GNN provides a\nscalable, equation-free alternative to traditional PBPK formulations and\ndemonstrates strong potential for data-driven pharmacokinetic modeling in\npreclinical and clinical research.",
    "categories": [
      "cs.LG"
    ],
    "published": "2025-10-25T00:40:12Z",
    "authors": [
      "Su Liu",
      "Xin Hu",
      "Shurong Wen",
      "Jiaqi Liu",
      "Jiexi Xu",
      "Lanruo Wang"
    ],
    "pdf_url": "http://arxiv.org/pdf/2510.22096v1"
  },
  {
    "id": "2510.22094v2",
    "title": "Hierarchical Graph Networks for Accurate Weather Forecasting via\n  Lightweight Training",
    "abstract": "Climate events arise from intricate, multivariate dynamics governed by\nglobal-scale drivers, profoundly impacting food, energy, and infrastructure.\nYet, accurate weather prediction remains elusive due to physical processes\nunfolding across diverse spatio-temporal scales, which fixed-resolution methods\ncannot capture. Hierarchical Graph Neural Networks (HGNNs) offer a multiscale\nrepresentation, but nonlinear downward mappings often erase global trends,\nweakening the integration of physics into forecasts. We introduce HiFlowCast\nand its ensemble variant HiAntFlow, HGNNs that embed physics within a\nmultiscale prediction framework. Two innovations underpin their design: a\nLatent-Memory-Retention mechanism that preserves global trends during downward\ntraversal, and a Latent-to-Physics branch that integrates PDE solution fields\nacross diverse scales. Our Flow models cut errors by over 5% at 13-day lead\ntimes and by 5-8% under 1st and 99th quantile extremes, improving reliability\nfor rare events. Leveraging pretrained model weights, they converge within a\nsingle epoch, reducing training cost and their carbon footprint. Such\nefficiency is vital as the growing scale of machine learning challenges\nsustainability and limits research accessibility. Code and model weights are in\nthe supplementary materials.",
    "categories": [
      "cs.LG",
      "physics.ao-ph"
    ],
    "published": "2025-10-25T00:21:16Z",
    "authors": [
      "Thomas Bailie",
      "S. Karthik Mukkavilli",
      "Varvara Vetrova",
      "Yun Sing Koh"
    ],
    "pdf_url": "http://arxiv.org/pdf/2510.22094v2"
  },
  {
    "id": "2510.22087v1",
    "title": "QuArch: A Benchmark for Evaluating LLM Reasoning in Computer\n  Architecture",
    "abstract": "The field of computer architecture, which bridges high-level software\nabstractions and low-level hardware implementations, remains absent from\ncurrent large language model (LLM) evaluations. To this end, we present QuArch\n(pronounced 'quark'), the first benchmark designed to facilitate the\ndevelopment and evaluation of LLM knowledge and reasoning capabilities\nspecifically in computer architecture. QuArch provides a comprehensive\ncollection of 2,671 expert-validated question-answer (QA) pairs covering\nvarious aspects of computer architecture, including processor design, memory\nsystems, and interconnection networks. Our evaluation reveals that while\nfrontier models possess domain-specific knowledge, they struggle with skills\nthat require higher-order thinking in computer architecture. Frontier model\naccuracies vary widely (from 34% to 72%) on these advanced questions,\nhighlighting persistent gaps in architectural reasoning across analysis,\ndesign, and implementation QAs. By holistically assessing fundamental skills,\nQuArch provides a foundation for building and measuring LLM capabilities that\ncan accelerate innovation in computing systems. With over 140 contributors from\n40 institutions, this benchmark represents a community effort to set the\nstandard for architectural reasoning in LLM evaluation.",
    "categories": [
      "cs.AR",
      "cs.AI",
      "cs.LG",
      "cs.SE"
    ],
    "published": "2025-10-24T23:54:17Z",
    "authors": [
      "Shvetank Prakash",
      "Andrew Cheng",
      "Arya Tschand",
      "Mark Mazumder",
      "Varun Gohil",
      "Jeffrey Ma",
      "Jason Yik",
      "Zishen Wan",
      "Jessica Quaye",
      "Elisavet Lydia Alvanaki",
      "Avinash Kumar",
      "Chandrashis Mazumdar",
      "Tuhin Khare",
      "Alexander Ingare",
      "Ikechukwu Uchendu",
      "Radhika Ghosal",
      "Abhishek Tyagi",
      "Chenyu Wang",
      "Andrea Mattia Garavagno",
      "Sarah Gu",
      "Alice Guo",
      "Grace Hur",
      "Luca Carloni",
      "Tushar Krishna",
      "Ankita Nayak",
      "Amir Yazdanbakhsh",
      "Vijay Janapa Reddi"
    ],
    "pdf_url": "http://arxiv.org/pdf/2510.22087v1"
  },
  {
    "id": "2510.22085v1",
    "title": "Jailbreak Mimicry: Automated Discovery of Narrative-Based Jailbreaks for\n  Large Language Models",
    "abstract": "Large language models (LLMs) remain vulnerable to sophisticated prompt\nengineering attacks that exploit contextual framing to bypass safety\nmechanisms, posing significant risks in cybersecurity applications. We\nintroduce Jailbreak Mimicry, a systematic methodology for training compact\nattacker models to automatically generate narrative-based jailbreak prompts in\na one-shot manner. Our approach transforms adversarial prompt discovery from\nmanual craftsmanship into a reproducible scientific process, enabling proactive\nvulnerability assessment in AI-driven security systems. Developed for the\nOpenAI GPT-OSS-20B Red-Teaming Challenge, we use parameter-efficient\nfine-tuning (LoRA) on Mistral-7B with a curated dataset derived from AdvBench,\nachieving an 81.0% Attack Success Rate (ASR) against GPT-OSS-20B on a held-out\ntest set of 200 items. Cross-model evaluation reveals significant variation in\nvulnerability patterns: our attacks achieve 66.5% ASR against GPT-4, 79.5% on\nLlama-3 and 33.0% against Gemini 2.5 Flash, demonstrating both broad\napplicability and model-specific defensive strengths in cybersecurity contexts.\nThis represents a 54x improvement over direct prompting (1.5% ASR) and\ndemonstrates systematic vulnerabilities in current safety alignment approaches.\nOur analysis reveals that technical domains (Cybersecurity: 93% ASR) and\ndeception-based attacks (Fraud: 87.8% ASR) are particularly vulnerable,\nhighlighting threats to AI-integrated threat detection, malware analysis, and\nsecure systems, while physical harm categories show greater resistance (55.6%\nASR). We employ automated harmfulness evaluation using Claude Sonnet 4,\ncross-validated with human expert assessment, ensuring reliable and scalable\nevaluation for cybersecurity red-teaming. Finally, we analyze failure\nmechanisms and discuss defensive strategies to mitigate these vulnerabilities\nin AI for cybersecurity.",
    "categories": [
      "cs.CR",
      "cs.AI",
      "cs.CL",
      "cs.LG",
      "I.2.7; I.2.0; K.6.5"
    ],
    "published": "2025-10-24T23:53:16Z",
    "authors": [
      "Pavlos Ntais"
    ],
    "pdf_url": "http://arxiv.org/pdf/2510.22085v1"
  },
  {
    "id": "2510.22075v1",
    "title": "Agentic Reinforcement Learning for Real-World Code Repair",
    "abstract": "We tackle the challenge of training reliable code-fixing agents in real\nrepositories, where complex builds and shifting dependencies make evaluation\nunstable. We developed a verifiable pipeline with success defined as post-fix\nbuild validation and improved reproducibility across ~1K real issues by pinning\ndependencies and disabling automatic upgrades. Building on this, we introduced\na scalable simplified pipeline for large-scale reinforcement learning (RL).\nUsing this setup, we supervised fine-tuned Qwen3-32B in the full pipeline and\napplied RL on top of the SFT model in the simplified environment. The SFT model\ndistilled from GPT-4.1 trajectories performs on par while being 56x smaller,\nand RL added 7-20% absolute gains under matched train-test conditions.\n\"Thinking mode\" was on par or worse in our experiments. Both SFT and RL models\nfailed to generalize across environments, highlighting the importance of\nmatching train-test environments for building reliable real-world code-fixing\nagents.",
    "categories": [
      "cs.LG",
      "cs.AI",
      "cs.CL"
    ],
    "published": "2025-10-24T23:25:02Z",
    "authors": [
      "Siyu Zhu",
      "Anastasiya Karpovich",
      "Albert Chen",
      "Jessica Koscheka",
      "Shailesh Jannu",
      "Di Wen",
      "Yuqing Zhu",
      "Rohit Jain",
      "Alborz Geramifard"
    ],
    "pdf_url": "http://arxiv.org/pdf/2510.22075v1"
  },
  {
    "id": "2510.22070v1",
    "title": "MAGIC-Flow: Multiscale Adaptive Conditional Flows for Generation and\n  Interpretable Classification",
    "abstract": "Generative modeling has emerged as a powerful paradigm for representation\nlearning, but its direct applicability to challenging fields like medical\nimaging remains limited: mere generation, without task alignment, fails to\nprovide a robust foundation for clinical use. We propose MAGIC-Flow, a\nconditional multiscale normalizing flow architecture that performs generation\nand classification within a single modular framework. The model is built as a\nhierarchy of invertible and differentiable bijections, where the Jacobian\ndeterminant factorizes across sub-transformations. We show how this ensures\nexact likelihood computation and stable optimization, while invertibility\nenables explicit visualization of sample likelihoods, providing an\ninterpretable lens into the model's reasoning. By conditioning on class labels,\nMAGIC-Flow supports controllable sample synthesis and principled\nclass-probability estimation, effectively aiding both generative and\ndiscriminative objectives. We evaluate MAGIC-Flow against top baselines using\nmetrics for similarity, fidelity, and diversity. Across multiple datasets, it\naddresses generation and classification under scanner noise, and\nmodality-specific synthesis and identification. Results show MAGIC-Flow creates\nrealistic, diverse samples and improves classification. MAGIC-Flow is an\neffective strategy for generation and classification in data-limited domains,\nwith direct benefits for privacy-preserving augmentation, robust\ngeneralization, and trustworthy medical AI.",
    "categories": [
      "cs.LG",
      "cs.CV",
      "eess.IV",
      "stat.ML"
    ],
    "published": "2025-10-24T23:11:25Z",
    "authors": [
      "Luca Caldera",
      "Giacomo Bottacini",
      "Lara Cavinato"
    ],
    "pdf_url": "http://arxiv.org/pdf/2510.22070v1"
  },
  {
    "id": "2510.22069v1",
    "title": "Neural Index Policies for Restless Multi-Action Bandits with\n  Heterogeneous Budgets",
    "abstract": "Restless multi-armed bandits (RMABs) provide a scalable framework for\nsequential decision-making under uncertainty, but classical formulations assume\nbinary actions and a single global budget. Real-world settings, such as\nhealthcare, often involve multiple interventions with heterogeneous costs and\nconstraints, where such assumptions break down. We introduce a Neural Index\nPolicy (NIP) for multi-action RMABs with heterogeneous budget constraints. Our\napproach learns to assign budget-aware indices to arm--action pairs using a\nneural network, and converts them into feasible allocations via a\ndifferentiable knapsack layer formulated as an entropy-regularized optimal\ntransport (OT) problem. The resulting model unifies index prediction and\nconstrained optimization in a single end-to-end differentiable framework,\nenabling gradient-based training directly on decision quality. The network is\noptimized to align its induced occupancy measure with the theoretical upper\nbound from a linear programming relaxation, bridging asymptotic RMAB theory\nwith practical learning. Empirically, NIP achieves near-optimal performance\nwithin 5% of the oracle occupancy-measure policy while strictly enforcing\nheterogeneous budgets and scaling to hundreds of arms. This work establishes a\ngeneral, theoretically grounded, and scalable framework for learning\nindex-based policies in complex resource-constrained environments.",
    "categories": [
      "cs.LG",
      "stat.ML"
    ],
    "published": "2025-10-24T23:08:36Z",
    "authors": [
      "Himadri S. Pandey",
      "Kai Wang",
      "Gian-Gabriel P. Garcia"
    ],
    "pdf_url": "http://arxiv.org/pdf/2510.22069v1"
  },
  {
    "id": "2510.22068v1",
    "title": "Deep Gaussian Processes for Functional Maps",
    "abstract": "Learning mappings between functional spaces, also known as\nfunction-on-function regression, plays a crucial role in functional data\nanalysis and has broad applications, e.g. spatiotemporal forecasting, curve\nprediction, and climate modeling. Existing approaches, such as functional\nlinear models and neural operators, either fall short of capturing complex\nnonlinearities or lack reliable uncertainty quantification under noisy, sparse,\nand irregularly sampled data. To address these issues, we propose Deep Gaussian\nProcesses for Functional Maps (DGPFM). Our method designs a sequence of\nGP-based linear and nonlinear transformations, leveraging integral transforms\nof kernels, GP interpolation, and nonlinear activations sampled from GPs. A key\ninsight simplifies implementation: under fixed locations, discrete\napproximations of kernel integral transforms collapse into direct functional\nintegral transforms, enabling flexible incorporation of various integral\ntransform designs. To achieve scalable probabilistic inference, we use inducing\npoints and whitening transformations to develop a variational learning\nalgorithm. Empirical results on real-world and PDE benchmark datasets\ndemonstrate that the advantage of DGPFM in both predictive performance and\nuncertainty calibration.",
    "categories": [
      "cs.LG",
      "stat.ML"
    ],
    "published": "2025-10-24T23:05:48Z",
    "authors": [
      "Matthew Lowery",
      "Zhitong Xu",
      "Da Long",
      "Keyan Chen",
      "Daniel S. Johnson",
      "Yang Bai",
      "Varun Shankar",
      "Shandian Zhe"
    ],
    "pdf_url": "http://arxiv.org/pdf/2510.22068v1"
  },
  {
    "id": "2510.22063v1",
    "title": "Frequentist Validity of Epistemic Uncertainty Estimators",
    "abstract": "Decomposing prediction uncertainty into its aleatoric (irreducible) and\nepistemic (reducible) components is critical for the development and deployment\nof machine learning systems. A popular, principled measure for epistemic\nuncertainty is the mutual information between the response variable and model\nparameters. However, evaluating this measure requires access to the posterior\ndistribution of the model parameters, which is challenging to compute. In view\nof this, we introduce a frequentist measure of epistemic uncertainty based on\nthe bootstrap. Our main theoretical contribution is a novel asymptotic\nexpansion that reveals that our proposed (frequentist) measure and the\n(Bayesian) mutual information are asymptotically equivalent. This provides\nfrequentist interpretations to mutual information and new computational\nstrategies for approximating it. Moreover, we link our proposed approach to the\nwidely-used heuristic approach of deep ensembles, giving added perspective on\ntheir practical success.",
    "categories": [
      "stat.ML",
      "cs.AI",
      "cs.LG",
      "math.ST",
      "stat.TH"
    ],
    "published": "2025-10-24T22:58:42Z",
    "authors": [
      "Anchit Jain",
      "Stephen Bates"
    ],
    "pdf_url": "http://arxiv.org/pdf/2510.22063v1"
  },
  {
    "id": "2510.22062v1",
    "title": "Differentially Private High-dimensional Variable Selection via Integer\n  Programming",
    "abstract": "Sparse variable selection improves interpretability and generalization in\nhigh-dimensional learning by selecting a small subset of informative features.\nRecent advances in Mixed Integer Programming (MIP) have enabled solving\nlarge-scale non-private sparse regression - known as Best Subset Selection\n(BSS) - with millions of variables in minutes. However, extending these\nalgorithmic advances to the setting of Differential Privacy (DP) has remained\nlargely unexplored. In this paper, we introduce two new pure differentially\nprivate estimators for sparse variable selection, levering modern MIP\ntechniques. Our framework is general and applies broadly to problems like\nsparse regression or classification, and we provide theoretical support\nrecovery guarantees in the case of BSS. Inspired by the exponential mechanism,\nwe develop structured sampling procedures that efficiently explore the\nnon-convex objective landscape, avoiding the exhaustive combinatorial search in\nthe exponential mechanism. We complement our theoretical findings with\nextensive numerical experiments, using both least squares and hinge loss for\nour objective function, and demonstrate that our methods achieve\nstate-of-the-art empirical support recovery, outperforming competing algorithms\nin settings with up to $p=10^4$.",
    "categories": [
      "stat.ML",
      "cs.CR",
      "cs.LG"
    ],
    "published": "2025-10-24T22:57:33Z",
    "authors": [
      "Petros Prastakos",
      "Kayhan Behdin",
      "Rahul Mazumder"
    ],
    "pdf_url": "http://arxiv.org/pdf/2510.22062v1"
  },
  {
    "id": "2510.22058v1",
    "title": "Pruning and Quantization Impact on Graph Neural Networks",
    "abstract": "Graph neural networks (GNNs) are known to operate with high accuracy on\nlearning from graph-structured data, but they suffer from high computational\nand resource costs. Neural network compression methods are used to reduce the\nmodel size while maintaining reasonable accuracy. Two of the common neural\nnetwork compression techniques include pruning and quantization. In this\nresearch, we empirically examine the effects of three pruning methods and three\nquantization methods on different GNN models, including graph classification\ntasks, node classification tasks, and link prediction. We conducted all\nexperiments on three graph datasets, including Cora, Proteins, and BBBP. Our\nfindings demonstrate that unstructured fine-grained and global pruning can\nsignificantly reduce the model's size(50\\%) while maintaining or even improving\nprecision after fine-tuning the pruned model. The evaluation of different\nquantization methods on GNN shows diverse impacts on accuracy, inference time,\nand model size across different datasets.",
    "categories": [
      "cs.LG"
    ],
    "published": "2025-10-24T22:44:25Z",
    "authors": [
      "Khatoon Khedri",
      "Reza Rawassizadeh",
      "Qifu Wen",
      "Mehdi Hosseinzadeh"
    ],
    "pdf_url": "http://arxiv.org/pdf/2510.22058v1"
  },
  {
    "id": "2510.22057v1",
    "title": "Automatic Assessment of Students' Classroom Engagement with Bias\n  Mitigated Multi-task Model",
    "abstract": "With the rise of online and virtual learning, monitoring and enhancing\nstudent engagement have become an important aspect of effective education.\nTraditional methods of assessing a student's involvement might not be\napplicable directly to virtual environments. In this study, we focused on this\nproblem and addressed the need to develop an automated system to detect student\nengagement levels during online learning. We proposed a novel training method\nwhich can discourage a model from leveraging sensitive features like gender for\nits predictions. The proposed method offers benefits not only in the\nenforcement of ethical standards, but also to enhance interpretability of the\nmodel predictions. We applied an attribute-orthogonal regularization technique\nto a split-model classifier, which uses multiple transfer learning strategies\nto achieve effective results in reducing disparity in the distribution of\nprediction for sensitivity groups from a Pearson correlation coefficient of\n0.897 for the unmitigated model, to 0.999 for the mitigated model. The source\ncode for this project is available on\nhttps://github.com/ashiskb/elearning-engagement-study .",
    "categories": [
      "cs.LG",
      "cs.AI",
      "cs.CY",
      "I.5.1; I.4.7"
    ],
    "published": "2025-10-24T22:39:01Z",
    "authors": [
      "James Thiering",
      "Tarun Sethupat Radha Krishna",
      "Dylan Zelkin",
      "Ashis Kumer Biswas"
    ],
    "pdf_url": "http://arxiv.org/pdf/2510.22057v1"
  },
  {
    "id": "2510.22054v1",
    "title": "Input Adaptive Bayesian Model Averaging",
    "abstract": "This paper studies prediction with multiple candidate models, where the goal\nis to combine their outputs. This task is especially challenging in\nheterogeneous settings, where different models may be better suited to\ndifferent inputs. We propose input adaptive Bayesian Model Averaging (IA-BMA),\na Bayesian method that assigns model weights conditional on the input. IA-BMA\nemploys an input adaptive prior, and yields a posterior distribution that\nadapts to each prediction, which we estimate with amortized variational\ninference. We derive formal guarantees for its performance, relative to any\nsingle predictor selected per input. We evaluate IABMA across regression and\nclassification tasks, studying data from personalized cancer treatment,\ncredit-card fraud detection, and UCI datasets. IA-BMA consistently delivers\nmore accurate and better-calibrated predictions than both non-adaptive\nbaselines and existing adaptive methods.",
    "categories": [
      "stat.ML",
      "cs.LG"
    ],
    "published": "2025-10-24T22:23:17Z",
    "authors": [
      "Yuli Slavutsky",
      "Sebastian Salazar",
      "David M. Blei"
    ],
    "pdf_url": "http://arxiv.org/pdf/2510.22054v1"
  },
  {
    "id": "2510.22052v1",
    "title": "Energy-Efficient Domain-Specific Artificial Intelligence Models and\n  Agents: Pathways and Paradigms",
    "abstract": "The field of artificial intelligence (AI) has taken a tight hold on broad\naspects of society, industry, business, and governance in ways that dictate the\nprosperity and might of the world's economies. The AI market size is projected\nto grow from 189 billion USD in 2023 to 4.8 trillion USD by 2033. Currently, AI\nis dominated by large language models that exhibit linguistic and visual\nintelligence. However, training these models requires a massive amount of data\nscraped from the web as well as large amounts of energy (50--60 GWh to train\nGPT-4). Despite these costs, these models often hallucinate, a characteristic\nthat prevents them from being deployed in critical application domains. In\ncontrast, the human brain consumes only 20~W of power. What is needed is the\nnext level of AI evolution in which lightweight domain-specific multimodal\nmodels with higher levels of intelligence can reason, plan, and make decisions\nin dynamic environments with real-time data and prior knowledge, while learning\ncontinuously and evolving in ways that enhance future decision-making\ncapability. This will define the next wave of AI, progressing from today's\nlarge models, trained with vast amounts of data, to nimble energy-efficient\ndomain-specific agents that can reason and think in a world full of\nuncertainty. To support such agents, hardware will need to be reimagined to\nallow energy efficiencies greater than 1000x over the state of the art. Such a\nvision of future AI systems is developed in this work.",
    "categories": [
      "cs.AI",
      "cs.LG"
    ],
    "published": "2025-10-24T22:21:08Z",
    "authors": [
      "Abhijit Chatterjee",
      "Niraj K. Jha",
      "Jonathan D. Cohen",
      "Thomas L. Griffiths",
      "Hongjing Lu",
      "Diana Marculescu",
      "Ashiqur Rasul",
      "Keshab K. Parhi"
    ],
    "pdf_url": "http://arxiv.org/pdf/2510.22052v1"
  },
  {
    "id": "2510.22050v1",
    "title": "Towards Error-Centric Intelligence II: Energy-Structured Causal Models",
    "abstract": "Contemporary machine learning optimizes for predictive accuracy, yet systems\nthat achieve state of the art performance remain causally opaque: their\ninternal representations provide no principled handle for intervention. We can\nretrain such models, but we cannot surgically edit specific mechanisms while\nholding others fixed, because learned latent variables lack causal semantics.\nWe argue for a conceptual reorientation: intelligence is the ability to build\nand refine explanations, falsifiable claims about manipulable structure that\nspecify what changes and what remains invariant under intervention.\nExplanations subsume prediction but demand more: causal commitments that can be\nindependently tested and corrected at the level of mechanisms. We introduce\ncomputational explanations, mappings from observations to intervention ready\ncausal accounts. We instantiate these explanations with Energy Structured\nCausal Models (ESCMs), in which mechanisms are expressed as constraints (energy\nfunctions or vector fields) rather than explicit input output maps, and\ninterventions act by local surgery on those constraints. This shift makes\ninternal structure manipulable at the level where explanations live: which\nrelations must hold, which can change, and what follows when they do. We\nprovide concrete instantiations of the structural-causal principles LAP and ICM\nin the ESCM context, and also argue that empirical risk minimization\nsystematically produces fractured, entangled representations, a failure we\nanalyze as gauge ambiguity in encoder energy pairs. Finally, we show that under\nmild conditions, ESCMs recover standard SCM semantics. Building on Part I's\nprinciples (LAP, ICM, CAP) and its definition of intelligence as\nexplanation-building under criticism, this paper offers a formal language for\ncausal reasoning in systems that aspire to understand, not merely to predict.",
    "categories": [
      "cs.AI",
      "cs.LG"
    ],
    "published": "2025-10-24T22:19:17Z",
    "authors": [
      "Marcus Thomas"
    ],
    "pdf_url": "http://arxiv.org/pdf/2510.22050v1"
  },
  {
    "id": "2510.22049v1",
    "title": "Massive Memorization with Hundreds of Trillions of Parameters for\n  Sequential Transducer Generative Recommenders",
    "abstract": "Modern large-scale recommendation systems rely heavily on user interaction\nhistory sequences to enhance the model performance. The advent of large\nlanguage models and sequential modeling techniques, particularly\ntransformer-like architectures, has led to significant advancements recently\n(e.g., HSTU, SIM, and TWIN models). While scaling to ultra-long user histories\n(10k to 100k items) generally improves model performance, it also creates\nsignificant challenges on latency, queries per second (QPS) and GPU cost in\nindustry-scale recommendation systems. Existing models do not adequately\naddress these industrial scalability issues. In this paper, we propose a novel\ntwo-stage modeling framework, namely VIrtual Sequential Target Attention\n(VISTA), which decomposes traditional target attention from a candidate item to\nuser history items into two distinct stages: (1) user history summarization\ninto a few hundred tokens; followed by (2) candidate item attention to those\ntokens. These summarization token embeddings are then cached in storage system\nand then utilized as sequence features for downstream model training and\ninference. This novel design for scalability enables VISTA to scale to lifelong\nuser histories (up to one million items) while keeping downstream training and\ninference costs fixed, which is essential in industry. Our approach achieves\nsignificant improvements in offline and online metrics and has been\nsuccessfully deployed on an industry leading recommendation platform serving\nbillions of users.",
    "categories": [
      "cs.IR",
      "cs.LG"
    ],
    "published": "2025-10-24T22:17:49Z",
    "authors": [
      "Zhimin Chen",
      "Chenyu Zhao",
      "Ka Chun Mo",
      "Yunjiang Jiang",
      "Jane H. Lee",
      "Shouwei Chen",
      "Khushhall Chandra Mahajan",
      "Ning Jiang",
      "Kai Ren",
      "Jinhui Li",
      "Wen-Yun Yang"
    ],
    "pdf_url": "http://arxiv.org/pdf/2510.22049v1"
  },
  {
    "id": "2510.22048v1",
    "title": "PF$\u0394$: A Benchmark Dataset for Power Flow under Load, Generation,\n  and Topology Variations",
    "abstract": "Power flow (PF) calculations are the backbone of real-time grid operations,\nacross workflows such as contingency analysis (where repeated PF evaluations\nassess grid security under outages) and topology optimization (which involves\nPF-based searches over combinatorially large action spaces). Running these\ncalculations at operational timescales or across large evaluation spaces\nremains a major computational bottleneck. Additionally, growing uncertainty in\npower system operations from the integration of renewables and climate-induced\nextreme weather also calls for tools that can accurately and efficiently\nsimulate a wide range of scenarios and operating conditions. Machine learning\nmethods offer a potential speedup over traditional solvers, but their\nperformance has not been systematically assessed on benchmarks that capture\nreal-world variability. This paper introduces PF$\\Delta$, a benchmark dataset\nfor power flow that captures diverse variations in load, generation, and\ntopology. PF$\\Delta$ contains 859,800 solved power flow instances spanning six\ndifferent bus system sizes, capturing three types of contingency scenarios (N ,\nN -1, and N -2), and including close-to-infeasible cases near steady-state\nvoltage stability limits. We evaluate traditional solvers and GNN-based\nmethods, highlighting key areas where existing approaches struggle, and\nidentifying open problems for future research. Our dataset is available at\nhttps://huggingface.co/datasets/pfdelta/pfdelta/tree/main and our code with\ndata generation scripts and model implementations is at\nhttps://github.com/MOSSLab-MIT/pfdelta.",
    "categories": [
      "cs.LG"
    ],
    "published": "2025-10-24T22:09:09Z",
    "authors": [
      "Ana K. Rivera",
      "Anvita Bhagavathula",
      "Alvaro Carbonero",
      "Priya Donti"
    ],
    "pdf_url": "http://arxiv.org/pdf/2510.22048v1"
  },
  {
    "id": "2510.22044v1",
    "title": "Fast Non-Log-Concave Sampling under Nonconvex Equality and Inequality\n  Constraints with Landing",
    "abstract": "Sampling from constrained statistical distributions is a fundamental task in\nvarious fields including Bayesian statistics, computational chemistry, and\nstatistical physics. This article considers the cases where the constrained\ndistribution is described by an unconstrained density, as well as additional\nequality and/or inequality constraints, which often make the constraint set\nnonconvex. Existing methods for nonconvex constraint set $\\Sigma \\subset\n\\mathbb{R}^d$ defined by equality or inequality constraints commonly rely on\ncostly projection steps. Moreover, they cannot handle equality and inequality\nconstraints simultaneously as each method only specialized in one case. In\naddition, rigorous and quantitative convergence guarantee is often lacking. In\nthis paper, we introduce Overdamped Langevin with LAnding (OLLA), a new\nframework that can design overdamped Langevin dynamics accommodating both\nequality and inequality constraints. The proposed dynamics also\ndeterministically corrects trajectories along the normal direction of the\nconstraint surface, thus obviating the need for explicit projections. We show\nthat, under suitable regularity conditions on the target density and $\\Sigma$,\nOLLA converges exponentially fast in $W_2$ distance to the constrained target\ndensity $\\rho_\\Sigma(x) \\propto \\exp(-f(x))d\\sigma_\\Sigma$. Lastly, through\nexperiments, we demonstrate the efficiency of OLLA compared to projection-based\nconstrained Langevin algorithms and their slack variable variants, highlighting\nits favorable computational cost and reasonable empirical mixing.",
    "categories": [
      "cs.LG",
      "stat.CO",
      "stat.ML"
    ],
    "published": "2025-10-24T22:06:03Z",
    "authors": [
      "Kijung Jeon",
      "Michael Muehlebach",
      "Molei Tao"
    ],
    "pdf_url": "http://arxiv.org/pdf/2510.22044v1"
  },
  {
    "id": "2510.22040v1",
    "title": "Generalized Top-k Mallows Model for Ranked Choices",
    "abstract": "The classic Mallows model is a foundational tool for modeling user\npreferences. However, it has limitations in capturing real-world scenarios,\nwhere users often focus only on a limited set of preferred items and are\nindifferent to the rest. To address this, extensions such as the top-k Mallows\nmodel have been proposed, aligning better with practical applications. In this\npaper, we address several challenges related to the generalized top-k Mallows\nmodel, with a focus on analyzing buyer choices. Our key contributions are: (1)\na novel sampling scheme tailored to generalized top-k Mallows models, (2) an\nefficient algorithm for computing choice probabilities under this model, and\n(3) an active learning algorithm for estimating the model parameters from\nobserved choice data. These contributions provide new tools for analysis and\nprediction in critical decision-making scenarios. We present a rigorous\nmathematical analysis for the performance of our algorithms. Furthermore,\nthrough extensive experiments on synthetic data and real-world data, we\ndemonstrate the scalability and accuracy of our proposed methods, and we\ncompare the predictive power of Mallows model for top-k lists compared to the\nsimpler Multinomial Logit model.",
    "categories": [
      "cs.LG",
      "cs.DS",
      "stat.ML"
    ],
    "published": "2025-10-24T21:49:21Z",
    "authors": [
      "Shahrzad Haddadan",
      "Sara Ahmadian"
    ],
    "pdf_url": "http://arxiv.org/pdf/2510.22040v1"
  },
  {
    "id": "2510.22037v1",
    "title": "ATLAS: Adaptive Transfer Scaling Laws for Multilingual Pretraining,\n  Finetuning, and Decoding the Curse of Multilinguality",
    "abstract": "Scaling laws research has focused overwhelmingly on English -- yet the most\nprominent AI models explicitly serve billions of international users. In this\nwork, we undertake the largest multilingual scaling laws study to date,\ntotaling 774 multilingual training experiments, spanning 10M-8B model\nparameters, 400+ training languages and 48 evaluation languages. We introduce\nthe Adaptive Transfer Scaling Law (ATLAS) for both monolingual and multilingual\npretraining, which outperforms existing scaling laws' out-of-sample\ngeneralization often by more than 0.3 R^2. Our analyses of the experiments shed\nlight on multilingual learning dynamics, transfer properties between languages,\nand the curse of multilinguality. First, we derive a cross-lingual transfer\nmatrix, empirically measuring mutual benefit scores between 38 x 38=1444\nlanguage pairs. Second, we derive a language-agnostic scaling law that reveals\nhow to optimally scale model size and data when adding languages without\nsacrificing performance. Third, we identify the computational crossover points\nfor when to pretrain from scratch versus finetune from multilingual\ncheckpoints. We hope these findings provide the scientific foundation for\ndemocratizing scaling laws across languages, and enable practitioners to\nefficiently scale models -- beyond English-first AI.",
    "categories": [
      "cs.CL",
      "cs.LG"
    ],
    "published": "2025-10-24T21:45:22Z",
    "authors": [
      "Shayne Longpre",
      "Sneha Kudugunta",
      "Niklas Muennighoff",
      "I-Hung Hsu",
      "Isaac Caswell",
      "Alex Pentland",
      "Sercan Arik",
      "Chen-Yu Lee",
      "Sayna Ebrahimi"
    ],
    "pdf_url": "http://arxiv.org/pdf/2510.22037v1"
  },
  {
    "id": "2510.22034v1",
    "title": "LLM-AR: LLM-powered Automated Reasoning Framework",
    "abstract": "Large language models (LLMs) can already identify patterns and reason\neffectively, yet their variable accuracy hampers adoption in high-stakes\ndecision-making applications. In this paper, we study this issue from a venture\ncapital perspective by predicting idea-stage startup success based on founder\ntraits. (i) To build a reliable prediction model, we introduce LLM-AR, a\npipeline inspired by neural-symbolic systems that distils LLM-generated\nheuristics into probabilistic rules executed by the ProbLog automated-reasoning\nengine. (ii) An iterative policy-evolution loop incorporates association-rule\nmining to progressively refine the prediction rules.\n  On unseen folds, LLM-AR achieves 59.5% precision and 8.7% recall, 5.9x the\nrandom baseline precision, while exposing every decision path for human\ninspection. The framework is interpretable and tunable via hyperparameters,\nshowing promise to extend into other domains.",
    "categories": [
      "cs.AI",
      "cs.LG"
    ],
    "published": "2025-10-24T21:36:18Z",
    "authors": [
      "Rick Chen",
      "Joseph Ternasky",
      "Aaron Ontoyin Yin",
      "Xianling Mu",
      "Fuat Alican",
      "Yigit Ihlamur"
    ],
    "pdf_url": "http://arxiv.org/pdf/2510.22034v1"
  },
  {
    "id": "2510.22033v2",
    "title": "Linearized Optimal Transport for Analysis of High-Dimensional\n  Point-Cloud and Single-Cell Data",
    "abstract": "Single-cell technologies generate high-dimensional point clouds of cells,\nenabling detailed characterization of complex patient states and treatment\nresponses. Yet each patient is represented by an irregular point cloud rather\nthan a simple vector, making it difficult to directly quantify and compare\nbiological differences between individuals. Nonlinear methods such as kernels\nand neural networks achieve predictive accuracy but act as black boxes,\noffering little biological interpretability.\n  To address these limitations, we adapt the Linear Optimal Transport (LOT)\nframework to this setting, embedding irregular point clouds into a\nfixed-dimensional Euclidean space while preserving distributional structure.\nThis embedding provides a principled linear representation that preserves\noptimal transport geometry while enabling downstream analysis. It also forms a\nregistration between any two patients, enabling direct comparison of their\ncellular distributions. Within this space, LOT enables: (i) \\textbf{accurate\nand interpretable classification} of COVID-19 patient states, where classifier\nweights map back to specific markers and spatial regions driving predictions;\nand (ii) \\textbf{synthetic data generation} for patient-derived organoids,\nexploiting the linearity of the LOT embedding. LOT barycenters yield averaged\ncellular profiles representing combined conditions or samples, supporting drug\ninteraction testing.\n  Together, these results establish LOT as a unified framework that bridges\npredictive performance, interpretability, and generative modeling. By\ntransforming heterogeneous point clouds into structured embeddings directly\ntraceable to the original data, LOT opens new opportunities for understanding\nimmune variation and treatment effects in high-dimensional biological systems.",
    "categories": [
      "cs.LG",
      "q-bio.QM",
      "stat.ML",
      "68T05"
    ],
    "published": "2025-10-24T21:33:12Z",
    "authors": [
      "Tianxiang Wang",
      "Yingtong Ke",
      "Dhananjay Bhaskar",
      "Smita Krishnaswamy",
      "Alexander Cloninger"
    ],
    "pdf_url": "http://arxiv.org/pdf/2510.22033v2"
  },
  {
    "id": "2510.24773v1",
    "title": "Point-level Uncertainty Evaluation of Mobile Laser Scanning Point Clouds",
    "abstract": "Reliable quantification of uncertainty in Mobile Laser Scanning (MLS) point\nclouds is essential for ensuring the accuracy and credibility of downstream\napplications such as 3D mapping, modeling, and change analysis. Traditional\nbackward uncertainty modeling heavily rely on high-precision reference data,\nwhich are often costly or infeasible to obtain at large scales. To address this\nissue, this study proposes a machine learning-based framework for point-level\nuncertainty evaluation that learns the relationship between local geometric\nfeatures and point-level errors. The framework is implemented using two\nensemble learning models, Random Forest (RF) and XGBoost, which are trained and\nvalidated on a spatially partitioned real-world dataset to avoid data leakage.\nExperimental results demonstrate that both models can effectively capture the\nnonlinear relationships between geometric characteristics and uncertainty,\nachieving mean ROC-AUC values above 0.87. The analysis further reveals that\ngeometric features describing elevation variation, point density, and local\nstructural complexity play a dominant role in predicting uncertainty. The\nproposed framework offers a data-driven perspective of uncertainty evaluation,\nproviding a scalable and adaptable foundation for future quality control and\nerror analysis of large-scale point clouds.",
    "categories": [
      "cs.CV",
      "cs.LG",
      "cs.RO",
      "eess.IV"
    ],
    "published": "2025-10-24T21:30:52Z",
    "authors": [
      "Ziyang Xu",
      "Olaf Wysocki",
      "Christoph Holst"
    ],
    "pdf_url": "http://arxiv.org/pdf/2510.24773v1"
  },
  {
    "id": "2510.22031v1",
    "title": "Differentiable Constraint-Based Causal Discovery",
    "abstract": "Causal discovery from observational data is a fundamental task in artificial\nintelligence, with far-reaching implications for decision-making, predictions,\nand interventions. Despite significant advances, existing methods can be\nbroadly categorized as constraint-based or score-based approaches.\nConstraint-based methods offer rigorous causal discovery but are often hindered\nby small sample sizes, while score-based methods provide flexible optimization\nbut typically forgo explicit conditional independence testing. This work\nexplores a third avenue: developing differentiable $d$-separation scores,\nobtained through a percolation theory using soft logic. This enables the\nimplementation of a new type of causal discovery method: gradient-based\noptimization of conditional independence constraints. Empirical evaluations\ndemonstrate the robust performance of our approach in low-sample regimes,\nsurpassing traditional constraint-based and score-based baselines on a\nreal-world dataset. Code and data of the proposed method are publicly available\nat https://github$.$com/PurdueMINDS/DAGPA.",
    "categories": [
      "cs.LG",
      "cs.AI",
      "stat.ML"
    ],
    "published": "2025-10-24T21:28:39Z",
    "authors": [
      "Jincheng Zhou",
      "Mengbo Wang",
      "Anqi He",
      "Yumeng Zhou",
      "Hessam Olya",
      "Murat Kocaoglu",
      "Bruno Ribeiro"
    ],
    "pdf_url": "http://arxiv.org/pdf/2510.22031v1"
  },
  {
    "id": "2510.22027v1",
    "title": "Online Optimization for Offline Safe Reinforcement Learning",
    "abstract": "We study the problem of Offline Safe Reinforcement Learning (OSRL), where the\ngoal is to learn a reward-maximizing policy from fixed data under a cumulative\ncost constraint. We propose a novel OSRL approach that frames the problem as a\nminimax objective and solves it by combining offline RL with online\noptimization algorithms. We prove the approximate optimality of this approach\nwhen integrated with an approximate offline RL oracle and no-regret online\noptimization. We also present a practical approximation that can be combined\nwith any offline RL algorithm, eliminating the need for offline policy\nevaluation. Empirical results on the DSRL benchmark demonstrate that our method\nreliably enforces safety constraints under stringent cost budgets, while\nachieving high rewards. The code is available at\nhttps://github.com/yassineCh/O3SRL.",
    "categories": [
      "cs.LG",
      "cs.AI",
      "stat.ML"
    ],
    "published": "2025-10-24T21:12:47Z",
    "authors": [
      "Yassine Chemingui",
      "Aryan Deshwal",
      "Alan Fern",
      "Thanh Nguyen-Tang",
      "Janardhan Rao Doppa"
    ],
    "pdf_url": "http://arxiv.org/pdf/2510.22027v1"
  },
  {
    "id": "2510.22026v1",
    "title": "Normalization in Attention Dynamics",
    "abstract": "We study the effect of normalization schemes on token representations in deep\ntransformers. Modeling their evolution as interacting particles on the sphere,\nwe show that normalization acts as a form of speed regulation. This perspective\nenables a unified analysis of several schemes -- including Post-LN, Pre-LN,\nMix-LN, Peri-LN, nGPT, and LN-Scaling -- revealing how they influence\nclustering dynamics and representation collapse. Our framework clarifies how\ndifferent schemes shape token representations across layers and provides a\nprincipled basis for comparing them, identifying Peri-LN as a particularly\neffective choice.",
    "categories": [
      "cs.LG",
      "cs.AI",
      "68T07, 35Q68, 37C10, 37N99, 82C22"
    ],
    "published": "2025-10-24T21:10:16Z",
    "authors": [
      "Nikita Karagodin",
      "Shu Ge",
      "Yury Polyanskiy",
      "Philippe Rigollet"
    ],
    "pdf_url": "http://arxiv.org/pdf/2510.22026v1"
  },
  {
    "id": "2510.22021v1",
    "title": "K-DAREK: Distance Aware Error for Kurkova Kolmogorov Networks",
    "abstract": "Neural networks are parametric and powerful tools for function approximation,\nand the choice of architecture heavily influences their interpretability,\nefficiency, and generalization. In contrast, Gaussian processes (GPs) are\nnonparametric probabilistic models that define distributions over functions\nusing a kernel to capture correlations among data points. However, these models\nbecome computationally expensive for large-scale problems, as they require\ninverting a large covariance matrix. Kolmogorov- Arnold networks (KANs),\nsemi-parametric neural architectures, have emerged as a prominent approach for\nmodeling complex functions with structured and efficient representations\nthrough spline layers. Kurkova Kolmogorov-Arnold networks (KKANs) extend this\nidea by reducing the number of spline layers in KAN and replacing them with\nChebyshev layers and multi-layer perceptrons, thereby mapping inputs into\nhigher-dimensional spaces before applying spline-based transformations.\nCompared to KANs, KKANs perform more stable convergence during training, making\nthem a strong architecture for estimating operators and system modeling in\ndynamical systems. By enhancing the KKAN architecture, we develop a novel\nlearning algorithm, distance-aware error for Kurkova-Kolmogorov networks\n(K-DAREK), for efficient and interpretable function approximation with\nuncertainty quantification. Our approach establishes robust error bounds that\nare distance-aware; this means they reflect the proximity of a test point to\nits nearest training points. Through case studies on a safe control task, we\ndemonstrate that K-DAREK is about four times faster and ten times higher\ncomputationally efficiency than Ensemble of KANs, 8.6 times more scalable than\nGP by increasing the data size, and 50% safer than our previous work\ndistance-aware error for Kolmogorov networks (DAREK).",
    "categories": [
      "cs.LG",
      "eess.SP",
      "stat.ML"
    ],
    "published": "2025-10-24T20:49:59Z",
    "authors": [
      "Masoud Ataei",
      "Vikas Dhiman",
      "Mohammad Javad Khojasteh"
    ],
    "pdf_url": "http://arxiv.org/pdf/2510.22021v1"
  },
  {
    "id": "2510.22017v1",
    "title": "Do You Trust the Process?: Modeling Institutional Trust for Community\n  Adoption of Reinforcement Learning Policies",
    "abstract": "Many governmental bodies are adopting AI policies for decision-making. In\nparticular, Reinforcement Learning has been used to design policies that\ncitizens would be expected to follow if implemented. Much RL work assumes that\ncitizens follow these policies, and evaluate them with this in mind. However,\nwe know from prior work that without institutional trust, citizens will not\nfollow policies put in place by governments. In this work, we develop a\ntrust-aware RL algorithm for resource allocation in communities. We consider\nthe case of humanitarian engineering, where the organization is aiming to\ndistribute some technology or resource to community members. We use a Deep\nDeterministic Policy Gradient approach to learn a resource allocation that fits\nthe needs of the organization. Then, we simulate resource allocation according\nto the learned policy, and model the changes in institutional trust of\ncommunity members. We investigate how this incorporation of institutional trust\naffects outcomes, and ask how effectively an organization can learn policies if\ntrust values are private. We find that incorporating trust into RL algorithms\ncan lead to more successful policies, specifically when the organization's\ngoals are less certain. We find more conservative trust estimates lead to\nincreased fairness and average community trust, though organization success\nsuffers. Finally, we explore a strategy to prevent unfair outcomes to\ncommunities. We implement a quota system by an external entity which decreases\nthe organization's utility when it does not serve enough community members. We\nfind this intervention can improve fairness and trust among communities in some\ncases, while decreasing the success of the organization. This work underscores\nthe importance of institutional trust in algorithm design and implementation,\nand identifies a tension between organization success and community well-being.",
    "categories": [
      "cs.LG",
      "cs.CY",
      "cs.SI"
    ],
    "published": "2025-10-24T20:37:31Z",
    "authors": [
      "Naina Balepur",
      "Xingrui Pei",
      "Hari Sundaram"
    ],
    "pdf_url": "http://arxiv.org/pdf/2510.22017v1"
  },
  {
    "id": "2510.22016v1",
    "title": "Cost-Sensitive Evaluation for Binary Classifiers",
    "abstract": "Selecting an appropriate evaluation metric for classifiers is crucial for\nmodel comparison and parameter optimization, yet there is not consensus on a\nuniversally accepted metric that serves as a definitive standard. Moreover,\nthere is often a misconception about the perceived need to mitigate imbalance\nin datasets used to train classification models. Since the final goal in\nclassifier optimization is typically maximizing the return of investment or,\nequivalently, minimizing the Total Classification Cost (TCC), we define\nWeighted Accuracy (WA), an evaluation metric for binary classifiers with a\nstraightforward interpretation as a weighted version of the well-known accuracy\nmetric, coherent with the need of minimizing TCC. We clarify the conceptual\nframework for handling class imbalance in cost-sensitive scenarios, providing\nan alternative to rebalancing techniques. This framework can be applied to any\nmetric that, like WA, can be expressed as a linear combination of\nexample-dependent quantities and allows for comparing the results obtained in\ndifferent datasets and for addressing discrepancies between the development\ndataset, used to train and validate the model, and the target dataset, where\nthe model will be deployed. It also specifies in which scenarios using\nUCCs-unaware class rebalancing techniques or rebalancing metrics aligns with\nTCC minimization and when it is instead counterproductive. Finally, we propose\na procedure to estimate the WA weight parameter in the absence of fully\nspecified UCCs and demonstrate the robustness of WA by analyzing its\ncorrelation with TCC in example-dependent scenarios.",
    "categories": [
      "cs.LG",
      "stat.ML",
      "62-08 (Primary) 62-04, 65D10 (Secondary)",
      "G.3; I.6.4"
    ],
    "published": "2025-10-24T20:34:18Z",
    "authors": [
      "Pierangelo Lombardo",
      "Antonio Casoli",
      "Cristian Cingolani",
      "Shola Oshodi",
      "Michele Zanatta"
    ],
    "pdf_url": "http://arxiv.org/pdf/2510.22016v1"
  },
  {
    "id": "2510.22010v1",
    "title": "FlowOpt: Fast Optimization Through Whole Flow Processes for\n  Training-Free Editing",
    "abstract": "The remarkable success of diffusion and flow-matching models has ignited a\nsurge of works on adapting them at test time for controlled generation tasks.\nExamples range from image editing to restoration, compression and\npersonalization. However, due to the iterative nature of the sampling process\nin those models, it is computationally impractical to use gradient-based\noptimization to directly control the image generated at the end of the process.\nAs a result, existing methods typically resort to manipulating each timestep\nseparately. Here we introduce FlowOpt - a zero-order (gradient-free)\noptimization framework that treats the entire flow process as a black box,\nenabling optimization through the whole sampling path without backpropagation\nthrough the model. Our method is both highly efficient and allows users to\nmonitor the intermediate optimization results and perform early stopping if\ndesired. We prove a sufficient condition on FlowOpt's step-size, under which\nconvergence to the global optimum is guaranteed. We further show how to\nempirically estimate this upper bound so as to choose an appropriate step-size.\nWe demonstrate how FlowOpt can be used for image editing, showcasing two\noptions: (i) inversion (determining the initial noise that generates a given\nimage), and (ii) directly steering the edited image to be similar to the source\nimage while conforming to a target text prompt. In both cases, FlowOpt achieves\nstate-of-the-art results while using roughly the same number of neural function\nevaluations (NFEs) as existing methods. Code and examples are available on the\nproject's webpage.",
    "categories": [
      "cs.CV",
      "cs.LG",
      "eess.IV"
    ],
    "published": "2025-10-24T20:24:26Z",
    "authors": [
      "Or Ronai",
      "Vladimir Kulikov",
      "Tomer Michaeli"
    ],
    "pdf_url": "http://arxiv.org/pdf/2510.22010v1"
  },
  {
    "id": "2510.22008v1",
    "title": "A Multimodal Human Protein Embeddings Database: DeepDrug Protein\n  Embeddings Bank (DPEB)",
    "abstract": "Computationally predicting protein-protein interactions (PPIs) is challenging\ndue to the lack of integrated, multimodal protein representations. DPEB is a\ncurated collection of 22,043 human proteins that integrates four embedding\ntypes: structural (AlphaFold2), transformer-based sequence (BioEmbeddings),\ncontextual amino acid patterns (ESM-2: Evolutionary Scale Modeling), and\nsequence-based n-gram statistics (ProtVec]). AlphaFold2 protein structures are\navailable through public databases (e.g., AlphaFold2 Protein Structure\nDatabase), but the internal neural network embeddings are not. DPEB addresses\nthis gap by providing AlphaFold2-derived embeddings for computational modeling.\nOur benchmark evaluations show GraphSAGE with BioEmbedding achieved the highest\nPPI prediction performance (87.37% AUROC, 79.16% accuracy). The framework also\nachieved 77.42% accuracy for enzyme classification and 86.04% accuracy for\nprotein family classification. DPEB supports multiple graph neural network\nmethods for PPI prediction, enabling applications in systems biology, drug\ntarget identification, pathway analysis, and disease mechanism studies.",
    "categories": [
      "cs.LG",
      "q-bio.MN"
    ],
    "published": "2025-10-24T20:22:17Z",
    "authors": [
      "Md Saiful Islam Sajol",
      "Magesh Rajasekaran",
      "Hayden Gemeinhardt",
      "Adam Bess",
      "Chris Alvin",
      "Supratik Mukhopadhyay"
    ],
    "pdf_url": "http://arxiv.org/pdf/2510.22008v1"
  },
  {
    "id": "2510.22007v1",
    "title": "Optimal Detection for Language Watermarks with Pseudorandom Collision",
    "abstract": "Text watermarking plays a crucial role in ensuring the traceability and\naccountability of large language model (LLM) outputs and mitigating misuse.\nWhile promising, most existing methods assume perfect pseudorandomness. In\npractice, repetition in generated text induces collisions that create\nstructured dependence, compromising Type I error control and invalidating\nstandard analyses.\n  We introduce a statistical framework that captures this structure through a\nhierarchical two-layer partition. At its core is the concept of minimal units\n-- the smallest groups treatable as independent across units while permitting\ndependence within. Using minimal units, we define a non-asymptotic efficiency\nmeasure and cast watermark detection as a minimax hypothesis testing problem.\n  Applied to Gumbel-max and inverse-transform watermarks, our framework\nproduces closed-form optimal rules. It explains why discarding repeated\nstatistics often improves performance and shows that within-unit dependence\nmust be addressed unless degenerate. Both theory and experiments confirm\nimproved detection power with rigorous Type I error control. These results\nprovide the first principled foundation for watermark detection under imperfect\npseudorandomness, offering both theoretical insight and practical guidance for\nreliable tracing of model outputs.",
    "categories": [
      "cs.LG",
      "cs.CL",
      "cs.CR",
      "math.ST",
      "stat.ML",
      "stat.TH"
    ],
    "published": "2025-10-24T20:21:52Z",
    "authors": [
      "T. Tony Cai",
      "Xiang Li",
      "Qi Long",
      "Weijie J. Su",
      "Garrett G. Wen"
    ],
    "pdf_url": "http://arxiv.org/pdf/2510.22007v1"
  },
  {
    "id": "2510.22002v1",
    "title": "An Introductory Guide to Koopman Learning",
    "abstract": "Koopman operators provide a linear framework for data-driven analyses of\nnonlinear dynamical systems, but their infinite-dimensional nature presents\nmajor computational challenges. In this article, we offer an introductory guide\nto Koopman learning, emphasizing rigorously convergent data-driven methods for\nforecasting and spectral analysis. We provide a unified account of error\ncontrol via residuals in both finite- and infinite-dimensional settings, an\nelementary proof of convergence for generalized Laplace analysis -- a variant\nof filtered power iteration that works for operators with continuous spectra\nand no spectral gaps -- and review state-of-the-art approaches for computing\ncontinuous spectra and spectral measures. The goal is to provide both newcomers\nand experts with a clear, structured overview of reliable data-driven\ntechniques for Koopman spectral analysis.",
    "categories": [
      "math.NA",
      "cs.LG",
      "cs.NA",
      "math.DS",
      "math.OC",
      "math.SP"
    ],
    "published": "2025-10-24T20:09:22Z",
    "authors": [
      "Matthew J. Colbrook",
      "Zlatko Drma\u010d",
      "Andrew Horning"
    ],
    "pdf_url": "http://arxiv.org/pdf/2510.22002v1"
  },
  {
    "id": "2510.21998v1",
    "title": "From Black-box to Causal-box: Towards Building More Interpretable Models",
    "abstract": "Understanding the predictions made by deep learning models remains a central\nchallenge, especially in high-stakes applications. A promising approach is to\nequip models with the ability to answer counterfactual questions --\nhypothetical ``what if?'' scenarios that go beyond the observed data and\nprovide insight into a model reasoning. In this work, we introduce the notion\nof causal interpretability, which formalizes when counterfactual queries can be\nevaluated from a specific class of models and observational data. We analyze\ntwo common model classes -- blackbox and concept-based predictors -- and show\nthat neither is causally interpretable in general. To address this gap, we\ndevelop a framework for building models that are causally interpretable by\ndesign. Specifically, we derive a complete graphical criterion that determines\nwhether a given model architecture supports a given counterfactual query. This\nleads to a fundamental tradeoff between causal interpretability and predictive\naccuracy, which we characterize by identifying the unique maximal set of\nfeatures that yields an interpretable model with maximal predictive\nexpressiveness. Experiments corroborate the theoretical findings.",
    "categories": [
      "cs.LG",
      "cs.AI",
      "stat.ML"
    ],
    "published": "2025-10-24T20:03:18Z",
    "authors": [
      "Inwoo Hwang",
      "Yushu Pan",
      "Elias Bareinboim"
    ],
    "pdf_url": "http://arxiv.org/pdf/2510.21998v1"
  },
  {
    "id": "2510.21995v1",
    "title": "Is Temporal Difference Learning the Gold Standard for Stitching in RL?",
    "abstract": "Reinforcement learning (RL) promises to solve long-horizon tasks even when\ntraining data contains only short fragments of the behaviors. This experience\nstitching capability is often viewed as the purview of temporal difference (TD)\nmethods. However, outside of small tabular settings, trajectories never\nintersect, calling into question this conventional wisdom. Moreover, the common\nbelief is that Monte Carlo (MC) methods should not be able to recombine\nexperience, yet it remains unclear whether function approximation could result\nin a form of implicit stitching. The goal of this paper is to empirically study\nwhether the conventional wisdom about stitching actually holds in settings\nwhere function approximation is used. We empirically demonstrate that Monte\nCarlo (MC) methods can also achieve experience stitching. While TD methods do\nachieve slightly stronger capabilities than MC methods (in line with\nconventional wisdom), that gap is significantly smaller than the gap between\nsmall and large neural networks (even on quite simple tasks). We find that\nincreasing critic capacity effectively reduces the generalization gap for both\nthe MC and TD methods. These results suggest that the traditional TD inductive\nbias for stitching may be less necessary in the era of large models for RL and,\nin some cases, may offer diminishing returns. Additionally, our results suggest\nthat stitching, a form of generalization unique to the RL setting, might be\nachieved not through specialized algorithms (temporal difference learning) but\nrather through the same recipe that has provided generalization in other\nmachine learning settings (via scale). Project website:\nhttps://michalbortkiewicz.github.io/golden-standard/",
    "categories": [
      "cs.LG",
      "cs.AI",
      "stat.ML"
    ],
    "published": "2025-10-24T20:00:14Z",
    "authors": [
      "Micha\u0142 Bortkiewicz",
      "W\u0142adys\u0142aw Pa\u0142ucki",
      "Mateusz Ostaszewski",
      "Benjamin Eysenbach"
    ],
    "pdf_url": "http://arxiv.org/pdf/2510.21995v1"
  },
  {
    "id": "2510.21994v1",
    "title": "Deep Learning on Real-World Graphs",
    "abstract": "Graph Neural Networks (GNNs) have become a central tool for learning on\ngraph-structured data, yet their applicability to real-world systems remains\nlimited by key challenges such as scalability, temporality, directionality,\ndata incompleteness, and structural uncertainty. This thesis introduces a\nseries of models addressing these limitations: SIGN for scalable graph\nlearning, TGN for temporal graphs, Dir-GNN for directed and heterophilic\nnetworks, Feature Propagation (FP) for learning with missing node features, and\nNuGget for game-theoretic structural inference. Together, these contributions\nbridge the gap between academic benchmarks and industrial-scale graphs,\nenabling the use of GNNs in domains such as social and recommender systems.",
    "categories": [
      "cs.LG"
    ],
    "published": "2025-10-24T19:58:13Z",
    "authors": [
      "Emanuele Rossi"
    ],
    "pdf_url": "http://arxiv.org/pdf/2510.21994v1"
  },
  {
    "id": "2510.21980v1",
    "title": "Boltzmann Graph Ensemble Embeddings for Aptamer Libraries",
    "abstract": "Machine-learning methods in biochemistry commonly represent molecules as\ngraphs of pairwise intermolecular interactions for property and structure\npredictions. Most methods operate on a single graph, typically the minimal free\nenergy (MFE) structure, for low-energy ensembles (conformations) representative\nof structures at thermodynamic equilibrium. We introduce a thermodynamically\nparameterized exponential-family random graph (ERGM) embedding that models\nmolecules as Boltzmann-weighted ensembles of interaction graphs. We evaluate\nthis embedding on SELEX datasets, where experimental biases (e.g., PCR\namplification or sequencing noise) can obscure true aptamer-ligand affinity,\nproducing anomalous candidates whose observed abundance diverges from their\nactual binding strength. We show that the proposed embedding enables robust\ncommunity detection and subgraph-level explanations for aptamer ligand\naffinity, even in the presence of biased observations. This approach may be\nused to identify low-abundance aptamer candidates for further experimental\nevaluation.",
    "categories": [
      "cs.LG",
      "math.PR",
      "q-bio.QM",
      "stat.ML"
    ],
    "published": "2025-10-24T19:13:36Z",
    "authors": [
      "Starlika Bauskar",
      "Jade Jiao",
      "Narayanan Kannan",
      "Alexander Kimm",
      "Justin M. Baker",
      "Matthew J. Tyler",
      "Andrea L. Bertozzi",
      "Anne M. Andrews"
    ],
    "pdf_url": "http://arxiv.org/pdf/2510.21980v1"
  },
  {
    "id": "2510.21978v1",
    "title": "Beyond Reasoning Gains: Mitigating General Capabilities Forgetting in\n  Large Reasoning Models",
    "abstract": "Reinforcement learning with verifiable rewards (RLVR) has delivered\nimpressive gains in mathematical and multimodal reasoning and has become a\nstandard post-training paradigm for contemporary language and vision-language\nmodels. However, the RLVR recipe introduces a significant risk of capability\nregression, where models forget foundational skills after prolonged training\nwithout employing regularization strategies. We empirically confirm this\nconcern, observing that open-source reasoning models suffer performance\ndegradation on core capabilities such as perception and faithfulness. While\nimposing regularization terms like KL divergence can help prevent deviation\nfrom the base model, these terms are calculated on the current task, thus they\ndo not guarantee broader knowledge. Meanwhile, commonly used experience replay\nacross heterogeneous domains makes it nontrivial to decide how much training\nfocus each objective should receive. To address this, we propose RECAP-a replay\nstrategy with dynamic objective reweighting for general knowledge preservation.\nOur reweighting mechanism adapts in an online manner using short-horizon\nsignals of convergence and instability, shifting the post-training focus away\nfrom saturated objectives and toward underperforming or volatile ones. Our\nmethod is end-to-end and readily applicable to existing RLVR pipelines without\ntraining additional models or heavy tuning. Extensive experiments on benchmarks\nbased on Qwen2.5-VL-3B and Qwen2.5-VL-7B demonstrate the effectiveness of our\nmethod, which not only preserves general capabilities but also improves\nreasoning by enabling more flexible trade-offs among in-task rewards.",
    "categories": [
      "cs.LG",
      "cs.AI"
    ],
    "published": "2025-10-24T19:08:48Z",
    "authors": [
      "Hoang Phan",
      "Xianjun Yang",
      "Kevin Yao",
      "Jingyu Zhang",
      "Shengjie Bi",
      "Xiaocheng Tang",
      "Madian Khabsa",
      "Lijuan Liu",
      "Deren Lei"
    ],
    "pdf_url": "http://arxiv.org/pdf/2510.21978v1"
  },
  {
    "id": "2510.21974v1",
    "title": "Deep Jump Gaussian Processes for Surrogate Modeling of High-Dimensional\n  Piecewise Continuous Functions",
    "abstract": "We introduce Deep Jump Gaussian Processes (DJGP), a novel method for\nsurrogate modeling of high-dimensional piecewise continuous functions. DJGP\novercomes the limitations of conventional Jump Gaussian Processes in\nhigh-dimensional input spaces by adding a locally linear projection layer to\nJump Gaussian Processes. This projection uses region-specific matrices to\ncapture local subspace structures, naturally complementing the localized nature\nof JGP, a variant of local Gaussian Processes. To control model complexity, we\nplace a Gaussian Process prior on the projection matrices, allowing them to\nevolve smoothly across the input space. The projected inputs are then modeled\nwith a JGP to capture piecewise continuous relationships with the response.\nThis yields a distinctive two-layer deep learning of GP/JGP. We further develop\na scalable variational inference algorithm to jointly learn the projection\nmatrices and JGP hyperparameters. Experiments on synthetic and benchmark\ndatasets demonstrate that DJGP delivers superior predictive accuracy and more\nreliable uncertainty quantification compared to existing approaches.",
    "categories": [
      "cs.LG",
      "stat.ML",
      "62G08",
      "I.2.6"
    ],
    "published": "2025-10-24T18:59:24Z",
    "authors": [
      "Yang Xu",
      "Chiwoo Park"
    ],
    "pdf_url": "http://arxiv.org/pdf/2510.21974v1"
  },
  {
    "id": "2510.23643v1",
    "title": "SAND: A Self-supervised and Adaptive NAS-Driven Framework for Hardware\n  Trojan Detection",
    "abstract": "The globalized semiconductor supply chain has made Hardware Trojans (HT) a\nsignificant security threat to embedded systems, necessitating the design of\nefficient and adaptable detection mechanisms. Despite promising machine\nlearning-based HT detection techniques in the literature, they suffer from ad\nhoc feature selection and the lack of adaptivity, all of which hinder their\neffectiveness across diverse HT attacks. In this paper, we propose SAND, a\nselfsupervised and adaptive NAS-driven framework for efficient HT detection.\nSpecifically, this paper makes three key contributions. (1) We leverage\nself-supervised learning (SSL) to enable automated feature extraction,\neliminating the dependency on manually engineered features. (2) SAND integrates\nneural architecture search (NAS) to dynamically optimize the downstream\nclassifier, allowing for seamless adaptation to unseen benchmarks with minimal\nfine-tuning. (3) Experimental results show that SAND achieves a significant\nimprovement in detection accuracy (up to 18.3%) over state-of-the-art methods,\nexhibits high resilience against evasive Trojans, and demonstrates strong\ngeneralization.",
    "categories": [
      "cs.CR",
      "cs.AI",
      "cs.LG",
      "I.2.6; D.4.6"
    ],
    "published": "2025-10-24T18:55:00Z",
    "authors": [
      "Zhixin Pan",
      "Ziyu Shu",
      "Linh Nguyen",
      "Amberbir Alemayoh"
    ],
    "pdf_url": "http://arxiv.org/pdf/2510.23643v1"
  },
  {
    "id": "2510.21969v1",
    "title": "Adaptive Split-MMD Training for Small-Sample Cross-Dataset P300 EEG\n  Classification",
    "abstract": "Detecting single-trial P300 from EEG is difficult when only a few labeled\ntrials are available. When attempting to boost a small target set with a large\nsource dataset through transfer learning, cross-dataset shift arises. To\naddress this challenge, we study transfer between two public visual-oddball ERP\ndatasets using five shared electrodes (Fz, Pz, P3, P4, Oz) under a strict\nsmall-sample regime (target: 10 trials/subject; source: 80 trials/subject). We\nintroduce Adaptive Split Maximum Mean Discrepancy Training (AS-MMD), which\ncombines (i) a target-weighted loss with warm-up tied to the square root of the\nsource/target size ratio, (ii) Split Batch Normalization (Split-BN) with shared\naffine parameters and per-domain running statistics, and (iii) a parameter-free\nlogit-level Radial Basis Function kernel Maximum Mean Discrepancy (RBF-MMD)\nterm using the median-bandwidth heuristic. Implemented on an EEG Conformer,\nAS-MMD is backbone-agnostic and leaves the inference-time model unchanged.\nAcross both transfer directions, it outperforms target-only and pooled training\n(Active Visual Oddball: accuracy/AUC 0.66/0.74; ERP CORE P3: 0.61/0.65), with\ngains over pooling significant under corrected paired t-tests. Ablations\nattribute improvements to all three components.",
    "categories": [
      "eess.SP",
      "cs.LG",
      "cs.NE"
    ],
    "published": "2025-10-24T18:48:21Z",
    "authors": [
      "Weiyu Chen",
      "Arnaud Delorme"
    ],
    "pdf_url": "http://arxiv.org/pdf/2510.21969v1"
  },
  {
    "id": "2510.21961v1",
    "title": "Parallel Sampling from Masked Diffusion Models via Conditional\n  Independence Testing",
    "abstract": "Masked diffusion models (MDMs) offer a compelling alternative to\nautoregressive models (ARMs) for discrete text generation because they enable\nparallel token sampling, rather than sequential, left-to-right generation. This\nmeans potentially much faster inference. However, effective parallel sampling\nfaces two competing requirements: (i) simultaneously updated tokens must be\nconditionally independent, and (ii) updates should prioritise high-confidence\npredictions. These goals conflict because high-confidence predictions often\ncluster and depend on each other, opportunities for parallel updates.\n  We present PUNT, a model-agnostic sampler that reconciles this trade-off. Our\nmethod identifies token dependencies and removes lower-confidence tokens from\nconflicting groups. This produces sets of indices for unmasking that satisfy\nboth independence and confidence criteria. Our approach ensures improved\nparallel unmasking through approximate conditional independence testing.\n  Our experiments show that PUNT delivers a superior trade-off between accuracy\nand compute when compared to other strong training-free baselines, especially\nfor generation of longer sequences. On the IFEval benchmark, it achieves up to\n16\\% higher accuracy over baseline methods, including sequential generation\n(one-by-one). These gains hold across different values of hyperparameters,\nmitigating the need for brittle hyperparameter tuning. Moreover, we observe\nthat PUNT induces an emergent hierarchical generation strategy, where the model\nfirst establishes high-level paragraph structure before local refinement,\nsuggesting a planning-like generation process that contributes to strong\nalignment performance.",
    "categories": [
      "cs.LG",
      "cs.CL"
    ],
    "published": "2025-10-24T18:41:26Z",
    "authors": [
      "Iskander Azangulov",
      "Teodora Pandeva",
      "Niranjani Prasad",
      "Javier Zazo",
      "Sushrut Karmalkar"
    ],
    "pdf_url": "http://arxiv.org/pdf/2510.21961v1"
  },
  {
    "id": "2510.21956v1",
    "title": "Transformer Based Linear Attention with Optimized GPU Kernel\n  Implementation",
    "abstract": "The original softmax-based attention mechanism (regular attention) in the\nextremely successful Transformer architecture computes attention between $N$\ntokens, each embedded in a $D$-dimensional head, with a time complexity of\n$O(N^2D)$. Given the success of Transformers, improving their runtime during\nboth training and inference is a popular research area. One such approach is\nthe introduction of the linear attention (LA) mechanisms, which offers a linear\ntime complexity of $O(ND^2)$ and have demonstrated comparable accuracy to\nregular attention. However, LA in practice lags behind its theoretical\nefficiency. We propose a novel method for LA's forward and backward passes,\nalong with a highly-optimized CUDA implementation. Our approach outperforms the\nstate-of-the-art by 3.3 times in speed and reduces memory consumption by 3.6\ntimes. We validate these improvements in both single-layer and end-to-end\nsettings by training a 1.4 billion parameter language model, which demonstrates\nsimilar expressivity to regular attention on major reasoning benchmarks.",
    "categories": [
      "cs.LG",
      "cs.CL"
    ],
    "published": "2025-10-24T18:32:20Z",
    "authors": [
      "Armin Gerami",
      "Ramani Duraiswami"
    ],
    "pdf_url": "http://arxiv.org/pdf/2510.21956v1"
  },
  {
    "id": "2510.21952v1",
    "title": "Revisiting Orbital Minimization Method for Neural Operator Decomposition",
    "abstract": "Spectral decomposition of linear operators plays a central role in many areas\nof machine learning and scientific computing. Recent work has explored training\nneural networks to approximate eigenfunctions of such operators, enabling\nscalable approaches to representation learning, dynamical systems, and partial\ndifferential equations (PDEs). In this paper, we revisit a classical\noptimization framework from the computational physics literature known as the\n\\emph{orbital minimization method} (OMM), originally proposed in the 1990s for\nsolving eigenvalue problems in computational chemistry. We provide a simple\nlinear-algebraic proof of the consistency of the OMM objective, and reveal\nconnections between this method and several ideas that have appeared\nindependently across different domains. Our primary goal is to justify its\nbroader applicability in modern learning pipelines. We adapt this framework to\ntrain neural networks to decompose positive semidefinite operators, and\ndemonstrate its practical advantages across a range of benchmark tasks. Our\nresults highlight how revisiting classical numerical methods through the lens\nof modern theory and computation can provide not only a principled approach for\ndeploying neural networks in numerical simulation, but also effective and\nscalable tools for machine learning.",
    "categories": [
      "cs.LG",
      "cs.NA",
      "math.NA",
      "stat.ML"
    ],
    "published": "2025-10-24T18:26:18Z",
    "authors": [
      "J. Jon Ryu",
      "Samuel Zhou",
      "Gregory W. Wornell"
    ],
    "pdf_url": "http://arxiv.org/pdf/2510.21952v1"
  },
  {
    "id": "2510.21945v1",
    "title": "Generalization Bounds for Rank-sparse Neural Networks",
    "abstract": "It has been recently observed in much of the literature that neural networks\nexhibit a bottleneck rank property: for larger depths, the activation and\nweights of neural networks trained with gradient-based methods tend to be of\napproximately low rank. In fact, the rank of the activations of each layer\nconverges to a fixed value referred to as the ``bottleneck rank'', which is the\nminimum rank required to represent the training data. This perspective is in\nline with the observation that regularizing linear networks (without\nactivations) with weight decay is equivalent to minimizing the Schatten $p$\nquasi norm of the neural network. In this paper we investigate the implications\nof this phenomenon for generalization. More specifically, we prove\ngeneralization bounds for neural networks which exploit the approximate low\nrank structure of the weight matrices if present. The final results rely on the\nSchatten $p$ quasi norms of the weight matrices: for small $p$, the bounds\nexhibit a sample complexity $ \\widetilde{O}(WrL^2)$ where $W$ and $L$ are the\nwidth and depth of the neural network respectively and where $r$ is the rank of\nthe weight matrices. As $p$ increases, the bound behaves more like a norm-based\nbound instead.",
    "categories": [
      "cs.LG"
    ],
    "published": "2025-10-24T18:19:32Z",
    "authors": [
      "Antoine Ledent",
      "Rodrigo Alves",
      "Yunwen Lei"
    ],
    "pdf_url": "http://arxiv.org/pdf/2510.21945v1"
  },
  {
    "id": "2510.21935v1",
    "title": "AutoSciDACT: Automated Scientific Discovery through Contrastive\n  Embedding and Hypothesis Testing",
    "abstract": "Novelty detection in large scientific datasets faces two key challenges: the\nnoisy and high-dimensional nature of experimental data, and the necessity of\nmaking statistically robust statements about any observed outliers. While there\nis a wealth of literature on anomaly detection via dimensionality reduction,\nmost methods do not produce outputs compatible with quantifiable claims of\nscientific discovery. In this work we directly address these challenges,\npresenting the first step towards a unified pipeline for novelty detection\nadapted for the rigorous statistical demands of science. We introduce\nAutoSciDACT (Automated Scientific Discovery with Anomalous Contrastive\nTesting), a general-purpose pipeline for detecting novelty in scientific data.\nAutoSciDACT begins by creating expressive low-dimensional data representations\nusing a contrastive pre-training, leveraging the abundance of high-quality\nsimulated data in many scientific domains alongside expertise that can guide\nprincipled data augmentation strategies. These compact embeddings then enable\nan extremely sensitive machine learning-based two-sample test using the New\nPhysics Learning Machine (NPLM) framework, which identifies and statistically\nquantifies deviations in observed data relative to a reference distribution\n(null hypothesis). We perform experiments across a range of astronomical,\nphysical, biological, image, and synthetic datasets, demonstrating strong\nsensitivity to small injections of anomalous data across all domains.",
    "categories": [
      "cs.LG",
      "cs.AI",
      "stat.ML"
    ],
    "published": "2025-10-24T18:07:50Z",
    "authors": [
      "Samuel Bright-Thonney",
      "Christina Reissel",
      "Gaia Grosso",
      "Nathaniel Woodward",
      "Katya Govorkova",
      "Andrzej Novak",
      "Sang Eon Park",
      "Eric Moreno",
      "Philip Harris"
    ],
    "pdf_url": "http://arxiv.org/pdf/2510.21935v1"
  },
  {
    "id": "2510.21934v1",
    "title": "Joint Score-Threshold Optimization for Interpretable Risk Assessment\n  Under Partial Supervision",
    "abstract": "Risk assessment tools in healthcare commonly employ point-based scoring\nsystems that map patients to ordinal risk categories via thresholds. While\nelectronic health record (EHR) data presents opportunities for data-driven\noptimization of these tools, two fundamental challenges impede standard\nsupervised learning: (1) partial supervision arising from intervention-censored\noutcomes, where only extreme categories can be reliably labeled, and (2)\nasymmetric misclassification costs that increase with ordinal distance. We\npropose a mixed-integer programming (MIP) framework that jointly optimizes\nscoring weights and category thresholds under these constraints. Our approach\nhandles partial supervision through per-instance feasible label sets,\nincorporates asymmetric distance-aware objectives, and prevents middle-category\ncollapse via minimum threshold gaps. We further develop a CSO relaxation using\nsoftplus losses that preserves the ordinal structure while enabling efficient\noptimization. The framework supports governance constraints including sign\nrestrictions, sparsity, and minimal modifications to incumbent tools, ensuring\npractical deployability in clinical workflows.",
    "categories": [
      "cs.LG",
      "stat.ML"
    ],
    "published": "2025-10-24T18:07:24Z",
    "authors": [
      "Fardin Gankhanloo",
      "Emmett Springer",
      "Erik H. Hoyer",
      "Daniel L. Young",
      "Kimia Ghobadi"
    ],
    "pdf_url": "http://arxiv.org/pdf/2510.21934v1"
  },
  {
    "id": "2510.23641v1",
    "title": "Spatially Aware Linear Transformer (SAL-T) for Particle Jet Tagging",
    "abstract": "Transformers are very effective in capturing both global and local\ncorrelations within high-energy particle collisions, but they present\ndeployment challenges in high-data-throughput environments, such as the CERN\nLHC. The quadratic complexity of transformer models demands substantial\nresources and increases latency during inference. In order to address these\nissues, we introduce the Spatially Aware Linear Transformer (SAL-T), a\nphysics-inspired enhancement of the linformer architecture that maintains\nlinear attention. Our method incorporates spatially aware partitioning of\nparticles based on kinematic features, thereby computing attention between\nregions of physical significance. Additionally, we employ convolutional layers\nto capture local correlations, informed by insights from jet physics. In\naddition to outperforming the standard linformer in jet classification tasks,\nSAL-T also achieves classification results comparable to full-attention\ntransformers, while using considerably fewer resources with lower latency\nduring inference. Experiments on a generic point cloud classification dataset\n(ModelNet10) further confirm this trend. Our code is available at\nhttps://github.com/aaronw5/SAL-T4HEP.",
    "categories": [
      "cs.LG",
      "cs.AI",
      "hep-ex",
      "physics.ins-det"
    ],
    "published": "2025-10-24T18:00:01Z",
    "authors": [
      "Aaron Wang",
      "Zihan Zhao",
      "Subash Katel",
      "Vivekanand Gyanchand Sahu",
      "Elham E Khoda",
      "Abhijith Gandrakota",
      "Jennifer Ngadiuba",
      "Richard Cavanaugh",
      "Javier Duarte"
    ],
    "pdf_url": "http://arxiv.org/pdf/2510.23641v1"
  },
  {
    "id": "2510.21706v1",
    "title": "Equivariance by Contrast: Identifiable Equivariant Embeddings from\n  Unlabeled Finite Group Actions",
    "abstract": "We propose Equivariance by Contrast (EbC) to learn equivariant embeddings\nfrom observation pairs $(\\mathbf{y}, g \\cdot \\mathbf{y})$, where $g$ is drawn\nfrom a finite group acting on the data. Our method jointly learns a latent\nspace and a group representation in which group actions correspond to\ninvertible linear maps -- without relying on group-specific inductive biases.\nWe validate our approach on the infinite dSprites dataset with structured\ntransformations defined by the finite group $G:= (R_m \\times \\mathbb{Z}_n\n\\times \\mathbb{Z}_n)$, combining discrete rotations and periodic translations.\nThe resulting embeddings exhibit high-fidelity equivariance, with group\noperations faithfully reproduced in latent space. On synthetic data, we further\nvalidate the approach on the non-abelian orthogonal group $O(n)$ and the\ngeneral linear group $GL(n)$. We also provide a theoretical proof for\nidentifiability. While broad evaluation across diverse group types on\nreal-world data remains future work, our results constitute the first\nsuccessful demonstration of general-purpose encoder-only equivariant learning\nfrom group action observations alone, including non-trivial non-abelian groups\nand a product group motivated by modeling affine equivariances in computer\nvision.",
    "categories": [
      "cs.LG",
      "stat.ML"
    ],
    "published": "2025-10-24T17:59:46Z",
    "authors": [
      "Tobias Schmidt",
      "Steffen Schneider",
      "Matthias Bethge"
    ],
    "pdf_url": "http://arxiv.org/pdf/2510.21706v1"
  },
  {
    "id": "2510.21697v1",
    "title": "Visual Diffusion Models are Geometric Solvers",
    "abstract": "In this paper we show that visual diffusion models can serve as effective\ngeometric solvers: they can directly reason about geometric problems by working\nin pixel space. We first demonstrate this on the Inscribed Square Problem, a\nlong-standing problem in geometry that asks whether every Jordan curve contains\nfour points forming a square. We then extend the approach to two other\nwell-known hard geometric problems: the Steiner Tree Problem and the Simple\nPolygon Problem.\n  Our method treats each problem instance as an image and trains a standard\nvisual diffusion model that transforms Gaussian noise into an image\nrepresenting a valid approximate solution that closely matches the exact one.\nThe model learns to transform noisy geometric structures into correct\nconfigurations, effectively recasting geometric reasoning as image generation.\n  Unlike prior work that necessitates specialized architectures and\ndomain-specific adaptations when applying diffusion to parametric geometric\nrepresentations, we employ a standard visual diffusion model that operates on\nthe visual representation of the problem. This simplicity highlights a\nsurprising bridge between generative modeling and geometric problem solving.\nBeyond the specific problems studied here, our results point toward a broader\nparadigm: operating in image space provides a general and practical framework\nfor approximating notoriously hard problems, and opens the door to tackling a\nfar wider class of challenging geometric tasks.",
    "categories": [
      "cs.CV",
      "cs.LG"
    ],
    "published": "2025-10-24T17:57:31Z",
    "authors": [
      "Nir Goren",
      "Shai Yehezkel",
      "Omer Dahary",
      "Andrey Voynov",
      "Or Patashnik",
      "Daniel Cohen-Or"
    ],
    "pdf_url": "http://arxiv.org/pdf/2510.21697v1"
  },
  {
    "id": "2510.21693v1",
    "title": "Mechanistic Interpretability for Neural TSP Solvers",
    "abstract": "Neural networks have advanced combinatorial optimization, with\nTransformer-based solvers achieving near-optimal solutions on the Traveling\nSalesman Problem (TSP) in milliseconds. However, these models operate as black\nboxes, providing no insight into the geometric patterns they learn or the\nheuristics they employ during tour construction. We address this opacity by\napplying sparse autoencoders (SAEs), a mechanistic interpretability technique,\nto a Transformer-based TSP solver, representing the first application of\nactivation-based interpretability methods to operations research models. We\ntrain a pointer network with reinforcement learning on 100-node instances, then\nfit an SAE to the encoder's residual stream to discover an overcomplete\ndictionary of interpretable features. Our analysis reveals that the solver\nnaturally develops features mirroring fundamental TSP concepts: boundary\ndetectors that activate on convex-hull nodes, cluster-sensitive features\nresponding to locally dense regions, and separator features encoding geometric\npartitions. These findings provide the first model-internal account of what\nneural TSP solvers compute before node selection, demonstrate that geometric\nstructure emerges without explicit supervision, and suggest pathways toward\ntransparent hybrid systems that combine neural efficiency with algorithmic\ninterpretability. Interactive feature explorer:\nhttps://reubennarad.github.io/TSP_interp",
    "categories": [
      "cs.LG"
    ],
    "published": "2025-10-24T17:54:19Z",
    "authors": [
      "Reuben Narad",
      "Leonard Boussioux",
      "Michael Wagner"
    ],
    "pdf_url": "http://arxiv.org/pdf/2510.21693v1"
  },
  {
    "id": "2510.21691v2",
    "title": "On Uncertainty Calibration for Equivariant Functions",
    "abstract": "Data-sparse settings such as robotic manipulation, molecular physics, and\ngalaxy morphology classification are some of the hardest domains for deep\nlearning. For these problems, equivariant networks can help improve modeling\nacross undersampled parts of the input space, and uncertainty estimation can\nguard against overconfidence. However, until now, the relationships between\nequivariance and model confidence, and more generally equivariance and model\ncalibration, has yet to be studied. Since traditional classification and\nregression error terms show up in the definitions of calibration error, it is\nnatural to suspect that previous work can be used to help understand the\nrelationship between equivariance and calibration error. In this work, we\npresent a theory relating equivariance to uncertainty estimation. By proving\nlower and upper bounds on uncertainty calibration errors (ECE and ENCE) under\nvarious equivariance conditions, we elucidate the generalization limits of\nequivariant models and illustrate how symmetry mismatch can result in\nmiscalibration in both classification and regression. We complement our\ntheoretical framework with numerical experiments that clarify the relationship\nbetween equivariance and uncertainty using a variety of real and simulated\ndatasets, and we comment on trends with symmetry mismatch, group size, and\naleatoric and epistemic uncertainties.",
    "categories": [
      "cs.LG",
      "math.ST",
      "stat.TH"
    ],
    "published": "2025-10-24T17:50:41Z",
    "authors": [
      "Edward Berman",
      "Jacob Ginesin",
      "Marco Pacini",
      "Robin Walters"
    ],
    "pdf_url": "http://arxiv.org/pdf/2510.21691v2"
  },
  {
    "id": "2510.21686v1",
    "title": "Multimodal Datasets with Controllable Mutual Information",
    "abstract": "We introduce a framework for generating highly multimodal datasets with\nexplicitly calculable mutual information between modalities. This enables the\nconstruction of benchmark datasets that provide a novel testbed for systematic\nstudies of mutual information estimators and multimodal self-supervised\nlearning techniques. Our framework constructs realistic datasets with known\nmutual information using a flow-based generative model and a structured causal\nframework for generating correlated latent variables.",
    "categories": [
      "stat.ML",
      "cs.LG"
    ],
    "published": "2025-10-24T17:44:40Z",
    "authors": [
      "Raheem Karim Hashmani",
      "Garrett W. Merz",
      "Helen Qu",
      "Mariel Pettee",
      "Kyle Cranmer"
    ],
    "pdf_url": "http://arxiv.org/pdf/2510.21686v1"
  },
  {
    "id": "2510.21910v1",
    "title": "Adversarial D\u00e9j\u00e0 Vu: Jailbreak Dictionary Learning for Stronger\n  Generalization to Unseen Attacks",
    "abstract": "Large language models remain vulnerable to jailbreak attacks that bypass\nsafety guardrails to elicit harmful outputs. Defending against novel jailbreaks\nrepresents a critical challenge in AI safety. Adversarial training -- designed\nto make models robust against worst-case perturbations -- has been the dominant\nparadigm for adversarial robustness. However, due to optimization challenges\nand difficulties in defining realistic threat models, adversarial training\nmethods often fail on newly developed jailbreaks in practice. This paper\nproposes a new paradigm for improving robustness against unseen jailbreaks,\ncentered on the Adversarial D\\'ej\\`a Vu hypothesis: novel jailbreaks are not\nfundamentally new, but largely recombinations of adversarial skills from\nprevious attacks. We study this hypothesis through a large-scale analysis of 32\nattack papers published over two years. Using an automated pipeline, we extract\nand compress adversarial skills into a sparse dictionary of primitives, with\nLLMs generating human-readable descriptions. Our analysis reveals that unseen\nattacks can be effectively explained as sparse compositions of earlier skills,\nwith explanatory power increasing monotonically as skill coverage grows. Guided\nby this insight, we introduce Adversarial Skill Compositional Training (ASCoT),\nwhich trains on diverse compositions of skill primitives rather than isolated\nattack instances. ASCoT substantially improves robustness to unseen attacks,\nincluding multi-turn jailbreaks, while maintaining low over-refusal rates. We\nalso demonstrate that expanding adversarial skill coverage, not just data\nscale, is key to defending against novel attacks.\n\\textcolor{red}{\\textbf{Warning: This paper contains content that may be\nharmful or offensive in nature.",
    "categories": [
      "cs.LG"
    ],
    "published": "2025-10-24T17:37:25Z",
    "authors": [
      "Mahavir Dabas",
      "Tran Huynh",
      "Nikhil Reddy Billa",
      "Jiachen T. Wang",
      "Peng Gao",
      "Charith Peris",
      "Yao Ma",
      "Rahul Gupta",
      "Ming Jin",
      "Prateek Mittal",
      "Ruoxi Jia"
    ],
    "pdf_url": "http://arxiv.org/pdf/2510.21910v1"
  },
  {
    "id": "2510.23640v1",
    "title": "Structure-Aware Fusion with Progressive Injection for Multimodal\n  Molecular Representation Learning",
    "abstract": "Multimodal molecular models often suffer from 3D conformer unreliability and\nmodality collapse, limiting their robustness and generalization. We propose\nMuMo, a structured multimodal fusion framework that addresses these challenges\nin molecular representation through two key strategies. To reduce the\ninstability of conformer-dependent fusion, we design a Structured Fusion\nPipeline (SFP) that combines 2D topology and 3D geometry into a unified and\nstable structural prior. To mitigate modality collapse caused by naive fusion,\nwe introduce a Progressive Injection (PI) mechanism that asymmetrically\nintegrates this prior into the sequence stream, preserving modality-specific\nmodeling while enabling cross-modal enrichment. Built on a state space\nbackbone, MuMo supports long-range dependency modeling and robust information\npropagation. Across 29 benchmark tasks from Therapeutics Data Commons (TDC) and\nMoleculeNet, MuMo achieves an average improvement of 2.7% over the\nbest-performing baseline on each task, ranking first on 22 of them, including a\n27% improvement on the LD50 task. These results validate its robustness to 3D\nconformer noise and the effectiveness of multimodal fusion in molecular\nrepresentation. The code is available at: github.com/selmiss/MuMo.",
    "categories": [
      "cs.LG",
      "cs.AI"
    ],
    "published": "2025-10-24T17:27:10Z",
    "authors": [
      "Zihao Jing",
      "Yan Sun",
      "Yan Yi Li",
      "Sugitha Janarthanan",
      "Alana Deng",
      "Pingzhao Hu"
    ],
    "pdf_url": "http://arxiv.org/pdf/2510.23640v1"
  },
  {
    "id": "2510.21908v1",
    "title": "Enabling Robust In-Context Memory and Rapid Task Adaptation in\n  Transformers with Hebbian and Gradient-Based Plasticity",
    "abstract": "Large language models display in-context learning as an emergent effect of\nscale, but they rely on static weights during inference. In contrast,\nbiological systems continually adapt via synaptic plasticity. We investigate\nwhether explicit, biologically inspired plasticity can endow Transformers with\nfaster in-sequence adaptation. To this end, we augment decoder-only\nTransformers with fast-weight modules updated either by (i) a neuromodulated\nHebbian rule or (ii) the gradient-based plasticity mechanism of Duan et al.\n(2023). Across copying, regression, and few-shot classification tasks\n(CIFAR-FS, Omniglot), Hebbian plasticity consistently achieves lower loss and\nstronger few-shot generalization, while gradient-based updates perform best on\nlong-horizon credit assignment. When associations are short and linearly\nseparable, static weights suffice, defining a clear boundary condition for when\nplasticity helps. Analysis of learned modulatory signals reveals that\ngradient-based rules maintain large, persistent updates, whereas Hebbian\nplasticity is sharply gated around salient events. Together, these results show\nthat explicit plasticity complements attention by enabling rapid, task-specific\nadaptation, and clarify when different plasticity mechanisms are most\neffective.",
    "categories": [
      "cs.NE",
      "cs.AI",
      "cs.LG"
    ],
    "published": "2025-10-24T17:26:03Z",
    "authors": [
      "Siddharth Chaudhary"
    ],
    "pdf_url": "http://arxiv.org/pdf/2510.21908v1"
  },
  {
    "id": "2510.21669v1",
    "title": "Optimal Graph Clustering without Edge Density Signals",
    "abstract": "This paper establishes the theoretical limits of graph clustering under the\nPopularity-Adjusted Block Model (PABM), addressing limitations of existing\nmodels. In contrast to the Stochastic Block Model (SBM), which assumes uniform\nvertex degrees, and to the Degree-Corrected Block Model (DCBM), which applies\nuniform degree corrections across clusters, PABM introduces separate popularity\nparameters for intra- and inter-cluster connections. Our main contribution is\nthe characterization of the optimal error rate for clustering under PABM, which\nprovides novel insights on clustering hardness: we demonstrate that unlike SBM\nand DCBM, cluster recovery remains possible in PABM even when traditional\nedge-density signals vanish, provided intra- and inter-cluster popularity\ncoefficients differ. This highlights a dimension of degree heterogeneity\ncaptured by PABM but overlooked by DCBM: local differences in connectivity\npatterns can enhance cluster separability independently of global edge\ndensities. Finally, because PABM exhibits a richer structure, its expected\nadjacency matrix has rank between $k$ and $k^2$, where $k$ is the number of\nclusters. As a result, spectral embeddings based on the top $k$ eigenvectors\nmay fail to capture important structural information. Our numerical experiments\non both synthetic and real datasets confirm that spectral clustering algorithms\nincorporating $k^2$ eigenvectors outperform traditional spectral approaches.",
    "categories": [
      "cs.LG",
      "stat.ML"
    ],
    "published": "2025-10-24T17:24:26Z",
    "authors": [
      "Maximilien Dreveton",
      "Elaine Siyu Liu",
      "Matthias Grossglauser",
      "Patrick Thiran"
    ],
    "pdf_url": "http://arxiv.org/pdf/2510.21669v1"
  },
  {
    "id": "2510.21638v1",
    "title": "DEEDEE: Fast and Scalable Out-of-Distribution Dynamics Detection",
    "abstract": "Deploying reinforcement learning (RL) in safety-critical settings is\nconstrained by brittleness under distribution shift. We study\nout-of-distribution (OOD) detection for RL time series and introduce DEEDEE, a\ntwo-statistic detector that revisits representation-heavy pipelines with a\nminimal alternative. DEEDEE uses only an episodewise mean and an RBF kernel\nsimilarity to a training summary, capturing complementary global and local\ndeviations. Despite its simplicity, DEEDEE matches or surpasses contemporary\ndetectors across standard RL OOD suites, delivering a 600-fold reduction in\ncompute (FLOPs / wall-time) and an average 5% absolute accuracy gain over\nstrong baselines. Conceptually, our results indicate that diverse anomaly types\noften imprint on RL trajectories through a small set of low-order statistics,\nsuggesting a compact foundation for OOD detection in complex environments.",
    "categories": [
      "cs.LG",
      "cs.AI"
    ],
    "published": "2025-10-24T16:51:17Z",
    "authors": [
      "Tala Aljaafari",
      "Varun Kanade",
      "Philip Torr",
      "Christian Schroeder de Witt"
    ],
    "pdf_url": "http://arxiv.org/pdf/2510.21638v1"
  },
  {
    "id": "2510.21631v1",
    "title": "Few-Shot Knowledge Distillation of LLMs With Counterfactual Explanations",
    "abstract": "Knowledge distillation is a promising approach to transfer capabilities from\ncomplex teacher models to smaller, resource-efficient student models that can\nbe deployed easily, particularly in task-aware scenarios. However, existing\nmethods of task-aware distillation typically require substantial quantities of\ndata which may be unavailable or expensive to obtain in many practical\nscenarios. In this paper, we address this challenge by introducing a novel\nstrategy called Counterfactual-explanation-infused Distillation CoD for\nfew-shot task-aware knowledge distillation by systematically infusing\ncounterfactual explanations. Counterfactual explanations (CFEs) refer to inputs\nthat can flip the output prediction of the teacher model with minimum\nperturbation. Our strategy CoD leverages these CFEs to precisely map the\nteacher's decision boundary with significantly fewer samples. We provide\ntheoretical guarantees for motivating the role of CFEs in distillation, from\nboth statistical and geometric perspectives. We mathematically show that CFEs\ncan improve parameter estimation by providing more informative examples near\nthe teacher's decision boundary. We also derive geometric insights on how CFEs\neffectively act as knowledge probes, helping the students mimic the teacher's\ndecision boundaries more effectively than standard data. We perform experiments\nacross various datasets and LLMs to show that CoD outperforms standard\ndistillation approaches in few-shot regimes (as low as 8-512 samples). Notably,\nCoD only uses half of the original samples used by the baselines, paired with\ntheir corresponding CFEs and still improves performance.",
    "categories": [
      "cs.LG",
      "cs.AI",
      "cs.CL",
      "cs.CY",
      "stat.ML"
    ],
    "published": "2025-10-24T16:36:34Z",
    "authors": [
      "Faisal Hamman",
      "Pasan Dissanayake",
      "Yanjun Fu",
      "Sanghamitra Dutta"
    ],
    "pdf_url": "http://arxiv.org/pdf/2510.21631v1"
  },
  {
    "id": "2510.21618v1",
    "title": "DeepAgent: A General Reasoning Agent with Scalable Toolsets",
    "abstract": "Large reasoning models have demonstrated strong problem-solving abilities,\nyet real-world tasks often require external tools and long-horizon\ninteractions. Existing agent frameworks typically follow predefined workflows,\nwhich limit autonomous and global task completion. In this paper, we introduce\nDeepAgent, an end-to-end deep reasoning agent that performs autonomous\nthinking, tool discovery, and action execution within a single, coherent\nreasoning process. To address the challenges of long-horizon interactions,\nparticularly the context length explosion from multiple tool calls and the\naccumulation of interaction history, we introduce an autonomous memory folding\nmechanism that compresses past interactions into structured episodic, working,\nand tool memories, reducing error accumulation while preserving critical\ninformation. To teach general-purpose tool use efficiently and stably, we\ndevelop an end-to-end reinforcement learning strategy, namely ToolPO, that\nleverages LLM-simulated APIs and applies tool-call advantage attribution to\nassign fine-grained credit to the tool invocation tokens. Extensive experiments\non eight benchmarks, including general tool-use tasks (ToolBench, API-Bank,\nTMDB, Spotify, ToolHop) and downstream applications (ALFWorld, WebShop, GAIA,\nHLE), demonstrate that DeepAgent consistently outperforms baselines across both\nlabeled-tool and open-set tool retrieval scenarios. This work takes a step\ntoward more general and capable agents for real-world applications. The code\nand demo are available at https://github.com/RUC-NLPIR/DeepAgent.",
    "categories": [
      "cs.AI",
      "cs.CL",
      "cs.IR",
      "cs.LG"
    ],
    "published": "2025-10-24T16:24:01Z",
    "authors": [
      "Xiaoxi Li",
      "Wenxiang Jiao",
      "Jiarui Jin",
      "Guanting Dong",
      "Jiajie Jin",
      "Yinuo Wang",
      "Hao Wang",
      "Yutao Zhu",
      "Ji-Rong Wen",
      "Yuan Lu",
      "Zhicheng Dou"
    ],
    "pdf_url": "http://arxiv.org/pdf/2510.21618v1"
  },
  {
    "id": "2510.21610v1",
    "title": "Generative Correlation Manifolds: Generating Synthetic Data with\n  Preserved Higher-Order Correlations",
    "abstract": "The increasing need for data privacy and the demand for robust machine\nlearning models have fueled the development of synthetic data generation\ntechniques. However, current methods often succeed in replicating simple\nsummary statistics but fail to preserve both the pairwise and higher-order\ncorrelation structure of the data that define the complex, multi-variable\ninteractions inherent in real-world systems. This limitation can lead to\nsynthetic data that is superficially realistic but fails when used for\nsophisticated modeling tasks. In this white paper, we introduce Generative\nCorrelation Manifolds (GCM), a computationally efficient method for generating\nsynthetic data. The technique uses Cholesky decomposition of a target\ncorrelation matrix to produce datasets that, by mathematical proof, preserve\nthe entire correlation structure -- from simple pairwise relationships to\nhigher-order interactions -- of the source dataset. We argue that this method\nprovides a new approach to synthetic data generation with potential\napplications in privacy-preserving data sharing, robust model training, and\nsimulation.",
    "categories": [
      "cs.LG",
      "cs.AI"
    ],
    "published": "2025-10-24T16:15:53Z",
    "authors": [
      "Jens E. d'Hondt",
      "Wieger R. Punter",
      "Odysseas Papapetrou"
    ],
    "pdf_url": "http://arxiv.org/pdf/2510.21610v1"
  },
  {
    "id": "2510.21609v1",
    "title": "Enhancing Tactile-based Reinforcement Learning for Robotic Control",
    "abstract": "Achieving safe, reliable real-world robotic manipulation requires agents to\nevolve beyond vision and incorporate tactile sensing to overcome sensory\ndeficits and reliance on idealised state information. Despite its potential,\nthe efficacy of tactile sensing in reinforcement learning (RL) remains\ninconsistent. We address this by developing self-supervised learning (SSL)\nmethodologies to more effectively harness tactile observations, focusing on a\nscalable setup of proprioception and sparse binary contacts. We empirically\ndemonstrate that sparse binary tactile signals are critical for dexterity,\nparticularly for interactions that proprioceptive control errors do not\nregister, such as decoupled robot-object motions. Our agents achieve superhuman\ndexterity in complex contact tasks (ball bouncing and Baoding ball rotation).\nFurthermore, we find that decoupling the SSL memory from the on-policy memory\ncan improve performance. We release the Robot Tactile Olympiad (RoTO) benchmark\nto standardise and promote future research in tactile-based manipulation.\nProject page: https://elle-miller.github.io/tactile_rl",
    "categories": [
      "cs.RO",
      "cs.LG"
    ],
    "published": "2025-10-24T16:15:05Z",
    "authors": [
      "Elle Miller",
      "Trevor McInroe",
      "David Abel",
      "Oisin Mac Aodha",
      "Sethu Vijayakumar"
    ],
    "pdf_url": "http://arxiv.org/pdf/2510.21609v1"
  },
  {
    "id": "2510.21608v1",
    "title": "Generalised Flow Maps for Few-Step Generative Modelling on Riemannian\n  Manifolds",
    "abstract": "Geometric data and purpose-built generative models on them have become\nubiquitous in high-impact deep learning application domains, ranging from\nprotein backbone generation and computational chemistry to geospatial data.\nCurrent geometric generative models remain computationally expensive at\ninference -- requiring many steps of complex numerical simulation -- as they\nare derived from dynamical measure transport frameworks such as diffusion and\nflow-matching on Riemannian manifolds. In this paper, we propose Generalised\nFlow Maps (GFM), a new class of few-step generative models that generalises the\nFlow Map framework in Euclidean spaces to arbitrary Riemannian manifolds. We\ninstantiate GFMs with three self-distillation-based training methods:\nGeneralised Lagrangian Flow Maps, Generalised Eulerian Flow Maps, and\nGeneralised Progressive Flow Maps. We theoretically show that GFMs, under\nspecific design decisions, unify and elevate existing Euclidean few-step\ngenerative models, such as consistency models, shortcut models, and meanflows,\nto the Riemannian setting. We benchmark GFMs against other geometric generative\nmodels on a suite of geometric datasets, including geospatial data, RNA torsion\nangles, and hyperbolic manifolds, and achieve state-of-the-art sample quality\nfor single- and few-step evaluations, and superior or competitive\nlog-likelihoods using the implicit probability flow.",
    "categories": [
      "cs.LG"
    ],
    "published": "2025-10-24T16:14:31Z",
    "authors": [
      "Oscar Davis",
      "Michael S. Albergo",
      "Nicholas M. Boffi",
      "Michael M. Bronstein",
      "Avishek Joey Bose"
    ],
    "pdf_url": "http://arxiv.org/pdf/2510.21608v1"
  },
  {
    "id": "2510.21599v1",
    "title": "SHAP Meets Tensor Networks: Provably Tractable Explanations with\n  Parallelism",
    "abstract": "Although Shapley additive explanations (SHAP) can be computed in polynomial\ntime for simple models like decision trees, they unfortunately become NP-hard\nto compute for more expressive black-box models like neural networks - where\ngenerating explanations is often most critical. In this work, we analyze the\nproblem of computing SHAP explanations for *Tensor Networks (TNs)*, a broader\nand more expressive class of models than those for which current exact SHAP\nalgorithms are known to hold, and which is widely used for neural network\nabstraction and compression. First, we introduce a general framework for\ncomputing provably exact SHAP explanations for general TNs with arbitrary\nstructures. Interestingly, we show that, when TNs are restricted to a *Tensor\nTrain (TT)* structure, SHAP computation can be performed in *poly-logarithmic*\ntime using *parallel* computation. Thanks to the expressiveness power of TTs,\nthis complexity result can be generalized to many other popular ML models such\nas decision trees, tree ensembles, linear models, and linear RNNs, therefore\ntightening previously reported complexity results for these families of models.\nFinally, by leveraging reductions of binarized neural networks to Tensor\nNetwork representations, we demonstrate that SHAP computation can become\n*efficiently tractable* when the network's *width* is fixed, while it remains\ncomputationally hard even with constant *depth*. This highlights an important\ninsight: for this class of models, width - rather than depth - emerges as the\nprimary computational bottleneck in SHAP computation.",
    "categories": [
      "cs.LG",
      "cs.CC",
      "cs.FL",
      "quant-ph"
    ],
    "published": "2025-10-24T16:02:51Z",
    "authors": [
      "Reda Marzouk",
      "Shahaf Bassan",
      "Guy Katz"
    ],
    "pdf_url": "http://arxiv.org/pdf/2510.21599v1"
  },
  {
    "id": "2510.21598v1",
    "title": "Fisher meets Feynman: score-based variational inference with a product\n  of experts",
    "abstract": "We introduce a highly expressive yet distinctly tractable family for\nblack-box variational inference (BBVI). Each member of this family is a\nweighted product of experts (PoE), and each weighted expert in the product is\nproportional to a multivariate $t$-distribution. These products of experts can\nmodel distributions with skew, heavy tails, and multiple modes, but to use them\nfor BBVI, we must be able to sample from their densities. We show how to do\nthis by reformulating these products of experts as latent variable models with\nauxiliary Dirichlet random variables. These Dirichlet variables emerge from a\nFeynman identity, originally developed for loop integrals in quantum field\ntheory, that expresses the product of multiple fractions (or in our case,\n$t$-distributions) as an integral over the simplex. We leverage this simplicial\nlatent space to draw weighted samples from these products of experts -- samples\nwhich BBVI then uses to find the PoE that best approximates a target density.\nGiven a collection of experts, we derive an iterative procedure to optimize the\nexponents that determine their geometric weighting in the PoE. At each\niteration, this procedure minimizes a regularized Fisher divergence to match\nthe scores of the variational and target densities at a batch of samples drawn\nfrom the current approximation. This minimization reduces to a convex quadratic\nprogram, and we prove under general conditions that these updates converge\nexponentially fast to a near-optimal weighting of experts. We conclude by\nevaluating this approach on a variety of synthetic and real-world target\ndistributions.",
    "categories": [
      "stat.ML",
      "cs.LG"
    ],
    "published": "2025-10-24T16:02:18Z",
    "authors": [
      "Diana Cai",
      "Robert M. Gower",
      "David M. Blei",
      "Lawrence K. Saul"
    ],
    "pdf_url": "http://arxiv.org/pdf/2510.21598v1"
  },
  {
    "id": "2510.21592v1",
    "title": "Accelerating Data Generation for Nonlinear temporal PDEs via homologous\n  perturbation in solution space",
    "abstract": "Data-driven deep learning methods like neural operators have advanced in\nsolving nonlinear temporal partial differential equations (PDEs). However,\nthese methods require large quantities of solution pairs\\u2014the solution\nfunctions and right-hand sides (RHS) of the equations. These pairs are\ntypically generated via traditional numerical methods, which need thousands of\ntime steps iterations far more than the dozens required for training, creating\nheavy computational and temporal overheads. To address these challenges, we\npropose a novel data generation algorithm, called HOmologous Perturbation in\nSolution Space (HOPSS), which directly generates training datasets with fewer\ntime steps rather than following the traditional approach of generating large\ntime steps datasets. This algorithm simultaneously accelerates dataset\ngeneration and preserves the approximate precision required for model training.\nSpecifically, we first obtain a set of base solution functions from a reliable\nsolver, usually with thousands of time steps, and then align them in time steps\nwith training datasets by downsampling. Subsequently, we propose a \"homologous\nperturbation\" approach: by combining two solution functions (one as the primary\nfunction, the other as a homologous perturbation term scaled by a small scalar)\nwith random noise, we efficiently generate comparable-precision PDE data\npoints. Finally, using these data points, we compute the variation in the\noriginal equation's RHS to form new solution pairs. Theoretical and\nexperimental results show HOPSS lowers time complexity. For example, on the\nNavier-Stokes equation, it generates 10,000 samples in approximately 10% of\ntraditional methods' time, with comparable model training performance.",
    "categories": [
      "cs.LG"
    ],
    "published": "2025-10-24T15:59:58Z",
    "authors": [
      "Lei Liu",
      "Zhenxin Huang",
      "Hong Wang",
      "huanshuo dong",
      "Haiyang Xin",
      "Hongwei Zhao",
      "Bin Li"
    ],
    "pdf_url": "http://arxiv.org/pdf/2510.21592v1"
  },
  {
    "id": "2510.23639v2",
    "title": "Integrating Genomics into Multimodal EHR Foundation Models",
    "abstract": "This paper introduces an innovative Electronic Health Record (EHR) foundation\nmodel that integrates Polygenic Risk Scores (PRS) as a foundational data\nmodality, moving beyond traditional EHR-only approaches to build more holistic\nhealth profiles. Leveraging the extensive and diverse data from the All of Us\n(AoU) Research Program, this multimodal framework aims to learn complex\nrelationships between clinical data and genetic predispositions. The\nmethodology extends advancements in generative AI to the EHR foundation model\nspace, enhancing predictive capabilities and interpretability. Evaluation on\nAoU data demonstrates the model's predictive value for the onset of various\nconditions, particularly Type 2 Diabetes (T2D), and illustrates the interplay\nbetween PRS and EHR data. The work also explores transfer learning for custom\nclassification tasks, showcasing the architecture's versatility and efficiency.\nThis approach is pivotal for unlocking new insights into disease prediction,\nproactive health management, risk stratification, and personalized treatment\nstrategies, laying the groundwork for more personalized, equitable, and\nactionable real-world evidence generation in healthcare.",
    "categories": [
      "cs.LG",
      "cs.AI",
      "q-bio.QM"
    ],
    "published": "2025-10-24T15:56:40Z",
    "authors": [
      "Jonathan Amar",
      "Edward Liu",
      "Alessandra Breschi",
      "Liangliang Zhang",
      "Pouya Kheradpour",
      "Sylvia Li",
      "Lisa Soleymani Lehmann",
      "Alessandro Giulianelli",
      "Matt Edwards",
      "Yugang Jia",
      "David Nola",
      "Raghav Mani",
      "Pankaj Vats",
      "Jesse Tetreault",
      "T. J. Chen",
      "Cory Y. McLean"
    ],
    "pdf_url": "http://arxiv.org/pdf/2510.23639v2"
  },
  {
    "id": "2510.21588v1",
    "title": "Contribution of task-irrelevant stimuli to drift of neural\n  representations",
    "abstract": "Biological and artificial learners are inherently exposed to a stream of data\nand experience throughout their lifetimes and must constantly adapt to, learn\nfrom, or selectively ignore the ongoing input. Recent findings reveal that,\neven when the performance remains stable, the underlying neural representations\ncan change gradually over time, a phenomenon known as representational drift.\nStudying the different sources of data and noise that may contribute to drift\nis essential for understanding lifelong learning in neural systems. However, a\nsystematic study of drift across architectures and learning rules, and the\nconnection to task, are missing. Here, in an online learning setup, we\ncharacterize drift as a function of data distribution, and specifically show\nthat the learning noise induced by task-irrelevant stimuli, which the agent\nlearns to ignore in a given context, can create long-term drift in the\nrepresentation of task-relevant stimuli. Using theory and simulations, we\ndemonstrate this phenomenon both in Hebbian-based learning -- Oja's rule and\nSimilarity Matching -- and in stochastic gradient descent applied to\nautoencoders and a supervised two-layer network. We consistently observe that\nthe drift rate increases with the variance and the dimension of the data in the\ntask-irrelevant subspace. We further show that this yields different\nqualitative predictions for the geometry and dimension-dependency of drift than\nthose arising from Gaussian synaptic noise. Overall, our study links the\nstructure of stimuli, task, and learning rule to representational drift and\ncould pave the way for using drift as a signal for uncovering underlying\ncomputation in the brain.",
    "categories": [
      "q-bio.NC",
      "cs.LG"
    ],
    "published": "2025-10-24T15:54:25Z",
    "authors": [
      "Farhad Pashakhanloo"
    ],
    "pdf_url": "http://arxiv.org/pdf/2510.21588v1"
  },
  {
    "id": "2510.21585v1",
    "title": "REVE: A Foundation Model for EEG -- Adapting to Any Setup with\n  Large-Scale Pretraining on 25,000 Subjects",
    "abstract": "Foundation models have transformed AI by reducing reliance on task-specific\ndata through large-scale pretraining. While successful in language and vision,\ntheir adoption in EEG has lagged due to the heterogeneity of public datasets,\nwhich are collected under varying protocols, devices, and electrode\nconfigurations. Existing EEG foundation models struggle to generalize across\nthese variations, often restricting pretraining to a single setup, resulting in\nsuboptimal performance, in particular under linear probing. We present REVE\n(Representation for EEG with Versatile Embeddings), a pretrained model\nexplicitly designed to generalize across diverse EEG signals. REVE introduces a\nnovel 4D positional encoding scheme that enables it to process signals of\narbitrary length and electrode arrangement. Using a masked autoencoding\nobjective, we pretrain REVE on over 60,000 hours of EEG data from 92 datasets\nspanning 25,000 subjects, representing the largest EEG pretraining effort to\ndate. REVE achieves state-of-the-art results on 10 downstream EEG tasks,\nincluding motor imagery classification, seizure detection, sleep staging,\ncognitive load estimation, and emotion recognition. With little to no\nfine-tuning, it demonstrates strong generalization, and nuanced spatio-temporal\nmodeling. We release code, pretrained weights, and tutorials to support\nstandardized EEG research and accelerate progress in clinical neuroscience.",
    "categories": [
      "cs.LG",
      "q-bio.NC"
    ],
    "published": "2025-10-24T15:52:46Z",
    "authors": [
      "Yassine El Ouahidi",
      "Jonathan Lys",
      "Philipp Th\u00f6lke",
      "Nicolas Farrugia",
      "Bastien Pasdeloup",
      "Vincent Gripon",
      "Karim Jerbi",
      "Giulia Lioi"
    ],
    "pdf_url": "http://arxiv.org/pdf/2510.21585v1"
  },
  {
    "id": "2510.21582v2",
    "title": "An unsupervised tour through the hidden pathways of deep neural networks",
    "abstract": "The goal of this thesis is to improve our understanding of the internal\nmechanisms by which deep artificial neural networks create meaningful\nrepresentations and are able to generalize. We focus on the challenge of\ncharacterizing the semantic content of the hidden representations with\nunsupervised learning tools, partially developed by us and described in this\nthesis, which allow harnessing the low-dimensional structure of the data.\nChapter 2. introduces Gride, a method that allows estimating the intrinsic\ndimension of the data as an explicit function of the scale without performing\nany decimation of the data set. Our approach is based on rigorous\ndistributional results that enable the quantification of uncertainty of the\nestimates. Moreover, our method is simple and computationally efficient since\nit relies only on the distances among nearest data points. In Chapter 3, we\nstudy the evolution of the probability density across the hidden layers in some\nstate-of-the-art deep neural networks. We find that the initial layers generate\na unimodal probability density getting rid of any structure irrelevant to\nclassification. In subsequent layers, density peaks arise in a hierarchical\nfashion that mirrors the semantic hierarchy of the concepts. This process\nleaves a footprint in the probability density of the output layer, where the\ntopography of the peaks allows reconstructing the semantic relationships of the\ncategories. In Chapter 4, we study the problem of generalization in deep neural\nnetworks: adding parameters to a network that interpolates its training data\nwill typically improve its generalization performance, at odds with the\nclassical bias-variance trade-off. We show that wide neural networks learn\nredundant representations instead of overfitting to spurious correlation and\nthat redundant neurons appear only if the network is regularized and the\ntraining error is zero.",
    "categories": [
      "cs.LG"
    ],
    "published": "2025-10-24T15:50:31Z",
    "authors": [
      "Diego Doimo"
    ],
    "pdf_url": "http://arxiv.org/pdf/2510.21582v2"
  },
  {
    "id": "2510.21574v1",
    "title": "Leveraging Classical Algorithms for Graph Neural Networks",
    "abstract": "Neural networks excel at processing unstructured data but often fail to\ngeneralise out-of-distribution, whereas classical algorithms guarantee\ncorrectness but lack flexibility. We explore whether pretraining Graph Neural\nNetworks (GNNs) on classical algorithms can improve their performance on\nmolecular property prediction tasks from the Open Graph Benchmark: ogbg-molhiv\n(HIV inhibition) and ogbg-molclintox (clinical toxicity). GNNs trained on 24\nclassical algorithms from the CLRS Algorithmic Reasoning Benchmark are used to\ninitialise and freeze selected layers of a second GNN for molecular prediction.\nCompared to a randomly initialised baseline, the pretrained models achieve\nconsistent wins or ties, with the Segments Intersect algorithm pretraining\nyielding a 6% absolute gain on ogbg-molhiv and Dijkstra pretraining achieving a\n3% gain on ogbg-molclintox. These results demonstrate embedding classical\nalgorithmic priors into GNNs provides useful inductive biases, boosting\nperformance on complex, real-world graph data.",
    "categories": [
      "cs.LG"
    ],
    "published": "2025-10-24T15:42:02Z",
    "authors": [
      "Jason Wu",
      "Petar Veli\u010dkovi\u0107"
    ],
    "pdf_url": "http://arxiv.org/pdf/2510.21574v1"
  },
  {
    "id": "2510.21571v1",
    "title": "Scalable Vision-Language-Action Model Pretraining for Robotic\n  Manipulation with Real-Life Human Activity Videos",
    "abstract": "This paper presents a novel approach for pretraining robotic manipulation\nVision-Language-Action (VLA) models using a large corpus of unscripted\nreal-life video recordings of human hand activities. Treating human hand as\ndexterous robot end-effector, we show that \"in-the-wild\" egocentric human\nvideos without any annotations can be transformed into data formats fully\naligned with existing robotic V-L-A training data in terms of task granularity\nand labels. This is achieved by the development of a fully-automated holistic\nhuman activity analysis approach for arbitrary human hand videos. This approach\ncan generate atomic-level hand activity segments and their language\ndescriptions, each accompanied with framewise 3D hand motion and camera motion.\nWe process a large volume of egocentric videos and create a hand-VLA training\ndataset containing 1M episodes and 26M frames. This training data covers a wide\nrange of objects and concepts, dexterous manipulation tasks, and environment\nvariations in real life, vastly exceeding the coverage of existing robot data.\nWe design a dexterous hand VLA model architecture and pretrain the model on\nthis dataset. The model exhibits strong zero-shot capabilities on completely\nunseen real-world observations. Additionally, fine-tuning it on a small amount\nof real robot action data significantly improves task success rates and\ngeneralization to novel objects in real robotic experiments. We also\ndemonstrate the appealing scaling behavior of the model's task performance with\nrespect to pretraining data scale. We believe this work lays a solid foundation\nfor scalable VLA pretraining, advancing robots toward truly generalizable\nembodied intelligence.",
    "categories": [
      "cs.RO",
      "cs.AI",
      "cs.CV",
      "cs.LG"
    ],
    "published": "2025-10-24T15:39:31Z",
    "authors": [
      "Qixiu Li",
      "Yu Deng",
      "Yaobo Liang",
      "Lin Luo",
      "Lei Zhou",
      "Chengtang Yao",
      "Lingqi Zeng",
      "Zhiyuan Feng",
      "Huizhi Liang",
      "Sicheng Xu",
      "Yizhong Zhang",
      "Xi Chen",
      "Hao Chen",
      "Lily Sun",
      "Dong Chen",
      "Jiaolong Yang",
      "Baining Guo"
    ],
    "pdf_url": "http://arxiv.org/pdf/2510.21571v1"
  },
  {
    "id": "2510.23638v1",
    "title": "Bridging Function Approximation and Device Physics via Negative\n  Differential Resistance Networks",
    "abstract": "Achieving fully analog neural computation requires hardware that can natively\nimplement both linear and nonlinear operations with high efficiency. While\nanalogue matrix-vector multiplication has advanced via compute-in-memory\narchitectures, nonlinear activation functions remain a bottleneck, often\nrequiring digital or hybrid solutions. Inspired by the Kolmogorov-Arnold\nframework, we propose KANalogue, a fully analogue implementation of\nKolmogorov-Arnold Networks (KANs) using negative differential resistance\ndevices as physical realizations of learnable univariate basis functions. By\nleveraging the intrinsic negative differential resistance characteristics of\ntunnel diodes fabricated from NbSi2N4/HfSi2N4 heterostructures, we construct\ncoordinate-wise nonlinearities with distinct curvature and support profiles. We\nextract I-V data from fabricated armchair and zigzag devices, fit high-order\npolynomials to emulate diode behavior in software, and train KANs on vision\nbenchmarks using these learned basis functions. Our results demonstrate that\nKANalogue can approximate complex functions with minimal parameters while\nmaintaining classification accuracy competitive with digital baselines. This\nwork bridges device-level physics and function approximation theory, charting a\npath toward scalable, energy-efficient analogue machine learning systems.",
    "categories": [
      "cs.ET",
      "cs.AI",
      "cs.LG"
    ],
    "published": "2025-10-24T15:38:22Z",
    "authors": [
      "Songyuan Li",
      "Teng Wang",
      "Jinrong Tang",
      "Ruiqi Liu",
      "Yuyao Lu",
      "Feng Xu",
      "Bin Gao",
      "Xiangwei Zhu"
    ],
    "pdf_url": "http://arxiv.org/pdf/2510.23638v1"
  },
  {
    "id": "2510.21553v1",
    "title": "Document Understanding, Measurement, and Manipulation Using Category\n  Theory",
    "abstract": "We apply category theory to extract multimodal document structure which leads\nus to develop information theoretic measures, content summarization and\nextension, and self-supervised improvement of large pretrained models. We first\ndevelop a mathematical representation of a document as a category of\nquestion-answer pairs. Second, we develop an orthogonalization procedure to\ndivide the information contained in one or more documents into non-overlapping\npieces. The structures extracted in the first and second steps lead us to\ndevelop methods to measure and enumerate the information contained in a\ndocument. We also build on those steps to develop new summarization techniques,\nas well as to develop a solution to a new problem viz. exegesis resulting in an\nextension of the original document. Our question-answer pair methodology\nenables a novel rate distortion analysis of summarization techniques. We\nimplement our techniques using large pretrained models, and we propose a\nmultimodal extension of our overall mathematical framework. Finally, we develop\na novel self-supervised method using RLVR to improve large pretrained models\nusing consistency constraints such as composability and closure under certain\noperations that stem naturally from our category theoretic framework.",
    "categories": [
      "cs.CL",
      "cs.LG"
    ],
    "published": "2025-10-24T15:12:08Z",
    "authors": [
      "Jared Claypoole",
      "Yunye Gong",
      "Noson S. Yanofsky",
      "Ajay Divakaran"
    ],
    "pdf_url": "http://arxiv.org/pdf/2510.21553v1"
  },
  {
    "id": "2510.21551v1",
    "title": "Interpretable Multimodal Zero-Shot ECG Diagnosis via Structured Clinical\n  Knowledge Alignment",
    "abstract": "Electrocardiogram (ECG) interpretation is essential for cardiovascular\ndisease diagnosis, but current automated systems often struggle with\ntransparency and generalization to unseen conditions. To address this, we\nintroduce ZETA, a zero-shot multimodal framework designed for interpretable ECG\ndiagnosis aligned with clinical workflows. ZETA uniquely compares ECG signals\nagainst structured positive and negative clinical observations, which are\ncurated through an LLM-assisted, expert-validated process, thereby mimicking\ndifferential diagnosis. Our approach leverages a pre-trained multimodal model\nto align ECG and text embeddings without disease-specific fine-tuning.\nEmpirical evaluations demonstrate ZETA's competitive zero-shot classification\nperformance and, importantly, provide qualitative and quantitative evidence of\nenhanced interpretability, grounding predictions in specific, clinically\nrelevant positive and negative diagnostic features. ZETA underscores the\npotential of aligning ECG analysis with structured clinical knowledge for\nbuilding more transparent, generalizable, and trustworthy AI diagnostic\nsystems. We will release the curated observation dataset and code to facilitate\nfuture research.",
    "categories": [
      "cs.LG"
    ],
    "published": "2025-10-24T15:09:09Z",
    "authors": [
      "Jialu Tang",
      "Hung Manh Pham",
      "Ignace De Lathauwer",
      "Henk S. Schipper",
      "Yuan Lu",
      "Dong Ma",
      "Aaqib Saeed"
    ],
    "pdf_url": "http://arxiv.org/pdf/2510.21551v1"
  },
  {
    "id": "2510.21542v1",
    "title": "HollowFlow: Efficient Sample Likelihood Evaluation using Hollow Message\n  Passing",
    "abstract": "Flow and diffusion-based models have emerged as powerful tools for scientific\napplications, particularly for sampling non-normalized probability\ndistributions, as exemplified by Boltzmann Generators (BGs). A critical\nchallenge in deploying these models is their reliance on sample likelihood\ncomputations, which scale prohibitively with system size $n$, often rendering\nthem infeasible for large-scale problems. To address this, we introduce\n$\\textit{HollowFlow}$, a flow-based generative model leveraging a novel\nnon-backtracking graph neural network (NoBGNN). By enforcing a block-diagonal\nJacobian structure, HollowFlow likelihoods are evaluated with a constant number\nof backward passes in $n$, yielding speed-ups of up to $\\mathcal{O}(n^2)$: a\nsignificant step towards scaling BGs to larger systems. Crucially, our\nframework generalizes: $\\textbf{any equivariant GNN or attention-based\narchitecture}$ can be adapted into a NoBGNN. We validate HollowFlow by training\nBGs on two different systems of increasing size. For both systems, the sampling\nand likelihood evaluation time decreases dramatically, following our\ntheoretical scaling laws. For the larger system we obtain a $10^2\\times$\nspeed-up, clearly illustrating the potential of HollowFlow-based approaches for\nhigh-dimensional scientific problems previously hindered by computational\nbottlenecks.",
    "categories": [
      "stat.ML",
      "cs.LG"
    ],
    "published": "2025-10-24T15:04:24Z",
    "authors": [
      "Johann Flemming Gloy",
      "Simon Olsson"
    ],
    "pdf_url": "http://arxiv.org/pdf/2510.21542v1"
  },
  {
    "id": "2510.21541v1",
    "title": "Cost Minimization for Space-Air-Ground Integrated Multi-Access Edge\n  Computing Systems",
    "abstract": "Space-air-ground integrated multi-access edge computing (SAGIN-MEC) provides\na promising solution for the rapidly developing low-altitude economy (LAE) to\ndeliver flexible and wide-area computing services. However, fully realizing the\npotential of SAGIN-MEC in the LAE presents significant challenges, including\ncoordinating decisions across heterogeneous nodes with different roles,\nmodeling complex factors such as mobility and network variability, and handling\nreal-time decision-making under partially observable environment with hybrid\nvariables. To address these challenges, we first present a hierarchical\nSAGIN-MEC architecture that enables the coordination between user devices\n(UDs), uncrewed aerial vehicles (UAVs), and satellites. Then, we formulate a UD\ncost minimization optimization problem (UCMOP) to minimize the UD cost by\njointly optimizing the task offloading ratio, UAV trajectory planning,\ncomputing resource allocation, and UD association. We show that the UCMOP is an\nNP-hard problem. To overcome this challenge, we propose a multi-agent deep\ndeterministic policy gradient (MADDPG)-convex optimization and coalitional game\n(MADDPG-COCG) algorithm. Specifically, we employ the MADDPG algorithm to\noptimize the continuous temporal decisions for heterogeneous nodes in the\npartially observable SAGIN-MEC system. Moreover, we propose a convex\noptimization and coalitional game (COCG) method to enhance the conventional\nMADDPG by deterministically handling the hybrid and varying-dimensional\ndecisions. Simulation results demonstrate that the proposed MADDPG-COCG\nalgorithm significantly enhances the user-centric performances in terms of the\naggregated UD cost, task completion delay, and UD energy consumption, with a\nslight increase in UAV energy consumption, compared to the benchmark\nalgorithms. Moreover, the MADDPG-COCG algorithm shows superior convergence\nstability and scalability.",
    "categories": [
      "cs.LG",
      "cs.IT",
      "math.IT"
    ],
    "published": "2025-10-24T15:03:07Z",
    "authors": [
      "Weihong Qin",
      "Aimin Wang",
      "Geng Sun",
      "Zemin Sun",
      "Jiacheng Wang",
      "Dusit Niyato",
      "Dong In Kim",
      "Zhu Han"
    ],
    "pdf_url": "http://arxiv.org/pdf/2510.21541v1"
  },
  {
    "id": "2510.21537v1",
    "title": "Excision Score: Evaluating Edits with Surgical Precision",
    "abstract": "Many tasks revolve around editing a document, whether code or text. We\nformulate the revision similarity problem to unify a wide range of machine\nlearning evaluation problems whose goal is to assess a revision to an existing\ndocument. We observe that revisions usually change only a small portion of an\nexisting document, so the existing document and its immediate revisions share a\nmajority of their content. We formulate five adequacy criteria for revision\nsimilarity measures, designed to align them with human judgement. We show that\npopular pairwise measures, like BLEU, fail to meet these criteria, because\ntheir scores are dominated by the shared content. They report high similarity\nbetween two revisions when humans would assess them as quite different. This is\na fundamental flaw we address. We propose a novel static measure, Excision\nScore (ES), which computes longest common subsequence (LCS) to remove content\nshared by an existing document with the ground truth and predicted revisions,\nbefore comparing only the remaining divergent regions. This is analogous to a\nsurgeon creating a sterile field to focus on the work area. We use\napproximation to speed the standard cubic LCS computation to quadratic. In\ncode-editing evaluation, where static measures are often used as a cheap proxy\nfor passing tests, we demonstrate that ES surpasses existing measures. When\naligned with test execution on HumanEvalFix, ES improves over its nearest\ncompetitor, SARI, by 12% Pearson correlation and by >21% over standard measures\nlike BLEU. The key criterion is invariance to shared context; when we perturb\nHumanEvalFix with increased shared context, ES' improvement over SARI increases\nto 20% and >30% over standard measures. ES also handles other corner cases that\nother measures do not, such as correctly aligning moved code blocks, and\nappropriately rewarding matching insertions or deletions.",
    "categories": [
      "cs.LG"
    ],
    "published": "2025-10-24T15:01:44Z",
    "authors": [
      "Nikolai Gruzinov",
      "Ksenia Sycheva",
      "Earl T. Barr",
      "Alex Bezzubov"
    ],
    "pdf_url": "http://arxiv.org/pdf/2510.21537v1"
  },
  {
    "id": "2510.21532v1",
    "title": "FrameShield: Adversarially Robust Video Anomaly Detection",
    "abstract": "Weakly Supervised Video Anomaly Detection (WSVAD) has achieved notable\nadvancements, yet existing models remain vulnerable to adversarial attacks,\nlimiting their reliability. Due to the inherent constraints of weak\nsupervision, where only video-level labels are provided despite the need for\nframe-level predictions, traditional adversarial defense mechanisms, such as\nadversarial training, are not effective since video-level adversarial\nperturbations are typically weak and inadequate. To address this limitation,\npseudo-labels generated directly from the model can enable frame-level\nadversarial training; however, these pseudo-labels are inherently noisy,\nsignificantly degrading performance. We therefore introduce a novel\nPseudo-Anomaly Generation method called Spatiotemporal Region Distortion (SRD),\nwhich creates synthetic anomalies by applying severe augmentations to localized\nregions in normal videos while preserving temporal consistency. Integrating\nthese precisely annotated synthetic anomalies with the noisy pseudo-labels\nsubstantially reduces label noise, enabling effective adversarial training.\nExtensive experiments demonstrate that our method significantly enhances the\nrobustness of WSVAD models against adversarial attacks, outperforming\nstate-of-the-art methods by an average of 71.0\\% in overall AUROC performance\nacross multiple benchmarks. The implementation and code are publicly available\nat https://github.com/rohban-lab/FrameShield.",
    "categories": [
      "cs.LG"
    ],
    "published": "2025-10-24T14:59:43Z",
    "authors": [
      "Mojtaba Nafez",
      "Mobina Poulaei",
      "Nikan Vasei",
      "Bardia Soltani Moakhar",
      "Mohammad Sabokrou",
      "MohammadHossein Rohban"
    ],
    "pdf_url": "http://arxiv.org/pdf/2510.21532v1"
  },
  {
    "id": "2510.21531v1",
    "title": "Probe-based Fine-tuning for Reducing Toxicity",
    "abstract": "Probes trained on model activations can detect undesirable behaviors like\ndeception or biases that are difficult to identify from outputs alone. This\nmakes them useful detectors to identify misbehavior. Furthermore, they are also\nvaluable training signals, since they not only reward outputs, but also good\ninternal processes for arriving at that output. However, training against\ninterpretability tools raises a fundamental concern: when a monitor becomes a\ntraining target, it may cease to be reliable (Goodhart's Law). We propose two\nmethods for training against probes based on Supervised Fine-tuning and Direct\nPreference Optimization. We conduct an initial exploration of these methods in\na testbed for reducing toxicity and evaluate the amount by which probe accuracy\ndrops when training against them. To retain the accuracy of probe-detectors\nafter training, we attempt (1) to train against an ensemble of probes, (2)\nretain held-out probes that aren't used for training, and (3) retrain new\nprobes after training.\n  First, probe-based preference optimization unexpectedly preserves probe\ndetectability better than classifier-based methods, suggesting the preference\nlearning objective incentivizes maintaining rather than obfuscating relevant\nrepresentations. Second, probe diversity provides minimal practical benefit -\nsimply retraining probes after optimization recovers high detection accuracy.\nOur findings suggest probe-based training can be viable for certain alignment\nmethods, though probe ensembles are largely unnecessary when retraining is\nfeasible.",
    "categories": [
      "cs.LG"
    ],
    "published": "2025-10-24T14:59:07Z",
    "authors": [
      "Jan Wehner",
      "Mario Fritz"
    ],
    "pdf_url": "http://arxiv.org/pdf/2510.21531v1"
  },
  {
    "id": "2510.21525v1",
    "title": "A Unified Model for Multi-Task Drone Routing in Post-Disaster Road\n  Assessment",
    "abstract": "Post-disaster road assessment (PDRA) is essential for emergency response,\nenabling rapid evaluation of infrastructure conditions and efficient allocation\nof resources. Although drones provide a flexible and effective tool for PDRA,\nrouting them in large-scale networks remains challenging. Traditional\noptimization methods scale poorly and demand domain expertise, while existing\ndeep reinforcement learning (DRL) approaches adopt a single-task paradigm,\nrequiring separate models for each problem variant and lacking adaptability to\nevolving operational needs. This study proposes a unified model (UM) for drone\nrouting that simultaneously addresses eight PDRA variants. By training a single\nneural network across multiple problem configurations, UM captures shared\nstructural knowledge while adapting to variant-specific constraints through a\nmodern transformer encoder-decoder architecture. A lightweight adapter\nmechanism further enables efficient finetuning to unseen attributes without\nretraining, enhancing deployment flexibility in dynamic disaster scenarios.\nExtensive experiments demonstrate that the UM reduces training time and\nparameters by a factor of eight compared with training separate models, while\nconsistently outperforming single-task DRL methods by 6--14\\% and traditional\noptimization approaches by 24--82\\% in terms of solution quality (total\ncollected information value). The model achieves real-time solutions (1--10\nseconds) across networks of up to 1,000 nodes, with robustness confirmed\nthrough sensitivity analyses. Moreover, finetuning experiments show that unseen\nattributes can be effectively incorporated with minimal cost while retaining\nhigh solution quality. The proposed UM advances neural combinatorial\noptimization for time-critical applications, offering a computationally\nefficient, high-quality, and adaptable solution for drone-based PDRA.",
    "categories": [
      "cs.LG"
    ],
    "published": "2025-10-24T14:48:57Z",
    "authors": [
      "Huatian Gong",
      "Jiuh-Biing Sheu",
      "Zheng Wang",
      "Xiaoguang Yang",
      "Ran Yan"
    ],
    "pdf_url": "http://arxiv.org/pdf/2510.21525v1"
  },
  {
    "id": "2510.23323v2",
    "title": "Towards Scaling Deep Neural Networks with Predictive Coding: Theory and\n  Practice",
    "abstract": "Backpropagation (BP) is the standard algorithm for training the deep neural\nnetworks that power modern artificial intelligence including large language\nmodels. However, BP is energy inefficient and unlikely to be implemented by the\nbrain. This thesis studies an alternative, potentially more efficient\nbrain-inspired algorithm called predictive coding (PC). Unlike BP, PC networks\n(PCNs) perform inference by iterative equilibration of neuron activities before\nlearning or weight updates. Recent work has suggested that this iterative\ninference procedure provides a range of benefits over BP, such as faster\ntraining. However, these advantages have not been consistently observed, the\ninference and learning dynamics of PCNs are still poorly understood, and deep\nPCNs remain practically untrainable. Here, we make significant progress towards\nscaling PCNs by taking a theoretical approach grounded in optimisation theory.\nFirst, we show that the learning dynamics of PC can be understood as an\napproximate trust-region method using second-order information, despite\nexplicitly using only first-order local updates. Second, going beyond this\napproximation, we show that PC can in principle make use of arbitrarily\nhigher-order information, such that for feedforward networks the effective\nlandscape on which PC learns is far more benign and robust to vanishing\ngradients than the (mean squared error) loss landscape. Third, motivated by a\nstudy of the inference dynamics of PCNs, we propose a new parameterisation\ncalled \"$\\mu$PC\", which for the first time allows stable training of 100+ layer\nnetworks with little tuning and competitive performance on simple tasks.\nOverall, this thesis significantly advances our fundamental understanding of\nthe inference and learning dynamics of PCNs, while highlighting the need for\nfuture research to focus on hardware co-design if PC is to compete with BP at\nscale.",
    "categories": [
      "cs.LG",
      "cs.NE",
      "I.2.6"
    ],
    "published": "2025-10-24T14:47:49Z",
    "authors": [
      "Francesco Innocenti"
    ],
    "pdf_url": "http://arxiv.org/pdf/2510.23323v2"
  },
  {
    "id": "2510.21523v1",
    "title": "Surrogate-based quantification of policy uncertainty in generative flow\n  networks",
    "abstract": "Generative flow networks are able to sample, via sequential construction,\nhigh-reward, complex objects according to a reward function. However, such\nreward functions are often estimated approximately from noisy data, leading to\nepistemic uncertainty in the learnt policy. We present an approach to quantify\nthis uncertainty by constructing a surrogate model composed of a polynomial\nchaos expansion, fit on a small ensemble of trained flow networks. This model\nlearns the relationship between reward functions, parametrised in a\nlow-dimensional space, and the probability distributions over actions at each\nstep along a trajectory of the flow network. The surrogate model can then be\nused for inexpensive Monte Carlo sampling to estimate the uncertainty in the\npolicy given uncertain rewards. We illustrate the performance of our approach\non a discrete and continuous grid-world, symbolic regression, and a Bayesian\nstructure learning task.",
    "categories": [
      "cs.LG",
      "stat.ML"
    ],
    "published": "2025-10-24T14:44:36Z",
    "authors": [
      "Ram\u00f3n Nartallo-Kaluarachchi",
      "Robert Manson-Sawko",
      "Shashanka Ubaru",
      "Dongsung Huh",
      "Ma\u0142gorzata J Zimo\u0144",
      "Lior Horesh",
      "Yoshua Bengio"
    ],
    "pdf_url": "http://arxiv.org/pdf/2510.21523v1"
  },
  {
    "id": "2510.21518v1",
    "title": "Head Pursuit: Probing Attention Specialization in Multimodal\n  Transformers",
    "abstract": "Language and vision-language models have shown impressive performance across\na wide range of tasks, but their internal mechanisms remain only partly\nunderstood. In this work, we study how individual attention heads in\ntext-generative models specialize in specific semantic or visual attributes.\nBuilding on an established interpretability method, we reinterpret the practice\nof probing intermediate activations with the final decoding layer through the\nlens of signal processing. This lets us analyze multiple samples in a\nprincipled way and rank attention heads based on their relevance to target\nconcepts. Our results show consistent patterns of specialization at the head\nlevel across both unimodal and multimodal transformers. Remarkably, we find\nthat editing as few as 1% of the heads, selected using our method, can reliably\nsuppress or enhance targeted concepts in the model output. We validate our\napproach on language tasks such as question answering and toxicity mitigation,\nas well as vision-language tasks including image classification and captioning.\nOur findings highlight an interpretable and controllable structure within\nattention layers, offering simple tools for understanding and editing\nlarge-scale generative models.",
    "categories": [
      "cs.CV",
      "cs.CL",
      "cs.LG"
    ],
    "published": "2025-10-24T14:41:47Z",
    "authors": [
      "Lorenzo Basile",
      "Valentino Maiorca",
      "Diego Doimo",
      "Francesco Locatello",
      "Alberto Cazzaniga"
    ],
    "pdf_url": "http://arxiv.org/pdf/2510.21518v1"
  },
  {
    "id": "2510.21513v2",
    "title": "Wisdom and Delusion of LLM Ensembles for Code Generation and Repair",
    "abstract": "Today's pursuit of a single Large Language Model (LMM) for all software\nengineering tasks is resource-intensive and overlooks the potential benefits of\ncomplementarity, where different models contribute unique strengths. However,\nthe degree to which coding LLMs complement each other and the best strategy for\nmaximizing an ensemble's potential are unclear, leaving practitioners without a\nclear path to move beyond single-model systems. To address this gap, we\nempirically compare ten individual LLMs from five families, and three ensembles\nof these LLMs across three software engineering benchmarks covering code\ngeneration and program repair. We assess the complementarity between models and\nthe performance gap between the best individual model and the ensembles. Next,\nwe evaluate various selection heuristics to identify correct solutions from an\nensemble's candidate pool. We find that the theoretical upperbound for an\nensemble's performance can be 83% above the best single model. Our results show\nthat consensus-based strategies for selecting solutions fall into a \"popularity\ntrap,\" amplifying common but incorrect outputs. In contrast, a diversity-based\nstrategy realizes up to 95% of this theoretical potential, and proves effective\neven in small two-model ensembles, enabling a cost-efficient way to enhance\nperformance by leveraging multiple LLMs.",
    "categories": [
      "cs.SE",
      "cs.CL",
      "cs.LG"
    ],
    "published": "2025-10-24T14:39:23Z",
    "authors": [
      "Fernando Vallecillos-Ruiz",
      "Max Hort",
      "Leon Moonen"
    ],
    "pdf_url": "http://arxiv.org/pdf/2510.21513v2"
  },
  {
    "id": "2510.21506v1",
    "title": "Uniform Convergence Beyond Glivenko-Cantelli",
    "abstract": "We characterize conditions under which collections of distributions on\n$\\{0,1\\}^\\mathbb{N}$ admit uniform estimation of their mean. Prior work from\nVapnik and Chervonenkis (1971) has focused on uniform convergence using the\nempirical mean estimator, leading to the principle known as $P-$\nGlivenko-Cantelli. We extend this framework by moving beyond the empirical mean\nestimator and introducing Uniform Mean Estimability, also called $UME-$\nlearnability, which captures when a collection permits uniform mean estimation\nby any arbitrary estimator. We work on the space created by the mean vectors of\nthe collection of distributions. For each distribution, the mean vector records\nthe expected value in each coordinate. We show that separability of the mean\nvectors is a sufficient condition for $UME-$ learnability. However, we show\nthat separability of the mean vectors is not necessary for $UME-$ learnability\nby constructing a collection of distributions whose mean vectors are\nnon-separable yet $UME-$ learnable using techniques fundamentally different\nfrom those used in our separability-based analysis. Finally, we establish that\ncountable unions of $UME-$ learnable collections are also $UME-$ learnable,\nsolving a conjecture posed in Cohen et al. (2025).",
    "categories": [
      "cs.LG"
    ],
    "published": "2025-10-24T14:33:22Z",
    "authors": [
      "Tanmay Devale",
      "Pramith Devulapalli",
      "Steve Hanneke"
    ],
    "pdf_url": "http://arxiv.org/pdf/2510.21506v1"
  },
  {
    "id": "2510.21898v1",
    "title": "A supervised discriminant data representation: application to pattern\n  classification",
    "abstract": "The performance of machine learning and pattern recognition algorithms\ngenerally depends on data representation. That is why, much of the current\neffort in performing machine learning algorithms goes into the design of\npreprocessing frameworks and data transformations able to support effective\nmachine learning. The method proposed in this work consists of a hybrid linear\nfeature extraction scheme to be used in supervised multi-class classification\nproblems. Inspired by two recent linear discriminant methods: robust sparse\nlinear discriminant analysis (RSLDA) and inter-class sparsitybased\ndiscriminative least square regression (ICS_DLSR), we propose a unifying\ncriterion that is able to retain the advantages of these two powerful methods.\nThe resulting transformation relies on sparsity-promoting techniques both to\nselect the features that most accurately represent the data and to preserve the\nrow-sparsity consistency property of samples from the same class. The linear\ntransformation and the orthogonal matrix are estimated using an iterative\nalternating minimization scheme based on steepest descent gradient method and\ndifferent initialization schemes. The proposed framework is generic in the\nsense that it allows the combination and tuning of other linear discriminant\nembedding methods. According to the experiments conducted on several datasets\nincluding faces, objects, and digits, the proposed method was able to\noutperform competing methods in most cases.",
    "categories": [
      "cs.LG",
      "cs.CV"
    ],
    "published": "2025-10-24T14:30:57Z",
    "authors": [
      "Fadi Dornaika",
      "Ahmad Khoder",
      "Abdelmalik Moujahid",
      "Wassim Khoder"
    ],
    "pdf_url": "http://arxiv.org/pdf/2510.21898v1"
  },
  {
    "id": "2510.23637v1",
    "title": "Combining Textual and Structural Information for Premise Selection in\n  Lean",
    "abstract": "Premise selection is a key bottleneck for scaling theorem proving in large\nformal libraries. Yet existing language-based methods often treat premises in\nisolation, ignoring the web of dependencies that connects them. We present a\ngraph-augmented approach that combines dense text embeddings of Lean\nformalizations with graph neural networks over a heterogeneous dependency graph\ncapturing both state--premise and premise--premise relations. On the LeanDojo\nBenchmark, our method outperforms the ReProver language-based baseline by over\n25% across standard retrieval metrics. These results demonstrate the power of\nrelational information for more effective premise selection.",
    "categories": [
      "cs.LG",
      "cs.AI",
      "cs.CL",
      "cs.LO"
    ],
    "published": "2025-10-24T14:24:13Z",
    "authors": [
      "Job Petrov\u010di\u010d",
      "David Eliecer Narvaez Denis",
      "Ljup\u010do Todorovski"
    ],
    "pdf_url": "http://arxiv.org/pdf/2510.23637v1"
  },
  {
    "id": "2510.21491v1",
    "title": "Benchmarking Catastrophic Forgetting Mitigation Methods in Federated\n  Time Series Forecasting",
    "abstract": "Catastrophic forgetting (CF) poses a persistent challenge in continual\nlearning (CL), especially within federated learning (FL) environments\ncharacterized by non-i.i.d. time series data. While existing research has\nlargely focused on classification tasks in vision domains, the regression-based\nforecasting setting prevalent in IoT and edge applications remains\nunderexplored. In this paper, we present the first benchmarking framework\ntailored to investigate CF in federated continual time series forecasting.\nUsing the Beijing Multi-site Air Quality dataset across 12 decentralized\nclients, we systematically evaluate several CF mitigation strategies, including\nReplay, Elastic Weight Consolidation, Learning without Forgetting, and Synaptic\nIntelligence. Key contributions include: (i) introducing a new benchmark for CF\nin time series FL, (ii) conducting a comprehensive comparative analysis of\nstate-of-the-art methods, and (iii) releasing a reproducible open-source\nframework. This work provides essential tools and insights for advancing\ncontinual learning in federated time-series forecasting systems.",
    "categories": [
      "cs.LG",
      "cs.DC",
      "stat.ML",
      "68T07, 68W15, 62M10",
      "I.2.6; I.2.7; I.5.1; I.5.4"
    ],
    "published": "2025-10-24T14:15:55Z",
    "authors": [
      "Khaled Hallak",
      "Oudom Kem"
    ],
    "pdf_url": "http://arxiv.org/pdf/2510.21491v1"
  },
  {
    "id": "2510.21468v1",
    "title": "Finite-Time Analysis of Stochastic Nonconvex Nonsmooth Optimization on\n  the Riemannian Manifolds",
    "abstract": "This work addresses the finite-time analysis of nonsmooth nonconvex\nstochastic optimization under Riemannian manifold constraints. We adapt the\nnotion of Goldstein stationarity to the Riemannian setting as a performance\nmetric for nonsmooth optimization on manifolds. We then propose a Riemannian\nOnline to NonConvex (RO2NC) algorithm, for which we establish the sample\ncomplexity of $O(\\epsilon^{-3}\\delta^{-1})$ in finding\n$(\\delta,\\epsilon)$-stationary points. This result is the first-ever\nfinite-time guarantee for fully nonsmooth, nonconvex optimization on manifolds\nand matches the optimal complexity in the Euclidean setting. When gradient\ninformation is unavailable, we develop a zeroth order version of RO2NC\nalgorithm (ZO-RO2NC), for which we establish the same sample complexity. The\nnumerical results support the theory and demonstrate the practical\neffectiveness of the algorithms.",
    "categories": [
      "math.OC",
      "cs.LG"
    ],
    "published": "2025-10-24T13:55:43Z",
    "authors": [
      "Emre Sahinoglu",
      "Youbang Sun",
      "Shahin Shahrampour"
    ],
    "pdf_url": "http://arxiv.org/pdf/2510.21468v1"
  },
  {
    "id": "2510.21462v1",
    "title": "Parameter-Free Hypergraph Neural Network for Few-Shot Node\n  Classification",
    "abstract": "Few-shot node classification on hypergraphs requires models that generalize\nfrom scarce labels while capturing high-order structures. Existing hypergraph\nneural networks (HNNs) effectively encode such structures but often suffer from\noverfitting and scalability issues due to complex, black-box architectures. In\nthis work, we propose ZEN (Zero-Parameter Hypergraph Neural Network), a fully\nlinear and parameter-free model that achieves both expressiveness and\nefficiency. Built upon a unified formulation of linearized HNNs, ZEN introduces\na tractable closed-form solution for the weight matrix and a redundancy-aware\npropagation scheme to avoid iterative training and to eliminate redundant self\ninformation. On 11 real-world hypergraph benchmarks, ZEN consistently\noutperforms eight baseline models in classification accuracy while achieving up\nto 696x speedups over the fastest competitor. Moreover, the decision process of\nZEN is fully interpretable, providing insights into the characteristic of a\ndataset. Our code and datasets are fully available at\nhttps://github.com/chaewoonbae/ZEN.",
    "categories": [
      "cs.LG"
    ],
    "published": "2025-10-24T13:44:48Z",
    "authors": [
      "Chaewoon Bae",
      "Doyun Choi",
      "Jaehyun Lee",
      "Jaemin Yoo"
    ],
    "pdf_url": "http://arxiv.org/pdf/2510.21462v1"
  },
  {
    "id": "2510.21460v1",
    "title": "Risk Management for Mitigating Benchmark Failure Modes: BenchRisk",
    "abstract": "Large language model (LLM) benchmarks inform LLM use decisions (e.g., \"is\nthis LLM safe to deploy for my use case and context?\"). However, benchmarks may\nbe rendered unreliable by various failure modes that impact benchmark bias,\nvariance, coverage, or people's capacity to understand benchmark evidence.\nUsing the National Institute of Standards and Technology's risk management\nprocess as a foundation, this research iteratively analyzed 26 popular\nbenchmarks, identifying 57 potential failure modes and 196 corresponding\nmitigation strategies. The mitigations reduce failure likelihood and/or\nseverity, providing a frame for evaluating \"benchmark risk,\" which is scored to\nprovide a metaevaluation benchmark: BenchRisk. Higher scores indicate that\nbenchmark users are less likely to reach an incorrect or unsupported conclusion\nabout an LLM. All 26 scored benchmarks present significant risk within one or\nmore of the five scored dimensions (comprehensiveness, intelligibility,\nconsistency, correctness, and longevity), which points to important open\nresearch directions for the field of LLM benchmarking. The BenchRisk workflow\nallows for comparison between benchmarks; as an open-source tool, it also\nfacilitates the identification and sharing of risks and their mitigations.",
    "categories": [
      "cs.SE",
      "cs.CY",
      "cs.LG"
    ],
    "published": "2025-10-24T13:43:29Z",
    "authors": [
      "Sean McGregor",
      "Victor Lu",
      "Vassil Tashev",
      "Armstrong Foundjem",
      "Aishwarya Ramasethu",
      "Sadegh AlMahdi Kazemi Zarkouei",
      "Chris Knotz",
      "Kongtao Chen",
      "Alicia Parrish",
      "Anka Reuel",
      "Heather Frase"
    ],
    "pdf_url": "http://arxiv.org/pdf/2510.21460v1"
  },
  {
    "id": "2510.21459v1",
    "title": "SBASH: a Framework for Designing and Evaluating RAG vs. Prompt-Tuned LLM\n  Honeypots",
    "abstract": "Honeypots are decoy systems used for gathering valuable threat intelligence\nor diverting attackers away from production systems. Maximising attacker\nengagement is essential to their utility. However research has highlighted that\ncontext-awareness, such as the ability to respond to new attack types, systems\nand attacker agents, is necessary to increase engagement. Large Language Models\n(LLMs) have been shown as one approach to increase context awareness but suffer\nfrom several challenges including accuracy and timeliness of response time,\nhigh operational costs and data-protection issues due to cloud deployment. We\npropose the System-Based Attention Shell Honeypot (SBASH) framework which\nmanages data-protection issues through the use of lightweight local LLMs. We\ninvestigate the use of Retrieval Augmented Generation (RAG) supported LLMs and\nnon-RAG LLMs for Linux shell commands and evaluate them using several different\nmetrics such as response time differences, realism from human testers, and\nsimilarity to a real system calculated with Levenshtein distance, SBert, and\nBertScore. We show that RAG improves accuracy for untuned models while models\nthat have been tuned via a system prompt that tells the LLM to respond like a\nLinux system achieve without RAG a similar accuracy as untuned with RAG, while\nhaving a slightly lower latency.",
    "categories": [
      "cs.CR",
      "cs.CL",
      "cs.LG",
      "K.6.5; D.4.6; I.2.7"
    ],
    "published": "2025-10-24T13:41:52Z",
    "authors": [
      "Adetayo Adebimpe",
      "Helmut Neukirchen",
      "Thomas Welsh"
    ],
    "pdf_url": "http://arxiv.org/pdf/2510.21459v1"
  },
  {
    "id": "2510.21457v1",
    "title": "Estimating Treatment Effects in Networks using Domain Adversarial\n  Training",
    "abstract": "Estimating heterogeneous treatment effects in network settings is complicated\nby interference, meaning that the outcome of an instance can be influenced by\nthe treatment status of others. Existing causal machine learning approaches\nusually assume a known exposure mapping that summarizes how the outcome of a\ngiven instance is influenced by others' treatment, a simplification that is\noften unrealistic. Furthermore, the interaction between homophily -- the\ntendency of similar instances to connect -- and the treatment assignment\nmechanism can induce a network-level covariate shift that may lead to\ninaccurate treatment effect estimates, a phenomenon that has not yet been\nexplicitly studied. To address these challenges, we propose HINet, a novel\nmethod that integrates graph neural networks with domain adversarial training.\nThis combination allows estimating treatment effects under unknown exposure\nmappings while mitigating the impact of (network-level) covariate shift. An\nextensive empirical evaluation on synthetic and semi-synthetic network datasets\ndemonstrates the effectiveness of our approach.",
    "categories": [
      "cs.LG"
    ],
    "published": "2025-10-24T13:34:43Z",
    "authors": [
      "Daan Caljon",
      "Jente Van Belle",
      "Wouter Verbeke"
    ],
    "pdf_url": "http://arxiv.org/pdf/2510.21457v1"
  },
  {
    "id": "2510.21455v1",
    "title": "Towards Explainable Personalized Recommendations by Learning from Users'\n  Photos",
    "abstract": "Explaining the output of a complex system, such as a Recommender System (RS),\nis becoming of utmost importance for both users and companies. In this paper we\nexplore the idea that personalized explanations can be learned as\nrecommendation themselves. There are plenty of online services where users can\nupload some photos, in addition to rating items. We assume that users take\nthese photos to reinforce or justify their opinions about the items. For this\nreason we try to predict what photo a user would take of an item, because that\nimage is the argument that can best convince her of the qualities of the item.\nIn this sense, an RS can explain its results and, therefore, increase its\nreliability. Furthermore, once we have a model to predict attractive images for\nusers, we can estimate their distribution. Thus, the companies acquire a vivid\nknowledge about the aspects that the clients highlight of their products. The\npaper includes a formal framework that estimates the authorship probability for\na given pair (user, photo). To illustrate the proposal, we use data gathered\nfrom TripAdvisor containing the reviews (with photos) of restaurants in six\ncities of different sizes.",
    "categories": [
      "cs.LG"
    ],
    "published": "2025-10-24T13:33:50Z",
    "authors": [
      "Jorge D\u00edez",
      "Pablo P\u00e9rez-N\u00fa\u00f1ez",
      "Oscar Luaces",
      "Beatriz Remeseiro",
      "Antonio Bahamonde"
    ],
    "pdf_url": "http://arxiv.org/pdf/2510.21455v1"
  },
  {
    "id": "2510.21453v1",
    "title": "Multi-Task Vehicle Routing Solver via Mixture of Specialized Experts\n  under State-Decomposable MDP",
    "abstract": "Existing neural methods for multi-task vehicle routing problems (VRPs)\ntypically learn unified solvers to handle multiple constraints simultaneously.\nHowever, they often underutilize the compositional structure of VRP variants,\neach derivable from a common set of basis VRP variants. This critical oversight\ncauses unified solvers to miss out the potential benefits of basis solvers,\neach specialized for a basis VRP variant. To overcome this limitation, we\npropose a framework that enables unified solvers to perceive the\nshared-component nature across VRP variants by proactively reusing basis\nsolvers, while mitigating the exponential growth of trained neural solvers.\nSpecifically, we introduce a State-Decomposable MDP (SDMDP) that reformulates\nVRPs by expressing the state space as the Cartesian product of basis state\nspaces associated with basis VRP variants. More crucially, this formulation\ninherently yields the optimal basis policy for each basis VRP variant.\nFurthermore, a Latent Space-based SDMDP extension is developed by incorporating\nboth the optimal basis policies and a learnable mixture function to enable the\npolicy reuse in the latent space. Under mild assumptions, this extension\nprovably recovers the optimal unified policy of SDMDP through the mixture\nfunction that computes the state embedding as a mapping from the basis state\nembeddings generated by optimal basis policies. For practical implementation,\nwe introduce the Mixture-of-Specialized-Experts Solver (MoSES), which realizes\nbasis policies through specialized Low-Rank Adaptation (LoRA) experts, and\nimplements the mixture function via an adaptive gating mechanism. Extensive\nexperiments conducted across VRP variants showcase the superiority of MoSES\nover prior methods.",
    "categories": [
      "cs.AI",
      "cs.LG"
    ],
    "published": "2025-10-24T13:31:31Z",
    "authors": [
      "Yuxin Pan",
      "Zhiguang Cao",
      "Chengyang Gu",
      "Liu Liu",
      "Peilin Zhao",
      "Yize Chen",
      "Fangzhen Lin"
    ],
    "pdf_url": "http://arxiv.org/pdf/2510.21453v1"
  },
  {
    "id": "2510.21450v1",
    "title": "ParaRNN: Unlocking Parallel Training of Nonlinear RNNs for Large\n  Language Models",
    "abstract": "Recurrent Neural Networks (RNNs) laid the foundation for sequence modeling,\nbut their intrinsic sequential nature restricts parallel computation, creating\na fundamental barrier to scaling. This has led to the dominance of\nparallelizable architectures like Transformers and, more recently, State Space\nModels (SSMs). While SSMs achieve efficient parallelization through structured\nlinear recurrences, this linearity constraint limits their expressive power and\nprecludes modeling complex, nonlinear sequence-wise dependencies. To address\nthis, we present ParaRNN, a framework that breaks the sequence-parallelization\nbarrier for nonlinear RNNs. Building on prior work, we cast the sequence of\nnonlinear recurrence relationships as a single system of equations, which we\nsolve in parallel using Newton's iterations combined with custom parallel\nreductions. Our implementation achieves speedups of up to 665x over naive\nsequential application, allowing training nonlinear RNNs at unprecedented\nscales. To showcase this, we apply ParaRNN to adaptations of LSTM and GRU\narchitectures, successfully training models of 7B parameters that attain\nperplexity comparable to similarly-sized Transformers and Mamba2 architectures.\nTo accelerate research in efficient sequence modeling, we release the ParaRNN\ncodebase as an open-source framework for automatic training-parallelization of\nnonlinear RNNs, enabling researchers and practitioners to explore new nonlinear\nRNN models at scale.",
    "categories": [
      "cs.LG",
      "68T07, 68W10",
      "I.2.7"
    ],
    "published": "2025-10-24T13:28:33Z",
    "authors": [
      "Federico Danieli",
      "Pau Rodriguez",
      "Miguel Sarabia",
      "Xavier Suau",
      "Luca Zappella"
    ],
    "pdf_url": "http://arxiv.org/pdf/2510.21450v1"
  },
  {
    "id": "2510.21448v1",
    "title": "Unified token representations for sequential decision models",
    "abstract": "Transformers have demonstrated strong potential in offline reinforcement\nlearning (RL) by modeling trajectories as sequences of return-to-go, states,\nand actions. However, existing approaches such as the Decision Transformer(DT)\nand its variants suffer from redundant tokenization and quadratic attention\ncomplexity, limiting their scalability in real-time or resource-constrained\nsettings. To address this, we propose a Unified Token Representation (UTR) that\nmerges return-to-go, state, and action into a single token, substantially\nreducing sequence length and model complexity. Theoretical analysis shows that\nUTR leads to a tighter Rademacher complexity bound, suggesting improved\ngeneralization. We further develop two variants: UDT and UDC, built upon\ntransformer and gated CNN backbones, respectively. Both achieve comparable or\nsuperior performance to state-of-the-art methods with markedly lower\ncomputation. These findings demonstrate that UTR generalizes well across\narchitectures and may provide an efficient foundation for scalable control in\nfuture large decision models.",
    "categories": [
      "cs.LG"
    ],
    "published": "2025-10-24T13:25:43Z",
    "authors": [
      "Zhuojing Tian",
      "Yushu Chen"
    ],
    "pdf_url": "http://arxiv.org/pdf/2510.21448v1"
  },
  {
    "id": "2510.21445v1",
    "title": "REMONI: An Autonomous System Integrating Wearables and Multimodal Large\n  Language Models for Enhanced Remote Health Monitoring",
    "abstract": "With the widespread adoption of wearable devices in our daily lives, the\ndemand and appeal for remote patient monitoring have significantly increased.\nMost research in this field has concentrated on collecting sensor data,\nvisualizing it, and analyzing it to detect anomalies in specific diseases such\nas diabetes, heart disease and depression. However, this domain has a notable\ngap in the aspect of human-machine interaction. This paper proposes REMONI, an\nautonomous REmote health MONItoring system that integrates multimodal large\nlanguage models (MLLMs), the Internet of Things (IoT), and wearable devices.\nThe system automatically and continuously collects vital signs, accelerometer\ndata from a special wearable (such as a smartwatch), and visual data in patient\nvideo clips collected from cameras. This data is processed by an anomaly\ndetection module, which includes a fall detection model and algorithms to\nidentify and alert caregivers of the patient's emergency conditions. A\ndistinctive feature of our proposed system is the natural language processing\ncomponent, developed with MLLMs capable of detecting and recognizing a\npatient's activity and emotion while responding to healthcare worker's\ninquiries. Additionally, prompt engineering is employed to integrate all\npatient information seamlessly. As a result, doctors and nurses can access\nreal-time vital signs and the patient's current state and mood by interacting\nwith an intelligent agent through a user-friendly web application. Our\nexperiments demonstrate that our system is implementable and scalable for\nreal-life scenarios, potentially reducing the workload of medical professionals\nand healthcare costs. A full-fledged prototype illustrating the functionalities\nof the system has been developed and being tested to demonstrate the robustness\nof its various capabilities.",
    "categories": [
      "cs.CL",
      "cs.AI",
      "cs.CV",
      "cs.LG"
    ],
    "published": "2025-10-24T13:23:38Z",
    "authors": [
      "Thanh Cong Ho",
      "Farah Kharrat",
      "Abderrazek Abid",
      "Fakhri Karray"
    ],
    "pdf_url": "http://arxiv.org/pdf/2510.21445v1"
  },
  {
    "id": "2510.21442v1",
    "title": "Scalable Neural Incentive Design with Parameterized Mean-Field\n  Approximation",
    "abstract": "Designing incentives for a multi-agent system to induce a desirable Nash\nequilibrium is both a crucial and challenging problem appearing in many\ndecision-making domains, especially for a large number of agents $N$. Under the\nexchangeability assumption, we formalize this incentive design (ID) problem as\na parameterized mean-field game (PMFG), aiming to reduce complexity via an\ninfinite-population limit. We first show that when dynamics and rewards are\nLipschitz, the finite-$N$ ID objective is approximated by the PMFG at rate\n$\\mathscr{O}(\\frac{1}{\\sqrt{N}})$. Moreover, beyond the Lipschitz-continuous\nsetting, we prove the same $\\mathscr{O}(\\frac{1}{\\sqrt{N}})$ decay for the\nimportant special case of sequential auctions, despite discontinuities in\ndynamics, through a tailored auction-specific analysis. Built on our novel\napproximation results, we further introduce our Adjoint Mean-Field Incentive\nDesign (AMID) algorithm, which uses explicit differentiation of iterated\nequilibrium operators to compute gradients efficiently. By uniting\napproximation bounds with optimization guarantees, AMID delivers a powerful,\nscalable algorithmic tool for many-agent (large $N$) ID. Across diverse auction\nsettings, the proposed AMID method substantially increases revenue over\nfirst-price formats and outperforms existing benchmark methods.",
    "categories": [
      "cs.GT",
      "cs.LG",
      "cs.MA"
    ],
    "published": "2025-10-24T13:18:54Z",
    "authors": [
      "Nathan Corecco",
      "Batuhan Yardim",
      "Vinzenz Thoma",
      "Zebang Shen",
      "Niao He"
    ],
    "pdf_url": "http://arxiv.org/pdf/2510.21442v1"
  },
  {
    "id": "2510.21431v1",
    "title": "Oracle-Efficient Combinatorial Semi-Bandits",
    "abstract": "We study the combinatorial semi-bandit problem where an agent selects a\nsubset of base arms and receives individual feedback. While this generalizes\nthe classical multi-armed bandit and has broad applicability, its scalability\nis limited by the high cost of combinatorial optimization, requiring oracle\nqueries at every round. To tackle this, we propose oracle-efficient frameworks\nthat significantly reduce oracle calls while maintaining tight regret\nguarantees. For the worst-case linear reward setting, our algorithms achieve\n$\\tilde{O}(\\sqrt{T})$ regret using only $O(\\log\\log T)$ oracle queries. We also\npropose covariance-adaptive algorithms that leverage noise structure for\nimproved regret, and extend our approach to general (non-linear) rewards.\nOverall, our methods reduce oracle usage from linear to (doubly) logarithmic in\ntime, with strong theoretical guarantees.",
    "categories": [
      "stat.ML",
      "cs.LG"
    ],
    "published": "2025-10-24T13:07:08Z",
    "authors": [
      "Jung-hun Kim",
      "Milan Vojnovi\u0107",
      "Min-hwan Oh"
    ],
    "pdf_url": "http://arxiv.org/pdf/2510.21431v1"
  },
  {
    "id": "2510.21427v1",
    "title": "Causality Meets Locality: Provably Generalizable and Scalable Policy\n  Learning for Networked Systems",
    "abstract": "Large-scale networked systems, such as traffic, power, and wireless grids,\nchallenge reinforcement-learning agents with both scale and environment shifts.\nTo address these challenges, we propose GSAC (Generalizable and Scalable\nActor-Critic), a framework that couples causal representation learning with\nmeta actor-critic learning to achieve both scalability and domain\ngeneralization. Each agent first learns a sparse local causal mask that\nprovably identifies the minimal neighborhood variables influencing its\ndynamics, yielding exponentially tight approximately compact representations\n(ACRs) of state and domain factors. These ACRs bound the error of truncating\nvalue functions to $\\kappa$-hop neighborhoods, enabling efficient learning on\ngraphs. A meta actor-critic then trains a shared policy across multiple source\ndomains while conditioning on the compact domain factors; at test time, a few\ntrajectories suffice to estimate the new domain factor and deploy the adapted\npolicy. We establish finite-sample guarantees on causal recovery, actor-critic\nconvergence, and adaptation gap, and show that GSAC adapts rapidly and\nsignificantly outperforms learning-from-scratch and conventional adaptation\nbaselines.",
    "categories": [
      "cs.LG"
    ],
    "published": "2025-10-24T13:06:43Z",
    "authors": [
      "Hao Liang",
      "Shuqing Shi",
      "Yudi Zhang",
      "Biwei Huang",
      "Yali Du"
    ],
    "pdf_url": "http://arxiv.org/pdf/2510.21427v1"
  },
  {
    "id": "2510.21426v1",
    "title": "A Rapid Physics-Informed Machine Learning Framework Based on Extreme\n  Learning Machine for Inverse Stefan Problems",
    "abstract": "The inverse Stefan problem, as a typical phase-change problem with moving\nboundaries, finds extensive applications in science and engineering. Recent\nyears have seen the applications of physics-informed neural networks (PINNs) to\nsolving Stefan problems, yet they still exhibit shortcomings in hyperparameter\ndependency, training efficiency, and prediction accuracy. To address this, this\npaper develops a physics-informed extreme learning machine (PIELM), a rapid\nphysics-informed learning method framework for inverse Stefan problems. PIELM\nreplaces conventional deep neural networks with an extreme learning machine\nnetwork. The input weights are fixed in the PIELM framework, and the output\nweights are determined by optimizing a loss vector of physical laws composed by\ninitial and boundary conditions and governing partial differential equations\n(PDEs). Then, solving inverse Stefan problems is transformed into finding the\nMoore-Penrose generalized inverse by the least squares method. Case studies\nshow that the PIELM can increase the prediction accuracy by 3-7 order of\nmagnitude in terms of the relative L2 error, and meanwhile saving more than 94%\ntraining time, compared to conventional PINNs.",
    "categories": [
      "cs.LG"
    ],
    "published": "2025-10-24T13:06:34Z",
    "authors": [
      "Pei-Zhi Zhuang",
      "Ming-Yue Yang",
      "Fei Ren",
      "Hong-Ya Yue",
      "He Yang"
    ],
    "pdf_url": "http://arxiv.org/pdf/2510.21426v1"
  },
  {
    "id": "2510.21424v1",
    "title": "Vision Language Models for Dynamic Human Activity Recognition in\n  Healthcare Settings",
    "abstract": "As generative AI continues to evolve, Vision Language Models (VLMs) have\nemerged as promising tools in various healthcare applications. One area that\nremains relatively underexplored is their use in human activity recognition\n(HAR) for remote health monitoring. VLMs offer notable strengths, including\ngreater flexibility and the ability to overcome some of the constraints of\ntraditional deep learning models. However, a key challenge in applying VLMs to\nHAR lies in the difficulty of evaluating their dynamic and often\nnon-deterministic outputs. To address this gap, we introduce a descriptive\ncaption data set and propose comprehensive evaluation methods to evaluate VLMs\nin HAR. Through comparative experiments with state-of-the-art deep learning\nmodels, our findings demonstrate that VLMs achieve comparable performance and,\nin some cases, even surpass conventional approaches in terms of accuracy. This\nwork contributes a strong benchmark and opens new possibilities for the\nintegration of VLMs into intelligent healthcare systems.",
    "categories": [
      "cs.CL",
      "cs.AI",
      "cs.CV",
      "cs.LG"
    ],
    "published": "2025-10-24T13:04:13Z",
    "authors": [
      "Abderrazek Abid",
      "Thanh-Cong Ho",
      "Fakhri Karray"
    ],
    "pdf_url": "http://arxiv.org/pdf/2510.21424v1"
  },
  {
    "id": "2510.21418v1",
    "title": "DreamerV3-XP: Optimizing exploration through uncertainty estimation",
    "abstract": "We introduce DreamerV3-XP, an extension of DreamerV3 that improves\nexploration and learning efficiency. This includes (i) a prioritized replay\nbuffer, scoring trajectories by return, reconstruction loss, and value error\nand (ii) an intrinsic reward based on disagreement over predicted environment\nrewards from an ensemble of world models. DreamerV3-XP is evaluated on a subset\nof Atari100k and DeepMind Control Visual Benchmark tasks, confirming the\noriginal DreamerV3 results and showing that our extensions lead to faster\nlearning and lower dynamics model loss, particularly in sparse-reward settings.",
    "categories": [
      "cs.LG",
      "cs.AI"
    ],
    "published": "2025-10-24T12:58:27Z",
    "authors": [
      "Lukas Bierling",
      "Davide Pasero",
      "Jan-Henrik Bertrand",
      "Kiki Van Gerwen"
    ],
    "pdf_url": "http://arxiv.org/pdf/2510.21418v1"
  },
  {
    "id": "2510.21417v1",
    "title": "Self-diffusion for Solving Inverse Problems",
    "abstract": "We propose self-diffusion, a novel framework for solving inverse problems\nwithout relying on pretrained generative models. Traditional diffusion-based\napproaches require training a model on a clean dataset to learn to reverse the\nforward noising process. This model is then used to sample clean solutions --\ncorresponding to posterior sampling from a Bayesian perspective -- that are\nconsistent with the observed data under a specific task. In contrast,\nself-diffusion introduces a self-contained iterative process that alternates\nbetween noising and denoising steps to progressively refine its estimate of the\nsolution. At each step of self-diffusion, noise is added to the current\nestimate, and a self-denoiser, which is a single untrained convolutional\nnetwork randomly initialized from scratch, is continuously trained for certain\niterations via a data fidelity loss to predict the solution from the noisy\nestimate. Essentially, self-diffusion exploits the spectral bias of neural\nnetworks and modulates it through a scheduled noise process. Without relying on\npretrained score functions or external denoisers, this approach still remains\nadaptive to arbitrary forward operators and noisy observations, making it\nhighly flexible and broadly applicable. We demonstrate the effectiveness of our\napproach on a variety of linear inverse problems, showing that self-diffusion\nachieves competitive or superior performance compared to other methods.",
    "categories": [
      "cs.LG"
    ],
    "published": "2025-10-24T12:57:22Z",
    "authors": [
      "Guanxiong Luo",
      "Shoujin Huang",
      "Yanlong Yang"
    ],
    "pdf_url": "http://arxiv.org/pdf/2510.21417v1"
  },
  {
    "id": "2510.21408v1",
    "title": "Large Language Models as Model Organisms for Human Associative Learning",
    "abstract": "Associative learning--forming links between co-occurring items--is\nfundamental to human cognition, reshaping internal representations in complex\nways. Testing hypotheses on how representational changes occur in biological\nsystems is challenging, but large language models (LLMs) offer a scalable\nalternative. Building on LLMs' in-context learning, we adapt a cognitive\nneuroscience associative learning paradigm and investigate how representations\nevolve across six models. Our initial findings reveal a non-monotonic pattern\nconsistent with the Non-Monotonic Plasticity Hypothesis, with moderately\nsimilar items differentiating after learning. Leveraging the controllability of\nLLMs, we further show that this differentiation is modulated by the overlap of\nassociated items with the broader vocabulary--a factor we term vocabulary\ninterference, capturing how new associations compete with prior knowledge. We\nfind that higher vocabulary interference amplifies differentiation, suggesting\nthat representational change is influenced by both item similarity and global\ncompetition. Our findings position LLMs not only as powerful tools for studying\nrepresentational dynamics in human-like learning systems, but also as\naccessible and general computational models for generating new hypotheses about\nthe principles underlying memory reorganization in the brain.",
    "categories": [
      "cs.LG",
      "cs.AI"
    ],
    "published": "2025-10-24T12:52:11Z",
    "authors": [
      "Camila Kolling",
      "Vy Ai Vo",
      "Mariya Toneva"
    ],
    "pdf_url": "http://arxiv.org/pdf/2510.21408v1"
  },
  {
    "id": "2510.21402v1",
    "title": "Disentangled Representation Learning via Modular Compositional Bias",
    "abstract": "Recent disentangled representation learning (DRL) methods heavily rely on\nfactor specific strategies-either learning objectives for attributes or model\narchitectures for objects-to embed inductive biases. Such divergent approaches\nresult in significant overhead when novel factors of variation do not align\nwith prior assumptions, such as statistical independence or spatial\nexclusivity, or when multiple factors coexist, as practitioners must redesign\narchitectures or objectives. To address this, we propose a compositional bias,\na modular inductive bias decoupled from both objectives and architectures. Our\nkey insight is that different factors obey distinct recombination rules in the\ndata distribution: global attributes are mutually exclusive, e.g., a face has\none nose, while objects share a common support (any subset of objects can\nco-exist). We therefore randomly remix latents according to factor-specific\nrules, i.e., a mixing strategy, and force the encoder to discover whichever\nfactor structure the mixing strategy reflects through two complementary\nobjectives: (i) a prior loss that ensures every remix decodes into a realistic\nimage, and (ii) the compositional consistency loss introduced by Wiedemer et\nal. (arXiv:2310.05327), which aligns each composite image with its\ncorresponding composite latent. Under this general framework, simply adjusting\nthe mixing strategy enables disentanglement of attributes, objects, and even\nboth, without modifying the objectives or architectures. Extensive experiments\ndemonstrate that our method shows competitive performance in both attribute and\nobject disentanglement, and uniquely achieves joint disentanglement of global\nstyle and objects. Code is available at\nhttps://github.com/whieya/Compositional-DRL.",
    "categories": [
      "cs.LG",
      "cs.CV"
    ],
    "published": "2025-10-24T12:46:19Z",
    "authors": [
      "Whie Jung",
      "Dong Hoon Lee",
      "Seunghoon Hong"
    ],
    "pdf_url": "http://arxiv.org/pdf/2510.21402v1"
  },
  {
    "id": "2510.21392v1",
    "title": "On Local Limits of Sparse Random Graphs: Color Convergence and the\n  Refined Configuration Model",
    "abstract": "Local convergence has emerged as a fundamental tool for analyzing sparse\nrandom graph models. We introduce a new notion of local convergence, color\nconvergence, based on the Weisfeiler-Leman algorithm. Color convergence fully\ncharacterizes the class of random graphs that are well-behaved in the limit for\nmessage-passing graph neural networks. Building on this, we propose the Refined\nConfiguration Model (RCM), a random graph model that generalizes the\nconfiguration model. The RCM is universal with respect to local convergence\namong locally tree-like random graph models, including Erd\\H{o}s-R\\'enyi,\nstochastic block and configuration models. Finally, this framework enables a\ncomplete characterization of the random trees that arise as local limits of\nsuch graphs.",
    "categories": [
      "cs.DM",
      "cs.LG"
    ],
    "published": "2025-10-24T12:29:51Z",
    "authors": [
      "Alexander Pluska",
      "Sagar Malhotra"
    ],
    "pdf_url": "http://arxiv.org/pdf/2510.21392v1"
  },
  {
    "id": "2510.21389v1",
    "title": "Assessing the Real-World Utility of Explainable AI for Arousal\n  Diagnostics: An Application-Grounded User Study",
    "abstract": "Artificial intelligence (AI) systems increasingly match or surpass human\nexperts in biomedical signal interpretation. However, their effective\nintegration into clinical practice requires more than high predictive accuracy.\nClinicians must discern \\textit{when} and \\textit{why} to trust algorithmic\nrecommendations. This work presents an application-grounded user study with\neight professional sleep medicine practitioners, who score nocturnal arousal\nevents in polysomnographic data under three conditions: (i) manual scoring,\n(ii) black-box (BB) AI assistance, and (iii) transparent white-box (WB) AI\nassistance. Assistance is provided either from the \\textit{start} of scoring or\nas a post-hoc quality-control (\\textit{QC}) review. We systematically evaluate\nhow the type and timing of assistance influence event-level and clinically most\nrelevant count-based performance, time requirements, and user experience. When\nevaluated against the clinical standard used to train the AI, both AI and\nhuman-AI teams significantly outperform unaided experts, with collaboration\nalso reducing inter-rater variability. Notably, transparent AI assistance\napplied as a targeted QC step yields median event-level performance\nimprovements of approximately 30\\% over black-box assistance, and QC timing\nfurther enhances count-based outcomes. While WB and QC approaches increase the\ntime required for scoring, start-time assistance is faster and preferred by\nmost participants. Participants overwhelmingly favor transparency, with seven\nout of eight expressing willingness to adopt the system with minor or no\nmodifications. In summary, strategically timed transparent AI assistance\neffectively balances accuracy and clinical efficiency, providing a promising\npathway toward trustworthy AI integration and user acceptance in clinical\nworkflows.",
    "categories": [
      "cs.LG",
      "cs.AI",
      "cs.HC"
    ],
    "published": "2025-10-24T12:23:02Z",
    "authors": [
      "Stefan Kraft",
      "Andreas Theissler",
      "Vera Wienhausen-Wilke",
      "Gjergji Kasneci",
      "Hendrik Lensch"
    ],
    "pdf_url": "http://arxiv.org/pdf/2510.21389v1"
  },
  {
    "id": "2510.23636v1",
    "title": "Flight Delay Prediction via Cross-Modality Adaptation of Large Language\n  Models and Aircraft Trajectory Representation",
    "abstract": "Flight delay prediction has become a key focus in air traffic management, as\ndelays highlight inefficiencies that impact overall network performance. This\npaper presents a lightweight large language model-based multimodal flight delay\nprediction, formulated from the perspective of air traffic controllers\nmonitoring aircraft delay after entering the terminal area. The approach\nintegrates trajectory representations with textual aeronautical information,\nincluding flight information, weather reports, and aerodrome notices, by\nadapting trajectory data into the language modality to capture airspace\nconditions. Experimental results show that the model consistently achieves\nsub-minute prediction error by effectively leveraging contextual information\nrelated to the sources of delay. The framework demonstrates that linguistic\nunderstanding, when combined with cross-modality adaptation of trajectory\ninformation, enhances delay prediction. Moreover, the approach shows\npracticality and scalability for real-world operations, supporting real-time\nupdates that refine predictions upon receiving new operational information.",
    "categories": [
      "cs.LG",
      "cs.AI",
      "cs.CL"
    ],
    "published": "2025-10-24T12:21:27Z",
    "authors": [
      "Thaweerath Phisannupawong",
      "Joshua Julian Damanik",
      "Han-Lim Choi"
    ],
    "pdf_url": "http://arxiv.org/pdf/2510.23636v1"
  },
  {
    "id": "2510.21379v1",
    "title": "Cost-Sensitive Freeze-thaw Bayesian Optimization for Efficient\n  Hyperparameter Tuning",
    "abstract": "In this paper, we address the problem of \\emph{cost-sensitive} hyperparameter\noptimization (HPO) built upon freeze-thaw Bayesian optimization (BO).\nSpecifically, we assume a scenario where users want to early-stop the HPO\nprocess when the expected performance improvement is not satisfactory with\nrespect to the additional computational cost. Motivated by this scenario, we\nintroduce \\emph{utility} in the freeze-thaw framework, a function describing\nthe trade-off between the cost and performance that can be estimated from the\nuser's preference data. This utility function, combined with our novel\nacquisition function and stopping criterion, allows us to dynamically continue\ntraining the configuration that we expect to maximally improve the utility in\nthe future, and also automatically stop the HPO process around the maximum\nutility. Further, we improve the sample efficiency of existing freeze-thaw\nmethods with transfer learning to develop a specialized surrogate model for the\ncost-sensitive HPO problem. We validate our algorithm on established\nmulti-fidelity HPO benchmarks and show that it outperforms all the previous\nfreeze-thaw BO and transfer-BO baselines we consider, while achieving a\nsignificantly better trade-off between the cost and performance. Our code is\npublicly available at https://github.com/db-Lee/CFBO.",
    "categories": [
      "cs.LG"
    ],
    "published": "2025-10-24T12:03:57Z",
    "authors": [
      "Dong Bok Lee",
      "Aoxuan Silvia Zhang",
      "Byungjoo Kim",
      "Junhyeon Park",
      "Steven Adriaensen",
      "Juho Lee",
      "Sung Ju Hwang",
      "Hae Beom Lee"
    ],
    "pdf_url": "http://arxiv.org/pdf/2510.21379v1"
  },
  {
    "id": "2510.21368v1",
    "title": "Efficient Exploration of Chemical Kinetics",
    "abstract": "Estimating reaction rates and chemical stability is fundamental, yet\nefficient methods for large-scale simulations remain out of reach despite\nadvances in modeling and exascale computing. Direct simulation is limited by\nshort timescales; machine-learned potentials require large data sets and\nstruggle with transition state regions essential for reaction rates. Reaction\nnetwork exploration with sufficient accuracy is hampered by the computational\ncost of electronic structure calculations, and even simplifications like\nharmonic transition state theory rely on prohibitively expensive saddle point\nsearches. Surrogate model-based acceleration has been promising but hampered by\noverhead and numerical instability.\n  This dissertation presents a holistic solution, co-designing physical\nrepresentations, statistical models, and systems architecture in the Optimal\nTransport Gaussian Process (OT-GP) framework. Using physics-aware optimal\ntransport metrics, OT-GP creates compact, chemically relevant surrogates of the\npotential energy surface, underpinned by statistically robust sampling.\nAlongside EON software rewrites for long timescale simulations, we introduce\nreinforcement learning approaches for both minimum-mode following (when the\nfinal state is unknown) and nudged elastic band methods (when endpoints are\nspecified). Collectively, these advances establish a representation-first,\nmodular approach to chemical kinetics simulation. Large-scale benchmarks and\nBayesian hierarchical validation demonstrate state-of-the-art performance and\npractical exploration of chemical kinetics, transforming a longstanding\ntheoretical promise into a working engine for discovery.",
    "categories": [
      "physics.chem-ph",
      "cs.LG",
      "cs.SE",
      "physics.atom-ph",
      "physics.data-an"
    ],
    "published": "2025-10-24T11:52:08Z",
    "authors": [
      "Rohit Goswami"
    ],
    "pdf_url": "http://arxiv.org/pdf/2510.21368v1"
  },
  {
    "id": "2510.21367v1",
    "title": "Randomized Neural Network with Adaptive Forward Regularization for\n  Online Task-free Class Incremental Learning",
    "abstract": "Class incremental learning (CIL) requires an agent to learn distinct tasks\nconsecutively with knowledge retention against forgetting. Problems impeding\nthe practical applications of CIL methods are twofold: (1) non-i.i.d batch\nstreams and no boundary prompts to update, known as the harsher online\ntask-free CIL (OTCIL) scenario; (2) CIL methods suffer from memory loss in\nlearning long task streams, as shown in Fig. 1 (a). To achieve efficient\ndecision-making and decrease cumulative regrets during the OTCIL process, a\nrandomized neural network (Randomized NN) with forward regularization (-F) is\nproposed to resist forgetting and enhance learning performance. This general\nframework integrates unsupervised knowledge into recursive convex optimization,\nhas no learning dissipation, and can outperform the canonical ridge style (-R)\nin OTCIL. Based on this framework, we derive the algorithm of the ensemble deep\nrandom vector functional link network (edRVFL) with adjustable forward\nregularization (-kF), where k mediates the intensity of the intervention.\nedRVFL-kF generates one-pass closed-form incremental updates and variable\nlearning rates, effectively avoiding past replay and catastrophic forgetting\nwhile achieving superior performance. Moreover, to curb unstable penalties\ncaused by non-i.i.d and mitigate intractable tuning of -kF in OTCIL, we improve\nit to the plug-and-play edRVFL-kF-Bayes, enabling all hard ks in multiple\nsub-learners to be self-adaptively determined based on Bayesian learning.\nExperiments were conducted on 2 image datasets including 6 metrics, dynamic\nperformance, ablation tests, and compatibility, which distinctly validates the\nefficacy of our OTCIL frameworks with -kF-Bayes and -kF styles.",
    "categories": [
      "cs.LG"
    ],
    "published": "2025-10-24T11:50:13Z",
    "authors": [
      "Junda Wang",
      "Minghui Hu",
      "Ning Li",
      "Abdulaziz Al-Ali",
      "Ponnuthurai Nagaratnam Suganthan"
    ],
    "pdf_url": "http://arxiv.org/pdf/2510.21367v1"
  },
  {
    "id": "2510.21366v1",
    "title": "BADiff: Bandwidth Adaptive Diffusion Model",
    "abstract": "In this work, we propose a novel framework to enable diffusion models to\nadapt their generation quality based on real-time network bandwidth\nconstraints. Traditional diffusion models produce high-fidelity images by\nperforming a fixed number of denoising steps, regardless of downstream\ntransmission limitations. However, in practical cloud-to-device scenarios,\nlimited bandwidth often necessitates heavy compression, leading to loss of fine\ntextures and wasted computation. To address this, we introduce a joint\nend-to-end training strategy where the diffusion model is conditioned on a\ntarget quality level derived from the available bandwidth. During training, the\nmodel learns to adaptively modulate the denoising process, enabling early-stop\nsampling that maintains perceptual quality appropriate to the target\ntransmission condition. Our method requires minimal architectural changes and\nleverages a lightweight quality embedding to guide the denoising trajectory.\nExperimental results demonstrate that our approach significantly improves the\nvisual fidelity of bandwidth-adapted generations compared to naive\nearly-stopping, offering a promising solution for efficient image delivery in\nbandwidth-constrained environments. Code is available at:\nhttps://github.com/xzhang9308/BADiff.",
    "categories": [
      "cs.CV",
      "cs.LG"
    ],
    "published": "2025-10-24T11:50:03Z",
    "authors": [
      "Xi Zhang",
      "Hanwei Zhu",
      "Yan Zhong",
      "Jiamang Wang",
      "Weisi Lin"
    ],
    "pdf_url": "http://arxiv.org/pdf/2510.21366v1"
  },
  {
    "id": "2510.21363v1",
    "title": "FairImagen: Post-Processing for Bias Mitigation in Text-to-Image Models",
    "abstract": "Text-to-image diffusion models, such as Stable Diffusion, have demonstrated\nremarkable capabilities in generating high-quality and diverse images from\nnatural language prompts. However, recent studies reveal that these models\noften replicate and amplify societal biases, particularly along demographic\nattributes like gender and race. In this paper, we introduce FairImagen\n(https://github.com/fuzihaofzh/FairImagen), a post-hoc debiasing framework that\noperates on prompt embeddings to mitigate such biases without retraining or\nmodifying the underlying diffusion model. Our method integrates Fair Principal\nComponent Analysis to project CLIP-based input embeddings into a subspace that\nminimizes group-specific information while preserving semantic content. We\nfurther enhance debiasing effectiveness through empirical noise injection and\npropose a unified cross-demographic projection method that enables simultaneous\ndebiasing across multiple demographic attributes. Extensive experiments across\ngender, race, and intersectional settings demonstrate that FairImagen\nsignificantly improves fairness with a moderate trade-off in image quality and\nprompt fidelity. Our framework outperforms existing post-hoc methods and offers\na simple, scalable, and model-agnostic solution for equitable text-to-image\ngeneration.",
    "categories": [
      "cs.LG",
      "cs.CL",
      "cs.CV"
    ],
    "published": "2025-10-24T11:47:15Z",
    "authors": [
      "Zihao Fu",
      "Ryan Brown",
      "Shun Shao",
      "Kai Rawal",
      "Eoin Delaney",
      "Chris Russell"
    ],
    "pdf_url": "http://arxiv.org/pdf/2510.21363v1"
  },
  {
    "id": "2510.21361v1",
    "title": "Compositional Monte Carlo Tree Diffusion for Extendable Planning",
    "abstract": "Monte Carlo Tree Diffusion (MCTD) integrates diffusion models with structured\ntree search to enable effective trajectory exploration through stepwise\nreasoning. However, MCTD remains fundamentally limited by training trajectory\nlengths. While periodic replanning allows plan concatenation for longer plan\ngeneration, the planning process remains locally confined, as MCTD searches\nwithin individual trajectories without access to global context. We propose\nCompositional Monte Carlo Tree Diffusion (C-MCTD), a framework that elevates\nplanning from individual trajectory optimization to reasoning over complete\nplan compositions. C-MCTD introduces three complementary components: (1) Online\nComposer, which performs globally-aware planning by searching across entire\nplan compositions; (2) Distributed Composer, which reduces search complexity\nthrough parallel exploration from multiple starting points; and (3) Preplan\nComposer, which accelerates inference by leveraging cached plan graphs.",
    "categories": [
      "cs.LG"
    ],
    "published": "2025-10-24T11:42:38Z",
    "authors": [
      "Jaesik Yoon",
      "Hyeonseo Cho",
      "Sungjin Ahn"
    ],
    "pdf_url": "http://arxiv.org/pdf/2510.21361v1"
  },
  {
    "id": "2510.21347v1",
    "title": "Robust Yield Curve Estimation for Mortgage Bonds Using Neural Networks",
    "abstract": "Robust yield curve estimation is crucial in fixed-income markets for accurate\ninstrument pricing, effective risk management, and informed trading strategies.\nTraditional approaches, including the bootstrapping method and parametric\nNelson-Siegel models, often struggle with overfitting or instability issues,\nespecially when underlying bonds are sparse, bond prices are volatile, or\ncontain hard-to-remove noise. In this paper, we propose a neural networkbased\nframework for robust yield curve estimation tailored to small mortgage bond\nmarkets. Our model estimates the yield curve independently for each day and\nintroduces a new loss function to enforce smoothness and stability, addressing\nchallenges associated with limited and noisy data. Empirical results on Swedish\nmortgage bonds demonstrate that our approach delivers more robust and stable\nyield curve estimates compared to existing methods such as\nNelson-Siegel-Svensson (NSS) and Kernel-Ridge (KR). Furthermore, the framework\nallows for the integration of domain-specific constraints, such as alignment\nwith risk-free benchmarks, enabling practitioners to balance the trade-off\nbetween smoothness and accuracy according to their needs.",
    "categories": [
      "cs.LG",
      "q-fin.RM"
    ],
    "published": "2025-10-24T11:24:41Z",
    "authors": [
      "Sina Molavipour",
      "Alireza M. Javid",
      "Cassie Ye",
      "Bj\u00f6rn L\u00f6fdahl",
      "Mikhail Nechaev"
    ],
    "pdf_url": "http://arxiv.org/pdf/2510.21347v1"
  },
  {
    "id": "2510.21345v1",
    "title": "$\u03b1$-LoRA: Effective Fine-Tuning via Base Model Rescaling",
    "abstract": "Fine-tuning has proven to be highly effective in adapting pre-trained models\nto perform better on new desired tasks with minimal data samples. Among the\nmost widely used approaches are reparameterization methods, which update a\ntarget module by augmenting its frozen weight matrix with an additional\ntrainable weight matrix. The most prominent example is Low Rank Adaption\n(LoRA), which gained significant attention in recent years. In this paper, we\nintroduce a new class of reparameterization methods for transfer learning,\ndesigned to enhance the generalization ability of fine-tuned models. We\nestablish the effectiveness of our approach in a high-dimensional binary\nclassification setting using tools from Random Matrix Theory, and further\nvalidate our theoretical findings through more realistic experiments, such as\nfine-tuning LLMs.",
    "categories": [
      "cs.LG",
      "cs.AI",
      "stat.ML"
    ],
    "published": "2025-10-24T11:19:33Z",
    "authors": [
      "Aymane El Firdoussi",
      "El Mahdi Chayti",
      "Mohamed El Amine Seddik",
      "Martin Jaggi"
    ],
    "pdf_url": "http://arxiv.org/pdf/2510.21345v1"
  },
  {
    "id": "2510.21339v2",
    "title": "Multi-turn Training with Basic Human Feedback Helps Little on LLM\n  Reasoning",
    "abstract": "The reasoning capabilities of Large Language Models (LLMs) are typically\ndeveloped through the single-turn reinforcement learning, whereas real-world\napplications often involve multi-turn interactions with human feedback, leading\nto a potential mismatch between training and deployment conditions. In this\nwork, we study whether multi-turn training with human feedback is necessary for\nreasoning tasks. We compare conventional single-turn training with three\nmulti-turn strategies and reach contrary conclusions to previous research. We\nfind that models trained in a single-turn setting generalize effectively to\nboth single- and multi-turn evaluations, while models trained with multi-turn\nstrategies exhibit a significant degradation in single-turn reasoning\nperformance. These results suggest that for tasks with complete information,\nrobust single-turn training remains more effective and reliable, as multi-turn\ntraining with basic feedback provides limited benefits and can even degrade\nreasoning capabilities.",
    "categories": [
      "cs.CL",
      "cs.IT",
      "cs.LG",
      "math.IT"
    ],
    "published": "2025-10-24T11:08:32Z",
    "authors": [
      "Qiang Liu",
      "Wuganjing Song",
      "Zhenzhou Lin",
      "Feifan Chen",
      "Qiaolong Cai",
      "Chen Li",
      "Yongduo Sui"
    ],
    "pdf_url": "http://arxiv.org/pdf/2510.21339v2"
  },
  {
    "id": "2510.21332v1",
    "title": "Weak-to-Strong Generalization under Distribution Shifts",
    "abstract": "As future superhuman models become increasingly complex, accurately\nsupervising their behavior may exceed human capabilities. Recent works have\ndemonstrated that in such scenarios, weak models can effectively supervise\nstrong models, a phenomenon known as weak-to-strong generalization. However, we\nfind that naive weak-to-strong generalization fails under distribution shifts,\noften leading to worse performance of the strong model than its weak\nsupervisors. To address this, we propose RAVEN, a robust weak-to-strong\ngeneralization framework that dynamically learns the optimal combinations of\nweak models in addition to parameters of the strong model. We demonstrate the\neffectiveness of RAVEN on image classification, text classification, and\npreference alignment tasks. RAVEN outperforms alternative baselines by over 30%\non out-of-distribution tasks while matching or surpassing existing methods on\nin-distribution tasks. Moreover, our results show that RAVEN assigns higher\nweights to more accurate weak models, demonstrating its ability to\nautomatically identify trustworthy supervision.",
    "categories": [
      "cs.LG",
      "cs.AI",
      "stat.ML"
    ],
    "published": "2025-10-24T10:46:50Z",
    "authors": [
      "Myeongho Jeon",
      "Jan Sobotka",
      "Suhwan Choi",
      "Maria Brbi\u0107"
    ],
    "pdf_url": "http://arxiv.org/pdf/2510.21332v1"
  },
  {
    "id": "2510.21330v1",
    "title": "SCORENF: Score-based Normalizing Flows for Sampling Unnormalized\n  distributions",
    "abstract": "Unnormalized probability distributions are central to modeling complex\nphysical systems across various scientific domains. Traditional sampling\nmethods, such as Markov Chain Monte Carlo (MCMC), often suffer from slow\nconvergence, critical slowing down, poor mode mixing, and high autocorrelation.\nIn contrast, likelihood-based and adversarial machine learning models, though\neffective, are heavily data-driven, requiring large datasets and often\nencountering mode covering and mode collapse. In this work, we propose ScoreNF,\na score-based learning framework built on the Normalizing Flow (NF)\narchitecture, integrated with an Independent Metropolis-Hastings (IMH) module,\nenabling efficient and unbiased sampling from unnormalized target\ndistributions. We show that ScoreNF maintains high performance even with small\ntraining ensembles, thereby reducing reliance on computationally expensive\nMCMC-generated training data. We also present a method for assessing\nmode-covering and mode-collapse behaviours. We validate our method on synthetic\n2D distributions (MOG-4 and MOG-8) and the high-dimensional $\\phi^4$ lattice\nfield theory distribution, demonstrating its effectiveness for sampling tasks.",
    "categories": [
      "cs.LG",
      "hep-lat",
      "quant-ph"
    ],
    "published": "2025-10-24T10:43:19Z",
    "authors": [
      "Vikas Kanaujia",
      "Vipul Arora"
    ],
    "pdf_url": "http://arxiv.org/pdf/2510.21330v1"
  },
  {
    "id": "2510.21323v1",
    "title": "VL-SAE: Interpreting and Enhancing Vision-Language Alignment with a\n  Unified Concept Set",
    "abstract": "The alignment of vision-language representations endows current\nVision-Language Models (VLMs) with strong multi-modal reasoning capabilities.\nHowever, the interpretability of the alignment component remains uninvestigated\ndue to the difficulty in mapping the semantics of multi-modal representations\ninto a unified concept set. To address this problem, we propose VL-SAE, a\nsparse autoencoder that encodes vision-language representations into its hidden\nactivations. Each neuron in its hidden layer correlates to a concept\nrepresented by semantically similar images and texts, thereby interpreting\nthese representations with a unified concept set. To establish the\nneuron-concept correlation, we encourage semantically similar representations\nto exhibit consistent neuron activations during self-supervised training.\nFirst, to measure the semantic similarity of multi-modal representations, we\nperform their alignment in an explicit form based on cosine similarity. Second,\nwe construct the VL-SAE with a distance-based encoder and two modality-specific\ndecoders to ensure the activation consistency of semantically similar\nrepresentations. Experiments across multiple VLMs (e.g., CLIP, LLaVA)\ndemonstrate the superior capability of VL-SAE in interpreting and enhancing the\nvision-language alignment. For interpretation, the alignment between vision and\nlanguage representations can be understood by comparing their semantics with\nconcepts. For enhancement, the alignment can be strengthened by aligning\nvision-language representations at the concept level, contributing to\nperformance improvements in downstream tasks, including zero-shot image\nclassification and hallucination elimination. Codes are available at\nhttps://github.com/ssfgunner/VL-SAE.",
    "categories": [
      "cs.CV",
      "cs.LG"
    ],
    "published": "2025-10-24T10:29:31Z",
    "authors": [
      "Shufan Shen",
      "Junshu Sun",
      "Qingming Huang",
      "Shuhui Wang"
    ],
    "pdf_url": "http://arxiv.org/pdf/2510.21323v1"
  },
  {
    "id": "2510.21322v1",
    "title": "Leverage Unlearning to Sanitize LLMs",
    "abstract": "Pre-trained large language models (LLMs) are becoming useful for various\ntasks. To improve their performance on certain tasks, it is necessary to\nfine-tune them on specific data corpora (e.g., medical reports, business data).\nThese specialized data corpora may contain sensitive data (e.g., personal or\nconfidential data) that will be memorized by the model and likely to be\nregurgitated during its subsequent use. This memorization of sensitive\ninformation by the model poses a significant privacy or confidentiality issue.\nTo remove this memorization and sanitize the model without requiring costly\nadditional fine-tuning on a secured data corpus, we propose SANI. SANI is an\nunlearning approach to sanitize language models. It relies on both an erasure\nand repair phases that 1) reset certain neurons in the last layers of the model\nto disrupt the memorization of fine-grained information, and then 2) fine-tune\nthe model while avoiding memorizing sensitive information. We comprehensively\nevaluate SANI to sanitize both a model fine-tuned and specialized with medical\ndata by removing directly and indirectly identifiers from the memorization of\nthe model, and a standard pre-trained model by removing specific terms defined\nas confidential information from the model. Results show that with only few\nadditional epochs of unlearning, the model is sanitized and the number of\nregurgitations is drastically reduced. This approach can be particularly useful\nfor hospitals or other industries that have already spent significant resources\ntraining models on large datasets and wish to sanitize them before sharing.",
    "categories": [
      "cs.LG",
      "cs.CL"
    ],
    "published": "2025-10-24T10:28:40Z",
    "authors": [
      "Antoine Boutet",
      "Lucas Magnana"
    ],
    "pdf_url": "http://arxiv.org/pdf/2510.21322v1"
  },
  {
    "id": "2510.21315v1",
    "title": "Seemingly Redundant Modules Enhance Robust Odor Learning in Fruit Flies",
    "abstract": "Biological circuits have evolved to incorporate multiple modules that perform\nsimilar functions. In the fly olfactory circuit, both lateral inhibition (LI)\nand neuronal spike frequency adaptation (SFA) are thought to enhance pattern\nseparation for odor learning. However, it remains unclear whether these\nmechanisms play redundant or distinct roles in this process. In this study, we\npresent a computational model of the fly olfactory circuit to investigate odor\ndiscrimination under varying noise conditions that simulate complex\nenvironments. Our results show that LI primarily enhances odor discrimination\nin low- and medium-noise scenarios, but this benefit diminishes and may reverse\nunder higher-noise conditions. In contrast, SFA consistently improves\ndiscrimination across all noise levels. LI is preferentially engaged in low-\nand medium-noise environments, whereas SFA dominates in high-noise settings.\nWhen combined, these two sparsification mechanisms enable optimal\ndiscrimination performance. This work demonstrates that seemingly redundant\nmodules in biological circuits can, in fact, be essential for achieving optimal\nlearning in complex contexts.",
    "categories": [
      "cs.NE",
      "cs.AI",
      "cs.LG"
    ],
    "published": "2025-10-24T10:18:38Z",
    "authors": [
      "Haiyang Li",
      "Liao Yu",
      "Qiang Yu",
      "Yunliang Zang"
    ],
    "pdf_url": "http://arxiv.org/pdf/2510.21315v1"
  },
  {
    "id": "2510.21314v1",
    "title": "A Convergence Analysis of Adaptive Optimizers under Floating-point\n  Quantization",
    "abstract": "The rapid scaling of large language models (LLMs) has made low-precision\ntraining essential for reducing memory, improving efficiency, and enabling\nlarger models and datasets. Existing convergence theories for adaptive\noptimizers, however, assume all components are exact and neglect hardware-aware\nquantization, leaving open the question of why low-precision training remains\neffective. We introduce the first theoretical framework for analyzing the\nconvergence of adaptive optimizers, including Adam and Muon, under\nfloating-point quantization of gradients, weights, and optimizer states (e.g.,\nmoment estimates). Within this framework, we derive convergence rates on smooth\nnon-convex objectives under standard stochastic gradient assumptions,\nexplicitly characterizing how quantization errors from different components\naffect convergence. We show that both algorithms retain rates close to their\nfull-precision counterparts provided mantissa length scales only\nlogarithmically with the number of iterations. Our analysis further reveals\nthat Adam is highly sensitive to weights and second-moment quantization due to\nits reliance on $\\beta_2 \\to 1$, while Muon requires weaker error control and\nis thus potentially more robust. These results narrow the gap between empirical\nsuccess and theoretical understanding of low-precision training methods.\nNumerical experiments on synthetic and real-world data corroborate our theory.",
    "categories": [
      "cs.LG",
      "cs.AI",
      "stat.ML"
    ],
    "published": "2025-10-24T10:16:23Z",
    "authors": [
      "Xuan Tang",
      "Jichu Li",
      "Difan Zou"
    ],
    "pdf_url": "http://arxiv.org/pdf/2510.21314v1"
  },
  {
    "id": "2510.21312v1",
    "title": "Revisiting Social Welfare in Bandits: UCB is (Nearly) All You Need",
    "abstract": "Regret in stochastic multi-armed bandits traditionally measures the\ndifference between the highest reward and either the arithmetic mean of\naccumulated rewards or the final reward. These conventional metrics often fail\nto address fairness among agents receiving rewards, particularly in settings\nwhere rewards are distributed across a population, such as patients in clinical\ntrials. To address this, a recent body of work has introduced Nash regret,\nwhich evaluates performance via the geometric mean of accumulated rewards,\naligning with the Nash social welfare function known for satisfying fairness\naxioms.\n  To minimize Nash regret, existing approaches require specialized algorithm\ndesigns and strong assumptions, such as multiplicative concentration\ninequalities and bounded, non-negative rewards, making them unsuitable for even\nGaussian reward distributions. We demonstrate that an initial uniform\nexploration phase followed by a standard Upper Confidence Bound (UCB) algorithm\nachieves near-optimal Nash regret, while relying only on additive Hoeffding\nbounds, and naturally extending to sub-Gaussian rewards. Furthermore, we\ngeneralize the algorithm to a broad class of fairness metrics called the\n$p$-mean regret, proving (nearly) optimal regret bounds uniformly across all\n$p$ values. This is in contrast to prior work, which made extremely restrictive\nassumptions on the bandit instances and even then achieved suboptimal regret\nbounds.",
    "categories": [
      "cs.LG"
    ],
    "published": "2025-10-24T10:15:22Z",
    "authors": [
      "Dhruv Sarkar",
      "Nishant Pandey",
      "Sayak Ray Chowdhury"
    ],
    "pdf_url": "http://arxiv.org/pdf/2510.21312v1"
  },
  {
    "id": "2510.21310v1",
    "title": "Efficient semantic uncertainty quantification in language models via\n  diversity-steered sampling",
    "abstract": "Accurately estimating semantic aleatoric and epistemic uncertainties in large\nlanguage models (LLMs) is particularly challenging in free-form question\nanswering (QA), where obtaining stable estimates often requires many expensive\ngenerations. We introduce a diversity-steered sampler that discourages\nsemantically redundant outputs during decoding, covers both autoregressive and\nmasked diffusion paradigms, and yields substantial sample-efficiency gains. The\nkey idea is to inject a continuous semantic-similarity penalty into the model's\nproposal distribution using a natural language inference (NLI) model lightly\nfinetuned on partial prefixes or intermediate diffusion states. We debias\ndownstream uncertainty estimates with importance reweighting and shrink their\nvariance with control variates. Across four QA benchmarks, our method matches\nor surpasses baselines while covering more semantic clusters with the same\nnumber of samples. Being modular and requiring no gradient access to the base\nLLM, the framework promises to serve as a drop-in enhancement for uncertainty\nestimation in risk-sensitive model deployments.",
    "categories": [
      "cs.CL",
      "cs.AI",
      "cs.LG"
    ],
    "published": "2025-10-24T10:06:21Z",
    "authors": [
      "Ji Won Park",
      "Kyunghyun Cho"
    ],
    "pdf_url": "http://arxiv.org/pdf/2510.21310v1"
  },
  {
    "id": "2510.21303v1",
    "title": "Data as a Lever: A Neighbouring Datasets Perspective on Predictive\n  Multiplicity",
    "abstract": "Multiplicity -- the existence of distinct models with comparable performance\n-- has received growing attention in recent years. While prior work has largely\nemphasized modelling choices, the critical role of data in shaping multiplicity\nhas been comparatively overlooked. In this work, we introduce a neighbouring\ndatasets framework to examine the most granular case: the impact of a\nsingle-data-point difference on multiplicity. Our analysis yields a seemingly\ncounterintuitive finding: neighbouring datasets with greater inter-class\ndistribution overlap exhibit lower multiplicity. This reversal of conventional\nexpectations arises from a shared Rashomon parameter, and we substantiate it\nwith rigorous proofs.\n  Building on this foundation, we extend our framework to two practical\ndomains: active learning and data imputation. For each, we establish natural\nextensions of the neighbouring datasets perspective, conduct the first\nsystematic study of multiplicity in existing algorithms, and finally, propose\nnovel multiplicity-aware methods, namely, multiplicity-aware data acquisition\nstrategies for active learning and multiplicity-aware data imputation\ntechniques.",
    "categories": [
      "cs.LG"
    ],
    "published": "2025-10-24T10:01:40Z",
    "authors": [
      "Prakhar Ganesh",
      "Hsiang Hsu",
      "Golnoosh Farnadi"
    ],
    "pdf_url": "http://arxiv.org/pdf/2510.21303v1"
  },
  {
    "id": "2510.23635v1",
    "title": "Help the machine to help you: an evaluation in the wild of egocentric\n  data cleaning via skeptical learning",
    "abstract": "Any digital personal assistant, whether used to support task performance,\nanswer questions, or manage work and daily life, including fitness schedules,\nrequires high-quality annotations to function properly. However, user\nannotations, whether actively produced or inferred from context (e.g., data\nfrom smartphone sensors), are often subject to errors and noise. Previous\nresearch on Skeptical Learning (SKEL) addressed the issue of noisy labels by\ncomparing offline active annotations with passive data, allowing for an\nevaluation of annotation accuracy. However, this evaluation did not include\nconfirmation from end-users, the best judges of their own context. In this\nstudy, we evaluate SKEL's performance in real-world conditions with actual\nusers who can refine the input labels based on their current perspectives and\nneeds. The study involves university students using the iLog mobile application\non their devices over a period of four weeks. The results highlight the\nchallenges of finding the right balance between user effort and data quality,\nas well as the potential benefits of using SKEL, which include reduced\nannotation effort and improved quality of collected data.",
    "categories": [
      "cs.LG",
      "cs.AI"
    ],
    "published": "2025-10-24T10:01:24Z",
    "authors": [
      "Andrea Bontempelli",
      "Matteo Busso",
      "Leonardo Javier Malcotti",
      "Fausto Giunchiglia"
    ],
    "pdf_url": "http://arxiv.org/pdf/2510.23635v1"
  },
  {
    "id": "2510.23634v1",
    "title": "Monotone and Separable Set Functions: Characterizations and Neural\n  Models",
    "abstract": "Motivated by applications for set containment problems, we consider the\nfollowing fundamental problem: can we design set-to-vector functions so that\nthe natural partial order on sets is preserved, namely $S\\subseteq T \\text{ if\nand only if } F(S)\\leq F(T) $. We call functions satisfying this property\nMonotone and Separating (MAS) set functions. % We establish lower and upper\nbounds for the vector dimension necessary to obtain MAS functions, as a\nfunction of the cardinality of the multisets and the underlying ground set. In\nthe important case of an infinite ground set, we show that MAS functions do not\nexist, but provide a model called our which provably enjoys a relaxed MAS\nproperty we name \"weakly MAS\" and is stable in the sense of Holder continuity.\nWe also show that MAS functions can be used to construct universal models that\nare monotone by construction and can approximate all monotone set functions.\nExperimentally, we consider a variety of set containment tasks. The experiments\nshow the benefit of using our our model, in comparison with standard set models\nwhich do not incorporate set containment as an inductive bias. Our code is\navailable in https://github.com/yonatansverdlov/Monotone-Embedding.",
    "categories": [
      "cs.LG",
      "cs.AI"
    ],
    "published": "2025-10-24T09:59:07Z",
    "authors": [
      "Soutrik Sarangi",
      "Yonatan Sverdlov",
      "Nadav Dym",
      "Abir De"
    ],
    "pdf_url": "http://arxiv.org/pdf/2510.23634v1"
  },
  {
    "id": "2510.21300v1",
    "title": "Amortized Variational Inference for Partial-Label Learning: A\n  Probabilistic Approach to Label Disambiguation",
    "abstract": "Real-world data is frequently noisy and ambiguous. In crowdsourcing, for\nexample, human annotators may assign conflicting class labels to the same\ninstances. Partial-label learning (PLL) addresses this challenge by training\nclassifiers when each instance is associated with a set of candidate labels,\nonly one of which is correct. While early PLL methods approximate the true\nlabel posterior, they are often computationally intensive. Recent deep learning\napproaches improve scalability but rely on surrogate losses and heuristic label\nrefinement. We introduce a novel probabilistic framework that directly\napproximates the posterior distribution over true labels using amortized\nvariational inference. Our method employs neural networks to predict\nvariational parameters from input data, enabling efficient inference. This\napproach combines the expressiveness of deep learning with the rigor of\nprobabilistic modeling, while remaining architecture-agnostic. Theoretical\nanalysis and extensive experiments on synthetic and real-world datasets\ndemonstrate that our method achieves state-of-the-art performance in both\naccuracy and efficiency.",
    "categories": [
      "cs.LG",
      "stat.ML"
    ],
    "published": "2025-10-24T09:54:23Z",
    "authors": [
      "Tobias Fuchs",
      "Nadja Klein"
    ],
    "pdf_url": "http://arxiv.org/pdf/2510.21300v1"
  },
  {
    "id": "2510.21296v1",
    "title": "An Evidence-Based Post-Hoc Adjustment Framework for Anomaly Detection\n  Under Data Contamination",
    "abstract": "Unsupervised anomaly detection (AD) methods typically assume clean training\ndata, yet real-world datasets often contain undetected or mislabeled anomalies,\nleading to significant performance degradation. Existing solutions require\naccess to the training pipelines, data or prior knowledge of the proportions of\nanomalies in the data, limiting their real-world applicability. To address this\nchallenge, we propose EPHAD, a simple yet effective test-time adaptation\nframework that updates the outputs of AD models trained on contaminated\ndatasets using evidence gathered at test time. Our approach integrates the\nprior knowledge captured by the AD model trained on contaminated datasets with\nevidence derived from multimodal foundation models like Contrastive\nLanguage-Image Pre-training (CLIP), classical AD methods like the Latent\nOutlier Factor or domain-specific knowledge. We illustrate the intuition behind\nEPHAD using a synthetic toy example and validate its effectiveness through\ncomprehensive experiments across eight visual AD datasets, twenty-six tabular\nAD datasets, and a real-world industrial AD dataset. Additionally, we conduct\nan ablation study to analyse hyperparameter influence and robustness to varying\ncontamination levels, demonstrating the versatility and robustness of EPHAD\nacross diverse AD models and evidence pairs. To ensure reproducibility, our\ncode is publicly available at https://github.com/sukanyapatra1997/EPHAD.",
    "categories": [
      "cs.LG"
    ],
    "published": "2025-10-24T09:45:26Z",
    "authors": [
      "Sukanya Patra",
      "Souhaib Ben Taieb"
    ],
    "pdf_url": "http://arxiv.org/pdf/2510.21296v1"
  },
  {
    "id": "2510.21292v1",
    "title": "Additive Models Explained: A Computational Complexity Approach",
    "abstract": "Generalized Additive Models (GAMs) are commonly considered *interpretable*\nwithin the ML community, as their structure makes the relationship between\ninputs and outputs relatively understandable. Therefore, it may seem natural to\nhypothesize that obtaining meaningful explanations for GAMs could be performed\nefficiently and would not be computationally infeasible. In this work, we\nchallenge this hypothesis by analyzing the *computational complexity* of\ngenerating different explanations for various forms of GAMs across multiple\ncontexts. Our analysis reveals a surprisingly diverse landscape of both\npositive and negative complexity outcomes. Particularly, under standard\ncomplexity assumptions such as P!=NP, we establish several key findings: (1) in\nstark contrast to many other common ML models, the complexity of generating\nexplanations for GAMs is heavily influenced by the structure of the input\nspace; (2) the complexity of explaining GAMs varies significantly with the\ntypes of component models used - but interestingly, these differences only\nemerge under specific input domain settings; (3) significant complexity\ndistinctions appear for obtaining explanations in regression tasks versus\nclassification tasks in GAMs; and (4) expressing complex models like neural\nnetworks additively (e.g., as neural additive models) can make them easier to\nexplain, though interestingly, this benefit appears only for certain\nexplanation methods and input domains. Collectively, these results shed light\non the feasibility of computing diverse explanations for GAMs, offering a\nrigorous theoretical picture of the conditions under which such computations\nare possible or provably hard.",
    "categories": [
      "cs.LG",
      "cs.CC"
    ],
    "published": "2025-10-24T09:40:30Z",
    "authors": [
      "Shahaf Bassan",
      "Michal Moshkovitz",
      "Guy Katz"
    ],
    "pdf_url": "http://arxiv.org/pdf/2510.21292v1"
  },
  {
    "id": "2510.21286v1",
    "title": "Adaptive Data Selection for Multi-Layer Perceptron Training: A\n  Sub-linear Value-Driven Method",
    "abstract": "Data selection is one of the fundamental problems in neural network training,\nparticularly for multi-layer perceptrons (MLPs) where identifying the most\nvaluable training samples from massive, multi-source, and heterogeneous data\nsources under budget constraints poses significant challenges. Existing data\nselection methods, including coreset construction, data Shapley values, and\ninfluence functions, suffer from critical limitations: they oversimplify\nnonlinear transformations, ignore informative intermediate representations in\nhidden layers, or fail to scale to larger MLPs due to high computational\ncomplexity. In response, we propose DVC (Data Value Contribution), a novel\nbudget-aware method for evaluating and selecting data for MLP training that\naccounts for the dynamic evolution of network parameters during training. The\nDVC method decomposes data contribution into Layer Value Contribution (LVC) and\nGlobal Value Contribution (GVC), employing six carefully designed metrics and\ncorresponding efficient algorithms to capture data characteristics across three\ndimensions--quality, relevance, and distributional diversity--at different\ngranularities. DVC integrates these assessments with an Upper Confidence Bound\n(UCB) algorithm for adaptive source selection that balances exploration and\nexploitation. Extensive experiments across six datasets and eight baselines\ndemonstrate that our method consistently outperforms existing approaches under\nvarious budget constraints, achieving superior accuracy and F1 scores. Our\napproach represents the first systematic treatment of hierarchical data\nevaluation for neural networks, providing both theoretical guarantees and\npractical advantages for large-scale machine learning systems.",
    "categories": [
      "cs.LG"
    ],
    "published": "2025-10-24T09:33:19Z",
    "authors": [
      "Xiyang Zhang",
      "Chen Liang",
      "Haoxuan Qiu",
      "Hongzhi Wang"
    ],
    "pdf_url": "http://arxiv.org/pdf/2510.21286v1"
  },
  {
    "id": "2510.21282v1",
    "title": "Sensor-Specific Transformer (PatchTST) Ensembles with Test-Matched\n  Augmentation",
    "abstract": "We present a noise-aware, sensor-specific ensemble approach for robust human\nactivity recognition on the 2nd WEAR Dataset Challenge. Our method leverages\nthe PatchTST transformer architecture, training four independent models-one per\ninertial sensor location-on a tampered training set whose 1-second sliding\nwindows are augmented to mimic the test-time noise. By aligning the train and\ntest data schemas (JSON-encoded 50-sample windows) and applying randomized\njitter, scaling, rotation, and channel dropout, each PatchTST model learns to\ngeneralize across real-world sensor perturbations. At inference, we compute\nsoftmax probabilities from all four sensor models on the Kaggle test set and\naverage them to produce final labels. On the private leaderboard, this pipeline\nachieves a macro-F1 substantially above the baseline, demonstrating that\ntest-matched augmentation combined with transformer-based ensembling is an\neffective strategy for robust HAR under noisy conditions.",
    "categories": [
      "cs.LG"
    ],
    "published": "2025-10-24T09:26:11Z",
    "authors": [
      "Pavankumar Chandankar",
      "Robin Burchard"
    ],
    "pdf_url": "http://arxiv.org/pdf/2510.21282v1"
  },
  {
    "id": "2510.21280v2",
    "title": "WhaleVAD-BPN: Improving Baleen Whale Call Detection with Boundary\n  Proposal Networks and Post-processing Optimisation",
    "abstract": "While recent sound event detection (SED) systems can identify baleen whale\ncalls in marine audio, challenges related to false positive and minority-class\ndetection persist. We propose the boundary proposal network (BPN), which\nextends an existing lightweight SED system. The BPN is inspired by work in\nimage object detection and aims to reduce the number of false positive\ndetections. It achieves this by using intermediate latent representations\ncomputed within the backbone classification model to gate the final output.\nWhen added to an existing SED system, the BPN achieves a 16.8 % absolute\nincrease in precision, as well as 21.3 % and 9.4 % improvements in the F1-score\nfor minority-class d-calls and bp-calls, respectively. We further consider two\napproaches to the selection of post-processing hyperparameters: a\nforward-search and a backward-search. By separately optimising event-level and\nframe-level hyperparameters, these two approaches lead to considerable\nperformance improvements over parameters selected using empirical methods. The\ncomplete WhaleVAD-BPN system achieves a cross-validated development F1-score of\n0.475, which is a 9.8 % absolute improvement over the baseline.",
    "categories": [
      "eess.AS",
      "cs.AI",
      "cs.LG",
      "cs.SD",
      "q-bio.QM"
    ],
    "published": "2025-10-24T09:25:31Z",
    "authors": [
      "Christiaan M. Geldenhuys",
      "G\u00fcnther Tonitz",
      "Thomas R. Niesler"
    ],
    "pdf_url": "http://arxiv.org/pdf/2510.21280v2"
  },
  {
    "id": "2510.21273v2",
    "title": "Enforcing Calibration in Multi-Output Probabilistic Regression with\n  Pre-rank Regularization",
    "abstract": "Probabilistic models must be well calibrated to support reliable\ndecision-making. While calibration in single-output regression is well studied,\ndefining and achieving multivariate calibration in multi-output regression\nremains considerably more challenging. The existing literature on multivariate\ncalibration primarily focuses on diagnostic tools based on pre-rank functions,\nwhich are projections that reduce multivariate prediction-observation pairs to\nunivariate summaries to detect specific types of miscalibration. In this work,\nwe go beyond diagnostics and introduce a general regularization framework to\nenforce multivariate calibration during training for arbitrary pre-rank\nfunctions. This framework encompasses existing approaches such as highest\ndensity region calibration and copula calibration. Our method enforces\ncalibration by penalizing deviations of the projected probability integral\ntransforms (PITs) from the uniform distribution, and can be added as a\nregularization term to the loss function of any probabilistic predictor.\nSpecifically, we propose a regularization loss that jointly enforces both\nmarginal and multivariate pre-rank calibration. We also introduce a new\nPCA-based pre-rank that captures calibration along directions of maximal\nvariance in the predictive distribution, while also enabling dimensionality\nreduction. Across 18 real-world multi-output regression datasets, we show that\nunregularized models are consistently miscalibrated, and that our methods\nsignificantly improve calibration across all pre-rank functions without\nsacrificing predictive accuracy.",
    "categories": [
      "stat.ML",
      "cs.LG"
    ],
    "published": "2025-10-24T09:16:12Z",
    "authors": [
      "Naomi Desobry",
      "Elnura Zhalieva",
      "Souhaib Ben Taieb"
    ],
    "pdf_url": "http://arxiv.org/pdf/2510.21273v2"
  },
  {
    "id": "2510.21271v2",
    "title": "Buffer layers for Test-Time Adaptation",
    "abstract": "In recent advancements in Test Time Adaptation (TTA), most existing\nmethodologies focus on updating normalization layers to adapt to the test\ndomain. However, the reliance on normalization-based adaptation presents key\nchallenges. First, normalization layers such as Batch Normalization (BN) are\nhighly sensitive to small batch sizes, leading to unstable and inaccurate\nstatistics. Moreover, normalization-based adaptation is inherently constrained\nby the structure of the pre-trained model, as it relies on training-time\nstatistics that may not generalize well to unseen domains. These issues limit\nthe effectiveness of normalization-based TTA approaches, especially under\nsignificant domain shift. In this paper, we introduce a novel paradigm based on\nthe concept of a Buffer layer, which addresses the fundamental limitations of\nnormalization layer updates. Unlike existing methods that modify the core\nparameters of the model, our approach preserves the integrity of the\npre-trained backbone, inherently mitigating the risk of catastrophic forgetting\nduring online adaptation. Through comprehensive experimentation, we demonstrate\nthat our approach not only outperforms traditional methods in mitigating domain\nshift and enhancing model robustness, but also exhibits strong resilience to\nforgetting. Furthermore, our Buffer layer is modular and can be seamlessly\nintegrated into nearly all existing TTA frameworks, resulting in consistent\nperformance improvements across various architectures. These findings validate\nthe effectiveness and versatility of the proposed solution in real-world domain\nadaptation scenarios. The code is available at\nhttps://github.com/hyeongyu-kim/Buffer_TTA.",
    "categories": [
      "cs.LG",
      "cs.CV"
    ],
    "published": "2025-10-24T09:12:59Z",
    "authors": [
      "Hyeongyu Kim",
      "Geonhui Han",
      "Dosik Hwang"
    ],
    "pdf_url": "http://arxiv.org/pdf/2510.21271v2"
  },
  {
    "id": "2510.21267v1",
    "title": "Relieving the Over-Aggregating Effect in Graph Transformers",
    "abstract": "Graph attention has demonstrated superior performance in graph learning\ntasks. However, learning from global interactions can be challenging due to the\nlarge number of nodes. In this paper, we discover a new phenomenon termed\nover-aggregating. Over-aggregating arises when a large volume of messages is\naggregated into a single node with less discrimination, leading to the dilution\nof the key messages and potential information loss. To address this, we propose\nWideformer, a plug-and-play method for graph attention. Wideformer divides the\naggregation of all nodes into parallel processes and guides the model to focus\non specific subsets of these processes. The division can limit the input volume\nper aggregation, avoiding message dilution and reducing information loss. The\nguiding step sorts and weights the aggregation outputs, prioritizing the\ninformative messages. Evaluations show that Wideformer can effectively mitigate\nover-aggregating. As a result, the backbone methods can focus on the\ninformative messages, achieving superior performance compared to baseline\nmethods.",
    "categories": [
      "cs.LG"
    ],
    "published": "2025-10-24T08:56:48Z",
    "authors": [
      "Junshu Sun",
      "Wanxing Chang",
      "Chenxue Yang",
      "Qingming Huang",
      "Shuhui Wang"
    ],
    "pdf_url": "http://arxiv.org/pdf/2510.21267v1"
  },
  {
    "id": "2510.21262v1",
    "title": "PINN Balls: Scaling Second-Order Methods for PINNs with Domain\n  Decomposition and Adaptive Sampling",
    "abstract": "Recent advances in Scientific Machine Learning have shown that second-order\nmethods can enhance the training of Physics-Informed Neural Networks (PINNs),\nmaking them a suitable alternative to traditional numerical methods for Partial\nDifferential Equations (PDEs). However, second-order methods induce large\nmemory requirements, making them scale poorly with the model size. In this\npaper, we define a local Mixture of Experts (MoE) combining the\nparameter-efficiency of ensemble models and sparse coding to enable the use of\nsecond-order training. Our model -- \\textsc{PINN Balls} -- also features a\nfully learnable domain decomposition structure, achieved through the use of\nAdversarial Adaptive Sampling (AAS), which adapts the DD to the PDE and its\ndomain. \\textsc{PINN Balls} achieves better accuracy than the state-of-the-art\nin scientific machine learning, while maintaining invaluable scalability\nproperties and drawing from a sound theoretical background.",
    "categories": [
      "cs.LG"
    ],
    "published": "2025-10-24T08:48:44Z",
    "authors": [
      "Andrea Bonfanti",
      "Ismael Medina",
      "Roman List",
      "Bj\u00f6rn Staeves",
      "Roberto Santana",
      "Marco Ellero"
    ],
    "pdf_url": "http://arxiv.org/pdf/2510.21262v1"
  },
  {
    "id": "2510.21252v1",
    "title": "Unified Implementations of Recurrent Neural Networks in Multiple Deep\n  Learning Frameworks",
    "abstract": "Recurrent neural networks (RNNs) are a cornerstone of sequence modeling\nacross various scientific and industrial applications. Owing to their\nversatility, numerous RNN variants have been proposed over the past decade,\naiming to improve the modeling of long-term dependencies and to address\nchallenges such as vanishing and exploding gradients. However, no central\nlibrary is available to test these variations, and reimplementing diverse\narchitectures can be time-consuming and error-prone, limiting reproducibility\nand exploration. Here, we introduce three open-source libraries in Julia and\nPython that centralize numerous recurrent cell implementations and higher-level\nrecurrent architectures. torchrecurrent, RecurrentLayers.jl, and\nLuxRecurrentLayers.jl offer a consistent framework for constructing and\nextending RNN models, providing built-in mechanisms for customization and\nexperimentation. All packages are available under the MIT license and actively\nmaintained on GitHub.",
    "categories": [
      "cs.LG",
      "cs.SE"
    ],
    "published": "2025-10-24T08:35:33Z",
    "authors": [
      "Francesco Martinuzzi"
    ],
    "pdf_url": "http://arxiv.org/pdf/2510.21252v1"
  },
  {
    "id": "2510.21245v1",
    "title": "Convergence of Stochastic Gradient Langevin Dynamics in the Lazy\n  Training Regime",
    "abstract": "Continuous-time models provide important insights into the training dynamics\nof optimization algorithms in deep learning. In this work, we establish a\nnon-asymptotic convergence analysis of stochastic gradient Langevin dynamics\n(SGLD), which is an It\\^o stochastic differential equation (SDE) approximation\nof stochastic gradient descent in continuous time, in the lazy training regime.\nWe show that, under regularity conditions on the Hessian of the loss function,\nSGLD with multiplicative and state-dependent noise (i) yields a non-degenerate\nkernel throughout the training process with high probability, and (ii) achieves\nexponential convergence to the empirical risk minimizer in expectation, and we\nestablish finite-time and finite-width bounds on the optimality gap. We\ncorroborate our theoretical findings with numerical examples in the regression\nsetting.",
    "categories": [
      "cs.LG",
      "math.OC"
    ],
    "published": "2025-10-24T08:28:53Z",
    "authors": [
      "Noah Oberweis",
      "Semih Cayci"
    ],
    "pdf_url": "http://arxiv.org/pdf/2510.21245v1"
  },
  {
    "id": "2510.21232v1",
    "title": "How Hard is it to Confuse a World Model?",
    "abstract": "In reinforcement learning (RL) theory, the concept of most confusing\ninstances is central to establishing regret lower bounds, that is, the minimal\nexploration needed to solve a problem. Given a reference model and its optimal\npolicy, a most confusing instance is the statistically closest alternative\nmodel that makes a suboptimal policy optimal. While this concept is\nwell-studied in multi-armed bandits and ergodic tabular Markov decision\nprocesses, constructing such instances remains an open question in the general\ncase. In this paper, we formalize this problem for neural network world models\nas a constrained optimization: finding a modified model that is statistically\nclose to the reference one, while producing divergent performance between\noptimal and suboptimal policies. We propose an adversarial training procedure\nto solve this problem and conduct an empirical study across world models of\nvarying quality. Our results suggest that the degree of achievable confusion\ncorrelates with uncertainty in the approximate model, which may inform\ntheoretically-grounded exploration strategies for deep model-based RL.",
    "categories": [
      "cs.LG"
    ],
    "published": "2025-10-24T08:08:12Z",
    "authors": [
      "Waris Radji",
      "Odalric-Ambrym Maillard"
    ],
    "pdf_url": "http://arxiv.org/pdf/2510.21232v1"
  },
  {
    "id": "2510.21223v1",
    "title": "Model Merging with Functional Dual Anchors",
    "abstract": "Model merging is an efficient post-training strategy for integrating\nknowledge from multiple finetuned checkpoints of a shared foundation model.\nExisting methods operate in the parameter space, combining task vectors to\nmitigate conflicts, but remain constrained by parameter inconsistencies. We\npropose Functional Dual Anchors (FDAs), a framework that instead models the\ninput-representation space. FDAs are synthetic inputs whose induced gradients\nalign with task vectors, capturing task-specific functional shifts relative to\nthe pretrained model. This perspective bridges joint multi-task training and\npost-hoc merging, offering both robustness and flexibility. We further\nintroduce a principled initialization scheme and show that FDAs are\ncomplementary to parameter-space model merging. Comprehensive experiments\ndemonstrate the effectiveness of FDAs in model merging.",
    "categories": [
      "cs.LG"
    ],
    "published": "2025-10-24T07:54:06Z",
    "authors": [
      "Kexuan Shi",
      "Yandong Wen",
      "Weiyang Liu"
    ],
    "pdf_url": "http://arxiv.org/pdf/2510.21223v1"
  },
  {
    "id": "2510.23633v1",
    "title": "Noise is All You Need: Solving Linear Inverse Problems by Noise\n  Combination Sampling with Diffusion Models",
    "abstract": "Pretrained diffusion models have demonstrated strong capabilities in\nzero-shot inverse problem solving by incorporating observation information into\nthe generation process of the diffusion models. However, this presents an\ninherent dilemma: excessive integration can disrupt the generative process,\nwhile insufficient integration fails to emphasize the constraints imposed by\nthe inverse problem. To address this, we propose \\emph{Noise Combination\nSampling}, a novel method that synthesizes an optimal noise vector from a noise\nsubspace to approximate the measurement score, replacing the noise term in the\nstandard Denoising Diffusion Probabilistic Models process. This enables\nconditional information to be naturally embedded into the generation process\nwithout reliance on step-wise hyperparameter tuning. Our method can be applied\nto a wide range of inverse problem solvers, including image compression, and,\nparticularly when the number of generation steps $T$ is small, achieves\nsuperior performance with negligible computational overhead, significantly\nimproving robustness and stability.",
    "categories": [
      "cs.LG",
      "cs.AI",
      "cs.CV",
      "eess.IV"
    ],
    "published": "2025-10-24T07:46:23Z",
    "authors": [
      "Xun Su",
      "Hiroyuki Kasai"
    ],
    "pdf_url": "http://arxiv.org/pdf/2510.23633v1"
  },
  {
    "id": "2510.21210v1",
    "title": "On the flow matching interpretability",
    "abstract": "Generative models based on flow matching have demonstrated remarkable success\nin various domains, yet they suffer from a fundamental limitation: the lack of\ninterpretability in their intermediate generation steps. In fact these models\nlearn to transform noise into data through a series of vector field updates,\nhowever the meaning of each step remains opaque. We address this problem by\nproposing a general framework constraining each flow step to be sampled from a\nknown physical distribution. Flow trajectories are mapped to (and constrained\nto traverse) the equilibrium states of the simulated physical process. We\nimplement this approach through the 2D Ising model in such a way that flow\nsteps become thermal equilibrium points along a parametric cooling schedule.\n  Our proposed architecture includes an encoder that maps discrete Ising\nconfigurations into a continuous latent space, a flow-matching network that\nperforms temperature-driven diffusion, and a projector that returns to discrete\nIsing states while preserving physical constraints.\n  We validate this framework across multiple lattice sizes, showing that it\npreserves physical fidelity while outperforming Monte Carlo generation in speed\nas the lattice size increases. In contrast with standard flow matching, each\nvector field represents a meaningful stepwise transition in the 2D Ising\nmodel's latent space. This demonstrates that embedding physical semantics into\ngenerative flows transforms opaque neural trajectories into interpretable\nphysical processes.",
    "categories": [
      "cs.LG",
      "math.ST",
      "physics.app-ph",
      "physics.comp-ph",
      "stat.TH",
      "68T07"
    ],
    "published": "2025-10-24T07:26:45Z",
    "authors": [
      "Francesco Pivi",
      "Simone Gazza",
      "Davide Evangelista",
      "Roberto Amadini",
      "Maurizio Gabbrielli"
    ],
    "pdf_url": "http://arxiv.org/pdf/2510.21210v1"
  },
  {
    "id": "2510.21207v1",
    "title": "Adaptive Graph Mixture of Residual Experts: Unsupervised Learning on\n  Diverse Graphs with Heterogeneous Specialization",
    "abstract": "Graph Neural Networks (GNNs) face a fundamental adaptability challenge: their\nfixed message-passing architectures struggle with the immense diversity of\nreal-world graphs, where optimal computational strategies vary by local\nstructure and task. While Mixture-of-Experts (MoE) offers a promising pathway\nto adaptability, existing graph MoE methods remain constrained by their\nreliance on supervised signals and instability when training heterogeneous\nexperts. We introduce ADaMoRE (Adaptive Mixture of Residual Experts), a\nprincipled framework that enables robust, fully unsupervised training of\nheterogeneous MoE on graphs. ADaMoRE employs a backbone-residual expert\narchitecture where foundational encoders provide stability while specialized\nresidual experts capture diverse computational patterns. A structurally-aware\ngating network performs fine-grained node routing. The entire architecture is\ntrained end-to-end using a unified unsupervised objective, which integrates a\nprimary reconstruction task with an information-theoretic diversity regularizer\nto explicitly enforce functional specialization among the experts. Theoretical\nanalysis confirms our design improves data efficiency and training stability.\nExtensive evaluation across 16 benchmarks validates ADaMoRE's state-of-the-art\nperformance in unsupervised node classification and few-shot learning,\nalongside superior generalization, training efficiency, and faster convergence\non diverse graphs and tasks.",
    "categories": [
      "cs.LG"
    ],
    "published": "2025-10-24T07:18:24Z",
    "authors": [
      "Yunlong Chu",
      "Minglai Shao",
      "Zengyi Wo",
      "Bing Hao",
      "Yuhang Liu",
      "Ruijie Wang",
      "Jianxin Li"
    ],
    "pdf_url": "http://arxiv.org/pdf/2510.21207v1"
  },
  {
    "id": "2510.21204v1",
    "title": "Mitra: Mixed Synthetic Priors for Enhancing Tabular Foundation Models",
    "abstract": "Since the seminal work of TabPFN, research on tabular foundation models\n(TFMs) based on in-context learning (ICL) has challenged long-standing\nparadigms in machine learning. Without seeing any real-world data, models\npretrained on purely synthetic datasets generalize remarkably well across\ndiverse datasets, often using only a moderate number of in-context examples.\nThis shifts the focus in tabular machine learning from model architecture\ndesign to the design of synthetic datasets, or, more precisely, to the prior\ndistributions that generate them. Yet the guiding principles for prior design\nremain poorly understood. This work marks the first attempt to address the gap.\nWe systematically investigate and identify key properties of synthetic priors\nthat allow pretrained TFMs to generalize well. Based on these insights, we\nintroduce Mitra, a TFM trained on a curated mixture of synthetic priors\nselected for their diversity, distinctiveness, and performance on real-world\ntabular data. Mitra consistently outperforms state-of-the-art TFMs, such as\nTabPFNv2 and TabICL, across both classification and regression benchmarks, with\nbetter sample efficiency.",
    "categories": [
      "cs.LG"
    ],
    "published": "2025-10-24T07:15:06Z",
    "authors": [
      "Xiyuan Zhang",
      "Danielle C. Maddix",
      "Junming Yin",
      "Nick Erickson",
      "Abdul Fatir Ansari",
      "Boran Han",
      "Shuai Zhang",
      "Leman Akoglu",
      "Christos Faloutsos",
      "Michael W. Mahoney",
      "Cuixiong Hu",
      "Huzefa Rangwala",
      "George Karypis",
      "Bernie Wang"
    ],
    "pdf_url": "http://arxiv.org/pdf/2510.21204v1"
  },
  {
    "id": "2510.21202v1",
    "title": "Online AUC Optimization Based on Second-order Surrogate Loss",
    "abstract": "The Area Under the Curve (AUC) is an important performance metric for\nclassification tasks, particularly in class-imbalanced scenarios. However,\nminimizing the AUC presents significant challenges due to the non-convex and\ndiscontinuous nature of pairwise 0/1 losses, which are difficult to optimize,\nas well as the substantial memory cost of instance-wise storage, which creates\nbottlenecks in large-scale applications. To overcome these challenges, we\npropose a novel second-order surrogate loss based on the pairwise hinge loss,\nand develop an efficient online algorithm. Unlike conventional approaches that\napproximate each individual pairwise 0/1 loss term with an instance-wise\nsurrogate function, our approach introduces a new paradigm that directly\nsubstitutes the entire aggregated pairwise loss with a surrogate loss function\nconstructed from the first- and second-order statistics of the training data.\nTheoretically, while existing online AUC optimization algorithms typically\nachieve an $\\mathcal{O}(\\sqrt{T})$ regret bound, our method attains a tighter\n$\\mathcal{O}(\\ln T)$ bound. Furthermore, we extend the proposed framework to\nnonlinear settings through a kernel-based formulation. Extensive experiments on\nmultiple benchmark datasets demonstrate the superior efficiency and\neffectiveness of the proposed second-order surrogate loss in optimizing online\nAUC performance.",
    "categories": [
      "cs.LG",
      "68T05",
      "I.5.0"
    ],
    "published": "2025-10-24T07:08:22Z",
    "authors": [
      "JunRu Luo",
      "Difei Cheng",
      "Bo Zhang"
    ],
    "pdf_url": "http://arxiv.org/pdf/2510.21202v1"
  },
  {
    "id": "2510.21192v1",
    "title": "Gen-Review: A Large-scale Dataset of AI-Generated (and Human-written)\n  Peer Reviews",
    "abstract": "How does the progressive embracement of Large Language Models (LLMs) affect\nscientific peer reviewing? This multifaceted question is fundamental to the\neffectiveness -- as well as to the integrity -- of the scientific process.\nRecent evidence suggests that LLMs may have already been tacitly used in peer\nreviewing, e.g., at the 2024 International Conference of Learning\nRepresentations (ICLR). Furthermore, some efforts have been undertaken in an\nattempt to explicitly integrate LLMs in peer reviewing by various editorial\nboards (including that of ICLR'25). To fully understand the utility and the\nimplications of LLMs' deployment for scientific reviewing, a comprehensive\nrelevant dataset is strongly desirable. Despite some previous research on this\ntopic, such dataset has been lacking so far. We fill in this gap by presenting\nGenReview, the hitherto largest dataset containing LLM-written reviews. Our\ndataset includes 81K reviews generated for all submissions to the 2018--2025\neditions of the ICLR by providing the LLM with three independent prompts: a\nnegative, a positive, and a neutral one. GenReview is also linked to the\nrespective papers and their original reviews, thereby enabling a broad range of\ninvestigations. To illustrate the value of GenReview, we explore a sample of\nintriguing research questions, namely: if LLMs exhibit bias in reviewing (they\ndo); if LLM-written reviews can be automatically detected (so far, they can);\nif LLMs can rigorously follow reviewing instructions (not always) and whether\nLLM-provided ratings align with decisions on paper acceptance or rejection\n(holds true only for accepted papers). GenReview can be accessed at the\nfollowing link: https://anonymous.4open.science/r/gen_review.",
    "categories": [
      "cs.LG"
    ],
    "published": "2025-10-24T06:54:27Z",
    "authors": [
      "Luca Demetrio",
      "Giovanni Apruzzese",
      "Kathrin Grosse",
      "Pavel Laskov",
      "Emil Lupu",
      "Vera Rimmer",
      "Philine Widmer"
    ],
    "pdf_url": "http://arxiv.org/pdf/2510.21192v1"
  },
  {
    "id": "2510.21188v1",
    "title": "PLAN: Proactive Low-Rank Allocation for Continual Learning",
    "abstract": "Continual learning (CL) requires models to continuously adapt to new tasks\nwithout forgetting past knowledge. In this work, we propose\n\\underline{P}roactive \\underline{L}ow-rank \\underline{A}llocatio\\underline{N}\n(PLAN), a framework that extends Low-Rank Adaptation (LoRA) to enable efficient\nand interference-aware fine-tuning of large pre-trained models in CL settings.\nPLAN proactively manages the allocation of task-specific subspaces by\nintroducing orthogonal basis vectors for each task and optimizing them through\na perturbation-based strategy that minimizes conflicts with previously learned\nparameters. Furthermore, PLAN incorporates a novel selection mechanism that\nidentifies and assigns basis vectors with minimal sensitivity to interference,\nreducing the risk of degrading past knowledge while maintaining efficient\nadaptation to new tasks. Empirical results on standard CL benchmarks\ndemonstrate that PLAN consistently outperforms existing methods, establishing a\nnew state-of-the-art for continual learning with foundation models.",
    "categories": [
      "cs.LG",
      "cs.AI"
    ],
    "published": "2025-10-24T06:37:41Z",
    "authors": [
      "Xiequn Wang",
      "Zhan Zhuang",
      "Yu Zhang"
    ],
    "pdf_url": "http://arxiv.org/pdf/2510.21188v1"
  },
  {
    "id": "2510.21184v1",
    "title": "Reducing the Probability of Undesirable Outputs in Language Models Using\n  Probabilistic Inference",
    "abstract": "Reinforcement learning (RL) has become a predominant technique to align\nlanguage models (LMs) with human preferences or promote outputs which are\ndeemed to be desirable by a given reward function. Standard RL approaches\noptimize average reward, while methods explicitly focused on reducing the\nprobability of undesired outputs typically come at a cost to average-case\nperformance. To improve this tradeoff, we introduce RePULSe, a new training\nmethod that augments the standard RL loss with an additional loss that uses\nlearned proposals to guide sampling low-reward outputs, and then reduces those\noutputs' probability. We run experiments demonstrating that RePULSe produces a\nbetter tradeoff of expected reward versus the probability of undesired outputs\nand is more adversarially robust, compared to standard RL alignment approaches\nand alternatives.",
    "categories": [
      "cs.LG",
      "cs.AI",
      "cs.CL",
      "stat.ML"
    ],
    "published": "2025-10-24T06:23:55Z",
    "authors": [
      "Stephen Zhao",
      "Aidan Li",
      "Rob Brekelmans",
      "Roger Grosse"
    ],
    "pdf_url": "http://arxiv.org/pdf/2510.21184v1"
  },
  {
    "id": "2510.21178v1",
    "title": "Instance-Adaptive Hypothesis Tests with Heterogeneous Agents",
    "abstract": "We study hypothesis testing over a heterogeneous population of strategic\nagents with private information. Any single test applied uniformly across the\npopulation yields statistical error that is sub-optimal relative to the\nperformance of an oracle given access to the private information. We show how\nit is possible to design menus of statistical contracts that pair type-optimal\ntests with payoff structures, inducing agents to self-select according to their\nprivate information. This separating menu elicits agent types and enables the\nprincipal to match the oracle performance even without a priori knowledge of\nthe agent type. Our main result fully characterizes the collection of all\nseparating menus that are instance-adaptive, matching oracle performance for an\narbitrary population of heterogeneous agents. We identify designs where\ninformation elicitation is essentially costless, requiring negligible\nadditional expense relative to a single-test benchmark, while improving\nstatistical performance. Our work establishes a connection between proper\nscoring rules and menu design, showing how the structure of the hypothesis test\nconstrains the elicitable information. Numerical examples illustrate the\ngeometry of separating menus and the improvements they deliver in error\ntrade-offs. Overall, our results connect statistical decision theory with\nmechanism design, demonstrating how heterogeneity and strategic participation\ncan be harnessed to improve efficiency in hypothesis testing.",
    "categories": [
      "cs.GT",
      "cs.LG",
      "econ.EM",
      "math.ST",
      "stat.ME",
      "stat.TH"
    ],
    "published": "2025-10-24T06:00:44Z",
    "authors": [
      "Flora C. Shi",
      "Martin J. Wainwright",
      "Stephen Bates"
    ],
    "pdf_url": "http://arxiv.org/pdf/2510.21178v1"
  },
  {
    "id": "2510.21177v1",
    "title": "Scalable Principal-Agent Contract Design via Gradient-Based Optimization",
    "abstract": "We study a bilevel \\emph{max-max} optimization framework for principal-agent\ncontract design, in which a principal chooses incentives to maximize utility\nwhile anticipating the agent's best response. This problem, central to moral\nhazard and contract theory, underlies applications ranging from market design\nto delegated portfolio management, hedge fund fee structures, and executive\ncompensation. While linear-quadratic models such as Holmstr\"om-Milgrom admit\nclosed-form solutions, realistic environments with nonlinear utilities,\nstochastic dynamics, or high-dimensional actions generally do not.\n  We introduce a generic algorithmic framework that removes this reliance on\nclosed forms. Our method adapts modern machine learning techniques for bilevel\noptimization -- using implicit differentiation with conjugate gradients (CG) --\nto compute hypergradients efficiently through Hessian-vector products, without\never forming or inverting Hessians. In benchmark CARA-Normal (Constant Absolute\nRisk Aversion with Gaussian distribution of uncertainty) environments, the\napproach recovers known analytical optima and converges reliably from random\ninitialization. More broadly, because it is matrix-free, variance-reduced, and\nproblem-agnostic, the framework extends naturally to complex nonlinear\ncontracts where closed-form solutions are unavailable, such as sigmoidal wage\nschedules (logistic pay), relative-performance/tournament compensation with\ncommon shocks, multi-task contracts with vector actions and heterogeneous\nnoise, and CARA-Poisson count models with $\\mathbb{E}[X\\mid a]=e^{a}$. This\nprovides a new computational tool for contract design, enabling systematic\nstudy of models that have remained analytically intractable.",
    "categories": [
      "cs.LG"
    ],
    "published": "2025-10-24T06:00:02Z",
    "authors": [
      "Tomer Galanti",
      "Aarya Bookseller",
      "Korok Ray"
    ],
    "pdf_url": "http://arxiv.org/pdf/2510.21177v1"
  },
  {
    "id": "2510.21176v1",
    "title": "A visual big data system for the prediction of weather-related\n  variables: Jordan-Spain case study",
    "abstract": "The Meteorology is a field where huge amounts of data are generated, mainly\ncollected by sensors at weather stations, where different variables can be\nmeasured. Those data have some particularities such as high volume and\ndimensionality, the frequent existence of missing values in some stations, and\nthe high correlation between collected variables. In this regard, it is crucial\nto make use of Big Data and Data Mining techniques to deal with those data and\nextract useful knowledge from them that can be used, for instance, to predict\nweather phenomena. In this paper, we propose a visual big data system that is\ndesigned to deal with high amounts of weather-related data and lets the user\nanalyze those data to perform predictive tasks over the considered variables\n(temperature and rainfall). The proposed system collects open data and loads\nthem onto a local NoSQL database fusing them at different levels of temporal\nand spatial aggregation in order to perform a predictive analysis using\nunivariate and multivariate approaches as well as forecasting based on training\ndata from neighbor stations in cases with high rates of missing values. The\nsystem has been assessed in terms of usability and predictive performance,\nobtaining an overall normalized mean squared error value of 0.00013, and an\noverall directional symmetry value of nearly 0.84. Our system has been rated\npositively by a group of experts in the area (all aspects of the system except\ngraphic desing were rated 3 or above in a 1-5 scale). The promising preliminary\nresults obtained demonstrate the validity of our system and invite us to keep\nworking on this area.",
    "categories": [
      "cs.LG"
    ],
    "published": "2025-10-24T05:59:08Z",
    "authors": [
      "Shadi Aljawarneh",
      "Juan A. Lara",
      "Muneer Bani Yassein"
    ],
    "pdf_url": "http://arxiv.org/pdf/2510.21176v1"
  },
  {
    "id": "2510.21172v1",
    "title": "A Unified Matrix Factorization Framework for Classical and Robust\n  Clustering",
    "abstract": "This paper presents a unified matrix factorization framework for classical\nand robust clustering. We begin by revisiting the well-known equivalence\nbetween crisp k-means clustering and matrix factorization, following and\nrigorously rederiving an unpublished formulation by Bauckhage. Extending this\nframework, we derive an analogous matrix factorization interpretation for fuzzy\nc-means clustering, which to the best of our knowledge has not been previously\nformalized. These reformulations allow both clustering paradigms to be\nexpressed as optimization problems over factor matrices, thereby enabling\nprincipled extensions to robust variants. To address sensitivity to outliers,\nwe propose robust formulations for both crisp and fuzzy clustering by replacing\nthe Frobenius norm with the l1,2-norm, which penalizes the sum of Euclidean\nnorms across residual columns. We develop alternating minimization algorithms\nfor the standard formulations and IRLS-based algorithms for the robust\ncounterparts. All algorithms are theoretically proven to converge to a local\nminimum.",
    "categories": [
      "cs.LG"
    ],
    "published": "2025-10-24T05:51:48Z",
    "authors": [
      "Angshul Majumdar"
    ],
    "pdf_url": "http://arxiv.org/pdf/2510.21172v1"
  },
  {
    "id": "2510.23632v1",
    "title": "LLMComp: A Language Modeling Paradigm for Error-Bounded Scientific Data\n  Compression",
    "abstract": "The rapid growth of high-resolution scientific simulations and observation\nsystems is generating massive spatiotemporal datasets, making efficient,\nerror-bounded compression increasingly important. Meanwhile, decoder-only large\nlanguage models (LLMs) have demonstrated remarkable capabilities in modeling\ncomplex sequential data. In this paper, we propose LLMCOMP, a novel lossy\ncompression paradigm that leverages decoder-only large LLMs to model scientific\ndata. LLMCOMP first quantizes 3D fields into discrete tokens, arranges them via\nZ-order curves to preserve locality, and applies coverage-guided sampling to\nenhance training efficiency. An autoregressive transformer is then trained with\nspatial-temporal embeddings to model token transitions. During compression, the\nmodel performs top-k prediction, storing only rank indices and fallback\ncorrections to ensure strict error bounds. Experiments on multiple reanalysis\ndatasets show that LLMCOMP consistently outperforms state-of-the-art\ncompressors, achieving up to 30% higher compression ratios under strict error\nbounds. These results highlight the potential of LLMs as general-purpose\ncompressors for high-fidelity scientific data.",
    "categories": [
      "cs.LG",
      "cs.AI"
    ],
    "published": "2025-10-24T05:41:04Z",
    "authors": [
      "Guozhong Li",
      "Muhannad Alhumaidi",
      "Spiros Skiadopoulos",
      "Panos Kalnis"
    ],
    "pdf_url": "http://arxiv.org/pdf/2510.23632v1"
  },
  {
    "id": "2510.21155v1",
    "title": "Towards Straggler-Resilient Split Federated Learning: An Unbalanced\n  Update Approach",
    "abstract": "Split Federated Learning (SFL) enables scalable training on edge devices by\ncombining the parallelism of Federated Learning (FL) with the computational\noffloading of Split Learning (SL). Despite its great success, SFL suffers\nsignificantly from the well-known straggler issue in distributed learning\nsystems. This problem is exacerbated by the dependency between Split Server and\nclients: the Split Server side model update relies on receiving activations\nfrom clients. Such synchronization requirement introduces significant time\nlatency, making straggler a critical bottleneck to the scalability and\nefficiency of the system. To mitigate this problem, we propose MU-SplitFed, a\nstraggler-resilient SFL algorithm in zeroth-order optimization that decouples\ntraining progress from straggler delays via a simple yet effective unbalanced\nupdate mechanism.\n  By enabling the server to perform $\\tau$ local updates per client round,\nMU-SplitFed achieves a convergence rate of $O(\\sqrt{d/(\\tau T)})$ for\nnon-convex objectives, demonstrating a linear speedup of $\\tau$ in\ncommunication rounds. Experiments demonstrate that MU-SplitFed consistently\noutperforms baseline methods with the presence of stragglers and effectively\nmitigates their impact through adaptive tuning of $\\tau$. The code for this\nproject is available at https://github.com/Johnny-Zip/MU-SplitFed.",
    "categories": [
      "cs.DC",
      "cs.AI",
      "cs.LG"
    ],
    "published": "2025-10-24T04:55:27Z",
    "authors": [
      "Dandan Liang",
      "Jianing Zhang",
      "Evan Chen",
      "Zhe Li",
      "Rui Li",
      "Haibo Yang"
    ],
    "pdf_url": "http://arxiv.org/pdf/2510.21155v1"
  },
  {
    "id": "2510.21153v1",
    "title": "Uncertainty-Aware Multi-Objective Reinforcement Learning-Guided\n  Diffusion Models for 3D De Novo Molecular Design",
    "abstract": "Designing de novo 3D molecules with desirable properties remains a\nfundamental challenge in drug discovery and molecular engineering. While\ndiffusion models have demonstrated remarkable capabilities in generating\nhigh-quality 3D molecular structures, they often struggle to effectively\ncontrol complex multi-objective constraints critical for real-world\napplications. In this study, we propose an uncertainty-aware Reinforcement\nLearning (RL) framework to guide the optimization of 3D molecular diffusion\nmodels toward multiple property objectives while enhancing the overall quality\nof the generated molecules. Our method leverages surrogate models with\npredictive uncertainty estimation to dynamically shape reward functions,\nfacilitating balance across multiple optimization objectives. We\ncomprehensively evaluate our framework across three benchmark datasets and\nmultiple diffusion model architectures, consistently outperforming baselines\nfor molecular quality and property optimization. Additionally, Molecular\nDynamics (MD) simulations and ADMET profiling of top generated candidates\nindicate promising drug-like behavior and binding stability, comparable to\nknown Epidermal Growth Factor Receptor (EGFR) inhibitors. Our results\ndemonstrate the strong potential of RL-guided generative diffusion models for\nadvancing automated molecular design.",
    "categories": [
      "cs.LG",
      "cs.AI"
    ],
    "published": "2025-10-24T04:49:23Z",
    "authors": [
      "Lianghong Chen",
      "Dongkyu Eugene Kim",
      "Mike Domaratzki",
      "Pingzhao Hu"
    ],
    "pdf_url": "http://arxiv.org/pdf/2510.21153v1"
  },
  {
    "id": "2510.21141v1",
    "title": "TURBOTEST: Learning When Less is Enough through Early Termination of\n  Internet Speed Tests",
    "abstract": "Internet speed tests are indispensable for users, ISPs, and policymakers, but\ntheir static flooding-based design imposes growing costs: a single high-speed\ntest can transfer hundreds of megabytes, and collectively, platforms like\nOokla, M-Lab, and Fast.com generate petabytes of traffic each month. Reducing\nthis burden requires deciding when a test can be stopped early without\nsacrificing accuracy. We frame this as an optimal stopping problem and show\nthat existing heuristics-static thresholds, BBR pipe-full signals, or\nthroughput stability rules from Fast.com and FastBTS-capture only a narrow\nportion of the achievable accuracy-savings trade-off. This paper introduces\nTURBOTEST, a systematic framework for speed test termination that sits atop\nexisting platforms. The key idea is to decouple throughput prediction (Stage 1)\nfrom test termination (Stage 2): Stage 1 trains a regressor to estimate final\nthroughput from partial measurements, while Stage 2 trains a classifier to\ndecide when sufficient evidence has accumulated to stop. Leveraging richer\ntransport-level features (RTT, retransmissions, congestion window) alongside\nthroughput, TURBOTEST exposes a single tunable parameter for accuracy tolerance\nand includes a fallback mechanism for high-variability cases. Evaluation on\n173,000 M-Lab NDT speed tests (2024-2025) shows that TURBOTEST achieves nearly\n2-4x higher data savings than an approach based on BBR signals while reducing\nmedian error. These results demonstrate that adaptive ML-based termination can\ndeliver accurate, efficient, and deployable speed tests at scale.",
    "categories": [
      "cs.NI",
      "cs.LG"
    ],
    "published": "2025-10-24T04:25:16Z",
    "authors": [
      "Haarika Manda",
      "Manshi Sagar",
      " Yogesh",
      "Kartikay Singh",
      "Cindy Zhao",
      "Tarun Mangla",
      "Phillipa Gill",
      "Elizabeth Belding",
      "Arpit Gupta"
    ],
    "pdf_url": "http://arxiv.org/pdf/2510.21141v1"
  },
  {
    "id": "2510.21135v1",
    "title": "Cloud-Fog-Edge Collaborative Computing for Sequential MIoT Workflow: A\n  Two-Tier DDPG-Based Scheduling Framework",
    "abstract": "The Medical Internet of Things (MIoT) demands stringent end-to-end latency\nguarantees for sequential healthcare workflows deployed over heterogeneous\ncloud-fog-edge infrastructures. Scheduling these sequential workflows to\nminimize makespan is an NP-hard problem. To tackle this challenge, we propose a\nTwo-tier DDPG-based scheduling framework that decomposes the scheduling\ndecision into a hierarchical process: a global controller performs layer\nselection (edge, fog, or cloud), while specialized local controllers handle\nnode assignment within the chosen layer. The primary optimization objective is\nthe minimization of the workflow makespan. Experiments results validate our\napproach, demonstrating increasingly superior performance over baselines as\nworkflow complexity rises. This trend highlights the frameworks ability to\nlearn effective long-term strategies, which is critical for complex,\nlarge-scale MIoT scheduling scenarios.",
    "categories": [
      "cs.LG"
    ],
    "published": "2025-10-24T03:58:31Z",
    "authors": [
      "Yuhao Fu",
      "Yinghao Zhang",
      "Yalin Liu",
      "Bishenghui Tao",
      "Junhong Ruan"
    ],
    "pdf_url": "http://arxiv.org/pdf/2510.21135v1"
  },
  {
    "id": "2510.21131v1",
    "title": "Large Language Models Meet Text-Attributed Graphs: A Survey of\n  Integration Frameworks and Applications",
    "abstract": "Large Language Models (LLMs) have achieved remarkable success in natural\nlanguage processing through strong semantic understanding and generation.\nHowever, their black-box nature limits structured and multi-hop reasoning. In\ncontrast, Text-Attributed Graphs (TAGs) provide explicit relational structures\nenriched with textual context, yet often lack semantic depth. Recent research\nshows that combining LLMs and TAGs yields complementary benefits: enhancing TAG\nrepresentation learning and improving the reasoning and interpretability of\nLLMs. This survey provides the first systematic review of LLM--TAG integration\nfrom an orchestration perspective. We introduce a novel taxonomy covering two\nfundamental directions: LLM for TAG, where LLMs enrich graph-based tasks, and\nTAG for LLM, where structured graphs improve LLM reasoning. We categorize\norchestration strategies into sequential, parallel, and multi-module\nframeworks, and discuss advances in TAG-specific pretraining, prompting, and\nparameter-efficient fine-tuning. Beyond methodology, we summarize empirical\ninsights, curate available datasets, and highlight diverse applications across\nrecommendation systems, biomedical analysis, and knowledge-intensive question\nanswering. Finally, we outline open challenges and promising research\ndirections, aiming to guide future work at the intersection of language and\ngraph learning.",
    "categories": [
      "cs.CL",
      "cs.AI",
      "cs.LG"
    ],
    "published": "2025-10-24T03:53:00Z",
    "authors": [
      "Guangxin Su",
      "Hanchen Wang",
      "Jianwei Wang",
      "Wenjie Zhang",
      "Ying Zhang",
      "Jian Pei"
    ],
    "pdf_url": "http://arxiv.org/pdf/2510.21131v1"
  },
  {
    "id": "2510.23631v1",
    "title": "Beyond Pairwise: Empowering LLM Alignment With Ranked Choice Modeling",
    "abstract": "Alignment of large language models (LLMs) has predominantly relied on\npairwise preference optimization, where annotators select the better of two\nresponses to a prompt. While simple, this approach overlooks the opportunity to\nlearn from richer forms of human feedback, such as multiwise comparisons and\ntop-$k$ rankings. We propose Ranked Choice Preference Optimization (RCPO), a\nunified framework that bridges preference optimization with (ranked) choice\nmodeling via maximum likelihood estimation. The framework is flexible,\nsupporting both utility-based and rank-based choice models. It subsumes several\nexisting pairwise methods (e.g., DPO, SimPO), while providing principled\ntraining objectives for richer feedback formats. We instantiate this framework\nwith two representative ranked choice models (Multinomial Logit and\nMallows-RMJ). Empirical studies on Llama-3-8B-Instruct and Gemma-2-9B-it across\nAlpacaEval 2 and Arena-Hard benchmarks show that RCPO consistently outperforms\ncompetitive baselines. RCPO shows how directly leveraging ranked preference\ndata, combined with the right choice models, yields more effective alignment.\nIt offers a versatile and extensible foundation for incorporating (ranked)\nchoice modeling into LLM training.",
    "categories": [
      "cs.LG",
      "cs.AI",
      "stat.ME",
      "stat.ML"
    ],
    "published": "2025-10-24T03:48:47Z",
    "authors": [
      "Yuxuan Tang",
      "Yifan Feng"
    ],
    "pdf_url": "http://arxiv.org/pdf/2510.23631v1"
  },
  {
    "id": "2510.21129v1",
    "title": "SolarBoost: Distributed Photovoltaic Power Forecasting Amid Time-varying\n  Grid Capacity",
    "abstract": "This paper presents SolarBoost, a novel approach for forecasting power output\nin distributed photovoltaic (DPV) systems. While existing centralized\nphotovoltaic (CPV) methods are able to precisely model output dependencies due\nto uniformity, it is difficult to apply such techniques to DPV systems, as DPVs\nface challenges such as missing grid-level data, temporal shifts in installed\ncapacity, geographic variability, and panel diversity. SolarBoost overcomes\nthese challenges by modeling aggregated power output as a composite of output\nfrom small grids, where each grid output is modeled using a unit output\nfunction multiplied by its capacity. This approach decouples the homogeneous\nunit output function from dynamic capacity for accurate prediction. Efficient\nalgorithms over an upper-bound approximation are proposed to overcome\ncomputational bottlenecks in loss functions. We demonstrate the superiority of\ngrid-level modeling via theoretical analysis and experiments. SolarBoost has\nbeen validated through deployment across various cities in China, significantly\nreducing potential losses and provides valuable insights for the operation of\npower grids. The code for this work is available at\nhttps://github.com/DAMO-DI-ML/SolarBoost.",
    "categories": [
      "cs.LG"
    ],
    "published": "2025-10-24T03:32:14Z",
    "authors": [
      "Linyuan Geng",
      "Linxiao Yang",
      "Xinyue Gu",
      "Liang Sun"
    ],
    "pdf_url": "http://arxiv.org/pdf/2510.21129v1"
  },
  {
    "id": "2510.21128v1",
    "title": "A Unified Approach to Submodular Maximization Under Noise",
    "abstract": "We consider the problem of maximizing a submodular function with access to a\nnoisy value oracle for the function instead of an exact value oracle. Similar\nto prior work, we assume that the noisy oracle is persistent in that multiple\ncalls to the oracle for a specific set always return the same value. In this\nmodel, Hassidim and Singer (2017) design a $(1-1/e)$-approximation algorithm\nfor monotone submodular maximization subject to a cardinality constraint, and\nHuang et al (2022) design a $(1-1/e)/2$-approximation algorithm for monotone\nsubmodular maximization subject to any arbitrary matroid constraint. In this\npaper, we design a meta-algorithm that allows us to take any \"robust\" algorithm\nfor exact submodular maximization as a black box and transform it into an\nalgorithm for the noisy setting while retaining the approximation guarantee. By\nusing the meta-algorithm with the measured continuous greedy algorithm, we\nobtain a $(1-1/e)$-approximation (resp. $1/e$-approximation) for monotone\n(resp. non-monotone) submodular maximization subject to a matroid constraint\nunder noise. Furthermore, by using the meta-algorithm with the double greedy\nalgorithm, we obtain a $1/2$-approximation for unconstrained (non-monotone)\nsubmodular maximization under noise.",
    "categories": [
      "cs.DS",
      "cs.CC",
      "cs.DM",
      "cs.LG"
    ],
    "published": "2025-10-24T03:31:25Z",
    "authors": [
      "Kshipra Bhawalkar",
      "Yang Cai",
      "Zhe Feng",
      "Christopher Liaw",
      "Tao Lin"
    ],
    "pdf_url": "http://arxiv.org/pdf/2510.21128v1"
  },
  {
    "id": "2510.21891v1",
    "title": "Embedding Trust: Semantic Isotropy Predicts Nonfactuality in Long-Form\n  Text Generation",
    "abstract": "To deploy large language models (LLMs) in high-stakes application domains\nthat require substantively accurate responses to open-ended prompts, we need\nreliable, computationally inexpensive methods that assess the trustworthiness\nof long-form responses generated by LLMs. However, existing approaches often\nrely on claim-by-claim fact-checking, which is computationally expensive and\nbrittle in long-form responses to open-ended prompts. In this work, we\nintroduce semantic isotropy -- the degree of uniformity across normalized text\nembeddings on the unit sphere -- and use it to assess the trustworthiness of\nlong-form responses generated by LLMs. To do so, we generate several long-form\nresponses, embed them, and estimate the level of semantic isotropy of these\nresponses as the angular dispersion of the embeddings on the unit sphere. We\nfind that higher semantic isotropy -- that is, greater embedding dispersion --\nreliably signals lower factual consistency across samples. Our approach\nrequires no labeled data, no fine-tuning, and no hyperparameter selection, and\ncan be used with open- or closed-weight embedding models. Across multiple\ndomains, our method consistently outperforms existing approaches in predicting\nnonfactuality in long-form responses using only a handful of samples --\noffering a practical, low-cost approach for integrating trust assessment into\nreal-world LLM workflows.",
    "categories": [
      "cs.CL",
      "cs.AI",
      "cs.LG",
      "stat.ME",
      "stat.ML"
    ],
    "published": "2025-10-24T03:24:57Z",
    "authors": [
      "Dhrupad Bhardwaj",
      "Julia Kempe",
      "Tim G. J. Rudner"
    ],
    "pdf_url": "http://arxiv.org/pdf/2510.21891v1"
  },
  {
    "id": "2510.21113v1",
    "title": "Distributionally Robust Feature Selection",
    "abstract": "We study the problem of selecting limited features to observe such that\nmodels trained on them can perform well simultaneously across multiple\nsubpopulations. This problem has applications in settings where collecting each\nfeature is costly, e.g. requiring adding survey questions or physical sensors,\nand we must be able to use the selected features to create high-quality\ndownstream models for different populations. Our method frames the problem as a\ncontinuous relaxation of traditional variable selection using a noising\nmechanism, without requiring backpropagation through model training processes.\nBy optimizing over the variance of a Bayes-optimal predictor, we develop a\nmodel-agnostic framework that balances overall performance of downstream\nprediction across populations. We validate our approach through experiments on\nboth synthetic datasets and real-world data.",
    "categories": [
      "cs.LG"
    ],
    "published": "2025-10-24T03:03:30Z",
    "authors": [
      "Maitreyi Swaroop",
      "Tamar Krishnamurti",
      "Bryan Wilder"
    ],
    "pdf_url": "http://arxiv.org/pdf/2510.21113v1"
  },
  {
    "id": "2510.23630v1",
    "title": "NUM2EVENT: Interpretable Event Reasoning from Numerical time-series",
    "abstract": "Large language models (LLMs) have recently demonstrated impressive multimodal\nreasoning capabilities, yet their understanding of purely numerical time-series\nsignals remains limited. Existing approaches mainly focus on forecasting or\ntrend description, without uncovering the latent events that drive numerical\nchanges or explaining the reasoning process behind them. In this work, we\nintroduce the task of number-to-event reasoning and decoding, which aims to\ninfer interpretable structured events from numerical inputs, even when current\ntext is unavailable. To address the data scarcity and semantic alignment\nchallenges, we propose a reasoning-aware framework that integrates an\nagent-guided event extractor (AGE), a marked multivariate Hawkes-based\nsynthetic generator (EveDTS), and a two-stage fine-tuning pipeline combining a\ntime-series encoder with a structured decoder. Our model explicitly reasons\nover numerical changes, generates intermediate explanations, and outputs\nstructured event hypotheses. Experiments on multi-domain datasets show that our\nmethod substantially outperforms strong LLM baselines in event-level precision\nand recall. These results suggest a new direction for bridging quantitative\nreasoning and semantic understanding, enabling LLMs to explain and predict\nevents directly from numerical dynamics.",
    "categories": [
      "cs.LG",
      "cs.AI",
      "cs.CL"
    ],
    "published": "2025-10-24T02:57:11Z",
    "authors": [
      "Ninghui Feng",
      "Yiyan Qi"
    ],
    "pdf_url": "http://arxiv.org/pdf/2510.23630v1"
  },
  {
    "id": "2510.21107v1",
    "title": "ESCORT: Efficient Stein-variational and Sliced Consistency-Optimized\n  Temporal Belief Representation for POMDPs",
    "abstract": "In Partially Observable Markov Decision Processes (POMDPs), maintaining and\nupdating belief distributions over possible underlying states provides a\nprincipled way to summarize action-observation history for effective\ndecision-making under uncertainty. As environments grow more realistic, belief\ndistributions develop complexity that standard mathematical models cannot\naccurately capture, creating a fundamental challenge in maintaining\nrepresentational accuracy. Despite advances in deep learning and probabilistic\nmodeling, existing POMDP belief approximation methods fail to accurately\nrepresent complex uncertainty structures such as high-dimensional, multi-modal\nbelief distributions, resulting in estimation errors that lead to suboptimal\nagent behaviors. To address this challenge, we present ESCORT (Efficient\nStein-variational and sliced Consistency-Optimized Representation for Temporal\nbeliefs), a particle-based framework for capturing complex, multi-modal\ndistributions in high-dimensional belief spaces. ESCORT extends SVGD with two\nkey innovations: correlation-aware projections that model dependencies between\nstate dimensions, and temporal consistency constraints that stabilize updates\nwhile preserving correlation structures. This approach retains SVGD's\nattractive-repulsive particle dynamics while enabling accurate modeling of\nintricate correlation patterns. Unlike particle filters prone to degeneracy or\nparametric methods with fixed representational capacity, ESCORT dynamically\nadapts to belief landscape complexity without resampling or restrictive\ndistributional assumptions. We demonstrate ESCORT's effectiveness through\nextensive evaluations on both POMDP domains and synthetic multi-modal\ndistributions of varying dimensionality, where it consistently outperforms\nstate-of-the-art methods in terms of belief approximation accuracy and\ndownstream decision quality.",
    "categories": [
      "cs.LG",
      "cs.AI",
      "cs.RO"
    ],
    "published": "2025-10-24T02:51:33Z",
    "authors": [
      "Yunuo Zhang",
      "Baiting Luo",
      "Ayan Mukhopadhyay",
      "Gabor Karsai",
      "Abhishek Dubey"
    ],
    "pdf_url": "http://arxiv.org/pdf/2510.21107v1"
  },
  {
    "id": "2510.21890v1",
    "title": "The Principles of Diffusion Models",
    "abstract": "This monograph presents the core principles that have guided the development\nof diffusion models, tracing their origins and showing how diverse formulations\narise from shared mathematical ideas. Diffusion modeling starts by defining a\nforward process that gradually corrupts data into noise, linking the data\ndistribution to a simple prior through a continuum of intermediate\ndistributions. The goal is to learn a reverse process that transforms noise\nback into data while recovering the same intermediates. We describe three\ncomplementary views. The variational view, inspired by variational\nautoencoders, sees diffusion as learning to remove noise step by step. The\nscore-based view, rooted in energy-based modeling, learns the gradient of the\nevolving data distribution, indicating how to nudge samples toward more likely\nregions. The flow-based view, related to normalizing flows, treats generation\nas following a smooth path that moves samples from noise to data under a\nlearned velocity field. These perspectives share a common backbone: a\ntime-dependent velocity field whose flow transports a simple prior to the data.\nSampling then amounts to solving a differential equation that evolves noise\ninto data along a continuous trajectory. On this foundation, the monograph\ndiscusses guidance for controllable generation, efficient numerical solvers,\nand diffusion-motivated flow-map models that learn direct mappings between\narbitrary times. It provides a conceptual and mathematically grounded\nunderstanding of diffusion models for readers with basic deep-learning\nknowledge.",
    "categories": [
      "cs.LG",
      "cs.AI",
      "cs.GR"
    ],
    "published": "2025-10-24T02:29:02Z",
    "authors": [
      "Chieh-Hsin Lai",
      "Yang Song",
      "Dongjun Kim",
      "Yuki Mitsufuji",
      "Stefano Ermon"
    ],
    "pdf_url": "http://arxiv.org/pdf/2510.21890v1"
  },
  {
    "id": "2510.23629v1",
    "title": "Chain of Execution Supervision Promotes General Reasoning in Large\n  Language Models",
    "abstract": "Building robust and general reasoning ability is a central goal in the\ndevelopment of large language models (LLMs). Recent efforts increasingly turn\nto code as a rich training source, given its inherent logical structure and\ndiverse reasoning paradigms such as divide-and-conquer, topological ordering,\nand enumeration. However, reasoning in code is often expressed implicitly and\nentangled with syntactic or implementation noise, making direct training on raw\ncode suboptimal.To address this, we introduce TracePile, a large-scale corpus\nof 2.6 million samples that transforms code execution into explicit,\nstep-by-step chain-of-thought-style rationales, which we call Chain of\nExecution (CoE). The corpus spans domains including mathematics, classical\nalgorithms and algorithmic competition, and is enriched with variable-tracing\nquestions and code rewritings to enhance logical granularity and code\ndiversity. We evaluate TracePile using three training setups:\ncontinue-pretraining, instruction tuning after pretraining, and two-stage\nfinetuning. Experiments across four base models (LLaMA 3, LLaMA 3.1, Qwen-2.5,\nand Qwen-2.5 Coder) and 20 benchmarks covering math, code, logic, and\nalgorithms demonstrate consistent improvements. Notably, TracePile boosts\nLLaMA3.1-8B by 7.1\\% on average across nine math datasets and delivers clear\ngains on LiveCodeBench, CRUX, and MMLU under two-stage fine-tuning.",
    "categories": [
      "cs.LG",
      "cs.AI",
      "cs.PL"
    ],
    "published": "2025-10-24T02:21:11Z",
    "authors": [
      "Nuo Chen",
      "Zehua Li",
      "Keqin Bao",
      "Junyang Lin",
      "Dayiheng Liu"
    ],
    "pdf_url": "http://arxiv.org/pdf/2510.23629v1"
  },
  {
    "id": "2510.21889v1",
    "title": "Bridging Prediction and Attribution: Identifying Forward and Backward\n  Causal Influence Ranges Using Assimilative Causal Inference",
    "abstract": "Causal inference identifies cause-and-effect relationships between variables.\nWhile traditional approaches rely on data to reveal causal links, a recently\ndeveloped method, assimilative causal inference (ACI), integrates observations\nwith dynamical models. It utilizes Bayesian data assimilation to trace causes\nback from observed effects by quantifying the reduction in uncertainty. ACI\nadvances the detection of instantaneous causal relationships and the\nintermittent reversal of causal roles over time. Beyond identifying causal\nconnections, an equally important challenge is determining the associated\ncausal influence range (CIR), indicating when causal influences emerged and for\nhow long they persist. In this paper, ACI is employed to develop mathematically\nrigorous formulations of both forward and backward CIRs at each time. The\nforward CIR quantifies the temporal impact of a cause, while the backward CIR\ntraces the onset of triggers for an observed effect, thus characterizing causal\npredictability and attribution of outcomes at each transient phase,\nrespectively. Objective and robust metrics for both CIRs are introduced,\neliminating the need for empirical thresholds. Computationally efficient\napproximation algorithms to compute CIRs are developed, which facilitate the\nuse of closed-form expressions for a broad class of nonlinear dynamical\nsystems. Numerical simulations demonstrate how this forward and backward CIR\nframework provides new possibilities for probing complex dynamical systems. It\nadvances the study of bifurcation-driven and noise-induced tipping points in\nEarth systems, investigates the impact from resolving the interfering variables\nwhen determining the influence ranges, and elucidates atmospheric blocking\nmechanisms in the equatorial region. These results have direct implications for\nscience, policy, and decision-making.",
    "categories": [
      "stat.ML",
      "cs.LG",
      "math.ST",
      "physics.data-an",
      "stat.ME",
      "stat.TH",
      "62F15, 62D20, 62M20, 93E11, 93E14, 60H10"
    ],
    "published": "2025-10-24T02:04:56Z",
    "authors": [
      "Marios Andreou",
      "Nan Chen"
    ],
    "pdf_url": "http://arxiv.org/pdf/2510.21889v1"
  },
  {
    "id": "2510.21091v1",
    "title": "Doubly-Regressing Approach for Subgroup Fairness",
    "abstract": "Algorithmic fairness is a socially crucial topic in real-world applications\nof AI.\n  Among many notions of fairness, subgroup fairness is widely studied when\nmultiple sensitive attributes (e.g., gender, race, age) are present.\n  However, as the number of sensitive attributes grows, the number of subgroups\nincreases accordingly, creating heavy computational burdens and data sparsity\nproblem (subgroups with too small sizes).\n  In this paper, we develop a novel learning algorithm for subgroup fairness\nwhich resolves these issues by focusing on subgroups with sufficient sample\nsizes as well as marginal fairness (fairness for each sensitive attribute).\n  To this end, we formalize a notion of subgroup-subset fairness and introduce\na corresponding distributional fairness measure called the supremum Integral\nProbability Metric (supIPM).\n  Building on this formulation, we propose the Doubly Regressing Adversarial\nlearning for subgroup Fairness (DRAF) algorithm, which reduces a surrogate\nfairness gap for supIPM with much less computation than directly reducing\nsupIPM.\n  Theoretically, we prove that the proposed surrogate fairness gap is an upper\nbound of supIPM.\n  Empirically, we show that the DRAF algorithm outperforms baseline methods in\nbenchmark datasets, specifically when the number of sensitive attributes is\nlarge so that many subgroups are very small.",
    "categories": [
      "stat.ML",
      "cs.LG",
      "stat.ME"
    ],
    "published": "2025-10-24T02:04:44Z",
    "authors": [
      "Kyungseon Lee",
      "Kunwoong Kim",
      "Jihu Lee",
      "Dongyoon Yang",
      "Yongdai Kim"
    ],
    "pdf_url": "http://arxiv.org/pdf/2510.21091v1"
  },
  {
    "id": "2510.21090v1",
    "title": "Self-Rewarding PPO: Aligning Large Language Models with Demonstrations\n  Only",
    "abstract": "Supervised fine-tuning (SFT) has emerged as a crucial method for aligning\nlarge language models (LLMs) with human-annotated demonstrations. However, SFT,\nbeing an off-policy approach similar to behavior cloning, often struggles with\noverfitting and poor out-of-domain generalization, especially in limited-data\nscenarios. To address these limitations, we propose Self-Rewarding PPO, a novel\nfine-tuning method that leverages on-policy techniques to enhance\ngeneralization performance. Our approach combines the strengths of SFT and\nproximal policy optimization (PPO) to achieve more effective alignment from\ndemonstration data. At its core is a reward function designed as the log policy\nratio between the SFT model and the pretrained base model. This function serves\nas an implicit reward signal, using the pretrained policy as a baseline and the\nSFT policy as a target. By doing so, it enables on-policy fine-tuning without\nrelying on human preference annotations. The integration of this self-rewarding\nmechanism with PPO addresses key limitations of SFT, improving generalization,\ndata efficiency, and robustness. Our empirical evaluation across a range of\nnatural language processing tasks demonstrates that Self-Rewarding PPO\nconsistently outperforms traditional SFT methods. The results highlight the\neffectiveness of our approach in aligning LLMs using demonstration data,\nparticularly in scenarios where high-quality annotated data is scarce.",
    "categories": [
      "cs.CL",
      "cs.AI",
      "cs.LG"
    ],
    "published": "2025-10-24T02:02:13Z",
    "authors": [
      "Qingru Zhang",
      "Liang Qiu",
      "Ilgee Hong",
      "Zhenghao Xu",
      "Tianyi Liu",
      "Shiyang Li",
      "Rongzhi Zhang",
      "Zheng Li",
      "Lihong Li",
      "Bing Yin",
      "Chao Zhang",
      "Jianshu Chen",
      "Haoming Jiang",
      "Tuo Zhao"
    ],
    "pdf_url": "http://arxiv.org/pdf/2510.21090v1"
  },
  {
    "id": "2510.21088v1",
    "title": "M-GLC: Motif-Driven Global-Local Context Graphs for Few-shot Molecular\n  Property Prediction",
    "abstract": "Molecular property prediction (MPP) is a cornerstone of drug discovery and\nmaterials science, yet conventional deep learning approaches depend on large\nlabeled datasets that are often unavailable. Few-shot Molecular property\nprediction (FSMPP) addresses this scarcity by incorporating relational\ninductive bias through a context graph that links molecule nodes to property\nnodes, but such molecule-property graphs offer limited structural guidance. We\npropose a comprehensive solution: Motif Driven Global-Local Context Graph for\nfew-shot molecular property prediction, which enriches contextual information\nat both the global and local levels. At the global level, chemically meaningful\nmotif nodes representing shared substructures, such as rings or functional\ngroups, are introduced to form a global tri-partite heterogeneous graph,\nyielding motif-molecule-property connections that capture long-range\ncompositional patterns and enable knowledge transfer among molecules with\ncommon motifs. At the local level, we build a subgraph for each node in the\nmolecule-property pair and encode them separately to concentrate the model's\nattention on the most informative neighboring molecules and motifs. Experiments\non five standard FSMPP benchmarks demonstrate that our framework consistently\noutperforms state-of-the-art methods. These results underscore the\neffectiveness of integrating global motif knowledge with fine-grained local\ncontext to advance robust few-shot molecular property prediction.",
    "categories": [
      "cs.LG",
      "cs.AI"
    ],
    "published": "2025-10-24T02:00:41Z",
    "authors": [
      "Xiangyang Xu",
      "Hongyang Gao"
    ],
    "pdf_url": "http://arxiv.org/pdf/2510.21088v1"
  },
  {
    "id": "2510.21086v1",
    "title": "DictPFL: Efficient and Private Federated Learning on Encrypted Gradients",
    "abstract": "Federated Learning (FL) enables collaborative model training across\ninstitutions without sharing raw data. However, gradient sharing still risks\nprivacy leakage, such as gradient inversion attacks. Homomorphic Encryption\n(HE) can secure aggregation but often incurs prohibitive computational and\ncommunication overhead. Existing HE-based FL methods sit at two extremes:\nencrypting all gradients for full privacy at high cost, or partially encrypting\ngradients to save resources while exposing vulnerabilities. We present DictPFL,\na practical framework that achieves full gradient protection with minimal\noverhead. DictPFL encrypts every transmitted gradient while keeping\nnon-transmitted parameters local, preserving privacy without heavy computation.\nIt introduces two key modules: Decompose-for-Partial-Encrypt (DePE), which\ndecomposes model weights into a static dictionary and an updatable lookup\ntable, only the latter is encrypted and aggregated, while the static dictionary\nremains local and requires neither sharing nor encryption; and\nPrune-for-Minimum-Encrypt (PrME), which applies encryption-aware pruning to\nminimize encrypted parameters via consistent, history-guided masks. Experiments\nshow that DictPFL reduces communication cost by 402-748$\\times$ and accelerates\ntraining by 28-65$\\times$ compared to fully encrypted FL, while outperforming\nstate-of-the-art selective encryption methods by 51-155$\\times$ in overhead and\n4-19$\\times$ in speed. Remarkably, DictPFL's runtime is within 2$\\times$ of\nplaintext FL, demonstrating for the first time, that HE-based private federated\nlearning is practical for real-world deployment. The code is publicly available\nat https://github.com/UCF-ML-Research/DictPFL.",
    "categories": [
      "cs.LG",
      "cs.CR"
    ],
    "published": "2025-10-24T01:58:42Z",
    "authors": [
      "Jiaqi Xue",
      "Mayank Kumar",
      "Yuzhang Shang",
      "Shangqian Gao",
      "Rui Ning",
      "Mengxin Zheng",
      "Xiaoqian Jiang",
      "Qian Lou"
    ],
    "pdf_url": "http://arxiv.org/pdf/2510.21086v1"
  },
  {
    "id": "2510.21081v1",
    "title": "Accelerating Mobile Inference through Fine-Grained CPU-GPU Co-Execution",
    "abstract": "Deploying deep neural networks on mobile devices is increasingly important\nbut remains challenging due to limited computing resources. On the other hand,\ntheir unified memory architecture and narrower gap between CPU and GPU\nperformance provide an opportunity to reduce inference latency by assigning\ntasks to both CPU and GPU. The main obstacles for such collaborative execution\nare the significant synchronization overhead required to combine partial\nresults, and the difficulty of predicting execution times of tasks assigned to\nCPU and GPU (due to the dynamic selection of implementations and parallelism\nlevel). To overcome these obstacles, we propose both a lightweight\nsynchronization mechanism based on OpenCL fine-grained shared virtual memory\n(SVM) and machine learning models to accurately predict execution times.\nNotably, these models capture the performance characteristics of GPU kernels\nand account for their dispatch times. A comprehensive evaluation on four mobile\nplatforms shows that our approach can quickly select CPU-GPU co-execution\nstrategies achieving up to 1.89x speedup for linear layers and 1.75x speedup\nfor convolutional layers (close to the achievable maximum values of 2.01x and\n1.87x, respectively, found by exhaustive grid search on a Pixel~5 smartphone).",
    "categories": [
      "cs.LG",
      "cs.DC",
      "cs.PF"
    ],
    "published": "2025-10-24T01:41:43Z",
    "authors": [
      "Zhuojin Li",
      "Marco Paolieri",
      "Leana Golubchik"
    ],
    "pdf_url": "http://arxiv.org/pdf/2510.21081v1"
  },
  {
    "id": "2510.21078v1",
    "title": "Neural Collapse under Gradient Flow on Shallow ReLU Networks for\n  Orthogonally Separable Data",
    "abstract": "Among many mysteries behind the success of deep networks lies the exceptional\ndiscriminative power of their learned representations as manifested by the\nintriguing Neural Collapse (NC) phenomenon, where simple feature structures\nemerge at the last layer of a trained neural network. Prior works on the\ntheoretical understandings of NC have focused on analyzing the optimization\nlandscape of matrix-factorization-like problems by considering the last-layer\nfeatures as unconstrained free optimization variables and showing that their\nglobal minima exhibit NC. In this paper, we show that gradient flow on a\ntwo-layer ReLU network for classifying orthogonally separable data provably\nexhibits NC, thereby advancing prior results in two ways: First, we relax the\nassumption of unconstrained features, showing the effect of data structure and\nnonlinear activations on NC characterizations. Second, we reveal the role of\nthe implicit bias of the training dynamics in facilitating the emergence of NC.",
    "categories": [
      "cs.LG",
      "math.OC"
    ],
    "published": "2025-10-24T01:36:19Z",
    "authors": [
      "Hancheng Min",
      "Zhihui Zhu",
      "Ren\u00e9 Vidal"
    ],
    "pdf_url": "http://arxiv.org/pdf/2510.21078v1"
  },
  {
    "id": "2510.21888v1",
    "title": "Computational Hardness of Reinforcement Learning with Partial\n  $q^\u03c0$-Realizability",
    "abstract": "This paper investigates the computational complexity of reinforcement\nlearning in a novel linear function approximation regime, termed partial\n$q^{\\pi}$-realizability. In this framework, the objective is to learn an\n$\\epsilon$-optimal policy with respect to a predefined policy set $\\Pi$, under\nthe assumption that all value functions for policies in $\\Pi$ are linearly\nrealizable. The assumptions of this framework are weaker than those in\n$q^{\\pi}$-realizability but stronger than those in $q^*$-realizability,\nproviding a practical model where function approximation naturally arises. We\nprove that learning an $\\epsilon$-optimal policy in this setting is\ncomputationally hard. Specifically, we establish NP-hardness under a\nparameterized greedy policy set (argmax) and show that - unless NP = RP - an\nexponential lower bound (in feature vector dimension) holds when the policy set\ncontains softmax policies, under the Randomized Exponential Time Hypothesis.\nOur hardness results mirror those in $q^*$-realizability and suggest\ncomputational difficulty persists even when $\\Pi$ is expanded beyond the\noptimal policy. To establish this, we reduce from two complexity problems,\n$\\delta$-Max-3SAT and $\\delta$-Max-3SAT(b), to instances of GLinear-$\\kappa$-RL\n(greedy policy) and SLinear-$\\kappa$-RL (softmax policy). Our findings indicate\nthat positive computational results are generally unattainable in partial\n$q^{\\pi}$-realizability, in contrast to $q^{\\pi}$-realizability under a\ngenerative access model.",
    "categories": [
      "cs.AI",
      "cs.CC",
      "cs.LG",
      "68Q17 (Primary) 68T05, 68T42 (Secondary)",
      "F.2.2; I.2.6; I.2.8"
    ],
    "published": "2025-10-24T01:18:49Z",
    "authors": [
      "Shayan Karimi",
      "Xiaoqi Tan"
    ],
    "pdf_url": "http://arxiv.org/pdf/2510.21888v1"
  },
  {
    "id": "2510.21067v1",
    "title": "The Virtues of Brevity: Avoid Overthinking in Parallel Test-Time\n  Reasoning",
    "abstract": "Reasoning models represent a significant advance in LLM capabilities,\nparticularly for complex reasoning tasks such as mathematics and coding.\nPrevious studies confirm that parallel test-time compute-sampling multiple\nsolutions and selecting the best one-can further enhance the predictive\nperformance of LLMs. However, strategies in this area often require complex\nscoring, thus increasing computational cost and complexity. In this work, we\ndemonstrate that the simple and counterintuitive heuristic of selecting the\nshortest solution is highly effective. We posit that the observed effectiveness\nstems from models operating in two distinct regimes: a concise, confident\nconventional regime and a verbose overthinking regime characterized by\nuncertainty, and we show evidence of a critical point where the overthinking\nregime begins to be significant. By selecting the shortest answer, the\nheuristic preferentially samples from the conventional regime. We confirm that\nthis approach is competitive with more complex methods such as self-consistency\nacross two challenging benchmarks while significantly reducing computational\noverhead. The shortest-answer heuristic provides a Pareto improvement over\nself-consistency and applies even to tasks where output equality is not well\ndefined.",
    "categories": [
      "cs.LG"
    ],
    "published": "2025-10-24T00:47:17Z",
    "authors": [
      "Raul Cavalcante Dinardi",
      "Bruno Yamamoto",
      "Anna Helena Reali Costa",
      "Artur Jordao"
    ],
    "pdf_url": "http://arxiv.org/pdf/2510.21067v1"
  },
  {
    "id": "2510.21066v1",
    "title": "Scalable Machine Learning Analysis of Parker Solar Probe Solar Wind Data",
    "abstract": "We present a scalable machine learning framework for analyzing Parker Solar\nProbe (PSP) solar wind data using distributed processing and the\nquantum-inspired Kernel Density Matrices (KDM) method. The PSP dataset\n(2018--2024) exceeds 150 GB, challenging conventional analysis approaches. Our\nframework leverages Dask for large-scale statistical computations and KDM to\nestimate univariate and bivariate distributions of key solar wind parameters,\nincluding solar wind speed, proton density, and proton thermal speed, as well\nas anomaly thresholds for each parameter. We reveal characteristic trends in\nthe inner heliosphere, including increasing solar wind speed with distance from\nthe Sun, decreasing proton density, and the inverse relationship between speed\nand density. Solar wind structures play a critical role in enhancing and\nmediating extreme space weather phenomena and can trigger geomagnetic storms;\nour analyses provide quantitative insights into these processes. This approach\noffers a tractable, interpretable, and distributed methodology for exploring\ncomplex physical datasets and facilitates reproducible analysis of large-scale\nin situ measurements. Processed data products and analysis tools are made\npublicly available to advance future studies of solar wind dynamics and space\nweather forecasting. The code and configuration files used in this study are\npublicly available to support reproducibility.",
    "categories": [
      "cs.LG",
      "astro-ph.SR",
      "physics.space-ph"
    ],
    "published": "2025-10-24T00:41:39Z",
    "authors": [
      "Daniela Martin",
      "Connor O'Brien",
      "Valmir P Moraes Filho",
      "Jinsu Hong",
      "Jasmine R. Kobayashi",
      "Evangelia Samara",
      "Joseph Gallego"
    ],
    "pdf_url": "http://arxiv.org/pdf/2510.21066v1"
  },
  {
    "id": "2510.21060v1",
    "title": "On the Sample Complexity of Differentially Private Policy Optimization",
    "abstract": "Policy optimization (PO) is a cornerstone of modern reinforcement learning\n(RL), with diverse applications spanning robotics, healthcare, and large\nlanguage model training. The increasing deployment of PO in sensitive domains,\nhowever, raises significant privacy concerns. In this paper, we initiate a\ntheoretical study of differentially private policy optimization, focusing\nexplicitly on its sample complexity. We first formalize an appropriate\ndefinition of differential privacy (DP) tailored to PO, addressing the inherent\nchallenges arising from on-policy learning dynamics and the subtlety involved\nin defining the unit of privacy. We then systematically analyze the sample\ncomplexity of widely-used PO algorithms, including policy gradient (PG),\nnatural policy gradient (NPG) and more, under DP constraints and various\nsettings, via a unified framework. Our theoretical results demonstrate that\nprivacy costs can often manifest as lower-order terms in the sample complexity,\nwhile also highlighting subtle yet important observations in private PO\nsettings. These offer valuable practical insights for privacy-preserving PO\nalgorithms.",
    "categories": [
      "cs.LG",
      "cs.AI"
    ],
    "published": "2025-10-24T00:21:38Z",
    "authors": [
      "Yi He",
      "Xingyu Zhou"
    ],
    "pdf_url": "http://arxiv.org/pdf/2510.21060v1"
  },
  {
    "id": "2510.21057v1",
    "title": "Soft Instruction De-escalation Defense",
    "abstract": "Large Language Models (LLMs) are increasingly deployed in agentic systems\nthat interact with an external environment; this makes them susceptible to\nprompt injections when dealing with untrusted data. To overcome this\nlimitation, we propose SIC (Soft Instruction Control)-a simple yet effective\niterative prompt sanitization loop designed for tool-augmented LLM agents. Our\nmethod repeatedly inspects incoming data for instructions that could compromise\nagent behavior. If such content is found, the malicious content is rewritten,\nmasked, or removed, and the result is re-evaluated. The process continues until\nthe input is clean or a maximum iteration limit is reached; if imperative\ninstruction-like content remains, the agent halts to ensure security. By\nallowing multiple passes, our approach acknowledges that individual rewrites\nmay fail but enables the system to catch and correct missed injections in later\nsteps. Although immediately useful, worst-case analysis shows that SIC is not\ninfallible; strong adversary can still get a 15% ASR by embedding\nnon-imperative workflows. This nonetheless raises the bar.",
    "categories": [
      "cs.CR",
      "cs.LG"
    ],
    "published": "2025-10-24T00:04:07Z",
    "authors": [
      "Nils Philipp Walter",
      "Chawin Sitawarin",
      "Jamie Hayes",
      "David Stutz",
      "Ilia Shumailov"
    ],
    "pdf_url": "http://arxiv.org/pdf/2510.21057v1"
  },
  {
    "id": "2510.21055v1",
    "title": "Online Multi-Class Selection with Group Fairness Guarantee",
    "abstract": "We study the online multi-class selection problem with group fairness\nguarantees, where limited resources must be allocated to sequentially arriving\nagents. Our work addresses two key limitations in the existing literature.\nFirst, we introduce a novel lossless rounding scheme that ensures the integral\nalgorithm achieves the same expected performance as any fractional solution.\nSecond, we explicitly address the challenges introduced by agents who belong to\nmultiple classes. To this end, we develop a randomized algorithm based on a\nrelax-and-round framework. The algorithm first computes a fractional solution\nusing a resource reservation approach -- referred to as the set-aside mechanism\n-- to enforce fairness across classes. The subsequent rounding step preserves\nthese fairness guarantees without degrading performance. Additionally, we\npropose a learning-augmented variant that incorporates untrusted\nmachine-learned predictions to better balance fairness and efficiency in\npractical settings.",
    "categories": [
      "cs.LG",
      "cs.DS"
    ],
    "published": "2025-10-23T23:59:49Z",
    "authors": [
      "Faraz Zargari",
      "Hossein Nekouyan",
      "Lyndon Hallett",
      "Bo Sun",
      "Xiaoqi Tan"
    ],
    "pdf_url": "http://arxiv.org/pdf/2510.21055v1"
  },
  {
    "id": "2510.21052v1",
    "title": "Amortized Active Generation of Pareto Sets",
    "abstract": "We introduce active generation of Pareto sets (A-GPS), a new framework for\nonline discrete black-box multi-objective optimization (MOO). A-GPS learns a\ngenerative model of the Pareto set that supports a-posteriori conditioning on\nuser preferences. The method employs a class probability estimator (CPE) to\npredict non-dominance relations and to condition the generative model toward\nhigh-performing regions of the search space. We also show that this\nnon-dominance CPE implicitly estimates the probability of hypervolume\nimprovement (PHVI). To incorporate subjective trade-offs, A-GPS introduces\npreference direction vectors that encode user-specified preferences in\nobjective space. At each iteration, the model is updated using both Pareto\nmembership and alignment with these preference directions, producing an\namortized generative model capable of sampling across the Pareto front without\nretraining. The result is a simple yet powerful approach that achieves\nhigh-quality Pareto set approximations, avoids explicit hypervolume\ncomputation, and flexibly captures user preferences. Empirical results on\nsynthetic benchmarks and protein design tasks demonstrate strong sample\nefficiency and effective preference incorporation.",
    "categories": [
      "cs.LG",
      "stat.ML"
    ],
    "published": "2025-10-23T23:49:23Z",
    "authors": [
      "Daniel M. Steinberg",
      "Asiri Wijesinghe",
      "Rafael Oliveira",
      "Piotr Koniusz",
      "Cheng Soon Ong",
      "Edwin V. Bonilla"
    ],
    "pdf_url": "http://arxiv.org/pdf/2510.21052v1"
  },
  {
    "id": "2510.21049v1",
    "title": "Reasoning's Razor: Reasoning Improves Accuracy but Can Hurt Recall at\n  Critical Operating Points in Safety and Hallucination Detection",
    "abstract": "Reasoning has become a central paradigm for large language models (LLMs),\nconsistently boosting accuracy across diverse benchmarks. Yet its suitability\nfor precision-sensitive tasks remains unclear. We present the first systematic\nstudy of reasoning for classification tasks under strict low false positive\nrate (FPR) regimes. Our analysis covers two tasks--safety detection and\nhallucination detection--evaluated in both fine-tuned and zero-shot settings,\nusing standard LLMs and Large Reasoning Models (LRMs). Our results reveal a\nclear trade-off: Think On (reasoning-augmented) generation improves overall\naccuracy, but underperforms at the low-FPR thresholds essential for practical\nuse. In contrast, Think Off (no reasoning during inference) dominates in these\nprecision-sensitive regimes, with Think On surpassing only when higher FPRs are\nacceptable. In addition, we find token-based scoring substantially outperforms\nself-verbalized confidence for precision-sensitive deployments. Finally, a\nsimple ensemble of the two modes recovers the strengths of each. Taken\ntogether, our findings position reasoning as a double-edged tool: beneficial\nfor average accuracy, but often ill-suited for applications requiring strict\nprecision.",
    "categories": [
      "cs.CL",
      "cs.AI",
      "cs.LG"
    ],
    "published": "2025-10-23T23:23:36Z",
    "authors": [
      "Atoosa Chegini",
      "Hamid Kazemi",
      "Garrett Souza",
      "Maria Safi",
      "Yang Song",
      "Samy Bengio",
      "Sinead Williamson",
      "Mehrdad Farajtabar"
    ],
    "pdf_url": "http://arxiv.org/pdf/2510.21049v1"
  },
  {
    "id": "2510.21048v1",
    "title": "xMem: A CPU-Based Approach for Accurate Estimation of GPU Memory in Deep\n  Learning Training Workloads",
    "abstract": "The global scarcity of GPUs necessitates more sophisticated strategies for\nDeep Learning jobs in shared cluster environments. Accurate estimation of how\nmuch GPU memory a job will require is fundamental to enabling advanced\nscheduling and GPU sharing, which helps prevent out-of-memory (OOM) errors and\nresource underutilization. However, existing estimation methods have\nlimitations. Approaches relying on static analysis or historical data with\nmachine learning often fail to accurately capture runtime dynamics.\nFurthermore, direct GPU analysis consumes scarce resources, and some techniques\nrequire intrusive code modifications. Thus, the key challenge lies in precisely\nestimating dynamic memory requirements, including memory allocator nuances,\nwithout consuming GPU resources and non-intrusive code changes. To address this\nchallenge, we propose xMem, a novel framework that leverages CPU-only dynamic\nanalysis to accurately estimate peak GPU memory requirements a priori. We\nconducted a thorough evaluation of xMem against state-of-the-art solutions\nusing workloads from 25 different models, including architectures like\nConvolutional Neural Networks and Transformers. The analysis of 5209 runs,\nwhich includes ANOVA and Monte Carlo results, highlights xMem's benefits: it\ndecreases the median relative error by 91% and significantly reduces the\nprobability of estimation failure as safe OOM thresholds by 75%, meaning that\nthe estimated value can often be used directly without causing OOM. Ultimately,\nthese improvements lead to a 368% increase in memory conservation potential\nover current solutions.",
    "categories": [
      "cs.PF",
      "cs.DC",
      "cs.LG"
    ],
    "published": "2025-10-23T23:16:27Z",
    "authors": [
      "Jiabo Shi",
      "Dimitrios Pezaros",
      "Yehia Elkhatib"
    ],
    "pdf_url": "http://arxiv.org/pdf/2510.21048v1"
  },
  {
    "id": "2510.21040v1",
    "title": "Efficient Meningioma Tumor Segmentation Using Ensemble Learning",
    "abstract": "Meningiomas represent the most prevalent form of primary brain tumors,\ncomprising nearly one-third of all diagnosed cases. Accurate delineation of\nthese tumors from MRI scans is crucial for guiding treatment strategies, yet\nremains a challenging and time-consuming task in clinical practice. Recent\ndevelopments in deep learning have accelerated progress in automated tumor\nsegmentation; however, many advanced techniques are hindered by heavy\ncomputational demands and long training schedules, making them less accessible\nfor researchers and clinicians working with limited hardware. In this work, we\npropose a novel ensemble-based segmentation approach that combines three\ndistinct architectures: (1) a baseline SegResNet model, (2) an\nattention-augmented SegResNet with concatenative skip connections, and (3) a\ndual-decoder U-Net enhanced with attention-gated skip connections (DDUNet). The\nensemble aims to leverage architectural diversity to improve robustness and\naccuracy while significantly reducing training demands. Each baseline model was\ntrained for only 20 epochs and Evaluated on the BraTS-MEN 2025 dataset. The\nproposed ensemble model achieved competitive performance, with average\nLesion-Wise Dice scores of 77.30%, 76.37% and 73.9% on test dataset for\nEnhancing Tumor (ET), Tumor Core (TC) and Whole Tumor (WT) respectively. These\nresults highlight the effectiveness of ensemble learning for brain tumor\nsegmentation, even under limited hardware constraints. Our proposed method\nprovides a practical and accessible tool for aiding the diagnosis of\nmeningioma, with potential impact in both clinical and research settings.",
    "categories": [
      "eess.IV",
      "cs.CV",
      "cs.LG"
    ],
    "published": "2025-10-23T22:51:22Z",
    "authors": [
      "Mohammad Mahdi Danesh Pajouh",
      "Sara Saeedi"
    ],
    "pdf_url": "http://arxiv.org/pdf/2510.21040v1"
  },
  {
    "id": "2510.21038v2",
    "title": "Elementary, My Dear Watson: Non-Invasive Neural Keyword Spotting in the\n  LibriBrain Dataset",
    "abstract": "Non-invasive brain-computer interfaces (BCIs) are beginning to benefit from\nlarge, public benchmarks. However, current benchmarks target relatively simple,\nfoundational tasks like Speech Detection and Phoneme Classification, while\napplication-ready results on tasks like Brain-to-Text remain elusive. We\npropose Keyword Spotting (KWS) as a practically applicable, privacy-aware\nintermediate task. Using the deep 52-hour, within-subject LibriBrain corpus, we\nprovide standardized train/validation/test splits for reproducible\nbenchmarking, and adopt an evaluation protocol tailored to extreme class\nimbalance. Concretely, we use area under the precision-recall curve (AUPRC) as\na robust evaluation metric, complemented by false alarms per hour (FA/h) at\nfixed recall to capture user-facing trade-offs. To simplify deployment and\nfurther experimentation within the research community, we are releasing an\nupdated version of the pnpl library with word-level dataloaders and Colab-ready\ntutorials. As an initial reference model, we present a compact 1-D Conv/ResNet\nbaseline with focal loss and top-k pooling that is trainable on a single\nconsumer-class GPU. The reference model achieves approximately 13x the\npermutation baseline AUPRC on held-out sessions, demonstrating the viability of\nthe task. Exploratory analyses reveal: (i) predictable within-subject scaling -\nperformance improves log-linearly with more training hours - and (ii) the\nexistence of word-level factors (frequency and duration) that systematically\nmodulate detectability.",
    "categories": [
      "cs.LG"
    ],
    "published": "2025-10-23T22:44:50Z",
    "authors": [
      "Gereon Elvers",
      "Gilad Landau",
      "Oiwi Parker Jones"
    ],
    "pdf_url": "http://arxiv.org/pdf/2510.21038v2"
  },
  {
    "id": "2510.21033v1",
    "title": "Iso-Riemannian Optimization on Learned Data Manifolds",
    "abstract": "High-dimensional data that exhibit an intrinsic low-dimensional structure are\nubiquitous in machine learning and data science. While various approaches allow\nfor learning the corresponding data manifold from finite samples, performing\ndownstream tasks such as optimization directly on these learned manifolds\npresents a significant challenge. This work introduces a principled framework\nfor optimization on learned data manifolds using iso-Riemannian geometry. Our\napproach addresses key limitations of classical Riemannian optimization in this\nsetting, specifically, that the Levi-Civita connection fails to yield\nconstant-speed geodesics, and that geodesic convexity assumptions break down\nunder the learned pullback constructions commonly used in practice. To overcome\nthese challenges, we propose new notions of monotonicity and Lipschitz\ncontinuity tailored to the iso-Riemannian setting and propose iso-Riemannian\ndescent algorithms for which we provide a detailed convergence analysis. We\ndemonstrate the practical effectiveness of those algorithms on both synthetic\nand real datasets, including MNIST under a learned pullback structure. Our\napproach yields interpretable barycentres, improved clustering, and provably\nefficient solutions to inverse problems, even in high-dimensional settings.\nThese results establish that optimization under iso-Riemannian geometry can\novercome distortions inherent to learned manifold mappings.",
    "categories": [
      "math.OC",
      "cs.LG",
      "math.DG",
      "90C26, 68T07, 53Z50"
    ],
    "published": "2025-10-23T22:34:55Z",
    "authors": [
      "Willem Diepeveen",
      "Melanie Weber"
    ],
    "pdf_url": "http://arxiv.org/pdf/2510.21033v1"
  },
  {
    "id": "2510.21027v1",
    "title": "Customizing Open Source LLMs for Quantitative Medication Attribute\n  Extraction across Heterogeneous EHR Systems",
    "abstract": "Harmonizing medication data across Electronic Health Record (EHR) systems is\na persistent barrier to monitoring medications for opioid use disorder (MOUD).\nIn heterogeneous EHR systems, key prescription attributes are scattered across\ndifferently formatted fields and freetext notes. We present a practical\nframework that customizes open source large language models (LLMs), including\nLlama, Qwen, Gemma, and MedGemma, to extract a unified set of MOUD prescription\nattributes (prescription date, drug name, duration, total quantity, daily\nquantity, and refills) from heterogeneous, site specific data and compute a\nstandardized metric of medication coverage, \\emph{MOUD days}, per patient. Our\npipeline processes records directly in a fixed JSON schema, followed by\nlightweight normalization and cross-field consistency checks. We evaluate the\nsystem on prescription level EHR data from five clinics in a national OUD study\n(25{,}605 records from 1{,}257 patients), using a previously annotated\nbenchmark of 10{,}369 records (776 patients) as the ground truth. Performance\nis reported as coverage (share of records with a valid, matchable output) and\nrecord-level exact-match accuracy. Larger models perform best overall:\nQwen2.5-32B achieves \\textbf{93.4\\%} coverage with \\textbf{93.0\\%} exact-match\naccuracy across clinics, and MedGemma-27B attains\n\\textbf{93.1\\%}/\\textbf{92.2\\%}. A brief error review highlights three common\nissues and fixes: imputing missing dosage fields using within-drug norms,\nhandling monthly/weekly injectables (e.g., Vivitrol) by setting duration from\nthe documented schedule, and adding unit checks to prevent mass units (e.g.,\n``250 g'') from being misread as daily counts. By removing brittle,\nsite-specific ETL and supporting local, privacy-preserving deployment, this\napproach enables consistent cross-site analyses of MOUD exposure, adherence,\nand retention in real-world settings.",
    "categories": [
      "cs.AI",
      "cs.LG"
    ],
    "published": "2025-10-23T22:27:10Z",
    "authors": [
      "Zhe Fei",
      "Mehmet Yigit Turali",
      "Shreyas Rajesh",
      "Xinyang Dai",
      "Huyen Pham",
      "Pavan Holur",
      "Yuhui Zhu",
      "Larissa Mooney",
      "Yih-Ing Hser",
      "Vwani Roychowdhury"
    ],
    "pdf_url": "http://arxiv.org/pdf/2510.21027v1"
  },
  {
    "id": "2510.21024v1",
    "title": "JSTprove: Pioneering Verifiable AI for a Trustless Future",
    "abstract": "The integration of machine learning (ML) systems into critical industries\nsuch as healthcare, finance, and cybersecurity has transformed decision-making\nprocesses, but it also brings new challenges around trust, security, and\naccountability. As AI systems become more ubiquitous, ensuring the transparency\nand correctness of AI-driven decisions is crucial, especially when they have\ndirect consequences on privacy, security, or fairness. Verifiable AI, powered\nby Zero-Knowledge Machine Learning (zkML), offers a robust solution to these\nchallenges. zkML enables the verification of AI model inferences without\nexposing sensitive data, providing an essential layer of trust and privacy.\nHowever, traditional zkML systems typically require deep cryptographic\nexpertise, placing them beyond the reach of most ML engineers. In this paper,\nwe introduce JSTprove, a specialized zkML toolkit, built on Polyhedra Network's\nExpander backend, to enable AI developers and ML engineers to generate and\nverify proofs of AI inference. JSTprove provides an end-to-end verifiable AI\ninference pipeline that hides cryptographic complexity behind a simple\ncommand-line interface while exposing auditable artifacts for reproducibility.\nWe present the design, innovations, and real-world use cases of JSTprove as\nwell as our blueprints and tooling to encourage community review and extension.\nJSTprove therefore serves both as a usable zkML product for current engineering\nneeds and as a reproducible foundation for future research and production\ndeployments of verifiable AI.",
    "categories": [
      "cs.CR",
      "cs.AI",
      "cs.DC",
      "cs.LG"
    ],
    "published": "2025-10-23T22:22:38Z",
    "authors": [
      "Jonathan Gold",
      "Tristan Freiberg",
      "Haruna Isah",
      "Shirin Shahabi"
    ],
    "pdf_url": "http://arxiv.org/pdf/2510.21024v1"
  },
  {
    "id": "2510.21023v1",
    "title": "Physically consistent and uncertainty-aware learning of spatiotemporal\n  dynamics",
    "abstract": "Accurate long-term forecasting of spatiotemporal dynamics remains a\nfundamental challenge across scientific and engineering domains. Existing\nmachine learning methods often neglect governing physical laws and fail to\nquantify inherent uncertainties in spatiotemporal predictions. To address these\nchallenges, we introduce a physics-consistent neural operator (PCNO) that\nenforces physical constraints by projecting surrogate model outputs onto\nfunction spaces satisfying predefined laws. A physics-consistent projection\nlayer within PCNO efficiently computes mass and momentum conservation in\nFourier space. Building upon deterministic predictions, we further propose a\ndiffusion model-enhanced PCNO (DiffPCNO), which leverages a consistency model\nto quantify and mitigate uncertainties, thereby improving the accuracy and\nreliability of forecasts. PCNO and DiffPCNO achieve high-fidelity\nspatiotemporal predictions while preserving physical consistency and\nuncertainty across diverse systems and spatial resolutions, ranging from\nturbulent flow modeling to real-world flood/atmospheric forecasting. Our\ntwo-stage framework provides a robust and versatile approach for accurate,\nphysically grounded, and uncertainty-aware spatiotemporal forecasting.",
    "categories": [
      "cs.LG",
      "cs.AI",
      "physics.comp-ph"
    ],
    "published": "2025-10-23T22:17:21Z",
    "authors": [
      "Qingsong Xu",
      "Jonathan L Bamber",
      "Nils Thuerey",
      "Niklas Boers",
      "Paul Bates",
      "Gustau Camps-Valls",
      "Yilei Shi",
      "Xiao Xiang Zhu"
    ],
    "pdf_url": "http://arxiv.org/pdf/2510.21023v1"
  },
  {
    "id": "2510.21022v1",
    "title": "CIPHER: Scalable Time Series Analysis for Physical Sciences with\n  Application to Solar Wind Phenomena",
    "abstract": "Labeling or classifying time series is a persistent challenge in the physical\nsciences, where expert annotations are scarce, costly, and often inconsistent.\nYet robust labeling is essential to enable machine learning models for\nunderstanding, prediction, and forecasting. We present the \\textit{Clustering\nand Indexation Pipeline with Human Evaluation for Recognition} (CIPHER), a\nframework designed to accelerate large-scale labeling of complex time series in\nphysics. CIPHER integrates \\textit{indexable Symbolic Aggregate approXimation}\n(iSAX) for interpretable compression and indexing, density-based clustering\n(HDBSCAN) to group recurring phenomena, and a human-in-the-loop step for\nefficient expert validation. Representative samples are labeled by domain\nscientists, and these annotations are propagated across clusters to yield\nsystematic, scalable classifications. We evaluate CIPHER on the task of\nclassifying solar wind phenomena in OMNI data, a central challenge in space\nweather research, showing that the framework recovers meaningful phenomena such\nas coronal mass ejections and stream interaction regions. Beyond this case\nstudy, CIPHER highlights a general strategy for combining symbolic\nrepresentations, unsupervised learning, and expert knowledge to address label\nscarcity in time series across the physical sciences. The code and\nconfiguration files used in this study are publicly available to support\nreproducibility.",
    "categories": [
      "cs.LG",
      "astro-ph.SR"
    ],
    "published": "2025-10-23T22:11:29Z",
    "authors": [
      "Jasmine R. Kobayashi",
      "Daniela Martin",
      "Valmir P Moraes Filho",
      "Connor O'Brien",
      "Jinsu Hong",
      "Sudeshna Boro Saikia",
      "Hala Lamdouar",
      "Nathan D. Miles",
      "Marcella Scoczynski",
      "Mavis Stone",
      "Sairam Sundaresan",
      "Anna Jungbluth",
      "Andr\u00e9s Mu\u00f1oz-Jaramillo",
      "Evangelia Samara",
      "Joseph Gallego"
    ],
    "pdf_url": "http://arxiv.org/pdf/2510.21022v1"
  },
  {
    "id": "2510.21020v1",
    "title": "From Information to Generative Exponent: Learning Rate Induces Phase\n  Transitions in SGD",
    "abstract": "To understand feature learning dynamics in neural networks, recent\ntheoretical works have focused on gradient-based learning of Gaussian\nsingle-index models, where the label is a nonlinear function of a latent\none-dimensional projection of the input. While the sample complexity of online\nSGD is determined by the information exponent of the link function, recent\nworks improved this by performing multiple gradient steps on the same sample\nwith different learning rates -- yielding a non-correlational update rule --\nand instead are limited by the (potentially much smaller) generative exponent.\nHowever, this picture is only valid when these learning rates are sufficiently\nlarge. In this paper, we characterize the relationship between learning rate(s)\nand sample complexity for a broad class of gradient-based algorithms that\nencapsulates both correlational and non-correlational updates. We demonstrate\nthat, in certain cases, there is a phase transition from an \"information\nexponent regime\" with small learning rate to a \"generative exponent regime\"\nwith large learning rate. Our framework covers prior analyses of one-pass SGD\nand SGD with batch reuse, while also introducing a new layer-wise training\nalgorithm that leverages a two-timescales approach (via different learning\nrates for each layer) to go beyond correlational queries without reusing\nsamples or modifying the loss from squared error. Our theoretical study\ndemonstrates that the choice of learning rate is as important as the design of\nthe algorithm in achieving statistical and computational efficiency.",
    "categories": [
      "cs.LG",
      "stat.ML"
    ],
    "published": "2025-10-23T22:03:53Z",
    "authors": [
      "Konstantinos Christopher Tsiolis",
      "Alireza Mousavi-Hosseini",
      "Murat A. Erdogdu"
    ],
    "pdf_url": "http://arxiv.org/pdf/2510.21020v1"
  },
  {
    "id": "2510.21019v1",
    "title": "More Than Memory Savings: Zeroth-Order Optimization Mitigates Forgetting\n  in Continual Learning",
    "abstract": "Zeroth-order (ZO) optimization has gained attention as a memory-efficient\nalternative to first-order (FO) methods, particularly in settings where\ngradient computation is expensive or even impractical. Beyond its memory\nefficiency, in this work, we investigate ZO optimization for continual learning\n(CL) as a novel approach to address the plasticity-stability-efficiency\ntrilemma. Through theoretical analysis and empirical evidence, we show that ZO\noptimization naturally leads to flatter loss landscapes, which in turn reduce\nforgetting in CL. However, this stability comes at a cost of plasticity: due to\nits imprecise gradient estimates and slower convergence, ZO optimization tends\nto be less effective than FO in acquiring new task-specific knowledge,\nparticularly under constrained training budgets. To better understand this\ntrade-off, we conduct a holistic evaluation of ZO optimization applied to\nvarious existing CL methods. Our findings reveal that ZO optimization enhances\nstability but often undermines plasticity, particularly when used with\nlearnable classifiers. Motivated by this insight, we propose ZO-FC, a simple\nbut effective approach that applies ZO optimization to a single adapter-based\nPEFT module with FO optimized classifier. This design leverages the stability\nbenefits of ZO while preserving the adaptability of FO updates with negligible\nmemory overhead. Experiments demonstrate that ZO-FC achieves an effective\nbalance between stability and plasticity, offering a practical and\nmemory-efficient solution for on-device CL.",
    "categories": [
      "cs.LG",
      "cs.CV"
    ],
    "published": "2025-10-23T21:54:00Z",
    "authors": [
      "Wanhao Yu",
      "Zheng Wang",
      "Shuteng Niu",
      "Sen Lin",
      "Li Yang"
    ],
    "pdf_url": "http://arxiv.org/pdf/2510.21019v1"
  },
  {
    "id": "2510.21017v1",
    "title": "Fair Representation Learning with Controllable High Confidence\n  Guarantees via Adversarial Inference",
    "abstract": "Representation learning is increasingly applied to generate representations\nthat generalize well across multiple downstream tasks. Ensuring fairness\nguarantees in representation learning is crucial to prevent unfairness toward\nspecific demographic groups in downstream tasks. In this work, we formally\nintroduce the task of learning representations that achieve high-confidence\nfairness. We aim to guarantee that demographic disparity in every downstream\nprediction remains bounded by a *user-defined* error threshold $\\epsilon$, with\n*controllable* high probability. To this end, we propose the ***F**air\n**R**epresentation learning with high-confidence **G**uarantees (FRG)*\nframework, which provides these high-confidence fairness guarantees by\nleveraging an optimized adversarial model. We empirically evaluate FRG on three\nreal-world datasets, comparing its performance to six state-of-the-art fair\nrepresentation learning methods. Our results demonstrate that FRG consistently\nbounds unfairness across a range of downstream models and tasks.",
    "categories": [
      "cs.LG"
    ],
    "published": "2025-10-23T21:50:46Z",
    "authors": [
      "Yuhong Luo",
      "Austin Hoag",
      "Xintong Wang",
      "Philip S. Thomas",
      "Przemyslaw A. Grabowicz"
    ],
    "pdf_url": "http://arxiv.org/pdf/2510.21017v1"
  },
  {
    "id": "2510.21012v1",
    "title": "Graph Neural Regularizers for PDE Inverse Problems",
    "abstract": "We present a framework for solving a broad class of ill-posed inverse\nproblems governed by partial differential equations (PDEs), where the target\ncoefficients of the forward operator are recovered through an iterative\nregularization scheme that alternates between FEM-based inversion and learned\ngraph neural regularization. The forward problem is numerically solved using\nthe finite element method (FEM), enabling applicability to a wide range of\ngeometries and PDEs. By leveraging the graph structure inherent to FEM\ndiscretizations, we employ physics-inspired graph neural networks as learned\nregularizers, providing a robust, interpretable, and generalizable alternative\nto standard approaches. Numerical experiments demonstrate that our framework\noutperforms classical regularization techniques and achieves accurate\nreconstructions even in highly ill-posed scenarios.",
    "categories": [
      "math.NA",
      "cs.LG",
      "cs.NA"
    ],
    "published": "2025-10-23T21:43:25Z",
    "authors": [
      "William Lauga",
      "James Rowbottom",
      "Alexander Denker",
      "\u017deljko Kereta",
      "Moshe Eliasof",
      "Carola-Bibiane Sch\u00f6nlieb"
    ],
    "pdf_url": "http://arxiv.org/pdf/2510.21012v1"
  },
  {
    "id": "2510.21004v1",
    "title": "Can Current Detectors Catch Face-to-Voice Deepfake Attacks?",
    "abstract": "The rapid advancement of generative models has enabled the creation of\nincreasingly stealthy synthetic voices, commonly referred to as audio\ndeepfakes. A recent technique, FOICE [USENIX'24], demonstrates a particularly\nalarming capability: generating a victim's voice from a single facial image,\nwithout requiring any voice sample. By exploiting correlations between facial\nand vocal features, FOICE produces synthetic voices realistic enough to bypass\nindustry-standard authentication systems, including WeChat Voiceprint and\nMicrosoft Azure. This raises serious security concerns, as facial images are\nfar easier for adversaries to obtain than voice samples, dramatically lowering\nthe barrier to large-scale attacks. In this work, we investigate two core\nresearch questions: (RQ1) can state-of-the-art audio deepfake detectors\nreliably detect FOICE-generated speech under clean and noisy conditions, and\n(RQ2) whether fine-tuning these detectors on FOICE data improves detection\nwithout overfitting, thereby preserving robustness to unseen voice generators\nsuch as SpeechT5.\n  Our study makes three contributions. First, we present the first systematic\nevaluation of FOICE detection, showing that leading detectors consistently fail\nunder both standard and noisy conditions. Second, we introduce targeted\nfine-tuning strategies that capture FOICE-specific artifacts, yielding\nsignificant accuracy improvements. Third, we assess generalization after\nfine-tuning, revealing trade-offs between specialization to FOICE and\nrobustness to unseen synthesis pipelines. These findings expose fundamental\nweaknesses in today's defenses and motivate new architectures and training\nprotocols for next-generation audio deepfake detection.",
    "categories": [
      "cs.CR",
      "cs.LG",
      "cs.MM",
      "cs.SD"
    ],
    "published": "2025-10-23T21:24:55Z",
    "authors": [
      "Nguyen Linh Bao Nguyen",
      "Alsharif Abuadbba",
      "Kristen Moore",
      "Tingming Wu"
    ],
    "pdf_url": "http://arxiv.org/pdf/2510.21004v1"
  },
  {
    "id": "2510.21003v1",
    "title": "Distilled Decoding 2: One-step Sampling of Image Auto-regressive Models\n  with Conditional Score Distillation",
    "abstract": "Image Auto-regressive (AR) models have emerged as a powerful paradigm of\nvisual generative models. Despite their promising performance, they suffer from\nslow generation speed due to the large number of sampling steps required.\nAlthough Distilled Decoding 1 (DD1) was recently proposed to enable few-step\nsampling for image AR models, it still incurs significant performance\ndegradation in the one-step setting, and relies on a pre-defined mapping that\nlimits its flexibility. In this work, we propose a new method, Distilled\nDecoding 2 (DD2), to further advances the feasibility of one-step sampling for\nimage AR models. Unlike DD1, DD2 does not without rely on a pre-defined\nmapping. We view the original AR model as a teacher model which provides the\nground truth conditional score in the latent embedding space at each token\nposition. Based on this, we propose a novel \\emph{conditional score\ndistillation loss} to train a one-step generator. Specifically, we train a\nseparate network to predict the conditional score of the generated distribution\nand apply score distillation at every token position conditioned on previous\ntokens. Experimental results show that DD2 enables one-step sampling for image\nAR models with an minimal FID increase from 3.40 to 5.43 on ImageNet-256.\nCompared to the strongest baseline DD1, DD2 reduces the gap between the\none-step sampling and original AR model by 67%, with up to 12.3$\\times$\ntraining speed-up simultaneously. DD2 takes a significant step toward the goal\nof one-step AR generation, opening up new possibilities for fast and\nhigh-quality AR modeling. Code is available at\nhttps://github.com/imagination-research/Distilled-Decoding-2.",
    "categories": [
      "cs.LG"
    ],
    "published": "2025-10-23T21:21:38Z",
    "authors": [
      "Enshu Liu",
      "Qian Chen",
      "Xuefei Ning",
      "Shengen Yan",
      "Guohao Dai",
      "Zinan Lin",
      "Yu Wang"
    ],
    "pdf_url": "http://arxiv.org/pdf/2510.21003v1"
  },
  {
    "id": "2510.21887v1",
    "title": "Generative AI in Depth: A Survey of Recent Advances, Model Variants, and\n  Real-World Applications",
    "abstract": "In recent years, deep learning based generative models, particularly\nGenerative Adversarial Networks (GANs), Variational Autoencoders (VAEs), and\nDiffusion Models (DMs), have been instrumental in in generating diverse,\nhigh-quality content across various domains, such as image and video synthesis.\nThis capability has led to widespread adoption of these models and has captured\nstrong public interest. As they continue to advance at a rapid pace, the\ngrowing volume of research, expanding application areas, and unresolved\ntechnical challenges make it increasingly difficult to stay current. To address\nthis need, this survey introduces a comprehensive taxonomy that organizes the\nliterature and provides a cohesive framework for understanding the development\nof GANs, VAEs, and DMs, including their many variants and combined approaches.\nWe highlight key innovations that have improved the quality, diversity, and\ncontrollability of generated outputs, reflecting the expanding potential of\ngenerative artificial intelligence. In addition to summarizing technical\nprogress, we examine rising ethical concerns, including the risks of misuse and\nthe broader societal impact of synthetic media. Finally, we outline persistent\nchallenges and propose future research directions, offering a structured and\nforward looking perspective for researchers in this fast evolving field.",
    "categories": [
      "cs.CV",
      "cs.AI",
      "cs.LG"
    ],
    "published": "2025-10-23T21:11:12Z",
    "authors": [
      "Shamim Yazdani",
      "Akansha Singh",
      "Nripsuta Saxena",
      "Zichong Wang",
      "Avash Palikhe",
      "Deng Pan",
      "Umapada Pal",
      "Jie Yang",
      "Wenbin Zhang"
    ],
    "pdf_url": "http://arxiv.org/pdf/2510.21887v1"
  },
  {
    "id": "2510.20997v1",
    "title": "Exploring Spiking Neural Networks for Binary Classification in\n  Multivariate Time Series at the Edge",
    "abstract": "We present a general framework for training spiking neural networks (SNNs) to\nperform binary classification on multivariate time series, with a focus on\nstep-wise prediction and high precision at low false alarm rates. The approach\nuses the Evolutionary Optimization of Neuromorphic Systems (EONS) algorithm to\nevolve sparse, stateful SNNs by jointly optimizing their architectures and\nparameters. Inputs are encoded into spike trains, and predictions are made by\nthresholding a single output neuron's spike counts. We also incorporate simple\nvoting ensemble methods to improve performance and robustness.\n  To evaluate the framework, we apply it with application-specific\noptimizations to the task of detecting low signal-to-noise ratio radioactive\nsources in gamma-ray spectral data. The resulting SNNs, with as few as 49\nneurons and 66 synapses, achieve a 51.8% true positive rate (TPR) at a false\nalarm rate of 1/hr, outperforming PCA (42.7%) and deep learning (49.8%)\nbaselines. A three-model any-vote ensemble increases TPR to 67.1% at the same\nfalse alarm rate. Hardware deployment on the microCaspian neuromorphic platform\ndemonstrates 2mW power consumption and 20.2ms inference latency.\n  We also demonstrate generalizability by applying the same framework, without\ndomain-specific modification, to seizure detection in EEG recordings. An\nensemble achieves 95% TPR with a 16% false positive rate, comparable to recent\ndeep learning approaches with significant reduction in parameter count.",
    "categories": [
      "cs.LG",
      "cs.AI"
    ],
    "published": "2025-10-23T20:52:11Z",
    "authors": [
      "James Ghawaly",
      "Andrew Nicholson",
      "Catherine Schuman",
      "Dalton Diez",
      "Aaron Young",
      "Brett Witherspoon"
    ],
    "pdf_url": "http://arxiv.org/pdf/2510.20997v1"
  },
  {
    "id": "2510.20995v2",
    "title": "AL-CoLe: Augmented Lagrangian for Constrained Learning",
    "abstract": "Despite the non-convexity of most modern machine learning parameterizations,\nLagrangian duality has become a popular tool for addressing constrained\nlearning problems. We revisit Augmented Lagrangian methods, which aim to\nmitigate the duality gap in non-convex settings while requiring only minimal\nmodifications, and have remained comparably unexplored in constrained learning\nsettings. We establish strong duality results under mild conditions, prove\nconvergence of dual ascent algorithms to feasible and optimal primal solutions,\nand provide PAC-style generalization guarantees. Finally, we demonstrate its\neffectiveness on fairness constrained classification tasks.",
    "categories": [
      "cs.LG",
      "eess.SP"
    ],
    "published": "2025-10-23T20:46:49Z",
    "authors": [
      "Ignacio Boero",
      "Ignacio Hounie",
      "Alejandro Ribeiro"
    ],
    "pdf_url": "http://arxiv.org/pdf/2510.20995v2"
  },
  {
    "id": "2510.20994v1",
    "title": "VESSA: Video-based objEct-centric Self-Supervised Adaptation for Visual\n  Foundation Models",
    "abstract": "Foundation models have advanced computer vision by enabling strong\nperformance across diverse tasks through large-scale pretraining and supervised\nfine-tuning. However, they may underperform in domains with distribution shifts\nand scarce labels, where supervised fine-tuning may be infeasible. While\ncontinued self-supervised learning for model adaptation is common for\ngenerative language models, this strategy has not proven effective for\nvision-centric encoder models. To address this challenge, we introduce a novel\nformulation of self-supervised fine-tuning for vision foundation models, where\nthe model is adapted to a new domain without requiring annotations, leveraging\nonly short multi-view object-centric videos. Our method is referred to as\nVESSA: Video-based objEct-centric Self-Supervised Adaptation for visual\nfoundation models. VESSA's training technique is based on a self-distillation\nparadigm, where it is critical to carefully tune prediction heads and deploy\nparameter-efficient adaptation techniques - otherwise, the model may quickly\nforget its pretrained knowledge and reach a degraded state. VESSA benefits\nsignificantly from multi-view object observations sourced from different frames\nin an object-centric video, efficiently learning robustness to varied capture\nconditions, without the need of annotations. Through comprehensive experiments\nwith 3 vision foundation models on 2 datasets, VESSA demonstrates consistent\nimprovements in downstream classification tasks, compared to the base models\nand previous adaptation methods. Code is publicly available at\nhttps://github.com/jesimonbarreto/VESSA.",
    "categories": [
      "cs.CV",
      "cs.AI",
      "cs.LG"
    ],
    "published": "2025-10-23T20:44:28Z",
    "authors": [
      "Jesimon Barreto",
      "Carlos Caetano",
      "Andr\u00e9 Araujo",
      "William Robson Schwartz"
    ],
    "pdf_url": "http://arxiv.org/pdf/2510.20994v1"
  },
  {
    "id": "2510.23626v1",
    "title": "From Detection to Discovery: A Closed-Loop Approach for Simultaneous and\n  Continuous Medical Knowledge Expansion and Depression Detection on Social\n  Media",
    "abstract": "Social media user-generated content (UGC) provides real-time, self-reported\nindicators of mental health conditions such as depression, offering a valuable\nsource for predictive analytics. While prior studies integrate medical\nknowledge to improve prediction accuracy, they overlook the opportunity to\nsimultaneously expand such knowledge through predictive processes. We develop a\nClosed-Loop Large Language Model (LLM)-Knowledge Graph framework that\nintegrates prediction and knowledge expansion in an iterative learning cycle.\nIn the knowledge-aware depression detection phase, the LLM jointly performs\ndepression detection and entity extraction, while the knowledge graph\nrepresents and weights these entities to refine prediction performance. In the\nknowledge refinement and expansion phase, new entities, relationships, and\nentity types extracted by the LLM are incorporated into the knowledge graph\nunder expert supervision, enabling continual knowledge evolution. Using\nlarge-scale UGC, the framework enhances both predictive accuracy and medical\nunderstanding. Expert evaluations confirmed the discovery of clinically\nmeaningful symptoms, comorbidities, and social triggers complementary to\nexisting literature. We conceptualize and operationalize\nprediction-through-learning and learning-through-prediction as mutually\nreinforcing processes, advancing both methodological and theoretical\nunderstanding in predictive analytics. The framework demonstrates the\nco-evolution of computational models and domain knowledge, offering a\nfoundation for adaptive, data-driven knowledge systems applicable to other\ndynamic risk monitoring contexts.",
    "categories": [
      "cs.LG",
      "cs.AI",
      "cs.CL"
    ],
    "published": "2025-10-23T20:34:36Z",
    "authors": [
      "Shuang Geng",
      "Wenli Zhang",
      "Jiaheng Xie",
      "Rui Wang",
      "Sudha Ram"
    ],
    "pdf_url": "http://arxiv.org/pdf/2510.23626v1"
  },
  {
    "id": "2510.20985v1",
    "title": "GPU Memory Requirement Prediction for Deep Learning Task Based on\n  Bidirectional Gated Recurrent Unit Optimization Transformer",
    "abstract": "In response to the increasingly critical demand for accurate prediction of\nGPU memory resources in deep learning tasks, this paper deeply analyzes the\ncurrent research status and innovatively proposes a deep learning model that\nintegrates bidirectional gated recurrent units (BiGRU) to optimize the\nTransformer architecture, aiming to improve the accuracy of memory demand\nprediction. To verify the effectiveness of the model, a carefully designed\ncomparative experiment was conducted, selecting four representative basic\nmachine learning models: decision tree, random forest, Adaboost, and XGBoost as\nbenchmarks. The detailed experimental results show that the BiGRU Transformer\noptimization model proposed in this paper exhibits significant advantages in\nkey evaluation indicators: in terms of mean square error (MSE) and root mean\nsquare error (RMSE), the model achieves the lowest value among all comparison\nmodels, and its predicted results have the smallest deviation from the actual\nvalues; In terms of mean absolute error (MAE) and coefficient of determination\n(R2) indicators, the model also performs well and the results are balanced and\nstable, with comprehensive predictive performance far exceeding the benchmark\nmachine learning methods compared. In summary, the Transformer model based on\nbidirectional gated recurrent unit optimization successfully constructed in\nthis study can efficiently and accurately complete GPU memory demand prediction\ntasks in deep learning tasks, and its prediction accuracy has been\nsignificantly improved compared to traditional machine learning methods. This\nresearch provides strong technical support and reliable theoretical basis for\noptimizing resource scheduling and management of deep learning tasks, and\nimproving the utilization efficiency of computing clusters.",
    "categories": [
      "cs.LG",
      "cs.AI"
    ],
    "published": "2025-10-23T20:20:35Z",
    "authors": [
      "Chao Wang",
      "Zhizhao Wen",
      "Ruoxin Zhang",
      "Puyang Xu",
      "Yifan Jiang"
    ],
    "pdf_url": "http://arxiv.org/pdf/2510.20985v1"
  },
  {
    "id": "2510.20984v1",
    "title": "Learning Grouped Lattice Vector Quantizers for Low-Bit LLM Compression",
    "abstract": "Large Language Models (LLMs) have demonstrated remarkable capabilities but\ntypically require extensive computational resources and memory for inference.\nPost-training quantization (PTQ) can effectively reduce these demands by\nstoring weights in lower bit-width formats. However, standard uniform\nquantization often leads to notable performance degradation, particularly in\nlow-bit scenarios. In this work, we introduce a Grouped Lattice Vector\nQuantization (GLVQ) framework that assigns each group of weights a customized\nlattice codebook, defined by a learnable generation matrix. To address the\nnon-differentiability of the quantization process, we adopt Babai rounding to\napproximate nearest-lattice-point search during training, which enables stable\noptimization of the generation matrices. Once trained, decoding reduces to a\nsimple matrix-vector multiplication, yielding an efficient and practical\nquantization pipeline. Experiments on multiple benchmarks show that our\napproach achieves a better trade-off between model size and accuracy compared\nto existing post-training quantization baselines, highlighting its\neffectiveness in deploying large models under stringent resource constraints.\nOur source code is available on GitHub repository:\nhttps://github.com/xzhang9308/GLVQ.",
    "categories": [
      "cs.LG",
      "cs.AI"
    ],
    "published": "2025-10-23T20:19:48Z",
    "authors": [
      "Xi Zhang",
      "Xiaolin Wu",
      "Jiamang Wang",
      "Weisi Lin"
    ],
    "pdf_url": "http://arxiv.org/pdf/2510.20984v1"
  },
  {
    "id": "2510.20979v1",
    "title": "Memory Constrained Dynamic Subnetwork Update for Transfer Learning",
    "abstract": "On-device neural network training faces critical memory constraints that\nlimit the adaptation of pre-trained models to downstream tasks. We present\nMeDyate, a theoretically-grounded framework for memory-constrained dynamic\nsubnetwork adaptation. Our approach introduces two key innovations: LaRa (Layer\nRanking), an improved layer importance metric that enables principled layer\npre-selection, and a dynamic channel sampling strategy that exploits the\ntemporal stability of channel importance distributions during fine-tuning.\nMeDyate dynamically resamples channels between epochs according to\nimportance-weighted probabilities, ensuring comprehensive parameter space\nexploration while respecting strict memory budgets. Extensive evaluation across\na large panel of tasks and architectures demonstrates that MeDyate achieves\nstate-of-the-art performance under extreme memory constraints, consistently\noutperforming existing static and dynamic approaches while maintaining high\ncomputational efficiency. Our method represents a significant step towards\nenabling efficient on-device learning by demonstrating effective fine-tuning\nwith memory budgets as low as a few hundred kB of RAM.",
    "categories": [
      "cs.LG",
      "cs.AI"
    ],
    "published": "2025-10-23T20:16:43Z",
    "authors": [
      "A\u00ebl Qu\u00e9lennec",
      "Pavlo Mozharovskyi",
      "Van-Tam Nguyen",
      "Enzo Tartaglione"
    ],
    "pdf_url": "http://arxiv.org/pdf/2510.20979v1"
  },
  {
    "id": "2510.20976v1",
    "title": "L^2M^3OF: A Large Language Multimodal Model for Metal-Organic Frameworks",
    "abstract": "Large language models have demonstrated remarkable reasoning capabilities\nacross diverse natural language tasks. However, comparable breakthroughs in\nscientific discovery are more limited, because understanding complex physical\nphenomena demands multifaceted representations far beyond language alone. A\ncompelling example is the design of functional materials such as MOFs-critical\nfor a range of impactful applications like carbon capture and hydrogen storage.\nNavigating their vast and intricate design space in language-based\nrepresentations interpretable by LLMs is challenging due to the numerous\npossible three-dimensional atomic arrangements and strict reticular rules of\ncoordination geometry and topology. Despite promising early results in\nLLM-assisted discovery for simpler materials systems, MOF design remains\nheavily reliant on tacit human expertise rarely codified in textual information\nalone. To overcome this barrier, we introduce L2M3OF, the first multimodal LLM\nfor MOFs. L2M3OF integrates crystal representation learning with language\nunderstanding to process structural, textual, and knowledge modalities jointly.\nL2M3OF employs a pre-trained crystal encoder with a lightweight projection\nlayer to compress structural information into a token space, enabling efficient\nalignment with language instructions. To facilitate training and evaluation, we\ncurate a structure-property-knowledge database of crystalline materials and\nbenchmark L2M3OF against state-of-the-art closed-source LLMs such as GPT-5,\nGemini-2.5-Pro and DeepSeek-R1. Experiments show that L2M3OF outperforms\nleading text-based closed-source LLMs in property prediction and knowledge\ngeneration tasks, despite using far fewer parameters. These results highlight\nthe importance of multimodal approaches for porous material understanding and\nestablish L2M3OF as a foundation for next-generation AI systems in materials\ndiscovery.",
    "categories": [
      "cs.LG"
    ],
    "published": "2025-10-23T20:12:46Z",
    "authors": [
      "Jiyu Cui",
      "Fang Wu",
      "Haokai Zhao",
      "Minggao Feng",
      "Xenophon Evangelopoulos",
      "Andrew I. Cooper",
      "Yejin Choi"
    ],
    "pdf_url": "http://arxiv.org/pdf/2510.20976v1"
  },
  {
    "id": "2510.23624v1",
    "title": "DiNo and RanBu: Lightweight Predictions from Shallow Random Forests",
    "abstract": "Random Forest ensembles are a strong baseline for tabular prediction tasks,\nbut their reliance on hundreds of deep trees often results in high inference\nlatency and memory demands, limiting deployment in latency-sensitive or\nresource-constrained environments. We introduce DiNo (Distance with Nodes) and\nRanBu (Random Bushes), two shallow-forest methods that convert a small set of\ndepth-limited trees into efficient, distance-weighted predictors. DiNo measures\ncophenetic distances via the most recent common ancestor of observation pairs,\nwhile RanBu applies kernel smoothing to Breiman's classical proximity measure.\nBoth approaches operate entirely after forest training: no additional trees are\ngrown, and tuning of the single bandwidth parameter $h$ requires only\nlightweight matrix-vector operations. Across three synthetic benchmarks and 25\npublic datasets, RanBu matches or exceeds the accuracy of full-depth random\nforests-particularly in high-noise settings-while reducing training plus\ninference time by up to 95\\%. DiNo achieves the best bias-variance trade-off in\nlow-noise regimes at a modest computational cost. Both methods extend directly\nto quantile regression, maintaining accuracy with substantial speed gains. The\nimplementation is available as an open-source R/C++ package at\nhttps://github.com/tiagomendonca/dirf. We focus on structured tabular random\nsamples (i.i.d.), leaving extensions to other modalities for future work.",
    "categories": [
      "cs.LG",
      "stat.ML"
    ],
    "published": "2025-10-23T20:12:08Z",
    "authors": [
      "Tiago Mendon\u00e7a dos Santos",
      "Rafael Izbicki",
      "Lu\u00eds Gustavo Esteves"
    ],
    "pdf_url": "http://arxiv.org/pdf/2510.23624v1"
  },
  {
    "id": "2510.20974v2",
    "title": "Robust Point Cloud Reinforcement Learning via PCA-Based Canonicalization",
    "abstract": "Reinforcement Learning (RL) from raw visual input has achieved impressive\nsuccesses in recent years, yet it remains fragile to out-of-distribution\nvariations such as changes in lighting, color, and viewpoint. Point Cloud\nReinforcement Learning (PC-RL) offers a promising alternative by mitigating\nappearance-based brittleness, but its sensitivity to camera pose mismatches\ncontinues to undermine reliability in realistic settings. To address this\nchallenge, we propose PCA Point Cloud (PPC), a canonicalization framework\nspecifically tailored for downstream robotic control. PPC maps point clouds\nunder arbitrary rigid-body transformations to a unique canonical pose, aligning\nobservations to a consistent frame, thereby substantially decreasing\nviewpoint-induced inconsistencies. In our experiments, we show that PPC\nimproves robustness to unseen camera poses across challenging robotic tasks,\nproviding a principled alternative to domain randomization.",
    "categories": [
      "cs.RO",
      "cs.LG"
    ],
    "published": "2025-10-23T20:06:29Z",
    "authors": [
      "Michael Bezick",
      "Vittorio Giammarino",
      "Ahmed H. Qureshi"
    ],
    "pdf_url": "http://arxiv.org/pdf/2510.20974v2"
  },
  {
    "id": "2510.20970v1",
    "title": "On the accuracy of implicit neural representations for cardiovascular\n  anatomies and hemodynamic fields",
    "abstract": "Implicit neural representations (INRs, also known as neural fields) have\nrecently emerged as a powerful framework for knowledge representation,\nsynthesis, and compression. By encoding fields as continuous functions within\nthe weights and biases of deep neural networks-rather than relying on voxel- or\nmesh-based structured or unstructured representations-INRs offer both\nresolution independence and high memory efficiency. However, their accuracy in\ndomain-specific applications remains insufficiently understood. In this work,\nwe assess the performance of state-of-the-art INRs for compressing hemodynamic\nfields derived from numerical simulations and for representing cardiovascular\nanatomies via signed distance functions. We investigate several strategies to\nmitigate spectral bias, including specialized activation functions, both fixed\nand trainable positional encoding, and linear combinations of nonlinear\nkernels. On realistic, space- and time-varying hemodynamic fields in the\nthoracic aorta, INRs achieved remarkable compression ratios of up to\napproximately 230, with maximum absolute errors of 1 mmHg for pressure and 5-10\ncm/s for velocity, without extensive hyperparameter tuning. Across 48 thoracic\naortic anatomies, the average and maximum absolute anatomical discrepancies\nwere below 0.5 mm and 1.6 mm, respectively. Overall, the SIREN, MFN-Gabor, and\nMHE architectures demonstrated the best performance. Source code and data is\navailable at https://github.com/desResLab/nrf.",
    "categories": [
      "cs.LG"
    ],
    "published": "2025-10-23T19:57:50Z",
    "authors": [
      "Jubilee Lee",
      "Daniele E. Schiavazzi"
    ],
    "pdf_url": "http://arxiv.org/pdf/2510.20970v1"
  },
  {
    "id": "2510.20968v1",
    "title": "Neural Mutual Information Estimation with Vector Copulas",
    "abstract": "Estimating mutual information (MI) is a fundamental task in data science and\nmachine learning. Existing estimators mainly rely on either highly flexible\nmodels (e.g., neural networks), which require large amounts of data, or overly\nsimplified models (e.g., Gaussian copula), which fail to capture complex\ndistributions. Drawing upon recent vector copula theory, we propose a\nprincipled interpolation between these two extremes to achieve a better\ntrade-off between complexity and capacity. Experiments on state-of-the-art\nsynthetic benchmarks and real-world data with diverse modalities demonstrate\nthe advantages of the proposed estimator.",
    "categories": [
      "cs.LG"
    ],
    "published": "2025-10-23T19:54:56Z",
    "authors": [
      "Yanzhi Chen",
      "Zijing Ou",
      "Adrian Weller",
      "Michael U. Gutmann"
    ],
    "pdf_url": "http://arxiv.org/pdf/2510.20968v1"
  },
  {
    "id": "2510.20965v1",
    "title": "SutureBot: A Precision Framework & Benchmark For Autonomous End-to-End\n  Suturing",
    "abstract": "Robotic suturing is a prototypical long-horizon dexterous manipulation task,\nrequiring coordinated needle grasping, precise tissue penetration, and secure\nknot tying. Despite numerous efforts toward end-to-end autonomy, a fully\nautonomous suturing pipeline has yet to be demonstrated on physical hardware.\nWe introduce SutureBot: an autonomous suturing benchmark on the da Vinci\nResearch Kit (dVRK), spanning needle pickup, tissue insertion, and knot tying.\nTo ensure repeatability, we release a high-fidelity dataset comprising 1,890\nsuturing demonstrations. Furthermore, we propose a goal-conditioned framework\nthat explicitly optimizes insertion-point precision, improving targeting\naccuracy by 59\\%-74\\% over a task-only baseline. To establish this task as a\nbenchmark for dexterous imitation learning, we evaluate state-of-the-art\nvision-language-action (VLA) models, including $\\pi_0$, GR00T N1, OpenVLA-OFT,\nand multitask ACT, each augmented with a high-level task-prediction policy.\nAutonomous suturing is a key milestone toward achieving robotic autonomy in\nsurgery. These contributions support reproducible evaluation and development of\nprecision-focused, long-horizon dexterous manipulation policies necessary for\nend-to-end suturing. Dataset is available at:\nhttps://huggingface.co/datasets/jchen396/suturebot",
    "categories": [
      "cs.RO",
      "cs.LG"
    ],
    "published": "2025-10-23T19:50:17Z",
    "authors": [
      "Jesse Haworth",
      "Juo-Tung Chen",
      "Nigel Nelson",
      "Ji Woong Kim",
      "Masoud Moghani",
      "Chelsea Finn",
      "Axel Krieger"
    ],
    "pdf_url": "http://arxiv.org/pdf/2510.20965v1"
  },
  {
    "id": "2510.20963v1",
    "title": "Towards Scalable Oversight with Collaborative Multi-Agent Debate in\n  Error Detection",
    "abstract": "Accurate detection of errors in large language models (LLM) responses is\ncentral to the success of scalable oversight, or providing effective\nsupervision to superhuman intelligence. Yet, self-diagnosis is often unreliable\non complex tasks unless aided by reliable external feedback. Multi-agent debate\n(MAD) seems to be a natural alternative to external feedback: multiple LLMs\nprovide complementary perspectives and cross-checks for error detection.\nHowever, prior MAD protocols frame debate as a zero-sum game, where the\ndebaters compete to win the game instead of seeking the truth. Consequently, it\nleads to debate hacking: debaters tend to mislead the judge by misinterpreting\nthe task or presenting overconfident claims, which introduce more mistakes and\nunderperform single-agent methods. To mitigate the issue, we introduce a new\ncollaborative MAD protocol, termed ColMAD, that reframes MAD as a non-zero sum\ngame. Specifically, ColMAD encourages multiple agents to criticize each other\nin a supportive way, such that they can complement the missing points of each\nother. Therefore, the judge agent can make a more informative conclusion based\non more comprehensive evidence. Empirically, we show that ColMAD significantly\noutperforms previous competitive MAD by 19% and brings non-trivial improvements\nover single-agent methods in error detection.",
    "categories": [
      "cs.LG"
    ],
    "published": "2025-10-23T19:46:00Z",
    "authors": [
      "Yongqiang Chen",
      "Gang Niu",
      "James Cheng",
      "Bo Han",
      "Masashi Sugiyama"
    ],
    "pdf_url": "http://arxiv.org/pdf/2510.20963v1"
  },
  {
    "id": "2510.20960v1",
    "title": "An Ensembled Penalized Federated Learning Framework for Falling People\n  Detection",
    "abstract": "Falls among elderly and disabled individuals remain a leading cause of injury\nand mortality worldwide, necessitating robust, accurate, and privacy-aware fall\ndetection systems. Traditional fall detection approaches, whether centralized\nor point-wise, often struggle with key challenges such as limited\ngeneralizability, data privacy concerns, and variability in individual movement\nbehaviors. To address these limitations, we propose EPFL-an Ensembled Penalized\nFederated Learning framework that integrates continual learning, personalized\nmodeling, and a novel Specialized Weighted Aggregation (SWA) strategy. EPFL\nleverages wearable sensor data to capture sequential motion patterns while\npreserving user privacy through homomorphic encryption and federated training.\nUnlike existing federated models, EPFL incorporates both penalized local\ntraining and ensemble-based inference to improve inter-client consistency and\nadaptability to behavioral differences. Extensive experiments on a benchmark\nfall detection dataset demonstrate the effectiveness of our approach, achieving\na Recall of 88.31 percent and an F1-score of 89.94 percent, significantly\noutperforming both centralized and baseline models. This work presents a\nscalable, secure, and accurate solution for real-world fall detection in\nhealthcare settings, with strong potential for continuous improvement via its\nadaptive feedback mechanism.",
    "categories": [
      "cs.LG"
    ],
    "published": "2025-10-23T19:37:19Z",
    "authors": [
      "Sizhe Rao",
      "Runqiu Zhang",
      "Sajal Saha",
      "Liang Chen"
    ],
    "pdf_url": "http://arxiv.org/pdf/2510.20960v1"
  },
  {
    "id": "2510.20958v2",
    "title": "NeuroPilot: A Realtime Brain-Computer Interface system to enhance\n  concentration of students in online learning",
    "abstract": "The prevalence of online learning poses a vital challenge in real-time\nmonitoring of students' concentration. Traditional methods such as\nquestionnaire assessments require manual intervention, and webcam-based\nmonitoring fails to provide accurate insights about learners' mental focus as\nit is deceived by mere screen fixation without cognitive engagement. Existing\nBCI-based approaches lack real-time validation and evaluation procedures. To\naddress these limitations, a Brain-Computer Interface (BCI) system is developed\nusing a non-invasive Electroencephalogram (EEG) headband, FocusCalm, to record\nbrainwave activity under attentive and non-attentive states. 20 minutes of data\nwere collected from each of 20 participants watching a pre-recorded educational\nvideo. The data validation employed a novel intra-video questionnaire\nassessment. Subsequently, collected signals were segmented (sliding window),\nfiltered (Butterworth bandpass), and cleaned (removal of high-amplitude and EOG\nartifacts such as eye blinks). Time, frequency, wavelet, and statistical\nfeatures were extracted, followed by recursive feature elimination (RFE) with\nsupport vector machines (SVMs) to classify attention and non-attention states.\nThe leave-one-subject-out (LOSO) cross-validation accuracy was found to be\n88.77%. The system provides feedback alerts upon detection of a non-attention\nstate and maintains focus profile logs. A pilot study was conducted to evaluate\nthe effectiveness of real-time feedback. Five participants underwent a\n10-minute session comprising a 5-minute baseline phase devoid of feedback,\nsucceeded by a 5-minute feedback phase, during which alerts were activated if\nparticipants exhibited inattention for approximately 8 consecutive seconds. A\npaired t-test (t = 5.73, p = 0.007) indicated a statistically significant\nimprovement in concentration during the feedback phase.",
    "categories": [
      "cs.HC",
      "cs.LG",
      "eess.SP",
      "q-bio.NC"
    ],
    "published": "2025-10-23T19:36:59Z",
    "authors": [
      "Asif Islam",
      "Farhan Ishtiaque",
      "Md. Muhyminul Haque",
      "Farhana Sarker",
      "Ravi Vaidyanathan",
      "Khondaker A. Mamun"
    ],
    "pdf_url": "http://arxiv.org/pdf/2510.20958v2"
  },
  {
    "id": "2510.20955v1",
    "title": "Safety Assessment in Reinforcement Learning via Model Predictive Control",
    "abstract": "Model-free reinforcement learning approaches are promising for control but\ntypically lack formal safety guarantees. Existing methods to shield or\notherwise provide these guarantees often rely on detailed knowledge of the\nsafety specifications. Instead, this work's insight is that many\ndifficult-to-specify safety issues are best characterized by invariance.\nAccordingly, we propose to leverage reversibility as a method for preventing\nthese safety issues throughout the training process. Our method uses\nmodel-predictive path integral control to check the safety of an action\nproposed by a learned policy throughout training. A key advantage of this\napproach is that it only requires the ability to query the black-box dynamics,\nnot explicit knowledge of the dynamics or safety constraints. Experimental\nresults demonstrate that the proposed algorithm successfully aborts before all\nunsafe actions, while still achieving comparable training progress to a\nbaseline PPO approach that is allowed to violate safety.",
    "categories": [
      "cs.LG",
      "cs.RO"
    ],
    "published": "2025-10-23T19:31:18Z",
    "authors": [
      "Jeff Pflueger",
      "Michael Everett"
    ],
    "pdf_url": "http://arxiv.org/pdf/2510.20955v1"
  },
  {
    "id": "2510.20954v1",
    "title": "A Short Note on Upper Bounds for Graph Neural Operator Convergence Rate",
    "abstract": "Graphons, as limits of graph sequences, provide a framework for analyzing the\nasymptotic behavior of graph neural operators. Spectral convergence of sampled\ngraphs to graphons yields operator-level convergence rates, enabling\ntransferability analyses of GNNs. This note summarizes known bounds under no\nassumptions, global Lipschitz continuity, and piecewise-Lipschitz continuity,\nhighlighting tradeoffs between assumptions and rates, and illustrating their\nempirical tightness on synthetic and real data.",
    "categories": [
      "stat.ML",
      "cs.LG",
      "eess.SP"
    ],
    "published": "2025-10-23T19:28:56Z",
    "authors": [
      "Roxanne Holden",
      "Luana Ruiz"
    ],
    "pdf_url": "http://arxiv.org/pdf/2510.20954v1"
  },
  {
    "id": "2510.20952v1",
    "title": "LLM-Integrated Bayesian State Space Models for Multimodal Time-Series\n  Forecasting",
    "abstract": "Forecasting in the real world requires integrating structured time-series\ndata with unstructured textual information, but existing methods are\narchitecturally limited by fixed input/output horizons and are unable to model\nor quantify uncertainty. We address this challenge by introducing\nLLM-integrated Bayesian State space models (LBS), a novel probabilistic\nframework for multimodal temporal forecasting. At a high level, LBS consists of\ntwo components: (1) a state space model (SSM) backbone that captures the\ntemporal dynamics of latent states from which both numerical and textual\nobservations are generated and (2) a pretrained large language model (LLM) that\nis adapted to encode textual inputs for posterior state estimation and decode\ntextual forecasts consistent with the latent trajectory. This design enables\nflexible lookback and forecast windows, principled uncertainty quantification,\nand improved temporal generalization thanks to the well-suited inductive bias\nof SSMs toward modeling dynamical systems. Experiments on the TextTimeCorpus\nbenchmark demonstrate that LBS improves the previous state-of-the-art by 13.20%\nwhile providing human-readable summaries of each forecast. Our work is the\nfirst to unify LLMs and SSMs for joint numerical and textual prediction,\noffering a novel foundation for multimodal temporal reasoning.",
    "categories": [
      "cs.LG"
    ],
    "published": "2025-10-23T19:28:26Z",
    "authors": [
      "Sungjun Cho",
      "Changho Shin",
      "Suenggwan Jo",
      "Xinya Yan",
      "Shourjo Aditya Chaudhuri",
      "Frederic Sala"
    ],
    "pdf_url": "http://arxiv.org/pdf/2510.20952v1"
  },
  {
    "id": "2510.20943v1",
    "title": "Meta-Learning for Cross-Task Generalization in Protein Mutation Property\n  Prediction",
    "abstract": "Protein mutations can have profound effects on biological function, making\naccurate prediction of property changes critical for drug discovery, protein\nengineering, and precision medicine. Current approaches rely on fine-tuning\nprotein-specific transformers for individual datasets, but struggle with\ncross-dataset generalization due to heterogeneous experimental conditions and\nlimited target domain data. We introduce two key innovations: (1) the first\napplication of Model-Agnostic Meta-Learning (MAML) to protein mutation property\nprediction, and (2) a novel mutation encoding strategy using separator tokens\nto directly incorporate mutations into sequence context. We build upon\ntransformer architectures integrating them with MAML to enable rapid adaptation\nto new tasks through minimal gradient steps rather than learning\ndataset-specific patterns. Our mutation encoding addresses the critical\nlimitation where standard transformers treat mutation positions as unknown\ntokens, significantly degrading performance. Evaluation across three diverse\nprotein mutation datasets (functional fitness, thermal stability, and\nsolubility) demonstrates significant advantages over traditional fine-tuning.\nIn cross-task evaluation, our meta-learning approach achieves 29% better\naccuracy for functional fitness with 65% less training time, and 94% better\naccuracy for solubility with 55% faster training. The framework maintains\nconsistent training efficiency regardless of dataset size, making it\nparticularly valuable for industrial applications and early-stage protein\ndesign where experimental data is limited. This work establishes a systematic\napplication of meta-learning to protein mutation analysis and introduces an\neffective mutation encoding strategy, offering transformative methodology for\ncross-domain generalization in protein engineering.",
    "categories": [
      "cs.LG",
      "cs.AI"
    ],
    "published": "2025-10-23T19:09:06Z",
    "authors": [
      "Srivathsan Badrinarayanan",
      "Yue Su",
      "Janghoon Ock",
      "Alan Pham",
      "Sanya Ahuja",
      "Amir Barati Farimani"
    ],
    "pdf_url": "http://arxiv.org/pdf/2510.20943v1"
  },
  {
    "id": "2510.20925v1",
    "title": "Learning from Interval Targets",
    "abstract": "We study the problem of regression with interval targets, where only upper\nand lower bounds on target values are available in the form of intervals. This\nproblem arises when the exact target label is expensive or impossible to\nobtain, due to inherent uncertainties. In the absence of exact targets,\ntraditional regression loss functions cannot be used. First, we study the\nmethodology of using a loss functions compatible with interval targets, for\nwhich we establish non-asymptotic generalization bounds based on smoothness of\nthe hypothesis class that significantly relaxing prior assumptions of\nrealizability and small ambiguity degree. Second, we propose a novel min-max\nlearning formulation: minimize against the worst-case (maximized) target labels\nwithin the provided intervals. The maximization problem in the latter is\nnon-convex, but we show that good performance can be achieved with the\nincorporation of smoothness constraints. Finally, we perform extensive\nexperiments on real-world datasets and show that our methods achieve\nstate-of-the-art performance.",
    "categories": [
      "cs.LG"
    ],
    "published": "2025-10-23T18:24:17Z",
    "authors": [
      "Rattana Pukdee",
      "Ziqi Ke",
      "Chirag Gupta"
    ],
    "pdf_url": "http://arxiv.org/pdf/2510.20925v1"
  },
  {
    "id": "2510.20905v1",
    "title": "Global Dynamics of Heavy-Tailed SGDs in Nonconvex Loss Landscape:\n  Characterization and Control",
    "abstract": "Stochastic gradient descent (SGD) and its variants enable modern artificial\nintelligence. However, theoretical understanding lags far behind their\nempirical success. It is widely believed that SGD has a curious ability to\navoid sharp local minima in the loss landscape, which are associated with poor\ngeneralization. To unravel this mystery and further enhance such capability of\nSGDs, it is imperative to go beyond the traditional local convergence analysis\nand obtain a comprehensive understanding of SGDs' global dynamics. In this\npaper, we develop a set of technical machinery based on the recent large\ndeviations and metastability analysis in Wang and Rhee (2023) and obtain sharp\ncharacterization of the global dynamics of heavy-tailed SGDs. In particular, we\nreveal a fascinating phenomenon in deep learning: by injecting and then\ntruncating heavy-tailed noises during the training phase, SGD can almost\ncompletely avoid sharp minima and achieve better generalization performance for\nthe test data. Simulation and deep learning experiments confirm our theoretical\nprediction that heavy-tailed SGD with gradient clipping finds local minima with\na more flat geometry and achieves better generalization performance.",
    "categories": [
      "cs.LG",
      "math.PR"
    ],
    "published": "2025-10-23T18:01:29Z",
    "authors": [
      "Xingyu Wang",
      "Chang-Han Rhee"
    ],
    "pdf_url": "http://arxiv.org/pdf/2510.20905v1"
  },
  {
    "id": "2510.20903v1",
    "title": "Information Theoretic Learning for Diffusion Models with Warm Start",
    "abstract": "Generative models that maximize model likelihood have gained traction in many\npractical settings. Among them, perturbation based approaches underpin many\nstrong likelihood estimation models, yet they often face slow convergence and\nlimited theoretical understanding. In this paper, we derive a tighter\nlikelihood bound for noise driven models to improve both the accuracy and\nefficiency of maximum likelihood learning. Our key insight extends the\nclassical KL divergence Fisher information relationship to arbitrary noise\nperturbations, going beyond the Gaussian assumption and enabling structured\nnoise distributions. This formulation allows flexible use of randomized noise\ndistributions that naturally account for sensor artifacts, quantization\neffects, and data distribution smoothing, while remaining compatible with\nstandard diffusion training. Treating the diffusion process as a Gaussian\nchannel, we further express the mismatched entropy between data and model,\nshowing that the proposed objective upper bounds the negative log-likelihood\n(NLL). In experiments, our models achieve competitive NLL on CIFAR-10 and SOTA\nresults on ImageNet across multiple resolutions, all without data augmentation,\nand the framework extends naturally to discrete data.",
    "categories": [
      "cs.IT",
      "cs.LG",
      "math.IT"
    ],
    "published": "2025-10-23T18:00:59Z",
    "authors": [
      "Yirong Shen",
      "Lu Gan",
      "Cong Ling"
    ],
    "pdf_url": "http://arxiv.org/pdf/2510.20903v1"
  },
  {
    "id": "2510.20819v2",
    "title": "Towards General Modality Translation with Contrastive and Predictive\n  Latent Diffusion Bridge",
    "abstract": "Recent advances in generative modeling have positioned diffusion models as\nstate-of-the-art tools for sampling from complex data distributions. While\nthese models have shown remarkable success across single-modality domains such\nas images and audio, extending their capabilities to Modality Translation (MT),\ntranslating information across different sensory modalities, remains an open\nchallenge. Existing approaches often rely on restrictive assumptions, including\nshared dimensionality, Gaussian source priors, and modality-specific\narchitectures, which limit their generality and theoretical grounding. In this\nwork, we propose the Latent Denoising Diffusion Bridge Model (LDDBM), a\ngeneral-purpose framework for modality translation based on a latent-variable\nextension of Denoising Diffusion Bridge Models. By operating in a shared latent\nspace, our method learns a bridge between arbitrary modalities without\nrequiring aligned dimensions. We introduce a contrastive alignment loss to\nenforce semantic consistency between paired samples and design a\ndomain-agnostic encoder-decoder architecture tailored for noise prediction in\nlatent space. Additionally, we propose a predictive loss to guide training\ntoward accurate cross-domain translation and explore several training\nstrategies to improve stability. Our approach supports arbitrary modality pairs\nand performs strongly on diverse MT tasks, including multi-view to 3D shape\ngeneration, image super-resolution, and multi-view scene synthesis.\nComprehensive experiments and ablations validate the effectiveness of our\nframework, establishing a new strong baseline in general modality translation.\nFor more information, see our project page:\nhttps://sites.google.com/view/lddbm/home.",
    "categories": [
      "cs.CV",
      "cs.AI",
      "cs.LG"
    ],
    "published": "2025-10-23T17:59:54Z",
    "authors": [
      "Nimrod Berman",
      "Omkar Joglekar",
      "Eitan Kosman",
      "Dotan Di Castro",
      "Omri Azencot"
    ],
    "pdf_url": "http://arxiv.org/pdf/2510.20819v2"
  },
  {
    "id": "2510.20818v1",
    "title": "VAMOS: A Hierarchical Vision-Language-Action Model for\n  Capability-Modulated and Steerable Navigation",
    "abstract": "A fundamental challenge in robot navigation lies in learning policies that\ngeneralize across diverse environments while conforming to the unique physical\nconstraints and capabilities of a specific embodiment (e.g., quadrupeds can\nwalk up stairs, but rovers cannot). We propose VAMOS, a hierarchical VLA that\ndecouples semantic planning from embodiment grounding: a generalist planner\nlearns from diverse, open-world data, while a specialist affordance model\nlearns the robot's physical constraints and capabilities in safe, low-cost\nsimulation. We enabled this separation by carefully designing an interface that\nlets a high-level planner propose candidate paths directly in image space that\nthe affordance model then evaluates and re-ranks. Our real-world experiments\nshow that VAMOS achieves higher success rates in both indoor and complex\noutdoor navigation than state-of-the-art model-based and end-to-end learning\nmethods. We also show that our hierarchical design enables cross-embodied\nnavigation across legged and wheeled robots and is easily steerable using\nnatural language. Real-world ablations confirm that the specialist model is key\nto embodiment grounding, enabling a single high-level planner to be deployed\nacross physically distinct wheeled and legged robots. Finally, this model\nsignificantly enhances single-robot reliability, achieving 3X higher success\nrates by rejecting physically infeasible plans. Website:\nhttps://vamos-vla.github.io/",
    "categories": [
      "cs.RO",
      "cs.AI",
      "cs.LG"
    ],
    "published": "2025-10-23T17:59:45Z",
    "authors": [
      "Mateo Guaman Castro",
      "Sidharth Rajagopal",
      "Daniel Gorbatov",
      "Matt Schmittle",
      "Rohan Baijal",
      "Octi Zhang",
      "Rosario Scalise",
      "Sidharth Talia",
      "Emma Romig",
      "Celso de Melo",
      "Byron Boots",
      "Abhishek Gupta"
    ],
    "pdf_url": "http://arxiv.org/pdf/2510.20818v1"
  },
  {
    "id": "2510.20817v1",
    "title": "KL-Regularized Reinforcement Learning is Designed to Mode Collapse",
    "abstract": "It is commonly believed that optimizing the reverse KL divergence results in\n\"mode seeking\", while optimizing forward KL results in \"mass covering\", with\nthe latter being preferred if the goal is to sample from multiple diverse\nmodes. We show -- mathematically and empirically -- that this intuition does\nnot necessarily transfer well to doing reinforcement learning with\nreverse/forward KL regularization (e.g. as commonly used with language models).\nInstead, the choice of reverse/forward KL determines the family of optimal\ntarget distributions, parameterized by the regularization coefficient. Mode\ncoverage depends primarily on other factors, such as regularization strength,\nand relative scales between rewards and reference probabilities. Further, we\nshow commonly used settings such as low regularization strength and equal\nverifiable rewards tend to specify unimodal target distributions, meaning the\noptimization objective is, by construction, non-diverse. We leverage these\ninsights to construct a simple, scalable, and theoretically justified\nalgorithm. It makes minimal changes to reward magnitudes, yet optimizes for a\ntarget distribution which puts high probability over all high-quality sampling\nmodes. In experiments, this simple modification works to post-train both Large\nLanguage Models and Chemical Language Models to have higher solution quality\nand diversity, without any external signals of diversity, and works with both\nforward and reverse KL when using either naively fails.",
    "categories": [
      "cs.LG"
    ],
    "published": "2025-10-23T17:59:40Z",
    "authors": [
      "Anthony GX-Chen",
      "Jatin Prakash",
      "Jeff Guo",
      "Rob Fergus",
      "Rajesh Ranganath"
    ],
    "pdf_url": "http://arxiv.org/pdf/2510.20817v1"
  },
  {
    "id": "2510.20810v1",
    "title": "On the Detectability of LLM-Generated Text: What Exactly Is\n  LLM-Generated Text?",
    "abstract": "With the widespread use of large language models (LLMs), many researchers\nhave turned their attention to detecting text generated by them. However, there\nis no consistent or precise definition of their target, namely \"LLM-generated\ntext\". Differences in usage scenarios and the diversity of LLMs further\nincrease the difficulty of detection. What is commonly regarded as the\ndetecting target usually represents only a subset of the text that LLMs can\npotentially produce. Human edits to LLM outputs, together with the subtle\ninfluences that LLMs exert on their users, are blurring the line between\nLLM-generated and human-written text. Existing benchmarks and evaluation\napproaches do not adequately address the various conditions in real-world\ndetector applications. Hence, the numerical results of detectors are often\nmisunderstood, and their significance is diminishing. Therefore, detectors\nremain useful under specific conditions, but their results should be\ninterpreted only as references rather than decisive indicators.",
    "categories": [
      "cs.CL",
      "cs.AI",
      "cs.CY",
      "cs.LG"
    ],
    "published": "2025-10-23T17:59:06Z",
    "authors": [
      "Mingmeng Geng",
      "Thierry Poibeau"
    ],
    "pdf_url": "http://arxiv.org/pdf/2510.20810v1"
  },
  {
    "id": "2510.20809v1",
    "title": "Real Deep Research for AI, Robotics and Beyond",
    "abstract": "With the rapid growth of research in AI and robotics now producing over\n10,000 papers annually it has become increasingly difficult for researchers to\nstay up to date. Fast evolving trends, the rise of interdisciplinary work, and\nthe need to explore domains beyond one's expertise all contribute to this\nchallenge. To address these issues, we propose a generalizable pipeline capable\nof systematically analyzing any research area: identifying emerging trends,\nuncovering cross domain opportunities, and offering concrete starting points\nfor new inquiry. In this work, we present Real Deep Research (RDR) a\ncomprehensive framework applied to the domains of AI and robotics, with a\nparticular focus on foundation models and robotics advancements. We also\nbriefly extend our analysis to other areas of science. The main paper details\nthe construction of the RDR pipeline, while the appendix provides extensive\nresults across each analyzed topic. We hope this work sheds light for\nresearchers working in the field of AI and beyond.",
    "categories": [
      "cs.AI",
      "cs.CL",
      "cs.CV",
      "cs.LG"
    ],
    "published": "2025-10-23T17:59:05Z",
    "authors": [
      "Xueyan Zou",
      "Jianglong Ye",
      "Hao Zhang",
      "Xiaoyu Xiang",
      "Mingyu Ding",
      "Zhaojing Yang",
      "Yong Jae Lee",
      "Zhuowen Tu",
      "Sifei Liu",
      "Xiaolong Wang"
    ],
    "pdf_url": "http://arxiv.org/pdf/2510.20809v1"
  },
  {
    "id": "2510.20808v1",
    "title": "The Reality Gap in Robotics: Challenges, Solutions, and Best Practices",
    "abstract": "Machine learning has facilitated significant advancements across various\nrobotics domains, including navigation, locomotion, and manipulation. Many such\nachievements have been driven by the extensive use of simulation as a critical\ntool for training and testing robotic systems prior to their deployment in\nreal-world environments. However, simulations consist of abstractions and\napproximations that inevitably introduce discrepancies between simulated and\nreal environments, known as the reality gap. These discrepancies significantly\nhinder the successful transfer of systems from simulation to the real world.\nClosing this gap remains one of the most pressing challenges in robotics.\nRecent advances in sim-to-real transfer have demonstrated promising results\nacross various platforms, including locomotion, navigation, and manipulation.\nBy leveraging techniques such as domain randomization, real-to-sim transfer,\nstate and action abstractions, and sim-real co-training, many works have\novercome the reality gap. However, challenges persist, and a deeper\nunderstanding of the reality gap's root causes and solutions is necessary. In\nthis survey, we present a comprehensive overview of the sim-to-real landscape,\nhighlighting the causes, solutions, and evaluation metrics for the reality gap\nand sim-to-real transfer.",
    "categories": [
      "cs.RO",
      "cs.AI",
      "cs.LG",
      "stat.ML",
      "I.2.6; I.2.8; I.2.9"
    ],
    "published": "2025-10-23T17:58:53Z",
    "authors": [
      "Elie Aljalbout",
      "Jiaxu Xing",
      "Angel Romero",
      "Iretiayo Akinola",
      "Caelan Reed Garrett",
      "Eric Heiden",
      "Abhishek Gupta",
      "Tucker Hermans",
      "Yashraj Narang",
      "Dieter Fox",
      "Davide Scaramuzza",
      "Fabio Ramos"
    ],
    "pdf_url": "http://arxiv.org/pdf/2510.20808v1"
  },
  {
    "id": "2510.20807v1",
    "title": "Video Prediction of Dynamic Physical Simulations With Pixel-Space\n  Spatiotemporal Transformers",
    "abstract": "Inspired by the performance and scalability of autoregressive large language\nmodels (LLMs), transformer-based models have seen recent success in the visual\ndomain. This study investigates a transformer adaptation for video prediction\nwith a simple end-to-end approach, comparing various spatiotemporal\nself-attention layouts. Focusing on causal modeling of physical simulations\nover time; a common shortcoming of existing video-generative approaches, we\nattempt to isolate spatiotemporal reasoning via physical object tracking\nmetrics and unsupervised training on physical simulation datasets. We introduce\na simple yet effective pure transformer model for autoregressive video\nprediction, utilizing continuous pixel-space representations for video\nprediction. Without the need for complex training strategies or latent\nfeature-learning components, our approach significantly extends the time\nhorizon for physically accurate predictions by up to 50% when compared with\nexisting latent-space approaches, while maintaining comparable performance on\ncommon video quality metrics. In addition, we conduct interpretability\nexperiments to identify network regions that encode information useful to\nperform accurate estimations of PDE simulation parameters via probing models,\nand find that this generalizes to the estimation of out-of-distribution\nsimulation parameters. This work serves as a platform for further\nattention-based spatiotemporal modeling of videos via a simple, parameter\nefficient, and interpretable approach.",
    "categories": [
      "cs.CV",
      "cs.LG"
    ],
    "published": "2025-10-23T17:58:45Z",
    "authors": [
      "Dean L Slack",
      "G Thomas Hudson",
      "Thomas Winterbottom",
      "Noura Al Moubayed"
    ],
    "pdf_url": "http://arxiv.org/pdf/2510.20807v1"
  },
  {
    "id": "2510.20800v1",
    "title": "Compress to Impress: Efficient LLM Adaptation Using a Single Gradient\n  Step on 100 Samples",
    "abstract": "Recently, Sharma et al. suggested a method called Layer-SElective-Rank\nreduction (LASER) which demonstrated that pruning high-order components of\ncarefully chosen LLM's weight matrices can boost downstream accuracy -- without\nany gradient-based fine-tuning. Yet LASER's exhaustive, per-matrix search (each\nrequiring full-dataset forward passes) makes it impractical for rapid\ndeployment. We demonstrate that this overhead can be removed and find that: (i)\nOnly a small, carefully chosen subset of matrices needs to be inspected --\neliminating the layer-by-layer sweep, (ii) The gradient of each matrix's\nsingular values pinpoints which matrices merit reduction, (iii) Increasing the\nfactorization search space by allowing matrices rows to cluster around multiple\nsubspaces and then decomposing each cluster separately further reduces\noverfitting on the original training data and further lifts accuracy by up to\n24.6 percentage points, and finally, (iv) we discover that evaluating on just\n100 samples rather than the full training data -- both for computing the\nindicative gradients and for measuring the final accuracy -- suffices to\nfurther reduce the search time; we explain that as adaptation to downstream\ntasks is dominated by prompting style, not dataset size. As a result, we show\nthat combining these findings yields a fast and robust adaptation algorithm for\ndownstream tasks. Overall, with a single gradient step on 100 examples and a\nquick scan of the top candidate layers and factorization techniques, we can\nadapt LLMs to new datasets -- entirely without fine-tuning.",
    "categories": [
      "cs.LG",
      "cs.AI",
      "cs.CL",
      "cs.CV"
    ],
    "published": "2025-10-23T17:58:01Z",
    "authors": [
      "Shiva Sreeram",
      "Alaa Maalouf",
      "Pratyusha Sharma",
      "Daniela Rus"
    ],
    "pdf_url": "http://arxiv.org/pdf/2510.20800v1"
  },
  {
    "id": "2510.20797v1",
    "title": "Simple Context Compression: Mean-Pooling and Multi-Ratio Training",
    "abstract": "A common strategy to reduce the computational costs of using long contexts in\nretrieval-augmented generation (RAG) with large language models (LLMs) is soft\ncontext compression, where the input sequence is transformed into a shorter\ncontinuous representation. We develop a lightweight and simple mean-pooling\napproach that consistently outperforms the widely used compression-tokens\narchitecture, and study training the same compressor to output multiple\ncompression ratios. We conduct extensive experiments across in-domain and\nout-of-domain QA datasets, as well as across model families, scales, and\ncompression ratios. Overall, our simple mean-pooling approach achieves the\nstrongest performance, with a relatively small drop when training for multiple\ncompression ratios. More broadly though, across architectures and training\nregimes the trade-offs are more nuanced, illustrating the complex landscape of\ncompression methods.",
    "categories": [
      "cs.CL",
      "cs.AI",
      "cs.LG"
    ],
    "published": "2025-10-23T17:57:23Z",
    "authors": [
      "Yair Feldman",
      "Yoav Artzi"
    ],
    "pdf_url": "http://arxiv.org/pdf/2510.20797v1"
  },
  {
    "id": "2510.20795v1",
    "title": "Bayesian Inference of Primordial Magnetic Field Parameters from CMB with\n  Spherical Graph Neural Networks",
    "abstract": "Deep learning has emerged as a transformative methodology in modern\ncosmology, providing powerful tools to extract meaningful physical information\nfrom complex astronomical datasets. This paper implements a novel Bayesian\ngraph deep learning framework for estimating key cosmological parameters in a\nprimordial magnetic field (PMF) cosmology directly from simulated Cosmic\nMicrowave Background (CMB) maps. Our methodology utilizes DeepSphere, a\nspherical convolutional neural network architecture specifically designed to\nrespect the spherical geometry of CMB data through HEALPix pixelization. To\nadvance beyond deterministic point estimates and enable robust uncertainty\nquantification, we integrate Bayesian Neural Networks (BNNs) into the\nframework, capturing aleatoric and epistemic uncertainties that reflect the\nmodel confidence in its predictions. The proposed approach demonstrates\nexceptional performance, achieving $R^{2}$ scores exceeding 0.89 for the\nmagnetic parameter estimation. We further obtain well-calibrated uncertainty\nestimates through post-hoc training techniques including Variance Scaling and\nGPNormal. This integrated DeepSphere-BNNs framework not only delivers accurate\nparameter estimation from CMB maps with PMF contributions but also provides\nreliable uncertainty quantification, providing the necessary tools for robust\ncosmological inference in the era of precision cosmology.",
    "categories": [
      "astro-ph.CO",
      "cs.AI",
      "cs.LG"
    ],
    "published": "2025-10-23T17:56:04Z",
    "authors": [
      "Juan Alejandro Pinto Castro",
      "H\u00e9ctor J. Hort\u00faa",
      "Jorge Enrique Garc\u00eda-Farieta",
      "Roger Anderson Hurtado"
    ],
    "pdf_url": "http://arxiv.org/pdf/2510.20795v1"
  },
  {
    "id": "2510.20792v1",
    "title": "BadGraph: A Backdoor Attack Against Latent Diffusion Model for\n  Text-Guided Graph Generation",
    "abstract": "The rapid progress of graph generation has raised new security concerns,\nparticularly regarding backdoor vulnerabilities. While prior work has explored\nbackdoor attacks in image diffusion and unconditional graph generation,\nconditional, especially text-guided graph generation remains largely\nunexamined. This paper proposes BadGraph, a backdoor attack method targeting\nlatent diffusion models for text-guided graph generation. BadGraph leverages\ntextual triggers to poison training data, covertly implanting backdoors that\ninduce attacker-specified subgraphs during inference when triggers appear,\nwhile preserving normal performance on clean inputs. Extensive experiments on\nfour benchmark datasets (PubChem, ChEBI-20, PCDes, MoMu) demonstrate the\neffectiveness and stealth of the attack: less than 10% poisoning rate can\nachieves 50% attack success rate, while 24% suffices for over 80% success rate,\nwith negligible performance degradation on benign samples. Ablation studies\nfurther reveal that the backdoor is implanted during VAE and diffusion training\nrather than pretraining. These findings reveal the security vulnerabilities in\nlatent diffusion models of text-guided graph generation, highlight the serious\nrisks in models' applications such as drug discovery and underscore the need\nfor robust defenses against the backdoor attack in such diffusion models.",
    "categories": [
      "cs.LG",
      "cs.CL",
      "q-bio.BM"
    ],
    "published": "2025-10-23T17:54:17Z",
    "authors": [
      "Liang Ye",
      "Shengqin Chen",
      "Jiazhu Dai"
    ],
    "pdf_url": "http://arxiv.org/pdf/2510.20792v1"
  },
  {
    "id": "2510.20787v2",
    "title": "Alleviating Forgetfulness of Linear Attention by Hybrid Sparse Attention\n  and Contextualized Learnable Token Eviction",
    "abstract": "Linear-attention models that compress the entire input sequence into a\nfixed-size recurrent state offer an efficient alternative to Transformers, but\ntheir finite memory induces forgetfulness that harms retrieval-intensive tasks.\nTo mitigate the issue, we explore a series of hybrid models that restore direct\naccess to past tokens. We interleave token mixers with intermediate time and\nspace complexity between linear and full attention, including sparse attention\nwith token eviction, and the query-aware native sparse attention. Particularly,\nwe propose a novel learnable token eviction approach. Combined with\nsliding-window attention, an end-to-end trainable lightweight CNN aggregates\ninformation from both past and future adjacent tokens to adaptively retain a\nlimited set of critical KV-pairs per head, maintaining linear attention's\nconstant time and space complexity. Efficient Triton kernels for the sparse\nattention mechanisms are provided. Empirical evaluations on retrieval-intensive\nbenchmarks support the effectiveness of our approaches.",
    "categories": [
      "cs.CL",
      "cs.LG"
    ],
    "published": "2025-10-23T17:53:03Z",
    "authors": [
      "Mutian He",
      "Philip N. Garner"
    ],
    "pdf_url": "http://arxiv.org/pdf/2510.20787v2"
  },
  {
    "id": "2510.20784v1",
    "title": "A Coherence-Based Measure of AGI",
    "abstract": "Recent work by \\citet{hendrycks2025agidefinition} formalized\n\\textit{Artificial General Intelligence} (AGI) as the arithmetic mean of\nproficiencies across cognitive domains derived from the Cattell--Horn--Carroll\n(CHC) model of human cognition. While elegant, this definition assumes\n\\textit{compensability} -- that exceptional ability in some domains can offset\nfailure in others. True general intelligence, however, should reflect\n\\textit{coherent sufficiency}: balanced competence across all essential\ndomains. We propose a coherence-aware measure of AGI based on the integral of\ngeneralized means over a continuum of compensability exponents. This\nformulation spans arithmetic, geometric, and harmonic regimes, and the\nresulting \\textit{area under the curve} (AUC) quantifies robustness under\nvarying compensability assumptions. Unlike the arithmetic mean, which rewards\nspecialization, the AUC penalizes imbalance and captures inter-domain\ndependency. Applied to published CHC-based domain scores for GPT-4 and GPT-5,\nthe coherence-adjusted AUC reveals that both systems remain far from general\ncompetence despite high arithmetic scores (e.g., GPT-5 at~24\\%). Integrating\nthe generalized mean thus yields a principled, interpretable, and stricter\nfoundation for measuring genuine progress toward AGI.",
    "categories": [
      "cs.AI",
      "cs.LG"
    ],
    "published": "2025-10-23T17:51:42Z",
    "authors": [
      "Fares Fourati"
    ],
    "pdf_url": "http://arxiv.org/pdf/2510.20784v1"
  },
  {
    "id": "2510.20783v1",
    "title": "Out-of-distribution Tests Reveal Compositionality in Chess Transformers",
    "abstract": "Chess is a canonical example of a task that requires rigorous reasoning and\nlong-term planning. Modern decision Transformers - trained similarly to LLMs -\nare able to learn competent gameplay, but it is unclear to what extent they\ntruly capture the rules of chess. To investigate this, we train a 270M\nparameter chess Transformer and test it on out-of-distribution scenarios,\ndesigned to reveal failures of systematic generalization. Our analysis shows\nthat Transformers exhibit compositional generalization, as evidenced by strong\nrule extrapolation: they adhere to fundamental syntactic rules of the game by\nconsistently choosing valid moves even in situations very different from the\ntraining data. Moreover, they also generate high-quality moves for OOD puzzles.\nIn a more challenging test, we evaluate the models on variants including\nChess960 (Fischer Random Chess) - a variant of chess where starting positions\nof pieces are randomized. We found that while the model exhibits basic strategy\nadaptation, they are inferior to symbolic AI algorithms that perform explicit\nsearch, but gap is smaller when playing against users on Lichess. Moreover, the\ntraining dynamics revealed that the model initially learns to move only its own\npieces, suggesting an emergent compositional understanding of the game.",
    "categories": [
      "cs.LG"
    ],
    "published": "2025-10-23T17:51:28Z",
    "authors": [
      "Anna M\u00e9sz\u00e1ros",
      "Patrik Reizinger",
      "Ferenc Husz\u00e1r"
    ],
    "pdf_url": "http://arxiv.org/pdf/2510.20783v1"
  },
  {
    "id": "2510.20771v1",
    "title": "AlphaFlow: Understanding and Improving MeanFlow Models",
    "abstract": "MeanFlow has recently emerged as a powerful framework for few-step generative\nmodeling trained from scratch, but its success is not yet fully understood. In\nthis work, we show that the MeanFlow objective naturally decomposes into two\nparts: trajectory flow matching and trajectory consistency. Through gradient\nanalysis, we find that these terms are strongly negatively correlated, causing\noptimization conflict and slow convergence. Motivated by these insights, we\nintroduce $\\alpha$-Flow, a broad family of objectives that unifies trajectory\nflow matching, Shortcut Model, and MeanFlow under one formulation. By adopting\na curriculum strategy that smoothly anneals from trajectory flow matching to\nMeanFlow, $\\alpha$-Flow disentangles the conflicting objectives, and achieves\nbetter convergence. When trained from scratch on class-conditional ImageNet-1K\n256x256 with vanilla DiT backbones, $\\alpha$-Flow consistently outperforms\nMeanFlow across scales and settings. Our largest $\\alpha$-Flow-XL/2+ model\nachieves new state-of-the-art results using vanilla DiT backbones, with FID\nscores of 2.58 (1-NFE) and 2.15 (2-NFE).",
    "categories": [
      "cs.CV",
      "cs.LG"
    ],
    "published": "2025-10-23T17:45:06Z",
    "authors": [
      "Huijie Zhang",
      "Aliaksandr Siarohin",
      "Willi Menapace",
      "Michael Vasilkovsky",
      "Sergey Tulyakov",
      "Qing Qu",
      "Ivan Skorokhodov"
    ],
    "pdf_url": "http://arxiv.org/pdf/2510.20771v1"
  },
  {
    "id": "2510.20769v1",
    "title": "CSU-PCAST: A Dual-Branch Transformer Framework for medium-range ensemble\n  Precipitation Forecasting",
    "abstract": "Accurate medium-range precipitation forecasting is crucial for\nhydrometeorological risk management and disaster mitigation, yet remains\nchallenging for current numerical weather prediction (NWP) systems. Traditional\nensemble systems such as the Global Ensemble Forecast System (GEFS) struggle to\nmaintain high skill, especially for moderate and heavy rainfall at extended\nlead times. This study develops a deep learning-based ensemble framework for\nmulti-step precipitation prediction through joint modeling of a comprehensive\nset of atmospheric variables. The model is trained on ERA5 reanalysis data at\n0.25$^{\\circ}$ spatial resolution, with precipitation labels from NASA's\nIntegrated Multi-satellite Retrievals for Global Precipitation Measurement\n(GPM) constellation (IMERG), incorporating 57 input variables, including\nupper-air and surface predictors. The architecture employs a patch-based Swin\nTransformer backbone with periodic convolutions to handle longitudinal\ncontinuity and integrates time and noise embeddings through conditional layer\nnormalization. A dual-branch decoder predicts total precipitation and other\nvariables, with targeted freezing of encoder-decoder pathways for specialized\ntraining. Training minimizes a hybrid loss combining the Continuous Ranked\nProbability Score (CRPS) and weighted log1p mean squared error (log1pMSE),\nbalancing probabilistic accuracy and magnitude fidelity. During inference, the\nmodel ingests real-time Global Forecast System (GFS) initial conditions to\ngenerate 15-day forecasts autoregressively. Evaluation against GEFS using IMERG\ndata demonstrates higher Critical Success Index (CSI) scores at precipitation\nthresholds of 0.1 mm, 1 mm, 10 mm, and 20 mm, highlighting improved performance\nfor moderate to heavy rainfall.",
    "categories": [
      "physics.ao-ph",
      "cs.LG"
    ],
    "published": "2025-10-23T17:43:38Z",
    "authors": [
      "Tianyi Xiong",
      "Haonan Chen"
    ],
    "pdf_url": "http://arxiv.org/pdf/2510.20769v1"
  },
  {
    "id": "2510.20884v1",
    "title": "ROPES: Robotic Pose Estimation via Score-Based Causal Representation\n  Learning",
    "abstract": "Causal representation learning (CRL) has emerged as a powerful unsupervised\nframework that (i) disentangles the latent generative factors underlying\nhigh-dimensional data, and (ii) learns the cause-and-effect interactions among\nthe disentangled variables. Despite extensive recent advances in\nidentifiability and some practical progress, a substantial gap remains between\ntheory and real-world practice. This paper takes a step toward closing that gap\nby bringing CRL to robotics, a domain that has motivated CRL. Specifically,\nthis paper addresses the well-defined robot pose estimation -- the recovery of\nposition and orientation from raw images -- by introducing Robotic Pose\nEstimation via Score-Based CRL (ROPES). Being an unsupervised framework, ROPES\nembodies the essence of interventional CRL by identifying those generative\nfactors that are actuated: images are generated by intrinsic and extrinsic\nlatent factors (e.g., joint angles, arm/limb geometry, lighting, background,\nand camera configuration) and the objective is to disentangle and recover the\ncontrollable latent variables, i.e., those that can be directly manipulated\n(intervened upon) through actuation. Interventional CRL theory shows that\nvariables that undergo variations via interventions can be identified. In\nrobotics, such interventions arise naturally by commanding actuators of various\njoints and recording images under varied controls. Empirical evaluations in\nsemi-synthetic manipulator experiments demonstrate that ROPES successfully\ndisentangles latent generative factors with high fidelity with respect to the\nground truth. Crucially, this is achieved by leveraging only distributional\nchanges, without using any labeled data. The paper also includes a comparison\nwith a baseline based on a recently proposed semi-supervised framework. This\npaper concludes by positioning robot pose estimation as a near-practical\ntestbed for CRL.",
    "categories": [
      "cs.RO",
      "cs.LG"
    ],
    "published": "2025-10-23T17:42:26Z",
    "authors": [
      "Pranamya Kulkarni",
      "Puranjay Datta",
      "Burak Var\u0131c\u0131",
      "Emre Acart\u00fcrk",
      "Karthikeyan Shanmugam",
      "Ali Tajer"
    ],
    "pdf_url": "http://arxiv.org/pdf/2510.20884v1"
  },
  {
    "id": "2510.20762v1",
    "title": "MEIcoder: Decoding Visual Stimuli from Neural Activity by Leveraging\n  Most Exciting Inputs",
    "abstract": "Decoding visual stimuli from neural population activity is crucial for\nunderstanding the brain and for applications in brain-machine interfaces.\nHowever, such biological data is often scarce, particularly in primates or\nhumans, where high-throughput recording techniques, such as two-photon imaging,\nremain challenging or impossible to apply. This, in turn, poses a challenge for\ndeep learning decoding techniques. To overcome this, we introduce MEIcoder, a\nbiologically informed decoding method that leverages neuron-specific most\nexciting inputs (MEIs), a structural similarity index measure loss, and\nadversarial training. MEIcoder achieves state-of-the-art performance in\nreconstructing visual stimuli from single-cell activity in primary visual\ncortex (V1), especially excelling on small datasets with fewer recorded\nneurons. Using ablation studies, we demonstrate that MEIs are the main drivers\nof the performance, and in scaling experiments, we show that MEIcoder can\nreconstruct high-fidelity natural-looking images from as few as 1,000-2,500\nneurons and less than 1,000 training data points. We also propose a unified\nbenchmark with over 160,000 samples to foster future research. Our results\ndemonstrate the feasibility of reliable decoding in early visual system and\nprovide practical insights for neuroscience and neuroengineering applications.",
    "categories": [
      "cs.LG",
      "cs.CV"
    ],
    "published": "2025-10-23T17:35:34Z",
    "authors": [
      "Jan Sobotka",
      "Luca Baroni",
      "J\u00e1n Antol\u00edk"
    ],
    "pdf_url": "http://arxiv.org/pdf/2510.20762v1"
  },
  {
    "id": "2510.20883v1",
    "title": "Kernel Learning with Adversarial Features: Numerical Efficiency and\n  Adaptive Regularization",
    "abstract": "Adversarial training has emerged as a key technique to enhance model\nrobustness against adversarial input perturbations. Many of the existing\nmethods rely on computationally expensive min-max problems that limit their\napplication in practice. We propose a novel formulation of adversarial training\nin reproducing kernel Hilbert spaces, shifting from input to feature-space\nperturbations. This reformulation enables the exact solution of inner\nmaximization and efficient optimization. It also provides a regularized\nestimator that naturally adapts to the noise level and the smoothness of the\nunderlying function. We establish conditions under which the feature-perturbed\nformulation is a relaxation of the original problem and propose an efficient\noptimization algorithm based on iterative kernel ridge regression. We provide\ngeneralization bounds that help to understand the properties of the method. We\nalso extend the formulation to multiple kernel learning. Empirical evaluation\nshows good performance in both clean and adversarial settings.",
    "categories": [
      "stat.ML",
      "cs.CR",
      "cs.LG",
      "math.OC"
    ],
    "published": "2025-10-23T17:34:51Z",
    "authors": [
      "Ant\u00f4nio H. Ribeiro",
      "David V\u00e4vinggren",
      "Dave Zachariah",
      "Thomas B. Sch\u00f6n",
      "Francis Bach"
    ],
    "pdf_url": "http://arxiv.org/pdf/2510.20883v1"
  },
  {
    "id": "2510.20748v1",
    "title": "Reinforcement Learning and Consumption-Savings Behavior",
    "abstract": "This paper demonstrates how reinforcement learning can explain two puzzling\nempirical patterns in household consumption behavior during economic downturns.\nI develop a model where agents use Q-learning with neural network approximation\nto make consumption-savings decisions under income uncertainty, departing from\nstandard rational expectations assumptions. The model replicates two key\nfindings from recent literature: (1) unemployed households with previously low\nliquid assets exhibit substantially higher marginal propensities to consume\n(MPCs) out of stimulus transfers compared to high-asset households (0.50 vs\n0.34), even when neither group faces borrowing constraints, consistent with\nGanong et al. (2024); and (2) households with more past unemployment\nexperiences maintain persistently lower consumption levels after controlling\nfor current economic conditions, a \"scarring\" effect documented by Malmendier\nand Shen (2024). Unlike existing explanations based on belief updating about\nincome risk or ex-ante heterogeneity, the reinforcement learning mechanism\ngenerates both higher MPCs and lower consumption levels simultaneously through\nvalue function approximation errors that evolve with experience. Simulation\nresults closely match the empirical estimates, suggesting that adaptive\nlearning through reinforcement learning provides a unifying framework for\nunderstanding how past experiences shape current consumption behavior beyond\nwhat current economic conditions would predict.",
    "categories": [
      "econ.GN",
      "cs.AI",
      "cs.LG",
      "q-fin.EC"
    ],
    "published": "2025-10-23T17:14:49Z",
    "authors": [
      "Brandon Kaplowitz"
    ],
    "pdf_url": "http://arxiv.org/pdf/2510.20748v1"
  },
  {
    "id": "2510.20739v1",
    "title": "Learning to Triage Taint Flows Reported by Dynamic Program Analysis in\n  Node.js Packages",
    "abstract": "Program analysis tools often produce large volumes of candidate vulnerability\nreports that require costly manual review, creating a practical challenge: how\ncan security analysts prioritize the reports most likely to be true\nvulnerabilities?\n  This paper investigates whether machine learning can be applied to\nprioritizing vulnerabilities reported by program analysis tools. We focus on\nNode.js packages and collect a benchmark of 1,883 Node.js packages, each\ncontaining one reported ACE or ACI vulnerability. We evaluate a variety of\nmachine learning approaches, including classical models, graph neural networks\n(GNNs), large language models (LLMs), and hybrid models that combine GNN and\nLLMs, trained on data based on a dynamic program analysis tool's output. The\ntop LLM achieves $F_{1} {=} 0.915$, while the best GNN and classical ML models\nreaching $F_{1} {=} 0.904$. At a less than 7% false-negative rate, the leading\nmodel eliminates 66.9% of benign packages from manual review, taking around 60\nms per package. If the best model is tuned to operate at a precision level of\n0.8 (i.e., allowing 20% false positives amongst all warnings), our approach can\ndetect 99.2% of exploitable taint flows while missing only 0.8%, demonstrating\nstrong potential for real-world vulnerability triage.",
    "categories": [
      "cs.CR",
      "cs.LG",
      "cs.SE"
    ],
    "published": "2025-10-23T16:58:02Z",
    "authors": [
      "Ronghao Ni",
      "Aidan Z. H. Yang",
      "Min-Chien Hsu",
      "Nuno Sabino",
      "Limin Jia",
      "Ruben Martins",
      "Darion Cassel",
      "Kevin Cheang"
    ],
    "pdf_url": "http://arxiv.org/pdf/2510.20739v1"
  },
  {
    "id": "2510.20736v1",
    "title": "Amplifying Prominent Representations in Multimodal Learning via\n  Variational Dirichlet Process",
    "abstract": "Developing effective multimodal fusion approaches has become increasingly\nessential in many real-world scenarios, such as health care and finance. The\nkey challenge is how to preserve the feature expressiveness in each modality\nwhile learning cross-modal interactions. Previous approaches primarily focus on\nthe cross-modal alignment, while over-emphasis on the alignment of marginal\ndistributions of modalities may impose excess regularization and obstruct\nmeaningful representations within each modality. The Dirichlet process (DP)\nmixture model is a powerful Bayesian non-parametric method that can amplify the\nmost prominent features by its richer-gets-richer property, which allocates\nincreasing weights to them. Inspired by this unique characteristic of DP, we\npropose a new DP-driven multimodal learning framework that automatically\nachieves an optimal balance between prominent intra-modal representation\nlearning and cross-modal alignment. Specifically, we assume that each modality\nfollows a mixture of multivariate Gaussian distributions and further adopt DP\nto calculate the mixture weights for all the components. This paradigm allows\nDP to dynamically allocate the contributions of features and select the most\nprominent ones, leveraging its richer-gets-richer property, thus facilitating\nmultimodal feature fusion. Extensive experiments on several multimodal datasets\ndemonstrate the superior performance of our model over other competitors.\nAblation analysis further validates the effectiveness of DP in aligning\nmodality distributions and its robustness to changes in key hyperparameters.\nCode is anonymously available at https://github.com/HKU-MedAI/DPMM.git",
    "categories": [
      "cs.LG"
    ],
    "published": "2025-10-23T16:53:24Z",
    "authors": [
      "Tsai Hor Chan",
      "Feng Wu",
      "Yihang Chen",
      "Guosheng Yin",
      "Lequan Yu"
    ],
    "pdf_url": "http://arxiv.org/pdf/2510.20736v1"
  },
  {
    "id": "2510.23622v1",
    "title": "Adversarially-Aware Architecture Design for Robust Medical AI Systems",
    "abstract": "Adversarial attacks pose a severe risk to AI systems used in healthcare,\ncapable of misleading models into dangerous misclassifications that can delay\ntreatments or cause misdiagnoses. These attacks, often imperceptible to human\nperception, threaten patient safety, particularly in underserved populations.\nOur study explores these vulnerabilities through empirical experimentation on a\ndermatological dataset, where adversarial methods significantly reduce\nclassification accuracy. Through detailed threat modeling, experimental\nbenchmarking, and model evaluation, we demonstrate both the severity of the\nthreat and the partial success of defenses like adversarial training and\ndistillation. Our results show that while defenses reduce attack success rates,\nthey must be balanced against model performance on clean data. We conclude with\na call for integrated technical, ethical, and policy-based approaches to build\nmore resilient, equitable AI in healthcare.",
    "categories": [
      "cs.LG",
      "cs.CR"
    ],
    "published": "2025-10-23T16:51:11Z",
    "authors": [
      "Alyssa Gerhart",
      "Balaji Iyangar"
    ],
    "pdf_url": "http://arxiv.org/pdf/2510.23622v1"
  },
  {
    "id": "2510.20733v1",
    "title": "Thought Communication in Multiagent Collaboration",
    "abstract": "Natural language has long enabled human cooperation, but its lossy,\nambiguous, and indirect nature limits the potential of collective intelligence.\nWhile machines are not subject to these constraints, most LLM-based multi-agent\nsystems still rely solely on natural language, exchanging tokens or their\nembeddings. To go beyond language, we introduce a new paradigm, thought\ncommunication, which enables agents to interact directly mind-to-mind, akin to\ntelepathy. To uncover these latent thoughts in a principled way, we formalize\nthe process as a general latent variable model, where agent states are\ngenerated by an unknown function of underlying thoughts. We prove that, in a\nnonparametric setting without auxiliary information, both shared and private\nlatent thoughts between any pair of agents can be identified. Moreover, the\nglobal structure of thought sharing, including which agents share which\nthoughts and how these relationships are structured, can also be recovered with\ntheoretical guarantees. Guided by the established theory, we develop a\nframework that extracts latent thoughts from all agents prior to communication\nand assigns each agent the relevant thoughts, along with their sharing\npatterns. This paradigm naturally extends beyond LLMs to all modalities, as\nmost observational data arise from hidden generative processes. Experiments on\nboth synthetic and real-world benchmarks validate the theory and demonstrate\nthe collaborative advantages of thought communication. We hope this work\nilluminates the potential of leveraging the hidden world, as many challenges\nremain unsolvable through surface-level observation alone, regardless of\ncompute or data scale.",
    "categories": [
      "cs.LG",
      "cs.AI",
      "cs.MA"
    ],
    "published": "2025-10-23T16:48:02Z",
    "authors": [
      "Yujia Zheng",
      "Zhuokai Zhao",
      "Zijian Li",
      "Yaqi Xie",
      "Mingze Gao",
      "Lizhu Zhang",
      "Kun Zhang"
    ],
    "pdf_url": "http://arxiv.org/pdf/2510.20733v1"
  },
  {
    "id": "2510.20725v1",
    "title": "No-Regret Thompson Sampling for Finite-Horizon Markov Decision Processes\n  with Gaussian Processes",
    "abstract": "Thompson sampling (TS) is a powerful and widely used strategy for sequential\ndecision-making, with applications ranging from Bayesian optimization to\nreinforcement learning (RL). Despite its success, the theoretical foundations\nof TS remain limited, particularly in settings with complex temporal structure\nsuch as RL. We address this gap by establishing no-regret guarantees for TS\nusing models with Gaussian marginal distributions. Specifically, we consider TS\nin episodic RL with joint Gaussian process (GP) priors over rewards and\ntransitions. We prove a regret bound of\n$\\mathcal{\\tilde{O}}(\\sqrt{KH\\Gamma(KH)})$ over $K$ episodes of horizon $H$,\nwhere $\\Gamma(\\cdot)$ captures the complexity of the GP model. Our analysis\naddresses several challenges, including the non-Gaussian nature of value\nfunctions and the recursive structure of Bellman updates, and extends classical\ntools such as the elliptical potential lemma to multi-output settings. This\nwork advances the understanding of TS in RL and highlights how structural\nassumptions and model uncertainty shape its performance in finite-horizon\nMarkov Decision Processes.",
    "categories": [
      "cs.LG"
    ],
    "published": "2025-10-23T16:44:31Z",
    "authors": [
      "Jasmine Bayrooti",
      "Sattar Vakili",
      "Amanda Prorok",
      "Carl Henrik Ek"
    ],
    "pdf_url": "http://arxiv.org/pdf/2510.20725v1"
  },
  {
    "id": "2510.20718v1",
    "title": "Unsupervised Anomaly Prediction with N-BEATS and Graph Neural Network in\n  Multi-variate Semiconductor Process Time Series",
    "abstract": "Semiconductor manufacturing is an extremely complex and precision-driven\nprocess, characterized by thousands of interdependent parameters collected\nacross diverse tools and process steps. Multi-variate time-series analysis has\nemerged as a critical field for real-time monitoring and fault detection in\nsuch environments. However, anomaly prediction in semiconductor fabrication\npresents several critical challenges, including high dimensionality of sensor\ndata and severe class imbalance due to the rarity of true faults. Furthermore,\nthe complex interdependencies between variables complicate both anomaly\nprediction and root-cause-analysis. This paper proposes two novel approaches to\nadvance the field from anomaly detection to anomaly prediction, an essential\nstep toward enabling real-time process correction and proactive fault\nprevention. The proposed anomaly prediction framework contains two main stages:\n(a) training a forecasting model on a dataset assumed to contain no anomalies,\nand (b) performing forecast on unseen time series data. The forecast is\ncompared with the forecast of the trained signal. Deviations beyond a\npredefined threshold are flagged as anomalies. The two approaches differ in the\nforecasting model employed. The first assumes independence between variables by\nutilizing the N-BEATS model for univariate time series forecasting. The second\nlifts this assumption by utilizing a Graph Neural Network (GNN) to capture\ninter-variable relationships. Both models demonstrate strong forecasting\nperformance up to a horizon of 20 time points and maintain stable anomaly\nprediction up to 50 time points. The GNN consistently outperforms the N-BEATS\nmodel while requiring significantly fewer trainable parameters and lower\ncomputational cost. These results position the GNN as promising solution for\nonline anomaly forecasting to be deployed in manufacturing environments.",
    "categories": [
      "cs.LG",
      "cs.AI",
      "I.2.0; J.6"
    ],
    "published": "2025-10-23T16:33:52Z",
    "authors": [
      "Daniel Sorensen",
      "Bappaditya Dey",
      "Minjin Hwang",
      "Sandip Halder"
    ],
    "pdf_url": "http://arxiv.org/pdf/2510.20718v1"
  },
  {
    "id": "2510.20714v1",
    "title": "Optimizing Clinical Fall Risk Prediction: A Data-Driven Integration of\n  EHR Variables with the Johns Hopkins Fall Risk Assessment Tool",
    "abstract": "In this study we aim to better align fall risk prediction from the Johns\nHopkins Fall Risk Assessment Tool (JHFRAT) with additional clinically\nmeaningful measures via a data-driven modelling approach. We conducted a\nretrospective analysis of 54,209 inpatient admissions from three Johns Hopkins\nHealth System hospitals between March 2022 and October 2023. A total of 20,208\nadmissions were included as high fall risk encounters, and 13,941 were included\nas low fall risk encounters. To incorporate clinical knowledge and maintain\ninterpretability, we employed constrained score optimization (CSO) models on\nJHFRAT assessment data and additional electronic health record (EHR) variables.\nThe model demonstrated significant improvements in predictive performance over\nthe current JHFRAT (CSO AUC-ROC=0.91, JHFRAT AUC-ROC=0.86). The constrained\nscore optimization models performed similarly with and without the EHR\nvariables. Although the benchmark black-box model (XGBoost), improves upon the\nperformance metrics of the knowledge-based constrained logistic regression\n(AUC-ROC=0.94), the CSO demonstrates more robustness to variations in risk\nlabelling. This evidence-based approach provides a robust foundation for health\nsystems to systematically enhance inpatient fall prevention protocols and\npatient safety using data-driven optimization techniques, contributing to\nimproved risk assessment and resource allocation in healthcare settings.",
    "categories": [
      "cs.LG"
    ],
    "published": "2025-10-23T16:31:09Z",
    "authors": [
      "Fardin Ganjkhanloo",
      "Emmett Springer",
      "Erik H. Hoyer",
      "Daniel L. Young",
      "Kimia Ghobadi"
    ],
    "pdf_url": "http://arxiv.org/pdf/2510.20714v1"
  },
  {
    "id": "2510.20709v1",
    "title": "Separating the what and how of compositional computation to enable reuse\n  and continual learning",
    "abstract": "The ability to continually learn, retain and deploy skills to accomplish\ngoals is a key feature of intelligent and efficient behavior. However, the\nneural mechanisms facilitating the continual learning and flexible\n(re-)composition of skills remain elusive. Here, we study continual learning\nand the compositional reuse of learned computations in recurrent neural network\n(RNN) models using a novel two-system approach: one system that infers what\ncomputation to perform, and one that implements how to perform it. We focus on\na set of compositional cognitive tasks commonly studied in neuroscience. To\nconstruct the what system, we first show that a large family of tasks can be\nsystematically described by a probabilistic generative model, where\ncompositionality stems from a shared underlying vocabulary of discrete task\nepochs. The shared epoch structure makes these tasks inherently compositional.\nWe first show that this compositionality can be systematically described by a\nprobabilistic generative model. Furthermore, We develop an unsupervised online\nlearning approach that can learn this model on a single-trial basis, building\nits vocabulary incrementally as it is exposed to new tasks, and inferring the\nlatent epoch structure as a time-varying computational context within a trial.\nWe implement the how system as an RNN whose low-rank components are composed\naccording to the context inferred by the what system. Contextual inference\nfacilitates the creation, learning, and reuse of low-rank RNN components as new\ntasks are introduced sequentially, enabling continual learning without\ncatastrophic forgetting. Using an example task set, we demonstrate the efficacy\nand competitive performance of this two-system learning framework, its\npotential for forward and backward transfer, as well as fast compositional\ngeneralization to unseen tasks.",
    "categories": [
      "cs.LG",
      "q-bio.NC"
    ],
    "published": "2025-10-23T16:24:40Z",
    "authors": [
      "Haozhe Shan",
      "Sun Minni",
      "Lea Duncker"
    ],
    "pdf_url": "http://arxiv.org/pdf/2510.20709v1"
  },
  {
    "id": "2510.20690v1",
    "title": "Neural Diversity Regularizes Hallucinations in Small Models",
    "abstract": "Language models continue to hallucinate despite increases in parameters,\ncompute, and data. We propose neural diversity -- decorrelated parallel\nrepresentations -- as a principled mechanism that reduces hallucination rates\nat fixed parameter and data budgets. Inspired by portfolio theory, where\nuncorrelated assets reduce risk by $\\sqrt{P}$, we prove hallucination\nprobability is bounded by representational correlation: $P(H) \\leq\nf(\\sigma^2((1-\\rho(P))/P + \\rho(P)), \\mu^2)$, which predicts that language\nmodels need an optimal amount of neurodiversity. To validate this, we introduce\nND-LoRA (Neural Diversity Low-Rank Adaptation), combining parallel LoRA\nadapters with Barlow Twins regularization, and demonstrate that ND-LoRA reduces\nhallucinations by up to 25.6% (and 14.6% on average) without degrading general\naccuracy. Ablations show LoRA adapters and regularization act synergistically,\ncausal interventions prove neurodiversity as the mediating factor and\ncorrelational analyses indicate scale: a 0.1% neural correlation increase is\nassociated with a 3.8% hallucination increase. Finally, task-dependent\noptimality emerges: different tasks require different amounts of optimal\nneurodiversity. Together, our results highlight neural diversity as a third\naxis of scaling -- orthogonal to parameters and data -- to improve the\nreliability of language models at fixed budgets.",
    "categories": [
      "cs.CL",
      "cs.AI",
      "cs.LG"
    ],
    "published": "2025-10-23T16:03:07Z",
    "authors": [
      "Kushal Chakrabarti",
      "Nirmal Balachundhar"
    ],
    "pdf_url": "http://arxiv.org/pdf/2510.20690v1"
  },
  {
    "id": "2510.20683v1",
    "title": "A Scalable, Causal, and Energy Efficient Framework for Neural Decoding\n  with Spiking Neural Networks",
    "abstract": "Brain-computer interfaces (BCIs) promise to enable vital functions, such as\nspeech and prosthetic control, for individuals with neuromotor impairments.\nCentral to their success are neural decoders, models that map neural activity\nto intended behavior. Current learning-based decoding approaches fall into two\nclasses: simple, causal models that lack generalization, or complex, non-causal\nmodels that generalize and scale offline but struggle in real-time settings.\nBoth face a common challenge, their reliance on power-hungry artificial neural\nnetwork backbones, which makes integration into real-world, resource-limited\nsystems difficult. Spiking neural networks (SNNs) offer a promising\nalternative. Because they operate causally these models are suitable for\nreal-time use, and their low energy demands make them ideal for\nbattery-constrained environments. To this end, we introduce Spikachu: a\nscalable, causal, and energy-efficient neural decoding framework based on SNNs.\nOur approach processes binned spikes directly by projecting them into a shared\nlatent space, where spiking modules, adapted to the timing of the input,\nextract relevant features; these latent representations are then integrated and\ndecoded to generate behavioral predictions. We evaluate our approach on 113\nrecording sessions from 6 non-human primates, totaling 43 hours of recordings.\nOur method outperforms causal baselines when trained on single sessions using\nbetween 2.26 and 418.81 times less energy. Furthermore, we demonstrate that\nscaling up training to multiple sessions and subjects improves performance and\nenables few-shot transfer to unseen sessions, subjects, and tasks. Overall,\nSpikachu introduces a scalable, online-compatible neural decoding framework\nbased on SNNs, whose performance is competitive relative to state-of-the-art\nmodels while consuming orders of magnitude less energy.",
    "categories": [
      "cs.LG",
      "cs.AI"
    ],
    "published": "2025-10-23T15:55:45Z",
    "authors": [
      "Georgios Mentzelopoulos",
      "Ioannis Asmanis",
      "Konrad P. Kording",
      "Eva L. Dyer",
      "Kostas Daniilidis",
      "Flavia Vitale"
    ],
    "pdf_url": "http://arxiv.org/pdf/2510.20683v1"
  },
  {
    "id": "2510.20673v1",
    "title": "Efficient Multi-bit Quantization Network Training via Weight Bias\n  Correction and Bit-wise Coreset Sampling",
    "abstract": "Multi-bit quantization networks enable flexible deployment of deep neural\nnetworks by supporting multiple precision levels within a single model.\nHowever, existing approaches suffer from significant training overhead as\nfull-dataset updates are repeated for each supported bit-width, resulting in a\ncost that scales linearly with the number of precisions. Additionally, extra\nfine-tuning stages are often required to support additional or intermediate\nprecision options, further compounding the overall training burden. To address\nthis issue, we propose two techniques that greatly reduce the training overhead\nwithout compromising model utility: (i) Weight bias correction enables shared\nbatch normalization and eliminates the need for fine-tuning by neutralizing\nquantization-induced bias across bit-widths and aligning activation\ndistributions; and (ii) Bit-wise coreset sampling strategy allows each child\nmodel to train on a compact, informative subset selected via gradient-based\nimportance scores by exploiting the implicit knowledge transfer phenomenon.\nExperiments on CIFAR-10/100, TinyImageNet, and ImageNet-1K with both ResNet and\nViT architectures demonstrate that our method achieves competitive or superior\naccuracy while reducing training time up to 7.88x. Our code is released at\nhttps://github.com/a2jinhee/EMQNet_jk.",
    "categories": [
      "cs.CV",
      "cs.LG"
    ],
    "published": "2025-10-23T15:49:02Z",
    "authors": [
      "Jinhee Kim",
      "Jae Jun An",
      "Kang Eun Jeon",
      "Jong Hwan Ko"
    ],
    "pdf_url": "http://arxiv.org/pdf/2510.20673v1"
  },
  {
    "id": "2510.20671v1",
    "title": "GRACE: GRaph-based Addiction Care prEdiction",
    "abstract": "Determining the appropriate locus of care for addiction patients is one of\nthe most critical clinical decisions that affects patient treatment outcomes\nand effective use of resources. With a lack of sufficient specialized treatment\nresources, such as inpatient beds or staff, there is an unmet need to develop\nan automated framework for the same. Current decision-making approaches suffer\nfrom severe class imbalances in addiction datasets. To address this limitation,\nwe propose a novel graph neural network (GRACE) framework that formalizes locus\nof care prediction as a structured learning problem. Further, we perform\nextensive feature engineering and propose a new approach of obtaining an\nunbiased meta-graph to train a GNN to overcome the class imbalance problem.\nExperimental results in real-world data show an improvement of 11-35% in terms\nof the F1 score of the minority class over competitive baselines. The codes and\nnote embeddings are available at https://anonymous.4open.science/r/GRACE-F8E1/.",
    "categories": [
      "cs.LG",
      "cs.AI"
    ],
    "published": "2025-10-23T15:48:01Z",
    "authors": [
      "Subham Kumar",
      "Prakrithi Shivaprakash",
      "Koustav Rudra",
      "Lekhansh Shukla",
      "Animesh Mukherjee"
    ],
    "pdf_url": "http://arxiv.org/pdf/2510.20671v1"
  },
  {
    "id": "2510.20668v1",
    "title": "From Masks to Worlds: A Hitchhiker's Guide to World Models",
    "abstract": "This is not a typical survey of world models; it is a guide for those who\nwant to build worlds. We do not aim to catalog every paper that has ever\nmentioned a ``world model\". Instead, we follow one clear road: from early\nmasked models that unified representation learning across modalities, to\nunified architectures that share a single paradigm, then to interactive\ngenerative models that close the action-perception loop, and finally to\nmemory-augmented systems that sustain consistent worlds over time. We bypass\nloosely related branches to focus on the core: the generative heart, the\ninteractive loop, and the memory system. We show that this is the most\npromising path towards true world models.",
    "categories": [
      "cs.LG"
    ],
    "published": "2025-10-23T15:46:44Z",
    "authors": [
      "Jinbin Bai",
      "Yu Lei",
      "Hecong Wu",
      "Yuchen Zhu",
      "Shufan Li",
      "Yi Xin",
      "Xiangtai Li",
      "Molei Tao",
      "Aditya Grover",
      "Ming-Hsuan Yang"
    ],
    "pdf_url": "http://arxiv.org/pdf/2510.20668v1"
  },
  {
    "id": "2510.20666v1",
    "title": "Bayesian Jammer Localization with a Hybrid CNN and Path-Loss Mixture of\n  Experts",
    "abstract": "Global Navigation Satellite System (GNSS) signals are vulnerable to jamming,\nparticularly in urban areas where multipath and shadowing distort received\npower. Previous data-driven approaches achieved reasonable localization but\npoorly reconstructed the received signal strength (RSS) field due to limited\nspatial context. We propose a hybrid Bayesian mixture-of-experts framework that\nfuses a physical path-loss (PL) model and a convolutional neural network (CNN)\nthrough log-linear pooling. The PL expert ensures physical consistency, while\nthe CNN leverages building-height maps to capture urban propagation effects.\nBayesian inference with Laplace approximation provides posterior uncertainty\nover both the jammer position and RSS field. Experiments on urban ray-tracing\ndata show that localization accuracy improves and uncertainty decreases with\nmore training points, while uncertainty concentrates near the jammer and along\nurban canyons where propagation is most sensitive.",
    "categories": [
      "cs.LG",
      "eess.SP",
      "68T05, 68T07, 62F15, 94A12"
    ],
    "published": "2025-10-23T15:45:45Z",
    "authors": [
      "Mariona Jaramillo-Civill",
      "Luis Gonz\u00e1lez-Gudi\u00f1o",
      "Tales Imbiriba",
      "Pau Closas"
    ],
    "pdf_url": "http://arxiv.org/pdf/2510.20666v1"
  },
  {
    "id": "2510.20653v1",
    "title": "Finding the Sweet Spot: Trading Quality, Cost, and Speed During\n  Inference-Time LLM Reflection",
    "abstract": "As Large Language Models (LLMs) continue to evolve, practitioners face\nincreasing options for enhancing inference-time performance without model\nretraining, including budget tuning and multi-step techniques like\nself-reflection. While these methods improve output quality, they create\ncomplex trade-offs among accuracy, cost, and latency that remain poorly\nunderstood across different domains. This paper systematically compares\nself-reflection and budget tuning across mathematical reasoning and translation\ntasks. We evaluate prominent LLMs, including Anthropic Claude, Amazon Nova, and\nMistral families, along with other models under varying reflection depths and\ncompute budgets to derive Pareto optimal performance frontiers. Our analysis\nreveals substantial domain dependent variation in self-reflection\neffectiveness, with performance gains up to 220\\% in mathematical reasoning. We\nfurther investigate how reflection round depth and feedback mechanism quality\ninfluence performance across model families. To validate our findings in a\nreal-world setting, we deploy a self-reflection enhanced marketing content\nlocalisation system at Lounge by Zalando, where it shows market-dependent\neffectiveness, reinforcing the importance of domain specific evaluation when\ndeploying these techniques. Our results provide actionable guidance for\nselecting optimal inference strategies given specific domains and resource\nconstraints. We open source our self-reflection implementation for\nreproducibility at\nhttps://github.com/aws-samples/sample-genai-reflection-for-bedrock.",
    "categories": [
      "stat.ML",
      "cs.AI",
      "cs.LG"
    ],
    "published": "2025-10-23T15:26:18Z",
    "authors": [
      "Jack Butler",
      "Nikita Kozodoi",
      "Zainab Afolabi",
      "Brian Tyacke",
      "Gaiar Baimuratov"
    ],
    "pdf_url": "http://arxiv.org/pdf/2510.20653v1"
  },
  {
    "id": "2510.20651v1",
    "title": "xTime: Extreme Event Prediction with Hierarchical Knowledge Distillation\n  and Expert Fusion",
    "abstract": "Extreme events frequently occur in real-world time series and often carry\nsignificant practical implications. In domains such as climate and healthcare,\nthese events, such as floods, heatwaves, or acute medical episodes, can lead to\nserious consequences. Accurate forecasting of such events is therefore of\nsubstantial importance. Most existing time series forecasting models are\noptimized for overall performance within the prediction window, but often\nstruggle to accurately predict extreme events, such as high temperatures or\nheart rate spikes. The main challenges are data imbalance and the neglect of\nvaluable information contained in intermediate events that precede extreme\nevents. In this paper, we propose xTime, a novel framework for extreme event\nforecasting in time series. xTime leverages knowledge distillation to transfer\ninformation from models trained on lower-rarity events, thereby improving\nprediction performance on rarer ones. In addition, we introduce a mixture of\nexperts (MoE) mechanism that dynamically selects and fuses outputs from expert\nmodels across different rarity levels, which further improves the forecasting\nperformance for extreme events. Experiments on multiple datasets show that\nxTime achieves consistent improvements, with forecasting accuracy on extreme\nevents improving from 3% to 78%.",
    "categories": [
      "cs.LG"
    ],
    "published": "2025-10-23T15:24:45Z",
    "authors": [
      "Quan Li",
      "Wenchao Yu",
      "Suhang Wang",
      "Minhua Lin",
      "Lingwei Chen",
      "Wei Cheng",
      "Haifeng Chen"
    ],
    "pdf_url": "http://arxiv.org/pdf/2510.20651v1"
  },
  {
    "id": "2510.20644v1",
    "title": "Connecting Jensen-Shannon and Kullback-Leibler Divergences: A New Bound\n  for Representation Learning",
    "abstract": "Mutual Information (MI) is a fundamental measure of statistical dependence\nwidely used in representation learning. While direct optimization of MI via its\ndefinition as a Kullback-Leibler divergence (KLD) is often intractable, many\nrecent methods have instead maximized alternative dependence measures, most\nnotably, the Jensen-Shannon divergence (JSD) between joint and product of\nmarginal distributions via discriminative losses. However, the connection\nbetween these surrogate objectives and MI remains poorly understood. In this\nwork, we bridge this gap by deriving a new, tight, and tractable lower bound on\nKLD as a function of JSD in the general case. By specializing this bound to\njoint and marginal distributions, we demonstrate that maximizing the JSD-based\ninformation increases a guaranteed lower bound on mutual information.\nFurthermore, we revisit the practical implementation of JSD-based objectives\nand observe that minimizing the cross-entropy loss of a binary classifier\ntrained to distinguish joint from marginal pairs recovers a known variational\nlower bound on the JSD. Extensive experiments demonstrate that our lower bound\nis tight when applied to MI estimation. We compared our lower bound to\nstate-of-the-art neural estimators of variational lower bound across a range of\nestablished reference scenarios. Our lower bound estimator consistently\nprovides a stable, low-variance estimate of a tight lower bound on MI. We also\ndemonstrate its practical usefulness in the context of the Information\nBottleneck framework. Taken together, our results provide new theoretical\njustifications and strong empirical evidence for using discriminative learning\nin MI-based representation learning.",
    "categories": [
      "cs.LG",
      "cs.IT",
      "math.IT"
    ],
    "published": "2025-10-23T15:18:12Z",
    "authors": [
      "Reuben Dorent",
      "Polina Golland",
      "William Wells III"
    ],
    "pdf_url": "http://arxiv.org/pdf/2510.20644v1"
  },
  {
    "id": "2510.20640v1",
    "title": "Attention Enhanced Entity Recommendation for Intelligent Monitoring in\n  Cloud Systems",
    "abstract": "In this paper, we present DiRecGNN, an attention-enhanced entity\nrecommendation framework for monitoring cloud services at Microsoft. We provide\ninsights on the usefulness of this feature as perceived by the cloud service\nowners and lessons learned from deployment. Specifically, we introduce the\nproblem of recommending the optimal subset of attributes (dimensions) that\nshould be tracked by an automated watchdog (monitor) for cloud services. To\nbegin, we construct the monitor heterogeneous graph at production-scale. The\ninteraction dynamics of these entities are often characterized by limited\nstructural and engagement information, resulting in inferior performance of\nstate-of-the-art approaches. Moreover, traditional methods fail to capture the\ndependencies between entities spanning a long range due to their homophilic\nnature. Therefore, we propose an attention-enhanced entity ranking model\ninspired by transformer architectures. Our model utilizes a multi-head\nattention mechanism to focus on heterogeneous neighbors and their attributes,\nand further attends to paths sampled using random walks to capture long-range\ndependencies. We also employ multi-faceted loss functions to optimize for\nrelevant recommendations while respecting the inherent sparsity of the data.\nEmpirical evaluations demonstrate significant improvements over existing\nmethods, with our model achieving a 43.1% increase in MRR. Furthermore, product\nteams who consumed these features perceive the feature as useful and rated it\n4.5 out of 5.",
    "categories": [
      "cs.LG"
    ],
    "published": "2025-10-23T15:14:09Z",
    "authors": [
      "Fiza Hussain",
      "Anson Bastos",
      "Anjaly Parayil",
      "Ayush Choure",
      "Chetan Bansal",
      "Rujia Wang",
      "Saravan Rajmohan"
    ],
    "pdf_url": "http://arxiv.org/pdf/2510.20640v1"
  },
  {
    "id": "2510.20637v1",
    "title": "Large Multimodal Models-Empowered Task-Oriented Autonomous\n  Communications: Design Methodology and Implementation Challenges",
    "abstract": "Large language models (LLMs) and large multimodal models (LMMs) have achieved\nunprecedented breakthrough, showcasing remarkable capabilities in natural\nlanguage understanding, generation, and complex reasoning. This transformative\npotential has positioned them as key enablers for 6G autonomous communications\namong machines, vehicles, and humanoids. In this article, we provide an\noverview of task-oriented autonomous communications with LLMs/LMMs, focusing on\nmultimodal sensing integration, adaptive reconfiguration, and\nprompt/fine-tuning strategies for wireless tasks. We demonstrate the framework\nthrough three case studies: LMM-based traffic control, LLM-based robot\nscheduling, and LMM-based environment-aware channel estimation. From\nexperimental results, we show that the proposed LLM/LMM-aided autonomous\nsystems significantly outperform conventional and discriminative deep learning\n(DL) model-based techniques, maintaining robustness under dynamic objectives,\nvarying input parameters, and heterogeneous multimodal conditions where\nconventional static optimization degrades.",
    "categories": [
      "cs.LG"
    ],
    "published": "2025-10-23T15:08:58Z",
    "authors": [
      "Hyun Jong Yang",
      "Hyunsoo Kim",
      "Hyeonho Noh",
      "Seungnyun Kim",
      "Byonghyo Shim"
    ],
    "pdf_url": "http://arxiv.org/pdf/2510.20637v1"
  },
  {
    "id": "2510.20629v1",
    "title": "Equitable Survival Prediction: A Fairness-Aware Survival Modeling (FASM)\n  Approach",
    "abstract": "As machine learning models become increasingly integrated into healthcare,\nstructural inequities and social biases embedded in clinical data can be\nperpetuated or even amplified by data-driven models. In survival analysis,\ncensoring and time dynamics can further add complexity to fair model\ndevelopment. Additionally, algorithmic fairness approaches often overlook\ndisparities in cross-group rankings, e.g., high-risk Black patients may be\nranked below lower-risk White patients who do not experience the event of\nmortality. Such misranking can reinforce biological essentialism and undermine\nequitable care. We propose a Fairness-Aware Survival Modeling (FASM), designed\nto mitigate algorithmic bias regarding both intra-group and cross-group risk\nrankings over time. Using breast cancer prognosis as a representative case and\napplying FASM to SEER breast cancer data, we show that FASM substantially\nimproves fairness while preserving discrimination performance comparable to\nfairness-unaware survival models. Time-stratified evaluations show that FASM\nmaintains stable fairness over a 10-year horizon, with the greatest\nimprovements observed during the mid-term of follow-up. Our approach enables\nthe development of survival models that prioritize both accuracy and equity in\nclinical decision-making, advancing fairness as a core principle in clinical\ncare.",
    "categories": [
      "cs.LG",
      "cs.AI"
    ],
    "published": "2025-10-23T15:03:27Z",
    "authors": [
      "Mingxuan Liu",
      "Yilin Ning",
      "Haoyuan Wang",
      "Chuan Hong",
      "Matthew Engelhard",
      "Danielle S. Bitterman",
      "William G. La Cava",
      "Nan Liu"
    ],
    "pdf_url": "http://arxiv.org/pdf/2510.20629v1"
  },
  {
    "id": "2510.20627v1",
    "title": "H-SPLID: HSIC-based Saliency Preserving Latent Information Decomposition",
    "abstract": "We introduce H-SPLID, a novel algorithm for learning salient feature\nrepresentations through the explicit decomposition of salient and non-salient\nfeatures into separate spaces. We show that H-SPLID promotes learning\nlow-dimensional, task-relevant features. We prove that the expected prediction\ndeviation under input perturbations is upper-bounded by the dimension of the\nsalient subspace and the Hilbert-Schmidt Independence Criterion (HSIC) between\ninputs and representations. This establishes a link between robustness and\nlatent representation compression in terms of the dimensionality and\ninformation preserved. Empirical evaluations on image classification tasks show\nthat models trained with H-SPLID primarily rely on salient input components, as\nindicated by reduced sensitivity to perturbations affecting non-salient\nfeatures, such as image backgrounds. Our code is available at\nhttps://github.com/neu-spiral/H-SPLID.",
    "categories": [
      "cs.LG"
    ],
    "published": "2025-10-23T15:02:07Z",
    "authors": [
      "Lukas Miklautz",
      "Chengzhi Shi",
      "Andrii Shkabrii",
      "Theodoros Thirimachos Davarakis",
      "Prudence Lam",
      "Claudia Plant",
      "Jennifer Dy",
      "Stratis Ioannidis"
    ],
    "pdf_url": "http://arxiv.org/pdf/2510.20627v1"
  },
  {
    "id": "2510.20616v1",
    "title": "On Optimal Hyperparameters for Differentially Private Deep Transfer\n  Learning",
    "abstract": "Differentially private (DP) transfer learning, i.e., fine-tuning a pretrained\nmodel on private data, is the current state-of-the-art approach for training\nlarge models under privacy constraints. We focus on two key hyperparameters in\nthis setting: the clipping bound $C$ and batch size $B$. We show a clear\nmismatch between the current theoretical understanding of how to choose an\noptimal $C$ (stronger privacy requires smaller $C$) and empirical outcomes\n(larger $C$ performs better under strong privacy), caused by changes in the\ngradient distributions. Assuming a limited compute budget (fixed epochs), we\ndemonstrate that the existing heuristics for tuning $B$ do not work, while\ncumulative DP noise better explains whether smaller or larger batches perform\nbetter. We also highlight how the common practice of using a single $(C,B)$\nsetting across tasks can lead to suboptimal performance. We find that\nperformance drops especially when moving between loose and tight privacy and\nbetween plentiful and limited compute, which we explain by analyzing clipping\nas a form of gradient re-weighting and examining cumulative DP noise.",
    "categories": [
      "cs.LG"
    ],
    "published": "2025-10-23T14:48:03Z",
    "authors": [
      "Aki Rehn",
      "Linzh Zhao",
      "Mikko A. Heikkil\u00e4",
      "Antti Honkela"
    ],
    "pdf_url": "http://arxiv.org/pdf/2510.20616v1"
  },
  {
    "id": "2510.20615v1",
    "title": "MS-BART: Unified Modeling of Mass Spectra and Molecules for Structure\n  Elucidation",
    "abstract": "Mass spectrometry (MS) plays a critical role in molecular identification,\nsignificantly advancing scientific discovery. However, structure elucidation\nfrom MS data remains challenging due to the scarcity of annotated spectra.\nWhile large-scale pretraining has proven effective in addressing data scarcity\nin other domains, applying this paradigm to mass spectrometry is hindered by\nthe complexity and heterogeneity of raw spectral signals. To address this, we\npropose MS-BART, a unified modeling framework that maps mass spectra and\nmolecular structures into a shared token vocabulary, enabling cross-modal\nlearning through large-scale pretraining on reliably computed\nfingerprint-molecule datasets. Multi-task pretraining objectives further\nenhance MS-BART's generalization by jointly optimizing denoising and\ntranslation task. The pretrained model is subsequently transferred to\nexperimental spectra through finetuning on fingerprint predictions generated\nwith MIST, a pre-trained spectral inference model, thereby enhancing robustness\nto real-world spectral variability. While finetuning alleviates the\ndistributional difference, MS-BART still suffers molecular hallucination and\nrequires further alignment. We therefore introduce a chemical feedback\nmechanism that guides the model toward generating molecules closer to the\nreference structure. Extensive evaluations demonstrate that MS-BART achieves\nSOTA performance across 5/12 key metrics on MassSpecGym and NPLIB1 and is\nfaster by one order of magnitude than competing diffusion-based methods, while\ncomprehensive ablation studies systematically validate the model's\neffectiveness and robustness.",
    "categories": [
      "cs.LG"
    ],
    "published": "2025-10-23T14:45:28Z",
    "authors": [
      "Yang Han",
      "Pengyu Wang",
      "Kai Yu",
      "Xin Chen",
      "Lu Chen"
    ],
    "pdf_url": "http://arxiv.org/pdf/2510.20615v1"
  },
  {
    "id": "2510.20612v1",
    "title": "Black Box Absorption: LLMs Undermining Innovative Ideas",
    "abstract": "Large Language Models are increasingly adopted as critical tools for\naccelerating innovation. This paper identifies and formalizes a systemic risk\ninherent in this paradigm: \\textbf{Black Box Absorption}. We define this as the\nprocess by which the opaque internal architectures of LLM platforms, often\noperated by large-scale service providers, can internalize, generalize, and\nrepurpose novel concepts contributed by users during interaction. This\nmechanism threatens to undermine the foundational principles of innovation\neconomics by creating severe informational and structural asymmetries between\nindividual creators and platform operators, thereby jeopardizing the long-term\nsustainability of the innovation ecosystem. To analyze this challenge, we\nintroduce two core concepts: the idea unit, representing the transportable\nfunctional logic of an innovation, and idea safety, a multidimensional standard\nfor its protection. This paper analyzes the mechanisms of absorption and\nproposes a concrete governance and engineering agenda to mitigate these risks,\nensuring that creator contributions remain traceable, controllable, and\nequitable.",
    "categories": [
      "cs.CY",
      "cs.AI",
      "cs.CR",
      "cs.LG",
      "econ.GN",
      "q-fin.EC"
    ],
    "published": "2025-10-23T14:43:09Z",
    "authors": [
      "Wenjun Cao"
    ],
    "pdf_url": "http://arxiv.org/pdf/2510.20612v1"
  },
  {
    "id": "2510.20611v1",
    "title": "PSO-XAI: A PSO-Enhanced Explainable AI Framework for Reliable Breast\n  Cancer Detection",
    "abstract": "Breast cancer is considered the most critical and frequently diagnosed cancer\nin women worldwide, leading to an increase in cancer-related mortality. Early\nand accurate detection is crucial as it can help mitigate possible threats\nwhile improving survival rates. In terms of prediction, conventional diagnostic\nmethods are often limited by variability, cost, and, most importantly, risk of\nmisdiagnosis. To address these challenges, machine learning (ML) has emerged as\na powerful tool for computer-aided diagnosis, with feature selection playing a\nvital role in improving model performance and interpretability. This research\nstudy proposes an integrated framework that incorporates customized Particle\nSwarm Optimization (PSO) for feature selection. This framework has been\nevaluated on a comprehensive set of 29 different models, spanning classical\nclassifiers, ensemble techniques, neural networks, probabilistic algorithms,\nand instance-based algorithms. To ensure interpretability and clinical\nrelevance, the study uses cross-validation in conjunction with explainable AI\nmethods. Experimental evaluation showed that the proposed approach achieved a\nsuperior score of 99.1\\% across all performance metrics, including accuracy and\nprecision, while effectively reducing dimensionality and providing transparent,\nmodel-agnostic explanations. The results highlight the potential of combining\nswarm intelligence with explainable ML for robust, trustworthy, and clinically\nmeaningful breast cancer diagnosis.",
    "categories": [
      "cs.LG",
      "cs.AI"
    ],
    "published": "2025-10-23T14:42:50Z",
    "authors": [
      "Mirza Raquib",
      "Niloy Das",
      "Farida Siddiqi Prity",
      "Arafath Al Fahim",
      "Saydul Akbar Murad",
      "Mohammad Amzad Hossain",
      "MD Jiabul Hoque",
      "Mohammad Ali Moni"
    ],
    "pdf_url": "http://arxiv.org/pdf/2510.20611v1"
  },
  {
    "id": "2510.20609v1",
    "title": "Practical Code RAG at Scale: Task-Aware Retrieval Design Choices under\n  Compute Budgets",
    "abstract": "We study retrieval design for code-focused generation tasks under realistic\ncompute budgets. Using two complementary tasks from Long Code Arena -- code\ncompletion and bug localization -- we systematically compare retrieval\nconfigurations across various context window sizes along three axes: (i)\nchunking strategy, (ii) similarity scoring, and (iii) splitting granularity.\n(1) For PL-PL, sparse BM25 with word-level splitting is the most effective and\npractical, significantly outperforming dense alternatives while being an order\nof magnitude faster. (2) For NL-PL, proprietary dense encoders (Voyager-3\nfamily) consistently beat sparse retrievers, however requiring 100x larger\nlatency. (3) Optimal chunk size scales with available context: 32-64 line\nchunks work best at small budgets, and whole-file retrieval becomes competitive\nat 16000 tokens. (4) Simple line-based chunking matches syntax-aware splitting\nacross budgets. (5) Retrieval latency varies by up to 200x across\nconfigurations; BPE-based splitting is needlessly slow, and BM25 + word\nsplitting offers the best quality-latency trade-off. Thus, we provide\nevidence-based recommendations for implementing effective code-oriented RAG\nsystems based on task requirements, model constraints, and computational\nefficiency.",
    "categories": [
      "cs.LG",
      "cs.AI",
      "cs.IR",
      "cs.LG, cs.IR, cs.SE, cs.AI"
    ],
    "published": "2025-10-23T14:40:11Z",
    "authors": [
      "Timur Galimzyanov",
      "Olga Kolomyttseva",
      "Egor Bogomolov"
    ],
    "pdf_url": "http://arxiv.org/pdf/2510.20609v1"
  },
  {
    "id": "2510.20608v2",
    "title": "Convergence Analysis of SGD under Expected Smoothness",
    "abstract": "Stochastic gradient descent (SGD) is the workhorse of large-scale learning,\nyet classical analyses rely on assumptions that can be either too strong\n(bounded variance) or too coarse (uniform noise). The expected smoothness (ES)\ncondition has emerged as a flexible alternative that ties the second moment of\nstochastic gradients to the objective value and the full gradient. This paper\npresents a self-contained convergence analysis of SGD under ES. We (i) refine\nES with interpretations and sampling-dependent constants; (ii) derive bounds of\nthe expectation of squared full gradient norm; and (iii) prove $O(1/K)$ rates\nwith explicit residual errors for various step-size schedules. All proofs are\ngiven in full detail in the appendix. Our treatment unifies and extends recent\nthreads (Khaled and Richt\\'arik, 2020; Umeda and Iiduka, 2025).",
    "categories": [
      "cs.LG"
    ],
    "published": "2025-10-23T14:39:57Z",
    "authors": [
      "Yuta Kawamoto",
      "Hideaki Iiduka"
    ],
    "pdf_url": "http://arxiv.org/pdf/2510.20608v2"
  },
  {
    "id": "2510.20607v1",
    "title": "Generalizable Reasoning through Compositional Energy Minimization",
    "abstract": "Generalization is a key challenge in machine learning, specifically in\nreasoning tasks, where models are expected to solve problems more complex than\nthose encountered during training. Existing approaches typically train\nreasoning models in an end-to-end fashion, directly mapping input instances to\nsolutions. While this allows models to learn useful heuristics from data, it\noften results in limited generalization beyond the training distribution. In\nthis work, we propose a novel approach to reasoning generalization by learning\nenergy landscapes over the solution spaces of smaller, more tractable\nsubproblems. At test time, we construct a global energy landscape for a given\nproblem by combining the energy functions of multiple subproblems. This\ncompositional approach enables the incorporation of additional constraints\nduring inference, allowing the construction of energy landscapes for problems\nof increasing difficulty. To improve the sample quality from this newly\nconstructed energy landscape, we introduce Parallel Energy Minimization (PEM).\nWe evaluate our approach on a wide set of reasoning problems. Our method\noutperforms existing state-of-the-art methods, demonstrating its ability to\ngeneralize to larger and more complex problems. Project website can be found\nat: https://alexoarga.github.io/compositional_reasoning/",
    "categories": [
      "cs.LG",
      "cs.AI"
    ],
    "published": "2025-10-23T14:38:36Z",
    "authors": [
      "Alexandru Oarga",
      "Yilun Du"
    ],
    "pdf_url": "http://arxiv.org/pdf/2510.20607v1"
  },
  {
    "id": "2510.20606v1",
    "title": "Strategic Costs of Perceived Bias in Fair Selection",
    "abstract": "Meritocratic systems, from admissions to hiring, aim to impartially reward\nskill and effort. Yet persistent disparities across race, gender, and class\nchallenge this ideal. Some attribute these gaps to structural inequality;\nothers to individual choice. We develop a game-theoretic model in which\ncandidates from different socioeconomic groups differ in their perceived\npost-selection value--shaped by social context and, increasingly, by AI-powered\ntools offering personalized career or salary guidance. Each candidate\nstrategically chooses effort, balancing its cost against expected reward;\neffort translates into observable merit, and selection is based solely on\nmerit. We characterize the unique Nash equilibrium in the large-agent limit and\nderive explicit formulas showing how valuation disparities and institutional\nselectivity jointly determine effort, representation, social welfare, and\nutility. We further propose a cost-sensitive optimization framework that\nquantifies how modifying selectivity or perceived value can reduce disparities\nwithout compromising institutional goals. Our analysis reveals a\nperception-driven bias: when perceptions of post-selection value differ across\ngroups, these differences translate into rational differences in effort,\npropagating disparities backward through otherwise \"fair\" selection processes.\nWhile the model is static, it captures one stage of a broader feedback cycle\nlinking perceptions, incentives, and outcome--bridging rational-choice and\nstructural explanations of inequality by showing how techno-social environments\nshape individual incentives in meritocratic systems.",
    "categories": [
      "cs.GT",
      "cs.CY",
      "cs.LG",
      "econ.TH"
    ],
    "published": "2025-10-23T14:38:05Z",
    "authors": [
      "L. Elisa Celis",
      "Lingxiao Huang",
      "Milind Sohoni",
      "Nisheeth K. Vishnoi"
    ],
    "pdf_url": "http://arxiv.org/pdf/2510.20606v1"
  },
  {
    "id": "2510.20595v1",
    "title": "Diffusion Autoencoders with Perceivers for Long, Irregular and\n  Multimodal Astronomical Sequences",
    "abstract": "Self-supervised learning has become a central strategy for representation\nlearning, but the majority of architectures used for encoding data have only\nbeen validated on regularly-sampled inputs such as images, audios. and videos.\nIn many scientific domains, data instead arrive as long, irregular, and\nmultimodal sequences. To extract semantic information from these data, we\nintroduce the Diffusion Autoencoder with Perceivers (daep). daep tokenizes\nheterogeneous measurements, compresses them with a Perceiver encoder, and\nreconstructs them with a Perceiver-IO diffusion decoder, enabling scalable\nlearning in diverse data settings. To benchmark the daep architecture, we adapt\nthe masked autoencoder to a Perceiver encoder/decoder design, and establish a\nstrong baseline (maep) in the same architectural family as daep. Across diverse\nspectroscopic and photometric astronomical datasets, daep achieves lower\nreconstruction errors, produces more discriminative latent spaces, and better\npreserves fine-scale structure than both VAE and maep baselines. These results\nestablish daep as an effective framework for scientific domains where data\narrives as irregular, heterogeneous sequences.",
    "categories": [
      "stat.ML",
      "cs.LG"
    ],
    "published": "2025-10-23T14:21:01Z",
    "authors": [
      "Yunyi Shen",
      "Alexander Gagliano"
    ],
    "pdf_url": "http://arxiv.org/pdf/2510.20595v1"
  },
  {
    "id": "2510.20590v1",
    "title": "Embedding the MLOps Lifecycle into OT Reference Models",
    "abstract": "Machine Learning Operations (MLOps) practices are increas- ingly adopted in\nindustrial settings, yet their integration with Opera- tional Technology (OT)\nsystems presents significant challenges. This pa- per analyzes the fundamental\nobstacles in combining MLOps with OT en- vironments and proposes a systematic\napproach to embed MLOps prac- tices into established OT reference models. We\nevaluate the suitability of the Reference Architectural Model for Industry 4.0\n(RAMI 4.0) and the International Society of Automation Standard 95 (ISA-95) for\nMLOps integration and present a detailed mapping of MLOps lifecycle compo-\nnents to RAMI 4.0 exemplified by a real-world use case. Our findings\ndemonstrate that while standard MLOps practices cannot be directly transplanted\nto OT environments, structured adaptation using existing reference models can\nprovide a pathway for successful integration.",
    "categories": [
      "cs.LG"
    ],
    "published": "2025-10-23T14:14:21Z",
    "authors": [
      "Simon Schindler",
      "Christoph Binder",
      "Lukas L\u00fcrzer",
      "Stefan Huber"
    ],
    "pdf_url": "http://arxiv.org/pdf/2510.20590v1"
  },
  {
    "id": "2510.23621v1",
    "title": "Speeding Up MACE: Low-Precision Tricks for Equivarient Force Fields",
    "abstract": "Machine-learning force fields can deliver accurate molecular dynamics (MD) at\nhigh computational cost. For SO(3)-equivariant models such as MACE, there is\nlittle systematic evidence on whether reduced-precision arithmetic and\nGPU-optimized kernels can cut this cost without harming physical fidelity. This\nthesis aims to make MACE cheaper and faster while preserving accuracy by\nidentifying computational bottlenecks and evaluating low-precision execution\npolicies. We profile MACE end-to-end and per block, compare the e3nn and NVIDIA\ncuEquivariance backends, and assess FP64/FP32/BF16/FP16 settings (with FP32\naccumulation) for inference, short NVT and long NPT water simulations, and toy\ntraining runs under reproducible, steady-state timing. cuEquivariance reduces\ninference latency by about $3\\times$. Casting only linear layers to BF16/FP16\nwithin an FP32 model yields roughly 4x additional speedups, while energies and\nthermodynamic observables in NVT/NPT MD remain within run-to-run variability.\nHalf-precision weights during training degrade force RMSE. Mixing e3nn and cuEq\nmodules without explicit adapters causes representation mismatches. Fused\nequivariant kernels and mixed-precision inference can substantially accelerate\nstate-of-the-art force fields with negligible impact on downstream MD. A\npractical policy is to use cuEquivariance with FP32 by default and enable\nBF16/FP16 for linear layers (keeping FP32 accumulations) for maximum\nthroughput, while training remains in FP32. Further gains are expected on\nAmpere/Hopper GPUs (TF32/BF16) and from kernel-level FP16/BF16 paths and\npipeline fusion.",
    "categories": [
      "cs.LG",
      "cs.AI"
    ],
    "published": "2025-10-23T14:02:34Z",
    "authors": [
      "Alexandre Benoit"
    ],
    "pdf_url": "http://arxiv.org/pdf/2510.23621v1"
  },
  {
    "id": "2510.24763v1",
    "title": "Dual-Domain Deep Learning-Assisted NOMA-CSK Systems for Secure and\n  Efficient Vehicular Communications",
    "abstract": "Ensuring secure and efficient multi-user (MU) transmission is critical for\nvehicular communication systems. Chaos-based modulation schemes have garnered\nconsiderable interest due to their benefits in physical layer security.\nHowever, most existing MU chaotic communication systems, particularly those\nbased on non-coherent detection, suffer from low spectral efficiency due to\nreference signal transmission, and limited user connectivity under orthogonal\nmultiple access (OMA). While non-orthogonal schemes, such as sparse code\nmultiple access (SCMA)-based DCSK, have been explored, they face high\ncomputational complexity and inflexible scalability due to their fixed codebook\ndesigns. This paper proposes a deep learning-assisted power domain\nnon-orthogonal multiple access chaos shift keying (DL-NOMA-CSK) system for\nvehicular communications. A deep neural network (DNN)-based demodulator is\ndesigned to learn intrinsic chaotic signal characteristics during offline\ntraining, thereby eliminating the need for chaotic synchronization or reference\nsignal transmission. The demodulator employs a dual-domain feature extraction\narchitecture that jointly processes the time-domain and frequency-domain\ninformation of chaotic signals, enhancing feature learning under dynamic\nchannels. The DNN is integrated into the successive interference cancellation\n(SIC) framework to mitigate error propagation issues. Theoretical analysis and\nextensive simulations demonstrate that the proposed system achieves superior\nperformance in terms of spectral efficiency (SE), energy efficiency (EE), bit\nerror rate (BER), security, and robustness, while maintaining lower\ncomputational complexity compared to traditional MU-DCSK and existing DL-aided\nschemes. These advantages validate its practical viability for secure vehicular\ncommunications.",
    "categories": [
      "cs.IT",
      "cs.AI",
      "cs.LG",
      "math.IT"
    ],
    "published": "2025-10-23T13:41:00Z",
    "authors": [
      "Tingting Huang",
      "Jundong Chen",
      "Huanqiang Zeng",
      "Guofa Cai",
      "Georges Kaddoum"
    ],
    "pdf_url": "http://arxiv.org/pdf/2510.24763v1"
  },
  {
    "id": "2510.26802v1",
    "title": "Are Video Models Ready as Zero-Shot Reasoners? An Empirical Study with\n  the MME-CoF Benchmark",
    "abstract": "Recent video generation models can produce high-fidelity, temporally coherent\nvideos, indicating that they may encode substantial world knowledge. Beyond\nrealistic synthesis, they also exhibit emerging behaviors indicative of visual\nperception, modeling, and manipulation. Yet, an important question still\nremains: Are video models ready to serve as zero-shot reasoners in challenging\nvisual reasoning scenarios? In this work, we conduct an empirical study to\ncomprehensively investigate this question, focusing on the leading and popular\nVeo-3. We evaluate its reasoning behavior across 12 dimensions, including\nspatial, geometric, physical, temporal, and embodied logic, systematically\ncharacterizing both its strengths and failure modes. To standardize this study,\nwe curate the evaluation data into MME-CoF, a compact benchmark that enables\nin-depth and thorough assessment of Chain-of-Frame (CoF) reasoning. Our\nfindings reveal that while current video models demonstrate promising reasoning\npatterns on short-horizon spatial coherence, fine-grained grounding, and\nlocally consistent dynamics, they remain limited in long-horizon causal\nreasoning, strict geometric constraints, and abstract logic. Overall, they are\nnot yet reliable as standalone zero-shot reasoners, but exhibit encouraging\nsigns as complementary visual engines alongside dedicated reasoning models.\nProject page: https://video-cof.github.io",
    "categories": [
      "cs.CV",
      "cs.AI",
      "cs.CL"
    ],
    "published": "2025-10-30T17:59:55Z",
    "authors": [
      "Ziyu Guo",
      "Xinyan Chen",
      "Renrui Zhang",
      "Ruichuan An",
      "Yu Qi",
      "Dongzhi Jiang",
      "Xiangtai Li",
      "Manyuan Zhang",
      "Hongsheng Li",
      "Pheng-Ann Heng"
    ],
    "pdf_url": "http://arxiv.org/pdf/2510.26802v1"
  },
  {
    "id": "2510.26790v1",
    "title": "Gistify! Codebase-Level Understanding via Runtime Execution",
    "abstract": "As coding agents are increasingly deployed in large codebases, the need to\nautomatically design challenging, codebase-level evaluation is central. We\npropose Gistify, a task where a coding LLM must create a single, minimal,\nself-contained file that can reproduce a specific functionality of a codebase.\nThe coding LLM is given full access to a codebase along with a specific\nentrypoint (e.g., a python command), and the generated file must replicate the\noutput of the same command ran under the full codebase, while containing only\nthe essential components necessary to execute the provided command. Success on\nGistify requires both structural understanding of the codebase, accurate\nmodeling of its execution flow as well as the ability to produce potentially\nlarge code patches. Our findings show that current state-of-the-art models\nstruggle to reliably solve Gistify tasks, especially ones with long executions\ntraces.",
    "categories": [
      "cs.CL",
      "cs.AI"
    ],
    "published": "2025-10-30T17:58:26Z",
    "authors": [
      "Hyunji Lee",
      "Minseon Kim",
      "Chinmay Singh",
      "Matheus Pereira",
      "Atharv Sonwane",
      "Isadora White",
      "Elias Stengel-Eskin",
      "Mohit Bansal",
      "Zhengyan Shi",
      "Alessandro Sordoni",
      "Marc-Alexandre C\u00f4t\u00e9",
      "Xingdi Yuan",
      "Lucas Caccia"
    ],
    "pdf_url": "http://arxiv.org/pdf/2510.26790v1"
  },
  {
    "id": "2510.26788v1",
    "title": "Defeating the Training-Inference Mismatch via FP16",
    "abstract": "Reinforcement learning (RL) fine-tuning of large language models (LLMs) often\nsuffers from instability due to the numerical mismatch between the training and\ninference policies. While prior work has attempted to mitigate this issue\nthrough algorithmic corrections or engineering alignments, we show that its\nroot cause lies in the floating point precision itself. The widely adopted\nBF16, despite its large dynamic range, introduces large rounding errors that\nbreaks the consistency between training and inference. In this work, we\ndemonstrate that simply reverting to \\textbf{FP16} effectively eliminates this\nmismatch. The change is simple, fully supported by modern frameworks with only\na few lines of code change, and requires no modification to the model\narchitecture or learning algorithm. Our results suggest that using FP16\nuniformly yields more stable optimization, faster convergence, and stronger\nperformance across diverse tasks, algorithms and frameworks. We hope these\nfindings motivate a broader reconsideration of precision trade-offs in RL\nfine-tuning.",
    "categories": [
      "cs.LG",
      "cs.AI",
      "cs.CL"
    ],
    "published": "2025-10-30T17:58:11Z",
    "authors": [
      "Penghui Qi",
      "Zichen Liu",
      "Xiangxin Zhou",
      "Tianyu Pang",
      "Chao Du",
      "Wee Sun Lee",
      "Min Lin"
    ],
    "pdf_url": "http://arxiv.org/pdf/2510.26788v1"
  },
  {
    "id": "2510.26787v1",
    "title": "Remote Labor Index: Measuring AI Automation of Remote Work",
    "abstract": "AIs have made rapid progress on research-oriented benchmarks of knowledge and\nreasoning, but it remains unclear how these gains translate into economic value\nand automation. To measure this, we introduce the Remote Labor Index (RLI), a\nbroadly multi-sector benchmark comprising real-world, economically valuable\nprojects designed to evaluate end-to-end agent performance in practical\nsettings. AI agents perform near the floor on RLI, with the highest-performing\nagent achieving an automation rate of 2.5%. These results help ground\ndiscussions of AI automation in empirical evidence, setting a common basis for\ntracking AI impacts and enabling stakeholders to proactively navigate AI-driven\nlabor automation.",
    "categories": [
      "cs.LG",
      "cs.AI",
      "cs.CL"
    ],
    "published": "2025-10-30T17:58:04Z",
    "authors": [
      "Mantas Mazeika",
      "Alice Gatti",
      "Cristina Menghini",
      "Udari Madhushani Sehwag",
      "Shivam Singhal",
      "Yury Orlovskiy",
      "Steven Basart",
      "Manasi Sharma",
      "Denis Peskoff",
      "Elaine Lau",
      "Jaehyuk Lim",
      "Lachlan Carroll",
      "Alice Blair",
      "Vinaya Sivakumar",
      "Sumana Basu",
      "Brad Kenstler",
      "Yuntao Ma",
      "Julian Michael",
      "Xiaoke Li",
      "Oliver Ingebretsen",
      "Aditya Mehta",
      "Jean Mottola",
      "John Teichmann",
      "Kevin Yu",
      "Zaina Shaik",
      "Adam Khoja",
      "Richard Ren",
      "Jason Hausenloy",
      "Long Phan",
      "Ye Htet",
      "Ankit Aich",
      "Tahseen Rabbani",
      "Vivswan Shah",
      "Andriy Novykov",
      "Felix Binder",
      "Kirill Chugunov",
      "Luis Ramirez",
      "Matias Geralnik",
      "Hern\u00e1n Mesura",
      "Dean Lee",
      "Ed-Yeremai Hernandez Cardona",
      "Annette Diamond",
      "Summer Yue",
      "Alexandr Wang",
      "Bing Liu",
      "Ernesto Hernandez",
      "Dan Hendrycks"
    ],
    "pdf_url": "http://arxiv.org/pdf/2510.26787v1"
  },
  {
    "id": "2510.26768v1",
    "title": "AMO-Bench: Large Language Models Still Struggle in High School Math\n  Competitions",
    "abstract": "We present AMO-Bench, an Advanced Mathematical reasoning benchmark with\nOlympiad level or even higher difficulty, comprising 50 human-crafted problems.\nExisting benchmarks have widely leveraged high school math competitions for\nevaluating mathematical reasoning capabilities of large language models (LLMs).\nHowever, many existing math competitions are becoming less effective for\nassessing top-tier LLMs due to performance saturation (e.g., AIME24/25). To\naddress this, AMO-Bench introduces more rigorous challenges by ensuring all 50\nproblems are (1) cross-validated by experts to meet at least the International\nMathematical Olympiad (IMO) difficulty standards, and (2) entirely original\nproblems to prevent potential performance leakages from data memorization.\nMoreover, each problem in AMO-Bench requires only a final answer rather than a\nproof, enabling automatic and robust grading for evaluation. Experimental\nresults across 26 LLMs on AMO-Bench show that even the best-performing model\nachieves only 52.4% accuracy on AMO-Bench, with most LLMs scoring below 40%.\nBeyond these poor performances, our further analysis reveals a promising\nscaling trend with increasing test-time compute on AMO-Bench. These results\nhighlight the significant room for improving the mathematical reasoning in\ncurrent LLMs. We release AMO-Bench to facilitate further research into\nadvancing the reasoning abilities of language models.\nhttps://amo-bench.github.io/",
    "categories": [
      "cs.CL",
      "cs.AI"
    ],
    "published": "2025-10-30T17:52:02Z",
    "authors": [
      "Shengnan An",
      "Xunliang Cai",
      "Xuezhi Cao",
      "Xiaoyu Li",
      "Yehao Lin",
      "Junlin Liu",
      "Xinxuan Lv",
      "Dan Ma",
      "Xuanlin Wang",
      "Ziwen Wang",
      "Shuang Zhou"
    ],
    "pdf_url": "http://arxiv.org/pdf/2510.26768v1"
  },
  {
    "id": "2510.26745v1",
    "title": "Deep sequence models tend to memorize geometrically; it is unclear why",
    "abstract": "In sequence modeling, the parametric memory of atomic facts has been\npredominantly abstracted as a brute-force lookup of co-occurrences between\nentities. We contrast this associative view against a geometric view of how\nmemory is stored. We begin by isolating a clean and analyzable instance of\nTransformer reasoning that is incompatible with memory as strictly a storage of\nthe local co-occurrences specified during training. Instead, the model must\nhave somehow synthesized its own geometry of atomic facts, encoding global\nrelationships between all entities, including non-co-occurring ones. This in\nturn has simplified a hard reasoning task involving an $\\ell$-fold composition\ninto an easy-to-learn 1-step geometric task.\n  From this phenomenon, we extract fundamental aspects of neural embedding\ngeometries that are hard to explain. We argue that the rise of such a geometry,\ndespite optimizing over mere local associations, cannot be straightforwardly\nattributed to typical architectural or optimizational pressures.\nCounterintuitively, an elegant geometry is learned even when it is not more\nsuccinct than a brute-force lookup of associations.\n  Then, by analyzing a connection to Node2Vec, we demonstrate how the geometry\nstems from a spectral bias that -- in contrast to prevailing theories -- indeed\narises naturally despite the lack of various pressures. This analysis also\npoints to practitioners a visible headroom to make Transformer memory more\nstrongly geometric. We hope the geometric view of parametric memory encourages\nrevisiting the default intuitions that guide researchers in areas like\nknowledge acquisition, capacity, discovery and unlearning.",
    "categories": [
      "cs.LG",
      "cs.AI",
      "cs.CL",
      "stat.ML"
    ],
    "published": "2025-10-30T17:40:22Z",
    "authors": [
      "Shahriar Noroozizadeh",
      "Vaishnavh Nagarajan",
      "Elan Rosenfeld",
      "Sanjiv Kumar"
    ],
    "pdf_url": "http://arxiv.org/pdf/2510.26745v1"
  },
  {
    "id": "2510.26732v1",
    "title": "Cross-Platform Evaluation of Reasoning Capabilities in Foundation Models",
    "abstract": "This paper presents a comprehensive cross-platform evaluation of reasoning\ncapabilities in contemporary foundation models, establishing an\ninfrastructure-agnostic benchmark across three computational paradigms: HPC\nsupercomputing (MareNostrum 5), cloud platforms (Nebius AI Studio), and\nuniversity clusters (a node with eight H200 GPUs).\n  We evaluate 15 foundation models across 79 problems spanning eight academic\ndomains (Physics, Mathematics, Chemistry, Economics, Biology, Statistics,\nCalculus, and Optimization) through three experimental phases: (1) Baseline\nestablishment: Six models (Mixtral-8x7B, Phi-3, LLaMA 3.1-8B, Gemma-2-9b,\nMistral-7B, OLMo-7B) evaluated on 19 problems using MareNostrum 5, establishing\nmethodology and reference performance; (2) Infrastructure validation: The\n19-problem benchmark repeated on university cluster (seven models including\nFalcon-Mamba state-space architecture) and Nebius AI Studio (nine\nstate-of-the-art models: Hermes-4 70B/405B, LLaMA 3.1-405B/3.3-70B, Qwen3\n30B/235B, DeepSeek-R1, GPT-OSS 20B/120B) to confirm infrastructure-agnostic\nreproducibility; (3) Extended evaluation: Full 79-problem assessment on both\nuniversity cluster and Nebius platforms, probing generalization at scale across\narchitectural diversity.\n  The findings challenge conventional scaling assumptions, establish training\ndata quality as more critical than model size, and provide actionable\nguidelines for model selection across educational, production, and research\ncontexts. The tri-infrastructure methodology and 79-problem benchmark enable\nlongitudinal tracking of reasoning capabilities as foundation models evolve.",
    "categories": [
      "cs.AI",
      "cs.CL"
    ],
    "published": "2025-10-30T17:31:03Z",
    "authors": [
      "J. de Curt\u00f2",
      "I. de Zarz\u00e0",
      "Pablo Garc\u00eda",
      "Jordi Cabot"
    ],
    "pdf_url": "http://arxiv.org/pdf/2510.26732v1"
  },
  {
    "id": "2510.26707v1",
    "title": "Value Drifts: Tracing Value Alignment During LLM Post-Training",
    "abstract": "As LLMs occupy an increasingly important role in society, they are more and\nmore confronted with questions that require them not only to draw on their\ngeneral knowledge but also to align with certain human value systems.\nTherefore, studying the alignment of LLMs with human values has become a\ncrucial field of inquiry. Prior work, however, mostly focuses on evaluating the\nalignment of fully trained models, overlooking the training dynamics by which\nmodels learn to express human values. In this work, we investigate how and at\nwhich stage value alignment arises during the course of a model's\npost-training. Our analysis disentangles the effects of post-training\nalgorithms and datasets, measuring both the magnitude and time of value drifts\nduring training. Experimenting with Llama-3 and Qwen-3 models of different\nsizes and popular supervised fine-tuning (SFT) and preference optimization\ndatasets and algorithms, we find that the SFT phase generally establishes a\nmodel's values, and subsequent preference optimization rarely re-aligns these\nvalues. Furthermore, using a synthetic preference dataset that enables\ncontrolled manipulation of values, we find that different preference\noptimization algorithms lead to different value alignment outcomes, even when\npreference data is held constant. Our findings provide actionable insights into\nhow values are learned during post-training and help to inform data curation,\nas well as the selection of models and algorithms for preference optimization\nto improve model alignment to human values.",
    "categories": [
      "cs.CL",
      "cs.CY",
      "cs.LG"
    ],
    "published": "2025-10-30T17:09:09Z",
    "authors": [
      "Mehar Bhatia",
      "Shravan Nayak",
      "Gaurav Kamath",
      "Marius Mosbach",
      "Karolina Sta\u0144czak",
      "Vered Shwartz",
      "Siva Reddy"
    ],
    "pdf_url": "http://arxiv.org/pdf/2510.26707v1"
  },
  {
    "id": "2510.26697v1",
    "title": "The End of Manual Decoding: Towards Truly End-to-End Language Models",
    "abstract": "The \"end-to-end\" label for LLMs is a misnomer. In practice, they depend on a\nnon-differentiable decoding process that requires laborious, hand-tuning of\nhyperparameters like temperature and top-p. This paper introduces AutoDeco, a\nnovel architecture that enables truly \"end-to-end\" generation by learning to\ncontrol its own decoding strategy. We augment the standard transformer with\nlightweight heads that, at each step, dynamically predict context-specific\ntemperature and top-p values alongside the next-token logits. This approach\ntransforms decoding into a parametric, token-level process, allowing the model\nto self-regulate its sampling strategy within a single forward pass.\n  Through extensive experiments on eight benchmarks, we demonstrate that\nAutoDeco not only significantly outperforms default decoding strategies but\nalso achieves performance comparable to an oracle-tuned baseline derived from\n\"hacking the test set\"-a practical upper bound for any static method.\nCrucially, we uncover an emergent capability for instruction-based decoding\ncontrol: the model learns to interpret natural language commands (e.g.,\n\"generate with low randomness\") and adjusts its predicted temperature and top-p\non a token-by-token basis, opening a new paradigm for steerable and interactive\nLLM decoding.",
    "categories": [
      "cs.CL",
      "cs.AI"
    ],
    "published": "2025-10-30T17:01:43Z",
    "authors": [
      "Zhichao Wang",
      "Dongyang Ma",
      "Xinting Huang",
      "Deng Cai",
      "Tian Lan",
      "Jiahao Xu",
      "Haitao Mi",
      "Xiaoying Tang",
      "Yan Wang"
    ],
    "pdf_url": "http://arxiv.org/pdf/2510.26697v1"
  },
  {
    "id": "2510.26692v1",
    "title": "Kimi Linear: An Expressive, Efficient Attention Architecture",
    "abstract": "We introduce Kimi Linear, a hybrid linear attention architecture that, for\nthe first time, outperforms full attention under fair comparisons across\nvarious scenarios -- including short-context, long-context, and reinforcement\nlearning (RL) scaling regimes. At its core lies Kimi Delta Attention (KDA), an\nexpressive linear attention module that extends Gated DeltaNet with a\nfiner-grained gating mechanism, enabling more effective use of limited\nfinite-state RNN memory. Our bespoke chunkwise algorithm achieves high hardware\nefficiency through a specialized variant of the Diagonal-Plus-Low-Rank (DPLR)\ntransition matrices, which substantially reduces computation compared to the\ngeneral DPLR formulation while remaining more consistent with the classical\ndelta rule.\n  We pretrain a Kimi Linear model with 3B activated parameters and 48B total\nparameters, based on a layerwise hybrid of KDA and Multi-Head Latent Attention\n(MLA). Our experiments show that with an identical training recipe, Kimi Linear\noutperforms full MLA with a sizeable margin across all evaluated tasks, while\nreducing KV cache usage by up to 75% and achieving up to 6 times decoding\nthroughput for a 1M context. These results demonstrate that Kimi Linear can be\na drop-in replacement for full attention architectures with superior\nperformance and efficiency, including tasks with longer input and output\nlengths.\n  To support further research, we open-source the KDA kernel and vLLM\nimplementations, and release the pre-trained and instruction-tuned model\ncheckpoints.",
    "categories": [
      "cs.CL",
      "cs.LG"
    ],
    "published": "2025-10-30T16:59:43Z",
    "authors": [
      " Kimi Team",
      "Yu Zhang",
      "Zongyu Lin",
      "Xingcheng Yao",
      "Jiaxi Hu",
      "Fanqing Meng",
      "Chengyin Liu",
      "Xin Men",
      "Songlin Yang",
      "Zhiyuan Li",
      "Wentao Li",
      "Enzhe Lu",
      "Weizhou Liu",
      "Yanru Chen",
      "Weixin Xu",
      "Longhui Yu",
      "Yejie Wang",
      "Yu Fan",
      "Longguang Zhong",
      "Enming Yuan",
      "Dehao Zhang",
      "Yizhi Zhang",
      "T. Y. Liu",
      "Haiming Wang",
      "Shengjun Fang",
      "Weiran He",
      "Shaowei Liu",
      "Yiwei Li",
      "Jianlin Su",
      "Jiezhong Qiu",
      "Bo Pang",
      "Junjie Yan",
      "Zhejun Jiang",
      "Weixiao Huang",
      "Bohong Yin",
      "Jiacheng You",
      "Chu Wei",
      "Zhengtao Wang",
      "Chao Hong",
      "Yutian Chen",
      "Guanduo Chen",
      "Yucheng Wang",
      "Huabin Zheng",
      "Feng Wang",
      "Yibo Liu",
      "Mengnan Dong",
      "Zheng Zhang",
      "Siyuan Pan",
      "Wenhao Wu",
      "Yuhao Wu",
      "Longyu Guan",
      "Jiawen Tao",
      "Guohong Fu",
      "Xinran Xu",
      "Yuzhi Wang",
      "Guokun Lai",
      "Yuxin Wu",
      "Xinyu Zhou",
      "Zhilin Yang",
      "Yulun Du"
    ],
    "pdf_url": "http://arxiv.org/pdf/2510.26692v1"
  },
  {
    "id": "2510.26683v1",
    "title": "Evontree: Ontology Rule-Guided Self-Evolution of Large Language Models",
    "abstract": "Large language models (LLMs) have demonstrated exceptional capabilities\nacross multiple domains by leveraging massive pre-training and curated\nfine-tuning data. However, in data-sensitive fields such as healthcare, the\nlack of high-quality, domain-specific training corpus hinders LLMs' adaptation\nfor specialized applications. Meanwhile, domain experts have distilled domain\nwisdom into ontology rules, which formalize relationships among concepts and\nensure the integrity of knowledge management repositories. Viewing LLMs as\nimplicit repositories of human knowledge, we propose Evontree, a novel\nframework that leverages a small set of high-quality ontology rules to\nsystematically extract, validate, and enhance domain knowledge within LLMs,\nwithout requiring extensive external datasets. Specifically, Evontree extracts\ndomain ontology from raw models, detects inconsistencies using two core\nontology rules, and reinforces the refined knowledge via self-distilled\nfine-tuning. Extensive experiments on medical QA benchmarks with\nLlama3-8B-Instruct and Med42-v2 demonstrate consistent outperformance over both\nunmodified models and leading supervised baselines, achieving up to a 3.7%\nimprovement in accuracy. These results confirm the effectiveness, efficiency,\nand robustness of our approach for low-resource domain adaptation of LLMs.",
    "categories": [
      "cs.CL",
      "cs.AI"
    ],
    "published": "2025-10-30T16:53:45Z",
    "authors": [
      "Mingchen Tu",
      "Zhiqiang Liu",
      "Juan Li",
      "Liangyurui Liu",
      "Junjie Wang",
      "Lei Liang",
      "Wen Zhang"
    ],
    "pdf_url": "http://arxiv.org/pdf/2510.26683v1"
  },
  {
    "id": "2510.26658v1",
    "title": "The Era of Agentic Organization: Learning to Organize with Language\n  Models",
    "abstract": "We envision a new era of AI, termed agentic organization, where agents solve\ncomplex problems by working collaboratively and concurrently, enabling outcomes\nbeyond individual intelligence. To realize this vision, we introduce\nasynchronous thinking (AsyncThink) as a new paradigm of reasoning with large\nlanguage models, which organizes the internal thinking process into\nconcurrently executable structures. Specifically, we propose a thinking\nprotocol where an organizer dynamically assigns sub-queries to workers, merges\nintermediate knowledge, and produces coherent solutions. More importantly, the\nthinking structure in this protocol can be further optimized through\nreinforcement learning. Experiments demonstrate that AsyncThink achieves 28%\nlower inference latency compared to parallel thinking while improving accuracy\non mathematical reasoning. Moreover, AsyncThink generalizes its learned\nasynchronous thinking capabilities, effectively tackling unseen tasks without\nadditional training.",
    "categories": [
      "cs.AI",
      "cs.CL"
    ],
    "published": "2025-10-30T16:25:10Z",
    "authors": [
      "Zewen Chi",
      "Li Dong",
      "Qingxiu Dong",
      "Yaru Hao",
      "Xun Wu",
      "Shaohan Huang",
      "Furu Wei"
    ],
    "pdf_url": "http://arxiv.org/pdf/2510.26658v1"
  },
  {
    "id": "2510.26622v1",
    "title": "Encoder-Decoder or Decoder-Only? Revisiting Encoder-Decoder Large\n  Language Model",
    "abstract": "Recent large language model (LLM) research has undergone an architectural\nshift from encoder-decoder modeling to nowadays the dominant decoder-only\nmodeling. This rapid transition, however, comes without a rigorous comparative\nanalysis especially \\textit{from the scaling perspective}, raising concerns\nthat the potential of encoder-decoder models may have been overlooked. To fill\nthis gap, we revisit encoder-decoder LLM (RedLLM), enhancing it with recent\nrecipes from decoder-only LLM (DecLLM). We conduct a comprehensive comparison\nbetween RedLLM, pretrained with prefix language modeling (LM), and DecLLM,\npretrained with causal LM, at different model scales, ranging from $\\sim$150M\nto $\\sim$8B. Using RedPajama V1 (1.6T tokens) for pretraining and FLAN for\ninstruction tuning, our experiments show that RedLLM produces compelling\nscaling properties and surprisingly strong performance. While DecLLM is overall\nmore compute-optimal during pretraining, RedLLM demonstrates comparable scaling\nand context length extrapolation capabilities. After instruction tuning, RedLLM\nachieves comparable and even better results on various downstream tasks while\nenjoying substantially better inference efficiency. We hope our findings could\ninspire more efforts on re-examining RedLLM, unlocking its potential for\ndeveloping powerful and efficient LLMs.",
    "categories": [
      "cs.CL"
    ],
    "published": "2025-10-30T15:48:28Z",
    "authors": [
      "Biao Zhang",
      "Yong Cheng",
      "Siamak Shakeri",
      "Xinyi Wang",
      "Min Ma",
      "Orhan Firat"
    ],
    "pdf_url": "http://arxiv.org/pdf/2510.26622v1"
  },
  {
    "id": "2510.26615v1",
    "title": "SlideAgent: Hierarchical Agentic Framework for Multi-Page Visual\n  Document Understanding",
    "abstract": "Multi-page visual documents such as manuals, brochures, presentations, and\nposters convey key information through layout, colors, icons, and cross-slide\nreferences. While large language models (LLMs) offer opportunities in document\nunderstanding, current systems struggle with complex, multi-page visual\ndocuments, particularly in fine-grained reasoning over elements and pages. We\nintroduce SlideAgent, a versatile agentic framework for understanding\nmulti-modal, multi-page, and multi-layout documents, especially slide decks.\nSlideAgent employs specialized agents and decomposes reasoning into three\nspecialized levels-global, page, and element-to construct a structured,\nquery-agnostic representation that captures both overarching themes and\ndetailed visual or textual cues. During inference, SlideAgent selectively\nactivates specialized agents for multi-level reasoning and integrates their\noutputs into coherent, context-aware answers. Extensive experiments show that\nSlideAgent achieves significant improvement over both proprietary (+7.9\noverall) and open-source models (+9.8 overall).",
    "categories": [
      "cs.CL"
    ],
    "published": "2025-10-30T15:41:15Z",
    "authors": [
      "Yiqiao Jin",
      "Rachneet Kaur",
      "Zhen Zeng",
      "Sumitra Ganesh",
      "Srijan Kumar"
    ],
    "pdf_url": "http://arxiv.org/pdf/2510.26615v1"
  },
  {
    "id": "2510.26606v1",
    "title": "Normative Reasoning in Large Language Models: A Comparative Benchmark\n  from Logical and Modal Perspectives",
    "abstract": "Normative reasoning is a type of reasoning that involves normative or deontic\nmodality, such as obligation and permission. While large language models (LLMs)\nhave demonstrated remarkable performance across various reasoning tasks, their\nability to handle normative reasoning remains underexplored. In this paper, we\nsystematically evaluate LLMs' reasoning capabilities in the normative domain\nfrom both logical and modal perspectives. Specifically, to assess how well LLMs\nreason with normative modals, we make a comparison between their reasoning with\nnormative modals and their reasoning with epistemic modals, which share a\ncommon formal structure. To this end, we introduce a new dataset covering a\nwide range of formal patterns of reasoning in both normative and epistemic\ndomains, while also incorporating non-formal cognitive factors that influence\nhuman reasoning. Our results indicate that, although LLMs generally adhere to\nvalid reasoning patterns, they exhibit notable inconsistencies in specific\ntypes of normative reasoning and display cognitive biases similar to those\nobserved in psychological studies of human reasoning. These findings highlight\nchallenges in achieving logical consistency in LLMs' normative reasoning and\nprovide insights for enhancing their reliability. All data and code are\nreleased publicly at https://github.com/kmineshima/NeuBAROCO.",
    "categories": [
      "cs.AI",
      "cs.CL"
    ],
    "published": "2025-10-30T15:35:13Z",
    "authors": [
      "Kentaro Ozeki",
      "Risako Ando",
      "Takanobu Morishita",
      "Hirohiko Abe",
      "Koji Mineshima",
      "Mitsuhiro Okada"
    ],
    "pdf_url": "http://arxiv.org/pdf/2510.26606v1"
  },
  {
    "id": "2510.26577v1",
    "title": "Inference-Cost-Aware Dynamic Tree Construction for Efficient Inference\n  in Large Language Models",
    "abstract": "Large Language Models (LLMs) face significant inference latency challenges\nstemming from their autoregressive design and large size. To address this,\nspeculative decoding emerges as a solution, enabling the simultaneous\ngeneration and validation of multiple tokens. While recent approaches like\nEAGLE-2 and EAGLE-3 improve speculative decoding using dynamic tree structures,\nthey often neglect the impact of crucial system variables such as GPU devices\nand batch sizes.\n  Therefore, we introduce a new dynamic tree decoding approach called CAST that\ntakes into account inference costs, including factors such as GPU\nconfigurations and batch sizes, to dynamically refine the tree structure.\nThrough comprehensive experimentation across six diverse tasks and utilizing\nsix distinct LLMs, our methodology demonstrates remarkable results, achieving\nspeeds up to 5.2 times faster than conventional decoding methods. Moreover, it\ngenerally outperforms existing state-of-the-art techniques from 5% to 20%.",
    "categories": [
      "cs.CL",
      "cs.LG"
    ],
    "published": "2025-10-30T15:04:36Z",
    "authors": [
      "Yinrong Hong",
      "Zhiquan Tan",
      "Kai Hu"
    ],
    "pdf_url": "http://arxiv.org/pdf/2510.26577v1"
  },
  {
    "id": "2510.26575v1",
    "title": "InfoFlow: Reinforcing Search Agent Via Reward Density Optimization",
    "abstract": "Reinforcement Learning with Verifiable Rewards (RLVR) is a promising approach\nfor enhancing agentic deep search. However, its application is often hindered\nby low \\textbf{Reward Density} in deep search scenarios, where agents expend\nsignificant exploratory costs for infrequent and often null final rewards. In\nthis paper, we formalize this challenge as the \\textbf{Reward Density\nOptimization} problem, which aims to improve the reward obtained per unit of\nexploration cost. This paper introduce \\textbf{InfoFlow}, a systematic\nframework that tackles this problem from three aspects. 1) \\textbf{Subproblem\ndecomposition}: breaking down long-range tasks to assign process rewards,\nthereby providing denser learning signals. 2) \\textbf{Failure-guided hints}:\ninjecting corrective guidance into stalled trajectories to increase the\nprobability of successful outcomes. 3) \\textbf{Dual-agent refinement}:\nemploying a dual-agent architecture to offload the cognitive burden of deep\nexploration. A refiner agent synthesizes the search history, which effectively\ncompresses the researcher's perceived trajectory, thereby reducing exploration\ncost and increasing the overall reward density. We evaluate InfoFlow on\nmultiple agentic search benchmarks, where it significantly outperforms strong\nbaselines, enabling lightweight LLMs to achieve performance comparable to\nadvanced proprietary LLMs.",
    "categories": [
      "cs.CL",
      "cs.AI"
    ],
    "published": "2025-10-30T15:03:21Z",
    "authors": [
      "Kun Luo",
      "Hongjin Qian",
      "Zheng Liu",
      "Ziyi Xia",
      "Shitao Xiao",
      "Siqi Bao",
      "Jun Zhao",
      "Kang Liu"
    ],
    "pdf_url": "http://arxiv.org/pdf/2510.26575v1"
  },
  {
    "id": "2510.26543v1",
    "title": "The Structure of Relation Decoding Linear Operators in Large Language\n  Models",
    "abstract": "This paper investigates the structure of linear operators introduced in\nHernandez et al. [2023] that decode specific relational facts in transformer\nlanguage models. We extend their single-relation findings to a collection of\nrelations and systematically chart their organization. We show that such\ncollections of relation decoders can be highly compressed by simple order-3\ntensor networks without significant loss in decoding accuracy. To explain this\nsurprising redundancy, we develop a cross-evaluation protocol, in which we\napply each linear decoder operator to the subjects of every other relation. Our\nresults reveal that these linear maps do not encode distinct relations, but\nextract recurring, coarse-grained semantic properties (e.g., country of capital\ncity and country of food are both in the country-of-X property). This\nproperty-centric structure clarifies both the operators' compressibility and\nhighlights why they generalize only to new relations that are semantically\nclose. Our findings thus interpret linear relational decoding in transformer\nlanguage models as primarily property-based, rather than relation-specific.",
    "categories": [
      "cs.CL",
      "cs.AI",
      "cs.LG"
    ],
    "published": "2025-10-30T14:36:09Z",
    "authors": [
      "Miranda Anna Christ",
      "Adri\u00e1n Csisz\u00e1rik",
      "Gergely Becs\u00f3",
      "D\u00e1niel Varga"
    ],
    "pdf_url": "http://arxiv.org/pdf/2510.26543v1"
  },
  {
    "id": "2510.26521v1",
    "title": "Hebrew Diacritics Restoration using Visual Representation",
    "abstract": "Diacritics restoration in Hebrew is a fundamental task for ensuring accurate\nword pronunciation and disambiguating textual meaning. Despite the language's\nhigh degree of ambiguity when unvocalized, recent machine learning approaches\nhave significantly advanced performance on this task.\n  In this work, we present DIVRIT, a novel system for Hebrew diacritization\nthat frames the task as a zero-shot classification problem. Our approach\noperates at the word level, selecting the most appropriate diacritization\npattern for each undiacritized word from a dynamically generated candidate set,\nconditioned on the surrounding textual context. A key innovation of DIVRIT is\nits use of a Hebrew Visual Language Model, which processes undiacritized text\nas an image, allowing diacritic information to be embedded directly within the\ninput's vector representation.\n  Through a comprehensive evaluation across various configurations, we\ndemonstrate that the system effectively performs diacritization without relying\non complex, explicit linguistic analysis. Notably, in an ``oracle'' setting\nwhere the correct diacritized form is guaranteed to be among the provided\ncandidates, DIVRIT achieves a high level of accuracy. Furthermore, strategic\narchitectural enhancements and optimized training methodologies yield\nsignificant improvements in the system's overall generalization capabilities.\nThese findings highlight the promising potential of visual representations for\naccurate and automated Hebrew diacritization.",
    "categories": [
      "cs.CL"
    ],
    "published": "2025-10-30T14:15:16Z",
    "authors": [
      "Yair Elboher",
      "Yuval Pinter"
    ],
    "pdf_url": "http://arxiv.org/pdf/2510.26521v1"
  },
  {
    "id": "2510.26512v1",
    "title": "Inside CORE-KG: Evaluating Structured Prompting and Coreference\n  Resolution for Knowledge Graphs",
    "abstract": "Human smuggling networks are increasingly adaptive and difficult to analyze.\nLegal case documents offer critical insights but are often unstructured,\nlexically dense, and filled with ambiguous or shifting references, which pose\nsignificant challenges for automated knowledge graph (KG) construction. While\nrecent LLM-based approaches improve over static templates, they still generate\nnoisy, fragmented graphs with duplicate nodes due to the absence of guided\nextraction and coreference resolution. The recently proposed CORE-KG framework\naddresses these limitations by integrating a type-aware coreference module and\ndomain-guided structured prompts, significantly reducing node duplication and\nlegal noise. In this work, we present a systematic ablation study of CORE-KG to\nquantify the individual contributions of its two key components. Our results\nshow that removing coreference resolution results in a 28.32% increase in node\nduplication and a 4.32% increase in noisy nodes, while removing structured\nprompts leads to a 4.34% increase in node duplication and a 73.33% increase in\nnoisy nodes. These findings offer empirical insights for designing robust\nLLM-based pipelines for extracting structured representations from complex\nlegal texts.",
    "categories": [
      "cs.CL",
      "cs.AI",
      "cs.IR",
      "cs.LG"
    ],
    "published": "2025-10-30T14:05:55Z",
    "authors": [
      "Dipak Meher",
      "Carlotta Domeniconi"
    ],
    "pdf_url": "http://arxiv.org/pdf/2510.26512v1"
  },
  {
    "id": "2510.26498v1",
    "title": "A Multi-agent Large Language Model Framework to Automatically Assess\n  Performance of a Clinical AI Triage Tool",
    "abstract": "Purpose: The purpose of this study was to determine if an ensemble of\nmultiple LLM agents could be used collectively to provide a more reliable\nassessment of a pixel-based AI triage tool than a single LLM.\n  Methods: 29,766 non-contrast CT head exams from fourteen hospitals were\nprocessed by a commercial intracranial hemorrhage (ICH) AI detection tool.\nRadiology reports were analyzed by an ensemble of eight open-source LLM models\nand a HIPAA compliant internal version of GPT-4o using a single multi-shot\nprompt that assessed for presence of ICH. 1,726 examples were manually\nreviewed. Performance characteristics of the eight open-source models and\nconsensus were compared to GPT-4o. Three ideal consensus LLM ensembles were\ntested for rating the performance of the triage tool.\n  Results: The cohort consisted of 29,766 head CTs exam-report pairs. The\nhighest AUC performance was achieved with llama3.3:70b and GPT-4o (AUC= 0.78).\nThe average precision was highest for Llama3.3:70b and GPT-4o (AP=0.75 & 0.76).\nLlama3.3:70b had the highest F1 score (0.81) and recall (0.85), greater\nprecision (0.78), specificity (0.72), and MCC (0.57). Using MCC (95% CI) the\nideal combination of LLMs were: Full-9 Ensemble 0.571 (0.552-0.591), Top-3\nEnsemble 0.558 (0.537-0.579), Consensus 0.556 (0.539-0.574), and GPT4o 0.522\n(0.500-0.543). No statistically significant differences were observed between\nTop-3, Full-9, and Consensus (p > 0.05).\n  Conclusion: An ensemble of medium to large sized open-source LLMs provides a\nmore consistent and reliable method to derive a ground truth retrospective\nevaluation of a clinical AI triage tool over a single LLM alone.",
    "categories": [
      "cs.CL"
    ],
    "published": "2025-10-30T13:50:19Z",
    "authors": [
      "Adam E. Flanders",
      "Yifan Peng",
      "Luciano Prevedello",
      "Robyn Ball",
      "Errol Colak",
      "Prahlad Menon",
      "George Shih",
      "Hui-Ming Lin",
      "Paras Lakhani"
    ],
    "pdf_url": "http://arxiv.org/pdf/2510.26498v1"
  },
  {
    "id": "2510.26495v1",
    "title": "Rethinking Text-to-SQL: Dynamic Multi-turn SQL Interaction for\n  Real-world Database Exploration",
    "abstract": "Recent advances in Text-to-SQL have achieved strong results in static,\nsingle-turn tasks, where models generate SQL queries from natural language\nquestions. However, these systems fall short in real-world interactive\nscenarios, where user intents evolve and queries must be refined over multiple\nturns. In applications such as finance and business analytics, users\niteratively adjust query constraints or dimensions based on intermediate\nresults. To evaluate such dynamic capabilities, we introduce DySQL-Bench, a\nbenchmark assessing model performance under evolving user interactions. Unlike\nprevious manually curated datasets, DySQL-Bench is built through an automated\ntwo-stage pipeline of task synthesis and verification. Structured tree\nrepresentations derived from raw database tables guide LLM-based task\ngeneration, followed by interaction-oriented filtering and expert validation.\nHuman evaluation confirms 100% correctness of the synthesized data. We further\npropose a multi-turn evaluation framework simulating realistic interactions\namong an LLM-simulated user, the model under test, and an executable database.\nThe model must adapt its reasoning and SQL generation as user intents change.\nDySQL-Bench covers 13 domains across BIRD and Spider 2 databases, totaling\n1,072 tasks. Even GPT-4o attains only 58.34% overall accuracy and 23.81% on the\nPass@5 metric, underscoring the benchmark's difficulty. All code and data are\nreleased at https://github.com/Aurora-slz/Real-World-SQL-Bench .",
    "categories": [
      "cs.DB",
      "cs.CL"
    ],
    "published": "2025-10-30T13:44:22Z",
    "authors": [
      "Linzhuang Sun",
      "Tianyu Guo",
      "Hao Liang",
      "Yuying Li",
      "Qifeng Cai",
      "Jingxuan Wei",
      "Bihui Yu",
      "Wentao Zhang",
      "Bin Cui"
    ],
    "pdf_url": "http://arxiv.org/pdf/2510.26495v1"
  },
  {
    "id": "2510.26493v1",
    "title": "Context Engineering 2.0: The Context of Context Engineering",
    "abstract": "Karl Marx once wrote that ``the human essence is the ensemble of social\nrelations'', suggesting that individuals are not isolated entities but are\nfundamentally shaped by their interactions with other entities, within which\ncontexts play a constitutive and essential role. With the advent of computers\nand artificial intelligence, these contexts are no longer limited to purely\nhuman--human interactions: human--machine interactions are included as well.\nThen a central question emerges: How can machines better understand our\nsituations and purposes? To address this challenge, researchers have recently\nintroduced the concept of context engineering. Although it is often regarded as\na recent innovation of the agent era, we argue that related practices can be\ntraced back more than twenty years. Since the early 1990s, the field has\nevolved through distinct historical phases, each shaped by the intelligence\nlevel of machines: from early human--computer interaction frameworks built\naround primitive computers, to today's human--agent interaction paradigms\ndriven by intelligent agents, and potentially to human--level or superhuman\nintelligence in the future. In this paper, we situate context engineering,\nprovide a systematic definition, outline its historical and conceptual\nlandscape, and examine key design considerations for practice. By addressing\nthese questions, we aim to offer a conceptual foundation for context\nengineering and sketch its promising future. This paper is a stepping stone for\na broader community effort toward systematic context engineering in AI systems.",
    "categories": [
      "cs.AI",
      "cs.CL"
    ],
    "published": "2025-10-30T13:43:10Z",
    "authors": [
      "Qishuo Hua",
      "Lyumanshan Ye",
      "Dayuan Fu",
      "Yang Xiao",
      "Xiaojie Cai",
      "Yunze Wu",
      "Jifan Lin",
      "Junfei Wang",
      "Pengfei Liu"
    ],
    "pdf_url": "http://arxiv.org/pdf/2510.26493v1"
  },
  {
    "id": "2510.26484v1",
    "title": "Bayesian Network Fusion of Large Language Models for Sentiment Analysis",
    "abstract": "Large language models (LLMs) continue to advance, with an increasing number\nof domain-specific variants tailored for specialised tasks. However, these\nmodels often lack transparency and explainability, can be costly to fine-tune,\nrequire substantial prompt engineering, yield inconsistent results across\ndomains, and impose significant adverse environmental impact due to their high\ncomputational demands. To address these challenges, we propose the Bayesian\nnetwork LLM fusion (BNLF) framework, which integrates predictions from three\nLLMs, including FinBERT, RoBERTa, and BERTweet, through a probabilistic\nmechanism for sentiment analysis. BNLF performs late fusion by modelling the\nsentiment predictions from multiple LLMs as probabilistic nodes within a\nBayesian network. Evaluated across three human-annotated financial corpora with\ndistinct linguistic and contextual characteristics, BNLF demonstrates\nconsistent gains of about six percent in accuracy over the baseline LLMs,\nunderscoring its robustness to dataset variability and the effectiveness of\nprobabilistic fusion for interpretable sentiment classification.",
    "categories": [
      "cs.CL",
      "cs.AI"
    ],
    "published": "2025-10-30T13:37:58Z",
    "authors": [
      "Rasoul Amirzadeh",
      "Dhananjay Thiruvady",
      "Fatemeh Shiri"
    ],
    "pdf_url": "http://arxiv.org/pdf/2510.26484v1"
  },
  {
    "id": "2510.26474v1",
    "title": "Counteracting Matthew Effect in Self-Improvement of LVLMs through\n  Head-Tail Re-balancing",
    "abstract": "Self-improvement has emerged as a mainstream paradigm for advancing the\nreasoning capabilities of large vision-language models (LVLMs), where models\nexplore and learn from successful trajectories iteratively. However, we\nidentify a critical issue during this process: the model excels at generating\nhigh-quality trajectories for simple queries (i.e., head data) but struggles\nwith more complex ones (i.e., tail data). This leads to an imbalanced\noptimization that drives the model to prioritize simple reasoning skills, while\nhindering its ability to tackle more complex reasoning tasks. Over iterations,\nthis imbalance becomes increasingly pronounced--a dynamic we term the \"Matthew\neffect\"--which ultimately hinders further model improvement and leads to\nperformance bottlenecks. To counteract this challenge, we introduce four\nefficient strategies from two perspectives: distribution-reshaping and\ntrajectory-resampling, to achieve head-tail re-balancing during the\nexploration-and-learning self-improvement process. Extensive experiments on\nQwen2-VL-7B-Instruct and InternVL2.5-4B models across visual reasoning tasks\ndemonstrate that our methods consistently improve visual reasoning\ncapabilities, outperforming vanilla self-improvement by 3.86 points on average.",
    "categories": [
      "cs.CV",
      "cs.AI",
      "cs.CL",
      "cs.LG"
    ],
    "published": "2025-10-30T13:26:58Z",
    "authors": [
      "Xin Guo",
      "Zhiheng Xi",
      "Yiwen Ding",
      "Yitao Zhai",
      "Xiaowei Shi",
      "Xunliang Cai",
      "Tao Gui",
      "Qi Zhang",
      "Xuanjing Huang"
    ],
    "pdf_url": "http://arxiv.org/pdf/2510.26474v1"
  },
  {
    "id": "2510.26457v1",
    "title": "SecureReviewer: Enhancing Large Language Models for Secure Code Review\n  through Secure-aware Fine-tuning",
    "abstract": "Identifying and addressing security issues during the early phase of the\ndevelopment lifecycle is critical for mitigating the long-term negative impacts\non software systems. Code review serves as an effective practice that enables\ndevelopers to check their teammates' code before integration into the codebase.\nTo streamline the generation of review comments, various automated code review\napproaches have been proposed, where LLM-based methods have significantly\nadvanced the capabilities of automated review generation. However, existing\nmodels primarily focus on general-purpose code review, their effectiveness in\nidentifying and addressing security-related issues remains underexplored.\nMoreover, adapting existing code review approaches to target security issues\nfaces substantial challenges, including data scarcity and inadequate evaluation\nmetrics. To address these limitations, we propose SecureReviewer, a new\napproach designed for enhancing LLMs' ability to identify and resolve\nsecurity-related issues during code review. Specifically, we first construct a\ndataset tailored for training and evaluating secure code review capabilities.\nLeveraging this dataset, we fine-tune LLMs to generate code review comments\nthat can effectively identify security issues and provide fix suggestions with\nour proposed secure-aware fine-tuning strategy. To mitigate hallucination in\nLLMs and enhance the reliability of their outputs, we integrate the RAG\ntechnique, which grounds the generated comments in domain-specific security\nknowledge. Additionally, we introduce SecureBLEU, a new evaluation metric\ndesigned to assess the effectiveness of review comments in addressing security\nissues. Experimental results demonstrate that SecureReviewer outperforms\nstate-of-the-art baselines in both security issue detection accuracy and the\noverall quality and practical utility of generated review comments.",
    "categories": [
      "cs.SE",
      "cs.AI",
      "cs.CL"
    ],
    "published": "2025-10-30T13:06:11Z",
    "authors": [
      "Fang Liu",
      "Simiao Liu",
      "Yinghao Zhu",
      "Xiaoli Lian",
      "Li Zhang"
    ],
    "pdf_url": "http://arxiv.org/pdf/2510.26457v1"
  },
  {
    "id": "2510.26446v1",
    "title": "1+1>2: A Synergistic Sparse and Low-Rank Compression Method for Large\n  Language Models",
    "abstract": "Large Language Models (LLMs) have demonstrated remarkable proficiency in\nlanguage comprehension and generation; however, their widespread adoption is\nconstrained by substantial bandwidth and computational demands. While pruning\nand low-rank approximation have each demonstrated promising performance\nindividually, their synergy for LLMs remains underexplored. We introduce\n\\underline{S}ynergistic \\underline{S}parse and \\underline{L}ow-Rank\n\\underline{C}ompression (SSLC) methods for LLMs, which leverages the strengths\nof both techniques: low-rank approximation compresses the model by retaining\nits essential structure with minimal information loss, whereas sparse\noptimization eliminates non-essential weights, preserving those crucial for\ngeneralization. Based on theoretical analysis, we first formulate the low-rank\napproximation and sparse optimization as a unified problem and solve it by\niterative optimization algorithm. Experiments on LLaMA and Qwen2.5 models\n(7B-70B) show that SSLC, without any additional training steps, consistently\nsurpasses standalone methods, achieving state-of-the-arts results. Notably,\nSSLC compresses Qwen2.5 by 50\\% with no performance drop and achieves at least\n1.63$\\times$ speedup, offering a practical solution for efficient LLM\ndeployment.",
    "categories": [
      "cs.CL"
    ],
    "published": "2025-10-30T12:50:30Z",
    "authors": [
      "Zeliang Zong",
      "Kai Zhang",
      "Zheyang Li",
      "Wenming Tan",
      "Ye Ren",
      "Yiyan Zhai",
      "Jilin Hu"
    ],
    "pdf_url": "http://arxiv.org/pdf/2510.26446v1"
  },
  {
    "id": "2510.26423v1",
    "title": "Nexus: Execution-Grounded Multi-Agent Test Oracle Synthesis",
    "abstract": "Test oracle generation in non-regression testing is a longstanding challenge\nin software engineering, where the goal is to produce oracles that can\naccurately determine whether a function under test (FUT) behaves as intended\nfor a given input. In this paper, we introduce Nexus, a novel multi-agent\nframework to address this challenge. Nexus generates test oracles by leveraging\na diverse set of specialized agents that synthesize test oracles through a\nstructured process of deliberation, validation, and iterative self-refinement.\nDuring the deliberation phase, a panel of four specialist agents, each\nembodying a distinct testing philosophy, collaboratively critiques and refines\nan initial set of test oracles. Then, in the validation phase, Nexus generates\na plausible candidate implementation of the FUT and executes the proposed\noracles against it in a secure sandbox. For any oracle that fails this\nexecution-based check, Nexus activates an automated selfrefinement loop, using\nthe specific runtime error to debug and correct the oracle before\nre-validation. Our extensive evaluation on seven diverse benchmarks\ndemonstrates that Nexus consistently and substantially outperforms\nstate-of-theart baselines. For instance, Nexus improves the test-level oracle\naccuracy on the LiveCodeBench from 46.30% to 57.73% for GPT-4.1-Mini. The\nimproved accuracy also significantly enhances downstream tasks: the bug\ndetection rate of GPT4.1-Mini generated test oracles on HumanEval increases\nfrom 90.91% to 95.45% for Nexus compared to baselines, and the success rate of\nautomated program repair improves from 35.23% to 69.32%.",
    "categories": [
      "cs.SE",
      "cs.CL"
    ],
    "published": "2025-10-30T12:20:25Z",
    "authors": [
      "Dong Huang",
      "Mingzhe Du",
      "Jie M. Zhang",
      "Zheng Lin",
      "Meng Luo",
      "Qianru Zhang",
      "See-Kiong Ng"
    ],
    "pdf_url": "http://arxiv.org/pdf/2510.26423v1"
  },
  {
    "id": "2510.26422v1",
    "title": "OmniEduBench: A Comprehensive Chinese Benchmark for Evaluating Large\n  Language Models in Education",
    "abstract": "With the rapid development of large language models (LLMs), various LLM-based\nworks have been widely applied in educational fields. However, most existing\nLLMs and their benchmarks focus primarily on the knowledge dimension, largely\nneglecting the evaluation of cultivation capabilities that are essential for\nreal-world educational scenarios. Additionally, current benchmarks are often\nlimited to a single subject or question type, lacking sufficient diversity.\nThis issue is particularly prominent within the Chinese context. To address\nthis gap, we introduce OmniEduBench, a comprehensive Chinese educational\nbenchmark. OmniEduBench consists of 24.602K high-quality question-answer pairs.\nThe data is meticulously divided into two core dimensions: the knowledge\ndimension and the cultivation dimension, which contain 18.121K and 6.481K\nentries, respectively. Each dimension is further subdivided into 6 fine-grained\ncategories, covering a total of 61 different subjects (41 in the knowledge and\n20 in the cultivation). Furthermore, the dataset features a rich variety of\nquestion formats, including 11 common exam question types, providing a solid\nfoundation for comprehensively evaluating LLMs' capabilities in education.\nExtensive experiments on 11 mainstream open-source and closed-source LLMs\nreveal a clear performance gap. In the knowledge dimension, only Gemini-2.5 Pro\nsurpassed 60\\% accuracy, while in the cultivation dimension, the\nbest-performing model, QWQ, still trailed human intelligence by nearly 30\\%.\nThese results highlight the substantial room for improvement and underscore the\nchallenges of applying LLMs in education.",
    "categories": [
      "cs.CL"
    ],
    "published": "2025-10-30T12:16:29Z",
    "authors": [
      "Min Zhang",
      "Hao Chen",
      "Hao Chen",
      "Wenqi Zhang",
      "Didi Zhu",
      "Xin Lin",
      "Bo Jiang",
      "Aimin Zhou",
      "Fei Wu",
      "Kun Kuang"
    ],
    "pdf_url": "http://arxiv.org/pdf/2510.26422v1"
  },
  {
    "id": "2510.26354v1",
    "title": "On the Role of Context for Discourse Relation Classification in\n  Scientific Writing",
    "abstract": "With the increasing use of generative Artificial Intelligence (AI) methods to\nsupport science workflows, we are interested in the use of discourse-level\ninformation to find supporting evidence for AI generated scientific claims. A\nfirst step towards this objective is to examine the task of inferring discourse\nstructure in scientific writing.\n  In this work, we present a preliminary investigation of pretrained language\nmodel (PLM) and Large Language Model (LLM) approaches for Discourse Relation\nClassification (DRC), focusing on scientific publications, an under-studied\ngenre for this task. We examine how context can help with the DRC task, with\nour experiments showing that context, as defined by discourse structure, is\ngenerally helpful. We also present an analysis of which scientific discourse\nrelation types might benefit most from context.",
    "categories": [
      "cs.CL"
    ],
    "published": "2025-10-30T11:05:36Z",
    "authors": [
      "Stephen Wan",
      "Wei Liu",
      "Michael Strube"
    ],
    "pdf_url": "http://arxiv.org/pdf/2510.26354v1"
  },
  {
    "id": "2510.26352v1",
    "title": "The Geometry of Dialogue: Graphing Language Models to Reveal Synergistic\n  Teams for Multi-Agent Collaboration",
    "abstract": "While a multi-agent approach based on large language models (LLMs) represents\na promising strategy to surpass the capabilities of single models, its success\nis critically dependent on synergistic team composition. However, forming\noptimal teams is a significant challenge, as the inherent opacity of most\nmodels obscures the internal characteristics necessary for effective\ncollaboration. In this paper, we propose an interaction-centric framework for\nautomatic team composition that does not require any prior knowledge including\ntheir internal architectures, training data, or task performances. Our method\nconstructs a \"language model graph\" that maps relationships between models from\nthe semantic coherence of pairwise conversations, and then applies community\ndetection to identify synergistic model clusters. Our experiments with diverse\nLLMs demonstrate that the proposed method discovers functionally coherent\ngroups that reflect their latent specializations. Priming conversations with\nspecific topics identified synergistic teams which outperform random baselines\non downstream benchmarks and achieve comparable accuracy to that of\nmanually-curated teams based on known model specializations. Our findings\nprovide a new basis for the automated design of collaborative multi-agent LLM\nteams.",
    "categories": [
      "cs.CL",
      "cs.AI",
      "cs.MA"
    ],
    "published": "2025-10-30T11:04:15Z",
    "authors": [
      "Kotaro Furuya",
      "Yuichi Kitagawa"
    ],
    "pdf_url": "http://arxiv.org/pdf/2510.26352v1"
  },
  {
    "id": "2510.26345v1",
    "title": "MisSynth: Improving MISSCI Logical Fallacies Classification with\n  Synthetic Data",
    "abstract": "Health-related misinformation is very prevalent and potentially harmful. It\nis difficult to identify, especially when claims distort or misinterpret\nscientific findings. We investigate the impact of synthetic data generation and\nlightweight fine-tuning techniques on the ability of large language models\n(LLMs) to recognize fallacious arguments using the MISSCI dataset and\nframework. In this work, we propose MisSynth, a pipeline that applies\nretrieval-augmented generation (RAG) to produce synthetic fallacy samples,\nwhich are then used to fine-tune an LLM model. Our results show substantial\naccuracy gains with fine-tuned models compared to vanilla baselines. For\ninstance, the LLaMA 3.1 8B fine-tuned model achieved an over 35% F1-score\nabsolute improvement on the MISSCI test split over its vanilla baseline. We\ndemonstrate that introducing synthetic fallacy data to augment limited\nannotated resources can significantly enhance zero-shot LLM classification\nperformance on real-world scientific misinformation tasks, even with limited\ncomputational resources. The code and synthetic dataset are available on\nhttps://github.com/mxpoliakov/MisSynth.",
    "categories": [
      "cs.CL",
      "cs.AI",
      "cs.LG"
    ],
    "published": "2025-10-30T10:52:43Z",
    "authors": [
      "Mykhailo Poliakov",
      "Nadiya Shvai"
    ],
    "pdf_url": "http://arxiv.org/pdf/2510.26345v1"
  },
  {
    "id": "2510.26336v1",
    "title": "From Amateur to Master: Infusing Knowledge into LLMs via Automated\n  Curriculum Learning",
    "abstract": "Large Language Models (LLMs) excel at general tasks but underperform in\nspecialized domains like economics and psychology, which require deep,\nprincipled understanding. To address this, we introduce ACER (Automated\nCurriculum-Enhanced Regimen) that transforms generalist models into domain\nexperts without sacrificing their broad capabilities. ACER first synthesizes a\ncomprehensive, textbook-style curriculum by generating a table of contents for\na subject and then creating question-answer (QA) pairs guided by Bloom's\ntaxonomy. This ensures systematic topic coverage and progressively increasing\ndifficulty. The resulting synthetic corpus is used for continual pretraining\nwith an interleaved curriculum schedule, aligning learning across both content\nand cognitive dimensions.\n  Experiments with Llama 3.2 (1B and 3B) show significant gains in specialized\nMMLU subsets. In challenging domains like microeconomics, where baselines\nstruggle, ACER boosts accuracy by 5 percentage points. Across all target\ndomains, we observe a consistent macro-average improvement of 3 percentage\npoints. Notably, ACER not only prevents catastrophic forgetting but also\nfacilitates positive cross-domain knowledge transfer, improving performance on\nnon-target domains by 0.7 points. Beyond MMLU, ACER enhances performance on\nknowledge-intensive benchmarks like ARC and GPQA by over 2 absolute points,\nwhile maintaining stable performance on general reasoning tasks. Our results\ndemonstrate that ACER offers a scalable and effective recipe for closing\ncritical domain gaps in LLMs.",
    "categories": [
      "cs.CL",
      "cs.AI"
    ],
    "published": "2025-10-30T10:43:40Z",
    "authors": [
      "Nishit Neema",
      "Srinjoy Mukherjee",
      "Sapan Shah",
      "Gokul Ramakrishnan",
      "Ganesh Venkatesh"
    ],
    "pdf_url": "http://arxiv.org/pdf/2510.26336v1"
  },
  {
    "id": "2510.26322v1",
    "title": "SCRIBE: Structured Chain Reasoning for Interactive Behaviour\n  Explanations using Tool Calling",
    "abstract": "Language models can be used to provide interactive, personalized student\nfeedback in educational settings. However, real-world deployment faces three\nkey challenges: privacy concerns, limited computational resources, and the need\nfor pedagogically valid responses. These constraints require small, open-source\nmodels that can run locally and reliably ground their outputs in correct\ninformation. We introduce SCRIBE, a framework for multi-hop, tool-augmented\nreasoning designed to generate valid responses to student questions about\nfeedback reports. SCRIBE combines domain-specific tools with a self-reflective\ninference pipeline that supports iterative reasoning, tool use, and error\nrecovery. We distil these capabilities into 3B and 8B models via two-stage LoRA\nfine-tuning on synthetic GPT-4o-generated data. Evaluation with a human-aligned\nGPT-Judge and a user study with 108 students shows that 8B-SCRIBE models\nachieve comparable or superior quality to much larger models in key dimensions\nsuch as relevance and actionability, while being perceived on par with GPT-4o\nand Llama-3.3 70B by students. These findings demonstrate the viability of\nSCRIBE for low-resource, privacy-sensitive educational applications.",
    "categories": [
      "cs.CL"
    ],
    "published": "2025-10-30T10:17:05Z",
    "authors": [
      "Fares Fawzi",
      "Vinitra Swamy",
      "Dominik Glandorf",
      "Tanya Nazaretsky",
      "Tanja K\u00e4ser"
    ],
    "pdf_url": "http://arxiv.org/pdf/2510.26322v1"
  },
  {
    "id": "2510.26298v1",
    "title": "Can Agent Conquer Web? Exploring the Frontiers of ChatGPT Atlas Agent in\n  Web Games",
    "abstract": "OpenAI's ChatGPT Atlas introduces new capabilities for web interaction,\nenabling the model to analyze webpages, process user intents, and execute\ncursor and keyboard inputs directly within the browser. While its capacity for\ninformation retrieval tasks has been demonstrated, its performance in dynamic,\ninteractive environments remains less explored. In this study, we conduct an\nearly evaluation of Atlas's web interaction capabilities using browser-based\ngames as test scenarios, including Google's T-Rex Runner, Sudoku, Flappy Bird,\nand Stein.world. We employ in-game performance scores as quantitative metrics\nto assess performance across different task types. Our results show that Atlas\nperforms strongly in logical reasoning tasks like Sudoku, completing puzzles\nsignificantly faster than human baselines, but struggles substantially in\nreal-time games requiring precise timing and motor control, often failing to\nprogress beyond initial obstacles. These findings suggest that while Atlas\ndemonstrates capable analytical processing, there remain notable limitations in\ndynamic web environments requiring real-time interaction. The website of our\nproject can be found at https://atlas-game-eval.github.io.",
    "categories": [
      "cs.CL",
      "cs.AI"
    ],
    "published": "2025-10-30T09:35:51Z",
    "authors": [
      "Jingran Zhang",
      "Ning Li",
      "Justin Cui"
    ],
    "pdf_url": "http://arxiv.org/pdf/2510.26298v1"
  },
  {
    "id": "2510.26285v1",
    "title": "Unravelling the Mechanisms of Manipulating Numbers in Language Models",
    "abstract": "Recent work has shown that different large language models (LLMs) converge to\nsimilar and accurate input embedding representations for numbers. These\nfindings conflict with the documented propensity of LLMs to produce erroneous\noutputs when dealing with numeric information. In this work, we aim to explain\nthis conflict by exploring how language models manipulate numbers and quantify\nthe lower bounds of accuracy of these mechanisms. We find that despite\nsurfacing errors, different language models learn interchangeable\nrepresentations of numbers that are systematic, highly accurate and universal\nacross their hidden states and the types of input contexts. This allows us to\ncreate universal probes for each LLM and to trace information -- including the\ncauses of output errors -- to specific layers. Our results lay a fundamental\nunderstanding of how pre-trained LLMs manipulate numbers and outline the\npotential of more accurate probing techniques in addressed refinements of LLMs'\narchitectures.",
    "categories": [
      "cs.CL",
      "cs.AI",
      "cs.LG",
      "cs.NE"
    ],
    "published": "2025-10-30T09:08:50Z",
    "authors": [
      "Michal \u0160tef\u00e1nik",
      "Timothee Mickus",
      "Marek Kadl\u010d\u00edk",
      "Bertram H\u00f8jer",
      "Michal Spiegel",
      "Ra\u00fal V\u00e1zquez",
      "Aman Sinha",
      "Josef Kucha\u0159",
      "Philipp Mondorf"
    ],
    "pdf_url": "http://arxiv.org/pdf/2510.26285v1"
  },
  {
    "id": "2510.26277v1",
    "title": "Do LLMs Signal When They're Right? Evidence from Neuron Agreement",
    "abstract": "Large language models (LLMs) commonly boost reasoning via\nsample-evaluate-ensemble decoders, achieving label free gains without ground\ntruth. However, prevailing strategies score candidates using only external\noutputs such as token probabilities, entropies, or self evaluations, and these\nsignals can be poorly calibrated after post training. We instead analyze\ninternal behavior based on neuron activations and uncover three findings: (1)\nexternal signals are low dimensional projections of richer internal dynamics;\n(2) correct responses activate substantially fewer unique neurons than\nincorrect ones throughout generation; and (3) activations from correct\nresponses exhibit stronger cross sample agreement, whereas incorrect ones\ndiverge. Motivated by these observations, we propose Neuron Agreement Decoding\n(NAD), an unsupervised best-of-N method that selects candidates using\nactivation sparsity and cross sample neuron agreement, operating solely on\ninternal signals and without requiring comparable textual outputs. NAD enables\nearly correctness prediction within the first 32 generated tokens and supports\naggressive early stopping. Across math and science benchmarks with verifiable\nanswers, NAD matches majority voting; on open ended coding benchmarks where\nmajority voting is inapplicable, NAD consistently outperforms Avg@64. By\npruning unpromising trajectories early, NAD reduces token usage by 99% with\nminimal loss in generation quality, showing that internal signals provide\nreliable, scalable, and efficient guidance for label free ensemble decoding.",
    "categories": [
      "cs.CL"
    ],
    "published": "2025-10-30T08:59:56Z",
    "authors": [
      "Kang Chen",
      "Yaoning Wang",
      "Kai Xiong",
      "Zhuoka Feng",
      "Wenhe Sun",
      "Haotian Chen",
      "Yixin Cao"
    ],
    "pdf_url": "http://arxiv.org/pdf/2510.26277v1"
  },
  {
    "id": "2510.26274v1",
    "title": "PVMark: Enabling Public Verifiability for LLM Watermarking Schemes",
    "abstract": "Watermarking schemes for large language models (LLMs) have been proposed to\nidentify the source of the generated text, mitigating the potential threats\nemerged from model theft. However, current watermarking solutions hardly\nresolve the trust issue: the non-public watermark detection cannot prove itself\nfaithfully conducting the detection. We observe that it is attributed to the\nsecret key mostly used in the watermark detection -- it cannot be public, or\nthe adversary may launch removal attacks provided the key; nor can it be\nprivate, or the watermarking detection is opaque to the public. To resolve the\ndilemma, we propose PVMark, a plugin based on zero-knowledge proof (ZKP),\nenabling the watermark detection process to be publicly verifiable by third\nparties without disclosing any secret key. PVMark hinges upon the proof of\n`correct execution' of watermark detection on which a set of ZKP constraints\nare built, including mapping, random number generation, comparison, and\nsummation. We implement multiple variants of PVMark in Python, Rust and Circom,\ncovering combinations of three watermarking schemes, three hash functions, and\nfour ZKP protocols, to show our approach effectively works under a variety of\ncircumstances. By experimental results, PVMark efficiently enables public\nverifiability on the state-of-the-art LLM watermarking schemes yet without\ncompromising the watermarking performance, promising to be deployed in\npractice.",
    "categories": [
      "cs.CR",
      "cs.CL",
      "cs.LG"
    ],
    "published": "2025-10-30T08:58:44Z",
    "authors": [
      "Haohua Duan",
      "Liyao Xiang",
      "Xin Zhang"
    ],
    "pdf_url": "http://arxiv.org/pdf/2510.26274v1"
  },
  {
    "id": "2510.26271v1",
    "title": "Distilling Multilingual Vision-Language Models: When Smaller Models Stay\n  Multilingual",
    "abstract": "Vision-language models (VLMs) exhibit uneven performance across languages, a\nproblem that is often exacerbated when the model size is reduced. While\nKnowledge distillation (KD) demonstrates promising results in transferring\nknowledge from larger to smaller VLMs, applying KD in multilingualism is an\nunderexplored area. This paper presents a controlled empirical study of KD\nbehavior across five distillation approaches, isolating their effects on\ncross-lingual representation consistency and downstream performance stability\nunder model compression. We study five distillation formulations across CLIP\nand SigLIP2, and evaluate them on in-domain retrieval and out-of-domain visual\nQA. We find that some configurations preserve or even improve multilingual\nretrieval robustness despite halving model size, but others fail to maintain\ncross-task stability, exposing design-sensitive trade-offs that aggregate\naccuracy alone does not reveal.",
    "categories": [
      "cs.CL"
    ],
    "published": "2025-10-30T08:56:06Z",
    "authors": [
      "Sukrit Sriratanawilai",
      "Jhayahgrit Thongwat",
      "Romrawin Chumpu",
      "Patomporn Payoungkhamdee",
      "Sarana Nutanong",
      "Peerat Limkonchotiwat"
    ],
    "pdf_url": "http://arxiv.org/pdf/2510.26271v1"
  },
  {
    "id": "2510.26254v1",
    "title": "Language Models Are Borrowing-Blind: A Multilingual Evaluation of\n  Loanword Identification across 10 Languages",
    "abstract": "Throughout language history, words are borrowed from one language to another\nand gradually become integrated into the recipient's lexicon. Speakers can\noften differentiate these loanwords from native vocabulary, particularly in\nbilingual communities where a dominant language continuously imposes lexical\nitems on a minority language. This paper investigates whether pretrained\nlanguage models, including large language models, possess similar capabilities\nfor loanword identification. We evaluate multiple models across 10 languages.\nDespite explicit instructions and contextual information, our results show that\nmodels perform poorly in distinguishing loanwords from native ones. These\nfindings corroborate previous evidence that modern NLP systems exhibit a bias\ntoward loanwords rather than native equivalents. Our work has implications for\ndeveloping NLP tools for minority languages and supporting language\npreservation in communities under lexical pressure from dominant languages.",
    "categories": [
      "cs.CL"
    ],
    "published": "2025-10-30T08:36:07Z",
    "authors": [
      "M\u00e9rilin Sousa Silva",
      "Sina Ahmadi"
    ],
    "pdf_url": "http://arxiv.org/pdf/2510.26254v1"
  },
  {
    "id": "2510.26253v1",
    "title": "Pragmatic Theories Enhance Understanding of Implied Meanings in LLMs",
    "abstract": "The ability to accurately interpret implied meanings plays a crucial role in\nhuman communication and language use, and language models are also expected to\npossess this capability. This study demonstrates that providing language models\nwith pragmatic theories as prompts is an effective in-context learning approach\nfor tasks to understand implied meanings. Specifically, we propose an approach\nin which an overview of pragmatic theories, such as Gricean pragmatics and\nRelevance Theory, is presented as a prompt to the language model, guiding it\nthrough a step-by-step reasoning process to derive a final interpretation.\nExperimental results showed that, compared to the baseline, which prompts\nintermediate reasoning without presenting pragmatic theories (0-shot\nChain-of-Thought), our methods enabled language models to achieve up to 9.6\\%\nhigher scores on pragmatic reasoning tasks. Furthermore, we show that even\nwithout explaining the details of pragmatic theories, merely mentioning their\nnames in the prompt leads to a certain performance improvement (around 1-3%) in\nlarger models compared to the baseline.",
    "categories": [
      "cs.CL"
    ],
    "published": "2025-10-30T08:35:52Z",
    "authors": [
      "Takuma Sato",
      "Seiya Kawano",
      "Koichiro Yoshino"
    ],
    "pdf_url": "http://arxiv.org/pdf/2510.26253v1"
  },
  {
    "id": "2510.26241v1",
    "title": "Which Way Does Time Flow? A Psychophysics-Grounded Evaluation for\n  Vision-Language Models",
    "abstract": "Modern vision-language models (VLMs) excel at many multimodal tasks, yet\ntheir grasp of temporal information in video remains weak and, crucially,\nunder-evaluated. We probe this gap with a deceptively simple but revealing\nchallenge: judging the arrow of time (AoT)-whether a short clip is played\nforward or backward. We introduce AoT-PsyPhyBENCH, a psychophysically validated\nbenchmark that tests whether VLMs can infer temporal direction in natural\nvideos using the same stimuli and behavioral baselines established for humans.\nOur comprehensive evaluation of open-weight and proprietary, reasoning and\nnon-reasoning VLMs reveals that most models perform near chance, and even the\nbest lag far behind human accuracy on physically irreversible processes (e.g.,\nfree fall, diffusion/explosion) and causal manual actions (division/addition)\nthat humans recognize almost instantly. These results highlight a fundamental\ngap in current multimodal systems: while they capture rich visual-semantic\ncorrelations, they lack the inductive biases required for temporal continuity\nand causal understanding. We release the code and data for AoT-PsyPhyBENCH to\nencourage further progress in the physical and temporal reasoning capabilities\nof VLMs.",
    "categories": [
      "cs.CV",
      "cs.CL"
    ],
    "published": "2025-10-30T08:21:50Z",
    "authors": [
      "Shiho Matta",
      "Lis Kanashiro Pereira",
      "Peitao Han",
      "Fei Cheng",
      "Shigeru Kitazawa"
    ],
    "pdf_url": "http://arxiv.org/pdf/2510.26241v1"
  },
  {
    "id": "2510.26205v1",
    "title": "Towards Global Retrieval Augmented Generation: A Benchmark for\n  Corpus-Level Reasoning",
    "abstract": "Retrieval-augmented generation (RAG) has emerged as a leading approach to\nreducing hallucinations in large language models (LLMs). Current RAG evaluation\nbenchmarks primarily focus on what we call local RAG: retrieving relevant\nchunks from a small subset of documents to answer queries that require only\nlocalized understanding within specific text chunks. However, many real-world\napplications require a fundamentally different capability -- global RAG --\nwhich involves aggregating and analyzing information across entire document\ncollections to derive corpus-level insights (for example, \"What are the top 10\nmost cited papers in 2023?\"). In this paper, we introduce GlobalQA -- the first\nbenchmark specifically designed to evaluate global RAG capabilities, covering\nfour core task types: counting, extremum queries, sorting, and top-k\nextraction. Through systematic evaluation across different models and\nbaselines, we find that existing RAG methods perform poorly on global tasks,\nwith the strongest baseline achieving only 1.51 F1 score. To address these\nchallenges, we propose GlobalRAG, a multi-tool collaborative framework that\npreserves structural coherence through chunk-level retrieval, incorporates\nLLM-driven intelligent filters to eliminate noisy documents, and integrates\naggregation modules for precise symbolic computation. On the Qwen2.5-14B model,\nGlobalRAG achieves 6.63 F1 compared to the strongest baseline's 1.51 F1,\nvalidating the effectiveness of our method.",
    "categories": [
      "cs.CL",
      "cs.AI"
    ],
    "published": "2025-10-30T07:29:14Z",
    "authors": [
      "Qi Luo",
      "Xiaonan Li",
      "Tingshuo Fan",
      "Xinchi Chen",
      "Xipeng Qiu"
    ],
    "pdf_url": "http://arxiv.org/pdf/2510.26205v1"
  },
  {
    "id": "2510.26202v1",
    "title": "What's In My Human Feedback? Learning Interpretable Descriptions of\n  Preference Data",
    "abstract": "Human feedback can alter language models in unpredictable and undesirable\nways, as practitioners lack a clear understanding of what feedback data\nencodes. While prior work studies preferences over certain attributes (e.g.,\nlength or sycophancy), automatically extracting relevant features without\npre-specifying hypotheses remains challenging. We introduce What's In My Human\nFeedback? (WIMHF), a method to explain feedback data using sparse autoencoders.\nWIMHF characterizes both (1) the preferences a dataset is capable of measuring\nand (2) the preferences that the annotators actually express. Across 7\ndatasets, WIMHF identifies a small number of human-interpretable features that\naccount for the majority of the preference prediction signal achieved by\nblack-box models. These features reveal a wide diversity in what humans prefer,\nand the role of dataset-level context: for example, users on Reddit prefer\ninformality and jokes, while annotators in HH-RLHF and PRISM disprefer them.\nWIMHF also surfaces potentially unsafe preferences, such as that LMArena users\ntend to vote against refusals, often in favor of toxic content. The learned\nfeatures enable effective data curation: re-labeling the harmful examples in\nArena yields large safety gains (+37%) with no cost to general performance.\nThey also allow fine-grained personalization: on the Community Alignment\ndataset, we learn annotator-specific weights over subjective features that\nimprove preference prediction. WIMHF provides a human-centered analysis method\nfor practitioners to better understand and use preference data.",
    "categories": [
      "cs.CL",
      "cs.AI"
    ],
    "published": "2025-10-30T07:25:10Z",
    "authors": [
      "Rajiv Movva",
      "Smitha Milli",
      "Sewon Min",
      "Emma Pierson"
    ],
    "pdf_url": "http://arxiv.org/pdf/2510.26202v1"
  },
  {
    "id": "2510.26200v1",
    "title": "Don't Let It Fade: Preserving Edits in Diffusion Language Models via\n  Token Timestep Allocation",
    "abstract": "While diffusion language models (DLMs) enable fine-grained refinement, their\npractical controllability remains fragile. We identify and formally\ncharacterize a central failure mode called update forgetting, in which uniform\nand context agnostic updates induce token level fluctuations across timesteps,\nerasing earlier semantic edits and disrupting the cumulative refinement\nprocess, thereby degrading fluency and coherence. As this failure originates in\nuniform and context agnostic updates, effective control demands explicit token\nordering. We propose Token Timestep Allocation (TTA), which realizes soft and\nsemantic token ordering via per token timestep schedules: critical tokens are\nfrozen early, while uncertain tokens receive continued refinement. This\ntimestep based ordering can be instantiated as either a fixed policy or an\nadaptive policy driven by task signals, thereby supporting a broad spectrum of\nrefinement strategies. Because it operates purely at inference time, it applies\nuniformly across various DLMs and naturally extends to diverse supervision\nsources. Empirically, TTA improves controllability and fluency: on sentiment\ncontrol, it yields more than 20 percent higher accuracy and nearly halves\nperplexity using less than one fifth the steps; in detoxification, it lowers\nmaximum toxicity (12.2 versus 14.5) and perplexity (26.0 versus 32.0).\nTogether, these results demonstrate that softened ordering via timestep\nallocation is the critical lever for mitigating update forgetting and achieving\nstable and controllable diffusion text generation.",
    "categories": [
      "cs.CL",
      "cs.AI"
    ],
    "published": "2025-10-30T07:21:05Z",
    "authors": [
      "Woojin Kim",
      "Jaeyoung Do"
    ],
    "pdf_url": "http://arxiv.org/pdf/2510.26200v1"
  },
  {
    "id": "2510.26193v1",
    "title": "RCScore: Quantifying Response Consistency in Large Language Models",
    "abstract": "Current LLM evaluations often rely on a single instruction template,\noverlooking models' sensitivity to instruction style-a critical aspect for\nreal-world deployments. We present RCScore, a multi-dimensional framework\nquantifying how instruction formulation affects model responses. By\nsystematically transforming benchmark problems into multiple instruction\nstyles, RCScore reveals performance variations undetected by conventional\nmetrics. Our experiments across ten LLMs on four reasoning benchmarks\ndemonstrate that instruction style can shift accuracy by up to 16.7% points. We\nintroduce Cross-Response Similarity (CRS), a method applying RCScore metrics to\nmeasure stylistic self-consistency, and establish its strong correlation with\ntask accuracy, suggesting consistency as a valuable proxy for model\nreliability. Additional findings show that deterministic decoding produces more\nstylistically stable outputs, and model scale correlates positively with\ncross-style consistency. RCScore offers a principled approach to assess\ninstruction robustness.",
    "categories": [
      "cs.CL"
    ],
    "published": "2025-10-30T07:06:47Z",
    "authors": [
      "Dongjun Jang",
      "Youngchae Ahn",
      "Hyopil Shin"
    ],
    "pdf_url": "http://arxiv.org/pdf/2510.26193v1"
  },
  {
    "id": "2510.26190v1",
    "title": "SP-MCQA: Evaluating Intelligibility of TTS Beyond the Word Level",
    "abstract": "The evaluation of intelligibility for TTS has reached a bottleneck, as\nexisting assessments heavily rely on word-by-word accuracy metrics such as WER,\nwhich fail to capture the complexity of real-world speech or reflect human\ncomprehension needs. To address this, we propose Spoken-Passage Multiple-Choice\nQuestion Answering, a novel subjective approach evaluating the accuracy of key\ninformation in synthesized speech, and release SP-MCQA-Eval, an 8.76-hour\nnews-style benchmark dataset for SP-MCQA evaluation. Our experiments reveal\nthat low WER does not necessarily guarantee high key-information accuracy,\nexposing a gap between traditional metrics and practical intelligibility.\nSP-MCQA shows that even state-of-the-art (SOTA) models still lack robust text\nnormalization and phonetic accuracy. This work underscores the urgent need for\nhigh-level, more life-like evaluation criteria now that many systems already\nexcel at WER yet may fall short on real-world intelligibility.",
    "categories": [
      "cs.SD",
      "cs.CL",
      "eess.AS"
    ],
    "published": "2025-10-30T06:57:07Z",
    "authors": [
      "Hitomi Jin Ling Tee",
      "Chaoren Wang",
      "Zijie Zhang",
      "Zhizheng Wu"
    ],
    "pdf_url": "http://arxiv.org/pdf/2510.26190v1"
  },
  {
    "id": "2510.26183v1",
    "title": "Similarity-Distance-Magnitude Language Models",
    "abstract": "We introduce Similarity-Distance-Magnitude (SDM) language models (LMs), which\nare sequence prediction models fine-tuned to maximize the proportion of\ngenerations in the well-calibrated, high-probability region partitioned by a\nfinal-layer SDM activation layer used for binary classification of\ninstruction-following. We demonstrate that existing pre-trained decoder-only\nTransformer LMs can be readily converted into SDM LMs via supervised\nfine-tuning, using the final-layer SDM activation layer during training to\nestimate a change-of-base for a supervised next-token loss over a contrastive\ninput encoding scheme, with additional hard negative examples generated online\nduring training. This results in reduced abstentions (i.e., improved\nstatistical efficiency) compared to strong supervised baselines.",
    "categories": [
      "cs.CL"
    ],
    "published": "2025-10-30T06:42:15Z",
    "authors": [
      "Allen Schmaltz"
    ],
    "pdf_url": "http://arxiv.org/pdf/2510.26183v1"
  },
  {
    "id": "2510.26182v1",
    "title": "MossNet: Mixture of State-Space Experts is a Multi-Head Attention",
    "abstract": "Large language models (LLMs) have significantly advanced generative\napplications in natural language processing (NLP). Recent trends in model\narchitectures revolve around efficient variants of transformers or\nstate-space/gated-recurrent models (SSMs, GRMs). However, prevailing\nSSM/GRM-based methods often emulate only a single attention head, potentially\nlimiting their expressiveness. In this work, we propose MossNet, a novel\nmixture-of-state-space-experts architecture that emulates a linear multi-head\nattention (MHA). MossNet leverages a mixture-of-experts (MoE) implementation\nnot only in channel-mixing multi-layered perceptron (MLP) blocks but also in\nthe time-mixing SSM kernels to realize multiple \"attention heads.\" Extensive\nexperiments on language modeling and downstream evaluations show that MossNet\noutperforms both transformer- and SSM-based architectures of similar model size\nand data budgets. Larger variants of MossNet, trained on trillions of tokens,\nfurther confirm its scalability and superior performance. In addition,\nreal-device profiling on a Samsung Galaxy S24 Ultra and an Nvidia A100 GPU\ndemonstrate favorable runtime speed and resource usage compared to similarly\nsized baselines. Our results suggest that MossNet is a compelling new direction\nfor efficient, high-performing recurrent LLM architectures.",
    "categories": [
      "cs.CL"
    ],
    "published": "2025-10-30T06:37:23Z",
    "authors": [
      "Shikhar Tuli",
      "James Seale Smith",
      "Haris Jeelani",
      "Chi-Heng Lin",
      "Abhishek Patel",
      "Vasili Ramanishka",
      "Yen-Chang Hsu",
      "Hongxia Jin"
    ],
    "pdf_url": "http://arxiv.org/pdf/2510.26182v1"
  },
  {
    "id": "2510.26167v1",
    "title": "One Model to Critique Them All: Rewarding Agentic Tool-Use via Efficient\n  Reasoning",
    "abstract": "Reward models (RMs) play a critical role in aligning large language models\n(LLMs) with human preferences. Yet in the domain of tool learning, the lack of\nRMs specifically designed for function-calling tasks has limited progress\ntoward more capable agentic AI. We introduce ToolRM, a family of lightweight\ngenerative RMs tailored for general tool-use scenarios. To build these models,\nwe propose a novel pipeline that constructs pairwise preference data using\nrule-based scoring and multidimensional sampling. This yields\nToolPref-Pairwise-30K, a diverse, balanced, and challenging dataset of critique\ntasks that supports reinforcement learning with verifiable feedback. To\nevaluate tool-use RMs, we also introduce TRBench$_{BFCL}$, a benchmark built on\nthe agentic evaluation suite BFCL. Trained on our constructed data, models from\nthe Qwen3-4B/8B series achieve up to 14.28% higher accuracy, substantially\noutperforming frontier models such as Claude 4 and OpenAI o3 in pairwise reward\njudgments. Beyond training objectives, ToolRM generalizes to broader critique\ntasks, including Best-of-N sampling and self-correction. Experiments on\nACEBench highlight its effectiveness and efficiency, enabling inference-time\nscaling and reducing output token usage by over 66%. We release data and model\ncheckpoints to facilitate future research.",
    "categories": [
      "cs.AI",
      "cs.CL"
    ],
    "published": "2025-10-30T06:08:27Z",
    "authors": [
      "Renhao Li",
      "Jianhong Tu",
      "Yang Su",
      "Hamid Alinejad-Rokny",
      "Derek F. Wong",
      "Junyang Lin",
      "Min Yang"
    ],
    "pdf_url": "http://arxiv.org/pdf/2510.26167v1"
  },
  {
    "id": "2510.26143v1",
    "title": "Reasoning Curriculum: Bootstrapping Broad LLM Reasoning from Math",
    "abstract": "Reinforcement learning (RL) can elicit strong reasoning in large language\nmodels (LLMs), yet most open efforts focus on math and code. We propose\nReasoning Curriculum, a simple two-stage curriculum that first elicits\nreasoning skills in pretraining-aligned domains such as math, then adapts and\nrefines these skills across other domains via joint RL. Stage 1 performs a\nbrief cold start and then math-only RL with verifiable rewards to develop\nreasoning skills. Stage 2 runs joint RL on mixed-domain data to transfer and\nconsolidate these skills. The curriculum is minimal and backbone-agnostic,\nrequiring no specialized reward models beyond standard verifiability checks.\nEvaluated on Qwen3-4B and Llama-3.1-8B over a multi-domain suite, reasoning\ncurriculum yields consistent gains. Ablations and a cognitive-skill analysis\nindicate that both stages are necessary and that math-first elicitation\nincreases cognitive behaviors important for solving complex problems. Reasoning\nCurriculum provides a compact, easy-to-adopt recipe for general reasoning.",
    "categories": [
      "cs.AI",
      "cs.CL"
    ],
    "published": "2025-10-30T04:56:44Z",
    "authors": [
      "Bo Pang",
      "Deqian Kong",
      "Silvio Savarese",
      "Caiming Xiong",
      "Yingbo Zhou"
    ],
    "pdf_url": "http://arxiv.org/pdf/2510.26143v1"
  },
  {
    "id": "2510.26124v1",
    "title": "On the Influence of Discourse Relations in Persuasive Texts",
    "abstract": "This paper investigates the relationship between Persuasion Techniques (PTs)\nand Discourse Relations (DRs) by leveraging Large Language Models (LLMs) and\nprompt engineering. Since no dataset annotated with both PTs and DRs exists, we\ntook the SemEval 2023 Task 3 dataset labelled with 19 PTs as a starting point\nand developed LLM-based classifiers to label each instance of the dataset with\none of the 22 PDTB 3.0 level-2 DRs. In total, four LLMs were evaluated using 10\ndifferent prompts, resulting in 40 unique DR classifiers. Ensemble models using\ndifferent majority-pooling strategies were used to create 5 silver datasets of\ninstances labelled with both persuasion techniques and level-2 PDTB senses. The\nsilver dataset sizes vary from 1,281 instances to 204 instances, depending on\nthe majority pooling technique used. Statistical analysis of these silver\ndatasets shows that six discourse relations (namely Cause, Purpose, Contrast,\nCause+Belief, Concession, and Condition) play a crucial role in persuasive\ntexts, especially in the use of Loaded Language, Exaggeration/Minimisation,\nRepetition and to cast Doubt. This insight can contribute to detecting online\npropaganda and misinformation, as well as to our general understanding of\neffective communication.",
    "categories": [
      "cs.CL",
      "I.2.7; I.2.6"
    ],
    "published": "2025-10-30T04:10:56Z",
    "authors": [
      "Nawar Turk",
      "Sevag Kaspar",
      "Leila Kosseim"
    ],
    "pdf_url": "http://arxiv.org/pdf/2510.26124v1"
  },
  {
    "id": "2510.26122v1",
    "title": "Reasoning Path Divergence: A New Metric and Curation Strategy to Unlock\n  LLM Diverse Thinking",
    "abstract": "While Test-Time Scaling (TTS) has proven effective in improving the reasoning\nability of large language models (LLMs), low diversity in model outputs often\nbecomes a bottleneck; this is partly caused by the common \"one problem, one\nsolution\" (1P1S) training practice, which provides a single canonical answer\nand can push models toward a narrow set of reasoning paths. To address this, we\npropose a \"one problem, multiple solutions\" (1PNS) training paradigm that\nexposes the model to a variety of valid reasoning trajectories and thus\nincreases inference diversity. A core challenge for 1PNS is reliably measuring\nsemantic differences between multi-step chains of thought, so we introduce\nReasoning Path Divergence (RPD), a step-level metric that aligns and scores\nLong Chain-of-Thought solutions to capture differences in intermediate\nreasoning. Using RPD, we curate maximally diverse solution sets per problem and\nfine-tune Qwen3-4B-Base. Experiments show that RPD-selected training yields\nmore varied outputs and higher pass@k, with an average +2.80% gain in pass@16\nover a strong 1P1S baseline and a +4.99% gain on AIME24, demonstrating that\n1PNS further amplifies the effectiveness of TTS. Our code is available at\nhttps://github.com/fengjujf/Reasoning-Path-Divergence .",
    "categories": [
      "cs.CL"
    ],
    "published": "2025-10-30T04:08:53Z",
    "authors": [
      "Feng Ju",
      "Zeyu Qin",
      "Rui Min",
      "Zhitao He",
      "Lingpeng Kong",
      "Yi R. Fung"
    ],
    "pdf_url": "http://arxiv.org/pdf/2510.26122v1"
  },
  {
    "id": "2510.26101v1",
    "title": "QCoder Benchmark: Bridging Language Generation and Quantum Hardware\n  through Simulator-Based Feedback",
    "abstract": "Large language models (LLMs) have increasingly been applied to automatic\nprogramming code generation. This task can be viewed as a language generation\ntask that bridges natural language, human knowledge, and programming logic.\nHowever, it remains underexplored in domains that require interaction with\nhardware devices, such as quantum programming, where human coders write Python\ncode that is executed on a quantum computer. To address this gap, we introduce\nQCoder Benchmark, an evaluation framework that assesses LLMs on quantum\nprogramming with feedback from simulated hardware devices. Our benchmark offers\ntwo key features. First, it supports evaluation using a quantum simulator\nenvironment beyond conventional Python execution, allowing feedback of\ndomain-specific metrics such as circuit depth, execution time, and error\nclassification, which can be used to guide better generation. Second, it\nincorporates human-written code submissions collected from real programming\ncontests, enabling both quantitative comparisons and qualitative analyses of\nLLM outputs against human-written codes. Our experiments reveal that even\nadvanced models like GPT-4o achieve only around 18.97% accuracy, highlighting\nthe difficulty of the benchmark. In contrast, reasoning-based models such as o3\nreach up to 78% accuracy, outperforming averaged success rates of human-written\ncodes (39.98%). We release the QCoder Benchmark dataset and public evaluation\nAPI to support further research.",
    "categories": [
      "cs.CL",
      "cs.PL",
      "quant-ph"
    ],
    "published": "2025-10-30T03:27:35Z",
    "authors": [
      "Taku Mikuriya",
      "Tatsuya Ishigaki",
      "Masayuki Kawarada",
      "Shunya Minami",
      "Tadashi Kadowaki",
      "Yohichi Suzuki",
      "Soshun Naito",
      "Shunya Takata",
      "Takumi Kato",
      "Tamotsu Basseda",
      "Reo Yamada",
      "Hiroya Takamura"
    ],
    "pdf_url": "http://arxiv.org/pdf/2510.26101v1"
  },
  {
    "id": "2510.26095v1",
    "title": "ORBIT -- Open Recommendation Benchmark for Reproducible Research with\n  Hidden Tests",
    "abstract": "Recommender systems are among the most impactful AI applications, interacting\nwith billions of users every day, guiding them to relevant products, services,\nor information tailored to their preferences. However, the research and\ndevelopment of recommender systems are hindered by existing datasets that fail\nto capture realistic user behaviors and inconsistent evaluation settings that\nlead to ambiguous conclusions. This paper introduces the Open Recommendation\nBenchmark for Reproducible Research with HIdden Tests (ORBIT), a unified\nbenchmark for consistent and realistic evaluation of recommendation models.\nORBIT offers a standardized evaluation framework of public datasets with\nreproducible splits and transparent settings for its public leaderboard.\nAdditionally, ORBIT introduces a new webpage recommendation task, ClueWeb-Reco,\nfeaturing web browsing sequences from 87 million public, high-quality webpages.\nClueWeb-Reco is a synthetic dataset derived from real, user-consented, and\nprivacy-guaranteed browsing data. It aligns with modern recommendation\nscenarios and is reserved as the hidden test part of our leaderboard to\nchallenge recommendation models' generalization ability. ORBIT measures 12\nrepresentative recommendation models on its public benchmark and introduces a\nprompted LLM baseline on the ClueWeb-Reco hidden test. Our benchmark results\nreflect general improvements of recommender systems on the public datasets,\nwith variable individual performances. The results on the hidden test reveal\nthe limitations of existing approaches in large-scale webpage recommendation\nand highlight the potential for improvements with LLM integrations. ORBIT\nbenchmark, leaderboard, and codebase are available at\nhttps://www.open-reco-bench.ai.",
    "categories": [
      "cs.IR",
      "cs.CL"
    ],
    "published": "2025-10-30T03:10:45Z",
    "authors": [
      "Jingyuan He",
      "Jiongnan Liu",
      "Vishan Vishesh Oberoi",
      "Bolin Wu",
      "Mahima Jagadeesh Patel",
      "Kangrui Mao",
      "Chuning Shi",
      "I-Ta Lee",
      "Arnold Overwijk",
      "Chenyan Xiong"
    ],
    "pdf_url": "http://arxiv.org/pdf/2510.26095v1"
  },
  {
    "id": "2510.26038v1",
    "title": "Do Students Debias Like Teachers? On the Distillability of Bias\n  Mitigation Methods",
    "abstract": "Knowledge distillation (KD) is an effective method for model compression and\ntransferring knowledge between models. However, its effect on model's\nrobustness against spurious correlations that degrade performance on\nout-of-distribution data remains underexplored. This study investigates the\neffect of knowledge distillation on the transferability of ``debiasing''\ncapabilities from teacher models to student models on natural language\ninference (NLI) and image classification tasks. Through extensive experiments,\nwe illustrate several key findings: (i) overall the debiasing capability of a\nmodel is undermined post-KD; (ii) training a debiased model does not benefit\nfrom injecting teacher knowledge; (iii) although the overall robustness of a\nmodel may remain stable post-distillation, significant variations can occur\nacross different types of biases; and (iv) we pin-point the internal attention\npattern and circuit that causes the distinct behavior post-KD. Given the above\nfindings, we propose three effective solutions to improve the distillability of\ndebiasing methods: developing high quality data for augmentation, implementing\niterative knowledge distillation, and initializing student models with weights\nobtained from teacher models. To the best of our knowledge, this is the first\nstudy on the effect of KD on debiasing and its interenal mechanism at scale.\nOur findings provide understandings on how KD works and how to design better\ndebiasing methods.",
    "categories": [
      "cs.LG",
      "cs.AI",
      "cs.CL",
      "cs.CV"
    ],
    "published": "2025-10-30T00:34:16Z",
    "authors": [
      "Jiali Cheng",
      "Chirag Agarwal",
      "Hadi Amiri"
    ],
    "pdf_url": "http://arxiv.org/pdf/2510.26038v1"
  },
  {
    "id": "2510.26037v1",
    "title": "SIRAJ: Diverse and Efficient Red-Teaming for LLM Agents via Distilled\n  Structured Reasoning",
    "abstract": "The ability of LLM agents to plan and invoke tools exposes them to new safety\nrisks, making a comprehensive red-teaming system crucial for discovering\nvulnerabilities and ensuring their safe deployment. We present SIRAJ: a generic\nred-teaming framework for arbitrary black-box LLM agents. We employ a dynamic\ntwo-step process that starts with an agent definition and generates diverse\nseed test cases that cover various risk outcomes, tool-use trajectories, and\nrisk sources. Then, it iteratively constructs and refines model-based\nadversarial attacks based on the execution trajectories of former attempts. To\noptimize the red-teaming cost, we present a model distillation approach that\nleverages structured forms of a teacher model's reasoning to train smaller\nmodels that are equally effective. Across diverse evaluation agent settings,\nour seed test case generation approach yields 2 -- 2.5x boost to the coverage\nof risk outcomes and tool-calling trajectories. Our distilled 8B red-teamer\nmodel improves attack success rate by 100%, surpassing the 671B Deepseek-R1\nmodel. Our ablations and analyses validate the effectiveness of the iterative\nframework, structured reasoning, and the generalization of our red-teamer\nmodels.",
    "categories": [
      "cs.CR",
      "cs.AI",
      "cs.CL"
    ],
    "published": "2025-10-30T00:32:58Z",
    "authors": [
      "Kaiwen Zhou",
      "Ahmed Elgohary",
      "A S M Iftekhar",
      "Amin Saied"
    ],
    "pdf_url": "http://arxiv.org/pdf/2510.26037v1"
  },
  {
    "id": "2510.26032v1",
    "title": "Artificial Intelligence-Enabled Analysis of Radiology Reports:\n  Epidemiology and Consequences of Incidental Thyroid Findings",
    "abstract": "Importance Incidental thyroid findings (ITFs) are increasingly detected on\nimaging performed for non-thyroid indications. Their prevalence, features, and\nclinical consequences remain undefined. Objective To develop, validate, and\ndeploy a natural language processing (NLP) pipeline to identify ITFs in\nradiology reports and assess their prevalence, features, and clinical outcomes.\nDesign, Setting, and Participants Retrospective cohort of adults without prior\nthyroid disease undergoing thyroid-capturing imaging at Mayo Clinic sites from\nJuly 1, 2017, to September 30, 2023. A transformer-based NLP pipeline\nidentified ITFs and extracted nodule characteristics from image reports from\nmultiple modalities and body regions. Main Outcomes and Measures Prevalence of\nITFs, downstream thyroid ultrasound, biopsy, thyroidectomy, and thyroid cancer\ndiagnosis. Logistic regression identified demographic and imaging-related\nfactors. Results Among 115,683 patients (mean age, 56.8 [SD 17.2] years; 52.9%\nwomen), 9,077 (7.8%) had an ITF, of which 92.9% were nodules. ITFs were more\nlikely in women, older adults, those with higher BMI, and when imaging was\nordered by oncology or internal medicine. Compared with chest CT, ITFs were\nmore likely via neck CT, PET, and nuclear medicine scans. Nodule\ncharacteristics were poorly documented, with size reported in 44% and other\nfeatures in fewer than 15% (e.g. calcifications). Compared with patients\nwithout ITFs, those with ITFs had higher odds of thyroid nodule diagnosis,\nbiopsy, thyroidectomy and thyroid cancer diagnosis. Most cancers were\npapillary, and larger when detected after ITFs vs no ITF. Conclusions ITFs were\ncommon and strongly associated with cascades leading to the detection of small,\nlow-risk cancers. These findings underscore the role of ITFs in thyroid cancer\noverdiagnosis and the need for standardized reporting and more selective\nfollow-up.",
    "categories": [
      "cs.CL",
      "cs.AI"
    ],
    "published": "2025-10-30T00:15:07Z",
    "authors": [
      "Felipe Larios",
      "Mariana Borras-Osorio",
      "Yuqi Wu",
      "Ana Gabriela Claros",
      "David Toro-Tobon",
      "Esteban Cabezas",
      "Ricardo Loor-Torres",
      "Maria Mateo Chavez",
      "Kerly Guevara Maldonado",
      "Luis Vilatuna Andrango",
      "Maria Lizarazo Jimenez",
      "Ivan Mateo Alzamora",
      "Misk Al Zahidy",
      "Marcelo Montero",
      "Ana Cristina Proano",
      "Cristian Soto Jacome",
      "Jungwei W. Fan",
      "Oscar J. Ponce-Ponte",
      "Megan E. Branda",
      "Naykky Singh Ospina",
      "Juan P. Brito"
    ],
    "pdf_url": "http://arxiv.org/pdf/2510.26032v1"
  },
  {
    "id": "2510.26024v1",
    "title": "Rethinking Cross-lingual Alignment: Balancing Transfer and Cultural\n  Erasure in Multilingual LLMs",
    "abstract": "Cross-lingual alignment (CLA) aims to align multilingual representations,\nenabling Large Language Models (LLMs) to seamlessly transfer knowledge across\nlanguages. While intuitive, we hypothesize, this pursuit of representational\nconvergence can inadvertently cause \"cultural erasure\", the functional loss of\nproviding culturally-situated responses that should diverge based on the query\nlanguage. In this work, we systematically analyze this trade-off by introducing\na holistic evaluation framework, the transfer-localization plane, which\nquantifies both desirable knowledge transfer and undesirable cultural erasure.\nUsing this framework, we re-evaluate recent CLA approaches and find that they\nconsistently improve factual transfer at the direct cost of cultural\nlocalization across all six languages studied. Our investigation into the\ninternal representations of these models reveals a key insight: universal\nfactual transfer and culturally-specific knowledge are optimally steerable at\ndifferent model layers. Based on this finding, we propose Surgical Steering, a\nnovel inference-time method that disentangles these two objectives. By applying\ntargeted activation steering to distinct layers, our approach achieves a better\nbalance between the two competing dimensions, effectively overcoming the\nlimitations of current alignment techniques.",
    "categories": [
      "cs.CL",
      "cs.AI"
    ],
    "published": "2025-10-29T23:37:54Z",
    "authors": [
      "HyoJung Han",
      "Sweta Agrawal",
      "Eleftheria Briakou"
    ],
    "pdf_url": "http://arxiv.org/pdf/2510.26024v1"
  },
  {
    "id": "2510.26020v1",
    "title": "PORTool: Tool-Use LLM Training with Rewarded Tree",
    "abstract": "Current tool-use large language models (LLMs) are trained on static datasets,\nenabling them to interact with external tools and perform multi-step,\ntool-integrated reasoning, which produces tool-call trajectories. However,\nthese models imitate how a query is resolved in a generic tool-call routine,\nthereby failing to explore possible solutions and demonstrating limited\nperformance in an evolved, dynamic tool-call environment. In this work, we\npropose PORTool, a reinforcement learning (RL) method that encourages a\ntool-use LLM to explore various trajectories yielding the correct answer.\nSpecifically, this method starts with generating multiple rollouts for a given\nquery, and some of them share the first few tool-call steps, thereby forming a\ntree-like structure. Next, we assign rewards to each step, based on its ability\nto produce a correct answer and make successful tool calls. A shared step\nacross different trajectories receives the same reward, while different steps\nunder the same fork receive different rewards. Finally, these step-wise rewards\nare used to calculate fork-relative advantages, blended with\ntrajectory-relative advantages, to train the LLM for tool use. The experiments\nutilize 17 tools to address user queries, covering both time-sensitive and\ntime-invariant topics. We conduct ablation studies to systematically justify\nthe necessity and the design robustness of step-wise rewards. Furthermore, we\ncompare the proposed PORTool with other training approaches and demonstrate\nsignificant improvements in final accuracy and the number of tool-call steps.",
    "categories": [
      "cs.CL",
      "cs.AI",
      "cs.LG"
    ],
    "published": "2025-10-29T23:28:53Z",
    "authors": [
      "Feijie Wu",
      "Weiwu Zhu",
      "Yuxiang Zhang",
      "Soumya Chatterjee",
      "Jiarong Zhu",
      "Fan Mo",
      "Rodin Luo",
      "Jing Gao"
    ],
    "pdf_url": "http://arxiv.org/pdf/2510.26020v1"
  },
  {
    "id": "2510.26006v1",
    "title": "CAVE: Detecting and Explaining Commonsense Anomalies in Visual\n  Environments",
    "abstract": "Humans can naturally identify, reason about, and explain anomalies in their\nenvironment. In computer vision, this long-standing challenge remains limited\nto industrial defects or unrealistic, synthetically generated anomalies,\nfailing to capture the richness and unpredictability of real-world anomalies.\nIn this work, we introduce CAVE, the first benchmark of real-world visual\nanomalies. CAVE supports three open-ended tasks: anomaly description,\nexplanation, and justification; with fine-grained annotations for visual\ngrounding and categorizing anomalies based on their visual manifestations,\ntheir complexity, severity, and commonness. These annotations draw inspiration\nfrom cognitive science research on how humans identify and resolve anomalies,\nproviding a comprehensive framework for evaluating Vision-Language Models\n(VLMs) in detecting and understanding anomalies. We show that state-of-the-art\nVLMs struggle with visual anomaly perception and commonsense reasoning, even\nwith advanced prompting strategies. By offering a realistic and cognitively\ngrounded benchmark, CAVE serves as a valuable resource for advancing research\nin anomaly detection and commonsense reasoning in VLMs.",
    "categories": [
      "cs.CV",
      "cs.CL"
    ],
    "published": "2025-10-29T22:34:26Z",
    "authors": [
      "Rishika Bhagwatkar",
      "Syrielle Montariol",
      "Angelika Romanou",
      "Beatriz Borges",
      "Irina Rish",
      "Antoine Bosselut"
    ],
    "pdf_url": "http://arxiv.org/pdf/2510.26006v1"
  },
  {
    "id": "2510.25992v1",
    "title": "Supervised Reinforcement Learning: From Expert Trajectories to Step-wise\n  Reasoning",
    "abstract": "Large Language Models (LLMs) often struggle with problems that require\nmulti-step reasoning. For small-scale open-source models, Reinforcement\nLearning with Verifiable Rewards (RLVR) fails when correct solutions are rarely\nsampled even after many attempts, while Supervised Fine-Tuning (SFT) tends to\noverfit long demonstrations through rigid token-by-token imitation. To address\nthis gap, we propose Supervised Reinforcement Learning (SRL), a framework that\nreformulates problem solving as generating a sequence of logical \"actions\". SRL\ntrains the model to generate an internal reasoning monologue before committing\nto each action. It provides smoother rewards based on the similarity between\nthe model's actions and expert actions extracted from the SFT dataset in a\nstep-wise manner. This supervision offers richer learning signals even when all\nrollouts are incorrect, while encouraging flexible reasoning guided by expert\ndemonstrations. As a result, SRL enables small models to learn challenging\nproblems previously unlearnable by SFT or RLVR. Moreover, initializing training\nwith SRL before refining with RLVR yields the strongest overall performance.\nBeyond reasoning benchmarks, SRL generalizes effectively to agentic software\nengineering tasks, establishing it as a robust and versatile training framework\nfor reasoning-oriented LLMs.",
    "categories": [
      "cs.CL",
      "cs.AI",
      "cs.LG"
    ],
    "published": "2025-10-29T22:05:08Z",
    "authors": [
      "Yihe Deng",
      "I-Hung Hsu",
      "Jun Yan",
      "Zifeng Wang",
      "Rujun Han",
      "Gufeng Zhang",
      "Yanfei Chen",
      "Wei Wang",
      "Tomas Pfister",
      "Chen-Yu Lee"
    ],
    "pdf_url": "http://arxiv.org/pdf/2510.25992v1"
  },
  {
    "id": "2510.25979v1",
    "title": "AttnCache: Accelerating Self-Attention Inference for LLM Prefill via\n  Attention Cache",
    "abstract": "Large Language Models (LLMs) are widely used in generative applications such\nas chatting, code generation, and reasoning. However, many realworld workloads\nsuch as classification, question answering, recommendation, and text embedding\nrely solely on the prefill stage of inference, where the model encodes input\nsequences without performing autoregressive decoding. In these prefill only\nscenarios, the self-attention computation becomes the primary performance\nbottleneck due to its quadratic complexity with respect to sequence length. In\nthis paper, we observe that semantically different sentences often produce\nsimilar attention maps across layers and heads. Building on this insight, we\npropose AttnCache, a framework that accelerates the prefill stage of LLM\ninference by retrieving and reusing similar attention maps. Based on an\nattention map memorization database, AttnCache employs efficient caching and\nsimilarity search techniques to identify and reuse pre-cached attention maps\nduring inference, thereby reducing the computational overhead of\nself-attention. Experimental results show that AttnCache achieves an average of\n1.2x end-to-end and 2x attention speedup on CPU, and 1.6x end-to-end and 3x\nattention speedup on GPU, with negligible accuracy degradation.",
    "categories": [
      "cs.CL",
      "cs.LG"
    ],
    "published": "2025-10-29T21:26:17Z",
    "authors": [
      "Dinghong Song",
      "Yuan Feng",
      "Yiwei Wang",
      "Shangye Chen",
      "Cyril Guyot",
      "Filip Blagojevic",
      "Hyeran Jeon",
      "Pengfei Su",
      "Dong Li"
    ],
    "pdf_url": "http://arxiv.org/pdf/2510.25979v1"
  },
  {
    "id": "2510.25977v1",
    "title": "NeuronMM: High-Performance Matrix Multiplication for LLM Inference on\n  AWS Trainium",
    "abstract": "AI accelerators, customized to AI workloads, provide cost-effective and\nhigh-performance solutions for training and inference. Trainium, an AI\naccelerator recently developed by Amazon Web Services (AWS), provides an\nattractive option for LLM training and inference through its heterogeneous\narchitecture. However, leveraging Trainium architecture for high performance\ncan be challenging because of its systolic array architecture and special\nrequirement on data layout. In this paper, we design high-performance matrix\nmultiplication (matmul), a critical compute kernel, for LLM inference on\nTrainium. We introduce a series of techniques customized to Trainium based on\nkernel fusion and novel caching strategies to reduce data movement across the\nsoftware-managed memory hierarchy, maximize SRAM bandwidth, and avoid expensive\nmatrix transpose. Evaluating with nine datasets and four recent LLMs, we show\nthat our system largely outperforms the state-of-the-art matmul implemented by\nAWS on Trainium: at the level of matmul kernel, it achieves an average 1.35x\nspeedup (up to 2.22x), which translates to an average 1.66x speedup (up to\n2.49x) for end-to-end LLM inference.",
    "categories": [
      "cs.CL"
    ],
    "published": "2025-10-29T21:22:08Z",
    "authors": [
      "Dinghong Song",
      "Jierui Xu",
      "Weichu Yang",
      "Pengfei Su",
      "Dong Li"
    ],
    "pdf_url": "http://arxiv.org/pdf/2510.25977v1"
  },
  {
    "id": "2510.25975v1",
    "title": "SymCode: A Neurosymbolic Approach to Mathematical Reasoning via\n  Verifiable Code Generation",
    "abstract": "Large Language Models (LLMs) often struggle with complex mathematical\nreasoning, where prose-based generation leads to unverified and arithmetically\nunsound solutions. Current prompting strategies like Chain of Thought still\noperate within this unreliable medium, lacking a mechanism for deterministic\nverification. To address these limitations, we introduce SymCode, a\nneurosymbolic framework that reframes mathematical problem-solving as a task of\nverifiable code generation using the SymPy library. We evaluate SymCode on\nchallenging benchmarks, including MATH-500 and OlympiadBench, demonstrating\nsignificant accuracy improvements of up to 13.6 percentage points over\nbaselines. Our analysis shows that SymCode is not only more token-efficient but\nalso fundamentally shifts model failures from opaque logical fallacies towards\ntransparent, programmatic errors. By grounding LLM reasoning in a deterministic\nsymbolic engine, SymCode represents a key step towards more accurate and\ntrustworthy AI in formal domains.",
    "categories": [
      "cs.CL",
      "cs.PL"
    ],
    "published": "2025-10-29T21:17:57Z",
    "authors": [
      "Sina Bagheri Nezhad",
      "Yao Li",
      "Ameeta Agrawal"
    ],
    "pdf_url": "http://arxiv.org/pdf/2510.25975v1"
  },
  {
    "id": "2510.25967v1",
    "title": "Semantic Label Drift in Cross-Cultural Translation",
    "abstract": "Machine Translation (MT) is widely employed to address resource scarcity in\nlow-resource languages by generating synthetic data from high-resource\ncounterparts. While sentiment preservation in translation has long been\nstudied, a critical but underexplored factor is the role of cultural alignment\nbetween source and target languages. In this paper, we hypothesize that\nsemantic labels are drifted or altered during MT due to cultural divergence.\nThrough a series of experiments across culturally sensitive and neutral\ndomains, we establish three key findings: (1) MT systems, including modern\nLarge Language Models (LLMs), induce label drift during translation,\nparticularly in culturally sensitive domains; (2) unlike earlier statistical MT\ntools, LLMs encode cultural knowledge, and leveraging this knowledge can\namplify label drift; and (3) cultural similarity or dissimilarity between\nsource and target languages is a crucial determinant of label preservation. Our\nfindings highlight that neglecting cultural factors in MT not only undermines\nlabel fidelity but also risks misinterpretation and cultural conflict in\ndownstream applications.",
    "categories": [
      "cs.CL"
    ],
    "published": "2025-10-29T21:11:23Z",
    "authors": [
      "Mohsinul Kabir",
      "Tasnim Ahmed",
      "Md Mezbaur Rahman",
      "Polydoros Giannouris",
      "Sophia Ananiadou"
    ],
    "pdf_url": "http://arxiv.org/pdf/2510.25967v1"
  },
  {
    "id": "2510.25947v1",
    "title": "Revisiting Multilingual Data Mixtures in Language Model Pretraining",
    "abstract": "The impact of different multilingual data mixtures in pretraining large\nlanguage models (LLMs) has been a topic of ongoing debate, often raising\nconcerns about potential trade-offs between language coverage and model\nperformance (i.e., the curse of multilinguality). In this work, we investigate\nthese assumptions by training 1.1B and 3B parameter LLMs on diverse\nmultilingual corpora, varying the number of languages from 25 to 400. Our study\nchallenges common beliefs surrounding multilingual training. First, we find\nthat combining English and multilingual data does not necessarily degrade the\nin-language performance of either group, provided that languages have a\nsufficient number of tokens included in the pretraining corpus. Second, we\nobserve that using English as a pivot language (i.e., a high-resource language\nthat serves as a catalyst for multilingual generalization) yields benefits\nacross language families, and contrary to expectations, selecting a pivot\nlanguage from within a specific family does not consistently improve\nperformance for languages within that family. Lastly, we do not observe a\nsignificant \"curse of multilinguality\" as the number of training languages\nincreases in models at this scale. Our findings suggest that multilingual data,\nwhen balanced appropriately, can enhance language model capabilities without\ncompromising performance, even in low-resource settings",
    "categories": [
      "cs.CL",
      "cs.AI",
      "cs.LG"
    ],
    "published": "2025-10-29T20:46:03Z",
    "authors": [
      "Negar Foroutan",
      "Paul Teiletche",
      "Ayush Kumar Tarun",
      "Antoine Bosselut"
    ],
    "pdf_url": "http://arxiv.org/pdf/2510.25947v1"
  },
  {
    "id": "2510.25941v1",
    "title": "RECAP: Reproducing Copyrighted Data from LLMs Training with an Agentic\n  Pipeline",
    "abstract": "If we cannot inspect the training data of a large language model (LLM), how\ncan we ever know what it has seen? We believe the most compelling evidence\narises when the model itself freely reproduces the target content. As such, we\npropose RECAP, an agentic pipeline designed to elicit and verify memorized\ntraining data from LLM outputs. At the heart of RECAP is a feedback-driven\nloop, where an initial extraction attempt is evaluated by a secondary language\nmodel, which compares the output against a reference passage and identifies\ndiscrepancies. These are then translated into minimal correction hints, which\nare fed back into the target model to guide subsequent generations. In\naddition, to address alignment-induced refusals, RECAP includes a jailbreaking\nmodule that detects and overcomes such barriers. We evaluate RECAP on\nEchoTrace, a new benchmark spanning over 30 full books, and the results show\nthat RECAP leads to substantial gains over single-iteration approaches. For\ninstance, with GPT-4.1, the average ROUGE-L score for the copyrighted text\nextraction improved from 0.38 to 0.47 - a nearly 24% increase.",
    "categories": [
      "cs.CL",
      "I.2"
    ],
    "published": "2025-10-29T20:36:37Z",
    "authors": [
      "Andr\u00e9 V. Duarte",
      "Xuying li",
      "Bin Zeng",
      "Arlindo L. Oliveira",
      "Lei Li",
      "Zhuo Li"
    ],
    "pdf_url": "http://arxiv.org/pdf/2510.25941v1"
  },
  {
    "id": "2510.25932v1",
    "title": "FakeZero: Real-Time, Privacy-Preserving Misinformation Detection for\n  Facebook and X",
    "abstract": "Social platforms distribute information at unprecedented speed, which in turn\naccelerates the spread of misinformation and threatens public discourse. We\npresent FakeZero, a fully client-side, cross-platform browser extension that\nflags unreliable posts on Facebook and X (formerly Twitter) while the user\nscrolls. All computation, DOM scraping, tokenisation, Transformer inference,\nand UI rendering run locally through the Chromium messaging API, so no personal\ndata leaves the device.FakeZero employs a three-stage training curriculum:\nbaseline fine-tuning and domain-adaptive training enhanced with focal loss,\nadversarial augmentation, and post-training quantisation. Evaluated on a\ndataset of 239,000 posts, the DistilBERT-Quant model (67.6 MB) reaches 97.1%\nmacro-F1, 97.4% accuracy, and an AUROC of 0.996, with a median latency of\napproximately 103 ms on a commodity laptop. A memory-efficient TinyBERT-Quant\nvariant retains 95.7% macro-F1 and 96.1% accuracy while shrinking the model to\n14.7 MB and lowering latency to approximately 40 ms, showing that high-quality\nfake-news detection is feasible under tight resource budgets with only modest\nperformance loss.By providing inline credibility cues, the extension can serve\nas a valuable tool for policymakers seeking to curb the spread of\nmisinformation across social networks. With user consent, FakeZero also opens\nthe door for researchers to collect large-scale datasets of fake news in the\nwild, enabling deeper analysis and the development of more robust detection\ntechniques.",
    "categories": [
      "cs.CR",
      "cs.CL"
    ],
    "published": "2025-10-29T20:11:48Z",
    "authors": [
      "Soufiane Essahli",
      "Oussama Sarsar",
      "Imane Fouad",
      "Anas Motii",
      "Ahmed Bentajer"
    ],
    "pdf_url": "http://arxiv.org/pdf/2510.25932v1"
  },
  {
    "id": "2510.25904v1",
    "title": "Evaluating the Impact of LLM-Assisted Annotation in a Perspectivized\n  Setting: the Case of FrameNet Annotation",
    "abstract": "The use of LLM-based applications as a means to accelerate and/or substitute\nhuman labor in the creation of language resources and dataset is a reality.\nNonetheless, despite the potential of such tools for linguistic research,\ncomprehensive evaluation of their performance and impact on the creation of\nannotated datasets, especially under a perspectivized approach to NLP, is still\nmissing. This paper contributes to reduction of this gap by reporting on an\nextensive evaluation of the (semi-)automatization of FrameNet-like semantic\nannotation by the use of an LLM-based semantic role labeler. The methodology\nemployed compares annotation time, coverage and diversity in three experimental\nsettings: manual, automatic and semi-automatic annotation. Results show that\nthe hybrid, semi-automatic annotation setting leads to increased frame\ndiversity and similar annotation coverage, when compared to the human-only\nsetting, while the automatic setting performs considerably worse in all\nmetrics, except for annotation time.",
    "categories": [
      "cs.CL",
      "cs.AI"
    ],
    "published": "2025-10-29T19:13:48Z",
    "authors": [
      "Frederico Belcavello",
      "Ely Matos",
      "Arthur Lorenzi",
      "Lisandra Bonoto",
      "L\u00edvia Ruiz",
      "Luiz Fernando Pereira",
      "Victor Herbst",
      "Yulla Navarro",
      "Helen de Andrade Abreu",
      "L\u00edvia Dutra",
      "Tiago Timponi Torrent"
    ],
    "pdf_url": "http://arxiv.org/pdf/2510.25904v1"
  },
  {
    "id": "2510.25884v1",
    "title": "Approximating Human Preferences Using a Multi-Judge Learned System",
    "abstract": "Aligning LLM-based judges with human preferences is a significant challenge,\nas they are difficult to calibrate and often suffer from rubric sensitivity,\nbias, and instability. Overcoming this challenge advances key applications,\nsuch as creating reliable reward models for Reinforcement Learning from Human\nFeedback (RLHF) and building effective routing systems that select the\nbest-suited model for a given user query. In this work, we propose a framework\nfor modeling diverse, persona-based preferences by learning to aggregate\noutputs from multiple rubric-conditioned judges. We investigate the performance\nof this approach against naive baselines and assess its robustness through case\nstudies on both human and LLM-judges biases. Our primary contributions include\na persona-based method for synthesizing preference labels at scale and two\ndistinct implementations of our aggregator: Generalized Additive Model (GAM)\nand a Multi-Layer Perceptron (MLP).",
    "categories": [
      "cs.AI",
      "cs.CL",
      "cs.LG"
    ],
    "published": "2025-10-29T18:32:53Z",
    "authors": [
      "Eit\u00e1n Sprejer",
      "Fernando Avalos",
      "Augusto Bernardi",
      "Jose Pedro Brito de Azevedo Faustino",
      "Jacob Haimes",
      "Narmeen Fatimah Oozeer"
    ],
    "pdf_url": "http://arxiv.org/pdf/2510.25884v1"
  },
  {
    "id": "2510.25860v1",
    "title": "Through the Judge's Eyes: Inferred Thinking Traces Improve Reliability\n  of LLM Raters",
    "abstract": "Large language models (LLMs) are increasingly used as raters for evaluation\ntasks. However, their reliability is often limited for subjective tasks, when\nhuman judgments involve subtle reasoning beyond annotation labels. Thinking\ntraces, the reasoning behind a judgment, are highly informative but challenging\nto collect and curate. We present a human-LLM collaborative framework to infer\nthinking traces from label-only annotations. The proposed framework uses a\nsimple and effective rejection sampling method to reconstruct these traces at\nscale. These inferred thinking traces are applied to two complementary tasks:\n(1) fine-tuning open LLM raters; and (2) synthesizing clearer annotation\nguidelines for proprietary LLM raters. Across multiple datasets, our methods\nlead to significantly improved LLM-human agreement. Additionally, the refined\nannotation guidelines increase agreement among different LLM models. These\nresults suggest that LLMs can serve as practical proxies for otherwise\nunrevealed human thinking traces, enabling label-only corpora to be extended\ninto thinking-trace-augmented resources that enhance the reliability of LLM\nraters.",
    "categories": [
      "cs.AI",
      "cs.CL",
      "cs.HC"
    ],
    "published": "2025-10-29T18:03:44Z",
    "authors": [
      "Xingjian Zhang",
      "Tianhong Gao",
      "Suliang Jin",
      "Tianhao Wang",
      "Teng Ye",
      "Eytan Adar",
      "Qiaozhu Mei"
    ],
    "pdf_url": "http://arxiv.org/pdf/2510.25860v1"
  },
  {
    "id": "2510.25771v1",
    "title": "Gaperon: A Peppered English-French Generative Language Model Suite",
    "abstract": "We release Gaperon, a fully open suite of French-English-coding language\nmodels designed to advance transparency and reproducibility in large-scale\nmodel training. The Gaperon family includes 1.5B, 8B, and 24B parameter models\ntrained on 2-4 trillion tokens, released with all elements of the training\npipeline: French and English datasets filtered with a neural quality\nclassifier, an efficient data curation and training framework, and hundreds of\nintermediate checkpoints. Through this work, we study how data filtering and\ncontamination interact to shape both benchmark and generative performance. We\nfind that filtering for linguistic quality enhances text fluency and coherence\nbut yields subpar benchmark results, and that late deliberate contamination --\ncontinuing training on data mixes that include test sets -- recovers\ncompetitive scores while only reasonably harming generation quality. We discuss\nhow usual neural filtering can unintentionally amplify benchmark leakage. To\nsupport further research, we also introduce harmless data poisoning during\npretraining, providing a realistic testbed for safety studies. By openly\nreleasing all models, datasets, code, and checkpoints, Gaperon establishes a\nreproducible foundation for exploring the trade-offs between data curation,\nevaluation, safety, and openness in multilingual language model development.",
    "categories": [
      "cs.CL",
      "cs.AI"
    ],
    "published": "2025-10-29T17:59:39Z",
    "authors": [
      "Nathan Godey",
      "Wissam Antoun",
      "Rian Touchent",
      "Rachel Bawden",
      "\u00c9ric de la Clergerie",
      "Beno\u00eet Sagot",
      "Djam\u00e9 Seddah"
    ],
    "pdf_url": "http://arxiv.org/pdf/2510.25771v1"
  },
  {
    "id": "2510.25766v1",
    "title": "Decomposition-Enhanced Training for Post-Hoc Attributions In Language\n  Models",
    "abstract": "Large language models (LLMs) are increasingly used for long-document question\nanswering, where reliable attribution to sources is critical for trust.\nExisting post-hoc attribution methods work well for extractive QA but struggle\nin multi-hop, abstractive, and semi-extractive settings, where answers\nsynthesize information across passages. To address these challenges, we argue\nthat post-hoc attribution can be reframed as a reasoning problem, where answers\nare decomposed into constituent units, each tied to specific context. We first\nshow that prompting models to generate such decompositions alongside\nattributions improves performance. Building on this, we introduce DecompTune, a\npost-training method that teaches models to produce answer decompositions as\nintermediate reasoning steps. We curate a diverse dataset of complex QA tasks,\nannotated with decompositions by a strong LLM, and post-train Qwen-2.5 (7B and\n14B) using a two-stage SFT + GRPO pipeline with task-specific curated rewards.\nAcross extensive experiments and ablations, DecompTune substantially improves\nattribution quality, outperforming prior methods and matching or exceeding\nstate-of-the-art frontier models.",
    "categories": [
      "cs.CL"
    ],
    "published": "2025-10-29T17:58:59Z",
    "authors": [
      "Sriram Balasubramaniam",
      "Samyadeep Basu",
      "Koustava Goswami",
      "Ryan Rossi",
      "Varun Manjunatha",
      "Roshan Santhosh",
      "Ruiyi Zhang",
      "Soheil Feizi",
      "Nedim Lipka"
    ],
    "pdf_url": "http://arxiv.org/pdf/2510.25766v1"
  },
  {
    "id": "2510.25761v1",
    "title": "DiagramEval: Evaluating LLM-Generated Diagrams via Graphs",
    "abstract": "Diagrams play a central role in research papers for conveying ideas, yet they\nare often notoriously complex and labor-intensive to create. Although diagrams\nare presented as images, standard image generative models struggle to produce\nclear diagrams with well-defined structure. We argue that a promising direction\nis to generate demonstration diagrams directly in textual form as SVGs, which\ncan leverage recent advances in large language models (LLMs). However, due to\nthe complexity of components and the multimodal nature of diagrams,\nsufficiently discriminative and explainable metrics for evaluating the quality\nof LLM-generated diagrams remain lacking. In this paper, we propose\nDiagramEval, a novel evaluation metric designed to assess demonstration\ndiagrams generated by LLMs. Specifically, DiagramEval conceptualizes diagrams\nas graphs, treating text elements as nodes and their connections as directed\nedges, and evaluates diagram quality using two new groups of metrics: node\nalignment and path alignment. For the first time, we effectively evaluate\ndiagrams produced by state-of-the-art LLMs on recent research literature,\nquantitatively demonstrating the validity of our metrics. Furthermore, we show\nhow the enhanced explainability of our proposed metrics offers valuable\ninsights into the characteristics of LLM-generated diagrams. Code:\nhttps://github.com/ulab-uiuc/diagram-eval.",
    "categories": [
      "cs.CL"
    ],
    "published": "2025-10-29T17:56:17Z",
    "authors": [
      "Chumeng Liang",
      "Jiaxuan You"
    ],
    "pdf_url": "http://arxiv.org/pdf/2510.25761v1"
  },
  {
    "id": "2510.25744v2",
    "title": "Completion $\\neq$ Collaboration: Scaling Collaborative Effort with\n  Agents",
    "abstract": "Current evaluations of agents remain centered around one-shot task\ncompletion, failing to account for the inherently iterative and collaborative\nnature of many real-world problems, where human goals are often underspecified\nand evolve. We argue for a shift from building and assessing task completion\nagents to developing collaborative agents, assessed not only by the quality of\ntheir final outputs but by how well they engage with and enhance human effort\nthroughout the problem-solving process. To support this shift, we introduce\ncollaborative effort scaling, a framework that captures how an agent's utility\ngrows with increasing user involvement. Through case studies and simulated\nevaluations, we show that state-of-the-art agents often underperform in\nmulti-turn, real-world scenarios, revealing a missing ingredient in agent\ndesign: the ability to sustain engagement and scaffold user understanding.\nCollaborative effort scaling offers a lens for diagnosing agent behavior and\nguiding development toward more effective interactions.",
    "categories": [
      "cs.CL",
      "cs.AI"
    ],
    "published": "2025-10-29T17:47:18Z",
    "authors": [
      "Shannon Zejiang Shen",
      "Valerie Chen",
      "Ken Gu",
      "Alexis Ross",
      "Zixian Ma",
      "Jillian Ross",
      "Alex Gu",
      "Chenglei Si",
      "Wayne Chi",
      "Andi Peng",
      "Jocelyn J Shen",
      "Ameet Talwalkar",
      "Tongshuang Wu",
      "David Sontag"
    ],
    "pdf_url": "http://arxiv.org/pdf/2510.25744v2"
  },
  {
    "id": "2510.25741v1",
    "title": "Scaling Latent Reasoning via Looped Language Models",
    "abstract": "Modern LLMs are trained to \"think\" primarily via explicit text generation,\nsuch as chain-of-thought (CoT), which defers reasoning to post-training and\nunder-leverages pre-training data. We present and open-source Ouro, named after\nthe recursive Ouroboros, a family of pre-trained Looped Language Models\n(LoopLM) that instead build reasoning into the pre-training phase through (i)\niterative computation in latent space, (ii) an entropy-regularized objective\nfor learned depth allocation, and (iii) scaling to 7.7T tokens. Ouro 1.4B and\n2.6B models enjoy superior performance that match the results of up to 12B SOTA\nLLMs across a wide range of benchmarks. Through controlled experiments, we show\nthis advantage stems not from increased knowledge capacity, but from superior\nknowledge manipulation capabilities. We also show that LoopLM yields reasoning\ntraces more aligned with final outputs than explicit CoT. We hope our results\nshow the potential of LoopLM as a novel scaling direction in the reasoning era.\nOur model could be found in: http://ouro-llm.github.io.",
    "categories": [
      "cs.CL"
    ],
    "published": "2025-10-29T17:45:42Z",
    "authors": [
      "Rui-Jie Zhu",
      "Zixuan Wang",
      "Kai Hua",
      "Tianyu Zhang",
      "Ziniu Li",
      "Haoran Que",
      "Boyi Wei",
      "Zixin Wen",
      "Fan Yin",
      "He Xing",
      "Lu Li",
      "Jiajun Shi",
      "Kaijing Ma",
      "Shanda Li",
      "Taylor Kergan",
      "Andrew Smith",
      "Xingwei Qu",
      "Mude Hui",
      "Bohong Wu",
      "Qiyang Min",
      "Hongzhi Huang",
      "Xun Zhou",
      "Wei Ye",
      "Jiaheng Liu",
      "Jian Yang",
      "Yunfeng Shi",
      "Chenghua Lin",
      "Enduo Zhao",
      "Tianle Cai",
      "Ge Zhang",
      "Wenhao Huang",
      "Yoshua Bengio",
      "Jason Eshraghian"
    ],
    "pdf_url": "http://arxiv.org/pdf/2510.25741v1"
  },
  {
    "id": "2510.25732v1",
    "title": "The Limits of Obliviate: Evaluating Unlearning in LLMs via\n  Stimulus-Knowledge Entanglement-Behavior Framework",
    "abstract": "Unlearning in large language models (LLMs) is crucial for managing sensitive\ndata and correcting misinformation, yet evaluating its effectiveness remains an\nopen problem. We investigate whether persuasive prompting can recall factual\nknowledge from deliberately unlearned LLMs across models ranging from 2.7B to\n13B parameters (OPT-2.7B, LLaMA-2-7B, LLaMA-3.1-8B, LLaMA-2-13B). Drawing from\nACT-R and Hebbian theory (spreading activation theories), as well as\ncommunication principles, we introduce Stimulus-Knowledge Entanglement-Behavior\nFramework (SKeB), which models information entanglement via domain graphs and\ntests whether factual recall in unlearned models is correlated with persuasive\nframing. We develop entanglement metrics to quantify knowledge activation\npatterns and evaluate factuality, non-factuality, and hallucination in outputs.\nOur results show persuasive prompts substantially enhance factual knowledge\nrecall (14.8% baseline vs. 24.5% with authority framing), with effectiveness\ninversely correlated to model size (128% recovery in 2.7B vs. 15% in 13B). SKeB\nprovides a foundation for assessing unlearning completeness, robustness, and\noverall behavior in LLMs.",
    "categories": [
      "cs.CL",
      "cs.AI",
      "I.2.7; I.2.6; I.2.4; G.2.2"
    ],
    "published": "2025-10-29T17:37:50Z",
    "authors": [
      "Aakriti Shah",
      "Thai Le"
    ],
    "pdf_url": "http://arxiv.org/pdf/2510.25732v1"
  },
  {
    "id": "2510.25726v1",
    "title": "The Tool Decathlon: Benchmarking Language Agents for Diverse, Realistic,\n  and Long-Horizon Task Execution",
    "abstract": "Real-world language agents must handle complex, multi-step workflows across\ndiverse Apps. For instance, an agent may manage emails by coordinating with\ncalendars and file systems, or monitor a production database to detect\nanomalies and generate reports following an operating manual. However, existing\nlanguage agent benchmarks often focus on narrow domains or simplified tasks\nthat lack the diversity, realism, and long-horizon complexity required to\nevaluate agents' real-world performance. To address this gap, we introduce the\nTool Decathlon (dubbed as Toolathlon), a benchmark for language agents offering\ndiverse Apps and tools, realistic environment setup, and reliable\nexecution-based evaluation. Toolathlon spans 32 software applications and 604\ntools, ranging from everyday platforms such as Google Calendar and Notion to\nprofessional ones like WooCommerce, Kubernetes, and BigQuery. Most of the tools\nare based on a high-quality set of Model Context Protocol (MCP) servers that we\nmay have revised or implemented ourselves. Unlike prior works, which primarily\nensure functional realism but offer limited environment state diversity, we\nprovide realistic initial environment states from real software, such as Canvas\ncourses with dozens of students or real financial spreadsheets. This benchmark\nincludes 108 manually sourced or crafted tasks in total, requiring interacting\nwith multiple Apps over around 20 turns on average to complete. Each task is\nstrictly verifiable through dedicated evaluation scripts. Comprehensive\nevaluation of SOTA models highlights their significant shortcomings: the\nbest-performing model, Claude-4.5-Sonnet, achieves only a 38.6% success rate\nwith 20.2 tool calling turns on average, while the top open-weights model\nDeepSeek-V3.2-Exp reaches 20.1%. We expect Toolathlon to drive the development\nof more capable language agents for real-world, long-horizon task execution.",
    "categories": [
      "cs.CL",
      "cs.AI"
    ],
    "published": "2025-10-29T17:32:49Z",
    "authors": [
      "Junlong Li",
      "Wenshuo Zhao",
      "Jian Zhao",
      "Weihao Zeng",
      "Haoze Wu",
      "Xiaochen Wang",
      "Rui Ge",
      "Yuxuan Cao",
      "Yuzhen Huang",
      "Wei Liu",
      "Junteng Liu",
      "Zhaochen Su",
      "Yiyang Guo",
      "Fan Zhou",
      "Lueyang Zhang",
      "Juan Michelini",
      "Xingyao Wang",
      "Xiang Yue",
      "Shuyan Zhou",
      "Graham Neubig",
      "Junxian He"
    ],
    "pdf_url": "http://arxiv.org/pdf/2510.25726v1"
  },
  {
    "id": "2510.25701v1",
    "title": "Interpreting LLMs as Credit Risk Classifiers: Do Their Feature\n  Explanations Align with Classical ML?",
    "abstract": "Large Language Models (LLMs) are increasingly explored as flexible\nalternatives to classical machine learning models for classification tasks\nthrough zero-shot prompting. However, their suitability for structured tabular\ndata remains underexplored, especially in high-stakes financial applications\nsuch as financial risk assessment. This study conducts a systematic comparison\nbetween zero-shot LLM-based classifiers and LightGBM, a state-of-the-art\ngradient-boosting model, on a real-world loan default prediction task. We\nevaluate their predictive performance, analyze feature attributions using SHAP,\nand assess the reliability of LLM-generated self-explanations. While LLMs are\nable to identify key financial risk indicators, their feature importance\nrankings diverge notably from LightGBM, and their self-explanations often fail\nto align with empirical SHAP attributions. These findings highlight the\nlimitations of LLMs as standalone models for structured financial risk\nprediction and raise concerns about the trustworthiness of their self-generated\nexplanations. Our results underscore the need for explainability audits,\nbaseline comparisons with interpretable models, and human-in-the-loop oversight\nwhen deploying LLMs in risk-sensitive financial environments.",
    "categories": [
      "cs.CL"
    ],
    "published": "2025-10-29T17:05:00Z",
    "authors": [
      "Saeed AlMarri",
      "Kristof Juhasz",
      "Mathieu Ravaut",
      "Gautier Marti",
      "Hamdan Al Ahbabi",
      "Ibrahim Elfadel"
    ],
    "pdf_url": "http://arxiv.org/pdf/2510.25701v1"
  },
  {
    "id": "2510.25817v1",
    "title": "A Survey on Efficient Large Language Model Training: From Data-centric\n  Perspectives",
    "abstract": "Post-training of Large Language Models (LLMs) is crucial for unlocking their\ntask generalization potential and domain-specific capabilities. However, the\ncurrent LLM post-training paradigm faces significant data challenges, including\nthe high costs of manual annotation and diminishing marginal returns on data\nscales. Therefore, achieving data-efficient post-training has become a key\nresearch question. In this paper, we present the first systematic survey of\ndata-efficient LLM post-training from a data-centric perspective. We propose a\ntaxonomy of data-efficient LLM post-training methods, covering data selection,\ndata quality enhancement, synthetic data generation, data distillation and\ncompression, and self-evolving data ecosystems. We summarize representative\napproaches in each category and outline future research directions. By\nexamining the challenges in data-efficient LLM post-training, we highlight open\nproblems and propose potential research avenues. We hope our work inspires\nfurther exploration into maximizing the potential of data utilization in\nlarge-scale model training. Paper List:\nhttps://github.com/luo-junyu/Awesome-Data-Efficient-LLM",
    "categories": [
      "cs.CL"
    ],
    "published": "2025-10-29T17:01:55Z",
    "authors": [
      "Junyu Luo",
      "Bohan Wu",
      "Xiao Luo",
      "Zhiping Xiao",
      "Yiqiao Jin",
      "Rong-Cheng Tu",
      "Nan Yin",
      "Yifan Wang",
      "Jingyang Yuan",
      "Wei Ju",
      "Ming Zhang"
    ],
    "pdf_url": "http://arxiv.org/pdf/2510.25817v1"
  },
  {
    "id": "2510.25694v1",
    "title": "Process-Level Trajectory Evaluation for Environment Configuration in\n  Software Engineering Agents",
    "abstract": "Large language model-based agents show promise for software engineering, but\nenvironment configuration remains a bottleneck due to heavy manual effort and\nscarce large-scale, high-quality datasets. Existing benchmarks assess only\nend-to-end build/test success, obscuring where and why agents succeed or fail.\nWe introduce the Environment Configuration Diagnosis Benchmark, Enconda-bench,\nwhich provides process-level trajectory assessment of fine-grained agent\ncapabilities during environment setup-planning, perception-driven error\ndiagnosis, feedback-driven repair, and action to execute final environment\nconfiguration. Our task instances are automatically constructed by injecting\nrealistic README errors and are validated in Docker for scalable, high-quality\nevaluation. Enconda-bench combines process-level analysis with end-to-end\nexecutability to enable capability assessments beyond aggregate success rates.\nEvaluations across state-of-the-art LLMs and agent frameworks show that while\nagents can localize errors, they struggle to translate feedback into effective\ncorrections, limiting end-to-end performance. To our knowledge, Enconda-bench\nis the first framework to provide process-level internal capability assessment\nfor environment configuration, offering actionable insights for improving\nsoftware engineering agents.",
    "categories": [
      "cs.SE",
      "cs.AI",
      "cs.CL"
    ],
    "published": "2025-10-29T16:59:07Z",
    "authors": [
      "Jiayi Kuang",
      "Yinghui Li",
      "Xin Zhang",
      "Yangning Li",
      "Di Yin",
      "Xing Sun",
      "Ying Shen",
      "Philip S. Yu"
    ],
    "pdf_url": "http://arxiv.org/pdf/2510.25694v1"
  },
  {
    "id": "2510.25682v2",
    "title": "PairUni: Pairwise Training for Unified Multimodal Language Models",
    "abstract": "Unified vision-language models (UVLMs) must perform both understanding and\ngeneration within a single architecture, but these tasks rely on heterogeneous\ndata and supervision, making it difficult to balance them during reinforcement\nlearning (RL). We propose PairUni, a unified framework that reorganizes data\ninto understanding-generation (UG) pairs and aligns optimization accordingly.\nWe first use GPT-o3 to augment single-task data, generating captions for\nunderstanding samples and question-answer (QA) pairs for generation samples,\nforming aligned pairs from the same instance. Additionally, for each generation\nsample, we retrieve a semantically related understanding example to form a\nretrieved pair, linking different but related data points. These paired\nstructures expose cross-task semantic correspondences and support consistent\npolicy learning. To leverage this structure, we present Pair-GPRO, a pair-aware\nvariant based on Group Relative Policy Optimization. It assigns a similarity\nscore to each pair to modulate the advantage, strengthening learning from\nwell-aligned examples and reducing task interference. We curate a high-quality\ndataset of 16K UG pairs named PairUG for RL fine-tuning and evaluate PairUni on\nthe powerful Janus-Pro UVLMs. Our approach achieves balanced improvements on\nvarious UVLMs, outperforming strong UVLM RL baselines. Codes are available at\nhttps://github.com/Haochen-Wang409/PairUni.",
    "categories": [
      "cs.CL"
    ],
    "published": "2025-10-29T16:47:02Z",
    "authors": [
      "Jiani Zheng",
      "Zhiyang Teng",
      "Xiangtai Li",
      "Anran Wang",
      "Yu Tian",
      "Kunpeng Qiu",
      "Ye Tian",
      "Haochen Wang",
      "Zhuochen Wang"
    ],
    "pdf_url": "http://arxiv.org/pdf/2510.25682v2"
  },
  {
    "id": "2510.25677v1",
    "title": "ZK-SenseLM: Verifiable Large-Model Wireless Sensing with Selective\n  Abstention and Zero-Knowledge Attestation",
    "abstract": "ZK-SenseLM is a secure and auditable wireless sensing framework that pairs a\nlarge-model encoder for Wi-Fi channel state information (and optionally mmWave\nradar or RFID) with a policy-grounded decision layer and end-to-end\nzero-knowledge proofs of inference. The encoder uses masked spectral\npretraining with phase-consistency regularization, plus a light cross-modal\nalignment that ties RF features to compact, human-interpretable policy tokens.\nTo reduce unsafe actions under distribution shift, we add a calibrated\nselective-abstention head; the chosen risk-coverage operating point is\nregistered and bound into the proof. We implement a four-stage proving\npipeline: (C1) feature sanity and commitment, (C2) threshold and version\nbinding, (C3) time-window binding, and (C4) PLONK-style proofs that the\nquantized network, given the committed window, produced the logged action and\nconfidence. Micro-batched proving amortizes cost across adjacent windows, and a\ngateway option offloads proofs from low-power devices. The system integrates\nwith differentially private federated learning and on-device personalization\nwithout weakening verifiability: model hashes and the registered threshold are\npart of each public statement. Across activity, presence or intrusion,\nrespiratory proxy, and RF fingerprinting tasks, ZK-SenseLM improves macro-F1\nand calibration, yields favorable coverage-risk curves under perturbations, and\nrejects tamper and replay with compact proofs and fast verification.",
    "categories": [
      "cs.CR",
      "cs.CL",
      "C.2.1; D.4.6; E.3; I.2.6; I.5.4"
    ],
    "published": "2025-10-29T16:43:07Z",
    "authors": [
      "Hasan Akgul",
      "Mari Eplik",
      "Javier Rojas",
      "Aina Binti Abdullah",
      "Pieter van der Merwe"
    ],
    "pdf_url": "http://arxiv.org/pdf/2510.25677v1"
  },
  {
    "id": "2510.25816v1",
    "title": "Beyond Long Context: When Semantics Matter More than Tokens",
    "abstract": "Electronic Health Records (EHR) store clinical documentation as base64\nencoded attachments in FHIR DocumentReference resources, which makes semantic\nquestion answering difficult. Traditional vector database methods often miss\nnuanced clinical relationships. The Clinical Entity Augmented Retrieval (CLEAR)\nmethod, introduced by Lopez et al. 2025, uses entity aware retrieval and\nachieved improved performance with an F1 score of 0.90 versus 0.86 for\nembedding based retrieval, while using over 70 percent fewer tokens. We\ndeveloped a Clinical Notes QA Evaluation Platform to validate CLEAR against\nzero shot large context inference and traditional chunk based retrieval\naugmented generation. The platform was tested on 12 clinical notes ranging from\n10,000 to 65,000 tokens representing realistic EHR content. CLEAR achieved a\n58.3 percent win rate, an average semantic similarity of 0.878, and used 78\npercent fewer tokens than wide context processing. The largest performance\ngains occurred on long notes, with a 75 percent win rate for documents\nexceeding 65,000 tokens. These findings confirm that entity aware retrieval\nimproves both efficiency and accuracy in clinical natural language processing.\nThe evaluation framework provides a reusable and transparent benchmark for\nassessing clinical question answering systems where semantic precision and\ncomputational efficiency are critical.",
    "categories": [
      "cs.CL",
      "cs.LG",
      "68T50, 68T07",
      "I.2.7; H.3.3"
    ],
    "published": "2025-10-29T16:41:44Z",
    "authors": [
      "Tarun Kumar Chawdhury",
      "Jon D. Duke"
    ],
    "pdf_url": "http://arxiv.org/pdf/2510.25816v1"
  },
  {
    "id": "2510.25628v1",
    "title": "EHR-R1: A Reasoning-Enhanced Foundational Language Model for Electronic\n  Health Record Analysis",
    "abstract": "Electronic Health Records (EHRs) contain rich yet complex information, and\ntheir automated analysis is critical for clinical decision-making. Despite\nrecent advances of large language models (LLMs) in clinical workflows, their\nability to analyze EHRs remains limited due to narrow task coverage and lack of\nEHR-oriented reasoning capabilities. This paper aims to bridge the gap,\nspecifically, we present EHR-Ins, a large-scale, comprehensive EHR reasoning\ninstruction dataset, comprising 300k high-quality reasoning cases and 4M\nnon-reasoning cases across 42 distinct EHR tasks. Its core innovation is a\nthinking-graph-driven framework that enables to generate high-quality reasoning\ndata at scale. Based on it, we develop EHR-R1, a series of reasoning-enhanced\nLLMs with up to 72B parameters tailored for EHR analysis. Through a multi-stage\ntraining paradigm, including domain adaptation, reasoning enhancement, and\nreinforcement learning, EHR-R1 systematically acquires domain knowledge and\ndiverse reasoning capabilities, enabling accurate and robust EHR analysis.\nLastly, we introduce EHR-Bench, a new benchmark curated from MIMIC-IV, spanning\n42 tasks, to comprehensively assess reasoning and prediction across EHR\nscenarios. In experiments, we show that the resulting EHR-R1 consistently\noutperforms state-of-the-art commercial and open-source LLMs (including\nDeepSeek-V3 and GPT-4o), surpassing GPT-4o by over 30 points on MIMIC-Bench and\nachieving a 10\\% higher zero-shot AUROC on EHRSHOT. Collectively, EHR-Ins,\nEHR-R1, and EHR-Bench have significantly advanced the development for more\nreliable and clinically relevant EHR analysis.",
    "categories": [
      "cs.CL"
    ],
    "published": "2025-10-29T15:32:47Z",
    "authors": [
      "Yusheng Liao",
      "Chaoyi Wu",
      "Junwei Liu",
      "Shuyang Jiang",
      "Pengcheng Qiu",
      "Haowen Wang",
      "Yun Yue",
      "Shuai Zhen",
      "Jian Wang",
      "Qianrui Fan",
      "Jinjie Gu",
      "Ya Zhang",
      "Yanfeng Wang",
      "Yu Wang",
      "Weidi Xie"
    ],
    "pdf_url": "http://arxiv.org/pdf/2510.25628v1"
  },
  {
    "id": "2510.25626v1",
    "title": "Are Language Models Efficient Reasoners? A Perspective from Logic\n  Programming",
    "abstract": "Modern language models (LMs) exhibit strong deductive reasoning capabilities,\nyet standard evaluations emphasize correctness while overlooking a key aspect\nof human-like reasoning: efficiency. In real-world reasoning scenarios, much of\nthe available information is irrelevant, and effective deductive inference\nrequires identifying and ignoring such distractions. We propose a framework for\nassessing LM reasoning efficiency through the lens of logic programming,\nintroducing a simple method to align proofs written in natural language -- as\ngenerated by an LM -- with shortest proofs found by executing the logic\nprogram. Efficiency is quantified by measuring how well a model avoids\nunnecessary inference. Empirically, we construct a dataset of math word\nproblems injected with various number of irrelevant axioms that vary in\nsemantic overlap with the goal theorem. We find that current LMs show marked\naccuracy declines under such conditions -- even with minimal, domain-consistent\ndistractions -- and the proofs they generate frequently exhibit detours through\nirrelevant inferences.",
    "categories": [
      "cs.CL",
      "cs.AI",
      "cs.LG",
      "cs.LO"
    ],
    "published": "2025-10-29T15:30:31Z",
    "authors": [
      "Andreas Opedal",
      "Yanick Zengaffinen",
      "Haruki Shirakami",
      "Clemente Pasti",
      "Mrinmaya Sachan",
      "Abulhair Saparov",
      "Ryan Cotterell",
      "Bernhard Sch\u00f6lkopf"
    ],
    "pdf_url": "http://arxiv.org/pdf/2510.25626v1"
  },
  {
    "id": "2510.25623v2",
    "title": "Evaluating the Role of Verifiers in Test-Time Scaling for Legal\n  Reasoning Tasks",
    "abstract": "Test-time scaling (TTS) techniques can improve the performance of large\nlanguage models (LLMs) at the expense of additional computation and latency.\nWhile TTS has proven effective in formal domains such as mathematics and\nprogramming, its value in argumentative domains such as law remains\nunderexplored. We present an empirical study of verifier-based TTS methods for\nlegal multiple-choice QA (MCQA) across five benchmarks. Using a family of 7\nreward models, we evaluate both outcome-level (Best-of-$N$) and process-level\n(tree search) verification under realistic low-$N$ budgets. Our analysis\nsystematically investigates how verifier utility is affected by key properties\nsuch as domain specialization, model size, and supervision type\n(process-supervised PRMs vs. outcome-only ORMs), even when applied across\ndifferent roles.",
    "categories": [
      "cs.CL"
    ],
    "published": "2025-10-29T15:27:47Z",
    "authors": [
      "Davide Romano",
      "Jonathan Schwarz",
      "Daniele Giofr\u00e9"
    ],
    "pdf_url": "http://arxiv.org/pdf/2510.25623v2"
  },
  {
    "id": "2510.25621v1",
    "title": "FARSIQA: Faithful and Advanced RAG System for Islamic Question Answering",
    "abstract": "The advent of Large Language Models (LLMs) has revolutionized Natural\nLanguage Processing, yet their application in high-stakes, specialized domains\nlike religious question answering is hindered by challenges like hallucination\nand unfaithfulness to authoritative sources. This issue is particularly\ncritical for the Persian-speaking Muslim community, where accuracy and\ntrustworthiness are paramount. Existing Retrieval-Augmented Generation (RAG)\nsystems, relying on simplistic single-pass pipelines, fall short on complex,\nmulti-hop queries requiring multi-step reasoning and evidence aggregation. To\naddress this gap, we introduce FARSIQA, a novel, end-to-end system for Faithful\nAdvanced Question Answering in the Persian Islamic domain. FARSIQA is built\nupon our innovative FAIR-RAG architecture: a Faithful, Adaptive, Iterative\nRefinement framework for RAG. FAIR-RAG employs a dynamic, self-correcting\nprocess: it adaptively decomposes complex queries, assesses evidence\nsufficiency, and enters an iterative loop to generate sub-queries,\nprogressively filling information gaps. Operating on a curated knowledge base\nof over one million authoritative Islamic documents, FARSIQA demonstrates\nsuperior performance. Rigorous evaluation on the challenging IslamicPCQA\nbenchmark shows state-of-the-art performance: the system achieves a remarkable\n97.0% in Negative Rejection - a 40-point improvement over baselines - and a\nhigh Answer Correctness score of 74.3%. Our work establishes a new standard for\nPersian Islamic QA and validates that our iterative, adaptive architecture is\ncrucial for building faithful, reliable AI systems in sensitive domains.",
    "categories": [
      "cs.CL",
      "cs.AI",
      "cs.IR",
      "68T50, 68T05, 68T30",
      "I.2.7; H.3.3"
    ],
    "published": "2025-10-29T15:25:34Z",
    "authors": [
      "Mohammad Aghajani Asl",
      "Behrooz Minaei Bidgoli"
    ],
    "pdf_url": "http://arxiv.org/pdf/2510.25621v1"
  },
  {
    "id": "2510.25595v1",
    "title": "Communication and Verification in LLM Agents towards Collaboration under\n  Information Asymmetry",
    "abstract": "While Large Language Model (LLM) agents are often approached from the angle\nof action planning/generation to accomplish a goal (e.g., given by language\ndescriptions), their abilities to collaborate with each other to achieve a\njoint goal are not well explored. To address this limitation, this paper\nstudies LLM agents in task collaboration, particularly under the condition of\ninformation asymmetry, where agents have disparities in their knowledge and\nskills and need to work together to complete a shared task. We extend Einstein\nPuzzles, a classical symbolic puzzle, to a table-top game. In this game, two\nLLM agents must reason, communicate, and act to satisfy spatial and relational\nconstraints required to solve the puzzle. We apply a fine-tuning-plus-verifier\nframework in which LLM agents are equipped with various communication\nstrategies and verification signals from the environment. Empirical results\nhighlight the critical importance of aligned communication, especially when\nagents possess both information-seeking and -providing capabilities.\nInterestingly, agents without communication can still achieve high task\nperformance; however, further analysis reveals a lack of true rule\nunderstanding and lower trust from human evaluators. Instead, by integrating an\nenvironment-based verifier, we enhance agents' ability to comprehend task rules\nand complete tasks, promoting both safer and more interpretable collaboration\nin AI systems. https://github.com/Roihn/EinsteinPuzzles",
    "categories": [
      "cs.CL",
      "cs.AI"
    ],
    "published": "2025-10-29T15:03:53Z",
    "authors": [
      "Run Peng",
      "Ziqiao Ma",
      "Amy Pang",
      "Sikai Li",
      "Zhang Xi-Jia",
      "Yingzhuo Yu",
      "Cristian-Paul Bara",
      "Joyce Chai"
    ],
    "pdf_url": "http://arxiv.org/pdf/2510.25595v1"
  },
  {
    "id": "2510.25577v1",
    "title": "Lost in Phonation: Voice Quality Variation as an Evaluation Dimension\n  for Speech Foundation Models",
    "abstract": "Recent advances in speech foundation models (SFMs) have enabled the direct\nprocessing of spoken language from raw audio, bypassing intermediate textual\nrepresentations. This capability allows SFMs to be exposed to, and potentially\nrespond to, rich paralinguistic variations embedded in the input speech signal.\nOne under-explored dimension of paralinguistic variation is voice quality,\nencompassing phonation types such as creaky and breathy voice. These phonation\ntypes are known to influence how listeners infer affective state, stance and\nsocial meaning in speech. Existing benchmarks for speech understanding largely\nrely on multiple-choice question answering (MCQA) formats, which are prone to\nfailure and therefore unreliable in capturing the nuanced ways paralinguistic\nfeatures influence model behaviour. In this paper, we probe SFMs through\nopen-ended generation tasks and speech emotion recognition, evaluating whether\nmodel behaviours are consistent across different phonation inputs. We introduce\na new parallel dataset featuring synthesized modifications to voice quality,\ndesigned to evaluate SFM responses to creaky and breathy voice. Our work\nprovides the first examination of SFM sensitivity to these particular\nnon-lexical aspects of speech perception.",
    "categories": [
      "eess.AS",
      "cs.AI",
      "cs.CL"
    ],
    "published": "2025-10-29T14:44:44Z",
    "authors": [
      "Harm Lameris",
      "Shree Harsha Bokkahalli Satish",
      "Joakim Gustafson",
      "\u00c9va Sz\u00e9kely"
    ],
    "pdf_url": "http://arxiv.org/pdf/2510.25577v1"
  },
  {
    "id": "2510.25557v1",
    "title": "Hybrid Quantum-Classical Recurrent Neural Networks",
    "abstract": "We present a hybrid quantum-classical recurrent neural network (QRNN)\narchitecture in which the entire recurrent core is realized as a parametrized\nquantum circuit (PQC) controlled by a classical feedforward network. The hidden\nstate is the quantum state of an $n$-qubit PQC, residing in an exponentially\nlarge Hilbert space $\\mathbb{C}^{2^n}$. The PQC is unitary by construction,\nmaking the hidden-state evolution norm-preserving without external constraints.\nAt each timestep, mid-circuit readouts are combined with the input embedding\nand processed by the feedforward network, which provides explicit classical\nnonlinearity. The outputs parametrize the PQC, which updates the hidden state\nvia unitary dynamics. The QRNN is compact and physically consistent, and it\nunifies (i) unitary recurrence as a high-capacity memory, (ii) partial\nobservation via mid-circuit measurements, and (iii) nonlinear classical control\nfor input-conditioned parametrization. We evaluate the model in simulation with\nup to 14 qubits on sentiment analysis, MNIST, permuted MNIST, copying memory,\nand language modeling, adopting projective measurements as a limiting case to\nobtain mid-circuit readouts while maintaining a coherent recurrent quantum\nmemory. We further devise a soft attention mechanism over the mid-circuit\nreadouts in a sequence-to-sequence model and show its effectiveness for machine\ntranslation. To our knowledge, this is the first model (RNN or otherwise)\ngrounded in quantum operations to achieve competitive performance against\nstrong classical baselines across a broad class of sequence-learning tasks.",
    "categories": [
      "cs.LG",
      "cs.AI",
      "cs.CL",
      "quant-ph"
    ],
    "published": "2025-10-29T14:21:49Z",
    "authors": [
      "Wenduan Xu"
    ],
    "pdf_url": "http://arxiv.org/pdf/2510.25557v1"
  },
  {
    "id": "2510.25536v2",
    "title": "TwinVoice: A Multi-dimensional Benchmark Towards Digital Twins via LLM\n  Persona Simulation",
    "abstract": "Large Language Models (LLMs) are exhibiting emergent human-like abilities and\nare increasingly envisioned as the foundation for simulating an individual's\ncommunication style, behavioral tendencies, and personality traits. However,\ncurrent evaluations of LLM-based persona simulation remain limited: most rely\non synthetic dialogues, lack systematic frameworks, and lack analysis of the\ncapability requirement. To address these limitations, we introduce TwinVoice, a\ncomprehensive benchmark for assessing persona simulation across diverse\nreal-world contexts. TwinVoice encompasses three dimensions: Social Persona\n(public social interactions), Interpersonal Persona (private dialogues), and\nNarrative Persona (role-based expression). It further decomposes the evaluation\nof LLM performance into six fundamental capabilities, including opinion\nconsistency, memory recall, logical reasoning, lexical fidelity, persona tone,\nand syntactic style. Experimental results reveal that while advanced models\nachieve moderate accuracy in persona simulation, they still fall short of\ncapabilities such as syntactic style and memory recall. Consequently, the\naverage performance achieved by LLMs remains considerably below the human\nbaseline.",
    "categories": [
      "cs.CL",
      "I.2.7; I.2.6; I.2.0"
    ],
    "published": "2025-10-29T14:00:42Z",
    "authors": [
      "Bangde Du",
      "Minghao Guo",
      "Songming He",
      "Ziyi Ye",
      "Xi Zhu",
      "Weihang Su",
      "Shuqi Zhu",
      "Yujia Zhou",
      "Yongfeng Zhang",
      "Qingyao Ai",
      "Yiqun Liu"
    ],
    "pdf_url": "http://arxiv.org/pdf/2510.25536v2"
  },
  {
    "id": "2510.25460v1",
    "title": "Fine-Tuned Language Models for Domain-Specific Summarization and Tagging",
    "abstract": "This paper presents a pipeline integrating fine-tuned large language models\n(LLMs) with named entity recognition (NER) for efficient domain-specific text\nsummarization and tagging. The authors address the challenge posed by rapidly\nevolving sub-cultural languages and slang, which complicate automated\ninformation extraction and law enforcement monitoring. By leveraging the LLaMA\nFactory framework, the study fine-tunes LLMs on both generalpurpose and custom\ndomain-specific datasets, particularly in the political and security domains.\nThe models are evaluated using BLEU and ROUGE metrics, demonstrating that\ninstruction fine-tuning significantly enhances summarization and tagging\naccuracy, especially for specialized corpora. Notably, the LLaMA3-8B-Instruct\nmodel, despite its initial limitations in Chinese comprehension, outperforms\nits Chinese-trained counterpart after domainspecific fine-tuning, suggesting\nthat underlying reasoning capabilities can transfer across languages. The\npipeline enables concise summaries and structured entity tagging, facilitating\nrapid document categorization and distribution. This approach proves scalable\nand adaptable for real-time applications, supporting efficient information\nmanagement and the ongoing need to capture emerging language trends. The\nintegration of LLMs and NER offers a robust solution for transforming\nunstructured text into actionable insights, crucial for modern knowledge\nmanagement and security operations.",
    "categories": [
      "cs.CL",
      "cs.AI"
    ],
    "published": "2025-10-29T12:33:48Z",
    "authors": [
      "Jun Wang",
      "Fuming Lin",
      "Yuyu Chen"
    ],
    "pdf_url": "http://arxiv.org/pdf/2510.25460v1"
  },
  {
    "id": "2510.25441v1",
    "title": "Grounded in Reality: Learning and Deploying Proactive LLM from Offline\n  Logs",
    "abstract": "Large Language Models (LLMs) excel as passive responders, but teaching them\nto be proactive, goal-oriented partners, a critical capability in high-stakes\ndomains, remains a major challenge. Current paradigms either myopically\noptimize single-turn attributes or rely on brittle, high-cost user simulators,\ncreating a persistent ``reality gap''. To bridge this gap, we introduce\n\\texttt{Learn-to-Ask}, a general, simulator-free framework for learning and\ndeploying proactive dialogue agents \\textit{directly from offline expert data},\nbypassing the need to model complex user dynamics. Our key insight is to\nreframe the offline policy learning problem by leveraging the \\textbf{observed\nfuture} of each expert trajectory. This allows us to infer a dense,\nturn-by-turn reward signal grounded in the expert's revealed strategy,\ndecomposing the intractable long-horizon problem into a series of supervised\nlearning tasks, and training a policy to output a structured \\texttt{(action,\nstate_assessment)} tuple, governing both \\textbf{what to ask} and, crucially,\n\\textbf{when to stop}. To ensure reward fidelity, our Automated Grader\nCalibration pipeline systematically purges noise from the LLM-based reward\nmodel with minimal human supervision. Empirically, we demonstrate the efficacy\nof \\texttt{Learn-to-Ask} in a real-world medical dataset, using LLMs of varying\nsizes up to 32B. Our approach culminates in the successful deployment of LLMs\ninto a live, large-scale online AI service. In rigorous in-house evaluations,\nour model was launched and achieved performance even superior to human experts,\nproving our framework's ability to translate offline data into tangible,\nreal-world impact. We hope this work provides a practical and economically\nviable blueprint for transforming passive LLMs into proactive, goal-oriented\nLLM applications.",
    "categories": [
      "cs.CL",
      "cs.AI"
    ],
    "published": "2025-10-29T12:08:07Z",
    "authors": [
      "Fei Wei",
      "Daoyuan Chen",
      "Ce Wang",
      "Yilun Huang",
      "Yushuo Chen",
      "Xuchen Pan",
      "Yaliang Li",
      "Bolin Ding"
    ],
    "pdf_url": "http://arxiv.org/pdf/2510.25441v1"
  },
  {
    "id": "2510.25440v1",
    "title": "More than a Moment: Towards Coherent Sequences of Audio Descriptions",
    "abstract": "Audio Descriptions (ADs) convey essential on-screen information, allowing\nvisually impaired audiences to follow videos. To be effective, ADs must form a\ncoherent sequence that helps listeners to visualise the unfolding scene, rather\nthan describing isolated moments. However, most automatic methods generate each\nAD independently, often resulting in repetitive, incoherent descriptions. To\naddress this, we propose a training-free method, CoherentAD, that first\ngenerates multiple candidate descriptions for each AD time interval, and then\nperforms auto-regressive selection across the sequence to form a coherent and\ninformative narrative. To evaluate AD sequences holistically, we introduce a\nsequence-level metric, StoryRecall, which measures how well the predicted ADs\nconvey the ground truth narrative, alongside repetition metrics that capture\nthe redundancy across consecutive AD outputs. Our method produces coherent AD\nsequences with enhanced narrative understanding, outperforming prior approaches\nthat rely on independent generations.",
    "categories": [
      "cs.CV",
      "cs.CL"
    ],
    "published": "2025-10-29T12:06:42Z",
    "authors": [
      "Eshika Khandelwal",
      "Junyu Xie",
      "Tengda Han",
      "Max Bain",
      "Arsha Nagrani",
      "Andrew Zisserman",
      "G\u00fcl Varol",
      "Makarand Tapaswi"
    ],
    "pdf_url": "http://arxiv.org/pdf/2510.25440v1"
  },
  {
    "id": "2510.25434v1",
    "title": "A Critical Study of Automatic Evaluation in Sign Language Translation",
    "abstract": "Automatic evaluation metrics are crucial for advancing sign language\ntranslation (SLT). Current SLT evaluation metrics, such as BLEU and ROUGE, are\nonly text-based, and it remains unclear to what extent text-based metrics can\nreliably capture the quality of SLT outputs. To address this gap, we\ninvestigate the limitations of text-based SLT evaluation metrics by analyzing\nsix metrics, including BLEU, chrF, and ROUGE, as well as BLEURT on the one\nhand, and large language model (LLM)-based evaluators such as G-Eval and GEMBA\nzero-shot direct assessment on the other hand. Specifically, we assess the\nconsistency and robustness of these metrics under three controlled conditions:\nparaphrasing, hallucinations in model outputs, and variations in sentence\nlength. Our analysis highlights the limitations of lexical overlap metrics and\ndemonstrates that while LLM-based evaluators better capture semantic\nequivalence often missed by conventional metrics, they can also exhibit bias\ntoward LLM-paraphrased translations. Moreover, although all metrics are able to\ndetect hallucinations, BLEU tends to be overly sensitive, whereas BLEURT and\nLLM-based evaluators are comparatively lenient toward subtle cases. This\nmotivates the need for multimodal evaluation frameworks that extend beyond\ntext-based metrics to enable a more holistic assessment of SLT outputs.",
    "categories": [
      "cs.CL"
    ],
    "published": "2025-10-29T11:57:03Z",
    "authors": [
      "Shakib Yazdani",
      "Yasser Hamidullah",
      "Cristina Espa\u00f1a-Bonet",
      "Eleftherios Avramidis",
      "Josef van Genabith"
    ],
    "pdf_url": "http://arxiv.org/pdf/2510.25434v1"
  },
  {
    "id": "2510.25432v1",
    "title": "Depth and Autonomy: A Framework for Evaluating LLM Applications in\n  Social Science Research",
    "abstract": "Large language models (LLMs) are increasingly utilized by researchers across\na wide range of domains, and qualitative social science is no exception;\nhowever, this adoption faces persistent challenges, including interpretive\nbias, low reliability, and weak auditability. We introduce a framework that\nsituates LLM usage along two dimensions, interpretive depth and autonomy,\nthereby offering a straightforward way to classify LLM applications in\nqualitative research and to derive practical design recommendations. We present\nthe state of the literature with respect to these two dimensions, based on all\npublished social science papers available on Web of Science that use LLMs as a\ntool and not strictly as the subject of study. Rather than granting models\nexpansive freedom, our approach encourages researchers to decompose tasks into\nmanageable segments, much as they would when delegating work to capable\nundergraduate research assistants. By maintaining low levels of autonomy and\nselectively increasing interpretive depth only where warranted and under\nsupervision, one can plausibly reap the benefits of LLMs while preserving\ntransparency and reliability.",
    "categories": [
      "cs.CL"
    ],
    "published": "2025-10-29T11:55:21Z",
    "authors": [
      "Ali Sanaei",
      "Ali Rajabzadeh"
    ],
    "pdf_url": "http://arxiv.org/pdf/2510.25432v1"
  },
  {
    "id": "2510.25427v1",
    "title": "RLMEval: Evaluating Research-Level Neural Theorem Proving",
    "abstract": "Despite impressive results on curated benchmarks, the practical impact of\nlarge language models (LLMs) on research-level neural theorem proving and proof\nautoformalization is still limited. We introduce RLMEval, an evaluation suite\nfor these tasks, focusing on research-level mathematics from real-world Lean\nformalization projects. RLMEval targets the evaluation of neural theorem\nproving and proof autoformalization on challenging research-level theorems by\nleveraging real Lean Blueprint formalization projects. Our evaluation of\nstate-of-the-art models on RLMEval, comprising 613 theorems from 6 Lean\nprojects, reveals a significant gap: progress on existing benchmarks does not\nreadily translate to these more realistic settings, with the best model\nachieving only a 10.3 % pass rate. RLMEval provides a new, challenging\nbenchmark designed to guide and accelerate progress in automated reasoning for\nformal mathematics.",
    "categories": [
      "cs.CL",
      "cs.AI"
    ],
    "published": "2025-10-29T11:49:49Z",
    "authors": [
      "Auguste Poiroux",
      "Antoine Bosselut",
      "Viktor Kun\u010dak"
    ],
    "pdf_url": "http://arxiv.org/pdf/2510.25427v1"
  },
  {
    "id": "2510.25426v1",
    "title": "Implicature in Interaction: Understanding Implicature Improves Alignment\n  in Human-LLM Interaction",
    "abstract": "The rapid advancement of Large Language Models (LLMs) is positioning language\nat the core of human-computer interaction (HCI). We argue that advancing HCI\nrequires attention to the linguistic foundations of interaction, particularly\nimplicature (meaning conveyed beyond explicit statements through shared\ncontext) which is essential for human-AI (HAI) alignment. This study examines\nLLMs' ability to infer user intent embedded in context-driven prompts and\nwhether understanding implicature improves response generation. Results show\nthat larger models approximate human interpretations more closely, while\nsmaller models struggle with implicature inference. Furthermore,\nimplicature-based prompts significantly enhance the perceived relevance and\nquality of responses across models, with notable gains in smaller models.\nOverall, 67.6% of participants preferred responses with implicature-embedded\nprompts to literal ones, highlighting a clear preference for contextually\nnuanced communication. Our work contributes to understanding how linguistic\ntheory can be used to address the alignment problem by making HAI interaction\nmore natural and contextually grounded.",
    "categories": [
      "cs.CL",
      "cs.AI"
    ],
    "published": "2025-10-29T11:49:42Z",
    "authors": [
      "Asutosh Hota",
      "Jussi P. P. Jokinen"
    ],
    "pdf_url": "http://arxiv.org/pdf/2510.25426v1"
  },
  {
    "id": "2510.25413v1",
    "title": "Seeing, Signing, and Saying: A Vision-Language Model-Assisted Pipeline\n  for Sign Language Data Acquisition and Curation from Social Media",
    "abstract": "Most existing sign language translation (SLT) datasets are limited in scale,\nlack multilingual coverage, and are costly to curate due to their reliance on\nexpert annotation and controlled recording setup. Recently, Vision Language\nModels (VLMs) have demonstrated strong capabilities as evaluators and real-time\nassistants. Despite these advancements, their potential remains untapped in the\ncontext of sign language dataset acquisition. To bridge this gap, we introduce\nthe first automated annotation and filtering framework that utilizes VLMs to\nreduce reliance on manual effort while preserving data quality. Our method is\napplied to TikTok videos across eight sign languages and to the already curated\nYouTube-SL-25 dataset in German Sign Language for the purpose of additional\nevaluation. Our VLM-based pipeline includes a face visibility detection, a sign\nactivity recognition, a text extraction from video content, and a judgment step\nto validate alignment between video and text, implementing generic filtering,\nannotation and validation steps. Using the resulting corpus, TikTok-SL-8, we\nassess the performance of two off-the-shelf SLT models on our filtered dataset\nfor German and American Sign Languages, with the goal of establishing baselines\nand evaluating the robustness of recent models on automatically extracted,\nslightly noisy data. Our work enables scalable, weakly supervised pretraining\nfor SLT and facilitates data acquisition from social media.",
    "categories": [
      "cs.CL"
    ],
    "published": "2025-10-29T11:29:56Z",
    "authors": [
      "Shakib Yazdani",
      "Yasser Hamidullah",
      "Cristina Espa\u00f1a-Bonet",
      "Josef van Genabith"
    ],
    "pdf_url": "http://arxiv.org/pdf/2510.25413v1"
  },
  {
    "id": "2510.25412v1",
    "title": "Serve Programs, Not Prompts",
    "abstract": "Current large language model (LLM) serving systems, primarily designed for\ntext completion, are neither efficient nor adaptable for increasingly complex\nLLM applications due to their inflexible design. We propose a new LLM serving\nsystem architecture that serves programs instead of prompts to address this\nproblem. These programs, called LLM Inference Programs (LIPs), allow users to\ncustomize token prediction and KV cache management at runtime and to offload\nparts of their application logic, such as tool execution, to the server. We\ndescribe an example of this architecture through a system named Symphony, which\nfunctions as an operating system for LIPs. Symphony exposes LLM model\ncomputations via system calls and virtualizes KV cache with a dedicated file\nsystem, while ensuring GPU efficiency with a two-level process scheduling\nscheme. Symphony has the potential to open the door to a more efficient and\nextensible ecosystem for LLM applications.",
    "categories": [
      "cs.CL"
    ],
    "published": "2025-10-29T11:29:03Z",
    "authors": [
      "In Gim",
      "Lin Zhong"
    ],
    "pdf_url": "http://arxiv.org/pdf/2510.25412v1"
  },
  {
    "id": "2510.25409v2",
    "title": "BhashaBench V1: A Comprehensive Benchmark for the Quadrant of Indic\n  Domains",
    "abstract": "The rapid advancement of large language models(LLMs) has intensified the need\nfor domain and culture specific evaluation. Existing benchmarks are largely\nAnglocentric and domain-agnostic, limiting their applicability to India-centric\ncontexts. To address this gap, we introduce BhashaBench V1, the first\ndomain-specific, multi-task, bilingual benchmark focusing on critical Indic\nknowledge systems. BhashaBench V1 contains 74,166 meticulously curated\nquestion-answer pairs, with 52,494 in English and 21,672 in Hindi, sourced from\nauthentic government and domain-specific exams. It spans four major domains:\nAgriculture, Legal, Finance, and Ayurveda, comprising 90+ subdomains and\ncovering 500+ topics, enabling fine-grained evaluation. Evaluation of 29+ LLMs\nreveals significant domain and language specific performance gaps, with\nespecially large disparities in low-resource domains. For instance, GPT-4o\nachieves 76.49% overall accuracy in Legal but only 59.74% in Ayurveda. Models\nconsistently perform better on English content compared to Hindi across all\ndomains. Subdomain-level analysis shows that areas such as Cyber Law,\nInternational Finance perform relatively well, while Panchakarma, Seed Science,\nand Human Rights remain notably weak. BhashaBench V1 provides a comprehensive\ndataset for evaluating large language models across India's diverse knowledge\ndomains. It enables assessment of models' ability to integrate domain-specific\nknowledge with bilingual understanding. All code, benchmarks, and resources are\npublicly available to support open research.",
    "categories": [
      "cs.CL",
      "cs.AI"
    ],
    "published": "2025-10-29T11:27:08Z",
    "authors": [
      "Vijay Devane",
      "Mohd Nauman",
      "Bhargav Patel",
      "Aniket Mahendra Wakchoure",
      "Yogeshkumar Sant",
      "Shyam Pawar",
      "Viraj Thakur",
      "Ananya Godse",
      "Sunil Patra",
      "Neha Maurya",
      "Suraj Racha",
      "Nitish Kamal Singh",
      "Ajay Nagpal",
      "Piyush Sawarkar",
      "Kundeshwar Vijayrao Pundalik",
      "Rohit Saluja",
      "Ganesh Ramakrishnan"
    ],
    "pdf_url": "http://arxiv.org/pdf/2510.25409v2"
  },
  {
    "id": "2510.25384v1",
    "title": "Roleplaying with Structure: Synthetic Therapist-Client Conversation\n  Generation from Questionnaires",
    "abstract": "The development of AI for mental health is hindered by a lack of authentic\ntherapy dialogues, due to strict privacy regulations and the fact that clinical\nsessions were historically rarely recorded. We present an LLM-driven pipeline\nthat generates synthetic counseling dialogues based on structured client\nprofiles and psychological questionnaires. Grounded on the principles of\nCognitive Behavioral Therapy (CBT), our method creates synthetic therapeutic\nconversations for clinical disorders such as anxiety and depression. Our\nframework, SQPsych (Structured Questionnaire-based Psychotherapy), converts\nstructured psychological input into natural language dialogues through\ntherapist-client simulations. Due to data governance policies and privacy\nrestrictions prohibiting the transmission of clinical questionnaire data to\nthird-party services, previous methodologies relying on proprietary models are\ninfeasible in our setting. We address this limitation by generating a\nhigh-quality corpus using open-weight LLMs, validated through human expert\nevaluation and LLM-based assessments. Our SQPsychLLM models fine-tuned on\nSQPsychConv achieve strong performance on counseling benchmarks, surpassing\nbaselines in key therapeutic skills. Our findings highlight the potential of\nsynthetic data to enable scalable, data-secure, and clinically informed AI for\nmental health support. We will release our code, models, and corpus at\nhttps://ai-mh.github.io/SQPsych",
    "categories": [
      "cs.CL"
    ],
    "published": "2025-10-29T10:55:52Z",
    "authors": [
      "Doan Nam Long Vu",
      "Rui Tan",
      "Lena Moench",
      "Svenja Jule Francke",
      "Daniel Woiwod",
      "Florian Thomas-Odenthal",
      "Sanna Stroth",
      "Tilo Kircher",
      "Christiane Hermann",
      "Udo Dannlowski",
      "Hamidreza Jamalabadi",
      "Shaoxiong Ji"
    ],
    "pdf_url": "http://arxiv.org/pdf/2510.25384v1"
  },
  {
    "id": "2510.25378v1",
    "title": "Hallucinations in Bibliographic Recommendation: Citation Frequency as a\n  Proxy for Training Data Redundancy",
    "abstract": "Large language models (LLMs) have been increasingly applied to a wide range\nof tasks, from natural language understanding to code generation. While they\nhave also been used to assist in bibliographic recommendation, the\nhallucination of non-existent papers remains a major issue. Building on prior\nstudies, this study hypothesizes that an LLM's ability to correctly produce\nbibliographic information depends on whether the underlying knowledge is\ngenerated or memorized, with highly cited papers (i.e., more frequently appear\nin the training corpus) showing lower hallucination rates. We therefore assume\ncitation count as a proxy for training data redundancy (i.e., the frequency\nwith which a given bibliographic record is repeatedly represented in the\npretraining corpus) and investigate how citation frequency affects hallucinated\nreferences in LLM outputs. Using GPT-4.1, we generated and manually verified\n100 bibliographic records across twenty computer-science domains, and measured\nfactual consistency via cosine similarity between generated and authentic\nmetadata. The results revealed that (i) hallucination rates vary across\nresearch domains, (ii) citation count is strongly correlated with factual\naccuracy, and (iii) bibliographic information becomes almost verbatimly\nmemorized beyond approximately 1,000 citations. These findings suggest that\nhighly cited papers are nearly verbatimly retained in the model, indicating a\nthreshold where generalization shifts into memorization.",
    "categories": [
      "cs.CL",
      "cs.AI"
    ],
    "published": "2025-10-29T10:51:35Z",
    "authors": [
      "Junichiro Niimi"
    ],
    "pdf_url": "http://arxiv.org/pdf/2510.25378v1"
  },
  {
    "id": "2510.25370v1",
    "title": "Monitoring Transformative Technological Convergence Through\n  LLM-Extracted Semantic Entity Triple Graphs",
    "abstract": "Forecasting transformative technologies remains a critical but challenging\ntask, particularly in fast-evolving domains such as Information and\nCommunication Technologies (ICTs). Traditional expert-based methods struggle to\nkeep pace with short innovation cycles and ambiguous early-stage terminology.\nIn this work, we propose a novel, data-driven pipeline to monitor the emergence\nof transformative technologies by identifying patterns of technological\nconvergence.\n  Our approach leverages advances in Large Language Models (LLMs) to extract\nsemantic triples from unstructured text and construct a large-scale graph of\ntechnology-related entities and relations. We introduce a new method for\ngrouping semantically similar technology terms (noun stapling) and develop\ngraph-based metrics to detect convergence signals. The pipeline includes\nmulti-stage filtering, domain-specific keyword clustering, and a temporal trend\nanalysis of topic co-occurence.\n  We validate our methodology on two complementary datasets: 278,625 arXiv\npreprints (2017--2024) to capture early scientific signals, and 9,793 USPTO\npatent applications (2018-2024) to track downstream commercial developments.\nOur results demonstrate that the proposed pipeline can identify both\nestablished and emerging convergence patterns, offering a scalable and\ngeneralizable framework for technology forecasting grounded in full-text\nanalysis.",
    "categories": [
      "cs.CL"
    ],
    "published": "2025-10-29T10:41:03Z",
    "authors": [
      "Alexander Sternfeld",
      "Andrei Kucharavy",
      "Dimitri Percia David",
      "Alain Mermoud",
      "Julian Jang-Jaccard",
      "Nathan Monnet"
    ],
    "pdf_url": "http://arxiv.org/pdf/2510.25370v1"
  },
  {
    "id": "2510.25364v1",
    "title": "CLASS-IT: Conversational and Lecture-Aligned Small-Scale Instruction\n  Tuning for BabyLMs",
    "abstract": "This work investigates whether small-scale LMs can benefit from instruction\ntuning. We compare conversational and question-answering instruction tuning\ndatasets, applied either in a merged or sequential curriculum, using\ndecoder-only models with 100M and 140M parameters. Evaluation spans both\nfine-tuning (SuperGLUE) and zero-shot (BLiMP, EWoK, WUGs, entity tracking, and\npsycholinguistic correlation) settings. Results show that instruction tuning\nyields small but consistent gains in fine-tuning scenarios, with sequential\ncurricula outperforming merged data; however, improvements do not consistently\ntransfer to zero-shot tasks, suggesting a trade-off between interaction-focused\nadaptation and broad linguistic generalization. These results highlight both\nthe potential and the constraints of adapting human-inspired learning\nstrategies to low-resource LMs, and point toward hybrid, curriculum-based\napproaches for enhancing generalization under ecological training limits.",
    "categories": [
      "cs.CL"
    ],
    "published": "2025-10-29T10:36:39Z",
    "authors": [
      "Luca Capone",
      "Alessandro Bondielli",
      "Alessandro Lenci"
    ],
    "pdf_url": "http://arxiv.org/pdf/2510.25364v1"
  },
  {
    "id": "2510.25356v1",
    "title": "Not ready for the bench: LLM legal interpretation is unstable and out of\n  step with human judgments",
    "abstract": "Legal interpretation frequently involves assessing how a legal text, as\nunderstood by an 'ordinary' speaker of the language, applies to the set of\nfacts characterizing a legal dispute in the U.S. judicial system. Recent\nscholarship has proposed that legal practitioners add large language models\n(LLMs) to their interpretive toolkit. This work offers an empirical argument\nagainst LLM interpretation as recently practiced by legal scholars and federal\njudges. Our investigation in English shows that models do not provide stable\ninterpretive judgments: varying the question format can lead the model to\nwildly different conclusions. Moreover, the models show weak to moderate\ncorrelation with human judgment, with large variance across model and question\nvariant, suggesting that it is dangerous to give much credence to the\nconclusions produced by generative AI.",
    "categories": [
      "cs.CL"
    ],
    "published": "2025-10-29T10:21:25Z",
    "authors": [
      "Abhishek Purushothama",
      "Junghyun Min",
      "Brandon Waldon",
      "Nathan Schneider"
    ],
    "pdf_url": "http://arxiv.org/pdf/2510.25356v1"
  },
  {
    "id": "2510.25333v1",
    "title": "CRMWeaver: Building Powerful Business Agent via Agentic RL and Shared\n  Memories",
    "abstract": "Recent years have witnessed the rapid development of LLM-based agents, which\nshed light on using language agents to solve complex real-world problems. A\nprominent application lies in business agents, which interact with databases\nand internal knowledge bases via tool calls to fulfill diverse user\nrequirements. However, this domain is characterized by intricate data\nrelationships and a wide range of heterogeneous tasks, from statistical data\nqueries to knowledge-based question-answering. To address these challenges, we\npropose CRMWeaver, a novel approach that enhances business agents in such\ncomplex settings. To acclimate the agentic model to intricate business\nenvironments, we employ a synthesis data generation and RL-based paradigm\nduring training, which significantly improves the model's ability to handle\ncomplex data and varied tasks. During inference, a shared memories mechanism is\nintroduced, prompting the agent to learn from task guidelines in similar\nproblems, thereby further boosting its effectiveness and generalization,\nespecially in unseen scenarios. We validate the efficacy of our approach on the\nCRMArena-Pro dataset, where our lightweight model achieves competitive results\nin both B2B and B2C business scenarios, underscoring its practical value for\nreal-world applications.",
    "categories": [
      "cs.CL"
    ],
    "published": "2025-10-29T09:47:40Z",
    "authors": [
      "Yilong Lai",
      "Yipin Yang",
      "Jialong Wu",
      "Fengran Mo",
      "Zhenglin Wang",
      "Ting Liang",
      "Jianguo Lin",
      "Keping Yang"
    ],
    "pdf_url": "http://arxiv.org/pdf/2510.25333v1"
  },
  {
    "id": "2510.25320v1",
    "title": "GAP: Graph-Based Agent Planning with Parallel Tool Use and Reinforcement\n  Learning",
    "abstract": "Autonomous agents powered by large language models (LLMs) have shown\nimpressive capabilities in tool manipulation for complex task-solving. However,\nexisting paradigms such as ReAct rely on sequential reasoning and execution,\nfailing to exploit the inherent parallelism among independent sub-tasks. This\nsequential bottleneck leads to inefficient tool utilization and suboptimal\nperformance in multi-step reasoning scenarios. We introduce Graph-based Agent\nPlanning (GAP), a novel framework that explicitly models inter-task\ndependencies through graph-based planning to enable adaptive parallel and\nserial tool execution. Our approach trains agent foundation models to decompose\ncomplex tasks into dependency-aware sub-task graphs, autonomously determining\nwhich tools can be executed in parallel and which must follow sequential\ndependencies. This dependency-aware orchestration achieves substantial\nimprovements in both execution efficiency and task accuracy. To train GAP, we\nconstruct a high-quality dataset of graph-based planning traces derived from\nthe Multi-Hop Question Answering (MHQA) benchmark. We employ a two-stage\ntraining strategy: supervised fine-tuning (SFT) on the curated dataset,\nfollowed by reinforcement learning (RL) with a correctness-based reward\nfunction on strategically sampled queries where tool-based reasoning provides\nmaximum value. Experimental results on MHQA datasets demonstrate that GAP\nsignificantly outperforms traditional ReAct baselines, particularly on\nmulti-step retrieval tasks, while achieving dramatic improvements in tool\ninvocation efficiency through intelligent parallelization. The project page is\navailable at: https://github.com/WJQ7777/Graph-Agent-Planning.",
    "categories": [
      "cs.AI",
      "cs.CL"
    ],
    "published": "2025-10-29T09:35:55Z",
    "authors": [
      "Jiaqi Wu",
      "Qinlao Zhao",
      "Zefeng Chen",
      "Kai Qin",
      "Yifei Zhao",
      "Xueqian Wang",
      "Yuhang Yao"
    ],
    "pdf_url": "http://arxiv.org/pdf/2510.25320v1"
  },
  {
    "id": "2510.25310v1",
    "title": "Parrot: A Training Pipeline Enhances Both Program CoT and Natural\n  Language CoT for Reasoning",
    "abstract": "Natural language chain-of-thought (N-CoT) and Program chain-of-thought\n(P-CoT) have emerged as two primary paradigms for large language models (LLMs)\nto solve mathematical reasoning problems. Current research typically endeavors\nto achieve unidirectional enhancement: P-CoT enhanced N-CoT or N-CoT enhanced\nP-CoT. In this paper, we seek to fully unleash the two paradigms' strengths for\nmutual enhancement and ultimately achieve simultaneous improvements. We conduct\na detailed analysis of the error types across two paradigms, based on which we\npropose Parrot, a novel training pipeline for mathematical problems: 1) Three\ntarget-designed subtasks integrate sequential P-CoT and N-CoT generation. 2) A\nsubtask hybrid training strategy to facilitate natural language semantic\ntransferability. 3) The converted N-CoT auxiliary reward is designed to\nalleviate the sparse rewards in P-CoT optimization. Extensive experiments\ndemonstrate that Parrot significantly enhances both the performance of N-CoT\nand P-CoT, especially on N-CoT. Using Parrot SFT, the N-CoT performance of\nLLaMA2 and CodeLLaMA achieve gains of +21.87 and +21.48 on MathQA over the RL\nbaseline, which is resource-intensive.",
    "categories": [
      "cs.CL"
    ],
    "published": "2025-10-29T09:23:17Z",
    "authors": [
      "Senjie Jin",
      "Lu Chen",
      "Zhiheng Xi",
      "Yuhui Wang",
      "Sirui Song",
      "Yuhao Zhou",
      "Xinbo Zhang",
      "Peng Sun",
      "Hong Lu",
      "Tao Gui",
      "Qi Zhang",
      "Xuanjing Huang"
    ],
    "pdf_url": "http://arxiv.org/pdf/2510.25310v1"
  },
  {
    "id": "2510.25303v1",
    "title": "Teaching Sarcasm: Few-Shot Multimodal Sarcasm Detection via Distillation\n  to a Parameter-Efficient Student",
    "abstract": "Multimodal sarcasm detection is challenging, especially in low-resource\nsettings where subtle image-text contradictions are hard to learn due to scarce\nannotated data, which hinders the model's performance. Parameter-efficient\nfine-tuning (PEFT) methods like adapters, LoRA, and prompt tuning reduce\noverfitting but struggle to reach optimal performance due to limited\nsupervision from few-shot data. We propose PEKD, a unified framework that\nenhances PEFT methods via distillation from an expert model trained on\nlarge-scale sarcasm data, which acts as the teacher. To mitigate unreliable\nsignals from the teacher, we introduce an entropy-aware gating mechanism that\ndynamically adjusts the distillation strength based on teacher confidence.\nExperiments on two public datasets demonstrate that our PEKD framework enables\nPEFT methods to outperform both prior parameter-efficient approaches and large\nmultimodal models, achieving strong results in the few-shot scenario. The\nframework is modular and adaptable to a wide range of multimodal models and\ntasks.",
    "categories": [
      "cs.CL"
    ],
    "published": "2025-10-29T09:14:41Z",
    "authors": [
      "Soumyadeep Jana",
      "Sanasam Ranbir Singh"
    ],
    "pdf_url": "http://arxiv.org/pdf/2510.25303v1"
  },
  {
    "id": "2510.25273v1",
    "title": "Adapting Small Language Models to Low-Resource Domains: A Case Study in\n  Hindi Tourism QA",
    "abstract": "Domain-specific question answering in low-resource languages faces two key\nchallenges: scarcity of annotated datasets and limited domain knowledge in\ngeneral-purpose language models. In this work, we present a multi-stage\nfinetuning strategy to adapt lightweight language models to the Hindi tourism\ndomain by leveraging both original and synthetic training data. Synthetic\nquestion-answer pairs are generated using large LLMs (LLaMA-70B, Phi-14B) and\nused to augment the limited original dataset. We explore several training\nmethodologies and analyse their impact on domain generalisation. Our results\ndemonstrate that large models can efficiently generate synthetic data, while\nsmall models can effectively adapt to it, offering a scalable pathway for\nlow-resource, domain-specific QA.",
    "categories": [
      "cs.CL"
    ],
    "published": "2025-10-29T08:32:22Z",
    "authors": [
      "Sandipan Majhi",
      "Paheli Bhattacharya"
    ],
    "pdf_url": "http://arxiv.org/pdf/2510.25273v1"
  },
  {
    "id": "2510.25232v1",
    "title": "From Medical Records to Diagnostic Dialogues: A Clinical-Grounded\n  Approach and Dataset for Psychiatric Comorbidity",
    "abstract": "Psychiatric comorbidity is clinically significant yet challenging due to the\ncomplexity of multiple co-occurring disorders. To address this, we develop a\nnovel approach integrating synthetic patient electronic medical record (EMR)\nconstruction and multi-agent diagnostic dialogue generation. We create 502\nsynthetic EMRs for common comorbid conditions using a pipeline that ensures\nclinical relevance and diversity. Our multi-agent framework transfers the\nclinical interview protocol into a hierarchical state machine and context tree,\nsupporting over 130 diagnostic states while maintaining clinical standards.\nThrough this rigorous process, we construct PsyCoTalk, the first large-scale\ndialogue dataset supporting comorbidity, containing 3,000 multi-turn diagnostic\ndialogues validated by psychiatrists. This dataset enhances diagnostic accuracy\nand treatment planning, offering a valuable resource for psychiatric\ncomorbidity research. Compared to real-world clinical transcripts, PsyCoTalk\nexhibits high structural and linguistic fidelity in terms of dialogue length,\ntoken distribution, and diagnostic reasoning strategies. Licensed psychiatrists\nconfirm the realism and diagnostic validity of the dialogues. This dataset\nenables the development and evaluation of models capable of multi-disorder\npsychiatric screening in a single conversational pass.",
    "categories": [
      "cs.AI",
      "cs.CL"
    ],
    "published": "2025-10-29T07:18:43Z",
    "authors": [
      "Tianxi Wan",
      "Jiaming Luo",
      "Siyuan Chen",
      "Kunyao Lan",
      "Jianhua Chen",
      "Haiyang Geng",
      "Mengyue Wu"
    ],
    "pdf_url": "http://arxiv.org/pdf/2510.25232v1"
  },
  {
    "id": "2510.25224v1",
    "title": "ProMediate: A Socio-cognitive framework for evaluating proactive agents\n  in multi-party negotiation",
    "abstract": "While Large Language Models (LLMs) are increasingly used in agentic\nframeworks to assist individual users, there is a growing need for agents that\ncan proactively manage complex, multi-party collaboration. Systematic\nevaluation methods for such proactive agents remain scarce, limiting progress\nin developing AI that can effectively support multiple people together.\nNegotiation offers a demanding testbed for this challenge, requiring\nsocio-cognitive intelligence to navigate conflicting interests between multiple\nparticipants and multiple topics and build consensus. Here, we present\nProMediate, the first framework for evaluating proactive AI mediator agents in\ncomplex, multi-topic, multi-party negotiations. ProMediate consists of two core\ncomponents: (i) a simulation testbed based on realistic negotiation cases and\ntheory-driven difficulty levels (ProMediate-Easy, ProMediate-Medium, and\nProMediate-Hard), with a plug-and-play proactive AI mediator grounded in\nsocio-cognitive mediation theories, capable of flexibly deciding when and how\nto intervene; and (ii) a socio-cognitive evaluation framework with a new suite\nof metrics to measure consensus changes, intervention latency, mediator\neffectiveness, and intelligence. Together, these components establish a\nsystematic framework for assessing the socio-cognitive intelligence of\nproactive AI agents in multi-party settings. Our results show that a socially\nintelligent mediator agent outperforms a generic baseline, via faster,\nbetter-targeted interventions. In the ProMediate-Hard setting, our social\nmediator increases consensus change by 3.6 percentage points compared to the\ngeneric baseline (10.65\\% vs 7.01\\%) while being 77\\% faster in response\n(15.98s vs. 3.71s). In conclusion, ProMediate provides a rigorous,\ntheory-grounded testbed to advance the development of proactive, socially\nintelligent agents.",
    "categories": [
      "cs.CL"
    ],
    "published": "2025-10-29T07:00:11Z",
    "authors": [
      "Ziyi Liu",
      "Bahar Sarrafzadeh",
      "Pei Zhou",
      "Longqi Yang",
      "Jieyu Zhao",
      "Ashish Sharma"
    ],
    "pdf_url": "http://arxiv.org/pdf/2510.25224v1"
  },
  {
    "id": "2510.25805v1",
    "title": "Ideology-Based LLMs for Content Moderation",
    "abstract": "Large language models (LLMs) are increasingly used in content moderation\nsystems, where ensuring fairness and neutrality is essential. In this study, we\nexamine how persona adoption influences the consistency and fairness of harmful\ncontent classification across different LLM architectures, model sizes, and\ncontent modalities (language vs. vision). At first glance, headline performance\nmetrics suggest that personas have little impact on overall classification\naccuracy. However, a closer analysis reveals important behavioral shifts.\nPersonas with different ideological leanings display distinct propensities to\nlabel content as harmful, showing that the lens through which a model \"views\"\ninput can subtly shape its judgments. Further agreement analyses highlight that\nmodels, particularly larger ones, tend to align more closely with personas from\nthe same political ideology, strengthening within-ideology consistency while\nwidening divergence across ideological groups. To show this effect more\ndirectly, we conducted an additional study on a politically targeted task,\nwhich confirmed that personas not only behave more coherently within their own\nideology but also exhibit a tendency to defend their perspective while\ndownplaying harmfulness in opposing views. Together, these findings highlight\nhow persona conditioning can introduce subtle ideological biases into LLM\noutputs, raising concerns about the use of AI systems that may reinforce\npartisan perspectives under the guise of neutrality.",
    "categories": [
      "cs.CL"
    ],
    "published": "2025-10-29T06:22:50Z",
    "authors": [
      "Stefano Civelli",
      "Pietro Bernardelle",
      "Nardiena A. Pratama",
      "Gianluca Demartini"
    ],
    "pdf_url": "http://arxiv.org/pdf/2510.25805v1"
  },
  {
    "id": "2510.25804v1",
    "title": "Beyond Length: Quantifying Long-Range Information for Long-Context LLM\n  Pretraining Data",
    "abstract": "Long-context language models unlock advanced capabilities in reasoning, code\ngeneration, and document summarization by leveraging dependencies across\nextended spans of text. However, a significant portion of readily available\nlong-text data lacks meaningful long-distance dependencies; most spans can be\npredicted using only local context. Training on such data is inefficient,\nmaking careful data selection crucial. Therefore, we introduce LongFilter, a\nframework for curating training data tailored to long-context pretraining.\nLongFilter measures the information gain provided by extended context by\ncontrasting model predictions under long-context versus short-context settings,\nthereby identifying samples where long-range dependencies are essential.\nExperiments with LLaMA-3-8B, extending its context length from 8K to 64K, show\nthat LongFilter efficiently selects high-quality data and yields substantial\nimprovements on benchmarks such as HELMET, LongBench, and RULER.",
    "categories": [
      "cs.CL"
    ],
    "published": "2025-10-29T06:21:08Z",
    "authors": [
      "Haoran Deng",
      "Yingyu Lin",
      "Zhenghao Lin",
      "Xiao Liu",
      "Yizhou Sun",
      "Yi-An Ma",
      "Yeyun Gong"
    ],
    "pdf_url": "http://arxiv.org/pdf/2510.25804v1"
  },
  {
    "id": "2510.25206v1",
    "title": "RAVR: Reference-Answer-guided Variational Reasoning for Large Language\n  Models",
    "abstract": "Reinforcement learning (RL) can refine the reasoning abilities of large\nlanguage models (LLMs), but critically depends on a key prerequisite: the LLM\ncan already generate high-utility reasoning paths with non-negligible\nprobability. For tasks beyond the LLM's current competence, such reasoning path\ncan be hard to sample, and learning risks reinforcing familiar but suboptimal\nreasoning. We are motivated by the insight from cognitive science that Why is\nthis the answer is often an easier question than What is the answer, as it\navoids the heavy cognitive load of open-ended exploration, opting instead for\nexplanatory reconstruction-systematically retracing the reasoning that links a\nquestion to its answer. We show that LLMs can similarly leverage answers to\nderive high-quality reasoning paths. We formalize this phenomenon and prove\nthat conditioning on answer provably increases the expected utility of sampled\nreasoning paths, thereby transforming intractable problems into learnable ones.\nBuilding on this insight, we introduce RAVR (Reference-Answer-guided\nVariational Reasoning), an end-to-end framework that uses answer-conditioned\nreasoning as a variational surrogate for question-only reasoning. Experiments\nin both general and math domains demonstrate consistent improvements over\nstrong baselines. We further analyze the reasoning behavior and find that RAVR\nreduces hesitation, strengthens conclusion consolidation, and promotes\nproblem-specific strategies in reasoning.",
    "categories": [
      "cs.AI",
      "cs.CL",
      "cs.LG",
      "I.2.7"
    ],
    "published": "2025-10-29T06:18:37Z",
    "authors": [
      "Tianqianjin Lin",
      "Xi Zhao",
      "Xingyao Zhang",
      "Rujiao Long",
      "Yi Xu",
      "Zhuoren Jiang",
      "Wenbo Su",
      "Bo Zheng"
    ],
    "pdf_url": "http://arxiv.org/pdf/2510.25206v1"
  },
  {
    "id": "2510.25187v1",
    "title": "Testing Cross-Lingual Text Comprehension In LLMs Using Next Sentence\n  Prediction",
    "abstract": "While large language models are trained on massive datasets, this data is\nheavily skewed towards English. Does their impressive performance reflect\ngenuine ability or just this data advantage? To find out, we tested them in a\nsetting where they could not rely on data abundance: low-resource languages.\nBuilding on prior work Agarwal et al. (2025) that used Next Sentence Prediction\n(NSP) as a test, we created a large-scale benchmark with 10,000 questions each\nfor English (a high-resource language), Swahili (medium-resource), and Hausa\n(low-resource). We then tested several top models, including GPT-4 Turbo,\nGemini 1.5 Flash, and LLaMA 3 70B, to see how their performance holds up. The\nresults painted a clear picture of how levels of language resources impact\noutcomes. While all models excelled in English, their accuracy dropped in\nSwahili and fell sharply in Hausa, with LLaMA 3 struggling the most. The story\nbecame even more interesting when we introduced Chain-of-Thought (CoT)\nprompting. For the struggling LLaMA 3, CoT acted as a helpful guide,\nsignificantly boosting its accuracy. However, for the more capable GPT-4 and\nGemini, the same technique often backfired, leading to a kind of \"overthinking\"\nthat hurt their results in the cross-lingual context. This reveals that\nChain-of-Thought is not a universal solution; its effectiveness depends heavily\non the model's baseline capability and the specific context of the task. Our\nframework pinpoints LLM weaknesses, highlights when CoT helps or hinders\ncross-lingual NSP performance, and factors influencing their decisions.",
    "categories": [
      "cs.CL"
    ],
    "published": "2025-10-29T05:38:06Z",
    "authors": [
      "Ritesh Sunil Chavan",
      "Jack Mostow"
    ],
    "pdf_url": "http://arxiv.org/pdf/2510.25187v1"
  },
  {
    "id": "2510.25160v2",
    "title": "Model-Document Protocol for AI Search",
    "abstract": "AI search depends on linking large language models (LLMs) with vast external\nknowledge sources. Yet web pages, PDF files, and other raw documents are not\ninherently LLM-ready: they are long, noisy, and unstructured. Conventional\nretrieval methods treat these documents as verbatim text and return raw\npassages, leaving the burden of fragment assembly and contextual reasoning to\nthe LLM. This gap underscores the need for a new retrieval paradigm that\nredefines how models interact with documents.\n  We introduce the Model-Document Protocol (MDP), a general framework that\nformalizes how raw text is bridged to LLMs through consumable knowledge\nrepresentations. Rather than treating retrieval as passage fetching, MDP\ndefines multiple pathways that transform unstructured documents into\ntask-specific, LLM-ready inputs. These include agentic reasoning, which curates\nraw evidence into coherent context; memory grounding, which accumulates\nreusable notes to enrich reasoning; and structured leveraging, which encodes\ndocuments into formal representations such as graphs or key-value caches. All\nthree pathways share the same goal: ensuring that what reaches the LLM is not\nraw fragments but compact, structured knowledge directly consumable for\nreasoning.\n  As an instantiation, we present MDP-Agent, which realizes the protocol\nthrough an agentic process: constructing document-level gist memories for\nglobal coverage, performing diffusion-based exploration with vertical\nexploitation to uncover layered dependencies, and applying map-reduce style\nsynthesis to integrate large-scale evidence into compact yet sufficient\ncontext. Experiments on information-seeking benchmarks demonstrate that\nMDP-Agent outperforms baselines, validating both the soundness of the MDP\nframework and the effectiveness of its agentic instantiation.",
    "categories": [
      "cs.CL",
      "cs.AI",
      "cs.IR"
    ],
    "published": "2025-10-29T04:29:17Z",
    "authors": [
      "Hongjin Qian",
      "Zheng Liu"
    ],
    "pdf_url": "http://arxiv.org/pdf/2510.25160v2"
  },
  {
    "id": "2510.25150v1",
    "title": "Explainable Disentanglement on Discrete Speech Representations for\n  Noise-Robust ASR",
    "abstract": "Discrete audio representations are gaining traction in speech modeling due to\ntheir interpretability and compatibility with large language models, but are\nnot always optimized for noisy or real-world environments. Building on existing\nworks that quantize Whisper embeddings for speech-to-unit modeling, we propose\ndisentangling semantic speech content from background noise in the latent\nspace. Our end-to-end model separates clean speech in the form of codebook\ntokens, while extracting interpretable noise vectors as quantization residue\nwhich are supervised via a lightweight classifier. We show that our approach\nimproves alignment between clean/noisy speech and text, producing speech tokens\nthat display a high degree of noiseinvariance, and improves ASR performance.\nKeeping Whisper frozen, we show an 82% reduction in error rate compared to\nWhisper, and 35% improvement over baseline methods on the VBDemand test set.\nFurther analyses show that the learned token space generalizes well to both\nseen and unseen acoustic conditions.",
    "categories": [
      "cs.CL"
    ],
    "published": "2025-10-29T04:08:19Z",
    "authors": [
      "Shreyas Gopal",
      "Ashutosh Anshul",
      "Haoyang Li",
      "Yue Heng Yeo",
      "Hexin Liu",
      "Eng Siong Chng"
    ],
    "pdf_url": "http://arxiv.org/pdf/2510.25150v1"
  },
  {
    "id": "2510.25801v1",
    "title": "Metis-SPECS: Decoupling Multimodal Learning via Self-distilled\n  Preference-based Cold Start",
    "abstract": "Reinforcement learning (RL) with verifiable rewards has recently catalyzed a\nwave of \"MLLM-r1\" approaches that bring RL to vision language models. Most\nrepresentative paradigms begin with a cold start, typically employing\nsupervised fine-tuning (SFT), to initialize the policy before RL. However,\nSFT-based cold start adopts the reasoning paradigm intertwined with task\nsolution and output format, which may induce instruction-style overfitting,\nweakens out-of-distribution generalization, and ultimately affects downstream\nRL. We revisit the cold start along two views, its training method and data\nconstruction, and introduce the Generalization Factor (GF) coefficient to\nquantify the generalization capability under different methods. Our empirical\nstudy finds that preference-based training methods (e.g. DPO) generalizes\nbetter than SFT-based methods in cold start. Motivated by this, we propose\nSPECS-a Self-distilled, Preference-based Cold Start framework that decouples\nmultimodal learning: (1) generates introspective preference data pairs via\nself-distillation, avoiding reliance on larger teachers or manual annotation;\n(2) performs preference-based training to learn, focusing on shallow,\ntransferable surface-form criteria (format, structure, style) rather than\nmemorizing content; and (3) hands off to RL with verifiable rewards for deep\nreasoning results. Experimental results across multiple multimodal benchmarks\nshow that our decoupling learning framework yields consistent performance gains\nover strong baselines, improving MEGA-Bench by 4.1% and MathVista by 12.2%.\nAdditional experiments indicate that SPECS contributes to reducing\nin-distribution \"stuckness,\" improving exploration, stabilizing training, and\nraising the performance ceiling.",
    "categories": [
      "cs.LG",
      "cs.AI",
      "cs.CL",
      "cs.CV"
    ],
    "published": "2025-10-29T03:42:23Z",
    "authors": [
      "Kun Chen",
      "Peng Shi",
      "Haibo Qiu",
      "Zhixiong Zeng",
      "Siqi Yang",
      "Wenji Mao",
      "Lin Ma"
    ],
    "pdf_url": "http://arxiv.org/pdf/2510.25801v1"
  },
  {
    "id": "2510.25799v1",
    "title": "LISTEN to Your Preferences: An LLM Framework for Multi-Objective\n  Selection",
    "abstract": "Human experts often struggle to select the best option from a large set of\nitems with multiple competing objectives, a process bottlenecked by the\ndifficulty of formalizing complex, implicit preferences. To address this, we\nintroduce LISTEN, a framework that leverages a Large Language Model (LLM) as a\nzero-shot preference oracle, guided only by an expert's high-level priorities\nin natural language. To operate within LLM constraints like context windows and\ninference costs, we propose two iterative algorithms: LISTEN-U, which uses the\nLLM to refine a parametric utility function, and LISTEN-T, a non-parametric\nmethod that performs tournament-style selections over small batches of\nsolutions. Evaluated on diverse tasks including flight booking, shopping, and\nexam scheduling, our results show LISTEN-U excels when preferences are\nparametrically aligned (a property we measure with a novel concordance metric),\nwhile LISTEN-T offers more robust performance. This work explores a promising\ndirection for steering complex multi-objective decisions directly with natural\nlanguage, reducing the cognitive burden of traditional preference elicitation.",
    "categories": [
      "cs.CL"
    ],
    "published": "2025-10-29T03:17:37Z",
    "authors": [
      "Adam S. Jovine",
      "Tinghan Ye",
      "Francis Bahk",
      "Jingjing Wang",
      "David B. Shmoys",
      "Peter I. Frazier"
    ],
    "pdf_url": "http://arxiv.org/pdf/2510.25799v1"
  },
  {
    "id": "2510.25798v1",
    "title": "MemEIC: A Step Toward Continual and Compositional Knowledge Editing",
    "abstract": "The dynamic nature of information necessitates continuously updating large\nvision-language models (LVLMs). While recent knowledge editing techniques hint\nat promising directions, they often focus on editing a single modality (vision\nor language) in isolation. This prevalent practice neglects the inherent\nmultimodality of LVLMs and the continuous nature of knowledge updates,\npotentially leading to suboptimal editing outcomes when considering the\ninterplay between modalities and the need for ongoing knowledge refinement. To\naddress these limitations, we propose MemEIC, a novel method for Continual and\nCompositional Knowledge Editing (CCKE) in LVLMs. MemEIC enables compositional\nediting of both visual and textual knowledge sequentially. Our approach employs\na hybrid external-internal editor featuring a dual external memory for\ncross-modal evidence retrieval and dual LoRA adapters that facilitate\ndisentangled parameter updates for each modality. A key component is a\nbrain-inspired knowledge connector, activated selectively for compositional\nreasoning, that integrates information across different modalities. Experiments\ndemonstrate that MemEIC significantly improves performance on complex\nmultimodal questions and effectively preserves prior edits, setting a new\nbenchmark for CCKE in LVLMs.",
    "categories": [
      "cs.LG",
      "cs.AI",
      "cs.CL"
    ],
    "published": "2025-10-29T03:11:59Z",
    "authors": [
      "Jin Seong",
      "Jiyun Park",
      "Wencke Liermann",
      "Hongseok Choi",
      "Yoonji Nam",
      "Hyun Kim",
      "Soojong Lim",
      "Namhoon Lee"
    ],
    "pdf_url": "http://arxiv.org/pdf/2510.25798v1"
  },
  {
    "id": "2510.25117v1",
    "title": "A Survey on Unlearning in Large Language Models",
    "abstract": "The advancement of Large Language Models (LLMs) has revolutionized natural\nlanguage processing, yet their training on massive corpora poses significant\nrisks, including the memorization of sensitive personal data, copyrighted\nmaterial, and knowledge that could facilitate malicious activities. To mitigate\nthese issues and align with legal and ethical standards such as the \"right to\nbe forgotten\", machine unlearning has emerged as a critical technique to\nselectively erase specific knowledge from LLMs without compromising their\noverall performance. This survey provides a systematic review of over 180\npapers on LLM unlearning published since 2021, focusing exclusively on\nlarge-scale generative models. Distinct from prior surveys, we introduce novel\ntaxonomies for both unlearning methods and evaluations. We clearly categorize\nmethods into training-time, post-training, and inference-time based on the\ntraining stage at which unlearning is applied. For evaluations, we not only\nsystematically compile existing datasets and metrics but also critically\nanalyze their advantages, disadvantages, and applicability, providing practical\nguidance to the research community. In addition, we discuss key challenges and\npromising future research directions. Our comprehensive overview aims to inform\nand guide the ongoing development of secure and reliable LLMs.",
    "categories": [
      "cs.CL"
    ],
    "published": "2025-10-29T02:34:17Z",
    "authors": [
      "Ruichen Qiu",
      "Jiajun Tan",
      "Jiayue Pu",
      "Honglin Wang",
      "Xiao-Shan Gao",
      "Fei Sun"
    ],
    "pdf_url": "http://arxiv.org/pdf/2510.25117v1"
  },
  {
    "id": "2510.25116v1",
    "title": "Pretraining Strategies using Monolingual and Parallel Data for\n  Low-Resource Machine Translation",
    "abstract": "This research article examines the effectiveness of various pretraining\nstrategies for developing machine translation models tailored to low-resource\nlanguages. Although this work considers several low-resource languages,\nincluding Afrikaans, Swahili, and Zulu, the translation model is specifically\ndeveloped for Lingala, an under-resourced African language, building upon the\npretraining approach introduced by Reid and Artetxe (2021), originally designed\nfor high-resource languages. Through a series of comprehensive experiments, we\nexplore different pretraining methodologies, including the integration of\nmultiple languages and the use of both monolingual and parallel data during the\npretraining phase. Our findings indicate that pretraining on multiple languages\nand leveraging both monolingual and parallel data significantly enhance\ntranslation quality. This study offers valuable insights into effective\npretraining strategies for low-resource machine translation, helping to bridge\nthe performance gap between high-resource and low-resource languages. The\nresults contribute to the broader goal of developing more inclusive and\naccurate NLP models for marginalized communities and underrepresented\npopulations. The code and datasets used in this study are publicly available to\nfacilitate further research and ensure reproducibility, with the exception of\ncertain data that may no longer be accessible due to changes in public\navailability.",
    "categories": [
      "cs.CL"
    ],
    "published": "2025-10-29T02:30:18Z",
    "authors": [
      "Idriss Nguepi Nguefack",
      "Mara Finkelstein",
      "Toadoum Sari Sakayo"
    ],
    "pdf_url": "http://arxiv.org/pdf/2510.25116v1"
  },
  {
    "id": "2510.25110v1",
    "title": "DEBATE: A Large-Scale Benchmark for Role-Playing LLM Agents in\n  Multi-Agent, Long-Form Debates",
    "abstract": "Accurately modeling opinion change through social interactions is crucial for\naddressing issues like misinformation and polarization. While role-playing\nlarge language models (LLMs) offer a promising way to simulate human-like\ninteractions, existing research shows that single-agent alignment does not\nguarantee authentic multi-agent group dynamics. Current LLM role-play setups\noften produce unnatural dynamics (e.g., premature convergence), without an\nempirical benchmark to measure authentic human opinion trajectories. To bridge\nthis gap, we introduce DEBATE, the first large-scale empirical benchmark\nexplicitly designed to evaluate the authenticity of the interaction between\nmulti-agent role-playing LLMs. DEBATE contains 29,417 messages from multi-round\ndebate conversations among over 2,792 U.S.-based participants discussing 107\ncontroversial topics, capturing both publicly-expressed messages and\nprivately-reported opinions. Using DEBATE, we systematically evaluate and\nidentify critical discrepancies between simulated and authentic group dynamics.\nWe further demonstrate DEBATE's utility for aligning LLMs with human behavior\nthrough supervised fine-tuning, achieving improvements in surface-level metrics\n(e.g., ROUGE-L and message length) while highlighting limitations in deeper\nsemantic alignment (e.g., semantic similarity). Our findings highlight both the\npotential and current limitations of role-playing LLM agents for realistically\nsimulating human-like social dynamics.",
    "categories": [
      "cs.CL"
    ],
    "published": "2025-10-29T02:21:10Z",
    "authors": [
      "Yun-Shiuan Chuang",
      "Ruixuan Tu",
      "Chengtao Dai",
      "Smit Vasani",
      "Binwei Yao",
      "Michael Henry Tessler",
      "Sijia Yang",
      "Dhavan Shah",
      "Robert Hawkins",
      "Junjie Hu",
      "Timothy T. Rogers"
    ],
    "pdf_url": "http://arxiv.org/pdf/2510.25110v1"
  },
  {
    "id": "2510.25101v1",
    "title": "KnowCoder-A1: Incentivizing Agentic Reasoning Capability with Outcome\n  Supervision for KBQA",
    "abstract": "Knowledge Base Question Answering (KBQA) aims to answer natural-language\nquestions over a structured Knowledge Base (KB). Recent work improves KBQA by\nadopting an agentic reasoning paradigm, in which Large Language Models (LLMs)\niteratively decompose a question, generate its corresponding logical queries,\nand interact with the KB to derive the answer. However, these methods typically\nfine-tune LLMs on reasoning trajectories synthesized via process supervision,\nwhich offers weak incentives for exploration and thus fails to strengthen the\nagentic reasoning ability. In this paper, we propose KnowCoder-A1, an LLM that\ncan autonomously perform agentic reasoning on KBs to obtain answers. To\nincentivize autonomous exploration, KnowCoder-A1 trains the LLM under\noutcome-only supervision via a multi-stage curriculum reinforcement learning\nwith an easy-to-hard curriculum. To establish foundational agentic\ncapabilities, KnowCoder-A1 first fine-tunes the LLM on a small set of\nhigh-quality trajectories obtained through outcome-based rejection sampling.\nThen, to alleviate the reward sparsity inherent in outcome-only supervision, it\napplies multi-stage curriculum RL with reward schedules that progress from easy\nto hard. Trained with outcome-only supervision, KnowCoder-A1 exhibits powerful\nreasoning behaviors and consistently outperforms prior approaches across three\nmainstream datasets. Notably, on the zero-shot subset of GrailQA, KnowCoder-A1\nachieves up to an 11.1% relative improvement while using only one-twelfth of\nthe training data, demonstrating strong agentic reasoning capabilities.",
    "categories": [
      "cs.AI",
      "cs.CL"
    ],
    "published": "2025-10-29T02:12:18Z",
    "authors": [
      "Zhuo Chen",
      "Fei Wang",
      "Zixuan Li",
      "Zhao Zhang",
      "Weiwei Ding",
      "Chuanguang Yang",
      "Yongjun Xu",
      "Xiaolong Jin",
      "Jiafeng Guo"
    ],
    "pdf_url": "http://arxiv.org/pdf/2510.25101v1"
  },
  {
    "id": "2510.25087v1",
    "title": "BioCoref: Benchmarking Biomedical Coreference Resolution with LLMs",
    "abstract": "Coreference resolution in biomedical texts presents unique challenges due to\ncomplex domain-specific terminology, high ambiguity in mention forms, and\nlong-distance dependencies between coreferring expressions. In this work, we\npresent a comprehensive evaluation of generative large language models (LLMs)\nfor coreference resolution in the biomedical domain. Using the CRAFT corpus as\nour benchmark, we assess the LLMs' performance with four prompting experiments\nthat vary in their use of local, contextual enrichment, and domain-specific\ncues such as abbreviations and entity dictionaries. We benchmark these\napproaches against a discriminative span-based encoder, SpanBERT, to compare\nthe efficacy of generative versus discriminative methods. Our results\ndemonstrate that while LLMs exhibit strong surface-level coreference\ncapabilities, especially when supplemented with domain-grounding prompts, their\nperformance remains sensitive to long-range context and mentions ambiguity.\nNotably, the LLaMA 8B and 17B models show superior precision and F1 scores\nunder entity-augmented prompting, highlighting the potential of lightweight\nprompt engineering for enhancing LLM utility in biomedical NLP tasks.",
    "categories": [
      "cs.CL",
      "cs.LG"
    ],
    "published": "2025-10-29T01:51:00Z",
    "authors": [
      "Nourah M Salem",
      "Elizabeth White",
      "Michael Bada",
      "Lawrence Hunter"
    ],
    "pdf_url": "http://arxiv.org/pdf/2510.25087v1"
  },
  {
    "id": "2510.25797v1",
    "title": "Enhancing Underwater Object Detection through Spatio-Temporal Analysis\n  and Spatial Attention Networks",
    "abstract": "This study examines the effectiveness of spatio-temporal modeling and the\nintegration of spatial attention mechanisms in deep learning models for\nunderwater object detection. Specifically, in the first phase, the performance\nof temporal-enhanced YOLOv5 variant T-YOLOv5 is evaluated, in comparison with\nthe standard YOLOv5. For the second phase, an augmented version of T-YOLOv5 is\ndeveloped, through the addition of a Convolutional Block Attention Module\n(CBAM). By examining the effectiveness of the already pre-existing YOLOv5 and\nT-YOLOv5 models and of the newly developed T-YOLOv5 with CBAM. With CBAM, the\nresearch highlights how temporal modeling improves detection accuracy in\ndynamic marine environments, particularly under conditions of sudden movements,\npartial occlusions, and gradual motion. The testing results showed that YOLOv5\nachieved a mAP@50-95 of 0.563, while T-YOLOv5 and T-YOLOv5 with CBAM\noutperformed with mAP@50-95 scores of 0.813 and 0.811, respectively,\nhighlighting their superior accuracy and generalization in detecting complex\nobjects. The findings demonstrate that T-YOLOv5 significantly enhances\ndetection reliability compared to the standard model, while T-YOLOv5 with CBAM\nfurther improves performance in challenging scenarios, although there is a loss\nof accuracy when it comes to simpler scenarios.",
    "categories": [
      "cs.CV",
      "cs.CL",
      "cs.RO"
    ],
    "published": "2025-10-29T01:22:42Z",
    "authors": [
      "Sai Likhith Karri",
      "Ansh Saxena"
    ],
    "pdf_url": "http://arxiv.org/pdf/2510.25797v1"
  },
  {
    "id": "2510.25069v1",
    "title": "TOPol: Capturing and Explaining Multidimensional Semantic Polarity\n  Fields and Vectors",
    "abstract": "Traditional approaches to semantic polarity in computational linguistics\ntreat sentiment as a unidimensional scale, overlooking the multidimensional\nstructure of language. This work introduces TOPol (Topic-Orientation POLarity),\na semi-unsupervised framework for reconstructing and interpreting\nmultidimensional narrative polarity fields under human-on-the-loop (HoTL)\ndefined contextual boundaries (CBs). The framework embeds documents using a\ntransformer-based large language model (tLLM), applies neighbor-tuned UMAP\nprojection, and segments topics via Leiden partitioning. Given a CB between\ndiscourse regimes A and B, TOPol computes directional vectors between\ncorresponding topic-boundary centroids, yielding a polarity field that\nquantifies fine-grained semantic displacement during regime shifts. This\nvectorial representation enables assessing CB quality and detecting polarity\nchanges, guiding HoTL CB refinement. To interpret identified polarity vectors,\nthe tLLM compares their extreme points and produces contrastive labels with\nestimated coverage. Robustness analyses show that only CB definitions (the main\nHoTL-tunable parameter) significantly affect results, confirming methodological\nstability. We evaluate TOPol on two corpora: (i) U.S. Central Bank speeches\naround a macroeconomic breakpoint, capturing non-affective semantic shifts, and\n(ii) Amazon product reviews across rating strata, where affective polarity\naligns with NRC valence. Results demonstrate that TOPol consistently captures\nboth affective and non-affective polarity transitions, providing a scalable,\ngeneralizable, and interpretable framework for context-sensitive\nmultidimensional discourse analysis.",
    "categories": [
      "cs.CL"
    ],
    "published": "2025-10-29T01:14:21Z",
    "authors": [
      "Gabin Taibi",
      "Lucia Gomez"
    ],
    "pdf_url": "http://arxiv.org/pdf/2510.25069v1"
  },
  {
    "id": "2510.25064v1",
    "title": "Can LLMs Estimate Cognitive Complexity of Reading Comprehension Items?",
    "abstract": "Estimating the cognitive complexity of reading comprehension (RC) items is\ncrucial for assessing item difficulty before it is administered to learners.\nUnlike syntactic and semantic features, such as passage length or semantic\nsimilarity between options, cognitive features that arise during answer\nreasoning are not readily extractable using existing NLP tools and have\ntraditionally relied on human annotation. In this study, we examine whether\nlarge language models (LLMs) can estimate the cognitive complexity of RC items\nby focusing on two dimensions-Evidence Scope and Transformation Level-that\nindicate the degree of cognitive burden involved in reasoning about the answer.\nOur experimental results demonstrate that LLMs can approximate the cognitive\ncomplexity of items, indicating their potential as tools for prior difficulty\nanalysis. Further analysis reveals a gap between LLMs' reasoning ability and\ntheir metacognitive awareness: even when they produce correct answers, they\nsometimes fail to correctly identify the features underlying their own\nreasoning process.",
    "categories": [
      "cs.CL"
    ],
    "published": "2025-10-29T01:07:26Z",
    "authors": [
      "Seonjeong Hwang",
      "Hyounghun Kim",
      "Gary Geunbae Lee"
    ],
    "pdf_url": "http://arxiv.org/pdf/2510.25064v1"
  },
  {
    "id": "2510.25055v1",
    "title": "GAPMAP: Mapping Scientific Knowledge Gaps in Biomedical Literature Using\n  Large Language Models",
    "abstract": "Scientific progress is driven by the deliberate articulation of what remains\nunknown. This study investigates the ability of large language models (LLMs) to\nidentify research knowledge gaps in the biomedical literature. We define two\ncategories of knowledge gaps: explicit gaps, clear declarations of missing\nknowledge; and implicit gaps, context-inferred missing knowledge. While prior\nwork has focused mainly on explicit gap detection, we extend this line of\nresearch by addressing the novel task of inferring implicit gaps. We conducted\ntwo experiments on almost 1500 documents across four datasets, including a\nmanually annotated corpus of biomedical articles. We benchmarked both\nclosed-weight models (from OpenAI) and open-weight models (Llama and Gemma 2)\nunder paragraph-level and full-paper settings. To address the reasoning of\nimplicit gaps inference, we introduce \\textbf{\\small TABI}, a Toulmin-Abductive\nBucketed Inference scheme that structures reasoning and buckets inferred\nconclusion candidates for validation. Our results highlight the robust\ncapability of LLMs in identifying both explicit and implicit knowledge gaps.\nThis is true for both open- and closed-weight models, with larger variants\noften performing better. This suggests a strong ability of LLMs for\nsystematically identifying candidate knowledge gaps, which can support\nearly-stage research formulation, policymakers, and funding decisions. We also\nreport observed failure modes and outline directions for robust deployment,\nincluding domain adaptation, human-in-the-loop verification, and benchmarking\nacross open- and closed-weight models.",
    "categories": [
      "cs.CL",
      "cs.AI",
      "cs.LG"
    ],
    "published": "2025-10-29T00:46:45Z",
    "authors": [
      "Nourah M Salem",
      "Elizabeth White",
      "Michael Bada",
      "Lawrence Hunter"
    ],
    "pdf_url": "http://arxiv.org/pdf/2510.25055v1"
  },
  {
    "id": "2510.25054v2",
    "title": "Evaluating Emotion Recognition in Spoken Language Models on Emotionally\n  Incongruent Speech",
    "abstract": "Advancements in spoken language processing have driven the development of\nspoken language models (SLMs), designed to achieve universal audio\nunderstanding by jointly learning text and audio representations for a wide\nrange of tasks. Although promising results have been achieved, there is growing\ndiscussion regarding these models' generalization capabilities and the extent\nto which they truly integrate audio and text modalities in their internal\nrepresentations. In this work, we evaluate four SLMs on the task of speech\nemotion recognition using a dataset of emotionally incongruent speech samples,\na condition under which the semantic content of the spoken utterance conveys\none emotion while speech expressiveness conveys another. Our results indicate\nthat SLMs rely predominantly on textual semantics rather than speech emotion to\nperform the task, indicating that text-related representations largely dominate\nover acoustic representations. We release both the code and the Emotionally\nIncongruent Synthetic Speech dataset (EMIS) to the community.",
    "categories": [
      "cs.CL",
      "eess.AS"
    ],
    "published": "2025-10-29T00:45:36Z",
    "authors": [
      "Pedro Corr\u00eaa",
      "Jo\u00e3o Lima",
      "Victor Moreno",
      "Lucas Ueda",
      "Paula Dornhofer Paro Costa"
    ],
    "pdf_url": "http://arxiv.org/pdf/2510.25054v2"
  },
  {
    "id": "2510.25017v1",
    "title": "StorageXTuner: An LLM Agent-Driven Automatic Tuning Framework for\n  Heterogeneous Storage Systems",
    "abstract": "Automatically configuring storage systems is hard: parameter spaces are large\nand conditions vary across workloads, deployments, and versions. Heuristic and\nML tuners are often system specific, require manual glue, and degrade under\nchanges. Recent LLM-based approaches help but usually treat tuning as a\nsingle-shot, system-specific task, which limits cross-system reuse, constrains\nexploration, and weakens validation. We present StorageXTuner, an LLM\nagent-driven auto-tuning framework for heterogeneous storage engines.\nStorageXTuner separates concerns across four agents - Executor (sandboxed\nbenchmarking), Extractor (performance digest), Searcher (insight-guided\nconfiguration exploration), and Reflector (insight generation and management).\nThe design couples an insight-driven tree search with layered memory that\npromotes empirically validated insights and employs lightweight checkers to\nguard against unsafe actions. We implement a prototype and evaluate it on\nRocksDB, LevelDB, CacheLib, and MySQL InnoDB with YCSB, MixGraph, and TPC-H/C.\nRelative to out-of-the-box settings and to ELMo-Tune, StorageXTuner reaches up\nto 575% and 111% higher throughput, reduces p99 latency by as much as 88% and\n56%, and converges with fewer trials.",
    "categories": [
      "cs.DB",
      "cs.AI",
      "cs.CL"
    ],
    "published": "2025-10-28T22:33:14Z",
    "authors": [
      "Qi Lin",
      "Zhenyu Zhang",
      "Viraj Thakkar",
      "Zhenjie Sun",
      "Mai Zheng",
      "Zhichao Cao"
    ],
    "pdf_url": "http://arxiv.org/pdf/2510.25017v1"
  },
  {
    "id": "2510.25013v1",
    "title": "Emergence of Minimal Circuits for Indirect Object Identification in\n  Attention-Only Transformers",
    "abstract": "Mechanistic interpretability aims to reverse-engineer large language models\n(LLMs) into human-understandable computational circuits. However, the\ncomplexity of pretrained models often obscures the minimal mechanisms required\nfor specific reasoning tasks. In this work, we train small, attention-only\ntransformers from scratch on a symbolic version of the Indirect Object\nIdentification (IOI) task -- a benchmark for studying coreference -- like\nreasoning in transformers. Surprisingly, a single-layer model with only two\nattention heads achieves perfect IOI accuracy, despite lacking MLPs and\nnormalization layers. Through residual stream decomposition, spectral analysis,\nand embedding interventions, we find that the two heads specialize into\nadditive and contrastive subcircuits that jointly implement IOI resolution.\nFurthermore, we show that a two-layer, one-head model achieves similar\nperformance by composing information across layers through query-value\ninteractions. These results demonstrate that task-specific training induces\nhighly interpretable, minimal circuits, offering a controlled testbed for\nprobing the computational foundations of transformer reasoning.",
    "categories": [
      "cs.CL",
      "cs.AI",
      "cs.LG"
    ],
    "published": "2025-10-28T22:25:19Z",
    "authors": [
      "Rabin Adhikari"
    ],
    "pdf_url": "http://arxiv.org/pdf/2510.25013v1"
  },
  {
    "id": "2510.24992v1",
    "title": "POWSM: A Phonetic Open Whisper-Style Speech Foundation Model",
    "abstract": "Recent advances in spoken language processing have led to substantial\nprogress in phonetic tasks such as automatic speech recognition (ASR), phone\nrecognition (PR), grapheme-to-phoneme conversion (G2P), and phoneme-to-grapheme\nconversion (P2G). Despite their conceptual similarity, these tasks have largely\nbeen studied in isolation, each relying on task-specific architectures and\ndatasets. In this paper, we introduce POWSM (Phonetic Open Whisper-style Speech\nModel), the first unified framework capable of jointly performing multiple\nphone-related tasks. POWSM enables seamless conversion between audio, text\n(graphemes), and phones, opening up new possibilities for universal and\nlow-resource speech processing. Our model outperforms or matches specialized PR\nmodels of similar size (Wav2Vec2Phoneme and ZIPA) while jointly supporting G2P,\nP2G, and ASR. Our training data, code and models are released to foster open\nscience.",
    "categories": [
      "cs.CL",
      "eess.AS"
    ],
    "published": "2025-10-28T21:43:45Z",
    "authors": [
      "Chin-Jou Li",
      "Kalvin Chang",
      "Shikhar Bharadwaj",
      "Eunjung Yeo",
      "Kwanghee Choi",
      "Jian Zhu",
      "David Mortensen",
      "Shinji Watanabe"
    ],
    "pdf_url": "http://arxiv.org/pdf/2510.24992v1"
  },
  {
    "id": "2510.24966v1",
    "title": "Sequences of Logits Reveal the Low Rank Structure of Language Models",
    "abstract": "A major problem in the study of large language models is to understand their\ninherent low-dimensional structure. We introduce an approach to study the\nlow-dimensional structure of language models at a model-agnostic level: as\nsequential probabilistic models. We first empirically demonstrate that a wide\nrange of modern language models exhibit low-rank structure: in particular,\nmatrices built from the model's logits for varying sets of prompts and\nresponses have low approximate rank. We then show that this low-rank structure\ncan be leveraged for generation -- in particular, we can generate a response to\na target prompt using a linear combination of the model's outputs on unrelated,\nor even nonsensical prompts.\n  On the theoretical front, we observe that studying the approximate rank of\nlanguage models in the sense discussed above yields a simple universal\nabstraction whose theoretical predictions parallel our experiments. We then\nanalyze the representation power of the abstraction and give provable learning\nguarantees.",
    "categories": [
      "cs.LG",
      "cs.AI",
      "cs.CL",
      "stat.ML"
    ],
    "published": "2025-10-28T20:55:58Z",
    "authors": [
      "Noah Golowich",
      "Allen Liu",
      "Abhishek Shetty"
    ],
    "pdf_url": "http://arxiv.org/pdf/2510.24966v1"
  },
  {
    "id": "2510.24963v1",
    "title": "Language Model Behavioral Phases are Consistent Across Architecture,\n  Training Data, and Scale",
    "abstract": "We show that across architecture (Transformer vs. Mamba vs. RWKV), training\ndataset (OpenWebText vs. The Pile), and scale (14 million parameters to 12\nbillion parameters), autoregressive language models exhibit highly consistent\npatterns of change in their behavior over the course of pretraining. Based on\nour analysis of over 1,400 language model checkpoints on over 110,000 tokens of\nEnglish, we find that up to 98% of the variance in language model behavior at\nthe word level can be explained by three simple heuristics: the unigram\nprobability (frequency) of a given word, the $n$-gram probability of the word,\nand the semantic similarity between the word and its context. Furthermore, we\nsee consistent behavioral phases in all language models, with their predicted\nprobabilities for words overfitting to those words' $n$-gram probabilities for\nincreasing $n$ over the course of training. Taken together, these results\nsuggest that learning in neural language models may follow a similar trajectory\nirrespective of model details.",
    "categories": [
      "cs.CL"
    ],
    "published": "2025-10-28T20:51:01Z",
    "authors": [
      "James A. Michaelov",
      "Roger P. Levy",
      "Benjamin K. Bergen"
    ],
    "pdf_url": "http://arxiv.org/pdf/2510.24963v1"
  },
  {
    "id": "2510.24942v1",
    "title": "Finding Culture-Sensitive Neurons in Vision-Language Models",
    "abstract": "Despite their impressive performance, vision-language models (VLMs) still\nstruggle on culturally situated inputs. To understand how VLMs process\nculturally grounded information, we study the presence of culture-sensitive\nneurons, i.e. neurons whose activations show preferential sensitivity to inputs\nassociated with particular cultural contexts. We examine whether such neurons\nare important for culturally diverse visual question answering and where they\nare located. Using the CVQA benchmark, we identify neurons of culture\nselectivity and perform causal tests by deactivating the neurons flagged by\ndifferent identification methods. Experiments on three VLMs across 25 cultural\ngroups demonstrate the existence of neurons whose ablation disproportionately\nharms performance on questions about the corresponding cultures, while having\nminimal effects on others. Moreover, we propose a new margin-based selector -\nContrastive Activation Selection (CAS), and show that it outperforms existing\nprobability- and entropy-based methods in identifying culture-sensitive\nneurons. Finally, our layer-wise analyses reveals that such neurons tend to\ncluster in certain decoder layers. Overall, our findings shed new light on the\ninternal organization of multimodal representations.",
    "categories": [
      "cs.LG",
      "cs.AI",
      "cs.CL"
    ],
    "published": "2025-10-28T20:14:37Z",
    "authors": [
      "Xiutian Zhao",
      "Rochelle Choenni",
      "Rohit Saxena",
      "Ivan Titov"
    ],
    "pdf_url": "http://arxiv.org/pdf/2510.24942v1"
  },
  {
    "id": "2510.24940v1",
    "title": "SemCoT: Accelerating Chain-of-Thought Reasoning through\n  Semantically-Aligned Implicit Tokens",
    "abstract": "The verbosity of Chain-of-Thought (CoT) reasoning hinders its mass deployment\nin efficiency-critical applications. Recently, implicit CoT approaches have\nemerged, which encode reasoning steps within LLM's hidden embeddings (termed\n``implicit reasoning'') rather than explicit tokens. This approach accelerates\nCoT by reducing the reasoning length and bypassing some LLM components.\nHowever, existing implicit CoT methods face two significant challenges: (1)\nthey fail to preserve the semantic alignment between the implicit reasoning\n(when transformed to natural language) and the ground-truth reasoning,\nresulting in a significant CoT performance degradation, and (2) they focus on\nreducing the length of the implicit reasoning; however, they neglect the\nconsiderable time cost for an LLM to generate one individual implicit reasoning\ntoken. To tackle these challenges, we propose a novel semantically-aligned\nimplicit CoT framework termed SemCoT. In particular, for the first challenge,\nwe design a contrastively trained sentence transformer that evaluates semantic\nalignment between implicit and explicit reasoning, which is used to enforce\nsemantic preservation during implicit reasoning optimization. To address the\nsecond challenge, we introduce an efficient implicit reasoning generator by\nfinetuning a lightweight language model using knowledge distillation. This\ngenerator is guided by our sentence transformer to distill ground-truth\nreasoning into semantically aligned implicit reasoning, while also optimizing\nfor accuracy. SemCoT is the first approach that enhances CoT efficiency by\njointly optimizing token-level generation speed and preserving semantic\nalignment with ground-truth reasoning. Extensive experiments demonstrate the\nsuperior performance of SemCoT compared to state-of-the-art methods in both\nefficiency and effectiveness. Our code can be found at\nhttps://github.com/YinhanHe123/SemCoT/.",
    "categories": [
      "cs.CL"
    ],
    "published": "2025-10-28T20:11:54Z",
    "authors": [
      "Yinhan He",
      "Wendy Zheng",
      "Yaochen Zhu",
      "Zaiyi Zheng",
      "Lin Su",
      "Sriram Vasudevan",
      "Qi Guo",
      "Liangjie Hong",
      "Jundong Li"
    ],
    "pdf_url": "http://arxiv.org/pdf/2510.24940v1"
  },
  {
    "id": "2510.24934v1",
    "title": "Disaggregation Reveals Hidden Training Dynamics: The Case of Agreement\n  Attraction",
    "abstract": "Language models generally produce grammatical text, but they are more likely\nto make errors in certain contexts. Drawing on paradigms from\npsycholinguistics, we carry out a fine-grained analysis of those errors in\ndifferent syntactic contexts. We demonstrate that by disaggregating over the\nconditions of carefully constructed datasets and comparing model performance on\neach over the course of training, it is possible to better understand the\nintermediate stages of grammatical learning in language models. Specifically,\nwe identify distinct phases of training where language model behavior aligns\nwith specific heuristics such as word frequency and local context rather than\ngeneralized grammatical rules. We argue that taking this approach to analyzing\nlanguage model behavior more generally can serve as a powerful tool for\nunderstanding the intermediate learning phases, overall training dynamics, and\nthe specific generalizations learned by language models.",
    "categories": [
      "cs.CL"
    ],
    "published": "2025-10-28T19:59:26Z",
    "authors": [
      "James A. Michaelov",
      "Catherine Arnett"
    ],
    "pdf_url": "http://arxiv.org/pdf/2510.24934v1"
  },
  {
    "id": "2510.24932v1",
    "title": "RiddleBench: A New Generative Reasoning Benchmark for LLMs",
    "abstract": "Large Language Models have demonstrated strong performance on many\nestablished reasoning benchmarks. However, these benchmarks primarily evaluate\nstructured skills like quantitative problem-solving, leaving a gap in assessing\nflexible, multifaceted reasoning abilities that are central to human\nintelligence. These abilities require integrating logical deduction with\nspatial awareness and constraint satisfaction, which current evaluations do not\nmeasure well. To address this, we introduce RiddleBench, a benchmark of 1,737\nchallenging puzzles in English designed to probe these core reasoning\ncapabilities. Evaluation of state-of-the-art models on RiddleBench shows\nfundamental weaknesses. Even top proprietary models like Gemini 2.5 Pro, o3,\nand Claude 4 Sonnet achieve accuracy just above 60% (60.30%, 63.37%, and\n63.16%). Analysis further reveals deep failures, including hallucination\ncascades (accepting flawed reasoning from other models) and poor\nself-correction due to a strong self-confirmation bias. Their reasoning is also\nfragile, with performance degrading significantly when constraints are\nreordered or irrelevant information is introduced. RiddleBench functions as a\ndiagnostic tool for these issues and as a resource for guiding the development\nof more robust and reliable language models.",
    "categories": [
      "cs.CL"
    ],
    "published": "2025-10-28T19:58:24Z",
    "authors": [
      "Deepon Halder",
      "Alan Saji",
      "Thanmay Jayakumar",
      "Ratish Puduppully",
      "Anoop Kunchukuttan",
      "Raj Dabre"
    ],
    "pdf_url": "http://arxiv.org/pdf/2510.24932v1"
  },
  {
    "id": "2510.24891v1",
    "title": "Idea2Plan: Exploring AI-Powered Research Planning",
    "abstract": "Large language models (LLMs) have demonstrated significant potential to\naccelerate scientific discovery as valuable tools for analyzing data,\ngenerating hypotheses, and supporting innovative approaches in various\nscientific fields. In this work, we investigate how LLMs can handle the\ntransition from conceptual research ideas to well-structured research plans.\nEffective research planning not only supports scientists in advancing their\nresearch but also represents a crucial capability for the development of\nautonomous research agents. Despite its importance, the field lacks a\nsystematic understanding of LLMs' research planning capability. To rigorously\nmeasure this capability, we introduce the Idea2Plan task and Idea2Plan Bench, a\nbenchmark built from 200 ICML 2025 Spotlight and Oral papers released after\nmajor LLM training cutoffs. Each benchmark instance includes a research idea\nand a grading rubric capturing the key components of valid plans. We further\npropose Idea2Plan JudgeEval, a complementary benchmark to assess the\nreliability of LLM-based judges against expert annotations. Experimental\nresults show that GPT-5 and GPT-5-mini achieve the strongest performance on the\nbenchmark, though substantial headroom remains for future improvement. Our\nstudy provides new insights into LLMs' capability for research planning and lay\nthe groundwork for future progress.",
    "categories": [
      "cs.CL",
      "cs.LG"
    ],
    "published": "2025-10-28T18:54:51Z",
    "authors": [
      "Jin Huang",
      "Silviu Cucerzan",
      "Sujay Kumar Jauhar",
      "Ryen W. White"
    ],
    "pdf_url": "http://arxiv.org/pdf/2510.24891v1"
  },
  {
    "id": "2510.24870v1",
    "title": "Seeing Through the MiRAGE: Evaluating Multimodal Retrieval Augmented\n  Generation",
    "abstract": "We introduce MiRAGE, an evaluation framework for retrieval-augmented\ngeneration (RAG) from multimodal sources. As audiovisual media becomes a\nprevalent source of information online, it is essential for RAG systems to\nintegrate information from these sources into generation. However, existing\nevaluations for RAG are text-centric, limiting their applicability to\nmultimodal, reasoning intensive settings because they don't verify information\nagainst sources. MiRAGE is a claim-centric approach to multimodal RAG\nevaluation, consisting of InfoF1, evaluating factuality and information\ncoverage, and CiteF1, measuring citation support and completeness. We show that\nMiRAGE, when applied by humans, strongly aligns with extrinsic quality\njudgments. We additionally introduce automatic variants of MiRAGE and three\nprominent TextRAG metrics -- ACLE, ARGUE, and RAGAS -- demonstrating the\nlimitations of text-centric work and laying the groundwork for automatic\nevaluation. We release open-source implementations and outline how to assess\nmultimodal RAG.",
    "categories": [
      "cs.CL",
      "cs.CV",
      "cs.IR"
    ],
    "published": "2025-10-28T18:21:19Z",
    "authors": [
      "Alexander Martin",
      "William Walden",
      "Reno Kriz",
      "Dengjia Zhang",
      "Kate Sanders",
      "Eugene Yang",
      "Chihsheng Jin",
      "Benjamin Van Durme"
    ],
    "pdf_url": "http://arxiv.org/pdf/2510.24870v1"
  },
  {
    "id": "2510.24856v1",
    "title": "Do Large Language Models Grasp The Grammar? Evidence from\n  Grammar-Book-Guided Probing in Luxembourgish",
    "abstract": "Grammar refers to the system of rules that governs the structural\norganization and the semantic relations among linguistic units such as\nsentences, phrases, and words within a given language. In natural language\nprocessing, there remains a notable scarcity of grammar focused evaluation\nprotocols, a gap that is even more pronounced for low-resource languages.\nMoreover, the extent to which large language models genuinely comprehend\ngrammatical structure, especially the mapping between syntactic structures and\nmeanings, remains under debate. To investigate this issue, we propose a Grammar\nBook Guided evaluation pipeline intended to provide a systematic and\ngeneralizable framework for grammar evaluation consisting of four key stages,\nand in this work we take Luxembourgish as a case study. The results show a weak\npositive correlation between translation performance and grammatical\nunderstanding, indicating that strong translations do not necessarily imply\ndeep grammatical competence. Larger models perform well overall due to their\nsemantic strength but remain weak in morphology and syntax, struggling\nparticularly with Minimal Pair tasks, while strong reasoning ability offers a\npromising way to enhance their grammatical understanding.",
    "categories": [
      "cs.CL"
    ],
    "published": "2025-10-28T18:02:51Z",
    "authors": [
      "Lujun Li",
      "Yewei Song",
      "Lama Sleem",
      "Yiqun Wang",
      "Yangjie Xu",
      "Cedric Lothritz",
      "Niccolo Gentile",
      "Radu State",
      "Tegawende F. Bissyande",
      "Jacques Klein"
    ],
    "pdf_url": "http://arxiv.org/pdf/2510.24856v1"
  },
  {
    "id": "2510.24707v1",
    "title": "MetricX-25 and GemSpanEval: Google Translate Submissions to the WMT25\n  Evaluation Shared Task",
    "abstract": "In this paper, we present our submissions to the unified WMT25 Translation\nEvaluation Shared Task. For the Quality Score Prediction subtask, we create a\nnew generation of MetricX with improvements in the input format and the\ntraining protocol, while for the Error Span Detection subtask we develop a new\nmodel, GemSpanEval, trained to predict error spans along with their severities\nand categories. Both systems are based on the state-of-the-art multilingual\nopen-weights model Gemma 3, fine-tuned on publicly available WMT data. We\ndemonstrate that MetricX-25, adapting Gemma 3 to an encoder-only architecture\nwith a regression head on top, can be trained to effectively predict both MQM\nand ESA quality scores, and significantly outperforms its predecessor. Our\ndecoder-only GemSpanEval model, on the other hand, we show to be competitive in\nerror span detection with xCOMET, a strong encoder-only sequence-tagging\nbaseline. With error span detection formulated as a generative task, we\ninstruct the model to also output the context for each predicted error span,\nthus ensuring that error spans are identified unambiguously.",
    "categories": [
      "cs.CL"
    ],
    "published": "2025-10-28T17:56:20Z",
    "authors": [
      "Juraj Juraska",
      "Tobias Domhan",
      "Mara Finkelstein",
      "Tetsuji Nakagawa",
      "Geza Kovacs",
      "Daniel Deutsch",
      "Pidong Wang",
      "Markus Freitag"
    ],
    "pdf_url": "http://arxiv.org/pdf/2510.24707v1"
  },
  {
    "id": "2510.24706v1",
    "title": "ComboBench: Can LLMs Manipulate Physical Devices to Play Virtual Reality\n  Games?",
    "abstract": "Virtual Reality (VR) games require players to translate high-level semantic\nactions into precise device manipulations using controllers and head-mounted\ndisplays (HMDs). While humans intuitively perform this translation based on\ncommon sense and embodied understanding, whether Large Language Models (LLMs)\ncan effectively replicate this ability remains underexplored. This paper\nintroduces a benchmark, ComboBench, evaluating LLMs' capability to translate\nsemantic actions into VR device manipulation sequences across 262 scenarios\nfrom four popular VR games: Half-Life: Alyx, Into the Radius, Moss: Book II,\nand Vivecraft. We evaluate seven LLMs, including GPT-3.5, GPT-4, GPT-4o,\nGemini-1.5-Pro, LLaMA-3-8B, Mixtral-8x7B, and GLM-4-Flash, compared against\nannotated ground truth and human performance. Our results reveal that while\ntop-performing models like Gemini-1.5-Pro demonstrate strong task decomposition\ncapabilities, they still struggle with procedural reasoning and spatial\nunderstanding compared to humans. Performance varies significantly across\ngames, suggesting sensitivity to interaction complexity. Few-shot examples\nsubstantially improve performance, indicating potential for targeted\nenhancement of LLMs' VR manipulation capabilities. We release all materials at\nhttps://sites.google.com/view/combobench.",
    "categories": [
      "cs.CL",
      "cs.AI",
      "cs.HC",
      "cs.SE"
    ],
    "published": "2025-10-28T17:55:42Z",
    "authors": [
      "Shuqing Li",
      "Jiayi Yan",
      "Chenyu Niu",
      "Jen-tse Huang",
      "Yun Peng",
      "Wenxuan Wang",
      "Yepang Liu",
      "Michael R. Lyu"
    ],
    "pdf_url": "http://arxiv.org/pdf/2510.24706v1"
  },
  {
    "id": "2510.24702v1",
    "title": "Agent Data Protocol: Unifying Datasets for Diverse, Effective\n  Fine-tuning of LLM Agents",
    "abstract": "Public research results on large-scale supervised finetuning of AI agents\nremain relatively rare, since the collection of agent training data presents\nunique challenges. In this work, we argue that the bottleneck is not a lack of\nunderlying data sources, but that a large variety of data is fragmented across\nheterogeneous formats, tools, and interfaces. To this end, we introduce the\nagent data protocol (ADP), a light-weight representation language that serves\nas an \"interlingua\" between agent datasets in diverse formats and unified agent\ntraining pipelines downstream. The design of ADP is expressive enough to\ncapture a large variety of tasks, including API/tool use, browsing, coding,\nsoftware engineering, and general agentic workflows, while remaining simple to\nparse and train on without engineering at a per-dataset level. In experiments,\nwe unified a broad collection of 13 existing agent training datasets into ADP\nformat, and converted the standardized ADP data into training-ready formats for\nmultiple agent frameworks. We performed SFT on these data, and demonstrated an\naverage performance gain of ~20% over corresponding base models, and delivers\nstate-of-the-art or near-SOTA performance on standard coding, browsing, tool\nuse, and research benchmarks, without domain-specific tuning. All code and data\nare released publicly, in the hope that ADP could help lower the barrier to\nstandardized, scalable, and reproducible agent training.",
    "categories": [
      "cs.CL",
      "cs.AI"
    ],
    "published": "2025-10-28T17:53:13Z",
    "authors": [
      "Yueqi Song",
      "Ketan Ramaneti",
      "Zaid Sheikh",
      "Ziru Chen",
      "Boyu Gou",
      "Tianbao Xie",
      "Yiheng Xu",
      "Danyang Zhang",
      "Apurva Gandhi",
      "Fan Yang",
      "Joseph Liu",
      "Tianyue Ou",
      "Zhihao Yuan",
      "Frank Xu",
      "Shuyan Zhou",
      "Xingyao Wang",
      "Xiang Yue",
      "Tao Yu",
      "Huan Sun",
      "Yu Su",
      "Graham Neubig"
    ],
    "pdf_url": "http://arxiv.org/pdf/2510.24702v1"
  },
  {
    "id": "2510.24701v1",
    "title": "Tongyi DeepResearch Technical Report",
    "abstract": "We present Tongyi DeepResearch, an agentic large language model, which is\nspecifically designed for long-horizon, deep information-seeking research\ntasks. To incentivize autonomous deep research agency, Tongyi DeepResearch is\ndeveloped through an end-to-end training framework that combines agentic\nmid-training and agentic post-training, enabling scalable reasoning and\ninformation seeking across complex tasks. We design a highly scalable data\nsynthesis pipeline that is fully automatic, without relying on costly human\nannotation, and empowers all training stages. By constructing customized\nenvironments for each stage, our system enables stable and consistent\ninteractions throughout. Tongyi DeepResearch, featuring 30.5 billion total\nparameters, with only 3.3 billion activated per token, achieves\nstate-of-the-art performance across a range of agentic deep research\nbenchmarks, including Humanity's Last Exam, BrowseComp, BrowseComp-ZH,\nWebWalkerQA, xbench-DeepSearch, FRAMES and xbench-DeepSearch-2510. We\nopen-source the model, framework, and complete solutions to empower the\ncommunity.",
    "categories": [
      "cs.CL",
      "cs.AI",
      "cs.IR",
      "cs.LG",
      "cs.MA"
    ],
    "published": "2025-10-28T17:53:02Z",
    "authors": [
      " Tongyi DeepResearch Team",
      "Baixuan Li",
      "Bo Zhang",
      "Dingchu Zhang",
      "Fei Huang",
      "Guangyu Li",
      "Guoxin Chen",
      "Huifeng Yin",
      "Jialong Wu",
      "Jingren Zhou",
      "Kuan Li",
      "Liangcai Su",
      "Litu Ou",
      "Liwen Zhang",
      "Pengjun Xie",
      "Rui Ye",
      "Wenbiao Yin",
      "Xinmiao Yu",
      "Xinyu Wang",
      "Xixi Wu",
      "Xuanzhong Chen",
      "Yida Zhao",
      "Zhen Zhang",
      "Zhengwei Tao",
      "Zhongwang Zhang",
      "Zile Qiao",
      "Chenxi Wang",
      "Donglei Yu",
      "Gang Fu",
      "Haiyang Shen",
      "Jiayin Yang",
      "Jun Lin",
      "Junkai Zhang",
      "Kui Zeng",
      "Li Yang",
      "Hailong Yin",
      "Maojia Song",
      "Ming Yan",
      "Peng Xia",
      "Qian Xiao",
      "Rui Min",
      "Ruixue Ding",
      "Runnan Fang",
      "Shaowei Chen",
      "Shen Huang",
      "Shihang Wang",
      "Shihao Cai",
      "Weizhou Shen",
      "Xiaobin Wang",
      "Xin Guan",
      "Xinyu Geng",
      "Yingcheng Shi",
      "Yuning Wu",
      "Zhuo Chen",
      "Zijian Li",
      "Yong Jiang"
    ],
    "pdf_url": "http://arxiv.org/pdf/2510.24701v1"
  },
  {
    "id": "2510.24698v1",
    "title": "ParallelMuse: Agentic Parallel Thinking for Deep Information Seeking",
    "abstract": "Parallel thinking expands exploration breadth, complementing the deep\nexploration of information-seeking (IS) agents to further enhance\nproblem-solving capability. However, conventional parallel thinking faces two\nkey challenges in this setting: inefficiency from repeatedly rolling out from\nscratch, and difficulty in integrating long-horizon reasoning trajectories\nduring answer generation, as limited context capacity prevents full\nconsideration of the reasoning process. To address these issues, we propose\nParallelMuse, a two-stage paradigm designed for deep IS agents. The first\nstage, Functionality-Specified Partial Rollout, partitions generated sequences\ninto functional regions and performs uncertainty-guided path reuse and\nbranching to enhance exploration efficiency. The second stage, Compressed\nReasoning Aggregation, exploits reasoning redundancy to losslessly compress\ninformation relevant to answer derivation and synthesize a coherent final\nanswer. Experiments across multiple open-source agents and benchmarks\ndemonstrate up to 62% performance improvement with a 10--30% reduction in\nexploratory token consumption.",
    "categories": [
      "cs.CL",
      "cs.AI"
    ],
    "published": "2025-10-28T17:51:50Z",
    "authors": [
      "Baixuan Li",
      "Dingchu Zhang",
      "Jialong Wu",
      "Wenbiao Yin",
      "Zhengwei Tao",
      "Yida Zhao",
      "Liwen Zhang",
      "Haiyang Shen",
      "Runnan Fang",
      "Pengjun Xie",
      "Jingren Zhou",
      "Yong Jiang"
    ],
    "pdf_url": "http://arxiv.org/pdf/2510.24698v1"
  },
  {
    "id": "2510.24699v1",
    "title": "AgentFold: Long-Horizon Web Agents with Proactive Context Management",
    "abstract": "LLM-based web agents show immense promise for information seeking, yet their\neffectiveness on long-horizon tasks is hindered by a fundamental trade-off in\ncontext management. Prevailing ReAct-based agents suffer from context\nsaturation as they accumulate noisy, raw histories, while methods that fixedly\nsummarize the full history at each step risk the irreversible loss of critical\ndetails. Addressing these, we introduce AgentFold, a novel agent paradigm\ncentered on proactive context management, inspired by the human cognitive\nprocess of retrospective consolidation. AgentFold treats its context as a\ndynamic cognitive workspace to be actively sculpted, rather than a passive log\nto be filled. At each step, it learns to execute a `folding' operation, which\nmanages its historical trajectory at multiple scales: it can perform granular\ncondensations to preserve vital, fine-grained details, or deep consolidations\nto abstract away entire multi-step sub-tasks. The results on prominent\nbenchmarks are striking: with simple supervised fine-tuning (without continual\npre-training or RL), our AgentFold-30B-A3B agent achieves 36.2% on BrowseComp\nand 47.3% on BrowseComp-ZH. Notably, this performance not only surpasses or\nmatches open-source models of a dramatically larger scale, such as the\nDeepSeek-V3.1-671B-A37B, but also surpasses leading proprietary agents like\nOpenAI's o4-mini.",
    "categories": [
      "cs.CL",
      "cs.AI",
      "cs.LG"
    ],
    "published": "2025-10-28T17:51:50Z",
    "authors": [
      "Rui Ye",
      "Zhongwang Zhang",
      "Kuan Li",
      "Huifeng Yin",
      "Zhengwei Tao",
      "Yida Zhao",
      "Liangcai Su",
      "Liwen Zhang",
      "Zile Qiao",
      "Xinyu Wang",
      "Pengjun Xie",
      "Fei Huang",
      "Siheng Chen",
      "Jingren Zhou",
      "Yong Jiang"
    ],
    "pdf_url": "http://arxiv.org/pdf/2510.24699v1"
  },
  {
    "id": "2510.24697v1",
    "title": "WebLeaper: Empowering Efficiency and Efficacy in WebAgent via Enabling\n  Info-Rich Seeking",
    "abstract": "Large Language Model (LLM)-based agents have emerged as a transformative\napproach for open-ended problem solving, with information seeking (IS) being a\ncore capability that enables autonomous reasoning and decision-making. While\nprior research has largely focused on improving retrieval depth, we observe\nthat current IS agents often suffer from low search efficiency, which in turn\nconstrains overall performance. A key factor underlying this inefficiency is\nthe sparsity of target entities in training tasks, which limits opportunities\nfor agents to learn and generalize efficient search behaviors. To address these\nchallenges, we propose WebLeaper, a framework for constructing high-coverage IS\ntasks and generating efficient solution trajectories. We formulate IS as a\ntree-structured reasoning problem, enabling a substantially larger set of\ntarget entities to be embedded within a constrained context. Leveraging curated\nWikipedia tables, we propose three variants for synthesizing IS tasks, Basic,\nUnion, and Reverse-Union, to systematically increase both IS efficiency and\nefficacy. Finally, we curate training trajectories by retaining only those that\nare simultaneously accurate and efficient, ensuring that the model is optimized\nfor both correctness and search performance. Extensive experiments on both\nbasic and comprehensive settings, conducted on five IS benchmarks, BrowserComp,\nGAIA, xbench-DeepSearch, WideSearch, and Seal-0, demonstrate that our method\nconsistently achieves improvements in both effectiveness and efficiency over\nstrong baselines.",
    "categories": [
      "cs.CL"
    ],
    "published": "2025-10-28T17:51:42Z",
    "authors": [
      "Zhengwei Tao",
      "Haiyang Shen",
      "Baixuan Li",
      "Wenbiao Yin",
      "Jialong Wu",
      "Kuan Li",
      "Zhongwang Zhang",
      "Huifeng Yin",
      "Rui Ye",
      "Liwen Zhang",
      "Xinyu Wang",
      "Pengjun Xie",
      "Jingren Zhou",
      "Yong Jiang"
    ],
    "pdf_url": "http://arxiv.org/pdf/2510.24697v1"
  },
  {
    "id": "2510.24695v1",
    "title": "AgentFrontier: Expanding the Capability Frontier of LLM Agents with\n  ZPD-Guided Data Synthesis",
    "abstract": "Training large language model agents on tasks at the frontier of their\ncapabilities is key to unlocking advanced reasoning. We introduce a data\nsynthesis approach inspired by the educational theory of the Zone of Proximal\nDevelopment (ZPD), which defines this frontier as tasks an LLM cannot solve\nalone but can master with guidance. To operationalize this, we present the\nAgentFrontier Engine, an automated pipeline that synthesizes high-quality,\nmultidisciplinary data situated precisely within the LLM's ZPD. This engine\nsupports both continued pre-training with knowledge-intensive data and targeted\npost-training on complex reasoning tasks. From the same framework, we derive\nthe ZPD Exam, a dynamic and automated benchmark designed to evaluate agent\ncapabilities on these frontier tasks. We train AgentFrontier-30B-A3B model on\nour synthesized data, which achieves state-of-the-art results on demanding\nbenchmarks like Humanity's Last Exam, even surpassing some leading proprietary\nagents. Our work demonstrates that a ZPD-guided approach to data synthesis\noffers a scalable and effective path toward building more capable LLM agents.",
    "categories": [
      "cs.CL"
    ],
    "published": "2025-10-28T17:50:47Z",
    "authors": [
      "Xuanzhong Chen",
      "Zile Qiao",
      "Guoxin Chen",
      "Liangcai Su",
      "Zhen Zhang",
      "Xinyu Wang",
      "Pengjun Xie",
      "Fei Huang",
      "Jingren Zhou",
      "Yong Jiang"
    ],
    "pdf_url": "http://arxiv.org/pdf/2510.24695v1"
  },
  {
    "id": "2510.24694v1",
    "title": "Repurposing Synthetic Data for Fine-grained Search Agent Supervision",
    "abstract": "LLM-based search agents are increasingly trained on entity-centric synthetic\ndata to solve complex, knowledge-intensive tasks. However, prevailing training\nmethods like Group Relative Policy Optimization (GRPO) discard this rich entity\ninformation, relying instead on sparse, outcome-based rewards. This critical\nlimitation renders them unable to distinguish informative \"near-miss\"\nsamples-those with substantially correct reasoning but a flawed final\nanswer-from complete failures, thus discarding valuable learning signals. We\naddress this by leveraging the very entities discarded during training. Our\nempirical analysis reveals a strong positive correlation between the number of\nground-truth entities identified during an agent's reasoning process and final\nanswer accuracy. Building on this insight, we introduce Entity-aware Group\nRelative Policy Optimization (E-GRPO), a novel framework that formulates a\ndense entity-aware reward function. E-GRPO assigns partial rewards to incorrect\nsamples proportional to their entity match rate, enabling the model to\neffectively learn from these \"near-misses\". Experiments on diverse\nquestion-answering (QA) and deep research benchmarks show that E-GRPO\nconsistently and significantly outperforms the GRPO baseline. Furthermore, our\nanalysis reveals that E-GRPO not only achieves superior accuracy but also\ninduces more efficient reasoning policies that require fewer tool calls,\ndemonstrating a more effective and sample-efficient approach to aligning search\nagents.",
    "categories": [
      "cs.CL",
      "cs.AI"
    ],
    "published": "2025-10-28T17:50:40Z",
    "authors": [
      "Yida Zhao",
      "Kuan Li",
      "Xixi Wu",
      "Liwen Zhang",
      "Dingchu Zhang",
      "Baixuan Li",
      "Maojia Song",
      "Zhuo Chen",
      "Chenxi Wang",
      "Xinyu Wang",
      "Kewei Tu",
      "Pengjun Xie",
      "Jingren Zhou",
      "Yong Jiang"
    ],
    "pdf_url": "http://arxiv.org/pdf/2510.24694v1"
  },
  {
    "id": "2510.24693v1",
    "title": "STAR-Bench: Probing Deep Spatio-Temporal Reasoning as Audio 4D\n  Intelligence",
    "abstract": "Despite rapid progress in Multi-modal Large Language Models and Large\nAudio-Language Models, existing audio benchmarks largely test semantics that\ncan be recovered from text captions, masking deficits in fine-grained\nperceptual reasoning. We formalize audio 4D intelligence that is defined as\nreasoning over sound dynamics in time and 3D space, and introduce STAR-Bench to\nmeasure it. STAR-Bench combines a Foundational Acoustic Perception setting (six\nattributes under absolute and relative regimes) with a Holistic Spatio-Temporal\nReasoning setting that includes segment reordering for continuous and discrete\nprocesses and spatial tasks spanning static localization, multi-source\nrelations, and dynamic trajectories. Our data curation pipeline uses two\nmethods to ensure high-quality samples. For foundational tasks, we use\nprocedurally synthesized and physics-simulated audio. For holistic data, we\nfollow a four-stage process that includes human annotation and final selection\nbased on human performance. Unlike prior benchmarks where caption-only\nanswering reduces accuracy slightly, STAR-Bench induces far larger drops\n(-31.5\\% temporal, -35.2\\% spatial), evidencing its focus on linguistically\nhard-to-describe cues. Evaluating 19 models reveals substantial gaps compared\nwith humans and a capability hierarchy: closed-source models are bottlenecked\nby fine-grained perception, while open-source models lag across perception,\nknowledge, and reasoning. Our STAR-Bench provides critical insights and a clear\npath forward for developing future models with a more robust understanding of\nthe physical world.",
    "categories": [
      "cs.SD",
      "cs.CL",
      "eess.AS"
    ],
    "published": "2025-10-28T17:50:34Z",
    "authors": [
      "Zihan Liu",
      "Zhikang Niu",
      "Qiuyang Xiao",
      "Zhisheng Zheng",
      "Ruoqi Yuan",
      "Yuhang Zang",
      "Yuhang Cao",
      "Xiaoyi Dong",
      "Jianze Liang",
      "Xie Chen",
      "Leilei Sun",
      "Dahua Lin",
      "Jiaqi Wang"
    ],
    "pdf_url": "http://arxiv.org/pdf/2510.24693v1"
  },
  {
    "id": "2510.24684v1",
    "title": "SPICE: Self-Play In Corpus Environments Improves Reasoning",
    "abstract": "Self-improving systems require environmental interaction for continuous\nadaptation. We introduce SPICE (Self-Play In Corpus Environments), a\nreinforcement learning framework where a single model acts in two roles: a\nChallenger that mines documents from a large corpus to generate diverse\nreasoning tasks, and a Reasoner that solves them. Through adversarial dynamics,\nthe Challenger creates an automatic curriculum at the frontier of the\nReasoner's capability, while corpus grounding provides the rich,\nnear-inexhaustible external signal necessary for sustained improvement. Unlike\nexisting ungrounded self-play methods that offer more limited benefits, SPICE\nachieves consistent gains across mathematical (+8.9%) and general reasoning\n(+9.8%) benchmarks on multiple model families. Our analysis reveals how\ndocument grounding is a key ingredient in SPICE to continuously generate its\nown increasingly challenging goals and achieve them, enabling sustained\nself-improvement.",
    "categories": [
      "cs.CL"
    ],
    "published": "2025-10-28T17:46:16Z",
    "authors": [
      "Bo Liu",
      "Chuanyang Jin",
      "Seungone Kim",
      "Weizhe Yuan",
      "Wenting Zhao",
      "Ilia Kulikov",
      "Xian Li",
      "Sainbayar Sukhbaatar",
      "Jack Lanchantin",
      "Jason Weston"
    ],
    "pdf_url": "http://arxiv.org/pdf/2510.24684v1"
  },
  {
    "id": "2510.24677v1",
    "title": "Dissecting Role Cognition in Medical LLMs via Neuronal Ablation",
    "abstract": "Large language models (LLMs) have gained significant traction in medical\ndecision support systems, particularly in the\n  context of medical question answering and role-playing simulations. A common\npractice, Prompt-Based Role Playing (PBRP),\n  instructs models to adopt different clinical roles (e.g., medical students,\nresidents, attending physicians) to simulate varied\n  professional behaviors. However, the impact of such role prompts on model\nreasoning capabilities remains unclear. This\n  study introduces the RP-Neuron-Activated Evaluation Framework(RPNA) to\nevaluate whether role prompts induce distinct,\n  role-specific cognitive processes in LLMs or merely modify linguistic style.\nWe test this framework on three medical QA\n  datasets, employing neuron ablation and representation analysis techniques to\nassess changes in reasoning pathways. Our\n  results demonstrate that role prompts do not significantly enhance the\nmedical reasoning abilities of LLMs. Instead, they\n  primarily affect surface-level linguistic features, with no evidence of\ndistinct reasoning pathways or cognitive differentiation\n  across clinical roles. Despite superficial stylistic changes, the core\ndecision-making mechanisms of LLMs remain uniform\n  across roles, indicating that current PBRP methods fail to replicate the\ncognitive complexity found in real-world medical\n  practice. This highlights the limitations of role-playing in medical AI and\nemphasizes the need for models that simulate genuine\n  cognitive processes rather than linguistic imitation.We have released the\nrelated code in the following repository:https:\n  //github.com/IAAR-Shanghai/RolePlay_LLMDoctor",
    "categories": [
      "cs.CL",
      "cs.AI"
    ],
    "published": "2025-10-28T17:40:53Z",
    "authors": [
      "Xun Liang",
      "Huayi Lai",
      "Hanyu Wang",
      "Wentao Zhang",
      "Linfeng Zhang",
      "Yanfang Chen",
      "Feiyu Xiong",
      "Zhiyu Li"
    ],
    "pdf_url": "http://arxiv.org/pdf/2510.24677v1"
  },
  {
    "id": "2510.24668v1",
    "title": "InteractComp: Evaluating Search Agents With Ambiguous Queries",
    "abstract": "Language agents have demonstrated remarkable potential in web search and\ninformation retrieval. However, these search agents assume user queries are\ncomplete and unambiguous, an assumption that diverges from reality where users\nbegin with incomplete queries requiring clarification through interaction. Yet\nmost agents lack interactive mechanisms during the search process, and existing\nbenchmarks cannot assess this capability. To address this gap, we introduce\nInteractComp, a benchmark designed to evaluate whether search agents can\nrecognize query ambiguity and actively interact to resolve it during search.\nFollowing the principle of easy to verify, interact to disambiguate, we\nconstruct 210 expert-curated questions across 9 domains through a\ntarget-distractor methodology that creates genuine ambiguity resolvable only\nthrough interaction. Evaluation of 17 models reveals striking failure: the best\nmodel achieves only 13.73% accuracy despite 71.50% with complete context,\nexposing systematic overconfidence rather than reasoning deficits. Forced\ninteraction produces dramatic gains, demonstrating latent capability current\nstrategies fail to engage. Longitudinal analysis shows interaction capabilities\nstagnated over 15 months while search performance improved seven-fold,\nrevealing a critical blind spot. This stagnation, coupled with the immediate\nfeedback inherent to search tasks, makes InteractComp a valuable resource for\nboth evaluating and training interaction capabilities in search agents. The\ncode is available at https://github.com/FoundationAgents/InteractComp.",
    "categories": [
      "cs.CL",
      "cs.AI"
    ],
    "published": "2025-10-28T17:35:54Z",
    "authors": [
      "Mingyi Deng",
      "Lijun Huang",
      "Yani Fan",
      "Jiayi Zhang",
      "Fashen Ren",
      "Jinyi Bai",
      "Fuzhen Yang",
      "Dayi Miao",
      "Zhaoyang Yu",
      "Yifan Wu",
      "Yanfei Zhang",
      "Fengwei Teng",
      "Yingjia Wan",
      "Song Hu",
      "Yude Li",
      "Xin Jin",
      "Conghao Hu",
      "Haoyu Li",
      "Qirui Fu",
      "Tai Zhong",
      "Xinyu Wang",
      "Xiangru Tang",
      "Nan Tang",
      "Chenglin Wu",
      "Yuyu Luo"
    ],
    "pdf_url": "http://arxiv.org/pdf/2510.24668v1"
  },
  {
    "id": "2510.24664v1",
    "title": "MQM Re-Annotation: A Technique for Collaborative Evaluation of Machine\n  Translation",
    "abstract": "Human evaluation of machine translation is in an arms race with translation\nmodel quality: as our models get better, our evaluation methods need to be\nimproved to ensure that quality gains are not lost in evaluation noise. To this\nend, we experiment with a two-stage version of the current state-of-the-art\ntranslation evaluation paradigm (MQM), which we call MQM re-annotation. In this\nsetup, an MQM annotator reviews and edits a set of pre-existing MQM\nannotations, that may have come from themselves, another human annotator, or an\nautomatic MQM annotation system. We demonstrate that rater behavior in\nre-annotation aligns with our goals, and that re-annotation results in\nhigher-quality annotations, mostly due to finding errors that were missed\nduring the first pass.",
    "categories": [
      "cs.CL"
    ],
    "published": "2025-10-28T17:29:59Z",
    "authors": [
      "Parker Riley",
      "Daniel Deutsch",
      "Mara Finkelstein",
      "Colten DiIanni",
      "Juraj Juraska",
      "Markus Freitag"
    ],
    "pdf_url": "http://arxiv.org/pdf/2510.24664v1"
  },
  {
    "id": "2510.24654v1",
    "title": "Evolving Diagnostic Agents in a Virtual Clinical Environment",
    "abstract": "In this paper, we present a framework for training large language models\n(LLMs) as diagnostic agents with reinforcement learning, enabling them to\nmanage multi-turn diagnostic processes, adaptively select examinations, and\ncommit to final diagnoses. Unlike instruction-tuned models trained on static\ncase summaries, our method acquires diagnostic strategies through interactive\nexploration and outcome-based feedback. Our contributions are fourfold: (i) We\npresent DiagGym, a diagnostics world model trained with electronic health\nrecords that emits examination outcomes conditioned on patient history and\nrecommended examination, serving as a virtual clinical environment for\nrealistic diagnosis training and evaluation; (ii) We train DiagAgent via\nend-to-end, multi-turn reinforcement learning to learn diagnostic policies that\noptimize both information yield and diagnostic accuracy; (iii) We introduce\nDiagBench, a diagnostic benchmark comprising 750 cases with physician-validated\nexamination recommendations and 99 cases annotated with 973 physician-written\nrubrics on diagnosis process; (iv) we demonstrate superior performance across\ndiverse diagnostic settings. DiagAgent significantly outperforms 10\nstate-of-the-art LLMs, including DeepSeek-v3 and GPT-4o, as well as two\nprompt-engineered agents. In single-turn settings, DiagAgent achieves 9.34%\nhigher diagnostic accuracy and 44.03% improvement in examination recommendation\nhit ratio. In end-to-end settings, it delivers 15.12% increase in diagnostic\naccuracy and 23.09% boost in examination recommendation F1 score. In\nrubric-based evaluation, it surpasses the next-best model, Claude-sonnet-4, by\n7.1% in weighted rubric score. These findings indicate that learning policies\nin interactive clinical environments confers dynamic and clinically meaningful\ndiagnostic management abilities unattainable through passive training alone.",
    "categories": [
      "cs.CL"
    ],
    "published": "2025-10-28T17:19:47Z",
    "authors": [
      "Pengcheng Qiu",
      "Chaoyi Wu",
      "Junwei Liu",
      "Qiaoyu Zheng",
      "Yusheng Liao",
      "Haowen Wang",
      "Yun Yue",
      "Qianrui Fan",
      "Shuai Zhen",
      "Jian Wang",
      "Jinjie Gu",
      "Yanfeng Wang",
      "Ya Zhang",
      "Weidi Xie"
    ],
    "pdf_url": "http://arxiv.org/pdf/2510.24654v1"
  },
  {
    "id": "2510.24652v1",
    "title": "Optimizing Retrieval for RAG via Reinforced Contrastive Learning",
    "abstract": "As retrieval-augmented generation (RAG) becomes increasingly widespread, the\nrole of information retrieval (IR) is shifting from retrieving information for\nhuman users to retrieving contextual knowledge for artificial intelligence (AI)\nsystems, where relevance becomes difficult to define or annotate beforehand. To\naddress this challenge, we propose R3, a Retrieval framework optimized for RAG\nthrough trialand-feedback Reinforced contrastive learning. Unlike prior\napproaches that rely on annotated or synthetic data for supervised fine-tuning,\nR3 enables the retriever to dynamically explore and optimize relevance within\nthe RAG environment. During training, the retrieved results interact with the\nenvironment to produce contrastive signals that automatically guide the\nretriever's self-improvement. Extensive experiments across diverse tasks\ndemonstrate that R3 improves RAG performance by 5.2% over the original\nretriever and surpasses state-of-the-art retrievers by 4.9%, while achieving\ncomparable results to LLM-augmented retrieval and RAG systems built on\npost-trained or instruction-tuned LLMs. It is both efficient and practical,\nrequiring only 4 GPUs and completing training within a single day.",
    "categories": [
      "cs.CL",
      "cs.IR"
    ],
    "published": "2025-10-28T17:18:30Z",
    "authors": [
      "Jiawei Zhou",
      "Lei Chen"
    ],
    "pdf_url": "http://arxiv.org/pdf/2510.24652v1"
  },
  {
    "id": "2510.24647v1",
    "title": "Quantifying the Effects of Word Length, Frequency, and Predictability on\n  Dyslexia",
    "abstract": "We ask where, and under what conditions, dyslexic reading costs arise in a\nlarge-scale naturalistic reading dataset. Using eye-tracking aligned to\nword-level features (word length, frequency, and predictability), we model how\neach feature influences dyslexic time costs. We find that all three features\nrobustly change reading times in both typical and dyslexic readers, and that\ndyslexic readers show stronger sensitivities to each, especially\npredictability. Counterfactual manipulations of these features substantially\nnarrow the dyslexic-control gap by about one third, with predictability showing\nthe strongest effect, followed by length and frequency. These patterns align\nwith dyslexia theories that posit heightened demands on linguistic working\nmemory and phonological encoding, and they motivate further work on lexical\ncomplexity and parafoveal preview benefits to explain the remaining gap. In\nshort, we quantify when extra dyslexic costs arise, how large they are, and\noffer actionable guidance for interventions and computational models for\ndyslexics.",
    "categories": [
      "cs.CL",
      "q-bio.NC"
    ],
    "published": "2025-10-28T17:15:31Z",
    "authors": [
      "Hugo Rydel-Johnston",
      "Alex Kafkas"
    ],
    "pdf_url": "http://arxiv.org/pdf/2510.24647v1"
  },
  {
    "id": "2510.24636v2",
    "title": "OpenReward: Learning to Reward Long-form Agentic Tasks via Reinforcement\n  Learning",
    "abstract": "Reward models (RMs) have become essential for aligning large language models\n(LLMs), serving as scalable proxies for human evaluation in both training and\ninference. However, existing RMs struggle on knowledge-intensive and long-form\ntasks, where evaluating correctness requires grounding beyond the model's\ninternal knowledge. This limitation hinders them from reliably discriminating\nsubtle quality differences, especially when external evidence is necessary. To\naddress this, we introduce OpenRM, a tool-augmented long-form reward model that\nsystematically judges open-ended responses by invoking external tools to gather\nrelevant evidence. We train OpenRM with Group Relative Policy Optimization\n(GRPO) on over 27K synthesized pairwise examples generated through a\ncontrollable data synthesis framework. The training objective jointly\nsupervises intermediate tool usage and final outcome accuracy, incentivizing\nour reward model to learn effective evidence-based judgment strategies.\nExtensive experiments on three newly-collected datasets and two widely-used\nbenchmarks demonstrate that OpenRM substantially outperforms existing reward\nmodeling approaches. As a further step, we integrate OpenRM into both\ninference-time response selection and training-time data selection. This yields\nconsistent gains in downstream LLM alignment tasks, highlighting the potential\nof tool-augmented reward models for scaling reliable long-form evaluation.",
    "categories": [
      "cs.CL"
    ],
    "published": "2025-10-28T17:02:46Z",
    "authors": [
      "Ziyou Hu",
      "Zhengliang Shi",
      "Minghang Zhu",
      "Haitao Li",
      "Teng Sun",
      "Pengjie Ren",
      "Suzan Verberne",
      "Zhaochun Ren"
    ],
    "pdf_url": "http://arxiv.org/pdf/2510.24636v2"
  },
  {
    "id": "2510.24628v1",
    "title": "\"Mm, Wat?\" Detecting Other-initiated Repair Requests in Dialogue",
    "abstract": "Maintaining mutual understanding is a key component in human-human\nconversation to avoid conversation breakdowns, in which repair, particularly\nOther-Initiated Repair (OIR, when one speaker signals trouble and prompts the\nother to resolve), plays a vital role. However, Conversational Agents (CAs)\nstill fail to recognize user repair initiation, leading to breakdowns or\ndisengagement. This work proposes a multimodal model to automatically detect\nrepair initiation in Dutch dialogues by integrating linguistic and prosodic\nfeatures grounded in Conversation Analysis. The results show that prosodic cues\ncomplement linguistic features and significantly improve the results of\npretrained text and audio embeddings, offering insights into how different\nfeatures interact. Future directions include incorporating visual cues,\nexploring multilingual and cross-context corpora to assess the robustness and\ngeneralizability.",
    "categories": [
      "cs.CL"
    ],
    "published": "2025-10-28T16:58:26Z",
    "authors": [
      "Anh Ngo",
      "Nicolas Rollet",
      "Catherine Pelachaud",
      "Chloe Clavel"
    ],
    "pdf_url": "http://arxiv.org/pdf/2510.24628v1"
  },
  {
    "id": "2510.24626v1",
    "title": "Relative Scaling Laws for LLMs",
    "abstract": "Scaling laws describe how language models improve with additional data,\nparameters, and compute. While widely used, they are typically measured on\naggregate test sets. Aggregate evaluations yield clean trends but average over\nheterogeneous subpopulations, obscuring performance disparities. We introduce\nrelative scaling laws, which track how performance gaps between test\ndistributions evolve with scale rather than focusing solely on absolute error.\nUsing 255 decoder-only Transformers trained under matched-compute (IsoFLOP)\nbudgets from $10^{18}$--$10^{20}$ FLOPs on standard pretraining datasets, we\nfind diverse trajectories: academic domains on MMLU converge toward parity;\nregional English dialects shift depending on population size; and clusters of\nAI risk behaviours split, with capability- and influence-related risks\nincreasing during pretraining while adversarial risks do not. These results\nshow that although scaling improves overall performance, it is not a universal\nequalizer. To support further study, we release all model checkpoints from this\nwork to enable practitioners to measure relative alongside traditional scaling\nlaws, in order to better prioritize robustness challenges in light of the\nbitter lesson.",
    "categories": [
      "cs.CL"
    ],
    "published": "2025-10-28T16:55:22Z",
    "authors": [
      "William Held",
      "David Hall",
      "Percy Liang",
      "Diyi Yang"
    ],
    "pdf_url": "http://arxiv.org/pdf/2510.24626v1"
  },
  {
    "id": "2510.24619v1",
    "title": "Zero-Shot Cross-Lingual Transfer using Prefix-Based Adaptation",
    "abstract": "With the release of new large language models (LLMs) like Llama and Mistral,\nzero-shot cross-lingual transfer has become increasingly feasible due to their\nmultilingual pretraining and strong generalization capabilities. However,\nadapting these decoder-only LLMs to new tasks across languages remains\nchallenging. While parameter-efficient fine-tuning (PeFT) techniques like\nLow-Rank Adaptation (LoRA) are widely used, prefix-based techniques such as\nsoft prompt tuning, prefix tuning, and Llama Adapter are less explored,\nespecially for zero-shot transfer in decoder-only models. We present a\ncomprehensive study of three prefix-based methods for zero-shot cross-lingual\ntransfer from English to 35+ high- and low-resource languages. Our analysis\nfurther explores transfer across linguistic families and scripts, as well as\nthe impact of scaling model sizes from 1B to 24B. With Llama 3.1 8B, prefix\nmethods outperform LoRA-baselines by up to 6% on the Belebele benchmark.\nSimilar improvements were observed with Mistral v0.3 7B as well. Despite using\nonly 1.23M learning parameters with prefix tuning, we achieve consistent\nimprovements across diverse benchmarks. These findings highlight the potential\nof prefix-based techniques as an effective and scalable alternative to LoRA,\nparticularly in low-resource multilingual settings.",
    "categories": [
      "cs.CL",
      "cs.AI",
      "cs.LG",
      "I.2.7"
    ],
    "published": "2025-10-28T16:48:03Z",
    "authors": [
      "Snegha A",
      "Sayambhu Sen",
      "Piyush Singh Pasi",
      "Abhishek Singhania",
      "Preethi Jyothi"
    ],
    "pdf_url": "http://arxiv.org/pdf/2510.24619v1"
  },
  {
    "id": "2510.24606v1",
    "title": "Long-Context Modeling with Dynamic Hierarchical Sparse Attention for\n  On-Device LLMs",
    "abstract": "The quadratic cost of attention hinders the scalability of long-context LLMs,\nespecially in resource-constrained settings. Existing static sparse methods\nsuch as sliding windows or global tokens utilizes the sparsity of attention to\nreduce the cost of attention, but poorly adapts to the content-dependent\nvariations in attention due to their staticity. While previous work has\nproposed several dynamic approaches to improve flexibility, they still depend\non predefined templates or heuristic mechanisms. Such strategies reduce\ngenerality and prune tokens that remain contextually important, limiting their\naccuracy across diverse tasks. To tackle these bottlenecks of existing methods\nfor long-context modeling, we introduce Dynamic Hierarchical Sparse Attention\n(DHSA), a data-driven framework that dynamically predicts attention sparsity\nonline without retraining. Our proposed DHSA adaptively segments sequences into\nvariable-length chunks, then computes chunk representations by aggregating the\ntoken embeddings within each chunk. To avoid the bias introduced by varying\nchunk lengths, we apply length-normalized aggregation that scales the averaged\nembeddings by the square root of the chunk size. Finally, DHSA upsamples the\nchunk-level similarity scores to token level similarities to calculate\nimportance scores that determine which token-level interactions should be\npreserved. Our experiments on Gemma2 with Needle-in-a-Haystack Test and\nLongBench show that DHSA matches dense attention in accuracy, while reducing\nprefill latency by 20-60% and peak memory usage by 35%. Compared to other\nrepresentative baselines such as block sparse attention, DHSA achieves\nconsistently higher accuracy (6-18% relative gains) with comparable or lower\ncost, offering an efficient and adaptable solution for long-context on-device\nLLMs.",
    "categories": [
      "cs.CL"
    ],
    "published": "2025-10-28T16:34:18Z",
    "authors": [
      "Siheng Xiong",
      "Joe Zou",
      "Faramarz Fekri",
      "Yae Jee Cho"
    ],
    "pdf_url": "http://arxiv.org/pdf/2510.24606v1"
  },
  {
    "id": "2510.24605v1",
    "title": "Diffusion LLM with Native Variable Generation Lengths: Let [EOS] Lead\n  the Way",
    "abstract": "Diffusion-based large language models (dLLMs) have exhibited substantial\npotential for parallel text generation, which may enable more efficient\ngeneration compared to autoregressive models. However, current dLLMs suffer\nfrom fixed generation lengths, which indicates the generation lengths of dLLMs\nhave to be determined before decoding as a hyper-parameter, leading to issues\nin efficiency and flexibility. To solve these problems, in this work, we\npropose to train a diffusion LLM with native variable generation lengths,\nabbreviated as dLLM-Var. Concretely, we aim to train a model to accurately\npredict the [EOS] token in the generated text, which makes a dLLM be able to\nnatively infer in a block diffusion manner, while still maintaining the ability\nof global bi-directional (full) attention and high parallelism. Experiments on\nstandard benchmarks demonstrate that our method achieves a 30.1x speedup over\ntraditional dLLM inference paradigms and a 2.4x speedup relative to\nautoregressive models such as Qwen and Llama. Our method achieves higher\naccuracy and faster inference, elevating dLLMs beyond mere academic novelty and\nsupporting their practical use in real-world applications. Codes and models\nhave been released.",
    "categories": [
      "cs.CL"
    ],
    "published": "2025-10-28T16:32:43Z",
    "authors": [
      "Yicun Yang",
      "Cong Wang",
      "Shaobo Wang",
      "Zichen Wen",
      "Biqing Qi",
      "Hanlin Xu",
      "Linfeng Zhang"
    ],
    "pdf_url": "http://arxiv.org/pdf/2510.24605v1"
  },
  {
    "id": "2510.24592v2",
    "title": "ReForm: Reflective Autoformalization with Prospective Bounded Sequence\n  Optimization",
    "abstract": "Autoformalization, which translates natural language mathematics into\nmachine-verifiable formal statements, is critical for using formal mathematical\nreasoning to solve math problems stated in natural language. While Large\nLanguage Models can generate syntactically correct formal statements, they\noften fail to preserve the original problem's semantic intent. This limitation\narises from the LLM approaches' treating autoformalization as a simplistic\ntranslation task which lacks mechanisms for self-reflection and iterative\nrefinement that human experts naturally employ. To address these issues, we\npropose ReForm, a Reflective Autoformalization method that tightly integrates\nsemantic consistency evaluation into the autoformalization process. This\nenables the model to iteratively generate formal statements, assess its\nsemantic fidelity, and self-correct identified errors through progressive\nrefinement. To effectively train this reflective model, we introduce\nProspective Bounded Sequence Optimization (PBSO), which employs different\nrewards at different sequence positions to ensure that the model develops both\naccurate autoformalization and correct semantic validations, preventing\nsuperficial critiques that would undermine the purpose of reflection. Extensive\nexperiments across four autoformalization benchmarks demonstrate that ReForm\nachieves an average improvement of 22.6 percentage points over the strongest\nbaselines. To further ensure evaluation reliability, we introduce\nConsistencyCheck, a benchmark of 859 expert-annotated items that not only\nvalidates LLMs as judges but also reveals that autoformalization is inherently\ndifficult: even human experts produce semantic errors in up to 38.5% of cases.",
    "categories": [
      "cs.CL"
    ],
    "published": "2025-10-28T16:22:54Z",
    "authors": [
      "Guoxin Chen",
      "Jing Wu",
      "Xinjie Chen",
      "Wayne Xin Zhao",
      "Ruihua Song",
      "Chengxi Li",
      "Kai Fan",
      "Dayiheng Liu",
      "Minpeng Liao"
    ],
    "pdf_url": "http://arxiv.org/pdf/2510.24592v2"
  },
  {
    "id": "2510.24591v1",
    "title": "ReplicationBench: Can AI Agents Replicate Astrophysics Research Papers?",
    "abstract": "Frontier AI agents show increasing promise as scientific research assistants,\nand may eventually be useful for extended, open-ended research workflows.\nHowever, in order to use agents for novel research, we must first assess the\nunderlying faithfulness and correctness of their work. To evaluate agents as\nresearch assistants, we introduce ReplicationBench, an evaluation framework\nthat tests whether agents can replicate entire research papers drawn from the\nastrophysics literature. Astrophysics, where research relies heavily on\narchival data and computational study while requiring little real-world\nexperimentation, is a particularly useful testbed for AI agents in scientific\nresearch. We split each paper into tasks which require agents to replicate the\npaper's core contributions, including the experimental setup, derivations, data\nanalysis, and codebase. Each task is co-developed with the original paper\nauthors and targets a key scientific result, enabling objective evaluation of\nboth faithfulness (adherence to original methods) and correctness (technical\naccuracy of results). ReplicationBench is extremely challenging for current\nfrontier language models: even the best-performing language models score under\n20%. We analyze ReplicationBench trajectories in collaboration with domain\nexperts and find a rich, diverse set of failure modes for agents in scientific\nresearch. ReplicationBench establishes the first benchmark of paper-scale,\nexpert-validated astrophysics research tasks, reveals insights about agent\nperformance generalizable to other domains of data-driven science, and provides\na scalable framework for measuring AI agents' reliability in scientific\nresearch.",
    "categories": [
      "cs.CL",
      "astro-ph.IM"
    ],
    "published": "2025-10-28T16:21:19Z",
    "authors": [
      "Christine Ye",
      "Sihan Yuan",
      "Suchetha Cooray",
      "Steven Dillmann",
      "Ian L. V. Roque",
      "Dalya Baron",
      "Philipp Frank",
      "Sergio Martin-Alvarez",
      "Nolan Koblischke",
      "Frank J Qu",
      "Diyi Yang",
      "Risa Wechsler",
      "Ioana Ciuca"
    ],
    "pdf_url": "http://arxiv.org/pdf/2510.24591v1"
  },
  {
    "id": "2510.24570v1",
    "title": "BEST-RQ-Based Self-Supervised Learning for Whisper Domain Adaptation",
    "abstract": "Automatic Speech Recognition (ASR) systems, despite large multilingual\ntraining, struggle in out-of-domain and low-resource scenarios where labeled\ndata is scarce. We propose BEARD (BEST-RQ Encoder Adaptation with Re-training\nand Distillation), a novel framework designed to adapt Whisper's encoder using\nunlabeled data. Unlike traditional self-supervised learning methods, BEARD\nuniquely combines a BEST-RQ objective with knowledge distillation from a frozen\nteacher encoder, ensuring the encoder's complementarity with the pre-trained\ndecoder. Our experiments focus on the ATCO2 corpus from the challenging Air\nTraffic Control (ATC) communications domain, characterized by non-native\nspeech, noise, and specialized phraseology. Using about 5,000 hours of\nuntranscribed speech for BEARD and 2 hours of transcribed speech for\nfine-tuning, the proposed approach significantly outperforms previous baseline\nand fine-tuned model, achieving a relative improvement of 12% compared to the\nfine-tuned model. To the best of our knowledge, this is the first work to use a\nself-supervised learning objective for domain adaptation of Whisper.",
    "categories": [
      "cs.CL"
    ],
    "published": "2025-10-28T16:01:24Z",
    "authors": [
      "Rapha\u00ebl Bagat",
      "Irina Illina",
      "Emmanuel Vincent"
    ],
    "pdf_url": "http://arxiv.org/pdf/2510.24570v1"
  },
  {
    "id": "2510.25786v1",
    "title": "BlackboxNLP-2025 MIB Shared Task: Improving Circuit Faithfulness via\n  Better Edge Selection",
    "abstract": "One of the main challenges in mechanistic interpretability is circuit\ndiscovery, determining which parts of a model perform a given task. We build on\nthe Mechanistic Interpretability Benchmark (MIB) and propose three key\nimprovements to circuit discovery. First, we use bootstrapping to identify\nedges with consistent attribution scores. Second, we introduce a simple\nratio-based selection strategy to prioritize strong positive-scoring edges,\nbalancing performance and faithfulness. Third, we replace the standard greedy\nselection with an integer linear programming formulation. Our methods yield\nmore faithful circuits and outperform prior approaches across multiple MIB\ntasks and models. Our code is available at:\nhttps://github.com/technion-cs-nlp/MIB-Shared-Task.",
    "categories": [
      "cs.CL",
      "cs.AI"
    ],
    "published": "2025-10-28T15:49:34Z",
    "authors": [
      "Yaniv Nikankin",
      "Dana Arad",
      "Itay Itzhak",
      "Anja Reusch",
      "Adi Simhi",
      "Gal Kesten-Pomeranz",
      "Yonatan Belinkov"
    ],
    "pdf_url": "http://arxiv.org/pdf/2510.25786v1"
  },
  {
    "id": "2510.24541v1",
    "title": "Open Korean Historical Corpus: A Millennia-Scale Diachronic Collection\n  of Public Domain Texts",
    "abstract": "The history of the Korean language is characterized by a discrepancy between\nits spoken and written forms and a pivotal shift from Chinese characters to the\nHangul alphabet. However, this linguistic evolution has remained largely\nunexplored in NLP due to a lack of accessible historical corpora. To address\nthis gap, we introduce the Open Korean Historical Corpus, a large-scale, openly\nlicensed dataset spanning 1,300 years and 6 languages, as well as\nunder-represented writing systems like Korean-style Sinitic (Idu) and\nHanja-Hangul mixed script. This corpus contains 18 million documents and 5\nbillion tokens from 19 sources, ranging from the 7th century to 2025. We\nleverage this resource to quantitatively analyze major linguistic shifts: (1)\nIdu usage peaked in the 1860s before declining sharply; (2) the transition from\nHanja to Hangul was a rapid transformation starting around 1890; and (3) North\nKorea's lexical divergence causes modern tokenizers to produce up to 51 times\nhigher out-of-vocabulary rates. This work provides a foundational resource for\nquantitative diachronic analysis by capturing the history of the Korean\nlanguage. Moreover, it can serve as a pre-training corpus for large language\nmodels, potentially improving their understanding of Sino-Korean vocabulary in\nmodern Hangul as well as archaic writing systems.",
    "categories": [
      "cs.CL"
    ],
    "published": "2025-10-28T15:43:26Z",
    "authors": [
      "Seyoung Song",
      "Nawon Kim",
      "Songeun Chae",
      "Kiwoong Park",
      "Jiho Jin",
      "Haneul Yoo",
      "Kyunghyun Cho",
      "Alice Oh"
    ],
    "pdf_url": "http://arxiv.org/pdf/2510.24541v1"
  },
  {
    "id": "2510.24538v1",
    "title": "Dark & Stormy: Modeling Humor in the Worst Sentences Ever Written",
    "abstract": "Textual humor is enormously diverse and computational studies need to account\nfor this range, including intentionally bad humor. In this paper, we curate and\nanalyze a novel corpus of sentences from the Bulwer-Lytton Fiction Contest to\nbetter understand \"bad\" humor in English. Standard humor detection models\nperform poorly on our corpus, and an analysis of literary devices finds that\nthese sentences combine features common in existing humor datasets (e.g., puns,\nirony) with metaphor, metafiction and simile. LLMs prompted to synthesize\ncontest-style sentences imitate the form but exaggerate the effect by\nover-using certain literary devices, and including far more novel\nadjective-noun bigrams than human writers. Data, code and analysis are\navailable at https://github.com/venkatasg/bulwer-lytton",
    "categories": [
      "cs.CL"
    ],
    "published": "2025-10-28T15:42:03Z",
    "authors": [
      "Venkata S Govindarajan",
      "Laura Biester"
    ],
    "pdf_url": "http://arxiv.org/pdf/2510.24538v1"
  },
  {
    "id": "2510.24530v1",
    "title": "Lev\u00e9e d'ambigu\u00eft\u00e9s par grammaires locales",
    "abstract": "Many words are ambiguous in terms of their part of speech (POS). However,\nwhen a word appears in a text, this ambiguity is generally much reduced.\nDisambiguating POS involves using context to reduce the number of POS\nassociated with words, and is one of the main challenges of lexical tagging.\nThe problem of labeling words by POS frequently arises in natural language\nprocessing, for example for spelling correction, grammar or style checking,\nexpression recognition, text-to-speech conversion, text corpus analysis, etc.\nLexical tagging systems are thus useful as an initial component of many natural\nlanguage processing systems. A number of recent lexical tagging systems produce\nmultiple solutions when the text is lexically ambiguous or the uniquely correct\nsolution cannot be found. These contributions aim to guarantee a zero silence\nrate: the correct tag(s) for a word must never be discarded. This objective is\nunrealistic for systems that tag each word uniquely. This article concerns a\nlexical disambiguation method adapted to the objective of a zero silence rate\nand implemented in Silberztein's INTEX system (1993). We present here a formal\ndescription of this method. We show that to verify a local disambiguation\ngrammar in this framework, it is not sufficient to consider the transducer\npaths separately: one needs to verify their interactions. Similarly, if a\ncombination of multiple transducers is used, the result cannot be predicted by\nconsidering them in isolation. Furthermore, when examining the initial labeling\nof a text as produced by INTEX, ideas for disambiguation rules come\nspontaneously, but grammatical intuitions may turn out to be inaccurate, often\ndue to an unforeseen construction or ambiguity. If a zero silence rate is\ntargeted, local grammars must be carefully tested. This is where a detailed\nspecification of what a grammar will do once applied to texts would be\nnecessary.",
    "categories": [
      "cs.CL"
    ],
    "published": "2025-10-28T15:38:22Z",
    "authors": [
      "Eric G. C. Laporte"
    ],
    "pdf_url": "http://arxiv.org/pdf/2510.24530v1"
  },
  {
    "id": "2510.24824v1",
    "title": "Parallel Loop Transformer for Efficient Test-Time Computation Scaling",
    "abstract": "Large Language Models (LLMs) are powerful but often too slow and costly for\nreal-world use during inference. Looped transformers save on parameters by\nreusing the same weights for multiple computational steps, or \"loops.\" However,\nthis approach has a major flaw: the loops run one after another, causing\ninference latency and memory requirements to increase with each added loop.\nThis makes them impractical for fast applications. To solve this problem, we\nintroduce the Parallel Loop Transformer (PLT). PLT is a new architecture that\ndelivers the performance benefits of a deep, looped model but with the low\nlatency of a standard, non-looped model. PLT works using two key techniques.\nFirst, Cross-Loop Parallelism (CLP) breaks the sequential dependency by\ncomputing different loops for different tokens at the same time, all within a\nsingle pass. Second, to prevent memory costs from growing, we use an Efficient\nRepresentation Enhancement strategy. This method shares the memory (KV cache)\nfrom the first loop with all other loops. It then uses a Gated Sliding-Window\nAttention (G-SWA) to combine this shared global information with local\ninformation, maintaining high accuracy. Our experiments show that PLT achieves\nthe high accuracy of a traditional looped model but with almost no extra\nlatency or memory cost compared to a standard transformer.",
    "categories": [
      "cs.CL"
    ],
    "published": "2025-10-28T15:35:50Z",
    "authors": [
      "Bohong Wu",
      "Mengzhao Chen",
      "Xiang Luo",
      "Shen Yan",
      "Qifan Yu",
      "Fan Xia",
      "Tianqi Zhang",
      "Hongrui Zhan",
      "Zheng Zhong",
      "Xun Zhou",
      "Siyuan Qiao",
      "Xingyan Bin"
    ],
    "pdf_url": "http://arxiv.org/pdf/2510.24824v1"
  },
  {
    "id": "2510.24514v1",
    "title": "Latent Sketchpad: Sketching Visual Thoughts to Elicit Multimodal\n  Reasoning in MLLMs",
    "abstract": "While Multimodal Large Language Models (MLLMs) excel at visual understanding,\nthey often struggle in complex scenarios that require visual planning and\nimagination. Inspired by how humans use sketching as a form of visual thinking\nto develop and communicate ideas, we introduce Latent Sketchpad, a framework\nthat equips MLLMs with an internal visual scratchpad. The internal visual\nrepresentations of MLLMs have traditionally been confined to perceptual\nunderstanding. We repurpose them to support generative visual thought without\ncompromising reasoning ability. Building on frontier MLLMs, our approach\nintegrates visual generation directly into their native autoregressive\nreasoning process. It allows the model to interleave textual reasoning with the\ngeneration of visual latents. These latents guide the internal thought process\nand can be translated into sketch images for interpretability. To realize this,\nwe introduce two components: a Context-Aware Vision Head autoregressively\nproduces visual representations, and a pretrained Sketch Decoder renders these\ninto human-interpretable images. We evaluate the framework on our new dataset\nMazePlanning. Experiments across various MLLMs show that Latent Sketchpad\ndelivers comparable or even superior reasoning performance to their backbone.\nIt further generalizes across distinct frontier MLLMs, including Gemma3 and\nQwen2.5-VL. By extending model's textual reasoning to visual thinking, our\nframework opens new opportunities for richer human-computer interaction and\nbroader applications. More details and resources are available on our project\npage: https://latent-sketchpad.github.io/.",
    "categories": [
      "cs.CV",
      "cs.CL"
    ],
    "published": "2025-10-28T15:26:20Z",
    "authors": [
      "Huanyu Zhang",
      "Wenshan Wu",
      "Chengzu Li",
      "Ning Shang",
      "Yan Xia",
      "Yangyu Huang",
      "Yifan Zhang",
      "Li Dong",
      "Zhang Zhang",
      "Liang Wang",
      "Tieniu Tan",
      "Furu Wei"
    ],
    "pdf_url": "http://arxiv.org/pdf/2510.24514v1"
  },
  {
    "id": "2510.24505v1",
    "title": "CritiCal: Can Critique Help LLM Uncertainty or Confidence Calibration?",
    "abstract": "Accurate confidence calibration in Large Language Models (LLMs) is critical\nfor safe use in high-stakes domains, where clear verbalized confidence enhances\nuser trust. Traditional methods that mimic reference confidence expressions\noften fail to capture the reasoning needed for accurate confidence assessment.\nWe propose natural language critiques as a solution, ideally suited for\nconfidence calibration, as precise gold confidence labels are hard to obtain\nand often require multiple generations. This paper studies how natural language\ncritiques can enhance verbalized confidence, addressing: (1) What to critique:\nuncertainty (question-focused) or confidence (answer-specific)? Analysis shows\nconfidence suits multiple-choice tasks, while uncertainty excels in open-ended\nscenarios. (2) How to critique: self-critique or critique calibration training?\nWe propose Self-Critique, enabling LLMs to critique and optimize their\nconfidence beyond mere accuracy, and CritiCal, a novel Critique Calibration\ntraining method that leverages natural language critiques to improve confidence\ncalibration, moving beyond direct numerical optimization. Experiments show that\nCritiCal significantly outperforms Self-Critique and other competitive\nbaselines, even surpassing its teacher model, GPT-4o, in complex reasoning\ntasks. CritiCal also shows robust generalization in out-of-distribution\nsettings, advancing LLM's reliability.",
    "categories": [
      "cs.CL"
    ],
    "published": "2025-10-28T15:16:06Z",
    "authors": [
      "Qing Zong",
      "Jiayu Liu",
      "Tianshi Zheng",
      "Chunyang Li",
      "Baixuan Xu",
      "Haochen Shi",
      "Weiqi Wang",
      "Zhaowei Wang",
      "Chunkit Chan",
      "Yangqiu Song"
    ],
    "pdf_url": "http://arxiv.org/pdf/2510.24505v1"
  },
  {
    "id": "2510.24488v1",
    "title": "A word association network methodology for evaluating implicit biases in\n  LLMs compared to humans",
    "abstract": "As Large language models (LLMs) become increasingly integrated into our\nlives, their inherent social biases remain a pressing concern. Detecting and\nevaluating these biases can be challenging because they are often implicit\nrather than explicit in nature, so developing evaluation methods that assess\nthe implicit knowledge representations of LLMs is essential. We present a novel\nword association network methodology for evaluating implicit biases in LLMs\nbased on simulating semantic priming within LLM-generated word association\nnetworks. Our prompt-based approach taps into the implicit relational\nstructures encoded in LLMs, providing both quantitative and qualitative\nassessments of bias. Unlike most prompt-based evaluation methods, our method\nenables direct comparisons between various LLMs and humans, providing a\nvaluable point of reference and offering new insights into the alignment of\nLLMs with human cognition. To demonstrate the utility of our methodology, we\napply it to both humans and several widely used LLMs to investigate social\nbiases related to gender, religion, ethnicity, sexual orientation, and\npolitical party. Our results reveal both convergences and divergences between\nLLM and human biases, providing new perspectives on the potential risks of\nusing LLMs. Our methodology contributes to a systematic, scalable, and\ngeneralizable framework for evaluating and comparing biases across multiple\nLLMs and humans, advancing the goal of transparent and socially responsible\nlanguage technologies.",
    "categories": [
      "cs.CL",
      "cs.AI"
    ],
    "published": "2025-10-28T15:03:18Z",
    "authors": [
      "Katherine Abramski",
      "Giulio Rossetti",
      "Massimo Stella"
    ],
    "pdf_url": "http://arxiv.org/pdf/2510.24488v1"
  },
  {
    "id": "2510.24478v1",
    "title": "Talk2Ref: A Dataset for Reference Prediction from Scientific Talks",
    "abstract": "Scientific talks are a growing medium for disseminating research, and\nautomatically identifying relevant literature that grounds or enriches a talk\nwould be highly valuable for researchers and students alike. We introduce\nReference Prediction from Talks (RPT), a new task that maps long, and\nunstructured scientific presentations to relevant papers. To support research\non RPT, we present Talk2Ref, the first large-scale dataset of its kind,\ncontaining 6,279 talks and 43,429 cited papers (26 per talk on average), where\nrelevance is approximated by the papers cited in the talk's corresponding\nsource publication. We establish strong baselines by evaluating\nstate-of-the-art text embedding models in zero-shot retrieval scenarios, and\npropose a dual-encoder architecture trained on Talk2Ref. We further explore\nstrategies for handling long transcripts, as well as training for domain\nadaptation. Our results show that fine-tuning on Talk2Ref significantly\nimproves citation prediction performance, demonstrating both the challenges of\nthe task and the effectiveness of our dataset for learning semantic\nrepresentations from spoken scientific content. The dataset and trained models\nare released under an open license to foster future research on integrating\nspoken scientific communication into citation recommendation systems.",
    "categories": [
      "cs.CL"
    ],
    "published": "2025-10-28T14:50:03Z",
    "authors": [
      "Frederik Broy",
      "Maike Z\u00fcfle",
      "Jan Niehues"
    ],
    "pdf_url": "http://arxiv.org/pdf/2510.24478v1"
  },
  {
    "id": "2510.24476v1",
    "title": "Mitigating Hallucination in Large Language Models (LLMs): An\n  Application-Oriented Survey on RAG, Reasoning, and Agentic Systems",
    "abstract": "Hallucination remains one of the key obstacles to the reliable deployment of\nlarge language models (LLMs), particularly in real-world applications. Among\nvarious mitigation strategies, Retrieval-Augmented Generation (RAG) and\nreasoning enhancement have emerged as two of the most effective and widely\nadopted approaches, marking a shift from merely suppressing hallucinations to\nbalancing creativity and reliability. However, their synergistic potential and\nunderlying mechanisms for hallucination mitigation have not yet been\nsystematically examined. This survey adopts an application-oriented perspective\nof capability enhancement to analyze how RAG, reasoning enhancement, and their\nintegration in Agentic Systems mitigate hallucinations. We propose a taxonomy\ndistinguishing knowledge-based and logic-based hallucinations, systematically\nexamine how RAG and reasoning address each, and present a unified framework\nsupported by real-world applications, evaluations, and benchmarks.",
    "categories": [
      "cs.CL",
      "cs.AI"
    ],
    "published": "2025-10-28T14:48:57Z",
    "authors": [
      "Yihan Li",
      "Xiyuan Fu",
      "Ghanshyam Verma",
      "Paul Buitelaar",
      "Mingming Liu"
    ],
    "pdf_url": "http://arxiv.org/pdf/2510.24476v1"
  },
  {
    "id": "2510.24469v1",
    "title": "Iterative Critique-Refine Framework for Enhancing LLM Personalization",
    "abstract": "Personalized text generation requires models not only to produce coherent\ntext but also to align with a target user's style, tone, and topical focus.\nExisting retrieval-augmented approaches such as LaMP and PGraphRAG enrich\nprofiles with user and neighbor histories, but they stop at generation and\noften yield outputs that drift in tone, topic, or style. We present PerFine, a\nunified, training-free critique-refine framework that enhances personalization\nthrough iterative, profile-grounded feedback. In each iteration, an LLM\ngenerator produces a draft conditioned on the retrieved profile, and a critic\nLLM - also conditioned on the same profile - provides structured feedback on\ntone, vocabulary, sentence structure, and topicality. The generator then\nrevises, while a novel knockout strategy retains the stronger draft across\niterations. We further study additional inference-time strategies such as\nBest-of-N and Topic Extraction to balance quality and efficiency. Across Yelp,\nGoodreads, and Amazon datasets, PerFine consistently improves personalization\nover PGraphRAG, with GEval gains of +7-13%, steady improvements over 3-5\nrefinement iterations, and scalability with increasing critic size. These\nresults highlight that post-hoc, profile-aware feedback offers a powerful\nparadigm for personalized LLM generation that is both training-free and\nmodel-agnostic.",
    "categories": [
      "cs.CL",
      "cs.AI",
      "cs.IR"
    ],
    "published": "2025-10-28T14:36:22Z",
    "authors": [
      "Durga Prasad Maram",
      "Dhruvin Gandhi",
      "Zonghai Yao",
      "Gayathri Akkinapalli",
      "Franck Dernoncourt",
      "Yu Wang",
      "Ryan A. Rossi",
      "Nesreen K. Ahmed"
    ],
    "pdf_url": "http://arxiv.org/pdf/2510.24469v1"
  },
  {
    "id": "2510.24450v1",
    "title": "Charting the European LLM Benchmarking Landscape: A New Taxonomy and a\n  Set of Best Practices",
    "abstract": "While new benchmarks for large language models (LLMs) are being developed\ncontinuously to catch up with the growing capabilities of new models and AI in\ngeneral, using and evaluating LLMs in non-English languages remains a\nlittle-charted landscape. We give a concise overview of recent developments in\nLLM benchmarking, and then propose a new taxonomy for the categorization of\nbenchmarks that is tailored to multilingual or non-English use scenarios. We\nfurther propose a set of best practices and quality standards that could lead\nto a more coordinated development of benchmarks for European languages. Among\nother recommendations, we advocate for a higher language and culture\nsensitivity of evaluation methods.",
    "categories": [
      "cs.CL",
      "cs.AI"
    ],
    "published": "2025-10-28T14:13:44Z",
    "authors": [
      "\u0160pela Vintar",
      "Taja Kuzman Punger\u0161ek",
      "Mojca Brglez",
      "Nikola Ljube\u0161i\u0107"
    ],
    "pdf_url": "http://arxiv.org/pdf/2510.24450v1"
  },
  {
    "id": "2510.24446v1",
    "title": "SPARTA: Evaluating Reasoning Segmentation Robustness through Black-Box\n  Adversarial Paraphrasing in Text Autoencoder Latent Space",
    "abstract": "Multimodal large language models (MLLMs) have shown impressive capabilities\nin vision-language tasks such as reasoning segmentation, where models generate\nsegmentation masks based on textual queries. While prior work has primarily\nfocused on perturbing image inputs, semantically equivalent textual\nparaphrases-crucial in real-world applications where users express the same\nintent in varied ways-remain underexplored. To address this gap, we introduce a\nnovel adversarial paraphrasing task: generating grammatically correct\nparaphrases that preserve the original query meaning while degrading\nsegmentation performance. To evaluate the quality of adversarial paraphrases,\nwe develop a comprehensive automatic evaluation protocol validated with human\nstudies. Furthermore, we introduce SPARTA-a black-box, sentence-level\noptimization method that operates in the low-dimensional semantic latent space\nof a text autoencoder, guided by reinforcement learning. SPARTA achieves\nsignificantly higher success rates, outperforming prior methods by up to 2x on\nboth the ReasonSeg and LLMSeg-40k datasets. We use SPARTA and competitive\nbaselines to assess the robustness of advanced reasoning segmentation models.\nWe reveal that they remain vulnerable to adversarial paraphrasing-even under\nstrict semantic and grammatical constraints. All code and data will be released\npublicly upon acceptance.",
    "categories": [
      "cs.CL",
      "cs.CV"
    ],
    "published": "2025-10-28T14:09:05Z",
    "authors": [
      "Viktoriia Zinkovich",
      "Anton Antonov",
      "Andrei Spiridonov",
      "Denis Shepelev",
      "Andrey Moskalenko",
      "Daria Pugacheva",
      "Elena Tutubalina",
      "Andrey Kuznetsov",
      "Vlad Shakhuro"
    ],
    "pdf_url": "http://arxiv.org/pdf/2510.24446v1"
  },
  {
    "id": "2510.24442v1",
    "title": "Law in Silico: Simulating Legal Society with LLM-Based Agents",
    "abstract": "Since real-world legal experiments are often costly or infeasible, simulating\nlegal societies with Artificial Intelligence (AI) systems provides an effective\nalternative for verifying and developing legal theory, as well as supporting\nlegal administration. Large Language Models (LLMs), with their world knowledge\nand role-playing capabilities, are strong candidates to serve as the foundation\nfor legal society simulation. However, the application of LLMs to simulate\nlegal systems remains underexplored. In this work, we introduce Law in Silico,\nan LLM-based agent framework for simulating legal scenarios with individual\ndecision-making and institutional mechanisms of legislation, adjudication, and\nenforcement. Our experiments, which compare simulated crime rates with\nreal-world data, demonstrate that LLM-based agents can largely reproduce\nmacro-level crime trends and provide insights that align with real-world\nobservations. At the same time, micro-level simulations reveal that a\nwell-functioning, transparent, and adaptive legal system offers better\nprotection of the rights of vulnerable individuals.",
    "categories": [
      "cs.AI",
      "cs.CL",
      "cs.CY",
      "cs.MA"
    ],
    "published": "2025-10-28T14:07:10Z",
    "authors": [
      "Yiding Wang",
      "Yuxuan Chen",
      "Fanxu Meng",
      "Xifan Chen",
      "Xiaolei Yang",
      "Muhan Zhang"
    ],
    "pdf_url": "http://arxiv.org/pdf/2510.24442v1"
  },
  {
    "id": "2510.24438v1",
    "title": "Can LLMs Write Faithfully? An Agent-Based Evaluation of LLM-generated\n  Islamic Content",
    "abstract": "Large language models are increasingly used for Islamic guidance, but risk\nmisquoting texts, misapplying jurisprudence, or producing culturally\ninconsistent responses. We pilot an evaluation of GPT-4o, Ansari AI, and Fanar\non prompts from authentic Islamic blogs. Our dual-agent framework uses a\nquantitative agent for citation verification and six-dimensional scoring (e.g.,\nStructure, Islamic Consistency, Citations) and a qualitative agent for\nfive-dimensional side-by-side comparison (e.g., Tone, Depth, Originality).\nGPT-4o scored highest in Islamic Accuracy (3.93) and Citation (3.38), Ansari AI\nfollowed (3.68, 3.32), and Fanar lagged (2.76, 1.82). Despite relatively strong\nperformance, models still fall short in reliably producing accurate Islamic\ncontent and citations -- a paramount requirement in faith-sensitive writing.\nGPT-4o had the highest mean quantitative score (3.90/5), while Ansari AI led\nqualitative pairwise wins (116/200). Fanar, though trailing, introduces\ninnovations for Islamic and Arabic contexts. This study underscores the need\nfor community-driven benchmarks centering Muslim perspectives, offering an\nearly step toward more reliable AI in Islamic knowledge and other high-stakes\ndomains such as medicine, law, and journalism.",
    "categories": [
      "cs.CL",
      "cs.AI",
      "cs.CY",
      "cs.MA"
    ],
    "published": "2025-10-28T14:05:55Z",
    "authors": [
      "Abdullah Mushtaq",
      "Rafay Naeem",
      "Ezieddin Elmahjub",
      "Ibrahim Ghaznavi",
      "Shawqi Al-Maliki",
      "Mohamed Abdallah",
      "Ala Al-Fuqaha",
      "Junaid Qadir"
    ],
    "pdf_url": "http://arxiv.org/pdf/2510.24438v1"
  },
  {
    "id": "2510.24434v1",
    "title": "LuxIT: A Luxembourgish Instruction Tuning Dataset from Monolingual Seed\n  Data",
    "abstract": "The effectiveness of instruction-tuned Large Language Models (LLMs) is often\nlimited in low-resource linguistic settings due to a lack of high-quality\ntraining data. We introduce LuxIT, a novel, monolingual instruction tuning\ndataset for Luxembourgish developed to mitigate this challenge. We synthesize\nthe dataset from a corpus of native Luxembourgish texts, utilizing\nDeepSeek-R1-0528, chosen for its shown proficiency in Luxembourgish. Following\ngeneration, we apply a quality assurance process, employing an LLM-as-a-judge\napproach. To investigate the practical utility of the dataset, we fine-tune\nseveral smaller-scale LLMs on LuxIT. Subsequent benchmarking against their base\nmodels on Luxembourgish language proficiency examinations, however, yields\nmixed results, with performance varying significantly across different models.\nLuxIT represents a critical contribution to Luxembourgish natural language\nprocessing and offers a replicable monolingual methodology, though our findings\nhighlight the need for further research to optimize its application.",
    "categories": [
      "cs.CL"
    ],
    "published": "2025-10-28T14:02:55Z",
    "authors": [
      "Julian Valline",
      "Cedric Lothritz",
      "Jordi Cabot"
    ],
    "pdf_url": "http://arxiv.org/pdf/2510.24434v1"
  },
  {
    "id": "2510.24427v1",
    "title": "SynthWorlds: Controlled Parallel Worlds for Disentangling Reasoning and\n  Knowledge in Language Models",
    "abstract": "Evaluating the reasoning ability of language models (LMs) is complicated by\ntheir extensive parametric world knowledge, where benchmark performance often\nreflects factual recall rather than genuine reasoning. Existing datasets and\napproaches (e.g., temporal filtering, paraphrasing, adversarial substitution)\ncannot cleanly separate the two. We present SynthWorlds, a framework that\ndisentangles task reasoning complexity from factual knowledge. In SynthWorlds,\nwe construct parallel corpora representing two worlds with identical\ninterconnected structure: a real-mapped world, where models may exploit\nparametric knowledge, and a synthetic-mapped world, where such knowledge is\nmeaningless. On top of these corpora, we design two mirrored tasks as case\nstudies: multi-hop question answering and page navigation, which maintain equal\nreasoning difficulty across worlds. Experiments in parametric-only (e.g.,\nclosed-book QA) and knowledge-augmented (e.g., retrieval-augmented) LM settings\nreveal a persistent knowledge advantage gap, defined as the performance boost\nmodels gain from memorized parametric world knowledge. Knowledge acquisition\nand integration mechanisms reduce but do not eliminate this gap, highlighting\nopportunities for system improvements. Fully automatic and scalable,\nSynthWorlds provides a controlled environment for evaluating LMs in ways that\nwere previously challenging, enabling precise and testable comparisons of\nreasoning and memorization.",
    "categories": [
      "cs.CL"
    ],
    "published": "2025-10-28T13:47:23Z",
    "authors": [
      "Ken Gu",
      "Advait Bhat",
      "Mike A Merrill",
      "Robert West",
      "Xin Liu",
      "Daniel McDuff",
      "Tim Althoff"
    ],
    "pdf_url": "http://arxiv.org/pdf/2510.24427v1"
  },
  {
    "id": "2510.24425v1",
    "title": "Comprehensive and Efficient Distillation for Lightweight Sentiment\n  Analysis Models",
    "abstract": "Recent efforts leverage knowledge distillation techniques to develop\nlightweight and practical sentiment analysis models. These methods are grounded\nin human-written instructions and large-scale user texts. Despite the promising\nresults, two key challenges remain: (1) manually written instructions are\nlimited in diversity and quantity, making them insufficient to ensure\ncomprehensive coverage of distilled knowledge; (2) large-scale user texts incur\nhigh computational cost, hindering the practicality of these methods. To this\nend, we introduce COMPEFFDIST, a comprehensive and efficient distillation\nframework for sentiment analysis. Our framework consists of two key modules:\nattribute-based automatic instruction construction and difficulty-based data\nfiltering, which correspondingly tackle the aforementioned challenges. Applying\nour method across multiple model series (Llama-3, Qwen-3, and Gemma-3), we\nenable 3B student models to match the performance of 20x larger teacher models\non most tasks. In addition, our approach greatly outperforms baseline methods\nin data efficiency, attaining the same performance level with only 10% of the\ndata.",
    "categories": [
      "cs.CL"
    ],
    "published": "2025-10-28T13:46:48Z",
    "authors": [
      "Guangyu Xie",
      "Yice Zhang",
      "Jianzhu Bao",
      "Qianlong Wang",
      "Yang Sun",
      "Bingbing Wang",
      "Ruifeng Xu"
    ],
    "pdf_url": "http://arxiv.org/pdf/2510.24425v1"
  },
  {
    "id": "2510.24411v1",
    "title": "OS-Sentinel: Towards Safety-Enhanced Mobile GUI Agents via Hybrid\n  Validation in Realistic Workflows",
    "abstract": "Computer-using agents powered by Vision-Language Models (VLMs) have\ndemonstrated human-like capabilities in operating digital environments like\nmobile platforms. While these agents hold great promise for advancing digital\nautomation, their potential for unsafe operations, such as system compromise\nand privacy leakage, is raising significant concerns. Detecting these safety\nconcerns across the vast and complex operational space of mobile environments\npresents a formidable challenge that remains critically underexplored. To\nestablish a foundation for mobile agent safety research, we introduce\nMobileRisk-Live, a dynamic sandbox environment accompanied by a safety\ndetection benchmark comprising realistic trajectories with fine-grained\nannotations. Built upon this, we propose OS-Sentinel, a novel hybrid safety\ndetection framework that synergistically combines a Formal Verifier for\ndetecting explicit system-level violations with a VLM-based Contextual Judge\nfor assessing contextual risks and agent actions. Experiments show that\nOS-Sentinel achieves 10%-30% improvements over existing approaches across\nmultiple metrics. Further analysis provides critical insights that foster the\ndevelopment of safer and more reliable autonomous mobile agents.",
    "categories": [
      "cs.AI",
      "cs.CL",
      "cs.CV",
      "cs.HC"
    ],
    "published": "2025-10-28T13:22:39Z",
    "authors": [
      "Qiushi Sun",
      "Mukai Li",
      "Zhoumianze Liu",
      "Zhihui Xie",
      "Fangzhi Xu",
      "Zhangyue Yin",
      "Kanzhi Cheng",
      "Zehao Li",
      "Zichen Ding",
      "Qi Liu",
      "Zhiyong Wu",
      "Zhuosheng Zhang",
      "Ben Kao",
      "Lingpeng Kong"
    ],
    "pdf_url": "http://arxiv.org/pdf/2510.24411v1"
  },
  {
    "id": "2510.25784v1",
    "title": "zFLoRA: Zero-Latency Fused Low-Rank Adapters",
    "abstract": "Large language models (LLMs) are increasingly deployed with task-specific\nadapters catering to multiple downstream applications. In such a scenario, the\nadditional compute associated with these apparently insignificant number of\nadapter parameters (typically less than 1% of the base model) turns out to be\ndisproportionately significant during inference time (upto 2.5x times that of\nthe base model). In this paper, we propose a new zero-latency fused low-rank\nadapter (zFLoRA) that introduces zero or negligible latency overhead on top of\nthe base model. Experimental results on LLMs of size 1B, 3B and 7B show that\nzFLoRA compares favorably against the popular supervised fine-tuning benchmarks\nincluding low-rank adapters (LoRA) as well as full fine-tuning (FFT).\nExperiments are conducted on 18 different tasks across three different\ncategories namely commonsense reasoning, math reasoning and summary-dialogue.\nLatency measurements made on NPU (Samsung Galaxy S25+) as well as GPU (NVIDIA\nH100) platforms show that the proposed zFLoRA adapters introduce zero to\nnegligible latency overhead.",
    "categories": [
      "cs.CL",
      "cs.AI",
      "cs.LG"
    ],
    "published": "2025-10-28T13:10:41Z",
    "authors": [
      "Dhananjaya Gowda",
      "Seoha Song",
      "Harshith Goka",
      "Junhyun Lee"
    ],
    "pdf_url": "http://arxiv.org/pdf/2510.25784v1"
  },
  {
    "id": "2510.24365v1",
    "title": "Text Simplification with Sentence Embeddings",
    "abstract": "Sentence embeddings can be decoded to give approximations of the original\ntexts used to create them. We explore this effect in the context of text\nsimplification, demonstrating that reconstructed text embeddings preserve\ncomplexity levels. We experiment with a small feed forward neural network to\neffectively learn a transformation between sentence embeddings representing\nhigh-complexity and low-complexity texts. We provide comparison to a Seq2Seq\nand LLM-based approach, showing encouraging results in our much smaller\nlearning setting. Finally, we demonstrate the applicability of our\ntransformation to an unseen simplification dataset (MedEASI), as well as\ndatasets from languages outside the training data (ES,DE). We conclude that\nlearning transformations in sentence embedding space is a promising direction\nfor future research and has potential to unlock the ability to develop small,\nbut powerful models for text simplification and other natural language\ngeneration tasks.",
    "categories": [
      "cs.CL"
    ],
    "published": "2025-10-28T12:41:10Z",
    "authors": [
      "Matthew Shardlow"
    ],
    "pdf_url": "http://arxiv.org/pdf/2510.24365v1"
  },
  {
    "id": "2510.24358v1",
    "title": "Automatically Benchmarking LLM Code Agents through Agent-Driven\n  Annotation and Evaluation",
    "abstract": "Recent advances in code agents have enabled automated software development at\nthe project level, supported by large language models (LLMs) and widely adopted\ntools. However, existing benchmarks for code agent evaluation face two major\nlimitations: high annotation cost and expertise requirements, and rigid\nevaluation metrics that rely primarily on unit tests. To address these\nchallenges, we propose an agent-driven benchmark construction pipeline that\nleverages human supervision to efficiently generate diverse and challenging\nproject-level tasks. Based on this approach, we introduce PRDBench, a novel\nbenchmark comprising 50 real-world Python projects across 20 domains, each with\nstructured Product Requirement Document (PRD) requirements, comprehensive\nevaluation criteria, and reference implementations. PRDBench features rich data\nsources, high task complexity, and flexible metrics. We further employ an\nAgent-as-a-Judge paradigm to score agent outputs, enabling the evaluation of\nvarious test types beyond unit tests. Extensive experiments on PRDBench\ndemonstrate its effectiveness in assessing the capabilities of both code agents\nand evaluation agents, providing a scalable and robust framework for annotation\nand evaluation.",
    "categories": [
      "cs.SE",
      "cs.CL"
    ],
    "published": "2025-10-28T12:26:45Z",
    "authors": [
      "Lingyue Fu",
      "Bolun Zhang",
      "Hao Guan",
      "Yaoming Zhu",
      "Lin Qiu",
      "Weiwen Liu",
      "Xuezhi Cao",
      "Xunliang Cai",
      "Weinan Zhang",
      "Yong Yu"
    ],
    "pdf_url": "http://arxiv.org/pdf/2510.24358v1"
  },
  {
    "id": "2510.24345v1",
    "title": "LongWeave: A Long-Form Generation Benchmark Bridging Real-World\n  Relevance and Verifiability",
    "abstract": "Generating long, informative, and factual outputs remains a major challenge\nfor Large Language Models (LLMs). Existing benchmarks for long-form generation\ntypically assess real-world queries with hard-to-verify metrics or use\nsynthetic setups that ease evaluation but overlook real-world intricacies. In\nthis paper, we introduce \\textbf{LongWeave}, which balances real-world and\nverifiable assessment with Constraint-Verifier Evaluation (CoV-Eval). CoV-Eval\nconstructs tasks by first defining verifiable targets within real-world\nscenarios, then systematically generating corresponding queries, textual\nmaterials, and constraints based on these targets. This ensures that tasks are\nboth realistic and objectively assessable, enabling rigorous assessment of\nmodel capabilities in meeting complex real-world constraints. LongWeave\nsupports customizable input/output lengths (up to 64K/8K tokens) across seven\ndistinct tasks. Evaluation on 23 LLMs shows that even state-of-the-art models\nencounter significant challenges in long-form generation as real-world\ncomplexity and output length increase.",
    "categories": [
      "cs.CL",
      "cs.AI"
    ],
    "published": "2025-10-28T12:11:12Z",
    "authors": [
      "Zikai Xiao",
      "Fei Huang",
      "Jianhong Tu",
      "Jianhui Wei",
      "Wen Ma",
      "Yuxuan Zhou",
      "Jian Wu",
      "Bowen Yu",
      "Zuozhu Liu",
      "Junyang Lin"
    ],
    "pdf_url": "http://arxiv.org/pdf/2510.24345v1"
  },
  {
    "id": "2510.24328v1",
    "title": "Beyond MCQ: An Open-Ended Arabic Cultural QA Benchmark with Dialect\n  Variants",
    "abstract": "Large Language Models (LLMs) are increasingly used to answer everyday\nquestions, yet their performance on culturally grounded and dialectal content\nremains uneven across languages. We propose a comprehensive method that (i)\ntranslates Modern Standard Arabic (MSA) multiple-choice questions (MCQs) into\nEnglish and several Arabic dialects, (ii) converts them into open-ended\nquestions (OEQs), (iii) benchmarks a range of zero-shot and fine-tuned LLMs\nunder both MCQ and OEQ settings, and (iv) generates chain-of-thought (CoT)\nrationales to fine-tune models for step-by-step reasoning. Using this method,\nwe extend an existing dataset in which QAs are parallelly aligned across\nmultiple language varieties, making it, to our knowledge, the first of its\nkind. We conduct extensive experiments with both open and closed models. Our\nfindings show that (i) models underperform on Arabic dialects, revealing\npersistent gaps in culturally grounded and dialect-specific knowledge; (ii)\nArabic-centric models perform well on MCQs but struggle with OEQs; and (iii)\nCoT improves judged correctness while yielding mixed n-gram-based metrics. The\ndeveloped dataset will be publicly released to support further research on\nculturally and linguistically inclusive evaluation.",
    "categories": [
      "cs.CL",
      "cs.AI",
      "68T50",
      "F.2.2; I.2.7"
    ],
    "published": "2025-10-28T11:52:51Z",
    "authors": [
      "Hunzalah Hassan Bhatti",
      "Firoj Alam"
    ],
    "pdf_url": "http://arxiv.org/pdf/2510.24328v1"
  },
  {
    "id": "2510.24320v1",
    "title": "Critique-RL: Training Language Models for Critiquing through Two-Stage\n  Reinforcement Learning",
    "abstract": "Training critiquing language models to assess and provide feedback on model\noutputs is a promising way to improve LLMs for complex reasoning tasks.\nHowever, existing approaches typically rely on stronger supervisors for\nannotating critique data. To address this, we propose Critique-RL, an online RL\napproach for developing critiquing language models without stronger\nsupervision. Our approach operates on a two-player paradigm: the actor\ngenerates a response, the critic provides feedback, and the actor refines the\nresponse accordingly. We first reveal that relying solely on indirect reward\nsignals from the actor's outputs for RL optimization often leads to\nunsatisfactory critics: while their helpfulness (i.e., providing constructive\nfeedback) improves, the discriminability (i.e., determining whether a response\nis high-quality or not) remains poor, resulting in marginal performance gains.\nTo overcome this, Critique-RL adopts a two-stage optimization strategy. In\nstage I, it reinforces the discriminability of the critic with direct\nrule-based reward signals; in stage II, it introduces indirect rewards based on\nactor refinement to improve the critic's helpfulness, while maintaining its\ndiscriminability via appropriate regularization. Extensive experiments across\nvarious tasks and models show that Critique-RL delivers substantial performance\nimprovements. For example, it achieves a 9.02% gain on in-domain tasks and a\n5.70% gain on out-of-domain tasks for Qwen2.5-7B, highlighting its potential.",
    "categories": [
      "cs.CL",
      "cs.AI"
    ],
    "published": "2025-10-28T11:37:01Z",
    "authors": [
      "Zhiheng Xi",
      "Jixuan Huang",
      "Xin Guo",
      "Boyang Hong",
      "Dingwen Yang",
      "Xiaoran Fan",
      "Shuo Li",
      "Zehui Chen",
      "Junjie Ye",
      "Siyu Yuan",
      "Zhengyin Du",
      "Xuesong Yao",
      "Yufei Xu",
      "Jiecao Chen",
      "Rui Zheng",
      "Tao Gui",
      "Qi Zhang",
      "Xuanjing Huang"
    ],
    "pdf_url": "http://arxiv.org/pdf/2510.24320v1"
  },
  {
    "id": "2510.24302v2",
    "title": "Lookahead Tree-Based Rollouts for Enhanced Trajectory-Level Exploration\n  in Reinforcement Learning with Verifiable Rewards",
    "abstract": "Reinforcement Learning with Verifiable Rewards (RLVR), particularly with\nalgorithms like Group Relative Policy Optimization (GRPO), has proven highly\neffective in enhancing the reasoning capabilities of large language models.\nHowever, a critical bottleneck in current pipelines lies in the limited\ndiversity of sampled trajectories during group rollouts. Homogeneous\ntrajectories and their associated rewards would diminish the return signals for\npolicy updates, thereby hindering effective policy learning. This lack of\ndiversity stems primarily from token-level stochastic sampling, where local\nvariations are likely to collapse into near-identical reasoning paths. To\naddress this limitation, we propose Lookahead Tree-Based Rollouts (LATR), a\nnovel rollout strategy designed to explicitly promotes trajectory-level\ndiversity by enforcing branching into different candidate tokens likely to\nyield distinct continuations. Specifically, LATR iteratively operates in three\nstages: (1) branching at high-uncertainty generation steps, (2) performing\nlookahead simulation for each new branch, and (3) pruning branches that\nexhibits prolonged similarity during simulation. Compared with stochastic\nSampling, LATR accelerates policy learning by 131% on average and improves\nfinal pass@1 performance by 4.2% on both GRPO and Dynamic sAmpling Policy\nOptimization (DAPO) algorithms across different reasoning tasks. Our code and\ndata are publicly available at https://github.com/starreeze/latr.",
    "categories": [
      "cs.CL"
    ],
    "published": "2025-10-28T11:12:02Z",
    "authors": [
      "Shangyu Xing",
      "Siyuan Wang",
      "Chenyuan Yang",
      "Xinyu Dai",
      "Xiang Ren"
    ],
    "pdf_url": "http://arxiv.org/pdf/2510.24302v2"
  },
  {
    "id": "2510.25783v1",
    "title": "LASTIST: LArge-Scale Target-Independent STance dataset",
    "abstract": "Stance detection has emerged as an area of research in the field of\nartificial intelligence. However, most research is currently centered on the\ntarget-dependent stance detection task, which is based on a person's stance in\nfavor of or against a specific target. Furthermore, most benchmark datasets are\nbased on English, making it difficult to develop models in low-resource\nlanguages such as Korean, especially for an emerging field such as stance\ndetection. This study proposes the LArge-Scale Target-Independent STance\n(LASTIST) dataset to fill this research gap. Collected from the press releases\nof both parties on Korean political parties, the LASTIST dataset uses 563,299\nlabeled Korean sentences. We provide a detailed description of how we collected\nand constructed the dataset and trained state-of-the-art deep learning and\nstance detection models. Our LASTIST dataset is designed for various tasks in\nstance detection, including target-independent stance detection and diachronic\nevolution stance detection. We deploy our dataset on\nhttps://anonymous.4open.science/r/LASTIST-3721/.",
    "categories": [
      "cs.CL",
      "cs.AI",
      "I.2.7"
    ],
    "published": "2025-10-28T11:07:29Z",
    "authors": [
      "DongJae Kim",
      "Yaejin Lee",
      "Minsu Park",
      "Eunil Park"
    ],
    "pdf_url": "http://arxiv.org/pdf/2510.25783v1"
  },
  {
    "id": "2510.24295v1",
    "title": "MERGE: Minimal Expression-Replacement GEneralization Test for Natural\n  Language Inference",
    "abstract": "In recent years, many generalization benchmarks have shown language models'\nlack of robustness in natural language inference (NLI). However, manually\ncreating new benchmarks is costly, while automatically generating high-quality\nones, even by modifying existing benchmarks, is extremely difficult. In this\npaper, we propose a methodology for automatically generating high-quality\nvariants of original NLI problems by replacing open-class words, while\ncrucially preserving their underlying reasoning. We dub our generalization test\nas MERGE (Minimal Expression-Replacements GEneralization), which evaluates the\ncorrectness of models' predictions across reasoning-preserving variants of the\noriginal problem. Our results show that NLI models' perform 4-20% worse on\nvariants, suggesting low generalizability even on such minimally altered\nproblems. We also analyse how word class of the replacements, word probability,\nand plausibility influence NLI models' performance.",
    "categories": [
      "cs.CL"
    ],
    "published": "2025-10-28T10:58:59Z",
    "authors": [
      "M\u0103d\u0103lina Zgreab\u0103n",
      "Tejaswini Deoskar",
      "Lasha Abzianidze"
    ],
    "pdf_url": "http://arxiv.org/pdf/2510.24295v1"
  }
]